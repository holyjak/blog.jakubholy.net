[
 {
  "title": "Interactive analysis of performance data with OOo Calc (distribution, checkboxes, …)",
  "published": "2010-11-11 12:27:07",
  "postType": "post",
  "slug": "/552",
  "status": "draft",
  "tags": [
   "analysis",
   "data",
   "openoffice",
   "performance",
   "statistics"
  ],
  "categories": [
   "General",
   "Tools"
  ],
  "content": "We need to somehow analyse statistical data about the performance of our batch job to understand its behavior in time and bottlenecks. The metrics include total run time, number of processed records and total/mean/std. deviation of execution time of various components of the job such as LDAP queries and web service call. We'd like to know how \"stable\" these metrics are, i.e. if there is large or small variation in the speed of the job/external systems, and what the average characteristics - and their variations - are. I've decided to use OpenOffice.org Calc to analyse the data, namely to compute the group characteristics (mean, deviation etc.) and to plot the data to get an easy to understand overview of the data. I'd also like the view of the data to be interactive, i.e. to change based on some choices regarding the input data, such as whether to include extreme values or custom, non-scheduled run of the job. This blogs describes what I've done and few neat Calc tricks I've learned.<br><br><!--more--><br><br>Disclaimer: I'm not a Calc guru and I've already forgotten most I've learned about statistics at the unviversity, therefore my use of them may be flawed. Improvement suggestions are warmly welcomed.<br><br>I'm using Calc 3.2 under Ubuntu 10.04.\r\n<h2>Side note about localization</h2>\r\nI believe that OOo Calc uses different special characters based on your local. For me the following apply:\r\n<ul>\r\n\t<li>function parameters are separated with a comma (,)</li>\r\n\t<li>text is enclosed with double quotes (\"...\")</li>\r\n\t<li>I use decimal dot (11/10 = 1.1)</li>\r\n</ul>\r\nCheck what works for you.\r\n<h2>My performance data analysis</h2>\r\nSee the next part, Calc functions and features used in the analysis, for detailed instructions regarding the individual Calc features used in the analysis.\r\n<h3>Generating frequency table for plotting distribution based on percentiles</h3>\r\nLets suppose that you have a range of numbers in A1:A30 and that the range is named 'data'. You want to see their distribution.<br><br>To plot a distribution graph in Calc you need to assign the (likely continous) input values into a limited number of discrete groups (categories). For example for time you could define a category for each hour (0-1h, 1-2h, .., 22-23h). In other words, you need to create a <strong>frequency table</strong> with some N categories:\r\n<table>\r\n<tbody>\r\n<tr>\r\n<th>Range upper limit</th>\r\n<th># values in the range</th>\r\n</tr>\r\n<tr>\r\n<td>Range 1 top</td>\r\n<td># values between 0 and this value</td>\r\n</tr>\r\n<tr>\r\n<td colspan=\"2\">...</td>\r\n</tr>\r\n<tr>\r\n<td>Range N-1 top</td>\r\n<td># values between (Range N-2 top) and (Range N-1 top)</td>\r\n</tr>\r\n<tr>\r\n<td>-</td>\r\n<td># values above (Range N-1 top)</td>\r\n</tr>\r\n</tbody>\r\n</table>\r\nHowever you don't want to define the limits of categories manually because you aren't sure how large numbers there can be in the input. Also, you don't want extremely low/high but rare values to distort the view of the normal and common values.<br><br>We will therefore <strong>define 10 categories dynamically</strong> using the 5% and 95% percentiles for the first and last category, dividing the range between them equally.\r\n<ul>\r\n\t<li>A \"10% percentile\" is such a value, that 10% of the input data is less  or equal to it. It approximately means that it is the 10th smallest  value.</li>\r\n</ul>\r\nOne of the advantages of this solution is that the extreme values, which tend to be little frequent, will be in the 5% percentile and between the 95% and 100% percentile, i.e. in the first and last categories, and we can thus easily exclude them to get less distorted view.<br><br>To compute the actual frequencies from the input data and the defined ranges we will use the FREQUENCY array function.<br><br>The frequency table will be:\r\n<ul>\r\n\t<li>the first column with \"range tops\" will be used to create the named range \"data_ranges\"</li>\r\n\t<li>lets suppose that the cell $B$28 contains the \"inner range step\" computed as ((first range - last range)/8), i.e. (PERCENTILE(data,0.95)-PERCENTILE(data,0.05))/8</li>\r\n\t<li>the INDEX(range,row,column) function returns, in this case, the first range, i.e. the 5% percentile</li>\r\n</ul>\r\n<table>\r\n<tbody>\r\n<tr>\r\n<th>Range tops</th>\r\n<th>Frequencies</th>\r\n</tr>\r\n<tr>\r\n<td>=PERCENTILE(data,0.05)</td>\r\n<td>{=FREQUENCY(data, data_ranges)}</td>\r\n</tr>\r\n<tr>\r\n<td>=1* $B$28*1+INDEX(data_ranges,1,1)</td>\r\n<td>(a frequency produced by the FREQ. function)</td>\r\n</tr>\r\n<tr>\r\n<td>=2* $B$28*1+INDEX(data_ranges,1,1)</td>\r\n<td>(a frequency produced by the FREQ. function)</td>\r\n</tr>\r\n<tr>\r\n<td>=3* $B$28*1+INDEX(data_ranges,1,1)</td>\r\n<td>(a frequency produced by the FREQ. function)</td>\r\n</tr>\r\n<tr>\r\n<td>=4* $B$28*1+INDEX(data_ranges,1,1)</td>\r\n<td>(a frequency produced by the FREQ. function)</td>\r\n</tr>\r\n<tr>\r\n<td>=5* $B$28*1+INDEX(data_ranges,1,1)</td>\r\n<td>(a frequency produced by the FREQ. function)</td>\r\n</tr>\r\n<tr>\r\n<td>=6* $B$28*1+INDEX(data_ranges,1,1)</td>\r\n<td>(a frequency produced by the FREQ. function)</td>\r\n</tr>\r\n<tr>\r\n<td>=7* $B$28*1+INDEX(data_ranges,1,1)</td>\r\n<td>(a frequency produced by the FREQ. function)</td>\r\n</tr>\r\n<tr>\r\n<td>=PERCENTILE(data,0.95)</td>\r\n<td>(a frequency produced by the FREQ. function)</td>\r\n</tr>\r\n<tr>\r\n<td></td>\r\n<td>(a frequency produced by the FREQ. function)</td>\r\n</tr>\r\n</tbody>\r\n</table>\r\nIt may be a good idea to use relative frequencies instead of the actual ones (FREQUENCY(..)/COUNT(data)).\r\n<h2>Calc functions and features used in the analysis</h2>\r\n<h3>Naming fields/ranges for readability and maintainability</h3>\r\nYou can assign a name to a cell or a range of cells and use that name instead of the cell name (such as A1) or range (such as A1:A26). The names are unique within the spreadsheet and thus don't need to be prefixed with sheet name.\r\n<h4>Naming a range</h4>\r\n<ul>\r\n\t<li>Select cells</li>\r\n\t<li>Insert - Names - Define, type a name, e.g. \"my range\"</li>\r\n\t<li>To select the whole range, select its cell and press Ctrl+\\ You will then see its name in the position field (next to the formula bar).</li>\r\n</ul>\r\nUsing the range in a function - simply type its name (without the sheet name), ex.: \"=PERCENTILE(my range, 0.1)\"\r\n<h4>Naming a cell</h4>\r\n<ul>\r\n\t<li>as naming a range but select just a single cell; can be used in functions as well</li>\r\n\t<li>when you click on the cell, you should see its name in the name field inst. of the old &lt;letter&gt;&lt;number&gt;</li>\r\n</ul>\r\n<h4>Limitations of the named ranges/cells</h4>\r\nIt seems that as of Calc 3.2.0, you can't use the names everywhere, for example when declaring a data range for a chart or a linked cell for a form control.\r\n<h3>Array formulas and functions (for applying an operation to a range of cells)</h3>\r\nInto a cell you can insert a formula that operates on an array of cells and also produces an array, instead of doing the operation for each cell separately. For example, if you have numbers in A1:A10 and want to have them divided by 10 in the row below then you can - instead of entering \"=A1/10\" into B1 etc. - enter \"=A1:A10/10\" into B1 and the whole row B1:B10 is generated. Individual cells of the result are then locked against changes.<br><br>BEWARE: For the formula to be truly an array formula, when <strong>creating it</strong>, <em>you must either press Control+Shift+Enter</em> instead of Enter if typing it manually <em>or check \"Array\"</em> (left-bottom corner) if using the Function Wizard. An array formula is denoted by braces (\"{=A1:A10/10}\") but you can't type them manually, you must use either C+S+Enter or the Array check-box.<br><br>Array formulas may contain also array functions such as the FREQUENCY function, taking data row and a list of upper limits and producing a table of frequencies of the data values in the individual categories.<br><br><strong>To modify</strong> an array formula you must select all its cells otherwise Calc will warn you that \"You cannot change only part of an array.\".\r\n<h3>Useful techniques</h3>\r\n<h4>Ignore/include a cell by switching between blank/value based on dynamic criteria</h4>\r\nI find it useful to be able to dynamically decide what data should or shouldn't go into a computation (such as including all data or only those in a particular range). The only way I've found so far to do it is to create a derived data range where data is replaced with a blank when it should be excluded and using functions and formulas that ignore such fields. Unfortunatelly it doesn't work everywhere, for example I don't know how to make charts ignore blank values.<br><br>To switch between blank/value you would use the IF function: IF(test, input cell, \"\"). You can build more complex expressions with the other logical functions.<br><br>Some functions that ignore blanks (which is what we want):\r\n<ul>\r\n\t<li>AVG</li>\r\n\t<li>SUMIF(test&amp;data range, condition) - blank cells are ignored; the condition is either a number, tested for equality, or a text expression such as \"&gt;3.1\". There is also a 3-parameters version, where the test and data ranges may be different.</li>\r\n</ul>\r\nWhere blanks aren't ingored:\r\n<ul>\r\n\t<li>Chart data ranges (you can select to either assume 0 or display a gap in the chart but not to ignore it)\r\n<ul>\r\n\t<li><a href=\"http://user.services.openoffice.org/en/forum/viewtopic.php?f=9&amp;t=13797\">Work-around</a>: Read the data from a \"database\" with \"select X from ... where X is not null\". You can also <a href=\"http://user.services.openoffice.org/en/forum/viewtopic.php?f=9&amp;t=13778&amp;p=64604#p64604\">turn the spreadsheet  into a pseudo-database</a> to do the trick (defined named DB ranges, File-New-Database, Connect to existing - spreadsheet).</li>\r\n</ul>\r\n</li>\r\n</ul>\r\n<h5>Example</h5>\r\nLet's suppose that you have\r\n<ul>\r\n\t<li>Measured heights of people in A1:A10</li>\r\n\t<li>The sex of the people in B1:B10 ('M' or 'F')</li>\r\n\t<li>A cell named \"female_only\", which contains either TRUE or FALSE (a boolean, not a string)</li>\r\n</ul>\r\nIn C1:C10 you want to have either all or only female heights based on the value of \"female_only\". You will therefore type the following into C1 and copy it to C2 - C10:<br><br><pre><code><br><br>=IF(AND(female_only,B1=&quot;M&quot;),&quot;&quot;, A1)<br><br></code></pre><br><br>If the condition is true then the content of the cell will be \"\", i.e. it will be blank.\r\n<h5>Alternatives</h5>\r\n<ul>\r\n\t<li>Somebody proposes to <a href=\"http://user.services.openoffice.org/en/forum/viewtopic.php?f=9&amp;t=13797#p64920\">use the function NA()</a> (not available) instead of blanks, though it also seems to have some issues.</li>\r\n</ul>\r\n<h3>Creating an interactive view with form elements (check boxes etc.)</h3>\r\nYou can add form elements such as check boxes to a Calc spreadsheet to make it easy for the reader to easily control the data. The form elements usually retrieve input from some cells and output something into a cell, based on their state. You could simply change data in the cells manually but the controls make it more comfortable to use.\r\n<h4>Adding a check box for enabling/disabling filtering criteria</h4>\r\n<ol>\r\n\t<li>Show the form controls toolbar: View - Toolbars - Form controls</li>\r\n\t<li>Use the Form controls toolbar to switch to the design mode (the icon an [OK] button and a hand)</li>\r\n\t<li>Click on the check box icon and place it somewhere into the sheet (by drawing a rectangle)</li>\r\n\t<li>Right-click it and select Control... from the pop-up menu</li>\r\n\t<li>Click the Data tab</li>\r\n\t<li>Enter a cell name (e.g. B1) into the Linked Cell (do not fill the Reference value fields)</li>\r\n\t<li>Switch off the design mode; now clicking the check box will insert TRUE or FALSE (a boolean value) into the linked cell</li>\r\n</ol>\r\n<h4>Adding a list box for selecting from a predefined list on entries</h4>\r\nThis is similar to inserting a checkbox, only we will define a static list of values that can be selected. This is done on the first tab of the control's configuration page in the List Entries entry - use Shift+Enter to separate individual values.<br><br>For detailed instructions see page 3 in [FIND].\r\n<h2>Resources</h2>\r\n<ul>\r\n\t<li>[FREF] <a href=\"http://wiki.services.openoffice.org/wiki/Documentation/How_Tos/Calc:_Functions_listed_by_category\">Calc funtions reference</a> - well done and very valuable (much better than Calc's Help)\r\n<ul>\r\n\t<li>The <a href=\"http://wiki.services.openoffice.org/wiki/Documentation/How_Tos/Calc:_FREQUENCY_function\">FREQUENCY</a> function (generates frequency tables based on data and thresholds)</li>\r\n</ul>\r\n</li>\r\n\t<li>[INST] <a href=\"http://www.comfsm.fm/~dleeling/statistics/notes000.html\">Introduction to Statistics Using OpenOffice.org Calc</a></li>\r\n\t<li>[FIND] <a href=\"http://www.linuxidentity.com/us/down/articles/OOo_23_calc_find.pdf\">Using formulas to find Calc data</a> - with form-based UI</li>\r\n</ul>\r\n<h2>Summary</h2>",
  "excerpt": ""
 },
 {
  "title": "Dynamic ranges in OOo Calc - a chart self-adjusts as data grow",
  "published": "0000-00-00 00:00:00",
  "postType": "post",
  "slug": "/574",
  "status": "draft",
  "tags": [
   "analysis",
   "calc",
   "charting"
  ],
  "categories": [
   "General",
   "Tools"
  ],
  "content": "I'm using OpenOffice.org Calc for data analysis and visualization and I'd like to have computations and charts that automatically update themselves as more data rows are added into the sheet. And I don't want to read the data from a database (though that would be the easiest and more flexible solution). A naive approach is to include all rows - whether they already contain data or not yet - but this doesn't really work because some functions do not ignore blank fields and certainly charts are not able to ignore them (there there only the options to either replace them with 0 or have a gap in the graph). However, there is a solution - using a derived, filtered database range.<br><br><!--more--><br><br>This article is <a href=\"http://user.services.openoffice.org/en/forum/viewtopic.php?f=9&amp;t=13797\">based on a forum post by Villeroy</a>, you may want to see its attachement <a href=\"http://user.services.openoffice.org/en/forum/download/file.php?id=3270&amp;sid=ff1466467799e26df48beda6b071350b\">Line_vs_Scatter.ods</a>.<br><br>My platform is Calc 3.2.0 on Ubuntu 10.04.\n<h2>Steps</h2>\nBeware the performance: Consider not including all rows because Calc could have performance problems if it had too many of rows to process. 65,536 rows seems to be quite OK for me.\n<h3>1. Prepare the input data - add an IsDataPresent indicator and define the source range</h3>\nWe will need to add a boolean column that indicates whether data is present on a row or not, to use it later in as a filter criteria.<br><br>Create a row with the label \"IsDataPresent\" that indicates whether the data in a column is present or not, for example via<br><br><pre><code>=NOT(ISBLANK(A1)),  =NOT(ISBLANK(A2)), etc.</code></pre>\n<p style=\"padding-left:30px;\">In theory it would be better to use an <em>array expression</em> (typing '=NOT(ISBLANK(A1:A65536))' into the 1st cell and pressing Ctrl+Shift+Enter) but I've found out that it makes updating the source range impossible (due to \"You cannot modify only a part of an array\" or st. like that).</p>\nNext define the source database range:\n<ol>\n\t<li>Select all the input columns and the IsDataPresent column and as many rows as you've decided to use at maximum (i.e. all rows that have the IsDataPresent formula).</li>\n\t<li>Data - Define Range...</li>\n\t<li>Type a name for examle \"data\"</li>\n\t<li>You may want to click the button [More] and check \"Contains column labels\"</li>\n\t<li>[OK]</li>\n</ol>\n<h3>2. Define the target database range</h3>\nSelect the space where you would like to have the data for all further operation. I'd suggest to select as many columns as there are in the input but only one row - the range will grow dynamically based on the number of present rows in the input.\n<ol>\n\t<li>Data - Define Range...</li>\n\t<li>Type a name for examle \"target\"</li>\n\t<li>Click the button [More]\n<ul>\n\t<li>Check \"Insert or delete cells\" so that the range can grow dynamically when rows are added into the source range (more exactly when the value of the filter criteria column changes)</li>\n\t<li>Perhaps check \"Don't save imported data\" and maybe also Keep formatting, Contains column labels</li>\n\t<li>Notice that Source: is empty and Operations: None.</li>\n</ul>\n</li>\n\t<li>[OK]</li>\n</ol>\n<h3>3. Define an input data filter to ignore empty rows, with output to the target db range</h3>\n<ol>\n\t<li>Select the range <em>source</em>: Data - Select Range... - select \"source\"</li>\n\t<li>Create a filter: Data - Filter - Standard Filter\n<ol>\n\t<li>Field name: IsDataPresent (created above), Condition: =1 (i.e. true)</li>\n\t<li>Click [More Options], check Copy results to... and select the db. range <em>target</em> (\"Keep filter criteria\" will be checked too)</li>\n</ol>\n</li>\n\t<li>Click [OK]</li>\n</ol>\nThe data of the source range is copied into the target range but only for the rows where IsDataPresent is true.<br><br>Aslo, when you checlk the definition of the source range, you will see that its Operations: has changed from None to Filter.\n<h3>4. Try to add data and refresh the source range</h3>\nAdd some data to the source range so that few rows that currently have FALSE in their IsDataPresent will change to TRUE.<br><br>While anywhere inside the source range, click <strong>Data - Refresh Range</strong>. The target range should have changed and be selected.\n<h2>Summary</h2>",
  "excerpt": ""
 },
 {
  "title": "Five Reasons For Being Vegetarian",
  "published": "0000-00-00 00:00:00",
  "postType": "post",
  "slug": "/617",
  "status": "draft",
  "tags": [],
  "categories": [
   "Uncategorized"
  ],
  "content": "For once I will violate the purely technical status of this blog and post here an answer to those wondering why I'm vegetarian (and why perhaps they should themselves consider this approach to life, though it's everyone's own decision).<br><br>There are five good reasons for being vegetarian (though for me just the first one is sufficient and the other ones are just \"bonuses\"):\r\n<ol>\r\n\t<li>Compassion</li>\r\n\t<li>Ecology</li>\r\n\t<li>Health</li>\r\n\t<li>..</li>\r\n\t<li>..</li>\r\n</ol>\r\nOf course there is lot of fanaticism on both sides and many arguments for or against vegetarianism are <strong>doubtable</strong>. Let me explain why I don't see the most common arguments against it as valid.\r\n<h3><del>It's dangerous for your health</del></h3>\r\nWell, I believe that generations of Indians and, if these are too distant for you, generations of the members of the <a href=\"http://www.sdada.org/position.htm\">Seventh-day Adventists</a> church are living proofs that being 100% is perfectly possible. And top-class sportmen such as <strong>XXXXX</strong> prove that you really don't need meet to be in top condition and to perform heavy work. Mahatma Gandhi was vegetarian all his life (with the exception of a single year, which he mourned a lot) and lived till 78 and they actually had to shoot him to kill him. (Bad joke, I know, sorry.)\r\nOf course an incorrect vegetarian diet can harm you, as well as an incorrect not-vegetarian one, have a look at the movie Oversize me.\r\n<h3><del>It's natural to eat meat</del></h3>\r\nPerhaps, but then living in caves, eating the hearths of your enemies and dying in your thirties is natuaral as well. And for example poisonous plants are 100% natural yet rather unhealthy.<br><br>Actually argumenting by something \"being natural...\" is wrong, for this kind of argument can and many times have been used to \"prove\" just the opposite points. <strong>LINK</strong><br><br>Also, I like to think that we are a bit more than animals (which, by the way, gives us more responsibility towards them, not power over them) and do not have to follow our instincts blindly. Having the power of mind, we should use it and think about our actions, about what is good and what is bad, and choose our course of action according to that. We live in a modern society and do not depend anymore on what we find in the forest and therefore we can freely apply our human qualities and decide for ourselves what we want or do not want to consume.\r\n<h3><del>Proper vegetarion diet is too complicated.</del></h3>\r\nNot, it isn't.\r\n<strong>// colourful vegetable, beans &amp; obiloviny, nuts, some tasty seeds; see the dietologic. org. online, milk etc. (vegans have workarounds) Stanovisko ...</strong>",
  "excerpt": ""
 },
 {
  "title": "Why I prefer Eclipse to NetBeans",
  "published": "0000-00-00 00:00:00",
  "postType": "post",
  "slug": "/895",
  "status": "draft",
  "tags": [],
  "categories": [
   "Uncategorized"
  ],
  "content": "I'm missing:\r\n<ul>\r\n\t<li>copy file name / including path</li>\r\n\t<li>search: can't sort (possible in eclispe?) by diff. criteria, can't remove some results</li>\r\n</ul>",
  "excerpt": ""
 },
 {
  "title": "The Essence of Lean as Seen by a Greenhorn",
  "published": "0000-00-00 00:00:00",
  "postType": "post",
  "slug": "/1098",
  "status": "draft",
  "tags": [],
  "categories": [
   "Uncategorized"
  ],
  "content": "KEY CHARS\nValues\n• respect for people\n• perfectionism<br><br>plus approach: empirical process control (x deterministic)<br><br>----------------------<br><br>Derived:\n• communication over contract &lt;= respect for people\n• self-organization &lt;= respect for people and their ability to figure out for themselves how best to do their job\n• frequent delivery and inspection &lt;= emp. process control\n• // commitment<br><br>Another lean char.: steady pace (Kanban, Toyota)\n• build quality in<br><br>Lean approaches: Scrum, Kanban, DSDM A., ?XP<br><br>---------<br><br>Cross-functional team (&lt;=&gt; direct, rich collaboration)<br><br>Emphasis on creating knowledge (&lt;-&gt; empirical process mgmt, not wasting)<br><br>Speed &lt;=&gt; cycle time &lt;=&gt; discover waste, build quality in<br><br>Queuing theory: high utilization (&gt; 80%)/large batches =&gt; slow flow, lot of waste =&gt; Limit work to capacity; Use pull scheduling<br><br>p125: \"Successful lean initiatives must be based first and foremost on a deep respect for every person in the company, especially those 'ordinary' people who make the product or pound out the code.\"<br><br>----------\nQuote:\nLean =\n- People first - People, and the way they interact with each other, are the primary determinant of success for a solution delivery project.\n- Learning-oriented",
  "excerpt": ""
 },
 {
  "title": "Executing Functions/Stored Procedures from Oracle SQL Developer",
  "published": "0000-00-00 00:00:00",
  "postType": "post",
  "slug": "/1200",
  "status": "draft",
  "tags": [
   "Oracle"
  ],
  "categories": [
   "Databases"
  ],
  "content": "SQL Developer version: 3.0.04<br><br>To execute use \"Run Script (F5)\"<br><br><pre><code>\nSET serveroutput on;\nDECLARE\noutput boolean;\nBEGIN\noutput := chema.package.function('my varchar parameter');\ndbms_output.put_line('Result (1 = true): ' || to_char(sys.diutil.bool_to_int(output)) );\nend;\n</code></pre><br><br>Resources - <a href=\"http://stackoverflow.com/questions/3991721/run-stored-procedure-in-sql-developer\">StackOverflow: Run Stored Procedure in SQL Developer?</a>",
  "excerpt": ""
 },
 {
  "title": "How Much Software Quality Do We Need?",
  "published": "2011-08-07 19:14:38",
  "postType": "post",
  "slug": "/1284",
  "status": "draft",
  "tags": [
   "opinion"
  ],
  "categories": [
   "General"
  ],
  "content": "Discussion: Can we afford any trade-off regarding quality? How much of it do we need? What is a quality?<br><br>Quality: Fit towards a goal?<br><br>Quality\n<ul>\n\t<li>Kent: internal x outer (UI)</li>\n\t<li>Elementary code quality (microdesign) &lt;-&gt; \"long-term\" life of SW</li>\n<ul>\n\t<li>readability: naming, structuring, DRY, simplicity, ...</li>\n</ul>\n\t<li>Macrodesign - flexibility?</li>\n\t<li>NFR</li>\n</ul>\nFrameworks and abstraction levels: It would be optimal to build an application with the most suitable level of abstraction and flexibility that is needed - but we don't know beforehand what will be needed and guessing is nearly always wrong (surely so when guessing more than 1 thing). So the most cost-effective way is to always use the simplest solution suitable for current needs and refactor/enhance as the needs actually evolve.\n<blockquote>Yes, we can refactor, but what are the chances that the code will ever look like our ideal design? In many cases, we're better off giving up on that vision. We <em>might</em> be able to get there from here, but if the class is complicated, it won't be easy Moreover, it might not be worth the effort relative to other things that we can do to make the code easier to deal with. [1]</blockquote>\n<blockquote>Sometimes I think that if I had to define design, I'd say that design is the process of making decisions in the face of constraints. [1]</blockquote>\nSources\n<ol>\n\t<li><a href=\"http://drdobbs.com/architecture-and-design/231002664\">Discovering Hidden Design</a>, Michael Feathers, 2011-07-26, Dr. Dobb's</li>\n\t<li><a href=\"http://martinfowler.com/bliki/TradableQualityHypothesis.html\">Tradable Quality Hypothesis</a>, Martin Fowler, blogged 2011-02-21</li>\n<ul>\n\t<li>We should never think about (inner) quality as tradeable because thus we make it impossible to overcome the naturale tendency to see quality as tradeable while in software the (inner) quality is not (or much less) tradeable then in other parts of life; quality as speed enabler &lt;=&gt; can't trade for more features</li>\n</ul>\n\t<li>Zen and the Art of Motorcycle Maintenance</li>\n</ol>",
  "excerpt": ""
 },
 {
  "title": "Teaching Non-Geek Programming 1: Selecting Language and Environment",
  "published": "0000-00-00 00:00:00",
  "postType": "post",
  "slug": "/1344",
  "status": "draft",
  "tags": [],
  "categories": [
   "Uncategorized"
  ],
  "content": "Ruby: fun. RoR, JVM, dynamic, all is object<br><br>Java: popular, static -&gt; IDE support (- verbose, - nonconsistent: primitives)<br><br>(J)Ruby\r\n<ul>\r\n\t<li><a href=\"http://hackety-hack.com/\">Hackety Hack</a> - learning Ruby with Shoes (only experimental for Linux) - set of lectures in a wizard-like form integrated with an editor and runner</li>\r\n\t<li>Blog <a href=\"http://teachingkids.railsbridge.org/2009/08/15/teaching-ruby-to-high-school-girls.html\">RailsBridge: Teaching Ruby to High School Girls</a></li>\r\n\t<li><a href=\"http://rubykoans.com/\">Ruby Koans</a> - download, run =&gt; a test will fail and point you to place to fix. Fill in blanks ... add method ... .</li>\r\n\t<li>Next steps: <a href=\"https://github.com/enebo/Purugin\">Purugin - Ruby framework for MineCraft plugins</a></li>\r\n</ul>\r\nJava\r\n<ul>\r\n\t<li><a href=\"http://www.learningwithrobots.com/\">Learning to Program with Robots</a> - inspired by Karel the Robot but richer - provide instructions for \"robot(s)\" in the form of few simple method calls to perform a job and then see their behavior visualized in their 2D city world (go forward, turn, sense a wall, operate an object found, ...)</li>\r\n\t<li><a href=\"http://processing.org/\">Processing.org</a> - a Java library and a development environment for creating amazing visualizations with only few lines of code, originally conceived as a tool for teaching programming. The best thing is that there exist books teaching Processing and programming to non-technicians such as Learning Processing (2008) and Processing: A Programming Handbook for Visual Designers and Artists.</li>\r\n</ul>\r\nPython\r\n<ul>\r\n\t<li><a href=\"http://inventwithpython.com/\">Invent Your Own Computer Games with Python</a> - Learn how to program with a free ebook programming tutorial</li>\r\n\t<li><a href=\"http://pystar.org/\">PyStar: Programming Workshops for Women and Their Friends</a></li>\r\n</ul>\r\nPoint &amp; click programming in 2D environments - learn to construct programs without having to learn a programming language syntax\r\n<ul>\r\n\t<li><a href=\"http://www.greenfoot.org/\">Greenfoot</a> - \"<em>a combination between a framework for creating two-dimensional grid assignments in Java and an integrated development environment (class browser, editor, compiler, execution, etc.) suitable for novice programmers. While greenfoot supports the full Java language, it is especially useful for programming exercises that have a visual element. In greenfoot object visualisation and object interaction are the key elements</em>\"</li>\r\n\t<li><a href=\"http://alice.org/\">Alice</a> by the Carnegie Mellon university - contains nice tutorials where you continually learn basic and more complex concepts and you can buy a book to guide you further</li>\r\n\t<li><a href=\"http://info.scratch.mit.edu/\">Scratch</a> by MIT - \"<em>a programming language that makes it easy to create your own interactive stories, animations, games, music, and art</em>\"</li>\r\n</ul>\r\nOther\r\n<ul>\r\n\t<li><a href=\"http://testfirst.org/\">TestFirst.org</a> - the home of test-first teaching - include TDD in teaching from the beginning - seems similar to <a href=\"http://rubykoans.com/\">Ruby Koans</a>, I'm not sure about its suitability for non-programmers</li>\r\n</ul>",
  "excerpt": ""
 },
 {
  "title": "Performance Testing and Scaling of Amazon RDS/MySQL (Small, Large)",
  "published": "0000-00-00 00:00:00",
  "postType": "post",
  "slug": "/1952",
  "status": "draft",
  "tags": [],
  "categories": [
   "Databases",
   "General"
  ],
  "content": "intro...<br><br><!--more-->\n<h2>Stoff - å bruke</h2>\n<ul>\n\t<li>RDS perf. can vary over time (HW lasted av en annen VM?) =&gt; repeat</li>\n\t<li><a href=\"http://aws.amazon.com/articles/1636185810492479#pre-warming\">Best Practices in Evaluating Elastic Load Balancing</a> - if you access the DB via ELB then you need to increase the load gradually so that it won't be categorized as a DoS attack and the ELB will manage to keep up: \"We recommend configuring the load test so that the traffic increases at no more than 50 percent over a five-minute interval.\"</li>\n\t<li>Amazon EC2 instances should handle 50k - 500k connections - see   <a href=\"https://forums.aws.amazon.com/thread.jspa?messageID=215604\" rel=\"nofollow\">https://forums.aws.amazon.com/thread.jspa?messageID=215604</a></li>\n</ul>\n<h2>Notes on RDS Configuration</h2>\nBy default the number of max_connections is derived from the RAM, i.e. 150 for small 1.5GB instance and 650 for large 7.5GB instance. According to one our expert, MySQL should handle 1k concurrent connections just well not very dependent on the RAM.<br><br>You might want to check the blog post <a href=\"http://mysqlhacker.com/kabir/performance/calculating-maximum-connections-for-mysql-server.html\">Calculating Maximum Connections for MySQL Server</a> that describe how to compute the connections based on the available memory, buffer sizes etc. and what other things to take into account (quality of threading library, ..). <a href=\"http://dev.mysql.com/doc/refman/5.1/en/too-many-connections.html\">From MySQL docs</a>:\n<blockquote>The maximum number of connections MySQL can support depends on the quality of the thread library on a given platform, the amount of RAM available, how much RAM is used for each connection, the workload from each connection, and the desired response time. Linux or Solaris should be able to support at 500 to 1000 simultaneous connections routinely and as many as 10,000 connections if you have many gigabytes of RAM available and the workload from each is low or the response time target undemanding.</blockquote>\n<h3>Changing Max Connections</h3>\n1. Create your own DB parameter group and use apply it to the DB; 2. Change the parameter:<br><br><pre><code>/usr/bin/rds-modify-db-parameter-group comoyo-mysql51 --parameters  &quot;name=max_connections, value=1000, method=pending-reboot&quot;</code></pre><br><br>(The other possible method is immediate according to <a href=\"http://docs.amazonwebservices.com/AmazonRDS/latest/CommandLineReference/CLIReference-cmd-ModifyDBParameterGroup.html\">the command doc</a>.)\n<h2>Performance Testing of RDS</h2>\nSmall instance: simple select+update ~ 6ms (update only: 4ms), with multiple threads only worse.\n<h2>Scaling Amazon RDS vertically</h2>\n<div class=\"linkscent-iconblock\" style=\"float:none!important;border:0 solid #ff0000!important;background:none repeat scroll center center transparent!important;width:auto!important;height:auto!important;display:block!important;overflow:visible!important;position:static!important;text-indent:0!important;z-index:auto!important;max-width:none!important;min-width:0!important;max-height:none!important;min-height:0!important;left:auto!important;top:auto!important;bottom:auto!important;right:auto!important;line-height:16px!important;white-space:nowrap!important;margin:0!important;padding:0!important;\"><img class=\"linkscent-icon\" style=\"float:none!important;border:0 solid #ff0000!important;width:16px!important;height:16px!important;display:none;overflow:visible!important;position:absolute!important;text-indent:0!important;z-index:2147483635!important;max-width:none!important;min-width:0!important;max-height:none!important;min-height:0!important;left:541px;top:159px;bottom:auto!important;right:auto!important;line-height:16px!important;white-space:nowrap!important;visibility:hidden;background:url('//interclue/content/cluecore/skins/default/linkscentExternal.png') no-repeat scroll center center transparent!important;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" /><img class=\"linkscent-icon\" style=\"float:none!important;border:0 solid #ff0000!important;background:none repeat scroll center center transparent;width:16px!important;height:16px!important;display:none;overflow:visible!important;position:absolute!important;text-indent:0!important;z-index:2147483635!important;max-width:none!important;min-width:0!important;max-height:none!important;min-height:0!important;left:559px;top:159px;bottom:auto!important;right:auto!important;line-height:16px!important;white-space:nowrap!important;visibility:hidden;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" /></div>",
  "excerpt": ""
 },
 {
  "title": "Book Review & Digest: ",
  "published": "0000-00-00 00:00:00",
  "postType": "post",
  "slug": "/2999",
  "status": "draft",
  "tags": [],
  "categories": [
   "Uncategorized"
  ],
  "content": "",
  "excerpt": ""
 },
 {
  "title": "Hello world!",
  "published": "2010-04-22 18:42:35",
  "postType": "post",
  "slug": "/2010/04/22/hello-world/",
  "status": "private",
  "tags": [],
  "categories": [
   "Uncategorized"
  ],
  "content": "Welcome to <a href=\"http://wordpress.com/\">WordPress.com</a>. This is your first post. Edit or delete it and start blogging!",
  "excerpt": ""
 },
 {
  "title": "Most interesting links of April",
  "published": "2010-05-04 07:43:54",
  "postType": "post",
  "slug": "/2010/05/04/most-interesting-links-of-april/",
  "status": "publish",
  "tags": [
   "groovy",
   "java",
   "nosql",
   "spock",
   "tdd",
   "Testing"
  ],
  "categories": [
   "General",
   "Languages",
   "Top links of month"
  ],
  "content": "The most interesting technical links I've encountered in April:\r\n<ul>\r\n\t<li><a href=\"http://www.dzone.com/links/rss/getting_started_with_tdd_in_java_using_eclipse_sc.html\">Getting Started with Tdd in Java using Eclipse [Screencast]</a> - you will see not only TDD in practices but also a number of best practices applied and some inspirational novelty (at least for me) ideas  such as creating one test class per test configuration (and thus multiple test classes for a single \"business\" class); I really recommend this even if you are not interested in TDD</li>\r\n\t<li>NoSQL links (as everybody these days, I'm also at least observing the NoSQL movement):\r\n<ul>\r\n\t<li><a href=\"http://nosql.mypopescu.com/post/407159447/cassandra-twitter-an-interview-with-ryan-king\">Why Twitter selected Cassandra</a> (brought by the great <a href=\"http://nosql.mypopescu.com/\">myNoSql blog</a>) - why they choose Cassandra over other alternatives and instead of the current solution of mysql with memcache</li>\r\n\t<li><a href=\"http://about.digg.com/blog/looking-future-cassandra\">Cassandra at Digg: Looking to the future with Cassandra</a> (9/2009) - why Digg considered switching to Cassandra (which <a href=\"http://about.digg.com/blog/saying-yes-nosql-going-steady-cassandra\">they also did</a>)</li>\r\n</ul>\r\n</li>\r\n\t<li>Testing\r\n<ul>\r\n\t<li><a href=\"http://pniederw.wordpress.com/2010/03/11/whats-new-in-spock-0-4-episode-1-data-tables/\">Easy data-driven testing with Spock</a> - the <a href=\"http://code.google.com/p/spock/\">Spock</a> framework based on the popular JVM scripting language <a href=\"http://groovy.codehaus.org/\">Groovy</a> (99% Java + 1000% added) introduces a custom domain-specific language (DSL), which makes testing of a method using different data incredily easy and readable, with all the power of Groovy at hand; see the post and you will see immediately what I mean</li>\r\n</ul>\r\n</li>\r\n</ul>\r\nThat's all for this month, stay tuned.<br><br><!-- AddThis Button BEGIN -->\r\n<div><a title=\"Bookmark and Share\" href=\"http://www.addthis.com/bookmark.php?v=250&amp;username=xa-4bdfd4493b5b66f8\" target=\"_blank\"><img style=\"border:0;\" src=\"http://s7.addthis.com/static/btn/v2/lg-share-en.gif\" alt=\"Bookmark and Share\" width=\"125\" height=\"16\" /></a></div>\r\n<!-- AddThis Button END -->\r\n<p class=\"getsocial\" style=\"text-align:left;\"><img style=\"border:0;margin:0;padding:0;\" src=\"http://getsocialserver.files.wordpress.com/2009/08/gs2004.png\" alt=\"\" /><a title=\"Add to Facebook\" rel=\"nofollow\" href=\"http://www.facebook.com/sharer.php?u=/2010/05/04/most-interesting-links-of-april/\" target=\"_blank\"><img style=\"border:0;margin:0;padding:0;\" src=\"http://getsocialserver.files.wordpress.com/2009/08/gs2014.png\" alt=\"Add to Facebook\" /></a><a title=\"Add to Digg\" rel=\"nofollow\" href=\"http://digg.com/submit?phase=2&amp;url=http%3A%2F%2Ftheholyjava.wordpress.com%2F2010%2F05%2F04%2Fmost-interesting-links-of-april%2F&amp;title=Most%20interesting%20links%20of%20April\" target=\"_blank\"><img style=\"border:0;margin:0;padding:0;\" src=\"http://getsocialserver.files.wordpress.com/2009/08/gs2024.png\" alt=\"Add to Digg\" /></a><a title=\"Add to Del.icio.us\" rel=\"nofollow\" href=\"http://del.icio.us/post?url=http%3A%2F%2Ftheholyjava.wordpress.com%2F2010%2F05%2F04%2Fmost-interesting-links-of-april%2F&amp;title=Most%20interesting%20links%20of%20April\" target=\"_blank\"><img style=\"border:0;margin:0;padding:0;\" src=\"http://getsocialserver.files.wordpress.com/2009/08/gs2034.png\" alt=\"Add to Del.icio.us\" /></a><a title=\"Add to Stumbleupon\" rel=\"nofollow\" href=\"http://www.stumbleupon.com/submit?url=http%3A%2F%2Ftheholyjava.wordpress.com%2F2010%2F05%2F04%2Fmost-interesting-links-of-april%2F&amp;title=Most%20interesting%20links%20of%20April\" target=\"_blank\"><img style=\"border:0;margin:0;padding:0;\" src=\"http://getsocialserver.files.wordpress.com/2009/08/gs2044.png\" alt=\"Add to Stumbleupon\" /></a><a title=\"Add to Reddit\" rel=\"nofollow\" href=\"http://reddit.com/submit?url=http%3A%2F%2Ftheholyjava.wordpress.com%2F2010%2F05%2F04%2Fmost-interesting-links-of-april%2F&amp;title=Most%20interesting%20links%20of%20April\" target=\"_blank\"><img style=\"border:0;margin:0;padding:0;\" src=\"http://getsocialserver.files.wordpress.com/2009/08/gs2054.png\" alt=\"Add to Reddit\" /></a><a title=\"Add to Blinklist\" rel=\"nofollow\" href=\"http://www.blinklist.com/index.php?Action=Blink/addblink.php&amp;Description=&amp;Url=http%3A%2F%2Ftheholyjava.wordpress.com%2F2010%2F05%2F04%2Fmost-interesting-links-of-april%2F&amp;Title=Most%20interesting%20links%20of%20April\" target=\"_blank\"><img style=\"border:0;margin:0;padding:0;\" src=\"http://getsocialserver.files.wordpress.com/2009/08/gs2064.png\" alt=\"Add to Blinklist\" /></a><a title=\"Add to Twitter\" rel=\"nofollow\" href=\"http://twitter.com/home/?status=Most%20interesting%20links%20of%20April+%40+http%3A%2F%2Ftheholyjava.wordpress.com%2F2010%2F05%2F04%2Fmost-interesting-links-of-april%2F\" target=\"_blank\"><img style=\"border:0;margin:0;padding:0;\" src=\"http://getsocialserver.files.wordpress.com/2009/08/gs2074.png\" alt=\"Add to Twitter\" /></a><a title=\"Add to Technorati\" rel=\"nofollow\" href=\"http://www.technorati.com/faves?add=/2010/05/04/most-interesting-links-of-april/\" target=\"_blank\"><img style=\"border:0;margin:0;padding:0;\" src=\"http://getsocialserver.files.wordpress.com/2009/08/gs2084.png\" alt=\"Add to Technorati\" /></a><a title=\"Add to Yahoo Buzz\" rel=\"nofollow\" href=\"http://buzz.yahoo.com/buzz?targetUrl=http%3A%2F%2Ftheholyjava.wordpress.com%2F2010%2F05%2F04%2Fmost-interesting-links-of-april%2F&amp;headline=Most%20interesting%20links%20of%20April\" target=\"_blank\"><img style=\"border:0;margin:0;padding:0;\" src=\"http://getsocialserver.files.wordpress.com/2009/08/gs2094.png\" alt=\"Add to Yahoo Buzz\" /></a><a title=\"Add to Newsvine\" rel=\"nofollow\" href=\"http://www.newsvine.com/_wine/save?u=http%3A%2F%2Ftheholyjava.wordpress.com%2F2010%2F05%2F04%2Fmost-interesting-links-of-april%2F&amp;h=Most%20interesting%20links%20of%20April\" target=\"_blank\"><img style=\"border:0;margin:0;padding:0;\" src=\"http://getsocialserver.files.wordpress.com/2009/08/gs2104.png\" alt=\"Add to Newsvine\" /></a><img style=\"border:0;margin:0;padding:0;\" src=\"http://getsocialserver.files.wordpress.com/2009/08/gs2114.png\" alt=\"\" /></p>",
  "excerpt": "The most interesting technical links I've encountered in April: NoSQL at Twitter and Digg, TDD and testing with Spock."
 },
 {
  "title": "My older posts at JRoller",
  "published": "2010-05-01 11:03:12",
  "postType": "post",
  "slug": "/2010/05/01/my-older-posts-at-jroller/",
  "status": "publish",
  "tags": [],
  "categories": [
   "General"
  ],
  "content": "My<a href=\"http://jroller.com/holy/\"> older posts are available on my JRoller blog</a>, I hope I'll manage to <span style=\"text-decoration:line-through;\">migrate them</span> finish their migration here soon.",
  "excerpt": ""
 },
 {
  "title": "Mocking out LDAP/JNDI in unit tests",
  "published": "2010-05-05 17:13:25",
  "postType": "post",
  "slug": "/2010/05/05/mocking-out-ldapjndi-in-unit-tests/",
  "status": "publish",
  "tags": [
   "java",
   "JNDI",
   "junit",
   "LDAP",
   "mock",
   "Mockito",
   "Testing"
  ],
  "categories": [
   "Testing"
  ],
  "content": "When unit testing a class that queries an LDAP server using Java's JNDI API I needed to replace the actual remote LDAP server with a mock LDAP access layer so that the unit test (remember, this is not an integration test) doesn't depend on any external SW/HW. Few hours of googling haven't yielded any suitable mock implementation and so I had to create my own one. It turned out to be an easy task after all. I hope it could be useful for you too.<br><br>To create a test implementation of LDAP/JNDI you need to:\r\n<ol>\r\n\t<li>Hook you mock JNDI implementation into the JVM and make sure that you use it</li>\r\n\t<li>Actually implement the JNDI layer by implementing/mocking few (3) JNDI classes, mostly from the <a href=\"http://java.sun.com/j2se/1.4.2/docs/api/javax/naming/directory/package-frame.html\" target=\"packageFrame\">javax.naming.directory</a> package</li>\r\n\t<li>Configure your mock implementation to return the data expected</li>\r\n</ol>\r\n<!--more-->\r\n<h2>1. Configuring the JVM to use the test JNDI implementation</h2>\r\nThe best way to \"inject\" your test LDAP/JNDI implementation depends on the way your code is accessing it. There are basically two options:\r\n<ol>\r\n\t<li>You specify explicitely the implementation to use via the parameter  INITIAL_CONTEXT_FACTORY</li>\r\n\t<li>You use the default implementation for the JVM</li>\r\n</ol>\r\nLet's see an example:<br><br><pre><code>\r\n new javax.naming.directory.InitialDirContext(new Hashtable(){{\r\n  put(Context.INITIAL_CONTEXT_FACTORY, &quot;com.sun.jndi.ldap.LdapCtxFactory&quot;);\r\n  put(Context.PROVIDER_URL, &quot;ldap://ldap.example.com:389&quot;);\r\n }});\r\n</code></pre><br><br>The javax.naming.directory.InitialDirContext will delegate most operations to the actual implementation, which is provided either by the requested initial context factory if the line #2 is included or based on the JVM's configuration - see  <a href=\"http://java.sun.com/j2se/1.4.2/docs/api/javax/naming/spi/NamingManager.html#getInitialContext(java.util.Hashtable)\">NamingManager.getInitialContext(..)</a>. Therefore:\r\n<ol>\r\n\t<li>If your code<strong> specifies explicitely the initial context factory</strong>, <strong>configure it to use your test initial context factory implementation</strong>, i.e. you modify the code to something like <code>put(Context.INITIAL_CONTEXT_FACTORY, \"your.own.MockInitialDirContextFactory\")</code> (you have that configurable, right?)</li>\r\n\t<li>If your code<strong> relies on the JVM's configuration</strong> to provide the proper implementation, <strong>configure it with a custom InitialContextFactoryBuilder</strong>, which will return your test initial context factory implementation. I won't go into the details here, you can see an example in the Spring's mock jndi <a href=\"http://static.springsource.org/spring/docs/2.5.x/api/org/springframework/mock/jndi/SimpleNamingContextBuilder.html\">SimpleNamingContextBuilder</a> [<a href=\"http://www.docjar.com/html/api/org/springframework/mock/jndi/SimpleNamingContextBuilder.java.html\">source</a>] (it mocks unfortunately only javax.naming, not the javax.naming.directory we need for LDAP)</li>\r\n</ol>\r\n<h2>2. Implementing/mocking JNDI classes</h2>\r\nThe test LDAP over JNDI implementation is quite simple. We need:\r\n<ol>\r\n\t<li>The <a href=\"http://java.sun.com/j2se/1.4.2/docs/api/javax/naming/spi/InitialContextFactory.html\">InitialContextFactory</a> for creating our test contexts, as described above</li>\r\n\t<li>The test <a href=\"http://java.sun.com/j2se/1.4.2/docs/api/javax/naming/directory/DirContext.html\">DirContext</a> implementation itself, which we will mock using <a href=\"http://mockito.googlecode.com/svn/tags/latest/javadoc/org/mockito/Mockito.html\">Mockito</a> (the interface has many methods to implement while my code is using only one of them)</li>\r\n\t<li>And a <a href=\"http://java.sun.com/j2se/1.4.2/docs/api/javax/naming/NamingEnumeration.html\">NamingEnumeration</a> implementation for returning search results from the mock DirContext's search method</li>\r\n</ol>\r\nThe test initial context factory is very simple:<br><br><pre><code>\r\npublic class MockInitialDirContextFactory implements InitialContextFactory {<br><br>\tprivate static DirContext mockContext = null;<br><br>\t/** Returns the last DirContext (which is a Mockito mock) retrieved from this factory. */\r\n\tpublic static DirContext getLatestMockContext() {\r\n\t\treturn mockContext;\r\n\t}<br><br>\tpublic Context getInitialContext(Hashtable environment)\r\n\t\t\tthrows NamingException {\r\n\t\tsynchronized(MockInitialDirContextFactory.class) {\r\n\t\t\tmockContext = (DirContext)\r\n\t\t\t\tMockito.mock(DirContext.class);\r\n\t\t}\r\n\t\treturn mockContext;\r\n\t}\r\n}\r\n</code></pre><br><br>We store the latest DirContext mock (the class under test only creates one so this is enough) so that we can tell it what calls to expect and what to return (i.e. to do some \"stubbing\").<br><br>We also need an implementation of the NamingEnumeration, which is returned by the various search methods. Because we actually do not use it we could also mock it with Mockito (simple <em>Mockito.mock(NamingEnumeration.class) </em> would be enough to replace all the lines below) but I've decided to create a real implementation so that in more involved tests it could be extended to actually be able of holding and returning some fake LDAP search data.<br><br>In this case the NamingEnumeration should hold instances of the conrete class <a href=\"http://java.sun.com/j2se/1.4.2/docs/api/javax/naming/directory/SearchResult.html\">SearchResult</a> with the actual LDAP data in its field of the type <a href=\"http://java.sun.com/j2se/1.4.2/docs/api/javax/naming/directory/Attributes.html\">Attributes</a>, for which we can use the concrete <a href=\"http://java.sun.com/j2se/1.4.2/docs/api/javax/naming/directory/BasicAttributes.html\">BasicAttributes</a> implementation provided by the JVM. But for now let's just return an empty enumeration.<br><br><pre><code><br><br>public class MockNamingEnumeration/*&lt;SearchResult&gt;*/ implements NamingEnumeration {<br><br>\tpublic void close() throws NamingException {\r\n\t}<br><br>\tpublic boolean hasMore() throws NamingException {\r\n\t\treturn hasMoreElements();\r\n\t}<br><br>\tpublic Object next() throws NamingException {\r\n\t\treturn nextElement();\r\n\t}<br><br>\tpublic boolean hasMoreElements() {\r\n\t\treturn false;\r\n\t}<br><br>\tpublic Object nextElement() {\r\n\t\treturn null;\r\n\t}\r\n}\r\n</code></pre><br><br>As you can see, this implementation will behave as if the search matched no records.\r\n<h2>3. Using the test LDAP/JNDI implementation</h2>\r\nThe last piece is the actual JUnit test of a hypothetical TestedLdapReader class, which searches an LDAP server:<br><br><pre><code>\r\npublic class MyMockLdapTest extends TestCase {\r\n\tprivate TestedLdapReader ldapReader;\r\n        ...\r\n\tprotected void setUp() throws Exception {\r\n\t\tsuper.setUp();\r\n\t\tldapReader = new TestedLdapReader();\r\n\t\tldapReader.setInitialContextFactory(\r\n\t\t\tMockInitialDirContextFactory.class.getName());\r\n\t\tldapReader.setLdapUrl(&quot;ldap://thisIsIgnoredInTests&quot;);\r\n\t}<br><br>\tpublic void testLdapSearch() throws Exception {\r\n\t\tldapReader.initLdap(); // obtains an InitialDirContext...\r\n\t\tfinal DirContext mockContext = MockInitialDirContextFactory.getLatestMockContext();\r\n \t\t//Stub the public NamingEnumeration search(String name, String filter, SearchControls cons)\r\n\t\tMockito.when( mockContext.search(\r\n\t\t\t (String) Mockito.eq(&quot;ou=bluepages,o=ibm.com&quot;)\r\n\t\t\t , Mockito.anyString()\r\n\t\t\t , (SearchControls) Mockito.any(SearchControls.class)))\r\n\t\t // a custom 'answer', which records the queries issued\r\n\t\t .thenAnswer(new Answer() {\r\n\t\t \tpublic Object answer(InvocationOnMock invocation) throws Throwable {\r\n\t\t \t\tLOG.debug(&quot;LDAP query:&quot; + invocation.getArguments()[1] );\r\n\t\t \t\treturn new MockNamingEnumeration();\r\n\t\t \t}\r\n\t\t });<br><br>\t\t try {\r\n\t\t \tldapReader.searchLdap();\r\n\t\t } catch (Exception e) {\r\n\t\t \tLOG.warn(&quot;exception during execution&quot;, e);\r\n\t\t }<br><br>\t\t // Uncomment to find out the methods called on the context:\r\n\t\t // Mockito.verifyNoMoreInteractions(new Object[]{mockContext});\r\n}\r\n</code></pre><br><br>Let's summarize what we do here:\r\n<ul>\r\n\t<li>#07,08: We tell the class under test to use our test JNDI implementation</li>\r\n\t<li>#13: It's assumed that this call instantiates an InitialDirContext supplying it the initial context factory class parameter set on the lines 07-08</li>\r\n\t<li>#16-26:  We use Mockito to configure the mock DirContext to expect a search call for the context \"ou=bluepages,o=ibm.com\", any query string and any search controls and tell it to return an empty MockNamingEnumeration while also logging the actual LDAP query (the 2nd argument).</li>\r\n\t<li>#29: The tested method is called</li>\r\n\t<li>#35: If we are not sure what methods the tested method calls on the DirContext, we may uncomment this line to let Mockito check it (adding <em>Mockito.verify(mockContext.&lt;method name&gt;(..))</em> prior to #35 for each method we know about already)</li>\r\n</ul>\r\n<h2>Summary</h2>\r\nWe've created a minimalist LDAP over JNDI implementation using partly real and partly mock objects. It could be easily extended to make it possible to configure the data returned from individual LDAP searches (currently we always return an empty collection) and thus test the behavior in reaction to different data sets. There is of course some space left for simplification.",
  "excerpt": ""
 },
 {
  "title": "File-based User Authentication under WebSphere 6",
  "published": "2010-04-12 16:20:43",
  "postType": "post",
  "slug": "/2010/04/12/file-based-user-authentication-und/",
  "status": "publish",
  "tags": [
   "administration"
  ],
  "categories": [
   "WebSphere"
  ],
  "content": "<h1>File-based User Authentication under WebSphere 6</h1>\r\nWhen developing a web application for the WebSphere Application Server you sometimes need to enable security because the application expects HttpServletRequest.<a id=\"twt2\" title=\"getUserPrincipal\" href=\"http://java.sun.com/javaee/5/docs/api/javax/servlet/http/HttpServletRequest.html#getUserPrincipal%28%29\">getUserPrincipal</a>() to be non-null. While in the production environment you will likely configure WAS to delegate the authentication to an LDAP server, during development you would likely prefer to use a simpler method that doesn't depend on an external service (and thus functions even when offline) and doesn't force you to use some real confidential credentials.<br><br>The solution is to use the sample custom <a id=\"t_n_\" title=\"file-based user registry\" href=\"http://publib.boulder.ibm.com/infocenter/wasinfo/v6r0/index.jsp?topic=/com.ibm.websphere.base.doc/info/aes/ae/rsec_frsjf502.html\">file-based user registry</a>, which is shipped with WebSphere 6.x and which enables you to define your groups and users in two files. The steps to configure it are quite simple.\r\n<div style=\"text-align:left;\">1. Open the WAS <a id=\"fe7t\" title=\"administration console\" href=\"https://localhost:9043/ibm/console/\">administration console</a></div>\r\n2. Configure the custom user registry under Security - Global security - Custom:\r\n2.a Define basic properties:\r\n<div id=\"u6hp\" style=\"text-align:left;\"><img style=\"height:442.713px;width:640px;\" src=\"http://docs.google.com/File?id=dfvwrb36_24grfmczgv_b\" alt=\"\" /></div>\r\n2.b Define location of the user and group files:\r\n<div id=\"n30i\" style=\"text-align:left;\"><img style=\"height:254.598px;width:648px;\" src=\"http://docs.google.com/File?id=dfvwrb36_25f59wc4hr_b\" alt=\"\" /></div>\r\n3. Enable security and select the configured custom user registry:\r\n<div id=\"x.sa\" style=\"text-align:left;\"><img style=\"height:460.89px;width:648px;\" src=\"http://docs.google.com/File?id=dfvwrb36_23hjvs52ct_b\" alt=\"\" /></div>\r\n4. ? Add self to the allowed console users (I'm not sure whether this is necessary):\r\n<div id=\"axqd\" style=\"text-align:left;\"><img style=\"height:329px;width:290px;\" src=\"http://docs.google.com/File?id=dfvwrb36_2639xvp7hs_b\" alt=\"\" /></div>\r\n5. Create the users and groups files defined in the step 2.b:\r\njh_user.props:\r\n<span style=\"font-family:courier new;\"># jh_user.props file (user name, password, unique user id, group id, user label)</span><br style=\"font-family:Courier New;\" /><span style=\"font-family:courier new;\">jholy@at.ibm.com:password:123:567:Jakub Holy</span><br><br>jh_group.props:\r\n<span style=\"font-family:courier new;\"># jh_group.props file (group name, unique group id, comma-separated member list,\r\n# a label)</span><br style=\"font-family:Courier New;\" /><span style=\"font-family:courier new;\">AutomatedBridge_admins:567:jholy@at.ibm.com:AB Admins</span><br><br>6. Restart WAS<br><br>7. Log in to the admin console with the credentials you've configured (id jholy@at.ibm.com above).",
  "excerpt": ""
 },
 {
  "title": "Most interesting links of March",
  "published": "2010-04-11 12:20:30",
  "postType": "post",
  "slug": "/2010/04/11/most-interesting-links-of-march/",
  "status": "publish",
  "tags": [],
  "categories": [
   "General",
   "Top links of month"
  ],
  "content": "<p>I've decided to publish links to the most interesting blogs, articles and pages that I've stubled upon in a particular month. Enjoy the first dose! (In no particular order.)<br /></p><p>I recommend the post <a href=\"http://www.uxbooth.com/blog/essential-controls-for-web-applications/\">43 Essential Controls for Web Applications</a>,which presents - with screenshots and short descriptions - the most used and useful javascript/ajax widgets for web pages, from the basic ones like auto-complete/suggestions and sliders through a calendar for less known yet very cool ones like sparklines. Read it to learn what's hot and you shouldn't miss in your application! (Warning: The number of widgets on a page is inversely proportional to its quality.)<br /></p><p><a href=\"http://www.cs.brown.edu/people/acb/codebubbles_site.htm\">Code Bubbles - a new IDE UI paradigm</a>: An extremely interesting proposal of a completely different UI for IDEs based on related pieces of code instead of files.<br /></p><div align=\"left\"><a href=\"http://blog.dynatrace.com/2010/03/11/week-6-how-to-make-developers-write-performance-tests/%20\">How to Make Developers Write Performance Tests</a> - why should we, as developers, be keen about writting performance tests for our code (e.g. because &quot;Everyone wants to be a hero&quot; and &quot;It will come back anyway&quot;).<br /></div><p><a href=\"http://www.artima.com/scalazine/articles/twitter_on_scala.html\">Twitter on Scala</a> - why some parts of Twitter are being ported to Scala -  shortcomings of JRuby (more excatly its virtual machine), advantages of Scala (high level, static, JVM), lessons learned.<br /><br /><a href=\"http://logback.qos.ch/reasonsToSwitch.html\">Reasons why to switch from Log4j to Logback</a>, a (not so) new logging framework by a Log4j father. Really compelling.</p><p><a href=\"http://canoo.com/blog/2010/03/19/10-lessons-learned-from-usability-testing/\">&nbsp;10 Lessons Learned from Usability Testing</a> - why doing usability testing can be cheap and afordable for anybody and whay you need. My experience is that users are too often frogotten and UT should certainly be done much more often - and this post argues that it's indeed possible. <br /></p><p><a href=\"https://bugs.eclipse.org/bugs/show_bug.cgi?id=249745#c25.\">A discussion of various Source Code Management systems</a> (scroll down) and which one to choose for Eclipse, including CVS, SVN, Git, Mercurial and Jazz SCM, with their advantages and disadvantages, really enlightening. For the busy yet curious ones, the winner was Git (though that doesn't mean that for a different project you wouldn't pick another one).</p><p><a href=\"http://jaxenter.com/maven-3-0-the-future-of-maven-10580.html\">What's new in Maven 3</a> - an interview with J. van Zyl. Among others: even better IDE integration, better dependency handling, mixins (since 3.1) for reusable pieces of configuration, a set of core plugins of guaranteed quality. Looking forward!<br /></p>",
  "excerpt": ""
 },
 {
  "title": "Enforcing a common log format with AspectJ",
  "published": "2010-04-08 14:19:11",
  "postType": "post",
  "slug": "/2010/04/08/enforcing-a-common-log-format-with/",
  "status": "publish",
  "tags": [
   "AOP",
   "AspectJ",
   "java"
  ],
  "categories": [
   "Languages"
  ],
  "content": "<h1>Enforcing a common log format with AspectJ</h1>\r\nAndy Wilson has recently blogged about the <a href=\"http://thepracticaldeveloper.com/post/499686768/designing-log-files-that-solve-problems-in-production\">need for uniformly formatted log</a> messages containing all the necessary information to make log parsing easier and mentioned an extensive refactoring he did on a project to achieve this. One of the readers mentioned that he could save the effort of manually modifying the log statements and use AOP to add the formatting automatically. Well, here is the solution.<br><br>Before we dive into the code, I should mention that I do not include a user name in the log, because it is not clear how to obtain it. If it was e.g. stored in a ThreadLocal variable, it would be easy to access it and include it in the log statement. Another thing is that if we could limit ourselves to Log4j instead of commons-logging, we could achieve the same with less effort using a custom formatter and perhaps Log4j's Nested Diagnostic Context.<br><br>The code is basically quite simple - we have one AspectJ aspect using the annotation-style, which intercepts calls to commons-logging's info(Object) and info(Object, Throwable) and re-formatts the message before handing it over to the actual logger.<br><br><pre><code>\r\npackage net.jakubholy.example.aoplog.aspect;<br><br>import org.apache.commons.logging.*;\r\nimport org.aspectj.lang.*;\r\nimport org.aspectj.lang.annotation.*;<br><br>@Aspect\r\npublic class LogFormattingAspect {<br><br>    private static final Log LOG = LogFactory.getLog(LogFormattingAspect.class);<br><br>    @Around(&quot;call(public void org.apache.commons.logging.Log.info(Object)) &amp;&amp; args(msg) &amp;&amp; !within(LogFormattingAspect)&quot;)\r\n    public Object formatMessageLog(\r\n            final Object msg\r\n            , final ProceedingJoinPoint invocation\r\n            , final JoinPoint.EnclosingStaticPart callerContext) throws Throwable {\r\n        return formatLogAndProceed(msg, null, invocation, callerContext);\r\n    }<br><br>    @Around(&quot;call(public void org.apache.commons.logging.Log.info(Object, Throwable)) &amp;&amp; args(msg, exception) &amp;&amp; !within(LogFormattingAspect)&quot;)\r\n    public Object formatMessageLog(\r\n            final Object msg\r\n            , final Throwable exception\r\n            , final ProceedingJoinPoint invocation\r\n            , final JoinPoint.EnclosingStaticPart callerContext) throws Throwable {\r\n        return formatLogAndProceed(msg, exception, invocation, callerContext);\r\n    }<br><br>    private Object formatLogAndProceed(final Object msg, final Throwable exception\r\n            , final ProceedingJoinPoint invocation\r\n            , final JoinPoint.EnclosingStaticPart callerContext\r\n            ) throws Throwable {<br><br>        final String callingMethod = callerContext.getSignature().getName();<br><br>        LOG.info(&quot;Log.info has been called from the method &quot; + callingMethod +\r\n                &quot; with message=&quot; + msg + &quot;, exception=&quot; + exception);<br><br>        final Object[] arguments = invocation.getArgs();\r\n        arguments[0] = formatMessage(callingMethod, msg);<br><br>        return invocation.proceed(arguments);\r\n    }<br><br>    private String formatMessage(final String callingMethod,\r\n            final Object originalMessage) {\r\n        return &quot;APPMSG: &quot; + callingMethod + &quot;: &quot; + originalMessage;\r\n    }\r\n}\r\n</code></pre><br><br>If you are new to AspectJ then you need to understand that\r\n<ul>\r\n\t<li>the methods annotated with @Around are invoked whenever Log.info(..) is called</li>\r\n\t<li>AspectJ provides values for the interceptor method's arguments including runtime and static information about the intercepted call, as represented by the *JoinPoint* instances</li>\r\n\t<li>those methods extract some information about the actual call and its arguments from the invocation context provided by AspectJ</li>\r\n\t<li>finally, they invoke the original intercepted method by calling proceed()</li>\r\n</ul>\r\nThe part <span style=\"font-family:courier new;\">args(msg, exception)</span> may seem tricky - it binds the intercepted method arguments to those of the intercepting method (i.e. <span style=\"font-family:Courier New;\">final Object msg, final Throwable exception</span>). This isn't necessary since we may access them via <span style=\"font-family:Courier New;\">invocation.getArgs()</span> as we anyway do but it's more convenient.<br><br>To apply the aspect to you code you need to weave them into it. You can choose either <em><a id=\"zjpo\" title=\"Load-Time Weaving\" href=\"http://www.eclipse.org/aspectj/doc/released/devguide/ltw.html\">Load-Time Weaving</a></em> (LTW), which uses Java 5's -javaagent option and instruments classes as they're loaded by the JVM based on configuration in an aop.xml file and which provides rather nice debugging output (when enabled), or <a id=\"vgn7\" title=\"bytecode weaving\" href=\"http://www.eclipse.org/aspectj/doc/released/devguide/bytecode-concepts.html\">Bytecode Weaving</a> (also called build- or compile-time weaving), which injects the aspects into .class files using the command-line compiler/weaver <a id=\"pue9\" title=\"ajc\" href=\"http://www.eclipse.org/aspectj/doc/released/devguide/ajc-ref.html\">ajc</a> or AspectJ's Ant tasks. During development I prefer LTW, which is more flexible, but for use in a production environment it's better to weave the bytecode because LTW consumes more memory (due to custom classloaders) and CPU.\r\n<h2>Try it out</h2>\r\nThe easiest way to try this out is to use Maven 2:\r\n<ol>\r\n\t<li>Download the source code archive <a id=\"ct8o\" title=\"aop-log-formatter-0.0.1-sources.jar\" href=\"http://oss.sonatype.org/content/repositories/jakubholy-snapshots/net/jakubholy/example/aop-log-formatter/0.0.1-SNAPSHOT/aop-log-formatter-0.0.1-20100408.181600-4-sources.jar\">aop-log-formatter-0.0.1-sources.jar</a></li>\r\n\t<li>Unpack them somewhere</li>\r\n\t<li>In the directory with the sources (namely pom.xml), execute\r\n<span style=\"font-family:courier new;\">mvn -Pexecute-from-sources compile exec:exec</span></li>\r\n\t<li>This will download some maven/project dependencies (a lot, if you don't use maven often, sorry), compile the sources and execute the application while printing its log to the console</li>\r\n</ol>\r\nIf you do not want to use maven:\r\n<ol>\r\n\t<li style=\"text-align:left;\">Download the source code archive <a id=\"atvh\" title=\"aop-log-formatter-0.0.1-sources.jar\" href=\"http://oss.sonatype.org/content/repositories/jakubholy-snapshots/net/jakubholy/example/aop-log-formatter/0.0.1-SNAPSHOT/aop-log-formatter-0.0.1-20100408.181600-4-sources.jar\">aop-log-formatter-0.0.1-sources.jar</a></li>\r\n\t<li>Download also the compiled binaries <a id=\"vag8\" title=\"aop-log-formatter-0.0.1.jar\" href=\"http://oss.sonatype.org/content/repositories/jakubholy-snapshots/net/jakubholy/example/aop-log-formatter/0.0.1-SNAPSHOT/aop-log-formatter-0.0.1-20100408.181600-4.jar\">aop-log-formatter-0.0.1.jar</a></li>\r\n\t<li>Download the dependencies, as recorded in the project's <a id=\"ki:u\" title=\"pom.xml\" href=\"http://oss.sonatype.org/content/repositories/jakubholy-snapshots/net/jakubholy/example/aop-log-formatter/0.0.1-SNAPSHOT/aop-log-formatter-0.0.1-20100408.181600-4.pom\">pom.xml</a> (commons-logging, AspectJ weaver)</li>\r\n\t<li>Execute it with Load-Time Weaving (java 5 or higher required; it's assumed that all dependencies are in the same folder):\r\n<pre>java -cp aop-log-formatter-0.0.1.jar:commons-logging-1.1.1.jar -javaagent:aspectjweaver-1.6.8.jar net.jakubholy.example.aoplog.ExampleLoggingClass</pre>\r\n</li>\r\n</ol>\r\nThe output will be long, because the aop.xml included in the jar enables the most detailed AspetJ logging but in the end you should see something like:\r\n<pre>[INFO] [INFO] LogFormattingAspect - Log.info has been called from the method main with message=A message w/o an exception., exception=null\r\n[INFO] [INFO] ExampleLoggingClass - APPMSG: main: A message w/o an exception.\r\n[INFO] [INFO] LogFormattingAspect - Log.info has been called from the method main with message=Another message accompanied by an exception., exception=java.lang.RuntimeException: I'm the exception!\r\n[INFO] [INFO] ExampleLoggingClass - APPMSG: main: Another message accompanied by an exception. java.lang.RuntimeException: I'm the exception!</pre>\r\nYou can see that the ExampleLoggingClass log message has been decorated with the prefix APPMSG and the method name (main).",
  "excerpt": ""
 },
 {
  "title": "Broken Eclipse shortcut under Gnome for Occurrences in File",
  "published": "2010-03-17 11:20:13",
  "postType": "post",
  "slug": "/2010/03/17/broken-eclipse-shortcut-under-gnom/",
  "status": "publish",
  "tags": [],
  "categories": [
   "eclipse"
  ],
  "content": "<h1>Broken Eclipse shortcut under Gnome for Occurrences in File</h1><div style=\"text-align:left;\">One of the extremely useful keyboard shortcuts for Eclipse is Shift+Control+U which finds all occurrences of a selected identifier in the current file. Unfortunately&nbsp; this doesn't work under Linux with Gnome because <a href=\"https://help.ubuntu.com/community/ComposeKey#Unicode%20composition\" id=\"o65b\" title=\"Gnome uses this shortcut for composing Unicode\">Gnome uses this shortcut for composing Unicode</a> characters. You can check it by typing Shift+Control+U followed by 123 and a space into your browser's address bar: first it will render an underlined <u>u</u> and then a strange g-like character.<br /><br />The conclusion is that you cannot use the shortcut Shift+Control+U and perhaps also a few others (I experienced troubles with Shift+Ctrl+A) in Eclipse under Gnome. You can the shortcut in preferences accessible e.g. via pressing twice Shift+Ctrl+L. For instance Shift+Ctrl+F1 is OK.<br /><br />Environment: Eclipse 3.4/3.5, Ubuntu 9.04 with Gnome 2.26.1.</div><br />",
  "excerpt": ""
 },
 {
  "title": "Eclipse: Open Type/Resource working again under Linux!",
  "published": "2010-02-26 05:28:45",
  "postType": "post",
  "slug": "/2010/02/26/eclipse-open-typeresource-working/",
  "status": "publish",
  "tags": [],
  "categories": [
   "eclipse"
  ],
  "content": "Some weeks ago the extremely useful features of Eclipse Open Type and Open Resource stopped working, throwing an uninformative&nbsp; Error instead, no matter which version or JRE vendor. I was desperate. Until finally I found a <a href=\"https://bugs.eclipse.org/bugs/show_bug.cgi?id=240033\">bug regarding this issue</a> which pointed me to the solution - switching off Gnome's assistive technologies (System - Preferences - Assistive Technologies - uncheck Enable assistive technologies under my Ubuntu 9.04 Jaunty). Thanks, allmighty powers of digitalized universe!",
  "excerpt": ""
 },
 {
  "title": "Released DbUnit Test Skeleton 1.1.0 - also in Maven Central",
  "published": "2010-02-23 03:10:54",
  "postType": "post",
  "slug": "/2010/02/23/released-dbunit-test-skeleton-1-1/",
  "status": "publish",
  "tags": [
   "java"
  ],
  "categories": [
   "Languages"
  ],
  "content": "<h1>Released DbUnit Test Skeleton 1.1.0 - also in Maven Central</h1><br />I've released version 1.1.0 of my DbUnit extension, which is now also available in the Maven central repository under the group id net.jakubholy.testing and artifact id dbunit-embeddedderby-parenttest. It brings some API changes, new utillities and removes the need to extend the base TestCase class.<br /><h3>What is it?</h3>Creating a a <a title=\"http://www.dbunit.org/\" rel=\"nofollow\" href=\"http://www.dbunit.org/\" class=\"external text\">DbUnit</a> test case may be time consuming. With the dbunit-embeddedderby-parenttest you can have your DbUnit test including an embedded database with structures and data ready in a few minutes. (At least if you are fast enough in writing SQL and preparing your data :-) ).<br /><br />The added value of this project is that provides classes pre-configured to interact with an embedded Derby database and the only thing you need to do is to provide a DDL file, execute a utillity to create the database, and enter data into the predefined data set XML file. In addition to that it also provides some nice utility methods and classes such as <a title=\"http://jeeutils.svn.sourceforge.net/viewvc/jeeutils/trunk/DbUnitTestSkeleton/src/main/java/net/jakubholy/testing/dbunit/embeddeddb/assertion/RowComparator.java?view=markup\" rel=\"nofollow\" href=\"http://jeeutils.svn.sourceforge.net/viewvc/jeeutils/trunk/DbUnitTestSkeleton/src/main/java/net/jakubholy/testing/dbunit/embeddeddb/assertion/RowComparator.java?view=markup\" class=\"external text\">RowComparator</a> and <a title=\"http://jeeutils.svn.sourceforge.net/viewvc/jeeutils/trunk/DbUnitTestSkeleton/src/main/java/net/jakubholy/testing/dbunit/embeddeddb/IEnhancedDatabaseTester.java?view=markup\" rel=\"nofollow\" href=\"http://jeeutils.svn.sourceforge.net/viewvc/jeeutils/trunk/DbUnitTestSkeleton/src/main/java/net/jakubholy/testing/dbunit/embeddeddb/IEnhancedDatabaseTester.java?view=markup\" class=\"external text\">IEnhancedDatabaseTester</a> and it overrides the default DbUnit setting to use fully qualified table names (in the form schema.table), which gives you more freedom.<br /><h3>New and noteworthy</h3>As you can guess from the version number change, the API has changed and may be not compatible with some code written against a previous version. The main changes are:<br /><ul><li>All functionality moved to EmbeddedDbTester so that extending the AbstractEmbeddedDbTestCase isn't necessary anymore, which is useful e.g. in JUnit 4 or when extending another JUnit derivation. It's also a standard DbUnit's IDatabaseTester.</li><li>It's now possible to change completely the DB used by defining some JDBC properties in dbunit-embedded.properties</li><li>Added utility methods getDataSource, getSqlConnection and a convenience method createCheckerForSelect, some of those implemented in  the EnhancedDatabaseTesterDecorator so that they can be added to any IDatabaseTester.</li><li>Switched from Java util logging to commons-logging for better configurability.<br /><br />You can download the release also from the Maven Central Repository at <a title=\"http://repo1.maven.org/maven2/net/jakubholy/testing/dbunit-embeddedderby-parenttest/1.1.0/\" id=\"xsov\" href=\"http://repo1.maven.org/maven2/net/jakubholy/testing/dbunit-embeddedderby-parenttest/1.1.0/\">http://repo1.maven.org/maven2/net/jakubholy/testing/dbunit-embeddedderby-parenttest/1.1.0/</a><br /></li></ul><br />",
  "excerpt": ""
 },
 {
  "title": "The Art of Logging (review)",
  "published": "2010-02-10 05:52:24",
  "postType": "post",
  "slug": "/2010/02/10/the-art-of-logging-review/",
  "status": "publish",
  "tags": [],
  "categories": [
   "General"
  ],
  "content": "<p>Colin Eberhardt, the co-author of the Simple Logging Facade, has written a very good article <a href=\"http://www.codeproject.com/KB/trace/ArtOfLogging.aspx\">The Art of Logging</a>, which should be a compulsory reading for every developer especially in the server side development domain. It's good both as an introduction as it covers all the important aspects and also for experienced developers because it has some very valuable insights.</p><p>Few ideas and sentences that really should be stressed:<br /></p><ul><li>&quot;Logging is the process of recording application actions and state to a secondary interface.&quot; Developers should really realize that a log is indeed an alternative interface to their application and may be the only one they'll have access to in a production environment.</li><li>&quot;Considering the importance of log levels, when embarking on a project, the development team should agree on exactly how these levels are used in order to ensure consistency between developers.&quot; I saw some projects where consistency was crouched and crying in the corner :-) With consistency it's easier to understand a log, to know what to look for and how to search for it.</li><li>Regarding exceptions, you should be aware that not all exceptions are actually errors and you should always consider what level is appropriate for reporting a particular exception.</li><li>What to log:</li><ul><li>The level of detail needed in a log depends on the presence or absence of other monitoring tools for the application.</li><li>On the importance of context: &quot;<b>In summary, a log message without context information is often as useful as no log message at all!</b>.&quot; This sentence shall be in gold and also burnt to the skin of each developer who fails to apply it. How many times have I been desperate troubleshooting a problem for hours and days that wouldn't take more than 5 minutes to diagnose and solve if proper context information was provided in the exception and/or log!</li></ul><li>&quot;... it is worth thinking about applying a standard format to your logged messages. This can prove very valuable if you need to analyse large log files (where tools like grep are indispensible).&quot; I can sign this, trust the guy, he knows what he's talking about!</li><li>&quot;good messages are brief and provide the most important context information&quot;</li></ul><p>Logging to little is terrible if not outright evil but logging too much isn't good either and brings numerous problems, for example it unnecessarily complicates the code, too detailed logs are hard to analyze, and, from my experience, large logs in production environments are cleared more often for space reasons and thus you're more likely to have no log at all when you need it.<br /><br />There is also a good point about unit testing your logging code to verify that important exceptions are indeed logged at the appropriate level and including the exception itself (not actually testing the message as that would be unnecessarily complicated to do and to maintain). I actually got recently the idea that while running unit tests you should always also review the log produced and verify that it communicates everything necessary for troubleshooting the tested cases and this at both the usually encountered log levels, i.e. info and debug.</p><p>Summary: Make sure to read the article and apply it in your day to day coding! And if you know about other sources regarding logging best practices, I'd be glad to learn about them too!<br /></p>",
  "excerpt": ""
 },
 {
  "title": "Releasing a project to Maven Central repository via Sonatype",
  "published": "2010-02-07 16:05:01",
  "postType": "post",
  "slug": "/2010/02/07/releasing-a-project-to-maven-centr/",
  "status": "publish",
  "tags": [
   "deployment",
   "Maven",
   "open_source",
   "oss"
  ],
  "categories": [
   "Tools"
  ],
  "content": "If you have an open-source project and want it published into the Maven Central repository - even if it itself isn't build with maven - to make it visible to all Maven users without any special effort (at least once you set everything up), read on.<br><br>This is excatly what I wanted to do with my <a href=\"http://sourceforge.net/apps/mediawiki/jeeutils/index.php?title=DbUnit_Test_Skeleton\">dbunit-embeddedderby-parenttest</a>, an extension of DbUnit that extremly simplifies setup of unit tests that need a database by using an embedded Derby DB and providing suitable defaults and utility methods.<br><br>The essential step is to deploy your artifacts to the Sonatype's OSS hosting repository, which is free for open-source project, and which will take care of hourly automatic synchronization with Maven Central once you release your artifacts to Sonatype, satisfy some requirements and let them know about it. There is a good <a href=\"https://docs.sonatype.org/display/Repository/Sonatype+OSS+Maven+Repository+Usage+Guide\">guide for setting up hosting with Sonatype</a> but there a few tricky parts and that's why I've written down this blog.<br><br>The procedure is as follows:\r\n<ol>\r\n\t<li>Mavenize your project. You don't actually need to build it with Maven, you only need to provide a maven metadata file (pom.xml). You may want to check <a href=\"https://jeeutils.svn.sourceforge.net/svnroot/jeeutils/tags/dbunit-embeddedderby-parenttest-1.0.2/pom.xml\">my project's pom.xml v1.0.2</a> (or the <a href=\"https://jeeutils.svn.sourceforge.net/svnroot/jeeutils/trunk/DbUnitTestSkeleton/pom.xml\">latest</a>) for inspiration and to see how I've configured the other things mentioned here.</li>\r\n\t<li>Follow the steps described in the <a href=\"https://docs.sonatype.org/display/Repository/Sonatype+OSS+Maven+Repository+Usage+Guide\">guide for setting up hosting with Sonatype</a>:\r\n<ol>\r\n\t<li>Sign up on the Sonatype repository manager Nexus at <a href=\"http://oss.sonatype.org/\">http://oss.sonatype.org/</a></li>\r\n\t<li>Sign up on the Sonatype ticketing system at <a href=\"https://issues.sonatype.org/browse/OSSRH\">https://issues.sonatype.org/browse/OSSRH</a></li>\r\n\t<li>Create a new ticket asking the creation of a maven repository for your project, see my <a href=\"https://issues.sonatype.org/browse/OSSRH-141\">OSSRH-141</a> as an example<a href=\"https://issues.sonatype.org/browse/OSSRH-141\">\r\n</a></li>\r\n\t<li>Make sure that your pom.xml satisfies all the requirements for publishing to the Maven Central Repo, listed in the guide (SCM url, site url, no &lt;repositories&gt; etc.)</li>\r\n\t<li>Wait for creation of the repositories, once finished, a comment will be added to the ticket, which should also result in send an email notification to you</li>\r\n</ol>\r\n</li>\r\n\t<li>Build and sign your artifacts (see below)</li>\r\n\t<li>Deploy your artifacts to the new repository at Sonatype (see below)</li>\r\n\t<li>(optional?) Promote the published artifacts from the staging to the release repository (only applicable if you do not deploy directly to the release repo - but it seems obligatory to use staging now.)</li>\r\n\t<li>When the artifacts are in the release repository, add a comment to the original ticket asking for them to be published to Maven Central. For the first time they need to do it manually but since that on it will be synchronized automatically every hour</li>\r\n</ol>\r\n<h2>Build and sign your artifacts</h2>\r\nBuild your project's artifacts as you are used to, for example with <span style=\"font-family:courier new, courier, monospace;\">mvn package</span> if you're a Maven guy or with <span style=\"font-family:courier new, courier, monospace;\">ant</span>.<br><br>Next you need to sign them with your private key because valid signatures are one of the requirements for publishing to Maven Central. This is already well described in the article <a href=\"//www.sonatype.com/people/2010/01/how-to-generate-pgp-signatures-with-maven/\">How to Generate PGP Signatures with Maven</a> so I'll only summarize it and add few tips.\r\n<ol>\r\n\t<li>Create a new GPG or PGP key if you haven't one already. You can use the command-line application gpg or a GUI tool such as seahorse (under Ubuntu: Applications &gt; Accessories &gt; Passwords and Encryption Keys).</li>\r\n\t<li>Publish the key to the required PGP server pgp.mit.edu: <span style=\"font-family:courier new, courier, monospace;\">\r\ngpg --keyserver pgp.mit.edu --send-key &lt;ID of your key; for me it was 66AE163A&gt;</span></li>\r\n\t<li>Sign your files using either gpg directly or the maven-gpg-plugin (also described in the article mentioned above) - see below.</li>\r\n</ol>\r\n<h3>Signing with maven-gpg-plugin and automatic deployment</h3>\r\nUsing the maven-gpg-plugin has the advantage that running<br><br><span style=\"font-family:courier new, courier, monospace;\">mvn deploy -DperformRelease=true -Dgpg.passphrase=**** -Dgpg.keyname=&lt;your key ID&gt;</span><br><br>will automatically sign your artifacts and deploy them together with the signatures. On the other hand, as with any plugin, its configuration and use may have some issues. (Setting the property performRelease=true is necessary in my case because I have configured the plugin to be actived only if this is set.)<br><br>Tips\r\n<ul>\r\n\t<li>If the key you want to use for signing isn't your defaul key then you need to tell Maven which key to use by storing its id in the property <em>gpg.keyname</em> either by passing -Dgpg.keyname=... on the command line or setting it in the pom.xml as you can is in the mine.</li>\r\n</ul>\r\n<h3 id=\"SignDeployManually\">Signing and deploying signatures manually</h3>\r\nYou may instead decide to sign your artifacts manually using directly gpg (or whatever tool you have), for example like this:<br><br><span style=\"font-family:courier new, courier, monospace;\">gpg -u &lt;your key ID&gt; --sign --detach-sign -a target/dbunit-embeddedderby-parenttest.jar</span><br><br>This command would create the signature file <span style=\"font-family:courier new, courier, monospace;\">target/dbunit-embeddedderby-parenttest.jar.asc</span>.<br><br>Next you will need to deploy the signature to the repository along with the original artifact:<br><br><span style=\"font-family:courier new, courier, monospace;\">mvn deploy:deploy-file -Durl=http://oss.sonatype.org/service/local/staging/deploy/maven2 -DrepositoryId=nexus-releases -Dfile=target/dbunit-embeddedderby-parenttest.jar.asc -DpomFile=pom.xml -Dpackaging=asc</span>\r\n<ul>\r\n\t<li>The <em>url</em> will be the same for everybody who wants to publish artifacts via a staging repository and not directly to to the release one otherwise you need to provide the URL of the release repository created for you by Sonatype.</li>\r\n\t<li>The <em>repositoryId</em> must correspond to a &lt;server&gt; record in your &lt;user home&gt;/.m2/.settings.xml with the same id and your login name and password  for oss.sonatype.org, it tells maven what credentials to use to authenticate with the target repository</li>\r\n\t<li>Beware that the name of the uploaded file isn't the same as of the local file being uploaded but is constructed by Maven from the artifactId, version, and optionally packaging and classifier provided in the pom.xml or on the command line</li>\r\n</ul>\r\nAnd perhaps also deploy the artifact itself if not done otherwise:<br><br><span style=\"font-family:courier new, courier, monospace;\">mvn deploy:deploy-file\r\n-Durl=http://oss.sonatype.org/service/local/staging/deploy/maven2\r\n-DrepositoryId=nexus-releases\r\n-Dfile=target/dbunit-embeddedderby-parenttest.jar -DpomFile=pom.xml</span>\r\n<h4>Examples of manual deployment</h4>\r\nThe following examples show you how to deploy files if different names to the Sonatype's staging repository. They all use a common pom.xml (you'll perhaps want change the groupId and artifactId) and you will need to change the -DrepositoryId to correspond to the server id you've assigned to your Sonatype repository credentials in your settings.xml (discussed below).<br><br>The common pom.xml:\r\n<pre> &lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\r\n        xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd\"&gt;\r\n        &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;\r\n        &lt;groupId&gt;eu.ibacz.pokusy.jakubholy&lt;/groupId&gt;\r\n        &lt;artifactId&gt;smazMe&lt;/artifactId&gt;\r\n        &lt;name&gt;dummy pokusny projekt&lt;/name&gt;\r\n        &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;       \r\n&lt;/project&gt;\r\n$ mvn deploy:deploy-file -Durl=http://oss.sonatype.org/service/local/staging/deploy/maven2 -DrepositoryId=nexus-releases -Dfile=smazMe.jar -DpomFile=pom.xml -Dpackaging=jar</pre>\r\n=&gt; Uploading: http://oss.sonatype.org/service/local/staging/deploy/maven2/eu/ibacz/pokusy/jakubholy/smazMe/1.0-SNAPSHOT/smazMe-1.0-20100210.143500-1.jar\r\n<pre>$ mvn deploy:deploy-file-Durl=http://oss.sonatype.org/service/local/staging/deploy/maven2 -DrepositoryId=nexus-releases -Dfile=smazMe.jar.asc -DpomFile=pom.xml</pre>\r\n=&gt; Uploading: http://oss.sonatype.org/service/local/staging/deploy/maven2/eu/ibacz/pokusy/jakubholy/smazMe/1.0-SNAPSHOT/smazMe-1.0-20100210.143508-2.jar.asc\r\n<pre> $  mvn deploy:deploy-file -Durl=http://oss.sonatype.org/service/local/staging/deploy/maven2 -DrepositoryId=nexus-releases -Dfile=smazMe-all.zip -DpomFile=pom.xml -Dpackaging=zip -Dclassifier=all</pre>\r\n=&gt; Uploading:\r\nhttp://oss.sonatype.org/service/local/staging/deploy/maven2/eu/ibacz/pokusy/jakubholy/smazMe/1.0-SNAPSHOT/smazMe-1.0-20100210.143513-3-all.zip\r\n<pre>$  mvn deploy:deploy-file -Durl=http://oss.sonatype.org/service/local/staging/deploy/maven2 -DrepositoryId=nexus-releases -Dfile=smazMe-all.zip.asc -DpomFile=pom.xml -Dpackaging=zip.asc -Dclassifier=all</pre>\r\n=&gt; Uploading:\r\nhttp://oss.sonatype.org/service/local/staging/deploy/maven2/eu/ibacz/pokusy/jakubholy/smazMe/1.0-SNAPSHOT/smazMe-1.0-20100210.143524-4-all.zip.asc<br><br>Note: You may also supply the option -DuniqueVersion=false to avoid the addition of a generated number to file names.\r\n<h2>Deploy your artifacts</h2>\r\nSince we are going to deploy our artifacts to a Maven repository, we need to use Maven for that. We have a couple of ways of doing that: we can let Maven to deploy all that is necessary (which will also build and sign the artifact, if necessary), alternatively we can deploy already prepared artifacts manually, one by one, or finally we can do any of these using Maven Ant integration.<br><br>Notice that it's now required to publish artifacts via a staging repository instead\r\nof directly to the release one so that you can review and have to approve them before they are actually release (details in the following section).\r\n<h3>A. Deploying directly with Maven</h3>\r\nUnless you decide to use the release plugin (which I do use), which does some neat and useful things such as creating an SVN tag, increasing the project's version etc., the deployment is as easy as executing<br><br><span style=\"font-family:courier new, courier, monospace;\">mvn deploy -DperformRelease=true -Dgpg.passphrase=**** -Dgpg.keyname=&lt;your key ID&gt;</span><br><br>(see the section about maven-gpg-plugin to understand why I need these three properties).<br><br>There are two important configurations that make this possible. First of all, you must configure the target deployment repository in your pom.xml:\r\n<pre>&lt;project ...&gt;\r\n   ...\r\n    &lt;distributionManagement&gt;\r\n        &lt;repository&gt;\r\n            &lt;id&gt;nexus-releases&lt;/id&gt;\r\n            &lt;name&gt;Nexus Release Repository&lt;/name&gt;\r\n            &lt;url&gt;http://oss.sonatype.org/service/local/staging/deploy/maven2/&lt;/url&gt;\r\n        &lt;/repository&gt;\r\n    &lt;/distributionManagement&gt;\r\n&lt;/project&gt;</pre>\r\nThe &lt;id&gt; is arbitrary and the &lt;url&gt; is same for all, it's actually a kind of a virtual repository and the artifacts will be in reality deployed to a temporary repository based on your username.<br><br>Next you need to store your username and password for oss.sonatype.org under the same &lt;id&gt; as above in the file &lt;user home&gt;/.m2/settings.xml so that maven can authenticate with the repository:\r\n<pre>&lt;settings&gt;\r\n   ...\r\n   &lt;servers&gt;\r\n      &lt;server&gt;\r\n         &lt;id&gt;nexus-releases&lt;/id&gt;\r\n         &lt;username&gt;malyvelky&lt;/username&gt;\r\n         &lt;password&gt;******&lt;/password&gt;\r\n      &lt;/server&gt;\r\n   &lt;/servers&gt;\r\n&lt;/settings&gt;</pre>\r\n<h4>Troubleshooting deployment failures</h4>\r\n<h5>Error 401 (Unauthorized)</h5>\r\nIf the deployement fails with an error like this:\r\n<pre>Error deploying artifact: Failed to transfer file: http://oss.sonatype.org/service/local/staging/deploy/maven2//net/jakubholy/testing/dbunit-embeddedderby-parenttest/1.0.2/dbunit-embeddedderby-parenttest-1.0.2.jar. Return code is: 401</pre>\r\n(notice the error code <a href=\"http://en.wikipedia.org/wiki/List_of_HTTP_status_codes#4xx_Client_Error\">401</a>) it most likely means that you haven't configured your username/password correctly or that the two IDs (repository id in pom.xml and server id in settings.xml) do not match.\r\n<h5>Error 400 (Bad Request)</h5>\r\nThis error indicates that the repository manager has rejected your artifact for some reason. This may happen for example if you try to deploy a snapshot version into the staging repository, which is not allowed by its policy. (For snapshots you should reference the snapshot repository created for you as distributionManagement/snapshotRepository in your pom.xml.)\r\n<h3>B. Deploying manually</h3>\r\nIf you have already built and signed your artifacts, you can deploy them manually with the mvn<a href=\"https://maven.apache.org/plugins/maven-deploy-plugin/deploy-file-mojo.html\"> deploy:deploy-file goal</a> as in the example below:\r\n<pre>$ mvn deploy:deploy-file-Durl=http://oss.sonatype.org/service/local/staging/deploy/maven2 -DrepositoryId=nexus-releases -Dfile=smazMe.jar.asc -DpomFile=pom.xml</pre>\r\nSee the section <a href=\"#SignDeployManually\">Signing and deploying signatures manually</a> above for explanation and examples of deployment of different types of files (.jar, .zip, signatures).<br><br>In this case you do not need the <span style=\"font-family:courier new, courier, monospace;\">distributionManagement</span> section in your pom.xml (because you're providing all the information on the command line) but you still need to provide your login and password for the target repository (option <span style=\"font-family:courier new, courier, monospace;\">-DrepositoryId=...</span>) in your settings.xml as described above.<br><br>Of course you can run the deployment commands manually or for instance from Ant.\r\n<h3>C. Deploying with Ant nad the Maven Ant Tasks</h3>\r\n<strong>Update 10/2010</strong>: Sonatype user guide now contains the section <a href=\"https://docs.sonatype.org/display/Repository/Sonatype+OSS+Maven+Repository+Usage+Guide#SonatypeOSSMavenRepositoryUsageGuide-7c.StageArtifactswithAnt\">7c. Stage Artifacts with Ant</a>.<br><br>You may also use the <a href=\"http://maven.apache.org/ant-tasks/index.html\">Maven Ant Tasks</a> to invoke Maven operations from an Ant build including a <a href=\"http://maven.apache.org/ant-tasks/examples/install-deploy.html\">task for file deployment</a>. It does basically the same as invoking mvn deploy:deploy-file from the command line but you can provide the repository credentials here without a need for settings.xml and you may also find this way of Maven invocation nicer than calling a command-line application.\r\n<h2>Promote the published artifacts from the staging to the release repository</h2>\r\nThis step is only necessary if you deploy via the staging repository and not directly to the release repository. But according to a recent email by Juven Xu it seems to be now obligatory to deploy via staging:\r\n<blockquote><em>Staging is one of the most outstanding features in Nexus Pro. We've\r\nbeen provided you this service for a long time, but maybe you were not\r\naware of this. So I changed your release repository configuration and\r\nyou will no longer be able to deploy release artifacts directly into\r\nthe release repository. Instead, you should deploy your release\r\nartifacts into the staging repository: <a href=\"http://email.seznam.cz/redir?hashId=2874787214&amp;to=http%3a%2f%2foss%2esonatype%2eorg%2fservice%2flocal%2fstaging%2fdeploy%2fmaven2%2f\" target=\"_blank\">http://oss.sonatype.org/service/local/staging/deploy/maven2/</a>,\r\nthen log in from Nexus UI, do things like closing staging repository,\r\nand promoting the staged artifacts into your release repository.</em></blockquote>\r\nIf you are not familiar with Staging, it's well documented at <a href=\"http://email.seznam.cz/redir?hashId=2874787214&amp;to=http%3a%2f%2fwww%2esonatype%2ecom%2fbooks%2fnexus%2dbook%2freference%2fstaging%2ehtml\" target=\"_blank\">http://www.sonatype.com/books/nexus-book/reference/staging.html</a>.\r\n<h3>New instructions (6/2011)</h3>\r\n<ol>\r\n\t<li>Log in to oss.sonatype.com</li>\r\n\t<li>Click on \"Staging Repositories\" under Build Promotion</li>\r\n\t<li>Verify the content of the repository (in the bottom pane), check it, click Close, confirm</li>\r\n\t<li>Check the repo again, click \"Release\"</li>\r\n\t<li>You shall now see your artifacts in the release repository created for you (mine is http://oss.sonatype.org/content/repositories/jakubholy-releases/).</li>\r\n\t<li>In some hours (?) it should also appear in Maven Central</li>\r\n</ol>\r\n<h3>Old instructions</h3>\r\nYou must do the following to promote the deployed artifacts from the staging to the release repository:\r\n<ol>\r\n\t<li>Log in to oss.sonatype.com</li>\r\n\t<li>In the right menu, click on \"Staging\" in the box called \"Enterprise\" (#1 in the screenshot) =&gt; you should see the \"staging profile\" named &lt;your project name&gt; (for me it was \"net.jakubholy\"; see #2)</li>\r\n\t<li>Click on your staging repository target (\"net.jakubholy\", #2) - you should see the individual repositories (some generated name such as net.jakubholy-028) within that including their status, which is \"open\" right after a deployment (which means that files may be still deployed and redeployed to this temporary repository)</li>\r\n\t<li>Verify that the project artifacts are as expected (see below)</li>\r\n\t<li>\"Close\" and \"Promote\" the staging repository to promote its content to the release repository: right-click on its status and you should see a little \"context menu\" with options Close and Drop, select Close (#3). You'll be asked for a description, which will be associated with that release. After some time you should also receive a confirmation email from the \"Nexus Repository Manager\" with the subject \"Nexus: Staging Completed.\"</li>\r\n\t<li>\"Promote\" the closed staging repository to the release one in a way similar to closing it, only now seeing the current status as \"closed\" and selecting \"Promote\" from the context menu (beware: there may be some delay before this becomes possible), select your release repository as the target (Jakubholy Releases for me).</li>\r\n\t<li>You shall now see your artifacts in the release repository created for you (mine is http://oss.sonatype.org/content/repositories/jakubholy-releases/).</li>\r\n</ol>\r\n<img src=\"http://jroller.com/holy/resource/sonatype_oss-staging_repo.png\" alt=\"Sonatype Repository Manager - closing a stagin repo.\" align=\"bottom\" border=\"0\" hspace=\"0\" vspace=\"0\" />\r\n<h3>Required artifacts</h3>\r\n[Since 2010-04-19] It is no required that you include -javadoc.jar along with -sources.jar with your artifacts otherwise you will not be allowed to promote. You can easily create them either with Maven or manually.\r\n<h3>Verifying project artifacts before promoting from the staging repository</h3>\r\nBefore you promote the project's artifacts from the staging to the release repository you may want to check few things to be sure that the release is OK:\r\n<ul>\r\n\t<li>Are all artifacts included?</li>\r\n\t<li>pom.xml:\r\n<ul>\r\n\t<li>Is the version all right?</li>\r\n\t<li>Are the SCM URLs correct? (Should be set by the release plugin to the tag for that release.)</li>\r\n</ul>\r\n</li>\r\n</ul>\r\n<h2>When will the artifacts be available in Maven Central?</h2>\r\nIn ideal case within one hour, in reality it seems to be few hours, <a href=\"https://issues.sonatype.org/browse/NEXUS-4278\">even 12h</a> sometimes.\r\n<h2>Summary</h2>\r\nWe've learned how to create a maven repository at oss.sonatype.org, how to sign our artifacts with a private key, how to use the staging repository and finally how to get the released artifacts pushed to the Maven Central repository, where they will be available to all maven users out of the box.\r\n<h2>Other useful links</h2>\r\n<ul>\r\n\t<li>Check <a href=\"https://jeeutils.svn.sourceforge.net/svnroot/jeeutils/tags/dbunit-embeddedderby-parenttest-1.0.2/pom.xml\">my project's pom.xml v1.0.2</a> (or the <a href=\"https://jeeutils.svn.sourceforge.net/svnroot/jeeutils/trunk/DbUnitTestSkeleton/pom.xml\">latest</a>) to see how I've configured the stuff described above. It uses the maven-gpg-plugin and maven-release-plugin and deployes to the staging repository. (Beware that some comments in the file may be a bit out of date or inexact.)</li>\r\n\t<li>Documentation about deployment via a staging repository: <a href=\"http://www.sonatype.com/books/nexus-book/reference/staging-sect-deployment.html\">http://www.sonatype.com/books/nexus-book/reference/staging-sect-deployment.html</a></li>\r\n\t<li>There is a pretty good article \"<a href=\"http://java.dzone.com/articles/automating-releases-maven-0\">Automating Releases With maven-release-plugin</a>\"; check also its discussion for some pros and cons of the plugin</li>\r\n</ul>\r\nUnrelated but interesting:\r\n<ul>\r\n\t<li>Maven and Sourceforge guide - <a href=\"http://docs.codehaus.org/display/MAVENUSER/MavenAndSourceforge\">http://docs.codehaus.org/display/MAVENUSER/MavenAndSourceforge</a></li>\r\n\t<li><span style=\"text-decoration:line-through;\">Maven SF plugin for building and deploying to SF: <a href=\"http://maven-plugins.sourceforge.net/maven-sourceforge-plugin/\">http://maven-plugins.sourceforge.net/maven-sourceforge-plugin/</a></span> <em>for Maven 1 only</em></li>\r\n</ul>",
  "excerpt": ""
 },
 {
  "title": "Compiling with AspectJ''s ajc compiler from Maven",
  "published": "2009-12-10 05:50:01",
  "postType": "post",
  "slug": "/2009/12/10/compiling-with-aspectjs-ajc-compil/",
  "status": "publish",
  "tags": [
   "AOP",
   "AspectJ",
   "java",
   "Maven"
  ],
  "categories": [
   "Languages"
  ],
  "content": "I needed to compile AspectJ classes (.java with annotations) with ajc and I wanted to have that integrated into the Maven build process. I tried several means, finally finding the one that worked.<br><br>Note: I had to use ajc even though I was using the pure java 5 syntax based on annotations instead of the legacy AspectJ syntax due to <a href=\"https://bugs.eclipse.org/bugs/show_bug.cgi?id=290227\">bug in AspectJ</a> (fixed in v. 1.6.6).\r\n<h1>Failed Attempts</h1>\r\n<h2>aspectj-maven-plugin v1.2</h2>\r\nFirst I tried the AspectJ Maven plugin but it didn't work for me because I had a special need - a project containing only an aspect while the plugin requires, if I remember correctly, also the advised sources to be in the project. A fix is available and should be included in the version 1.3 but the project doesn't seem to be very active so who knows when it will be released. See <a href=\"http://jira.codehaus.org/browse/MASPECTJ-7\">MASPECTJ-7</a>.\r\n<h2>maven-compiler-plugin for aspectj</h2>\r\nNext I tried the maven-compiler-plugin, which supports various back-ends including AspectJ with the dependency on plexus-compiler-aspectj and compilerId set to aspectj. Unfortunately the plexus-compiler-aspectj is quite out of date, supporting only AspectJ 1.3 while I needed 1.6.\r\n<h1>Finally the Success: maven-antrun-plugin</h1>\r\nBeing failed by Maven plugins, I had to resort to the standard way of running ajc via Ant. Fortunately Maven has a very good integration of Ant and its tasks.<br><br>The only problem here was that Ant requires ${java.home} to point to JDK (and not JRE) to find javac. It doesn't help to set the envrionmental variable JAVA_HOME to point to the JDK because Maven resets it to $JAVA_HOME/jre in the case - see <a href=\"http://jira.codehaus.org/browse/MANTRUN-91\">MANTRUN-91</a>. The solution is to add tools.jar (which includes javac classes) to maven-antrun-plugin's dependencies.<br><br>The corresponding piece of pom.xml:\r\n<pre>&lt;build&gt;\r\n&lt;plugins&gt;\r\n  &lt;plugin&gt;\r\n    &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt;\r\n    &lt;!-- Tell javac not to compile sources for antrun will do it --&gt;\r\n    &lt;configuration&gt;\r\n        &lt;excludes&gt;\r\n            &lt;exclude&gt;**/*.*&lt;/exclude&gt;\r\n        &lt;/excludes&gt;\r\n    &lt;/configuration&gt;\r\n  &lt;/plugin&gt;<br><br>  &lt;plugin&gt;\r\n    &lt;artifactId&gt;maven-antrun-plugin&lt;/artifactId&gt;\r\n    &lt;version&gt;1.3&lt;/version&gt;\r\n    &lt;dependencies&gt;\r\n      &lt;dependency&gt;\r\n        &lt;groupId&gt;sun.jdk&lt;/groupId&gt;\r\n        &lt;artifactId&gt;tools&lt;/artifactId&gt;\r\n        &lt;version&gt;1.5.0&lt;/version&gt;\r\n        &lt;scope&gt;system&lt;/scope&gt;\r\n        &lt;systemPath&gt;${java.home}/../lib/tools.jar&lt;/systemPath&gt;\r\n      &lt;/dependency&gt;\r\n      &lt;dependency&gt;\r\n        &lt;groupId&gt;org.aspectj&lt;/groupId&gt;\r\n        &lt;artifactId&gt;aspectjtools&lt;/artifactId&gt; &lt;!-- apectj ant plugin --&gt;\r\n        &lt;version&gt;1.6.0&lt;/version&gt;\r\n      &lt;/dependency&gt;\r\n    &lt;/dependencies&gt;<br><br>    &lt;executions&gt;\r\n      &lt;execution&gt;\r\n        &lt;phase&gt;compile&lt;/phase&gt;\r\n        &lt;goals&gt;\r\n          &lt;goal&gt;run&lt;/goal&gt;\r\n        &lt;/goals&gt;\r\n        &lt;configuration&gt;\r\n          &lt;tasks&gt;\r\n            &lt;echo&gt;AntRun: Compiling AspectJ classes with ajc, java.home=${java.home}&lt;/echo&gt;\r\n            &lt;taskdef\r\n              resource=\"org/aspectj/tools/ant/taskdefs/aspectjTaskdefs.properties\"\r\n              classpathref=\"maven.plugin.classpath\" /&gt;<br><br>            &lt;iajc\r\n              srcDir=\"src/main/java\"\r\n              destDir=\"target/classes\"\r\n              verbose=\"true\"\r\n              showWeaveInfo=\"true\"\r\n              source=\"1.5\"\r\n              classpathRef=\"maven.compile.classpath\"\r\n              Xlint=\"ignore\" &gt;<br><br>              &lt;exclude name=\"eu/ibacz/pbns/util/aspect/ExampleTimingAnnotatedAspect.java\"/&gt;\r\n            &lt;/iajc&gt;<br><br>          &lt;/tasks&gt;\r\n        &lt;/configuration&gt;\r\n      &lt;/execution&gt;\r\n    &lt;/executions&gt;\r\n  &lt;/plugin&gt;\r\n&lt;/plugins&gt;\r\n&lt;/build&gt;</pre>\r\nNote: maven-antrun-plugin v1.3 uses Ant 1.7.1 - see http://maven.apache.org/plugins/maven-antrun-plugin/dependencies.html\r\n<h1>Conclusion</h1>\r\nIt's a bit tricky but very well possible to run AspectJ compiler instead of javac during a maven build. The most flexible way is to use the AspectJ Ant task and maven-antrun-plugin though in more standard cases the aspectj-maven-plugin can serve you well too.",
  "excerpt": ""
 },
 {
  "title": "Troubleshooting logging configuration (Log4j, commons-logging)",
  "published": "2009-12-07 04:13:39",
  "postType": "post",
  "slug": "/2009/12/07/troubleshooting-logging-configurat/",
  "status": "publish",
  "tags": [
   "commons-logging",
   "configuration",
   "java",
   "log4j",
   "logging",
   "troubleshooting"
  ],
  "categories": [
   "Languages",
   "Tools"
  ],
  "content": "Did it ever happen to you that your logging didn't behave as expected? Here are some tips how to find out what's going on.\r\n<h3>Commons-logging (since 1.1)</h3>\r\nSet the system property <code>org.apache.commons.logging.diagnostics.dest</code> to <code>STDOUT</code> (or <code>STDERR</code> or a file name); <a href=\"http://commons.apache.org/logging/commons-logging-1.1.1/troubleshooting.html#How%20To%20Use%20Diagnostic%20logging\">docs</a>: <code>-Dorg.apache.commons.logging.diagnostics.dest=STDOUT</code><br><br>Extract of a sample output (no commons-logging.properties):\r\n<pre><code>\r\n...\r\n[LogFactory from sun.misc.Launcher$AppClassLoader@934873913] [ENV] Application classpath (java.class.path): ..\r\n...\r\n[LOOKUP] No properties file of name 'commons-logging.properties' found\r\n....\r\nDiscovering a Log implementation...\r\n...\r\nLog adapter 'org.apache.commons.logging.impl.Log4JLogger' from classloader java.net.URLClassLoader@32689826 has been selected for use.\r\n</code></pre><br><br>Extract of a sample output (incorrect commons-logging.properties found):\r\n<pre><code>\r\n...\r\n[LogFactory from sun.misc.Launcher$AppClassLoader@934873913] [LOOKUP] Properties file found at 'jar:file:/myproject/lib/test/dbunit-embeddedderby-parenttest-sources.jar!/commons-logging.properties' with priority 0.0\r\n.. [LOOKUP] Properties file at 'file:/myproject/web/WEB-INF/classes/commons-logging.properties' with priority 0.0 does not override file at 'jar:file:/myproject/lib/test/dbunit-embeddedderby-parenttest-sources.jar!/commons-logging.properties' with priority 0.0\r\n.. [LOOKUP] Properties file of name 'commons-logging.properties' found at 'jar:file:/myproject/lib/test/dbunit-embeddedderby-parenttest-sources.jar!/commons-logging.properties&quot;\r\n.. Attempting to load user-specified log class 'org.apache.commons.logging.impl.SimpleLog'...\r\n.. Log adapter 'org.apache.commons.logging.impl.SimpleLog' from classloader sun.misc.Launcher$AppClassLoader@934873913 has been selected for use.\r\n...\r\n</code></pre><br><br>Notice that Commons Logging uses the context classloader and not e.g. Class.getClassloader() to locate the implementation to use, which may occassionally lead to some problems.<br><br>PS: You may be better of not using commons-logging because of its classloader issues. (SLF4J may be better?)\r\n<h3>Log4j</h3>\r\nSet the system property log4j.debug to true for Log4j to log the location of the configuration file it's using and other useful information. You can also set it in in the log4j.properties file:\r\n<pre>log4j.debug=true</pre>\r\nOr, as mentioned above, pass it as a system property to Java, for example as in\r\n<pre><code>java -Dlog4j.debug=true -jar YourApplication.jar</code></pre>\r\nThe debug information will be printed into the System.out, not in any log file you may have configured (Log4j can't use itself for this logging).<br><br>Example output:<br><br><pre><code>\r\nlog4j: Parsing for [root] with value=[INFO, CONSOLE, filelog].\r\nlog4j: Level token is [INFO].\r\nlog4j: Category root set to INFO\r\nlog4j: Parsing appender named &quot;CONSOLE&quot;.\r\nlog4j: Parsing layout options for &quot;CONSOLE&quot;.\r\nlog4j: Setting property [conversionPattern] to [%6rms [%p] ..%0.46c %x- %m%n].\r\nlog4j: End of parsing for &quot;CONSOLE&quot;.\r\nlog4j: Parsed &quot;CONSOLE&quot; options.\r\nlog4j: Parsing appender named &quot;filelog&quot;.\r\nlog4j: Parsing layout options for &quot;filelog&quot;.\r\nlog4j: Setting property [conversionPattern] to [%6rms [%p] ..%0.46c %x- %m%n].\r\nlog4j: End of parsing for &quot;filelog&quot;.\r\nlog4j: Setting property [file] to [/home/me/mylog.log].\r\nlog4j: Setting property [maxBackupIndex] to [5].\r\nlog4j: Setting property [maxFileSize] to [50MB].\r\nlog4j: setFile called: /home/me/mylog.log, true\r\nlog4j: setFile ended\r\nlog4j: Parsed &quot;filelog&quot; options.\r\nlog4j: Parsing for [eu.ibacz.lqs.uiradrupdater] with value=[DEBUG].\r\nlog4j: Level token is [DEBUG].\r\nlog4j: Category eu.ibacz.lqs.uiradrupdater set to DEBUG\r\nlog4j: Handling log4j.additivity.eu.ibacz.lqs.uiradrupdater=[null]\r\nlog4j: Finished configuring.\r\n</code></pre><br><br>For the log4j.properties:<br><br><pre><code>\r\nlog4j.rootCategory=INFO, CONSOLE, filelog<br><br>log4j.appender.CONSOLE=org.apache.log4j.ConsoleAppender\r\nlog4j.appender.CONSOLE.layout=org.apache.log4j.PatternLayout\r\nlog4j.appender.CONSOLE.layout.ConversionPattern=%6rms [%p] ..%0.46c %x- %m%n<br><br>log4j.appender.filelog=org.apache.log4j.RollingFileAppender\r\nlog4j.appender.filelog.File=${user.home}/mylog.log\r\nlog4j.appender.filelog.MaxFileSize=50MB\r\nlog4j.appender.filelog.MaxBackupIndex=5\r\nlog4j.appender.filelog.layout=org.apache.log4j.PatternLayout\r\nlog4j.appender.filelog.layout.ConversionPattern=%6rms [%p] ..%0.46c %x- %m%n<br><br>log4j.logger.eu.ibacz.lqs.uiradrupdater=DEBUG\r\n</code></pre>",
  "excerpt": ""
 },
 {
  "title": "Preview of the Portlets in Action book available",
  "published": "2009-11-07 04:40:24",
  "postType": "post",
  "slug": "/2009/11/07/preview-of-the-portlets-in-action/",
  "status": "publish",
  "tags": [],
  "categories": [
   "Portlets"
  ],
  "content": "<p>The book Portlets in Action being written by Ashish Sarin, which I've already mentioned and which looks really promising, has been made <a href=\"http://www.manning.com/sarin/\">available via the Manning Early Access</a> Program. As of today there are two chapters available and you can read the first one &quot;<a href=\"http://www.manning.com/sarin/Sarin_MEAP_Ch1.pdf\" target=\"_blank\">Introducing Portals and Portlets</a>&quot; for free.</p><p>What I find to be the most attractive features of this book is that it concentrates on the &quot;new&quot; JSR 286 also known as Portlets 2.0 and goes beyond teaching portlets with its intorduction of Spring MVC and Ajax libraries suitable for portlets.<br /></p>",
  "excerpt": ""
 },
 {
  "title": "PatternTesting: Automatically verifying the good application of architectural/design patterns in code",
  "published": "2009-09-25 04:53:00",
  "postType": "post",
  "slug": "/2009/09/25/patterntesting-automatically-verif/",
  "status": "publish",
  "tags": [
   "AOP",
   "architecture",
   "java",
   "patterns",
   "Testing"
  ],
  "categories": [
   "Languages",
   "Testing"
  ],
  "content": "<a href=\"http://patterntesting.sourceforge.net/\">PatternTesting</a> is a mature open-source project that enables you to automatically check at the compile- or run-time that architectural/design/implementation decisions are implemented and bad practices avoided in the code. The main differences from tools like FindBugs and PMD are that you can implement tests spanning multiple files (classes) and that aside of compile-time checks there are also run-time checks (using AOP with ApsectJ) to do things like \"ensuring that there are no more than 10 calls to the database per user case\" and providing better error messages in the case of e.g. IOException.<br><br>Read more in a The Server Side's <a href=\"http://www.theserverside.com/news/thread.tss?thread_id=25415\">introductory article</a> and on the <a href=\"http://patterntesting.sourceforge.net/09/doc/whatis.html\">project's page</a>.<br><br>I haven't yet the chance to try this out but it really intrigues me.",
  "excerpt": ""
 },
 {
  "title": "Injecting timing aspect into JUnit test in Eclipse using AspectJ, AJDT",
  "published": "2009-07-10 10:45:51",
  "postType": "post",
  "slug": "/2009/07/10/injecting-timing-aspect-into-junit/",
  "status": "publish",
  "tags": [
   "ajdt",
   "AOP",
   "AspectJ",
   "eclipse",
   "java",
   "junit"
  ],
  "categories": [
   "Languages"
  ],
  "content": "<h2>Introduction</h2>\r\nThis blog describes my experience with using <a href=\"http://en.wikipedia.org/wiki/Aspect-oriented_programming\">AOP</a>, namely AspectJ, to measure the individual execution times and their average of a particular low-level method invoked many times during a JUnit test run from within Eclipse. It concentrates on creating the aspect and integrating (weaving) it into the JUnit test execution in the Eclipse environment.<br><br>Of course it would be easier to use e.g. profiler but I wanted to play with AOP/AspectJ to learn it better because it's an incredibly useful tool for a number of problems and you can use it even if you don't have access to the application's source code and/or cannot control the runtime environment (such as running it in a profiler).\r\n<h3>Why AspectJ?</h3>\r\nThere are also other AOP tools for Java but it seems that AspectJ is the most wide-spread one, especially since its merge with AspectWerkz. I used to dislike it because it required a special extended Java syntax and compiler but this isn't true anymnore (more on that later).\r\n<h2>Disclaimer</h2>\r\nI'm only learning AspectJ, so the solution may be not and likely isn't the best one. I appreciate improvement suggestions.\r\n<h2>Preparing the environment</h2>\r\nI use <a href=\"http://www.poweredbypulse.com/\">Pulse</a> to set up my Eclipse environment. For this I'll use:\r\n<ul>\r\n\t<li>Eclipse 3.4 for Java EE (Pulse doesn't yet support 3.5)</li>\r\n\t<li>AJDT 2.0.0</li>\r\n\t<li>AspectJ 1.6.5</li>\r\n\t<li>JUnit 4</li>\r\n\t<li>JDK 1.5.0.18 (the test fails with 1.6 due to xml libs incompatibility) and Java 5.0 syntax</li>\r\n</ul>\r\n<h2>Implementing the timing aspect</h2>\r\nMy goal is to create an aspect invoked around the method in question that will measure the time it takes for the method to execute, log it, and compute and log the average execution time.<br><br>Since AspectJ 5 we have two options - either using the older custom AspectJ syntax with AspectJ compiler or using annotations. I'll explore both possibilities.\r\n<h3>Project structure</h3>\r\nFirst, we have a Java project with the junit test that we want to run with the timing aspect. It depends on another project with the actual class and method whose performance we want to measure.<br><br><strong>MyLibraryProject</strong>\r\n<ul>\r\n\t<li>/src/main/java/com/tonbeller/jpivot/xmla/XMLA_SOAP.java</li>\r\n</ul>\r\n<strong>MyTestProject</strong>\r\n<ul>\r\n\t<li>/src/main/java/\r\n<ul>\r\n\t<li>eu/ibacz/studna/jpivot/OLAPModelStructure.java\r\n- calls (indirectly) XMLA_SOAP.discoverMem during its execution</li>\r\n</ul>\r\n</li>\r\n\t<li>/src/test/java/\r\n<ul>\r\n\t<li>eu/ibacz/studna/jpivot/OLAPModelStructurePerformanceTest.java\r\n- standard JUnit4 test case</li>\r\n</ul>\r\n</li>\r\n</ul>\r\nWe create another project to hold our new shiny aspect: File &gt; New &gt; Other... &gt; AspectJ &gt; AspectJ Project =&gt;<br><br><strong>MyAspectProject</strong>\r\n<ul>\r\n\t<li>/src/\r\n<ul>\r\n\t<li>eu/ibacz/pbns/util/aspect/TimingAspect.aj (solution 1)</li>\r\n\t<li>eu/ibacz/pbns/util/aspect/TimingAnnotatedAspect.java (solution 2)</li>\r\n</ul>\r\n</li>\r\n</ul>\r\n<h3>Solution 1: using custom ApectJ syntax</h3>\r\nBefore AspectJ 5 this was the only option and it is still more powerful and has better support of AJDT (according to the <a href=\"http://www.eclipse.org/aspectj/doc/released/faq.php#q:codeversusannotationstyles\">FAQ</a>). Basically you write the aspect in an extended Java syntax in an .aj file and compile it with a special AspectJ compiler - though this is done behind the scene for you thanks to having created an AspectJ project, which also provides you with a special AspectJ/Java editor for .aj and .java aspect files.<br><br>Enough talking, let's see the aspect:<br><br>File<strong> eu/ibacz/pbns/util/aspect/TimingAspect.aj:</strong><br><br><pre><code>\r\npackage eu.ibacz.pbns.util.aspect;<br><br>import ...<br><br>public aspect TimingAspect {<br><br>    // instance/class field ...<br><br>    public TimingAspect() {\r\n        formatter = NumberFormat.getIntegerInstance();\r\n        formatter.setMinimumIntegerDigits(3);\r\n        System.out.println(getClass() + &quot; instantiated!&quot;);\r\n    }<br><br>//  before(): execution(public * com.tonbeller.jpivot..XMLA_SOAP.*(..) ) {\r\n//      System.err.println(&quot;About to call &quot; + thisJoinPoint.getSignature().toShortString() + &quot;, args:&quot; + Arrays.toString(thisJoinPoint.getArgs()) );\r\n//  }<br><br>    Object around() : execution( * com.tonbeller.jpivot..XMLA_SOAP.discoverMem(..) ) {<br><br>        final long startTimeCpuMs = getCurrentTimeMs();\r\n        final long startTimeMs = System.currentTimeMillis();<br><br>        Object result = proceed();<br><br>        final long endTimeMs = System.currentTimeMillis();\r\n        final long endTimeCpuMs = getCurrentTimeMs();<br><br>        final long execTimeMs = endTimeMs - startTimeMs;\r\n        final long execTimeCpuMs = endTimeCpuMs - startTimeCpuMs;<br><br>        ++totalExecutionCount;\r\n        totalExecutionTimeMs += execTimeMs;\r\n        totalCpuExecutionTimeMs += execTimeCpuMs;<br><br>        final String msg = &quot;executing discoverMem #&quot; + formatter.format(totalExecutionCount) +\r\n                &quot; took &quot; + execTimeCpuMs + &quot;ms of CPU, &quot; +\r\n                execTimeMs + &quot;ms real; current average is [ms/call]: &quot; +\r\n                totalCpuExecutionTimeMs / totalExecutionCount + &quot; for CPU, &quot; +\r\n                totalExecutionTimeMs / totalExecutionCount + &quot; real time.&quot;;\r\n        System.out.println(getClass().getName() + &quot;: &quot; + msg);<br><br>        return result;\r\n    }<br><br>}\r\n</code></pre><br><br>(I've ommited the fields and some methods for brevity.)<br><br>PS: You can use the commented-out before adivce to print all methods called on XMLA_SOAP including their name and arguments. This is useful to find out whether the method you're trying to measure is actually called at all.\r\n<h3>Solution 2: using annotation (@AspectJ)</h3>\r\nSince AspectJ 5 we can use a normal Java class with special annotations to define an aspect. It's less powerful (see above) but more familiar to a Java developer and more comfortable to use since it doesn't need any special compiler (the annotations are processed by AspectJ during weaving).<br><br>File <strong>eu/ibacz/pbns/util/aspect/TimingAnnotatedAspect.java</strong>:<br><br><pre><code>\r\npackage eu.ibacz.pbns.util.aspect;<br><br>import ...<br><br>public class TimingAnnotatedAspect {<br><br>    // instance/class field ...<br><br>    public TimingAspect() {\r\n        formatter = NumberFormat.getIntegerInstance();\r\n        formatter.setMinimumIntegerDigits(3);\r\n        System.out.println(getClass() + &quot; instantiated!&quot;);\r\n    }<br><br>    @Around(&quot;execution( * com.tonbeller.jpivot..XMLA_SOAP.discoverMem(..) )&quot;)\r\n    public Object around(ProceedingJointPoint pjp) {<br><br>        final long startTimeCpuMs = getCurrentTimeMs();\r\n        final long startTimeMs = System.currentTimeMillis();<br><br>        Object result = pjp.proceed();<br><br>        final long endTimeMs = System.currentTimeMillis();\r\n        final long endTimeCpuMs = getCurrentTimeMs();<br><br>        final long execTimeMs = endTimeMs - startTimeMs;\r\n        final long execTimeCpuMs = endTimeCpuMs - startTimeCpuMs;<br><br>        ++totalExecutionCount;\r\n        totalExecutionTimeMs += execTimeMs;\r\n        totalCpuExecutionTimeMs += execTimeCpuMs;<br><br>        final String msg = &quot;executing discoverMem #&quot; + formatter.format(totalExecutionCount) +\r\n                &quot; took &quot; + execTimeCpuMs + &quot;ms of CPU, &quot; +\r\n                execTimeMs + &quot;ms real; current average is [ms/call]: &quot; +\r\n                totalCpuExecutionTimeMs / totalExecutionCount + &quot; for CPU, &quot; +\r\n                totalExecutionTimeMs / totalExecutionCount + &quot; real time.&quot;;\r\n        System.out.println(getClass().getName() + &quot;: &quot; + msg);<br><br>        return result;\r\n    }<br><br>}</code></pre><br><br>As you can see, we've replaced the special AspectJ syntactical elements with annotationes @Aspect and @Around (there is also @Pointcut and others).<br><br>(I've ommited the fields and some methods for brevity.)\r\n<h3>Conclusion: Annotations vs. custom syntax</h3>\r\nWhen deciding\r\nwhether to use the the old custom AspectJ syntax and .aj files with an\r\nAspectJ compiler or the new annotation-based aspects in standard .java\r\nfiles you have to take into account that the annotation-based aspects\r\nare less powerful (regarding what all can be weaved) and have weaker\r\nsupport of the AJDT tooling so that your aspects may not display in its\r\nviews etc.\r\n<h3>Common project info</h3>\r\nFor both projects we need to have the class to modify with the aspect, in our case XMLA_SOAP, on the classpath, to get some special support from AJDT (see below).<br><br>The good thing when using AJDT is that if a pointcut definition (such as the execution(...) above) doesn't match an existing class/method, you will be warned about it - in Eclipse there will be the standard warning marker with text like \"<em>no match for this type name: XMLA_SOAP [Xlint:invalidAbsoluteTypeName]</em>\". This works both for .aj and .java files though it may not discover all issues.<br><br>The common code, if you're interested:<br><br><pre><code>\r\n    private ThreadMXBean threadMxb;<br><br>    /**\r\n     * Return the current time in miliseconds, if possible, return only the current thread's CPU time, if not,\r\n     * return system time.\r\n     * &lt;p&gt;\r\n     * thread's CPU time is usually few times less than the absolute time between\r\n     * its start and end due to the fact that it has to share the CPU with other processes/threads.\r\n     */\r\n    private long getCurrentTimeMs() {\r\n        return getThreadMxBean().isCurrentThreadCpuTimeSupported()?\r\n                threadMxb.getCurrentThreadCpuTime() / 1000000 : System.currentTimeMillis();<br><br>    }<br><br>    /** Lazy-init getter. */\r\n    private ThreadMXBean getThreadMxBean() {\r\n        if (threadMxb == null) {\r\n            threadMxb = ManagementFactory.getThreadMXBean();<br><br>            if (threadMxb.isThreadCpuTimeSupported()) {\r\n                LOG.info(&quot;Thread user/cpu time monitoring supported.&quot;);\r\n                if (threadMxb.isThreadCpuTimeSupported() &amp;amp;&amp;amp; threadMxb.isThreadCpuTimeEnabled()) {\r\n                        LOG.info(&quot;Thread user/cpu time monitoring supported&amp;amp;enabled.&quot;); // TODO do only once\r\n                } else {\r\n                    LOG.warn(&quot;Thread user/cpu time monitoring supported but disabled.&quot;);\r\n                }\r\n            } else {\r\n                LOG.warn(&quot;Thread user/cpu time monitoring NOT supported.&quot;);\r\n            } // supported thr. time\r\n        }<br><br>        return threadMxb;\r\n    } /* getThreadMxBean */\r\n</code></pre>\r\n<h2>Integrating the aspect into the JUnit test</h2>\r\nOur tracing aspect is ready and we want to apply it to XMLA_SOAP.discoverMem when running our JUnit test OLAPModelStructurePerformanceTest. Unfortunately AJDT doesn't provide any support for running JUnit tests with AspectJ support though it does that for normal java programs via the additional Run As... &gt; AspectJ/Java Application menu item therefore we will need to do it manually. Maybe there is a better way but this is what I did:\r\n<ol>\r\n\t<li>Get aspectjweaver.jar - it includes complete AspectJ runtime plus Java 5 agent lib.</li>\r\n\t<li>Modify the Run configuration of the JUnit test (Run &gt; Run Configurations) as follows:\r\n<ol>\r\n\t<li>On the tab Arguments, add the VM argument\r\n-javaagent:/path/to/aspectjweaver.jar</li>\r\n\t<li>On the tab Classpath, click on User Entries and add there the project MyAspectProject so that it can see the aspect.</li>\r\n</ol>\r\n</li>\r\n\t<li>In the project MyTestProject create under /src/test/java/ (or any other source folder) META-INF/aop.xml with the content shown below.</li>\r\n</ol>\r\nFile <strong>aop.xml</strong> :<br><br><pre><code>\r\n&lt;aspectj&gt;\r\n    &lt;aspects&gt;\r\n        &lt;!-- aspect name=&quot;eu.ibacz.pbns.util.aspect.TimingAspect&quot;/--&gt; &lt;!--  fails if not found --&gt;\r\n        &lt;aspect name=&quot;eu.ibacz.pbns.util.aspect.TimingAnnotatedAspect&quot;/&gt;\r\n    &lt;/aspects&gt;\r\n&lt;/aspectj&gt;\r\n</code></pre><br><br>This file tells AspectJ's Load-Time Weaver what aspects to introduce into the existing classes. Without it no instrumentation would occur. You can configure here which of the 2 aspects to use. You can also \"specify\r\nthe set of types that should be woven. If no include elements are specified\r\nthen all types visible to the weaver will be woven\". See the <a href=\"http://www.eclipse.org/aspectj/doc/next/devguide/ltw-configuration.html\">documentation on aop.xml</a> and Load-Time Weaving configuration for more info.\r\n<h2>Troubleshooting load-time weaving</h2>\r\nIf you need to learn more about what AspectJ does during the weaving and whether it does modify the target class or not (e.g. due to wrong pointcut match pattern or classpath order) you may enable some logging using either some properties on the command-line or by specifying this in the aop.xml:<br><br><pre><code>\r\n&lt;aspectj&gt;\r\n    &lt;aspects&gt;\r\n        &lt;!-- aspect name=&quot;eu.ibacz.pbns.util.aspect.TimingAspect&quot;/--&gt; &lt;!--  fails if not found --&gt;\r\n        &lt;aspect name=&quot;eu.ibacz.pbns.util.aspect.TimingAnnotatedAspect&quot;/&gt;\r\n    &lt;/aspects&gt;\r\n    &lt;weaver options=&quot;-verbose -showWeaveInfo &quot;&gt; &lt;!-- add -debug to print every class [not] woven  --&gt;\r\n        &lt;include within=&quot;com.tonbeller.jpivot.xmla..*&quot;/&gt; &lt;!-- Notice the 2 dots to include also subpackages --&gt;\r\n        &lt;include within=&quot;eu.ibacz..*&quot;/&gt;\r\n    &lt;/weaver&gt;\r\n&lt;/aspectj&gt;\r\n</code></pre><br><br>If the weaving proceeds as expected, this should produce an output similar to the one below:\r\n<pre>[AppClassLoader@1858610] info AspectJ Weaver Version DEVELOPMENT built on Friday Aug 29, 2008 at 00:25:33 GMT\r\n[AppClassLoader@1858610] info register classloader sun.misc.Launcher$AppClassLoader@1858610\r\n[AppClassLoader@1858610] info using configuration /home/jholy/devel/MyTestProject/target/classes/META-INF/aop.xml\r\n[AppClassLoader@1858610] info register aspect eu.ibacz.pbns.util.aspect.TimingAspect\r\n[AppClassLoader@1858610] info processing reweavable type com.tonbeller.jpivot.xmla.XMLA_Model: com/tonbeller/jpivot/xmla/XMLA_Model.java\r\n[AppClassLoader@1858610] info successfully verified type eu.ibacz.pbns.util.aspect.TimingAspect exists.\r\n  Originates from eu/ibacz/pbns/util/aspect//home/jholy/devel/MyAspectProject/src/eu/ibacz/pbns/util/aspect/TimingAspect.aj\r\n[AppClassLoader@1858610] weaveinfo Join point 'method-execution(void com.tonbeller.jpivot.xmla.XMLA_Model.retrieveMemberChildren(com.tonbeller.jpivot.xmla.XMLA_Member))'\r\n in Type 'com.tonbeller.jpivot.xmla.XMLA_Model' (XMLA_Model.java:1094) advised by around advice from 'eu.ibacz.pbns.util.aspect.TimingAspect' (TimingAspect.aj:56)</pre>\r\nThe line '<em>info register aspect eu.ibacz.pbns.util.aspect.TimingAspect</em>' tells us that AspectJ has found the aspect referenced from aop.xml. If the aspect class didn't exist then it would print an error message. The information about registered aspects, configuration aop.xml and AspectJ version is displayed thanks to the option -verbose.<br><br>The line '<em>weaveinfo Join point ...</em>' tells us that AspectJ has actually found and modified the target and is enabled with the -showWeaveInfo flag.<br><br>If you enabled -debug in aop.xml, AspectJ would print the list of classes that it has processed (whether there was an aspect to apply or not) - this can help you to verify that it doesn't ignore your target class.<br><br>Note: all weaver messages are prefixed with the classloader the weaver instance is attached to, e.g. in a web server you'd have multiple instances.\r\n<h2>Conclusion</h2>\r\nIt works! :-)\r\n<h3>Limitations of aop.xml</h3>\r\nAspectJ is extremely powerful, especially because it isn't limited to \"advicing\" or intercepting method calls but can also intercept field access, add fields, inject interface implementation into classes and much more.<br><br>What I find quite limiting is that in aop.xml you cannot specify very much what should or should not be woven, only the classes to include in/exclude from the process. If you want to limit to what methods etc. your apect applies, you have to change that in its source code and recompile it :-)\r\n<h2>Resources and links</h2>\r\n<ul>\r\n\t<li><a href=\"http://www.eclipse.org/aspectj/doc/released/quick5.pdf\">AspectJ Quick Reference</a> - pdf, 4 pages.</li>\r\n\t<li><a href=\"http://www.eclipse.org/aspectj/doc/released/progguide/semantics-pointcuts.html\">AspectJ: Semantics of pointcuts</a> - we need the Type patterns described close to the very end</li>\r\n</ul>\r\nOther\r\n<ul>\r\n\t<li><a href=\"http://www.irisa.fr/triskell/Softwares/protos/advicetracer/\">AdviceTracer</a> - JUnit extension for testing that advices get applied where they're expected to. An <a href=\"http://selab.csie.ntut.edu.tw/silder/81.pdf\">introductory presentation</a>.</li>\r\n</ul>",
  "excerpt": ""
 },
 {
  "title": "See how Test Driven Development is done in practice",
  "published": "2009-07-05 04:20:50",
  "postType": "post",
  "slug": "/2009/07/05/see-how-test-driven-development-is/",
  "status": "publish",
  "tags": [
   "book",
   "tdd",
   "Testing"
  ],
  "categories": [
   "Testing"
  ],
  "content": "On the Manning site you can read the 2nd chapter of the book Test Driven - Practical TDD and Acceptance TDD for Java Developers by Lasse Koskela from 2007. The <a href=\"http://www.manning-source.com/books/koskela/Chapter2Sample.pdf\">chapter 2: Beginning TDD</a> let's you follow the mental process of a programmer practicing TDD to implement a set of user stories. You've probably heard a lot about TDD on the theoretical level but this sample chapter gives you the unique opportunity to see the basic, practical level of TDD in action. I'm very glad to have read it.<br><br>The interesting thing is how he really always does the simplest possible solution (read 'dummy and 0% generic') to make the test pass and continuously adds tests and refactors the implementation to get the final code.",
  "excerpt": ""
 },
 {
  "title": "The quest for a portal web framework is over and the winner is: Spring Portlet MVC",
  "published": "2009-07-04 03:36:36",
  "postType": "post",
  "slug": "/2009/07/04/the-quest-for-a-portal-web-framewo/",
  "status": "publish",
  "tags": [],
  "categories": [
   "Portlets"
  ],
  "content": "<p>For a long time I've been looking for a web framework that would ease the development of web UI in portlets. Pure JSP is too old-fashioned and the abstraction it provides is just too low-level. There are many good web frameworks for standard web applications (JSF/Seam, GWT, Struts 2, Wicket, you name it...) but if they include portlet support than only as an after-thought and it's usually far behind the quality and features of the standard web framework. Nobody was able to recommend me a decent portlet web framework - until recently.</p><p>&nbsp;First I've learned about an upcoming book Portlets in Action (<a href=\"http://www.manning.com/sarin/\">preview</a>) by Ashish Sarin, which teaches not only Portlets 2.0 (JSR 286) but also other must-haves for a real world development like a portlet web framework and Ajax (DWR in this case). You've surely already guessed that Ashish uses Spring Portlet MVC, which indicates that it must be indeed good.</p><p>Than I've been surprised to learn that my good and trustworthy collegue, <a href=\"http://www.linkedin.com/in/vladimirschreiner\">Vlado</a>, is using Spring Portlet MVC on his project. He had but positive words about the framework: &quot;<i>It's excellent, I wouldn't make portlets with anything else. It's enough lightweight, it helps where it should and doesn't limit you anyhow.</i>&quot;</p><p>The only issue is that the current stable release doesn't support JSR286 yet (events, resource serving...). Fortunately the upcoming release of Spring 3.0 will support it. Spring 3.0 <a href=\"http://blog.springsource.com/2009/05/06/spring-framework-30-m3-released/\">M3 have been released in May</a> 2009 (more <a href=\"http://blog.springsource.com/2009/02/25/spring-framework-30-m2-released/\">about Portlet 2.0 support</a> on M2 release page), RC1 should have been released in June. You can learn about details in the <a href=\"http://jira.springframework.org/browse/SPR-4259\">corresponding Jira issue</a>.</p><p><b>Update 2/2010</b>:&nbsp; Liferay uses quite a lot Struts to build its portlets, for instance when developing a portlet as an EXT plugin (not recommanded), you can only use Struts, so Struts is surely a viable alternative. There is a <a href=\"http://www.liferay.com/community/forums/-/message_boards/message/3409471?_19_threadView=flat\">discussion of Spring vs. Struts</a> at Liferay forums (6/2009).<br /></p><h4>Resources</h4><ul><li>Liferay wiki:<br /></li><ul><li><a href=\"http://www.liferay.com/web/guest/community/wiki/-/wiki/Main/Spring-Hibernate-DWR\">Spring-Hibernate-DWR</a> - Integrating Spring MVC Portlet 3.0 M2, Hibernate 3.3.1 GA, DWR 3 RC1 and Liferay 5.2.2</li><li><a href=\"http://www.liferay.com/web/guest/community/wiki/-/wiki/Main/Sample+Spring+Portlet\">Sample Spring Portlet</a> <br /></li></ul></ul>",
  "excerpt": ""
 },
 {
  "title": "Released DbUnit Test Skeleton 1.0.0 - setup DbUnit test w/ embedded DB in few minutes",
  "published": "2009-06-14 08:06:50",
  "postType": "post",
  "slug": "/2009/06/14/released-dbunit-test-skeleton-1-0/",
  "status": "publish",
  "tags": [
   "java"
  ],
  "categories": [
   "Languages"
  ],
  "content": "<p id=\"tochome4\">I've just released a little open-source project <a href=\"http://jeeutils.wiki.sourceforge.net/DbUnit+Test+Skeleton\" title=\"DbUnit Test Skeleton home page\">DbUnit Test Skeleton 1.0.0</a>. <br /></p>\nCreating a a <a rel=\"nofollow\" href=\"http://www.dbunit.org/\" class=\"wiki_link_ext\">DbUnit</a>\ntest case may be time consuming. With this project you can have your\nDbUnit test including an embedded database with structures and data\nready in a few minutes. (At least if you are fast enough in writing SQL\nand preparing your data :-) ).<br />\n<br />\nThis project helps you to setup a DbUnit test using an embedded Derby database by providing<br /><br><br><ol><li>An <a rel=\"nofollow\" href=\"http://jeeutils.svn.sourceforge.net/viewvc/jeeutils/trunk/DbUnitTestSkeleton/src/main/java/net/jakubholy/testing/dbunit/embeddeddb/AbstractEmbeddedDbTestCase.java?view=markup\" class=\"wiki_link_ext\">AbstractEmbeddedDbTestCase.java</a>, which creates a connection to the database, sets some useful defaults, and provides improved error reporting,</li><li>The utility <a rel=\"nofollow\" href=\"http://jeeutils.svn.sourceforge.net/viewvc/jeeutils/trunk/DbUnitTestSkeleton/src/main/java/net/jakubholy/testing/dbunit/embeddeddb/DatabaseCreator.java?view=markup\" class=\"wiki_link_ext\">DatabaseCreator.java</a> for creating and initializing the embedded DB based on a .ddl file,</li><li>Sample <a rel=\"nofollow\" href=\"http://jeeutils.svn.sourceforge.net/viewvc/jeeutils/trunk/DbUnitTestSkeleton/testData/create_db_content.ddl?view=markup\" class=\"wiki_link_ext\">create_db_content.ddl</a> and <a rel=\"nofollow\" href=\"http://jeeutils.svn.sourceforge.net/viewvc/jeeutils/trunk/DbUnitTestSkeleton/testData/dbunit-test_data_set.xml?view=markup\" class=\"wiki_link_ext\">dbunit-test_data_set.xml</a> for creating the database and filling it with test data,</li><li>Instructions for using them.</li></ol><br><br>Everything is well commented (I hope) to help you to start using it quickly.<br />\n<br />\nMore details including examples and some useful links to related utilities on yhe <a href=\"http://jeeutils.wiki.sourceforge.net/DbUnit+Test+Skeleton\" class=\"wiki_link\">DbUnit Test Skeleton</a> page.",
  "excerpt": ""
 },
 {
  "title": "A logging wrapper around PreparedStatement to provide detailed info upon error",
  "published": "2009-05-23 12:41:58",
  "postType": "post",
  "slug": "/2009/05/23/a-logging-wrapper-around-prepareds/",
  "status": "publish",
  "tags": [
   "error",
   "java",
   "jdbc",
   "logging",
   "statement"
  ],
  "categories": [
   "Languages"
  ],
  "content": "<p>In my java web application I use JDBC to store data in batches into a database. When there is a problem the whole batch insert fails and it's difficult to find out what data caused it to fail. Therefore I've created a wrapper around PreparedStatement that remembers values passed into the various set* methods and can provide a comma-separated listing of all rows in the batch upon failure. </p><p>This is my LoggingStatementDecorator that stores values for later logging; based on java.lang.reflect.Proxy:</p><br><br><pre><code>\r\npackage eu.ibacz.example;<br><br>import java.lang.reflect.InvocationHandler;\r\nimport java.lang.reflect.InvocationTargetException;\r\nimport java.lang.reflect.Method;\r\nimport java.lang.reflect.Proxy;\r\nimport java.sql.PreparedStatement;\r\nimport java.util.LinkedList;\r\nimport java.util.List;<br><br>/**\r\n * Remember values passed into a sql statement via setString etc. for later logging. \r\n */\r\nclass LoggingStatementDecorator implements InvocationHandler {\r\n    \r\n    /** File's Subversion info (version etc.). */\r\n    public static final String SVN_ID = &quot;$id$&quot;;\r\n    \r\n    private List&lt;List&lt;Object&gt;&gt; batch = new LinkedList&lt;List&lt;Object&gt;&gt;();\r\n    private List&lt;Object&gt; currentRow = new LinkedList&lt;Object&gt;();\r\n    private PreparedStatement target;\r\n    private boolean failed = false;\r\n    \r\n    public LoggingStatementDecorator(PreparedStatement target) {\r\n        if (target == null) throw new IllegalArgumentException(&quot;'target' can't be null.&quot;);\r\n        this.target = target;\r\n    }<br><br>\r\n     // @see java.lang.reflect.InvocationHandler#invoke(java.lang.Object, java.lang.reflect.Method, java.lang.Object[]) */\r\n    public Object invoke(Object proxy, Method method, Object[] args)\r\n            throws Throwable {\r\n        \r\n        final Object result; \r\n        \r\n        try {\r\n            result = method.invoke(target, args);\r\n            failed = false;\r\n        } catch (InvocationTargetException e) {\r\n            failed = true;\r\n            throw e.getTargetException();\r\n        } catch (Exception e) {\r\n            failed = true;\r\n            throw e;\r\n        }\r\n        \r\n        if ( method.getName().startsWith(&quot;setNull&quot;) \r\n                &amp;&amp; (args.length &gt;=1 &amp;&amp; Integer.TYPE == method.getParameterTypes()[0] ) ) {\r\n            handleSetSomething((Integer) args[0], null);\r\n        } else if ( method.getName().startsWith(&quot;set&quot;) \r\n                &amp;&amp; (args.length &gt;=2 &amp;&amp; Integer.TYPE == method.getParameterTypes()[0] ) ) {\r\n            handleSetSomething((Integer) args[0], args[1]);\r\n        } else if (&quot;addBatch&quot;.equals(method.getName())) {\r\n            handleAddBatch();\r\n        }\r\n        \r\n        return result;\r\n    }\r\n    \r\n    private void handleSetSomething(int index, Object value) {\r\n        currentRow.add(value);\r\n    }\r\n    \r\n    private void handleAddBatch() {\r\n        batch.add(currentRow);\r\n        currentRow = new LinkedList&lt;Object&gt;();\r\n    }\r\n    \r\n    public List&lt;List&lt;Object&gt;&gt; getValues() {\r\n        return batch;\r\n    }\r\n    \r\n    public PreparedStatement getTarget() { return target; }\r\n    \r\n    /** Has the last method called on the Statement caused an exception? */\r\n    public boolean isFailed() { return failed; }\r\n    \r\n    public String toString() { return &quot;LoggingHandler[failed=&quot;+failed+&quot;]&quot;; }\r\n    \r\n    /** Values as comma-separated values. */\r\n    public String getValuesAsCsv() {\r\n        StringBuilder csv = new StringBuilder();\r\n        for (List&lt;Object&gt; row : getValues()) {\r\n            for (Object field : row) {\r\n                // Escape Strings\r\n                if (field instanceof String) {\r\n                    field = &quot;'&quot; + ((String) field).replaceAll(&quot;'&quot;, &quot;''&quot;) + &quot;'&quot;;\r\n                }\r\n                csv.append(field).append(&quot;,&quot;);\r\n            }\r\n            csv.append(&quot;\\n&quot;);\r\n        }\r\n        return csv.toString();\r\n    } /* getValuesAsCsv */\r\n    \r\n    public PreparedStatement createProxy() {\r\n        return (PreparedStatement) Proxy.newProxyInstance(\r\n                PreparedStatement.class.getClassLoader(),\r\n                new Class[] { PreparedStatement.class },\r\n                this);\r\n    };\r\n    \r\n}\r\n</code></pre><br><br><p>And this is how you use it:</p><br><br>\r\n<pre><code>\r\n        // ...\r\n        PreparedStatement stmt = null;\r\n        try {\r\n            LoggingStatementDecorator stmtHandler = new LoggingStatementDecorator( connection.prepareStatement(&quot;insert into mytable values(?,?)&quot;) );\r\n            stmt =  stmtHandler.createProxy();\r\n            \r\n            // add data to the batch\r\n            for(int i=0; i&lt;10; ++i) {\r\n                stmt.setInt(1, i);\r\n                stmt.setString(2, &quot;Row number &quot; + i);\r\n                stmt.addBatch();\r\n            }\r\n            \r\n            stmt.executeBatch();\r\n            \r\n        } catch (SQLException e) {\r\n            // ... some rollback etc.\r\n            \r\n            LoggingStatementDecorator stmtHandler = (LoggingStatementDecorator)\r\n                    ((stmt instanceof Proxy)? Proxy.getInvocationHandler(stmt) : null);\r\n                // TODO include the insert sql in the log!!!\r\n                StringBuilder log = new StringBuilder();\r\n                log = buildFailureInfo(&quot;mytable&quot;, stmtHandler, log);\r\n                LOG.error(&quot;Failure while processing data:&quot; + log, e);\r\n            }\r\n        }\r\n            <br><br>    private StringBuilder buildFailureInfo(String table, LoggingStatementDecorator stmtHandler, StringBuilder details) {\r\n        \r\n        if (stmtHandler != null &amp;&amp; stmtHandler.isFailed()) {\r\n            // Already insertion of records failed\r\n            details.append(&quot;\\nInsert of records failed. Table=&quot;).append(table)\r\n                .append(&quot;), values=[\\n&quot;).append(stmtHandler.getValuesAsCsv()).append(&quot;]&quot;);\r\n            \r\n        }\r\n        \r\n        return details;\r\n    } /* buildFailureInfo */\r\n</code></pre><br><br><p>When an excepion occures, you get nice log that shall tell you all you need to detect the problem or reproduce it.</p><p>Fotnote: Of course I could have perhaps used the open-source <a href=\"http://www.p6spy.com/\">P6Spy</a> but I'm afraid it would log more than I need (I believe it to be bound to a data source, not a particular webapp's PreparedStatement).<br /></p>",
  "excerpt": ""
 },
 {
  "title": "A new release 0.30 of MiniPauker, a J2ME flashcard learning application",
  "published": "2009-05-23 12:17:20",
  "postType": "post",
  "slug": "/2009/05/23/a-new-release-0-30-of-minipauker-a/",
  "status": "publish",
  "tags": [
   "java"
  ],
  "categories": [
   "Languages"
  ],
  "content": "<p>I've just released <a href=\"https://sourceforge.net/project/platformdownload.php?group_id=159194\">MiniPauker v0.30</a>, a J2ME application for learning vocabulary etc.<br /></p><p><i>MiniPauker is like <a href=\"http://pauker.sf.net/\">Pauker</a> a generic flashcard learning\nprogram, but written in J2ME for the use with mobile devices which\nsupport J2ME with MIDP2 and JSR-75. MiniPauker is compatible with\nPauker (import/export).</i></p><p>What's new:<br /></p><p>\n</p><ul><li>Added &quot;repeat new&quot;, i.e. repeat unlearned cards = card's you haven't learned using the application. Good if you have actually learned them elsewhere as I often do.</li><li>Used often with &quot;repeat new&quot;, you can select in the preferences that you want the cards to be presented in a random order rather than always in the same (usually alphabetical) one.</li><li>Support for reading files on Siemens mobiles that don't support the FileConnection API but have their custom file access. The file must be named lessons.pau.gz and be stored in the top folder.</li><li>If your mobile doesn't support file access, you can embed a lesson file directly in the application.</li><li>Added help with detailed instructions for various functions of the app.</li><li>Hopefully an improvement of keys allocation so it should be easier to use the app.</li><li>Reading of stored session loads first 100 cards and then continues in the background (loading in chunks of 100 ) so that you can start working with those loaded so far. Good for slow phones like Siemens CX65, Siemens ME75. You can check the progress in main menu &gt; statistics.</li></ul>MiniPauker has been originally and mostly developed by Markus Brosch.<br /><pre><br /></pre>",
  "excerpt": ""
 },
 {
  "title": "Lotus Notes 8.x under Linux: No window shows up, Tips for upgrading to LN8.5",
  "published": "2009-04-30 09:05:02",
  "postType": "post",
  "slug": "/2009/04/30/lotus-notes-8-x-under-linux-no-win/",
  "status": "publish",
  "tags": [],
  "categories": [
   "Tools"
  ],
  "content": "<p>Since recently when I started Lotus Notes 8.0.2 as another user via sudo, it has started with the splash screen, asked for a password nad displayed a progress bar but as soon as the startup finished and the splash screen disappeared it hasn't open the main window. The process was running but there was no visible manifestation of it.</p><p>After a long time and an upgrade to LN 8.5 I've figured out that perhaps there was something wrong with the configuration. The reason to think so is that LN8.5 exhibited exactly the same problem but for all users. Later I've discovered that there were some configuration files like /etc/notes/ and /etc/ibm-hannover.conf left from the previous version though I uninstalled it (maybe these aren't created during the installation but during first startup). After their deletion and LN8.5 reinstall it more less started to work.</p><h3>Upgrading Lotus Notes 8.0.2 to 8.5 <br /></h3><p>Based on my experience I'd recommand the following steps when upgading 8.0.2 to 8.5:</p><ol><li>Uninstall LN 8.0.2 (I installed mine from .deb packages created by converting .rpm packages by alien).<br /></li><li>Remove&nbsp;  /etc/notes/ and /etc/ibm-hannover.conf.</li><li>Move $HOME/lotus/ somewhere else so that when you run LN for the 1st time it works in a clean environment. You can move it back when you get LN working.</li><li>Install LN8.5 - now there are .deb packages. You will need to install ibm_lotus_notes-8.5.i586.deb first for the others depend on it.</li><ul><li>Some people recommend to change /bin/sh to point to /bin/bash. That's a good idea also for other IBM software, for instance I was long unable to install Rational Software Developer 7.x for a mysterious problem caused by having /bin/sh pointing to dash (a bash-like thing used by default under Ubuntu).</li><li>Some people recommend installing additional fonts otherwise LN may use just one ugly font.<br /></li></ul><li>Start it by running /opt/ibm/lotus/notes/notes from the command line.<br /></li><ol><li>It should print some output and after a while open a new terminal window with license. Scroll till its end using Enters, accept by typing 1 [Enter].</li><ul><li>Maybe it isn't necessary to go to the license's end but once I've accepted it already when it opened but it somehow hasn't worked out.<br /></li><li>Under Xfce the license window hasn't opened. Switching to Gnome fixed the problem. If you try to run notes again, it will print some logs and end, close to its end you could see the warning that the license hasn't been accepted.</li><li>You may need to try several times to get the license window. But be patient, it takes the installer few (10s of) seconds to open it.<br /></li></ul><li>LN finishes without actually doing something. You need to run it again (/opt/ibm/lotus/notes/note) to actually start it. (Still it sometimes happens to me that running it does nothing and I have to run it again.) It should open the new user dialog. Give it what it wants to get the main window open.</li></ol><li>Close LN. Now you've verified that it does indeed run.<br /></li><li>Move the newly created $HOME/lotus/ somewhere and move (or copy) back your original mail file.</li><li>Start LN. Again you will be asked for a license confirmation (since you have a new lotus folder, it doesn't rember you accepting it already) etc.<br /></li></ol><h3>My environment</h3><ul><li>Ubuntu 9.0.4 (recently upgraded from 8.0.4 when the problem first appeared).</li><li>LN 8.5</li></ul><h3>Resources</h3><ul><li>Official docs: <a href=\"http://www-01.ibm.com/support/docview.wss?rs=475&amp;uid=swg27013074#Linux85standard\">LN8.5 SW/HW requirements</a><br /></li><li>Official docs: <a href=\"http://publib.boulder.ibm.com/infocenter/domhelp/v8r0/index.jsp?topic=/com.ibm.help.domino.admin85.doc/DOC/H_CONSIDERATIONS_BEFORE_INSTALLING_LINUX_7218_OVER.html\">Considerations before installing Notes on Linux</a><br /></li><li><a href=\"http://www-10.lotus.com/ldd/nd8forum.nsf/5f27803bba85d8e285256bf10054620d/f683185b98129dd7852572ea001db523?OpenDocument\">LN8 beta3: Step by step from initial Ubuntu Feisty install</a> (may contain some useful info also for 8.5 and Ubuntu 9.0.4)<br /></li></ul>",
  "excerpt": ""
 },
 {
  "title": "How I managed to deploy a JSF/Seam portlet to JBoss after all",
  "published": "2009-04-20 11:15:34",
  "postType": "post",
  "slug": "/2009/04/20/how-i-managed-to-deploy-a-jsfseam/",
  "status": "publish",
  "tags": [
   "deploy",
   "eclipse",
   "java",
   "jboss",
   "jsf",
   "jsr168",
   "jsr286",
   "Maven",
   "portal",
   "portlet",
   "seam"
  ],
  "categories": [
   "Portlets"
  ],
  "content": "Deploying a custom JSF/Seam portlet to JBoss Portal Server isn't as easy as you'd expect, either manually or using Eclipse with JBoss Tools. I'll share with you what I learned about this.\r\n<h2>Introduction</h2>\r\nSee the previous <a href=\"http://www.jroller.com/holy/entry/seam_tutorial_1_1_richfaces\">Seam Tutorial 1.1</a> and <a href=\"http://www.jroller.com/holy/entry/seam_tutorial_1_2_richfaces\">1.2</a> to learn what SW versions I use, how to configure a server in Eclipse etc. The issues with JBoss Tools, JBoss Portal, and Seam/RichFaces depend pretty much on their respective version and can change significantly even with a minor version change.<br><br>Including:\r\n<ul>\r\n\t<li>jboss-portlet-bridge-1.0.0.B6</li>\r\n</ul>\r\nIn the blog <a href=\"http://blog.jboss-portal.org/2008/08/jboss-portlet-support-in-eclipse.html\">JBoss Portlet support in Eclipse</a> you may learn more about creating portlets for JBoss in Eclipse and issues with various versions of JBoss Tools.\r\n<h2>Deploying a portlet via Maven 2</h2>\r\nJBoss provides Maven archetypes for creating Seam portlets and also tasks for deploying them to a portal server, either an existing one or a newly downloaded one. This is described in the development guide but not sufficiently.<br><br>Note: You need maven 2.0.9 or higher.\r\n<ol>\r\n\t<li><span style=\"font-family:monospace;\">run$ mkdir /tmp/jboss; cd /tmp/jboss</span></li>\r\n\t<li><span style=\"font-family:monospace;\">run$ mvn archetype:generate\r\n-DarchetypeGroupId=org.jboss.portletbridge.archetypes\r\n-DarchetypeArtifactId=seam-basic\r\n-DarchetypeVersion=1.0.0.B6\r\n-DgroupId=eu.ibacz.seamtutorial2\r\n-DartifactId=seamproject\r\n-DarchetypeRepository=http://repository.jboss.org/maven2/\r\n</span>\r\n(accept all defaults)</li>\r\n\t<li><span style=\"font-family:monospace;\">cd /tmp/jbossrun/seamproject</span></li>\r\n\t<li>edit /tmp/jboss/seamproject/web/pom.xml\r\n<ul>\r\n\t<li>Running mvn install would fail because of missing org.jboss.portletbridge:portletbridge-api:jar:1.0-SNAPSHOT for  eu.ibacz.seamtutorial2.web:seamproject:war:1.0-SNAPSHOT.</li>\r\n\t<li>=&gt; replace &lt;version&gt;${project.version}&lt;/version&gt; with &lt;version&gt;${portletbridge.version}&lt;/version&gt; for artifactId portletbridge-api in /tmp/jboss/seamproject/web/pom.xml</li>\r\n</ul>\r\n</li>\r\n\t<li><span style=\"font-family:monospace;\">run$  mvn install</span>\r\nThis will create a WAR package and install it into the local maven repository.</li>\r\n\t<li><span style=\"font-family:monospace;\">run$ cd /tmp/jboss/seamproject/ear</span></li>\r\n\t<li><span style=\"font-family:monospace;\">run$  mvn -Plocal-portal cargo:start</span>\r\nThis uses the Maven plugin cargo to start a local JBoss Portal. It must be run from the ear/ folder because ear/pom.xml defines the necessary settings.</li>\r\n\t<li>Set the JDK to use if needed - JBoss requires JRE 1.5. and has troubles under 1.6. You may define the JRE to use by adding a property like\r\n<pre>&lt;cargo.java.home&gt;/path/to/jdk1.5.0_17/jre&lt;/cargo.java.home&gt;</pre>\r\nto the other cargo properties in ear/pom.xml\r\nIndication of the problem: an error like below in jboss startup log:\r\n<em>[INFO] [talledLocalContainer] Caused by: java.lang.UnsupportedOperationException: setProperty must be overridden by all subclasses of SOAPMessage</em>\r\n- Strangely jboss still reports jre 1.6 after setting this property but the error disappears:\r\n<em> [INFO] [talledLocalContainer] 10:14:54,415 INFO  [ServerInfo] Java version: 1.6.0_07,Sun Microsystems Inc.</em><br><br>Output:\r\n[INFO] [cargo:start]\r\n[INFO] [talledLocalContainer] Parsed JBoss version = [4.2.3]\r\n[INFO] [talledLocalContainer] JBoss 4.2.3 starting...\r\n...\r\n[INFO] [talledLocalContainer] 10:01:34,211 INFO  [Server] JBoss (MX MicroKernel) [4.2.3.GA (build: SVNTag=JBoss_4_2_3_GA date=200807181417)] Started in 2m:34s:75ms</li>\r\n\t<li>(in new window) run$ mvn cargo:deploy -Plocal-portal\r\n<pre>[INFO] [cargo:deploy]\r\n[INFO] [talledLocalContainer] Parsed JBoss version = [4.2.3]\r\n[INFO] [stalledLocalDeployer] Deploying [/POWEROLAP/jboss/seamproject/ear/target/seamproject-1.0-SNAPSHOT.ear] to [/POWEROLAP/jboss/seamproject/ear/target/installs/jboss-portal-2.7.0.GA-bundled/jboss-portal-2.7.0.GA/server/default/deploy]...\r\n(Some related logs are added also to the window where we started jboss.)</pre>\r\n</li>\r\n\t<li>Go to http://localhost:8080/portal You should see a tab called \"seamproject\" in the portal.</li>\r\n</ol>\r\nThe bug report <a href=\"http://www.jboss.org/community/docs/DOC-13317\">DOC-13317</a> describes the shortcomings of the documentation for this.\r\n<h2>Manual deployement of a Seam portlet created with Eclipse/JBoss Tools</h2>\r\nHow to create a Seam portlet in Eclipse with JBoss Tools and deploy it to JBoss Portal.\r\n<h3>Create a new Seam portlet project</h3>\r\nNote&gt; There are multiple ways to create a Seam Portlet project.<br><br>New &gt; Project &gt; Dynamic Web Project &gt;\r\n<ol>\r\n\t<li>Page Dynamic Web Project:\r\n<ul>\r\n\t<li>Target runtime: jboss 4.3.2 portal 2.7.1,</li>\r\n\t<li>Dynamic Web Module version: 2.5</li>\r\n\t<li>Configuration \"JBoss Seam Portlet  Project v2.0\"; if you haven't it on the selection list, click [Modify...] and select the facets Seam, JBoss Portlets and all under it (JBoss Core Portlet, JBoss JSF Portlet, JBoss Seam Portlet), Java, Dynamic Web Module.</li>\r\n\t<li>Click Next &gt;</li>\r\n</ul>\r\n</li>\r\n\t<li>Page Web Modules: keep the defaults.</li>\r\n\t<li>Page JBoss Portlet Capabilities: keep the defaults (Enable implementation library, Libraries provided by server runtime).</li>\r\n\t<li>Page JSF Capabilities: keep the defaults (Server supplied JSF implementation, ...).</li>\r\n\t<li>Page Seam Facet: set the Seam runtime and Database as we did in the other projects of <strong>my Seam/RichFaces tutorials (TODO link)</strong>.</li>\r\n\t<li>Page JBoss Portlet Capabilities: Portletbridge Runtime: select e.g. jboss-portal-2.7.1/server/default/deploy/jboss-portal.sar/lib .</li>\r\n</ol>\r\n<h3>Add a portlet to the project</h3>\r\nNew &gt; Other... &gt; JBoss Tools Web &gt; Portlet &gt; JBoss JSF/Seam Portlet (there is also a plain Java Portlet).<br><br>Accept all defaults. This will create a portlet called seamPortlet that will display the page home.xhtrml.\r\n<h3>Deploy the portlet</h3>\r\nOne we have created s Seam portlet we would like to be able to deploy it to JBoss Portal. Here we will learn how to deploy it manually, that means by exporting it from Eclipse as a WAR file and installing that to the server. If you try that you will fail. Below I describe the necessary steps to get the exported WAR working under JBoss.<br><br>By comparing the SeamBooking example portlet that you can find in the portlet bridge download package and my Seam portlet exported from Eclipse I've discovered the following  differences.\r\n<ul>\r\n\t<li>SeamBooking's META-INF/ contains a persistence.xml (likely some JPA stuff).</li>\r\n\t<li>SeamBooking's jboss-portlet.xml defines links to 2 RichFaces JavaScript files and 1 CSS file.</li>\r\n\t<li>SeamBooking's jboss-object.xml has the property theme.renderSetId=emptyRenderer .</li>\r\n\t<li>My portlet exported from Eclipse contains many libraries in WEB-INF/lib/ but not e.g. any portletbridge stuff.</li>\r\n</ul>\r\nDeploy the exporeted WAR to JBoss and start it.<br><br>Attempt I - failure:\r\n<ol>\r\n\t<li>Missing portletbridge class:\r\n<pre>Cause: Unable to find class 'org.jboss.portletbridge.application.PortletViewHandler'</pre>\r\n&amp;l\r\nt;li&gt;Missing datasource.</li>\r\n</ol>\r\nSolution:\r\n<ol>\r\n\t<li>Copy portletbridge-impl.jar and portletbridge-api.jar to the WAR's WEB-INF/lib/.</li>\r\n\t<li>Copy\r\n/resources/*-ds.xml to deploy/.</li>\r\n</ol>\r\nAttempt II - failure:\r\n<pre>ERROR [LifeCycle] Cannot start objectorg.jboss.portal.portlet.container.PortletInitializationException: The portlet seamPortlet threw a runtime exception during init\r\nCaused by: java.lang.ClassCastException: javax.portlet.faces.GenericFacesPortlet cannot be cast to javax.portlet.Portlet\r\n    at org.jboss.portal.portlet.impl.jsr168.PortletContainerImpl.start(PortletContainerImpl.java:254)</pre>\r\nSolution: Remove all portal*, portlet*.jar including portlet-api.jar (contains javax.portlet.Portlet.class), excluding. portletbridge.<br><br>Attempt III - portlet running:<br><br>No there are no more exceptions and when JBoss Portal starts, you will see there the tab \"seamPortlet\" with your portlet.<br><br>However when you go to the tab to see your portlet there will be another exception:\r\n<pre>ERROR [InternalPortletContentProvider] Portlet invoker exception during portlet window renderingorg.jboss.portal.portlet.PortletInvokerException: javax.servlet.ServletException\r\nCaused by: java.lang.NoSuchMethodError: org.ajax4jsf.context.ViewResources.processHeadResources(Ljavax/faces/context/FacesContext;)V\r\n</pre>\r\nSolution: Replace libs with richfaces-api-3.3.0.GA.jar richfaces-impl-3.3.0.GA.jar richfaces-ui-3.3.0.GA.jar<br><br><strong>Attempt VI - everything finally works</strong>.\r\n<h2>Seam portlet deployment from Eclipse with JBoss Tools</h2>\r\nThis is something I haven't managed so far :-(",
  "excerpt": ""
 },
 {
  "title": "Developing portlets for Liferay in Eclipse",
  "published": "2009-04-20 00:00:00",
  "postType": "post",
  "slug": "/2009/04/20/developing-portlets-for-liferay-in/",
  "status": "publish",
  "tags": [
   "jsr168",
   "jsr286",
   "Liferay",
   "portlet"
  ],
  "categories": [
   "eclipse",
   "Portlets"
  ],
  "content": "In this blog I'd like to tell you how to use Eclipse with Liferay to develop portlets with the ability to change a class or a JSP in Eclipse and have that immediatelly reflected on the server (hot deployment).\r\n<h2>Environment</h2>\r\n<ul>\r\n\t<li>Liferay Portal 5.2.2 running on Tomcat 5.5.27.</li>\r\n\t<li>Eclipse IDE for Java EE Developers, version Ganymede 3.4.1.</li>\r\n\t<li>(optional) Eclipse Maven plugin m2eclipse 0.9.6.</li>\r\n</ul>\r\n<h2>A note about Eclipse and Maven projects</h2>\r\nMy web project is actually also a Maven project because we use Maven for building our projects. That means that it has a specific directory structure (src/main/webapp, target/classes, etc.) and that it includes a pom.xml that defines its dependencies on other artifacts, usually JAR libraries. Thanks to the m2eclipse plugin, Eclipse is aware of these dependencies and makes them available to the project during development and deployment.<br><br>With the m2eclipse plugin you get the nice feature that if your web application project depends on an artifact produced from another Eclipse project then if you change something in this project you depend upon, Eclipse detect it and pushes the change to the web application deployed on a server.<br><br>Normally with maven alone you would need to run mvn install or mvn package on the library project and either copy the produced .jar manually to the deployed webapp's WEB-INF/lib or do a full rebuild (mvn package) and redeploy of the web app.\r\n<h2>Preparing the portlet project for hot deployment to Liferay</h2>\r\nNormally you deploy a WAR with portlets by putting them in the Liferay's hot deploy directory (&lt;liferay&gt;/deploy). It notices that, processes the WAR, and deploys it to Tomcat. However since Eclipse knows nothing about Liferay and can only deploy to Tomcat itself in the normal way, that means by copying the exploded WAR to &lt;liferay&gt;/tomcat-5.5.27/webapps/, we need to do the Liferay's modifications by ourselves and also modify the way that Eclipse does the deployment. Liferay does monitor Tomcat's webapps/ directory and will detect a change to an application and redeploy it however this deployment doesn't include all the operations that are performed when deploying via its hot deploy directory.\r\n<h3>Configuring Eclipse</h3>\r\n<h4>1. Define a Server Runtime Environment for Liferay</h4>\r\n<ol>\r\n\t<li>Window &gt; Preferences &gt; Server &gt; Runtime Environments &gt; Add... .</li>\r\n\t<li>Select Apache Tomcat 5.5.</li>\r\n\t<li>For the Tomcat installation directory browse to or type &lt;liferay&gt;/tomcat-5.5.27 (replace &lt;liferay&gt; with you liferay installation directory, of course).</li>\r\n\t<li>Name it e.g. \"Liferay 5.2.2@Tomcat 5.5.27\".</li>\r\n</ol>\r\n<h4>2. Define a Server instance for Liferay</h4>\r\n<ol>\r\n\t<li>Window &gt; Show View &gt; Other... &gt; Server &gt; Servers.</li>\r\n\t<li>Right-click somewhere in the view Servers &gt; New &gt; Server:\r\n<ul>\r\n\t<li>Server type Tomcat v5.5 Server.</li>\r\n\t<li>Server runtime environment: select the one defined in the previous step (Liferay 5.2.2@Tomcat 5.5.27).</li>\r\n</ul>\r\n</li>\r\n</ol>\r\n<h4>3. Adjust the server's configuration</h4>\r\nIn the view Servers, double-click on the newly created server, which will open its configuration. Do the following modifications:\r\n<ul>\r\n\t<li>In Server Locations change \"<span style=\"text-decoration:line-through;\">Use workspace metadata</span>\" to \"Use Tomcat installation\".\r\n<ul>\r\n\t<li>Notice: If you have any projects deployed to the server, this section is greyed-out and cannot be edited. Remove all projects from the server, publish, perhaps restart and you should be able to modify this settings.</li>\r\n</ul>\r\n</li>\r\n\t<li>In Server Locations change Deploy path from <span style=\"text-decoration:line-through;\">wtpwebapps</span> to webapps. (Maybe this isn't necessary but I wanted to be sure I won't create any troubles for the Liferay's monitoring.)</li>\r\n\t<li>In Timeouts perhaps increase the Start timeout to some period long enough, e.g. 300 s. (My Liferay usually starts in ~ 70s but once it took over 200 s.)</li>\r\n\t<li>During server startup, if you get<br><br>Exception in thread \"main\" java.lang.OutOfMemoryError: PermGen space<br><br>then click Open launch configuration in the server's configuration and add something like <kbd>-XX:MaxPermSize=128m</kbd> to Arguments &gt; VM arguments.</li>\r\n</ul>\r\nNow you should be able to run the server, deploy your portlet webapp to it (view Servers &gt; right-clik the server &gt; Add and Remove Projects ...) and see your portlets in the Liferay portal (login, Add application &gt; find it under the category you've defined in your liferay-display.xml &gt; add it to a page).<br><br>When you deployed the application to the server, you should have been able to see in the log (i.e. in the Eclipse's Console view) that Liferay has detected it and deployed the portlets. There should be a line like<br><br>INFO [PortletHotDeployListener:303] 1 portlets for &lt;your webapp's name&gt; are available for use<br><br>telling you that your portlet is deployed and ready to use.\r\n<h3>Adjusting the portlet project</h3>\r\nWhen you add you portlet to a portal page, you will be most likely surprised to see there\r\nThe requested resource (/example-portlet/MyPortlet/invoke) is not available.\r\ninstead of the expected portlet content. (Of course it will differ if your project/webapp context root isn't example-portlet and the portlet's name isn't MyPortlet.)<br><br>Google won't reveal any solution but I'll will :-). Try to deploy the application first from Eclipse (which you've just done) and then in the regular way by exporting it as a WAR file from Eclipse and putting it into &lt;liferay&gt;/deploy/ and waiting for Liferay to pick it up and deploy it to Tomcat. Then compare the two resulting directories from Tomcat's webapps/ folder. Thus you will learn what you will need to modify. Or simply keep on reading :).\r\n<h4>Adjust web.xml</h4>\r\nLiferay needs to have a servlet defined for each portlet. The error above (<em>The requested resource (/example-portlet/MyPortlet/invoke) is not available.</em>) indicates that a servlet MyPortlet is missing. So we will add it together with the proper servlet mapping:<br><br><strong>web.xml modification:</strong>\r\n<pre>&lt;servlet&gt;\r\n        &lt;servlet-name&gt;MyPortlet&lt;/servlet-name&gt;\r\n        &lt;servlet-class&gt;com.liferay.portal.kernel.servlet.PortletServlet&lt;/servlet-class&gt;\r\n        &lt;init-param&gt;\r\n            &lt;param-name&gt;portlet-class&lt;/param-name&gt;\r\n            &lt;param-value&gt;eu.ibacz.example.MyPortlet&lt;/param-value&gt; &lt;!--replace with your portlet class --&gt;\r\n        &lt;/init-param&gt;\r\n        &lt;load-on-startup&gt;0&lt;/load-on-startup&gt;\r\n    &lt;/servlet&gt;\r\n        ....\r\n    &lt;servlet-mapping&gt;\r\n        &lt;servlet-name&gt;MyPortlet&lt;/servlet-name&gt;\r\n        &lt;url-pattern&gt;/MyPortlet/*&lt;/url-pattern&gt;\r\n    &lt;/servlet-mapping&gt;\r\n</pre>\r\n<h4>Add portlet TLD</h4>\r\nWe will likely (though I'm not 100% sure about this) need to replicate yet another change done by Liferay and that is adding it's TLD for portlet 2.0 and a link for it to web.xml. Liferay adds taglibs also for all its other taglibs but I suppose you don't need them. (I suppose you develop a JSR 286 portlet but you could do the same for a JSR 168 portlet by using its specific uri and tld file.)<br><br>1. Copy liferay-portlet.tld to WEB-INF/tld/liferay-portlet.tld. Get it from the Liferay-deployed WAR or find in somewhere under &lt;liferay&gt;.<br><br>2. Add a taglib declaration to <strong>web.xml</strong>:\r\n<pre>        &lt;taglib&gt;\r\n            &lt;taglib-uri&gt;http://java.sun.com/portlet_2_0&lt;/taglib-uri&gt;\r\n            &lt;taglib-location&gt;/WEB-INF/tld/liferay-portlet.tld&lt;/taglib-location&gt;\r\n        &lt;/taglib&gt;</pre>\r\n<h4>Adding Liferay libs</h4>\r\nYou will likely need to add at least the Liferay library\r\n&lt;liferay&gt;/tomcat-6.0.18/webapps/ROOT/WEB-INF/lib/util-taglib.jar\r\nto your projet's WEB-INF/lib. If you ommit that you may, when accessing the portlet, get for example one of the following errors:\r\n<pre> <span style=\"font-size:small;\"><span style=\"color:#000000;\">javax.portlet.PortletException: javax.servlet.ServletException: java.lang.NoClassDefFoundError: com/liferay/taglib/portlet/DefineObjectsTag</span></span></pre>\r\n<pre>JasperException: Impossible de charger ou d'instancier la classe TagExtraInfo: com.liferay.taglib.portlet.ActionURLTei</pre>\r\n<h4>That's all, folks!</h4>\r\nThat's all! Your portlet should work now (tough Eclipse may require Tomcat restart for that). Enjoy!\r\n<h2>About the portlet project</h2>\r\nSelected files of the project's WAR:\r\n<ul>\r\n\t<li>WEB-INF/\r\n<ul>\r\n\t<li>lib/\r\n<ul>\r\n\t<li>util-taglib.jar</li>\r\n</ul>\r\n</li>\r\n\t<li>tld/\r\n<ul>\r\n\t<li>liferay-portlet.tld</li>\r\n</ul>\r\n</li>\r\n\t<li>classes/\r\n<ul>\r\n\t<li>eu.ibacz.example.MyPortlet.class</li>\r\n</ul>\r\n</li>\r\n\t<li>liferay-display.xml</li>\r\n\t<li>liferay-plugin-package.properties</li>\r\n\t<li>liferay-portlet.xml</li>\r\n\t<li>portlet.xml</li>\r\n\t<li>web.xml</li>\r\n</ul>\r\n</li>\r\n\t<li>myPortlet_view.jsp</li>\r\n</ul>\r\n<strong>eu/ibacz/example/MyPortlet.java</strong>:\r\n<pre><code>\r\npackage eu.ibacz.example;<br><br>import java.io.IOException;\r\nimport javax.portlet.*;<br><br>public class MyPortlet extends GenericPortlet {\r\n\t\r\n\t@Override\r\n\tprotected void doView(RenderRequest request, RenderResponse response)\r\n\t\t\tthrows PortletException, IOException {\t\t<br><br>\t\tPortletRequestDispatcher dispatcher = getPortletConfig().getPortletContext().getRequestDispatcher(\r\n\t\t\t\t&quot;/myPortlet_view.jsp&quot;);\r\n\t\tif (dispatcher != null) {\r\n\t\t\t//dispatcher.forward(request, response); // this displays an empty page instead of the JSP?!\r\n\t\t\tdispatcher.include(request, response);\t// this works\r\n\t\t} else {\r\n\t\t\tthrow new IllegalStateException(&quot;Failed to get a PortletRequestDispatcher, can't forward to the JSP&quot;);\r\n\t\t}\r\n\t}\r\n}\r\n</code></pre>\r\n<strong>liferay-display.xml</strong>:\r\n<pre>&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;!DOCTYPE display PUBLIC \"-//Liferay//DTD Display 5.2.0//EN\" \"http://www.liferay.com/dtd/liferay-display_5_2_0.dtd\"&gt;\r\n&lt;display&gt;\r\n  &lt;category name=\"My Experiments\"&gt;\r\n    &lt;portlet id=\"MyPortlet\"&gt;My Test Portlet&lt;/portlet&gt;\r\n  &lt;/category&gt;\r\n&lt;/display&gt;</pre>\r\n<strong>liferay-plugin-package.properties</strong> (I suppose this actually isn't need or could be empty):\r\n<pre>portal.dependency.jars=commons-logging.jartags=portlet</pre>\r\n<strong>liferay-portlet.xml</strong>:\r\n<pre>&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;\r\n&lt;!DOCTYPE liferay-portlet-app PUBLIC &quot;-//Liferay//DTD Portlet Application 5.2.0//EN&quot; &quot;http://www.liferay.com/dtd/liferay-portlet-app_5_2_0.dtd&quot;&gt;\r\n&lt;liferay-portlet-app&gt;\r\n       \r\n    &lt;portlet&gt;\r\n        &lt;portlet-name&gt;MyPortlet&lt;/portlet-name&gt;\r\n        &lt;instanceable&gt;true&lt;/instanceable&gt;\r\n    &lt;/portlet&gt;\r\n    \r\n    &lt;role-mapper&gt;\r\n        &lt;role-name&gt;administrator&lt;/role-name&gt;\r\n        &lt;role-link&gt;Administrator&lt;/role-link&gt;\r\n    &lt;/role-mapper&gt;\r\n    &lt;role-mapper&gt;\r\n        &lt;role-name&gt;guest&lt;/role-name&gt;\r\n        &lt;role-link&gt;Guest&lt;/role-link&gt;\r\n    &lt;/role-mapper&gt;\r\n    &lt;role-mapper&gt;\r\n        &lt;role-name&gt;power-user&lt;/role-name&gt;\r\n        &lt;role-link&gt;Power User&lt;/role-link&gt;\r\n    &lt;/role-mapper&gt;\r\n    &lt;role-mapper&gt;\r\n        &lt;role-name&gt;user&lt;/role-name&gt;\r\n        &lt;role-link&gt;User&lt;/role-link&gt;\r\n    &lt;/role-mapper&gt;\r\n    \r\n&lt;/liferay-portlet-app&gt;</pre>\r\n<strong>portlet.xml</strong>:\r\n<pre>&lt;?xml version='1.0' encoding='UTF-8' ?&gt;\r\n&lt;portlet-app xmlns='http://java.sun.com/xml/ns/portlet/portlet-app_2_0.xsd' xmlns:xsi='http://www.w3.org/2001/XMLSchema-instance' xsi:schemaLocation='http://java.sun.com/xml/ns/portlet/portlet-app_2_0.xsd http://java.sun.com/xml/ns/portlet/portlet-app_2_0.xsd' version='2.0'&gt;    \r\n    \r\n    &lt;portlet&gt;\r\n        &lt;description&gt;&lt;/description&gt;\r\n        &lt;portlet-name&gt;MyPortlet&lt;/portlet-name&gt;\r\n        &lt;display-name&gt;MyPortlet&lt;/display-name&gt;\r\n        &lt;portlet-class&gt;eu.ibacz.example.MyPortlet&lt;/portlet-class&gt;        \r\n        &lt;expiration-cache&gt;0&lt;/expiration-cache&gt;\r\n        &lt;supports&gt;\r\n            &lt;mime-type&gt;text/html&lt;/mime-type&gt;\r\n            &lt;portlet-mode&gt;VIEW&lt;/portlet-mode&gt;\r\n        &lt;/supports&gt;\r\n        &lt;portlet-info&gt;\r\n            &lt;title&gt;MyPortlet&lt;/title&gt;\r\n            &lt;short-title&gt;MyPortlet&lt;/short-title&gt;\r\n        &lt;/portlet-info&gt;\r\n    &lt;/portlet&gt;\r\n    \r\n&lt;/portlet-app&gt;</pre>\r\n<strong>web.xml</strong>:\r\n<pre>&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;<br><br>&lt;web-app id=&quot;WebApp_ID&quot; version=&quot;2.4&quot; xmlns=&quot;http://java.sun.com/xml/ns/j2ee&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://java.sun.com/xml/ns/j2ee http://java.sun.com/xml/ns/j2ee/web-app_2_4.xsd&quot;&gt;\r\n    &lt;display-name&gt;My Test Portlet Webapp&lt;/display-name&gt;\r\n    &lt;description/&gt;\r\n    <br><br>    &lt;servlet&gt;\r\n        &lt;servlet-name&gt;JHPokusy&lt;/servlet-name&gt;\r\n        &lt;servlet-class&gt;com.liferay.portal.kernel.servlet.PortletServlet&lt;/servlet-class&gt;\r\n        &lt;init-param&gt;\r\n            &lt;param-name&gt;portlet-class&lt;/param-name&gt;\r\n            &lt;param-value&gt;eu.ibacz.studna.PokusnyPortlet&lt;/param-value&gt;\r\n        &lt;/init-param&gt;\r\n        &lt;load-on-startup&gt;0&lt;/load-on-startup&gt;\r\n    &lt;/servlet&gt;\r\n        \r\n    &lt;servlet-mapping&gt;\r\n        &lt;servlet-name&gt;JHPokusy&lt;/servlet-name&gt;\r\n        &lt;url-pattern&gt;/JHPokusy/*&lt;/url-pattern&gt;\r\n    &lt;/servlet-mapping&gt;\r\n    \r\n    &lt;session-config&gt;\r\n        &lt;session-timeout&gt;30&lt;/session-timeout&gt;\r\n    &lt;/session-config&gt;\r\n    &lt;welcome-file-list&gt;\r\n        &lt;welcome-file&gt;index.jsp&lt;/welcome-file&gt;\r\n    &lt;/welcome-file-list&gt;<br><br>    &lt;jsp-config&gt;                \r\n        &lt;taglib&gt;\r\n            &lt;taglib-uri&gt;http://java.sun.com/portlet_2_0&lt;/taglib-uri&gt;\r\n            &lt;taglib-location&gt;/WEB-INF/tld/liferay-portlet.tld&lt;/taglib-location&gt;\r\n        &lt;/taglib&gt;\r\n   &lt;/jsp-config&gt;<br><br>&lt;/web-app&gt;</pre>\r\n<strong>myPortlet_view.jsp</strong>:\r\n<pre>&lt;%@ page language=\"java\" contentType=\"text/html; charset=UTF-8\"    pageEncoding=\"UTF-8\"%&gt;<br><br>&lt;h1&gt;MyPortlet is alive!&lt;/h1&gt;</pre>\r\n<h2>Known issues</h2>\r\n<h3>Omission of .properties during deploy</h3>\r\nSometimes Eclipse omits to copy .properties files to the server. I don't know whether it's Eclipse problem or my Eclipse Maven plugin problem. I don't know why because .settings/org.eclipse.wst.common.component does contain &lt;wb-resource deploy-path=\"/WEB-INF/classes\" source-path=\"/src/main/resources\"/&gt;. I've open the bug report <a href=\"http://jira.codehaus.org/browse/MECLIPSE-556\">MECLIPSE-556</a> regarding this.\r\n<h3>Enforcing a particular JDK version</h3>\r\nIf you use the maven enforcer plugin to enforce a particular version of Java, like this:\r\n<pre>&lt;plugin&gt;\r\n\t\t&lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;\r\n\t\t&lt;artifactId&gt;maven-enforcer-plugin&lt;/artifactId&gt;\r\n\t\t&lt;configuration&gt;\r\n\t\t\t\t&lt;rules&gt;                                                \r\n\t\t\t\t\t\t&lt;requireJavaVersion&gt;\r\n\t\t\t\t\t\t\t\t&lt;version&gt;[1.5,1.6)&lt;/version&gt;\r\n\t\t\t\t\t\t\t\t&lt;message&gt;...&lt;/message&gt;\r\n\t\t\t\t\t\t&lt;/requireJavaVersion&gt;\r\n\t\t\t\t&lt;/rules&gt;\r\n\t\t&lt;/configuration&gt;\r\n\t\t&lt;executions&gt;\r\n\t\t\t\t&lt;execution&gt;\r\n\t\t\t\t\t\t&lt;id&gt;enforce-versions&lt;/id&gt;\r\n\t\t\t\t\t\t&lt;goals&gt;\r\n\t\t\t\t\t\t\t\t&lt;goal&gt;enforce&lt;/goal&gt;\r\n\t\t\t\t\t\t&lt;/goals&gt;\r\n\t\t\t\t&lt;/execution&gt;\r\n\t\t&lt;/executions&gt;\r\n&lt;/plugin&gt;</pre>\r\nthen you may have troubles building your Maven project with Eclipse if running Eclipse under another JVM version. For example my default system JVM used also for Eclipse is 1.6 but for a particular project I need 1.5. When you try to build the project, it will fail with\r\n<pre>Build errors for jpivot-portlet-liferay-classes; org.apache.maven.lifecycle.LifecycleExecutionException:\r\n Internal error in the plugin manager executing goal 'org.apache.maven.plugins:maven-enforcer-plugin:1.0-beta-1:enforce':\r\n Mojo execution failed.</pre>\r\nI've tried the following to force Maven to use JVM 1.5 for building the project:\r\n<ol>\r\n\t<li>Set the JRE System Library in Project - Properties - Java Build Path - Libraries.</li>\r\n\t<li>Set the Eclipse's command line option -vm to point to the desired JVM in eclipse.ini:\r\n<pre>-vm /usr/lib/jvm/java-1.5.0-sun</pre>\r\n</li>\r\n\t<li>Set JAVA_HOME to point to the desired JVM prior to starting Eclipse:\r\n<pre>bash$ export JAVA_HOME=\"/usr/lib/jvm/java-1.5.0-sun/jre\"bash$ ./eclipse</pre>\r\n</li>\r\n\t<li><strong>Setting PATH to point to 1.5 JVM prior to startin Eclipse</strong>:\r\n<pre>bash$ export PATH=\"/usr/lib/jvm/java-1.5.0-sun/bin:$PATH\"bash$ ./eclipse</pre>\r\n</li>\r\n</ol>\r\nOf those only nr. 4, setting the PATH, had the desired effect of running Eclipse and thus also the Maven build under the required JVM 1.5. The conclusion is that you must run Eclipse using the same JVM you want to use for Maven builds.<br><br>There is the bug report <a href=\"http://jira.codehaus.org/browse/MNGECLIPSE-1091\">MNGECLIPSE-1091</a> regarding this problem with many votes but no resolution or workaround.\r\n<h3>Why not to use m2eclipse</h3>\r\nA nice post (6/2009) lists some <a href=\"http://twasink.net/blog/2009/06/m2eclipse-plugin-is-not-for-me/\">reasons why not to use m2eclipse</a> for Maven-Eclipse integration:\r\n<ol>\r\n\t<li>No real support for separate output folder.</li>\r\n\t<li>It uses the Maven Embedder, which is not Maven but more of an experiment.</li>\r\n\t<li>It wants to use the JDK associated with the JRE that launched Eclipse.</li>\r\n</ol>\r\nAccording to Brian Fox, the upcoming M2e 0.9.9 should address this issues.<br><br>Another reader , Benedikt, recommends solutions:\r\n<ol>\r\n\t<li>Of course you can change the output-folder by modifying your pom.xml to have separate output-folders for your class-files.</li>\r\n\t<li>You can tell the plugin which maven installation it should use and it doesn’t break anything if you do so.</li>\r\n\t<li>If you don’t use the internal maven builder then maven will use the JRE configured under “Installed JREs”.</li>\r\n</ol>\r\nSo maybe its usable after all? Or you may also give try to <a href=\"http://eclipse.org/iam\">Eclipse IAM</a> (former Q4E), the new Maven-Eclipse integration, currently v. 0.1.0. It seems to be yet no as mature as m2eclipse, see a <a href=\"http://docs.codehaus.org/display/MAVENUSER/Eclipse+Integration\">comparison</a>.\r\n<h2>Additional notes</h2>\r\n<strong> </strong>You may want to follow the instructions on Liferay site and <a href=\"http://www.liferay.com/web/guest/community/wiki/-/wiki/Main/Liferay+Developer+Mode\">use Liferay in a development mode</a> by using special portal.properties that prevent some caching etc. (Add -Dexternal-properties=$CATALINA_BASE/webapps/ROOT/WEB-INF/classes/portal-developer.properties to &lt;liferay&gt;/tomcat-5.5.27/bin/catalina.sh.)<br><br>You may also want to try to install JBoss Tools into your Eclipse and use its Servers view, which also supports Tomcat and may be better than the standard one.<br><br>Another interesting SW - <a href=\"https://eclipse-portalpack.dev.java.net/\">Eclipse Portal Pack</a> for developing JSR168 and JSR286 portlets with Eclipse, currently v2.0M1.\r\n<h2>An alternative: the Liferay way</h2>\r\nThe upcoming book <a href=\"http://www.manning.com/sezov/\">Liferay in Action</a> by R. Sezov describes how to set up portlet development environment for Liferay 6 using either Eclipse or NetBeans in its chapter two. He recommands to create and deploy a portlet using the Ant-based Liferay Plugins SDK and use an IDE only to import and develop the portlet while invoking ant deploy for the deployment. I don't know wheter that supports hot deployment of only changed files (provided that it matters at all) and of course it has a completely different structer than Maven assumes, complicating if not rendering it impossible to use Maven.",
  "excerpt": ""
 },
 {
  "title": "Using ScribeFire to publish to JRoller.com",
  "published": "2009-04-20 01:13:14",
  "postType": "post",
  "slug": "/2009/04/20/using-scribefire-to-publish-to-jro/",
  "status": "publish",
  "tags": [],
  "categories": [
   "Tools"
  ],
  "content": "<p>To get the Firefox extension ScribeFire (v.3.2.3) to publish to jroller.com you may set you account as follows:</p><ol><li>Address of you blog: e.g. http://jroller.com/page/holy</li><li>Blog system: MetaWeblog API (though there is also en experimental support of Roller)</li><ul><li>Of course you must first allow the MetaWeblog API in your blog's settings<br /></li></ul><li>URL of API server: http://www.jroller.com/roller-services/xmlrpc <br /></li><li>The username and password you use to log in to JRoller.</li></ol>I wish this was documented somewhere in the official JRoller documentation (is there any?!) so that I wouldn't need to aste my time trying to figure it out.<br /><br />Actually using ScribeFire 3.2.3 may not be such a good idea after all. I've just found it has some nasty problems with not escaping and un-escaping &lt; and &gt; (at least inside &lt;pre&gt;) and doesn't really understand that &lt;p&gt; should be closed when a &lt;h2&gt; is created :-(<br />",
  "excerpt": ""
 },
 {
  "title": "[DRAFT] Maven \"change\" project extending a non-maven web project",
  "published": "2009-04-10 05:01:06",
  "postType": "post",
  "slug": "/2009/04/10/draft-maven-change-project-extendi/",
  "status": "publish",
  "tags": [],
  "categories": [
   "Tools"
  ],
  "content": "<p><i>Disclaimer: I'm rather new to Maven and thus my solution is likely not the best one. I welcome any improvement suggestions.&nbsp;</i> <br /></p><p>My current project here at IBA CZ extends a legacy non-maven web project and I had to devise how to organize the extension modules and other new modules depending upon them. The final goal was to create a portlet face for this servlet-only web application that is written in JSP and a strange presentation framework and then create specific portlets for specific needs.<br /></p><p>Key factors and motivations:</p><ol><li>The source WAR project is not under our control.</li><li>The source WAR project has been imported into an external maven repository but only with a minimal Maven POM without any definitions of dependencies etc.</li><li>I need to extend this WAR to work in our specific environment (Liferay portal) and to satisfy our specific requirements, which will require some but hopefully not many modifications of its source codes and other resources.<br /></li><li>I want to be able to migrate my changes easily to a new version of the source WAR.</li><li>I want to use Maven because its our preferred build tool, integrates well with our Continuous Integration (CI) server (Hudson), and - last but not least - handles dependencies so that I can execute <i>svn co http://ibacz.eu/my/project &amp;&amp; cd project &amp;&amp; mvn package</i> to build a working, deployable package.<br /></li></ol>My idea was to create only a &quot;change&quot; project, which would only include our changes to the original WAR (additions/deletions/modifications) and merge it with the original project fetched from its maven repository to create a final deployable artifact. Then I'd create other artifacts depending on this.<br /><br><br><h2>The source artifacts</h2><br><br><p>As I've said, the source application - jpivot.war - is maven agnostic but is imported into an external Maven repository (http://repository.pentaho.org/artifactory/).<br /></p><br><br><h3>Web app artifact: jpivot.war </h3>\n<p>The web application that we want to customize. It doesn't include any classes directly - they're in WEB-INF/lib/jpivot.jar.</p><p>Its pom.xml: <br /></p><br><br><pre>&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project&gt;<br />  &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;<br />  &lt;groupId&gt;com.tonbeller&lt;/groupId&gt;<br />  &lt;artifactId&gt;jpivot&lt;/artifactId&gt;<br />  &lt;packaging&gt;war&lt;/packaging&gt;<br />  &lt;version&gt;1.8.0-081008&lt;/version&gt;<br />  &lt;description&gt;Auto generated POM&lt;/description&gt;<br />&lt;/project&gt;</pre><br><br><h3>Classes artifact: jpivot.jar</h3>\n<p>The same jar as in&nbsp; jpivot.war/WEB-INF/lib/jpivot.jar but as a standalone maven artifact, also without any dependencies definitions. Its pom.xml:<br /></p><br><br><pre>&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project&gt;<br />  &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;<br />  &lt;groupId&gt;com.tonbeller&lt;/groupId&gt;<br />  &lt;artifactId&gt;jpivot&lt;/artifactId&gt;<br />  &lt;version&gt;1.8.0-081008&lt;/version&gt;<br />  &lt;description&gt;Auto generated POM&lt;/description&gt;<br />&lt;/project&gt;</pre><br><br><h3>Handling dependencies:  jpivot-libs-combined.jar</h3>\n<p>For compilation and comfortable development of our change and other projects we will certainly need the source project's dependencies. Unfortunately they're not listed in its maven POM and it would be a tedious task to do that. Also we do not control the WAR's POM and it's likely that some of the dependencies also aren't mavenized, which gives us a nice recursive trouble.<br /></p><p>Therefore I'll go for the simplest solution and combine all libraries' classes from jpivot.war/WEB-INF/lib/*.jar excluding jpivot.jar (for it has already its own imported maven artifact) into a single &quot;uberjar&quot; jpivot-libs-combined.jar and deploy it to the company-wide thirdparty maven repository.</p><br><br><p>An Ant build.xml that merges all JARs except of jpivot.jar from the working directory together:<br /></p><br><br><pre><code>&lt;?xml version=&quot;1.0&quot; encoding=&quot;ISO-8859-1&quot;?&gt;<br />&lt;project name=&quot;jpivot-libs-combined&quot; default=&quot;combine&quot; basedir=&quot;.&quot;&gt;<br />  &lt;target name=&quot;combine&quot;&gt;<br />        &lt;zip destfile=&quot;jpivot-libs-combined.jar&quot;&gt;<br />                &lt;zipgroupfileset dir=&quot;.&quot; includes=&quot;*.jar&quot; excludes=&quot;jpivot.jar&quot;/&gt;<br />                &lt;fileset dir=&quot;.&quot; excludes=&quot;*.jar&quot;/&gt;<br />        &lt;/zip&gt;<br />  &lt;/target&gt;<br />&lt;/project&gt;</code></pre><br><br><p>A pom.xml that shall be included with the combined JAR:<br /></p><br><br><pre><code>&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project&gt;<br />  &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;<br />  &lt;groupId&gt;com.tonbeller&lt;/groupId&gt;<br />  &lt;artifactId&gt;jpivot-libs-combined&lt;/artifactId&gt;<br />  &lt;version&gt;1.8.0-081008&lt;/version&gt;<br />  &lt;dependencies&gt;<br />    &lt;dependency&gt;<br />        &lt;!-- Dummy dependency to show what has this been generated from --&gt;<br />        &lt;groupId&gt;com.tonbeller&lt;/groupId&gt;<br />        &lt;artifactId&gt;jpivot&lt;/artifactId&gt;<br />        &lt;version&gt;1.8.0-081008&lt;/version&gt;<br />        &lt;type&gt;war&lt;/type&gt;<br />        &lt;scope&gt;provided&lt;/scope&gt;<br />        &lt;optional&gt;true&lt;/optional&gt;<br />    &lt;/dependency&gt;<br />  &lt;/dependencies&gt;<br />  &lt;description&gt;<br />  Dependencies extraced from jpivot.war/WEB-INF/lib (excluding jpivot.jar that already has a maven artefact) and merged into a single .jar.<br />  &lt;/description&gt;<br />&lt;/project&gt;</code></pre><br><br><p>Commands to create the uberjar and install it into a maven repository:</p><pre>/tmp$ unzip /path/to/jpivot.war WEB-INF/lib<br />/tmp$ ant -f /path/to/the/build.xml<br />/tmp$ mvn install:install-file -Dfile=jpivot-libs-combined.jar -DgroupId=com.tonbeller -DartifactId=jpivot-libs-combined -Dversion=1.8.0-081008 -Dpackaging=jar -DgeneratePom=true<br /><br /></pre><p>Now we should deploy the artifact to the company-wide Maven repository for thirdparty stuff and replace the pom.xml generated by the install command with the one provided above.</p><br><br><h2>Our artifacts</h2><p>Finally the artifacts that we do develop. </p><br><br><h3>A root POM</h3><p>I like a parent POM for my artifacts that defines common configuration including properties, repositories and SW versions.</p>\n<pre><code>\n&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;\n    xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd&quot;&gt;\n    &lt;parent&gt;\n        &lt;artifactId&gt;ibacz-root-pom&lt;/artifactId&gt;\n        &lt;groupId&gt;eu.ibacz.maven&lt;/groupId&gt;\n        &lt;version&gt;1.1&lt;/version&gt;\n    &lt;/parent&gt;\n    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;<br><br>    &lt;groupId&gt;eu.ibacz.pbns&lt;/groupId&gt;\n    &lt;artifactId&gt;pbns-root-pom&lt;/artifactId&gt;\n    &lt;packaging&gt;pom&lt;/packaging&gt;\n    &lt;name&gt;PBNS - Root project&lt;/name&gt;\n    &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt;\n    &lt;description/&gt;<br><br>    &lt;build&gt;\n        &lt;plugins&gt;\n            &lt;plugin&gt;\n                &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt;\n                &lt;configuration&gt;\n                    &lt;source&gt;1.5&lt;/source&gt;\n                    &lt;target&gt;1.5&lt;/target&gt;\n                &lt;/configuration&gt;\n            &lt;/plugin&gt;\n            &lt;plugin&gt;\n                &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;\n                &lt;artifactId&gt;maven-enforcer-plugin&lt;/artifactId&gt;\n                &lt;executions&gt;\n                    &lt;execution&gt;\n                        &lt;id&gt;enforce-versions&lt;/id&gt;\n                        &lt;goals&gt;\n                            &lt;goal&gt;enforce&lt;/goal&gt;\n                        &lt;/goals&gt;\n                        &lt;configuration&gt;\n                            &lt;rules&gt;\n                                &lt;requireMavenVersion&gt;\n                                    &lt;version&gt;2.0.9&lt;/version&gt;\n                                &lt;/requireMavenVersion&gt;\n                                &lt;requireJavaVersion&gt;\n                                    &lt;version&gt;1.5&lt;/version&gt;\n                                &lt;/requireJavaVersion&gt;\n                            &lt;/rules&gt;\n                        &lt;/configuration&gt;\n                    &lt;/execution&gt;\n                &lt;/executions&gt;\n            &lt;/plugin&gt;\n        &lt;/plugins&gt;\n    &lt;/build&gt;<br><br>    &lt;repositories&gt;\n        &lt;repository&gt;\n            &lt;id&gt;pentaho&lt;/id&gt;\n            &lt;name&gt;iba copy of pentaho repo at http://repository.pentaho.org/artifactory&lt;/name&gt;\n            &lt;url&gt;http://w3.ibacz.cz/nexus/content/repositories/pentaho&lt;/url&gt;\n            &lt;snapshots&gt;\n                &lt;enabled&gt;false&lt;/enabled&gt;\n            &lt;/snapshots&gt;\n        &lt;/repository&gt;\n        &lt;repository&gt;\n            &lt;id&gt;thirdparty&lt;/id&gt;\n            &lt;name&gt;Third party repository&lt;/name&gt;\n            &lt;url&gt;http://w3.ibacz.cz/nexus/content/repositories/thirdparty&lt;/url&gt;\n        &lt;/repository&gt;\n    &lt;/repositories&gt;<br><br>    &lt;properties&gt;\n        &lt;wcf.version&gt;1.8.0-070305&lt;/wcf.version&gt;\n        &lt;jpivot.version&gt;1.8.0-081008&lt;/jpivot.version&gt;\n        &lt;jpivot.source.version&gt;1.8.0-081008snapshotsrc&lt;/jpivot.source.version&gt;\n    &lt;/properties&gt;<br><br>&lt;/project&gt;\n</code></pre><br><br><h3>The &quot;change&quot; artifacts</h3><p>As mentioned, these reflect the source artifacts and contain changes to them.<br /></p><h4 align=\"left\">jpivot-classes-customized [jar] </h4><p>Depends on jpivot.jar and contains classes changed from the original jar. They're combined together for deployment, overriding original classes with the modified ones.</p><p>The combination and overriding is done by using the maven-dependency-plugin and its undeploy goal to unpack jpivot.jar to the target compilation prior to running the compile phase, which will thus override original jpivot's classes with our modified ones.</p><br><br><pre><code>\n&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;\n    xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd&quot;&gt;\n    &lt;parent&gt;\n        &lt;artifactId&gt;pbns-root-pom&lt;/artifactId&gt;\n        &lt;groupId&gt;eu.ibacz.pbns&lt;/groupId&gt;\n        &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt;\n    &lt;/parent&gt;\n    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;\n    &lt;groupId&gt;eu.ibacz.pbns&lt;/groupId&gt;\n    &lt;artifactId&gt;jpivot-classes-customized&lt;/artifactId&gt;\n    &lt;name&gt;Customized JPivot Classes&lt;/name&gt;\n    &lt;version&gt;1.8.0-SNAPSHOT&lt;/version&gt;<br><br>    &lt;dependencies&gt;\n        &lt;dependency&gt;\n            &lt;groupId&gt;com.tonbeller&lt;/groupId&gt;\n            &lt;artifactId&gt;jpivot&lt;/artifactId&gt;\n            &lt;version&gt;${jpivot.version}&lt;/version&gt;\n            &lt;type&gt;jar&lt;/type&gt;\n            &lt;scope&gt;provided&lt;/scope&gt; &lt;!-- don't propagate further as it will be merged into this project's jar --&gt;\n        &lt;/dependency&gt;\n        &lt;dependency&gt;\n            &lt;groupId&gt;com.tonbeller&lt;/groupId&gt;\n            &lt;artifactId&gt;jpivot-libs-combined&lt;/artifactId&gt;\n            &lt;version&gt;${jpivot.version}&lt;/version&gt;\n            &lt;scope&gt;compile&lt;/scope&gt; &lt;!-- with 'provided' it doesn't get as a transitive dep. of this project's dependants. --&gt;\n        &lt;/dependency&gt;\n    &lt;/dependencies&gt;\n    &lt;description&gt;modified classes of jpivot.jar&lt;/description&gt;\n    &lt;build&gt;\n        &lt;finalName&gt;jpivot-classes-customized&lt;/finalName&gt;\n        &lt;plugins&gt;\n            &lt;plugin&gt;\n                &lt;!--\n                    Merge this project's classes with the original jpivot.jar. You can\n                    safely ignore reports about duplicates - this happens for classes\n                    that we override here.\n                --&gt;\n                &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;\n                &lt;artifactId&gt;maven-dependency-plugin&lt;/artifactId&gt;\n                &lt;version&gt;2.1&lt;/version&gt;\n                &lt;executions&gt;\n                    &lt;execution&gt;\n                        &lt;id&gt;unpack&lt;/id&gt;\n                        &lt;phase&gt;process-resources&lt;/phase&gt; &lt;!-- To run before compile and this be overriden by compiled classes --&gt;\n                        &lt;goals&gt;\n                            &lt;goal&gt;unpack&lt;/goal&gt;\n                        &lt;/goals&gt;\n                        &lt;configuration&gt;\n                            &lt;artifactItems&gt;\n                                &lt;artifactItem&gt;\n                                    &lt;groupId&gt;com.tonbeller&lt;/groupId&gt;\n                                    &lt;artifactId&gt;jpivot&lt;/artifactId&gt;\n                                    &lt;version&gt;${jpivot.version}&lt;/version&gt;\n                                    &lt;type&gt;jar&lt;/type&gt;\n                                &lt;/artifactItem&gt;\n                            &lt;/artifactItems&gt;\n                            &lt;!--excludes&gt;**/AClassIDontLike.class&lt;/excludes&gt; --&gt;\n                            &lt;outputDirectory&gt;${project.build.outputDirectory}&lt;/outputDirectory&gt;\n                        &lt;/configuration&gt;\n                    &lt;/execution&gt;\n                &lt;/executions&gt;\n            &lt;/plugin&gt;\n        &lt;/plugins&gt;\n    &lt;/build&gt;\n&lt;/project&gt;</code></pre><br><br><h4>jpivot-web-customized [war] </h4><p>Depends on and includes jpivot-classes-customized.jar and depends on jpivot.war, contains changed and new resources and is merged with jpivot.war replacing its jpivot.jar with our jpivot-classes-customized.jar during packaging.</p><p>The combination and overriding is done by using overlays of the maven-war-plugin. We also exclude jpivot.jar and replace it with our dependency  jpivot-classes-customized.jar (which mixes the original jar with our changes).</p><br><br><pre><code>&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;<br />    xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd&quot;&gt;<br />    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;<br />    &lt;groupId&gt;eu.ibacz.pbns&lt;/groupId&gt;<br />    &lt;artifactId&gt;jpivot-web-customized&lt;/artifactId&gt;<br />    &lt;packaging&gt;war&lt;/packaging&gt;<br />    &lt;version&gt;1.8.0-SNAPSHOT&lt;/version&gt;<br />    &lt;name&gt;jpivot-web-customized Maven Webapp&lt;/name&gt;<br />    &lt;dependencies&gt;<br />        &lt;dependency&gt;<br />            &lt;groupId&gt;junit&lt;/groupId&gt;<br />            &lt;artifactId&gt;junit&lt;/artifactId&gt;<br />            &lt;version&gt;3.8.1&lt;/version&gt;<br />            &lt;scope&gt;test&lt;/scope&gt;<br />        &lt;/dependency&gt;<br />        &lt;dependency&gt;<br />            &lt;groupId&gt;com.tonbeller&lt;/groupId&gt;<br />            &lt;artifactId&gt;jpivot&lt;/artifactId&gt;<br />            &lt;version&gt;${jpivot.version}&lt;/version&gt;<br />            &lt;type&gt;war&lt;/type&gt;<br />        &lt;/dependency&gt;<br />        &lt;dependency&gt;<br />            &lt;groupId&gt;eu.ibacz.pbns&lt;/groupId&gt;<br />            &lt;artifactId&gt;jpivot-classes-customized&lt;/artifactId&gt;<br />            &lt;version&gt;1.8.0-SNAPSHOT&lt;/version&gt;<br />        &lt;/dependency&gt;<br />    &lt;/dependencies&gt;<br />    &lt;description&gt;Our modification of the original jpivot 1.8.0 webapp. This project should only include the classes, JSPs etc. that we do change.<br />    A package is generated by combining this with the original war.&lt;/description&gt;<br />    &lt;parent&gt;<br />        &lt;artifactId&gt;pbns-root-pom&lt;/artifactId&gt;<br />        &lt;groupId&gt;eu.ibacz.pbns&lt;/groupId&gt;<br />        &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt;<br />    &lt;/parent&gt;<br />    &lt;build&gt;<br />        &lt;finalName&gt;jpivot-web-customized&lt;/finalName&gt;<br />        &lt;plugins&gt;<br />            &lt;plugin&gt;<br />                &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;<br />                &lt;artifactId&gt;maven-war-plugin&lt;/artifactId&gt;<br />                &lt;version&gt;2.1-alpha-2&lt;/version&gt;<br />                &lt;configuration&gt;<br />                    &lt;!--<br />                        exclude jpivot.jar, replace it with jpivot-classes-customized.jar<br />                    --&gt;<br />                    &lt;packagingExcludes&gt;**/jpivot-libs-combined-*.jar&lt;/packagingExcludes&gt;<br />                    &lt;overlays&gt;<br />                        &lt;overlay&gt;<br />                            &lt;groupId&gt;com.tonbeller&lt;/groupId&gt;<br />                            &lt;artifactId&gt;jpivot&lt;/artifactId&gt;<br />                            &lt;excludes&gt;<br />                                &lt;exclude&gt;WEB-INF/lib/jpivot.jar&lt;/exclude&gt;<br />                                &lt;!-- Mondrian stuff we do not needed. --&gt;<br />                                &lt;exclude&gt;WEB-INF/mondrian.properties&lt;/exclude&gt;<br />                                &lt;exclude&gt;WEB-INF/datasources.xml&lt;/exclude&gt;<br />                            &lt;/excludes&gt;<br />                        &lt;/overlay&gt;<br />                    &lt;/overlays&gt;<br />                &lt;/configuration&gt;<br />            &lt;/plugin&gt;<br />        &lt;/plugins&gt;<br />    &lt;/build&gt;<br />&lt;/project&gt;</code></pre><br><br><h3>New dependant artifacts</h3><br><br><h4>jpivot-portlet-liferay-classes [jar]</h4><p>Classes necessary to implement a jpivot portlet working under the Liferay portal (5.2.2).<br /></p><p>Depends on jpivot-classes-customized.jar for compilation only. It depends also on some Liferay libraries that have been imported into our thirdparty maven repository.<br /></p><br><br><pre><code>&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;<br />    xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd&quot;&gt;<br />    &lt;parent&gt;<br />        &lt;artifactId&gt;pbns-root-pom&lt;/artifactId&gt;<br />        &lt;groupId&gt;eu.ibacz.pbns&lt;/groupId&gt;<br />        &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt;<br />    &lt;/parent&gt;<br />    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;<br />    &lt;groupId&gt;eu.ibacz.pbns&lt;/groupId&gt;<br />    &lt;artifactId&gt;jpivot-portlet-liferay-classes&lt;/artifactId&gt;<br />    &lt;name&gt;JPivot Liferay Portlet Classes&lt;/name&gt;<br />    &lt;version&gt;1.8.0-SNAPSHOT&lt;/version&gt;<br /><br />    &lt;dependencies&gt;<br />        &lt;dependency&gt;<br />            &lt;groupId&gt;eu.ibacz.pbns&lt;/groupId&gt;<br />            &lt;artifactId&gt;jpivot-classes-customized&lt;/artifactId&gt;<br />            &lt;version&gt;1.8.0-SNAPSHOT&lt;/version&gt;<br />            &lt;type&gt;jar&lt;/type&gt;<br />        &lt;/dependency&gt;<br /><br />        &lt;dependency&gt;<br />            &lt;groupId&gt;javax.servlet&lt;/groupId&gt;<br />            &lt;artifactId&gt;servlet-api&lt;/artifactId&gt;<br />            &lt;version&gt;2.3&lt;/version&gt;<br />            &lt;scope&gt;provided&lt;/scope&gt;<br />        &lt;/dependency&gt;<br /><br />        &lt;dependency&gt;<br />            &lt;groupId&gt;javax.portlet&lt;/groupId&gt;<br />            &lt;artifactId&gt;portlet-api&lt;/artifactId&gt;<br />            &lt;version&gt;2.0&lt;/version&gt;<br />            &lt;scope&gt;provided&lt;/scope&gt;<br />        &lt;/dependency&gt;<br />        &lt;dependency&gt;<br />            &lt;groupId&gt;com.liferay&lt;/groupId&gt;<br />            &lt;artifactId&gt;portal-kernel&lt;/artifactId&gt;<br />            &lt;version&gt;5.2.2&lt;/version&gt;<br />            &lt;type&gt;jar&lt;/type&gt;<br />            &lt;scope&gt;provided&lt;/scope&gt;<br />        &lt;/dependency&gt;<br />        &lt;dependency&gt;<br />            &lt;groupId&gt;com.liferay&lt;/groupId&gt;<br />            &lt;artifactId&gt;portal-service&lt;/artifactId&gt;<br />            &lt;version&gt;5.2.2&lt;/version&gt;<br />            &lt;type&gt;jar&lt;/type&gt;<br />            &lt;scope&gt;provided&lt;/scope&gt;<br />        &lt;/dependency&gt;<br />        &lt;dependency&gt;<br />            &lt;groupId&gt;com.liferay&lt;/groupId&gt;<br />            &lt;artifactId&gt;portal-impl&lt;/artifactId&gt;<br />            &lt;version&gt;5.2.2&lt;/version&gt;<br />            &lt;type&gt;jar&lt;/type&gt;<br />            &lt;scope&gt;provided&lt;/scope&gt;<br />        &lt;/dependency&gt;<br />        <br />        &lt;!--<br />            Actually included in jpivot's libs, but made explicit here; Apache<br />            FOP for printing<br />        --&gt;<br />        &lt;dependency&gt;<br />            &lt;groupId&gt;fop&lt;/groupId&gt;<br />            &lt;artifactId&gt;fop&lt;/artifactId&gt;<br />            &lt;version&gt;0.20.5&lt;/version&gt;<br />            &lt;type&gt;jar&lt;/type&gt;<br />            &lt;scope&gt;provided&lt;/scope&gt;<br />        &lt;/dependency&gt;<br />    &lt;/dependencies&gt;<br />    &lt;description&gt;Classes for a jpivot portlet ready for Liferay&lt;/description&gt;<br />    &lt;build&gt;<br />        &lt;finalName&gt;jpivot-portlet-liferay-classes&lt;/finalName&gt;<br />    &lt;/build&gt;<br />&lt;/project&gt;</code></pre><br><br><h4> bns-portlets [war]</h4><p>A set of JPivot portlets, usually consisting of JSPs, CSSs, and JSs.<br /></p><p>Extends further jpivot-web-customized and is merged with this WAR during packaging, same as jpivot-web-customized itself is merged with jpivot.war. Only it doesn't include any changes but only additions.</p><br><br><pre><code>&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;<br />    xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd&quot;&gt;<br />    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;<br />    &lt;groupId&gt;eu.ibacz.pbns&lt;/groupId&gt;<br />    &lt;artifactId&gt;bns-portlets&lt;/artifactId&gt;<br />    &lt;packaging&gt;war&lt;/packaging&gt;<br />    &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt;<br />    &lt;name&gt;BNS Portal Portlets&lt;/name&gt;<br /><br />    &lt;dependencies&gt;<br />        &lt;dependency&gt;<br />            &lt;groupId&gt;eu.ibacz.pbns&lt;/groupId&gt;<br />            &lt;artifactId&gt;jpivot-web-customized&lt;/artifactId&gt;<br />            &lt;version&gt;1.8.0-SNAPSHOT&lt;/version&gt;<br />            &lt;type&gt;war&lt;/type&gt;<br />        &lt;/dependency&gt;<br />        &lt;dependency&gt;<br />            &lt;groupId&gt;eu.ibacz.pbns&lt;/groupId&gt;<br />            &lt;artifactId&gt;jpivot-portlet-liferay-classes&lt;/artifactId&gt;<br />            &lt;version&gt;1.8.0-SNAPSHOT&lt;/version&gt;<br />            &lt;type&gt;jar&lt;/type&gt;<br />        &lt;/dependency&gt;<br />    &lt;/dependencies&gt;<br />    &lt;description&gt;<br />  Portlets for BNS Portal panels based on our modified JPivot and jpivot liferay portlet support.<br />  &lt;/description&gt;<br />    &lt;parent&gt;<br />        &lt;artifactId&gt;pbns-root-pom&lt;/artifactId&gt;<br />        &lt;groupId&gt;eu.ibacz.pbns&lt;/groupId&gt;<br />        &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt;<br />    &lt;/parent&gt;<br />    &lt;build&gt;<br />        &lt;finalName&gt;bns-portlets&lt;/finalName&gt;<br />        &lt;plugins&gt;<br />            &lt;plugin&gt;<br />                &lt;!-- Merge this WAR with the jpivot war stuff. --&gt;<br />                &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;<br />                &lt;artifactId&gt;maven-war-plugin&lt;/artifactId&gt;<br />                &lt;version&gt;2.1-alpha-2&lt;/version&gt;<br />                &lt;configuration&gt;<br />                    &lt;!-- Exclude the transitive jpivot libs dependency - the WAR has it. --&gt;<br />                    &lt;packagingExcludes&gt;WEB-INF/lib/jpivot-libs-combined-*.jar&lt;/packagingExcludes&gt;<br />                    &lt;overlays&gt;<br />                        &lt;overlay&gt;<br />                            &lt;groupId&gt;eu.ibacz.pbns&lt;/groupId&gt;<br />                            &lt;artifactId&gt;jpivot-web-customized&lt;/artifactId&gt;<br />                        &lt;/overlay&gt;<br />                    &lt;/overlays&gt;<br />                &lt;/configuration&gt;<br />            &lt;/plugin&gt;<br />        &lt;/plugins&gt;<br />    &lt;/build&gt;<br />&lt;/project&gt;</code></pre><br><br><h3>The build process summarized</h3><ol><li><i>jpivot-classes-customized</i> is compiled and merged with the original jpivot.jar into a single archive.</li><li><i>jpivot-web-customized</i> is merged with the original jpivot.war, replacing its WEB-INF/lib/jpivot.war with the already built jpivot-classes-customized.jar. The output is a standalone and deployable standard web application.<br /></li><li><i>jpivot-portlet-liferay-classes</i> is packaged in the standard way and the produced JAR includes only its own classes.<br /></li><li><i>bns-portlets</i> is merged with our already built jpivot-web-customized.war to produce a deployable portlet application.<br /></li></ol><h2>A development project for IDEs<br /></h2><p>The &quot;change projects&quot; are not complete on their own and are therefore not very suitable for use for development in an Integrated Development Environment (IDE). If we used an IDE to work on a change web project, it would complain about missing TLDs and other resources from the WAR to be merged in and it wouldn't be able to deploy it thus loosing the advantage of hot deploy.</p><p>The proposed solutions is as follows:</p><ol><li>Build the final, complete bns-portlets.war (<font size=\"2\" face=\"courier new,courier,monospace\">cd bns-portlets; mvn package</font>).</li><li>Import the WAR as a project into an IDE.</li><ul><li>Eclipse: File - Import - Web - WAR file.</li><li>NetBeans: Unpack the WAR somewhere then File - New Project - Java Web - Web Application with Existing Sources - go to the unpacked directory.<br /></li></ul><li>You should have defined a Liferay runtime environment for the server. If not, you will need to add classpath entries for the Liferay libraries it uses to be able to compile it.<br /></li><li>Delete WEB-INF/lib/jpivot-portlet-liferay-classes.jar.</li><li>// If WEB-INF/classes hasn't precedence over lib/ then delete classes that we've modified from jpivot-classes-customized.jar.<br /></li><li>Add 2 new source folders that are linked to the source folders of the jar projects, namely one to jpivot-classes-customized/src/main/java/ and the other to jpivot-portlet-liferay-classes/src/main/java/ .</li><ul><li>Eclipse: Project - Properties - Java Build Path - Source - [Link Source]<br /></li></ul><li>Develop.<br /></li><ul><li>Now you can modify the sources if needed and commit their modifications to SVN. Because we actually work on the original projects' directories, the proper svn metadata will be picked up and the changes will be commited to the respective projects.</li><ul><li>Unfortunately Eclipse ignores the SVN information of the linked sources. To be able to commit etc. them you'll need either to use another svn client or have the projects owning the sources open in Eclipse. An alternative is may be to drop the links and define project dependency.<br /></li></ul><li>If you need to modify another source code or resource file, copy it first to the approrpiate change project from the original jpivot.war or jpivot.jar's sources.</li></ul></ol>All changes will be commited to the corresponding SVN projects so this is ok but there is now the risk that a developer will do something in this development project, commit it to SVN, but forgets to build and deploy the corresponding real project's artifact. Well, this is a risk we have to live with. Such an omission could be detected by our continuous integration server (indicated by a failed build) and perhaps we could add a test which verifies that deployed artifacts aren't older than the corresponding SVN project.<br /><h2>Known limitations and issues</h2><h2>Next steps</h2><p>Continuous integration with Hudson.<br /></p><h2>Conclusion/summary</h2><p>TODO<br /></p>",
  "excerpt": ""
 },
 {
  "title": "Seam Tutorial 1.2: RichFaces and paged table (datascroller)",
  "published": "2009-03-23 06:30:52",
  "postType": "post",
  "slug": "/2009/03/23/seam-tutorial-1-2-richfaces-and-pa/",
  "status": "publish",
  "tags": [
   "jsf",
   "jsr168",
   "jsr286",
   "portlet",
   "RichFaces",
   "seam"
  ],
  "categories": [
   "Portlets"
  ],
  "content": "In this two-part tutorial you will\r\nlearn how to get started with the development of Seam applications\r\nwith RichFaces using Eclipse with JBoss Tools. In <a href=\"/2009/03/07/seam-tutorial-1-1-richfaces-and-pa/\">the 1<sup>st</sup>\r\npart</a> we've set up our environment, created, and run an empty shell\r\nSeam application. In this 2<sup>nd</sup> part we will create a simple\r\nweb page with a table presenting data on multiple pages using Ajax (a\r\nRichFaces component) and its model stored as a POJO Component in the\r\nSeam Conversation scope. I assume that you already have some basic\r\nknowledge of Seam and JSF, for instance that you know what a\r\nComponent or the Conversation scope are. I'll present my path to this\r\ngoal with all the mistakes so that you too can learn from them.\r\n<p style=\"margin-bottom:0;\">My aim in this tutorial series is to\r\ncreate a Seam portlet displaying data in a paged (and ideally also\r\nsortable and filterable, but lets be realistic) table running in the\r\nLiferay portal.</p>\r\n<!--more-->\r\n<h3 class=\"western\">Attempt 1: The straightforward version</h3>\r\nFirst we will create a new Seam project in exactly the same way as\r\nin part 1.1, the only difference being that we will call it\r\nseamTutorial12. Or you can reuse the existing project. I will not\r\nrepeat the steps here, you can refer to the previous post.<br><br><em>TIP: Cleaning of the jboss deploy folder doesn't work very well\r\n(event with the Clean button in the JBoss Server View). You may need\r\nto help it by undeploying all projects and manually deleting contents\r\nof deploy/ in the JBoss folder, which is, for a server named\r\nJBoss_4.2.3, &lt;eclipse\r\nworkspace&gt;/.metadata/.plugins/org.jboss.ide.eclipse.as.core/JBoss_4.2.3/.\r\nAn alternative is to create a new server.</em><br><br><em>Note: When working offline you may get exceptions due to\r\n<a href=\"http://www.w3.org/\">www.w3.org</a> being unreachable, which\r\nwill prevent the deployment of\r\njboss-portal.sar/portal-wsrp.sar/portal-wsrp.war/. This is nothing to\r\nworry about.</em>\r\n<h4 class=\"western\">Create a component and a page</h4>\r\nAssuming that you have the project seamTutorial12 created and\r\nrunning, we will add a new component and page to it for our\r\nexperiments.<br><br>File &gt; New &gt; Seam Action\r\n<ul>\r\n\t<li>Type the Seam component name <em>richTable</em> and accept the\r\ndefaults (it would be better to apply a reasonable naming standard\r\nbut let's keep it simple).</li>\r\n\t<li>Finish.</li>\r\n\t<li>Note: We could also select Seam Form, which would create a\r\npage with a form and button.</li>\r\n</ul>\r\n<img title=\"Screenshot - New Seam Action\" src=\"http://www.jroller.com/holy/resource/seamTutorial12/Screenshot-NewSeamAction.png\" alt=\"\" /><br><br>This will create two files:<br><br>1. src/hot/org/domain/seamtutorial12/session/RichTable.java\r\n<pre><code>\r\npackage org.domain.seamtutorial12.session;<br><br>import org.jboss.seam.annotations.Name;\r\nimport org.jboss.seam.annotations.In;\r\nimport org.jboss.seam.annotations.Logger;\r\nimport org.jboss.seam.log.Log;\r\nimport org.jboss.seam.faces.FacesMessages;<br><br>@Name(\"richTable\")\r\npublic class RichTable {\r\n@Logger private Log log;\r\n@In FacesMessages facesMessages;<br><br>public void richTable()\r\n{\r\n   //implement your business logic here\r\n   log.info(\"richTable.richTable() action called\");\r\n   facesMessages.add(\"richTable\");\r\n}<br><br>//add additional action methods\r\n}\r\n</code></pre>\r\n2. WebContent/richTable.xhtml .\r\n<pre><code>\r\n&lt;!DOCTYPE composition PUBLIC \"-//W3C//DTD XHTML 1.0 Transitional//EN\"\r\n\"http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd\"&gt;<br><br>&lt;ui:composition xmlns=\"http://www.w3.org/1999/xhtml\"\r\nxmlns:s=\"http://jboss.com/products/seam/taglib\" xmlns:ui=\"http://java.sun.com/jsf/facelets\"\r\nxmlns:f=\"http://java.sun.com/jsf/core\" xmlns:h=\"http://java.sun.com/jsf/html\"\r\nxmlns:rich=\"http://richfaces.org/rich\" xmlns:a=\"http://richfaces.org/a4j\"\r\ntemplate=\"layout/template.xhtml\"&gt;<br><br>&lt;ui:define name=\"body\"&gt;<br><br>&lt;h:messages globalOnly=\"true\" styleClass=\"message\" /&gt;<br><br>&lt;rich:panel&gt;\r\n&lt;f:facet name=\"header\"&gt;richTable&lt;/f:facet&gt;\r\n&lt;h:form id=\"richTableForm\"&gt;\r\n&lt;h:commandButton id=\"richTable\" value=\"richTable!\"\r\naction=\"#{richTable.richTable}\" /&gt;\r\n&lt;/h:form&gt;\r\n&lt;/rich:panel&gt;<br><br>&lt;/ui:define&gt;<br><br>&lt;/ui:composition&gt;<br><br></code></pre>\r\nOpening the page in Eclipse will show an editor with a text and\r\nvisual views of the page (notice that the selected tag – h:form –\r\nis emphasized in the visual view – the blue line):<br><br><img title=\"Eclipse - visual and source view of a xhtml page\" src=\"http://jroller.com/holy/resource/seamTutorial12/Screenshot3-Eclipse-richTable-source+visual_page_editor.png\" alt=\"\" /><br><br>Go to <a href=\"http://localhost:8080/seamTutorial12/richTable.seam\">http://localhost:8080/seamTutorial12/richTable.seam</a>\r\nto see it:<br><br><img title=\"New RichTable page in Firefox\" src=\"http://jroller.com/holy/resource/seamTutorial12/Screenshot2-seamTutorial12-vanilla_richTablePage-Firefox.png\" alt=\"\" /><br><br>Clicking the button RichTable! should add a message “RichTable”\r\nto the page.\r\n<h4 class=\"western\">Define a table data model</h4>\r\nTo use a table we need the data to display in it. JSF requires\r\ndata to be provided as an instance of DataModel however we will use a\r\nsimple List and let Seam to wrap it into a DataModel. We will add the\r\nfollowing snippet to RichTable.java (plus the necessary imports) to\r\ndefine the data model property/component rowList and to initialize in\r\nthe class' constructor:\r\n<pre>@DataModel\r\nList&lt;String&gt; rowList = new LinkedList&lt;String&gt;();<br><br>public RichTable() {\r\nfinal Date now = new Date();\r\nrowList.add(\"row 1 created on \" + now);\r\nrowList.add(\"row 2 created on \" + now);\r\nrowList.add(\"row 3 created on \" + now);\r\n}</pre>\r\n<h4 class=\"western\">Create a RichFaces table</h4>\r\nFinally we will create the rich table to display the data.\r\n<ol>\r\n\t<li>Double click on richTable.xhtml in Eclipse to open it in the\r\nJBoss Tools HTML Editor.</li>\r\n\t<li>In the source view click inside the h:form and in the JBoss\r\nTools Palette click on JBoss RichFaces – <a href=\"http://livedemo.exadel.com/richfaces-demo/richfaces/extendedDataTable.jsf?c=extendedDataTable&amp;tab=usage\">extendedDataTable</a>. I've selected the extendedDataTable and not the\r\nbasic rich:dataTable because the extended one has sorting and\r\nfiltering built-in. (You can also add these features to the standard\r\ntable using other components.)\r\nThe table will be inserted at the\r\ncursor's location.<br><br><img title=\"Eclipse - adding a RichTable component to the page\" src=\"http://jroller.com/holy/resource/seamTutorial12/Screenshot4-Eclipse-add_extRichTable2page.png\" alt=\"\" /></li>\r\n\t<li>You could continue with adding columns etc. in this manner\r\nbut I leave this up to your playful nature and just provide the\r\nfinal code that the ones in a hurry can copy&amp;paste.</li>\r\n</ol>\r\nThe final code:\r\n<p style=\"margin-bottom:0;\"></p>\r\n<p style=\"margin-bottom:0;\"><span style=\"color:#008080;\"><span style=\"font-family:Monospace;\"><span style=\"font-size:x-small;\">&lt;h:form&gt;</span></span></span></p>\r\n<p style=\"margin-bottom:0;\"><span style=\"font-family:Monospace;\"><span style=\"font-size:x-small;\"><span style=\"color:#7f007f;\"><span style=\"color:#008080;\">&lt;</span><span style=\"color:#3f7f7f;\">rich:extendedDataTable </span><span style=\"color:#7f007f;\">width</span>=<span style=\"color:#2a00ff;\"><em>\"483\"</em></span> <span style=\"color:#7f007f;\">id</span>=<span style=\"color:#2a00ff;\"><em>\"richTable\"</em></span> <span style=\"color:#7f007f;\">rows</span>=<span style=\"color:#2a00ff;\"><em>\"2\"</em></span> <span style=\"color:#7f007f;\">columnClasses</span>=<span style=\"color:#2a00ff;\"><em>\"col\" </em></span>value</span><span style=\"color:#000000;\">=</span><span style=\"color:#2a00ff;\"><em>\"#{rowList}\"</em></span> <span style=\"color:#7f007f;\">var</span><span style=\"color:#000000;\">=</span><span style=\"color:#2a00ff;\"><em>\"row\"</em></span><span style=\"color:#008080;\">&gt;</span></span></span></p>\r\n<p style=\"margin-bottom:0;\"><span style=\"font-family:Monospace;\"><span style=\"font-size:x-small;\"><span style=\"color:#008080;\">&lt;</span><span style=\"color:#3f7f7f;\">f:facet </span><span style=\"color:#7f007f;\">name</span><span style=\"color:#000000;\">=</span><span style=\"color:#2a00ff;\"><em>\"header\"</em></span><span style=\"color:#008080;\">&gt;</span></span></span></p>\r\n<p style=\"margin-bottom:0;\"><span style=\"font-family:Monospace;\"><span style=\"font-size:x-small;\"><span style=\"color:#008080;\">&lt;</span><span style=\"color:#3f7f7f;\">rich:columnGroup</span><span style=\"color:#008080;\">&gt;\r\n&lt;</span><span style=\"color:#3f7f7f;\">h:column</span><span style=\"color:#008080;\">&gt;\r\n&lt;</span><span style=\"color:#3f7f7f;\">h:outputText</span> <span style=\"color:#7f007f;\">styleClass</span><span style=\"color:#000000;\">=</span><span style=\"color:#2a00ff;\"><em>\"headerText\"</em></span> <span style=\"color:#7f007f;\">value</span><span style=\"color:#000000;\">=</span><span style=\"color:#2a00ff;\"><em>\"A Column\"</em></span> <span style=\"color:#008080;\">/&gt;</span></span>\r\n<span style=\"font-size:x-small;\"><span style=\"color:#008080;\"> &lt;/</span><span style=\"color:#3f7f7f;\">h:column</span><span style=\"color:#008080;\">&gt;\r\n</span><span style=\"color:#008080;\">&lt;/</span><span style=\"color:#3f7f7f;\">rich:columnGroup</span><span style=\"color:#008080;\">&gt;</span></span></span></p>\r\n<p style=\"margin-bottom:0;\"><span style=\"font-family:Monospace;\"><span style=\"font-size:x-small;\"><span style=\"color:#008080;\">&lt;/</span><span style=\"color:#3f7f7f;\">f:facet</span><span style=\"color:#008080;\">&gt;</span></span></span></p>\r\n<p style=\"margin-bottom:0;\"><span style=\"font-family:Monospace;\"><span style=\"font-size:x-small;\"><span style=\"color:#008080;\">&lt;</span><span style=\"color:#3f7f7f;\">h:column</span><span style=\"color:#008080;\">&gt;&lt;</span><span style=\"color:#3f7f7f;\">h:outputText</span> <span style=\"color:#7f007f;\">value</span><span style=\"color:#000000;\">=</span><span style=\"color:#2a00ff;\"><em>\"#{row}\"</em></span> <span style=\"color:#008080;\">/&gt;&lt;/</span><span style=\"color:#3f7f7f;\">h:column</span><span style=\"color:#008080;\">&gt;</span></span></span></p>\r\n<p style=\"margin-bottom:0;\"><span style=\"font-family:Monospace;\"><span style=\"font-size:x-small;\"><span style=\"color:#008080;\">&lt;/</span><span style=\"color:#3f7f7f;\">rich:extendedDataTable</span><span style=\"color:#008080;\">&gt;</span></span></span></p>\r\n<p style=\"margin-bottom:0;\"><span style=\"font-family:Monospace;\"><span style=\"font-size:x-small;\"><span style=\"color:#008080;\">&lt;</span><span style=\"color:#3f7f7f;\">rich:spacer </span><span style=\"color:#7f007f;\">height</span><span style=\"color:#000000;\">=</span><span style=\"color:#2a00ff;\"><em>\"30\"</em></span> <span style=\"color:#008080;\">/&gt;</span></span></span></p>\r\n<p style=\"margin-bottom:0;\"><span style=\"font-size:x-small;\"><span style=\"color:#008080;\"><span style=\"font-family:Monospace;\">&lt;</span></span><span style=\"color:#3f7f7f;\"><span style=\"font-family:Monospace;\">rich:datascroller </span></span><span style=\"color:#7f007f;\"><span style=\"font-family:Monospace;\">id</span></span><span style=\"color:#000000;\"><span style=\"font-family:Monospace;\">=</span></span><span style=\"color:#2a00ff;\"><span style=\"font-family:Monospace;\"><em>\"richTableScroller\"</em></span></span> <span style=\"color:#7f007f;\"><span style=\"font-family:Monospace;\">align</span></span><span style=\"color:#000000;\"><span style=\"font-family:Monospace;\">=</span></span><span style=\"color:#2a00ff;\"><span style=\"font-family:Monospace;\"><em>\"left\"</em></span></span> <span style=\"color:#7f007f;\"><span style=\"font-family:Monospace;\">for</span></span><span style=\"color:#000000;\"><span style=\"font-family:Monospace;\">=</span></span><span style=\"color:#2a00ff;\"><span style=\"font-family:Monospace;\"><em>\"richTable\"</em></span></span> <span style=\"color:#7f007f;\"><span style=\"font-family:Monospace;\">maxPages</span></span><span style=\"color:#000000;\"><span style=\"font-family:Monospace;\">=</span></span><span style=\"color:#2a00ff;\"><span style=\"font-family:Monospace;\"><em>\"20\" /</em></span></span><span style=\"color:#008080;\"><span style=\"font-family:Monospace;\">&gt;</span></span></span></p>\r\n<p style=\"margin-bottom:0;\"><a name=\"DDE_LINK3\"></a><span style=\"color:#008080;\"><span style=\"font-family:Monospace;\"><span style=\"font-size:x-small;\">&lt;/h:form&gt;</span></span></span></p>\r\n<p style=\"margin-bottom:0;\">Notice that I've removed the command\r\nbutton (<span style=\"color:#3f7f7f;\"><span style=\"font-family:Monospace;\"><span style=\"font-size:x-small;\">h:commandButton</span></span></span>),\r\nwhich we don't need, to make the code cleaner.</p>\r\n<p style=\"margin-bottom:0;\">That's it! Notes:</p><br><br><ul>\r\n\t<li>\r\n<p style=\"margin-bottom:0;\">We use a datascroller to have\r\npaging of the table via Ajax. The table is set to display at most 2\r\nrows via its attribute rows=2 thus we should see the 3<sup>rd</sup>\r\nelement of our data model on the next page of the table.</p>\r\n</li>\r\n\t<li>\r\n<p style=\"margin-bottom:0;\">RichFaces (Ajax) components must\r\nbe within a form because its function is based on submitting the\r\nclosest enclosing form. (See the RichFaces Developer Guide for\r\n3.1.4.GA, part 5.4.3. Data Processing Options )<strong>.</strong></p>\r\n</li>\r\n</ul>\r\n<h4 class=\"western\">Run the application</h4>\r\n<p style=\"margin-bottom:0;\">Now we can run it. In the JBoss Server\r\nView right-click on seamTutorial12 &gt; Full Publish (though\r\nincremental publish or waiting for JBoss tools to publish the change\r\nautomatically should also work).</p>\r\n<p style=\"margin-bottom:0;\">When you access\r\n<a href=\"http://localhost:8080/seamTutorial12/richTable.seam\">http://localhost:8080/seamTutorial12/richTable.seam</a>\r\nyou will be surprised to see a Facelets Error page reading:</p><br><br><pre style=\"margin-bottom:.5cm;\">/richTable.xhtml @22,46 &lt;rich:extendedDataTable&gt; Tag Library supports namespace: http://richfaces.org/rich, but no tag was defined for name: extendedDataTable.</pre>\r\n<h4 class=\"western\">Catch #1: JBoss Tools Palette uses newer version of RichFaces than\r\nSeam itself and let you add a component not present in the runtime\r\nversion.</h4>\r\n<p style=\"margin-bottom:0;\">The error message above indicates that\r\nFacelets can't find the tag extendedDataTable in the taglib rich.\r\nIndeed if you look in Eclipse in the Package Explorer into\r\nseamTutorial12 &gt; Web App Libraries &gt;\r\nrichfaces-ui.jar/META-INF/rich.tld you will not find it there either.\r\nA look inside richfaces-ui.jar/META-INF/MANIFEST.MF reveals that this\r\nversion of RichFaces is 3.1.4 GA and not the latest (as of 2/2009)\r\n3.3.0.</p><br><br><h3 class=\"western\">Intermezzo: Get RichFaces demo 3.1.4 GA running</h3>\r\nThe RichFaces demo is the best way to learn what its components\r\ncan do, how to do it, and to copy the code for that. The online demo\r\nis of the latest version but for Seam 2.0.2 SP1 you would need\r\nRichFaces demo 3.1.4 GA.\r\n<ol>\r\n\t<li>Download <a href=\"http://repository.jboss.com/maven2/org/richfaces/samples/richfaces-demo/3.1.4.GA/richfaces-demo-3.1.4.GA-tomcat6.war\">richfaces-demo-3.1.4.GA-tomcat6.war</a></li>\r\n\t<li>Download Tomcat 6.0.18.</li>\r\n\t<li>Install it to the Tomcat. I've imported the .war into Eclipse\r\n(File &gt; Import) as JSF Project From *.war, defined a Tomcat\r\nserver (right click in JBoss Server View &gt; New &gt; Server &gt;\r\n...) , and added the project to the server (JBoss Server View &gt;\r\n[your Tomcat server] &gt; Add and Remove Projects...).</li>\r\n\t<li>Perhaps change the ports Tomcat uses so that you can have it\r\nrunning in parallel with JBoss: double click on the newly created\r\nTomcat server in the JBoss Server View, change Ports e.g. by\r\nprepending 2 (-&gt; 28080 etc.).</li>\r\n\t<li>Start Tomcat.</li>\r\n\t<li>Go to\r\n<a href=\"http://localhost:28080/Richfaces-demo-3.1.4.GA-tomcat6/richfaces/dataTable.jsf?c=dataTable\">http://localhost:28080/Richfaces-demo-3.1.4.GA-tomcat6/richfaces/dataTable.jsf?c=dataTable</a>\r\n(or :8080 if you haven't changed the port) and you shall see the\r\ndemo .</li>\r\n</ol>\r\nI haven't managed to get the demo running under JBoss but this\r\nsolution is fine.\r\n<h3 class=\"western\">Attempt 2: Page valid for the actual RichFaces\r\nversion</h3>\r\n<h4 class=\"western\">Create a RichFaces table, version 2 – a basic\r\nrich:dataTable</h4>\r\nSince RichFaces 3.1.4 doesn't have the lovely extendedDataTable we\r\nwill give up on sorting and filtering and use the basic\r\nrich:dataTable. The change to the code is trivial, just replace\r\nextendedDataTable with dataTable.\r\n<p style=\"margin-bottom:0;\"><span style=\"font-family:Monospace;\"><span style=\"font-size:x-small;\"><span style=\"color:#008080;\">&lt;</span><span style=\"color:#3f7f7f;\">h:form</span><span style=\"color:#008080;\">&gt;</span></span></span></p>\r\n<p style=\"margin-bottom:0;\"><span style=\"color:#008080;\"><span style=\"font-family:Monospace;\"><span style=\"color:#7f007f;\"><span style=\"color:#008080;\">&lt;</span><span style=\"color:#3f7f7f;\">rich:</span><span style=\"color:#3f7f7f;\"><em><strong>dataTable </strong></em></span><span style=\"color:#7f007f;\">width</span>=<span style=\"color:#2a00ff;\"><em>\"483\"</em></span> <span style=\"color:#7f007f;\">id</span>=<span style=\"color:#2a00ff;\"><em>\"richTable\"</em></span> <span style=\"color:#7f007f;\">rows</span>=<span style=\"color:#2a00ff;\"><em>\"2\"</em></span> <span style=\"color:#7f007f;\">columnClasses</span>=<span style=\"color:#2a00ff;\"><em>\"col\" </em></span>value</span><span style=\"color:#000000;\">=</span><span style=\"color:#2a00ff;\"><em>\"#{rowList}\"</em></span> <span style=\"color:#7f007f;\">var</span><span style=\"color:#000000;\">=</span><span style=\"color:#2a00ff;\"><em>\"row\"</em></span><span style=\"font-size:x-small;\">&gt;\r\n...</span></span></span></p>\r\n<p style=\"margin-bottom:0;\"><span style=\"font-family:Monospace;\"><span style=\"font-size:x-small;\"><span style=\"color:#008080;\">&lt;/</span><span style=\"color:#3f7f7f;\">rich:</span><span style=\"color:#3f7f7f;\"><em><strong>dataTable</strong></em></span><span style=\"color:#008080;\">&gt;</span></span></span></p>\r\n<p style=\"margin-bottom:0;\"><span style=\"color:#008080;\"><span style=\"font-family:Monospace;\"><span style=\"font-size:x-small;\">...</span></span></span></p>\r\n<p style=\"margin-bottom:0;\"><span style=\"font-size:x-small;\"><span style=\"color:#008080;\"><span style=\"font-family:Monospace;\">&lt;/</span></span><span style=\"color:#3f7f7f;\"><span style=\"font-family:Monospace;\">h:form</span></span><span style=\"color:#008080;\"><span style=\"font-family:Monospace;\">&gt;</span></span></span></p>\r\nModify the .xhtml and save it, JBoss should pick the change up\r\nautomatically. (Or do force its publication.) Reload\r\n<a href=\"http://localhost:8080/seamTutorial12/richTable.seam\">http://localhost:8080/seamTutorial12/richTable.seam</a>\r\nin your browser. You may need to wait for some time.<br><br><img title=\"The first table in a browser\" src=\"http://jroller.com/holy/resource/seamTutorial12/Screenshot6-seamTutorial12-2ndRichTable_empty-Konqueror.png\" alt=\"\" /><br><br>Certainly you wonder why the table is empty instead of showing our\r\n3 rows (or actually the first two ones) . The answer is that at the\r\ntime the table was being rendered, the data model component rowList\r\nwas undefined.\r\n<table border=\"1\" cellspacing=\"0\" cellpadding=\"4\"><col></col>\r\n<tbody>\r\n<tr>\r\n<th valign=\"top\">Issue: Undefined data source during startup</th>\r\n</tr>\r\n<tr>\r\n<td valign=\"top\" bgcolor=\"#ffff99\">When deploying and undeploying projects it may (will) happen that\r\nJBoss Tools get confused and forget to deploy the project's data\r\nsource. Normally when you are adding a project, like seamTutorial12,\r\nto a server, you should be able and should do select also its data\r\nsource, like /../seamTutorial12-ds.xml. If you haven't the choice or\r\nforget it you will see an error like the following one during the\r\nSeam application startup following its deployment:\r\n<p style=\"margin-bottom:0;\"><span style=\"color:#000000;\"><span style=\"font-family:Monospace;\"><span style=\"font-size:x-small;\">ERROR\r\n[DatasourceConnectionProvider] Could not find datasource:\r\njava:/seamTutorial12Datasource</span></span></span></p>\r\n<p style=\"margin-bottom:0;\"><span style=\"color:#000080;\"><span style=\"font-family:Monospace;\"><span style=\"font-size:x-small;\"><span style=\"text-decoration:underline;\">javax.naming.NameNotFoundException</span></span></span></span><span style=\"color:#000000;\"><span style=\"font-family:Monospace;\"><span style=\"font-size:x-small;\">:\r\nseamTutorial12Datasource not bound</span></span></span></p>\r\nThe solution is to deploy the data source manually:\r\n<ol>\r\n\t<li>In the Package Explorer, right-click on\r\n/seamTutorial12/resources/seamTutorial12-ds.xml and select Make\r\nDeployable from the context menu, then select the proper target\r\nserver from the window that pops up (JBoss_4.2.3)</li>\r\n\t<li>In the JBoss Server View. you should now see\r\n/seamTutorial12/resources/seamTutorial12-ds.xml below the server name\r\nand the server's status changed to Started, Republish (if it was\r\nstarted).</li>\r\n\t<li>After republishing or restarting (which may be safer) the\r\nserver the error should have been gone. In the log you should\r\nsee:\r\n<span style=\"color:#000000;\"><span style=\"font-family:Monospace;\"><span style=\"font-size:x-small;\">INFO\r\n[ConnectionFactoryBindingService] Bound ConnectionManager\r\n'jboss.jca:service=DataSourceBinding,name=seamTutorial12Datasource'\r\nto JNDI name 'java:seamTutorial12Datasource'</span></span></span></li>\r\n</ol>\r\nNotice: On the screenshot there is “Make Undeployable” instead\r\nof Deployable because it's been taken after the step #3, i.e. when\r\nalready deployed.\r\n<img title=\"Manual deployment of a data source\" src=\"http://jroller.com/holy/resource/seamTutorial12/Screenshot6-deploy_datasource.png\" alt=\"\" /></td>\r\n</tr>\r\n</tbody>\r\n</table>\r\n<h4 class=\"western\">Lesson learned 1: DataModel needs a Factory\r\nmethod unless the parent component is also used on the page</h4>\r\nYou may have a component that outjects another component as a data\r\nmodel via the annotation @DataModel on a property. However if the\r\nowning component (richTable) isn't used on a page where the data\r\nmodel is used, it won't be instantiated and therefore also there will\r\nbe nobody to create and outject the data model component (rowList)\r\nitself. Seam is not clever or active enough to understand that to\r\nhave the component rowList it must first instantiate richTable.<br><br>The solution is to provide a method annotated with\r\n<span style=\"color:#646464;\"><span style=\"font-family:Monospace;\"><span style=\"font-size:x-small;\">@Factory</span></span></span><span style=\"color:#000000;\"><span style=\"font-family:Monospace;\"><span style=\"font-size:x-small;\">(</span></span></span><span style=\"color:#2a00ff;\"><span style=\"font-family:Monospace;\"><span style=\"font-size:x-small;\">\"rowList\"</span></span></span><span style=\"color:#000000;\"><span style=\"font-family:Monospace;\"><span style=\"font-size:x-small;\">)</span></span></span>\r\nto tell Seam that to instantiate the rowList component, it must call\r\nthis method (which will likely also require instantiation of its\r\nparent component, richTable). See Seam Reference 2.0.2 SP1, chapter\r\n4.8. Factory and manager components.\r\n<h3 class=\"western\">Attempt 3: Tell Seam how to get an instance of\r\nrowList via a @Factory method</h3>\r\nAs explained above, we will provide a new method to tell Seam what\r\nto do when #{rowList} is referenced on a page and it doesn't exist\r\nyet. We will move here the initiation code from the parent\r\ncomponent's constructor.\r\n<p style=\"margin-bottom:0;\"><span style=\"font-family:Monospace;\"><span style=\"font-size:x-small;\"><span style=\"color:#646464;\">@Factory</span><span style=\"color:#000000;\">(</span><span style=\"color:#2a00ff;\">\"rowList\"</span><span style=\"color:#000000;\">)</span></span></span></p>\r\n<p style=\"margin-bottom:0;\"><span style=\"font-family:Monospace;\"><span style=\"font-size:x-small;\"><span style=\"color:#7f0055;\"><strong>public</strong></span><span style=\"color:#7f0055;\"><strong> void</strong></span><span style=\"color:#000000;\"> initRowList() {</span></span></span></p>\r\n<p style=\"margin-bottom:0;\"><span style=\"color:#000000;\"><span style=\"font-family:Monospace;\"><span style=\"color:#0000c0;\">rowList </span>= <span style=\"color:#7f0055;\"><strong>new</strong></span> LinkedList&lt;String&gt;();</span></span></p>\r\n<p style=\"margin-bottom:0;\"><span style=\"color:#000000;\"><span style=\"font-family:Monospace;\"><span style=\"color:#7f0055;\"><strong>final </strong></span>Date now = <span style=\"color:#7f0055;\"><strong>new</strong></span> Date();</span></span></p>\r\n<p style=\"margin-bottom:0;\"><span style=\"color:#000000;\"><span style=\"font-family:Monospace;\"><span style=\"color:#0000c0;\">rowList</span>.add(<span style=\"color:#2a00ff;\">\"row1 created on \"</span> + now);</span></span></p>\r\n<p style=\"margin-bottom:0;\"><span style=\"color:#000000;\"><span style=\"font-family:Monospace;\"><span style=\"color:#0000c0;\">rowList</span>.add(<span style=\"color:#2a00ff;\">\"row2 created on \"</span> + now);</span></span></p>\r\n<p style=\"margin-bottom:0;\"><span style=\"color:#000000;\"><span style=\"font-family:Monospace;\"><span style=\"color:#0000c0;\">rowList</span>.add(<span style=\"color:#2a00ff;\">\"row3 created on \"</span> + now);</span></span></p>\r\n<p style=\"margin-bottom:0;\"><span style=\"color:#000000;\"><span style=\"font-family:Monospace;\"><span style=\"font-size:x-small;\">}</span></span></span></p>\r\nPublishing the change to the server and accessing\r\n<a href=\"http://localhost:8080/seamTutorial12/richTable.seam\">http://localhost:8080/seamTutorial12/richTable.seam</a>\r\nagain will finally show the paged table (nearly) as expected. On the\r\nfollowing screenshot you can see both the 1<sup>st</sup> and the 2<sup>nd</sup>\r\npage of the table, the red arrowhead emphasizing the current one:<br><br><img title=\"1st and 2nd page of the table in a browser\" src=\"http://jroller.com/holy/resource/seamTutorial12/Screenshot7-seamTutorial12-3rdRichTable_both_pages_diff_times-Konqueror.png\" alt=\"\" /><br><br>Have you noticed anything strange? Not? Look carefully at the\r\ndates on both pages. You will see that on the first page there is\r\n“row 1 created on Sat Mar 21 0<strong>9:04:27</strong> GMT+01:00 2009”\r\nwhile on the second one “row 3 created on Sat Mar 21 0<strong>9:06:22</strong>\r\nGMT+01:00 2009”. The times differ even though all the rows were\r\ncreated at once in the initRowList method!<br><br>The explanation is obvious: When we move to the 2<sup>nd</sup>\r\npage of the table, it triggers a new request to the server and since\r\nthe data model only lives during a request, a new one was created\r\nwith a new creation time. Coming back to page 1 would show yet later\r\ntime. The solution is of course to keep the list in a longer-living\r\nscope and since we've Seam, the best candidate is the Conversation\r\nscope.\r\n<h3 class=\"western\">Attempt 4: Moving the data model into the\r\nConversation scope to survive across request</h3>\r\nWe want to create the rowList data model only once and then simply\r\naccess this instance when a user moves through the table's pages. The\r\nmotivation is clear – in a normal, non-tutorial scenario we'd load\r\ndata from a database and wouldn't want to repeat this operation over\r\nand over again.\r\n<p style=\"margin-bottom:0;\">You've been nice readers and thus I'll\r\ntell you two important things right away without teasing you.</p><br><br><h4 class=\"western\">Lesson learned 2: POJO Components are in the\r\nEvent (Request) scope by default</h4>\r\nAs opposed to EJB components, plain old Java object components are\r\nstored in the Event scope unless specified otherwise. Don't trust you\r\nfriends, don't be lazy, and check the defaults by yourself :-)<br><br>If you're not sure what scope a component is in, you can check it:\r\n<ul>\r\n\t<li>In Eclipse in the Seam Component view (Window &gt; Show View\r\n&gt; Other &gt; Seam &gt; Seam Components)<br><br><img title=\"Eclipse - Seam Components View\" src=\"http://jroller.com/holy/resource/seamTutorial12/Screenshot8-Eclipse-SeamComponentsView.png\" alt=\"\" /></li>\r\n\t<li>In the server log during startup of a Seam web application,\r\nSeam prints all components it has found together with their scope\r\nand class.</li>\r\n</ul>\r\nTo make the component conversation-scoped, we will modify\r\nRichTable.java as follows:\r\n<p style=\"margin-bottom:0;\"><span style=\"font-family:Monospace;\"><span style=\"font-size:x-small;\"><span style=\"color:#646464;\">@Name</span><span style=\"color:#000000;\">(</span><span style=\"color:#2a00ff;\">\"richTable\"</span><span style=\"color:#646464;\">)\r\n@Scope</span><span style=\"color:#000000;\">(ScopeType.</span><span style=\"color:#0000c0;\"><em>CONVERSATION</em></span><span style=\"color:#7f0055;\">)<strong>\r\npublic </strong></span><span style=\"color:#7f0055;\"><strong>class</strong></span><span style=\"color:#000000;\"> RichTable {</span></span></span></p><br><br><h4 class=\"western\">Lesson learned 3: Conversation scope doesn't\r\nexist and behaves as Event scope unless you start a conversation\r\nexplicitly.</h4>\r\nIt may surprise you (it did surprise me!) but marking a component\r\nas a conversation-scoped is not enough. That's because no\r\nconversation scope actually exists until created explicitly. Normally\r\nSeam creates a new conversation for each request and destroys it when\r\nthe request ends, in the very same way as with the Event scope. To\r\nget a truly long-lived conversation you must start it explicitly.<br><br>You can start a conversation in several ways, usually you do it\r\nwhen an action method is called. But we've no such method, we need a\r\nconversation started as soon as somebody lands on the richTable.seam\r\npage. This is something that can be set in the page configuration\r\nfile. You may have a global pages.xml but we will create a separate\r\nconfiguration file /seamTutorial12/WebContent/richTable.page.xml next\r\nto the page file itself (thanks to the matching names Seam will\r\nunderstand it's for richTable.xhtml):\r\n<pre>&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;\r\n&lt;page xmlns=\"http://jboss.com/products/seam/pages\"\r\n      xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\r\n      xsi:schemaLocation=\"http://jboss.com/products/seam/pages http://jboss.com/products/seam/pages-2.0.xsd\"\r\n      login-required=\"false\"\r\n      &gt;<br><br>      <strong>&lt;begin-conversation join=\"true\"/&gt;</strong>\r\n&lt;/page&gt;</pre>\r\nThe only important line is &lt;begin-conversation join=\"true\"/&gt;\r\nthat tells Seam to start a new or join an existing long-lived\r\nconversation when the page is accessed.\r\n<h4 class=\"western\">Summary</h4>\r\n<ol>\r\n\t<li>We marked the component as belonging to the Conversation\r\nscope applying the annotation <span style=\"color:#646464;\"><span style=\"font-family:Monospace;\"><span style=\"font-size:x-small;\">@Scope</span></span></span><span style=\"color:#000000;\"><span style=\"font-family:Monospace;\"><span style=\"font-size:x-small;\">(ScopeType.</span></span></span><span style=\"color:#0000c0;\"><span style=\"font-family:Monospace;\"><span style=\"font-size:x-small;\"><em>CONVERSATION</em></span></span></span><span style=\"color:#000000;\"><span style=\"font-family:Monospace;\"><span style=\"font-size:x-small;\">)</span></span></span>\r\nin the .java file</li>\r\n\t<li>We requested that a real conversation is started whenever a\r\nusers enters the page richTable.xhtml (.seam) by specifying\r\nbegin-conversation join=\"true\" in a new page configuration\r\nfile richTable.page.xml.</li>\r\n</ol>\r\nNow you can once again go to\r\n<a href=\"http://localhost:8080/seamTutorial12/richTable.seam\">http://localhost:8080/seamTutorial12/richTable.seam</a>\r\nand you will see that the dates within rows do not change anymore no\r\nmatter how you switch the table pages.\r\n<h3 class=\"western\">The final version</h3>\r\nRichTable.java:<br><br><pre><code>package org.domain.seamtutorial12.session;<br><br>import java.util.Date;\r\nimport java.util.LinkedList;\r\nimport java.util.List;<br><br>import org.jboss.seam.ScopeType;\r\nimport org.jboss.seam.annotations.Factory;\r\nimport org.jboss.seam.annotations.In;\r\nimport org.jboss.seam.annotations.Logger;\r\nimport org.jboss.seam.annotations.Name;\r\nimport org.jboss.seam.annotations.Scope;\r\nimport org.jboss.seam.annotations.datamodel.DataModel;\r\nimport org.jboss.seam.faces.FacesMessages;\r\nimport org.jboss.seam.log.Log;<br><br>@Name(&quot;richTable&quot;)\r\n@Scope(ScopeType.CONVERSATION)\r\npublic class RichTable {<br><br>    @Logger private Log log;<br><br>    @In FacesMessages facesMessages;<br><br>    @DataModel\r\n    List&amp;lt;String&amp;gt; rowList;<br><br>    /**\r\n     * We must provide this factory method to init the rowList instead of\r\n     * initiating it e.g. in a constructor because otherwise it would be\r\n     * uninitialized until this component itself - tichTable - is also\r\n     * used by the page using  rowList.\r\n     * &amp;lt;p&amp;gt;\r\n     * See Seam Reference 2.0.2 SP1, chapter 4.8. Factory and manager components.\r\n     */\r\n    @Factory(&quot;rowList&quot;)\r\n    public void initRowList() {\r\n    \trowList = new LinkedList&amp;lt;String&amp;gt;();\r\n    \tfinal Date now = new Date();\r\n    \trowList.add(&quot;row 1 created on &quot; + now);\r\n    \trowList.add(&quot;row 2 created on &quot; + now);\r\n    \trowList.add(&quot;row 3 created on &quot; + now);<br><br>    \tlog.info(&quot;initRowList called at &quot; + now);\r\n    }<br><br>}\r\n</code></pre><br><br>richTable.xhtml:<br><br><pre><code>\r\n&lt;!DOCTYPE composition PUBLIC &quot;-//W3C//DTD XHTML 1.0 Transitional//EN&quot;\r\n                             &quot;http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd&quot;&gt;\r\n&lt;ui:composition xmlns=&quot;http://www.w3.org/1999/xhtml&quot;\r\n                xmlns:s=&quot;http://jboss.com/products/seam/taglib&quot;\r\n                xmlns:ui=&quot;http://java.sun.com/jsf/facelets&quot;\r\n                xmlns:f=&quot;http://java.sun.com/jsf/core&quot;\r\n                xmlns:h=&quot;http://java.sun.com/jsf/html&quot;\r\n                xmlns:rich=&quot;http://richfaces.org/rich&quot;\r\n                xmlns:a=&quot;http://richfaces.org/a4j&quot;\r\n                template=&quot;layout/template.xhtml&quot;&gt;<br><br>&lt;ui:define name=&quot;body&quot;&gt;<br><br>    &lt;h:messages globalOnly=&quot;true&quot; styleClass=&quot;message&quot;/&gt;<br><br>    &lt;rich:panel&gt;\r\n        &lt;f:facet name=&quot;header&quot;&gt;richTable&lt;/f:facet&gt;<br><br>        &lt;h:form&gt;\r\n        \t&lt;rich:dataTable width=&quot;483&quot; id=&quot;myRichTable&quot; rows=&quot;2&quot; columnClasses=&quot;col&quot;\r\n                value=&quot;#{rowList}&quot; var=&quot;row&quot;&gt;<br><br>                &lt;f:facet name=&quot;header&quot;&gt;\r\n                    &lt;rich:columnGroup&gt;\r\n                        &lt;h:column&gt;\r\n                            &lt;h:outputText styleClass=&quot;headerText&quot; value=&quot;A Column&quot; /&gt;\r\n                        &lt;/h:column&gt;\r\n                    &lt;/rich:columnGroup&gt;\r\n                &lt;/f:facet&gt;<br><br>                &lt;h:column&gt;\r\n                    &lt;h:outputText value=&quot;#{row}&quot; /&gt;\r\n                &lt;/h:column&gt;<br><br>            &lt;/rich:dataTable&gt;<br><br>            &lt;rich:spacer height=&quot;30&quot; /&gt;<br><br>            &lt;rich:datascroller id=&quot;richTableScroller&quot; align=&quot;left&quot;  for=&quot;myRichTable&quot; maxPages=&quot;20&quot; /&gt;\r\n         &lt;/h:form&gt;<br><br>    &lt;/rich:panel&gt;<br><br>&lt;/ui:define&gt;<br><br>&lt;/ui:composition&gt;\r\n</code></pre><br><br>richTable.page.xml<br><br><pre><code>\r\n&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;\r\n&lt;page xmlns=&quot;http://jboss.com/products/seam/pages&quot;\r\n      xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;\r\n      xsi:schemaLocation=&quot;http://jboss.com/products/seam/pages http://jboss.com/products/seam/pages-2.0.xsd&quot;\r\n      login-required=&quot;false&quot;\r\n      &gt;<br><br>      &lt;begin-conversation join=&quot;true&quot;/&gt;\r\n&lt;/page&gt;\r\n</code></pre>\r\n<h3 class=\"western\">Troubleshooting tips</h3>\r\n<h4 class=\"western\">RichFaces monitoring and troubleshooting</h4>\r\nThere are two tools you can use for monitoring Ajax requests and\r\nRichFaces behavior. The first one is the RichFaces tag <a href=\"http://www.jboss.org/file-access/default/members/jbossrichfaces/freezone/docs/tlddoc/a4j/log.html\">a:log</a>\r\nthat will display detailed log about what RichFaces is doing, once it\r\nactually starts doing something:<br><br>&lt;a:log level=\"ALL\" popup=\"false\"\r\nwidth=\"400\" height=\"200\"/&gt;<br><br>I've found this tag useful but not sufficient. I also haven't got\r\npopup=true working (likely a mistake on my part).<br><br>With the addition of the Firefox extension <a href=\"http://www.getfirebug.com/\">FireBug</a>,\r\na JavaScript/CSS/... debugger and monitor and one of the best free\r\nweb development tools, you'll have all you need. Notice that you will\r\nfist need to enable FireBug for the site (localhost) to monitor.\r\nBelow you can see FireBug in action observing Post parameters of an\r\nAjax request (tab “XHR”):<br><br><img title=\"FireBug, Firefox extension\" src=\"http://jroller.com/holy/resource/seamTutorial12/Screenshot8-Firefox-FireBug.png\" alt=\"\" />\r\n<h4 class=\"western\">Tracking Seam conversations</h4>\r\nHow do you find out whether an action triggered a new conversation\r\nor remained in an existing conversation? By checking whether the\r\nrequest parameter <em>cid</em> has changed it's number or not or wasn't\r\na part of the request at all. This parameter carries a numerical ID\r\nof the current conversation and is always present and unchanged if a\r\nuser action is within an existing conversation. (But notice above\r\nthat the Ajax request for switching a table page captured by FireBug\r\ndoesn't have any such attribute – perhaps some Seam-RichFaces\r\nmagic.)\r\n<h3 class=\"western\">Summary</h3>\r\nWe have created a conversation scoped Seam component holding a\r\nlist of items that are displayed in a paged RichFaces table. We have\r\nalso learned what the correct version of RichFaces is and how to get\r\nits demo running and about all the steps required to really get a\r\ncomponent into a persistent conversation scope. Additionally we've\r\nfound out what to do when the project's data source isn't deployed\r\ncorrectly to the server and got to know some troubleshooting tools.\r\n<h3>Update 2009-04-21: Hotdeploy Seam app with Maven</h3>\r\nThere is an interesting Maven plugin (under active development) that can perform a hot-deploy of a Seam application to JBoss: <a href=\"http://code.google.com/p/ctpjava/wiki/MavenSeamHotdeployPluginUsage\">Seam Hotdeploy Maven Plugin</a>.\r\n<h3 class=\"western\">Resources</h3>\r\nYou can <a href=\"https://sourceforge.net/project/showfiles.php?group_id=210989&amp;package_id=315228&amp;release_id=669998\">download\r\nthe complete seamTutorial12 Eclipse projects</a>, namely the project\r\nitself and its companion Seam-generated *-test project. Notice that\r\nthe login, home, etc. pages have been generated by Seam and aren't\r\nactually needed for the richTable stuff though their removal would\r\nrequire some modifications.<br><br><strong>PS:</strong> Please excuse the terrible formatting :-(",
  "excerpt": ""
 },
 {
  "title": "The Forgotten Hells or God Save North Korea!",
  "published": "2009-03-19 04:53:12",
  "postType": "post",
  "slug": "/2009/03/19/the-forgotten-hells-or-god-save-no/",
  "status": "publish",
  "tags": [],
  "categories": [
   "General"
  ],
  "content": "<p>I intended this as an exclusively technological blog but after seeing the movie <a href=\"http://yodokfilm.com/\">Yodok Stories</a> yesterday I feel I can't keep silent on the subject. I'm even more touched by the movie because the first years of my life I spent myself in a communist dictatorship though it was already in its last stage and can be by no means compared to the nightmare of Korea.<br /></p><p>&nbsp;On this planet there are hellish places where human life or dignity have no value, where people live in such a suffering, fear, and pain that we perhaps even can not call them human any more. These places are well hidden from our sight though as the recent Fritzl case has shown, it doesn't need to be far away. I'd like to remind the world of two such places because pretending they do not exist only helps them to last longer. It's very good that everybody speaks about the human rights violations in Tibet but there are countries that need our attention even more though they may not be as attractive and &quot;in&quot;.</p><h2>Democratic People's Republic of Korea: The Hell on Earth<br /></h2><p>Simply known as North Korea, this country is a victim of likely the hardest totalitarian regime on the Earth. The inhabitants are cut off from the outside world and would only learn from the state media how great their fatherland, Party, and beloved General Kim Jong-il are. And I'd expect them to believe it because the propaganda is so strong and other voices inexistent that they've no way to resist it. And anyway they've enough trouble with trying to get something to eat (though today is far better than during the famine of 90's that killed 2-3 million people).</p><p>On the bright side you can see mass parades demonstrating the people's happiness and devotion to the country, Party, and the Eternal President and his son. On the dark side there are about 20* concentration camps. They are perhaps the most hellish places on the Earth. One of them you can leave if you are extremely lucky and live to the day, the others are till death. It's estimated that maybe 100 or 200 000* people are imprisoned there, which is a higher number than the estimated size of North Korean elite of cca 150 000* (depends how you count). The Party is uncompromising in its fight against the internal enemy aiming at destroying the happy Republic and therefore if you commit a crime against the country, Party, or President/General, such as telling an unpleasant truth, trying to emigrate, or dishonoring the President, you will be sentenced to detention in a camp together with your children and parents. God be with you then (if there is any in North Korea at all).</p><p>In a camp you are not a human anymore and the only rights you have is the right to suffer and the right to die. You, your little child, and old parents are all class enemies. You will experience constant hunger, cold, health problems, torture, rape. You can trust nobody, nobody will help you, nobody cares about you. You're a class enemy trying to destroy the north Korean communist paradise and therefore you deserve hell and you'll get it.<br /></p><p>* Of course any information about North Korea is uncertain because the regime tries to prevent the truth from coming out and certainly they've the means.<br /></p><h2>Democratic Republic of the Congo: Woman's Nightmare<br /></h2><p>10 years of a civil war torture Congo, supported by battle forces from Rwanda, Zaire, Uganda,&nbsp; Angola, Zimbabwe and Namibia taking the country for a place to exercise their influence and square accounts with one another. </p><p>The poor civilians of Congo are mere amusement for the rolling armies. It's common for a woman to be kidnapped, hold as a sex slave and repeatedly raped until she dies or is perhaps released back to her home village where she's often rejected and cast out by her husband, perhaps with all the children. Actually the term &quot;woman&quot; is misleading. Any female between birth and death is a potential subject to rape (and perhaps death as consequence), now and whenever another military force passes by, being Congolian or foreigner. An older woman was raped by a group of child soldiers that could have been her sons and grandsons. It's a question whether those who die aren't luckier. I'm a man (I must feel ashamed of that) and can hardly imagine the psychological trauma of a woman that has lived through such a terror and that she will carry till the death.<br /></p><h2>Disclaimer</h2><p>I've been neither to a North Korean concentration camp (thanks!!!) nor have I been a raped woman in Kongo and inevitably my information about this is very limited. But my knowledge of the world and of the truth of Nazi and Czech and Soviet concentration camps lead me to believe the worst. During World War II people in America or England were unwilling to believe the brutal truth of concentration camps and Holocaust and of course it's always easy to deny the existence of something unpleasant (barely adequate term!). That's why I cannot deny these things do happen.<br /></p><h2>Links</h2><ul><li>The movie <a href=\"http://yodokfilm.com/\">Yodok Stories</a></li><li><a href=\"http://en.wikipedia.org/wiki/North_Corea\">Wiki: North Korea</a></li><li><a href=\"http://en.wikipedia.org/wiki/Democratic_Republic_of_the_Congo\">Wiki: Congo</a></li><li><a href=\"http://www.amnesty.org/\">Amnesty International</a></li><li>Czech humanitarian organization <a href=\"http://clovekvtisni.cz/indexen.php\">People in Need</a><br /></li><li>Movie <a href=\"http://thegreatestsilence.org/Synopsis.html\">The Greatest Silence</a> <br /></li></ul>",
  "excerpt": ""
 },
 {
  "title": "When will we see JSR 286 in JSF portlets?",
  "published": "2009-03-17 08:38:19",
  "postType": "post",
  "slug": "/2009/03/17/when-will-we-see-jsr-286-in-jsf-po/",
  "status": "publish",
  "tags": [],
  "categories": [
   "Portlets"
  ],
  "content": "<p>Since June 2008 we have the final release of Portlet 2.0 (<a href=\"http://jcp.org/en/jsr/detail?id=286\">JSR 286</a>) specification bringing the long sought after features like inter-portlet communication (IPC - events, shared/public render parameters), support for Ajax (resource request), portlet filters and more. It's already implemented in the latest versions of leading portals including Liferay 5.0, JBoss 2.7, Websphere 6.1 (though you can still encounter some bugs). </p><p>Now we would like to know when the lovers of JSF will be able to profit from these features in their JSF portlets.<br /></p><h2>Current state</h2><p>Currently it's possible to embed a JSF 1.2 application into a <a href=\"http://jcp.org/en/jsr/detail?id=168\">JSR 168</a> portal using a Portlet Bridge 1.0  (<a href=\"http://jcp.org/en/jsr/detail?id=301\">JSR 301</a>). This is all still quite new - JSR 301 is only a proposed final draft as of June 8th 2009. So you can expect that it will take time to see also support for JSR 286 (or the upcoming <a href=\"http://jcp.org/en/jsr/detail?id=314\">JSF 2.0</a>).</p><p>Note: Of course you can run JSF portlet bridge 1.0 applications in JSR 286 compliant portals but won't have an easy access to the new features.<br /></p><h2>Future</h2><p>A specification of&nbsp;<a href=\"https://cds.sun.com/is-bin/INTERSHOP.enfinity/WFS/CDS-CDS_JCP-Site/en_US/-/USD/ViewProductDetail-Start?ProductRef=portlet_2_0_bridge-ea-oth-JSpec@CDS-CDS_JCP\"> Portlet Bridge 2.0</a> that would bring JSR 286 to the JSF world is being born but it's still so young that it even hasn't a JSR number yet. While creating the specification for Portlet Bridge 1.0 took 2-3 years we may hope that 2.0 could be faster as the foundation is already laid by 1.0 but still it will surely take at least half a year, much more likely a year or more. For the time being the only option is to take any of the open source implementations and try to hack the feature you need.</p><p><b>Update</b>: The <a href=\"http://jcp.org/en/jsr/detail?id=329\">JSR for Portlet 2.0 Bridge for JSF 1.2 is #329</a> (thanks, balz).<br /></p><h2> Implementations</h2><p><b>MyFaces</b> Portlet Bridge 2.0, a reference implementation of the new specification being formed, already has some <a href=\"http://myfaces.apache.org/portlet-bridge/2.0/index.html\">alpha code</a>. They're quite ahead of time :-)</p><p>According to some posts <b>WebSphere Portal 6.1</b> implementation of portlet bridge <a href=\"http://www.ibm.com/developerworks/forums/thread.jspa?threadID=230393&amp;tstart=0\">seems to support JSR 286</a> though it is not yet perfect.</p><p><a href=\"http://www.jboss.org/portletbridge/\">JBoss Portlet Bridge</a> (now 1.0.0 beta 6) and <a href=\"https://jsfportletbridge.dev.java.net/\">Sun JSF Portlet Bridge</a> (1.2.3, 8/2008) plan this perhaps in their 2.0 versions. We can also see that the authors of <a href=\"http://jira.icefaces.org/browse/ICE-3419\">ICEFaces plan to incorporate this</a> in v2.0 (currently 1.8.0RC1), but likely all of them depend on the specification coming to some stable state.</p><p>But a limited support is already available, for instance you can use<a href=\"http://blogs.sun.com/deepakg/entry/jsf_portlet_and_public_render\"> public render parameters in JSF Portlet Bridge</a>.</p><h2>Summary</h2><p>It will take at least months to have a JSR 286 enabled Portlet Bridge buth work is already under way.<br /></p>",
  "excerpt": ""
 },
 {
  "title": "Seam Tutorial 1.1: RichFaces and paged table (datascroller)",
  "published": "2009-03-07 06:12:45",
  "postType": "post",
  "slug": "/2009/03/07/seam-tutorial-1-1-richfaces-and-pa/",
  "status": "publish",
  "tags": [
   "jsf",
   "jsr168",
   "jsr286",
   "portlet",
   "RichFaces",
   "seam"
  ],
  "categories": [
   "Portlets"
  ],
  "content": "\tIn this two-part tutorial you will\r\nlearn how to get started with the development of <a href=\"http://www.seamframework.org/\">Seam</a> applications\r\nwith RichFaces using Eclipse with JBoss Tools. In <a href=\"/2009/03/23/seam-tutorial-1-2-richfaces-and-pa/\">the 2<sup>nd</sup>\r\npart</a> we will create a simple page with a table presenting data on\r\nmultiple pages using Ajax and its model stored as a POJO Component in\r\nthe Seam Conversation scope. I assume that you already have some\r\nbasic knowledge of Seam and JSF, for instance that you know what a\r\nComponent or the Conversation scope are.<br><br><p style=\"margin-bottom:0;\">My aim in this tutorial series is to\r\ncreate a Seam portlet displaying data in a paged (and ideally also\r\nsortable and filterable, but let's be realistic) table running in the\r\nLiferay portal. The tutorial will follow my steps with all the dead ends and mistakes so that you too can learn from them.<br /></p><h5 class=\"western\">Why Seam?</h5>\r\n<p>In my opinion, Seam is one of the best application frameworks for\r\nJava web application development. It's not the best one because none\r\nis and it always depends on the task at hand what solution/tool is the most\r\nsuitable one. I like Seam because it integrates so well some of the most\r\npopular and standard or de facto standard technologies (all of them\r\nare optional in a Seam application) including JSF, EJB 3.0, JPA, and\r\nHibernate. Not only does it integrate them but also fixes their\r\nshortcomings (especially in JSF) and adds invaluable features you've\r\nbeen looking for for ages, like the conversation scope, eventing, or\r\nruntime component injection.</p>\r\n<h5 class=\"western\">Why RichFaces?</h5>\r\n<p>The answer is simple: go to <a href=\"http://livedemo.exadel.com/richfaces-demo/richfaces/extendedDataTable.jsf?c=extendedDataTable&amp;tab=usage\">see\r\nthe RichFaces demo</a> :-). RichFaces is a library of good-looking,\r\ndynamic (Ajax) JSF components and support for ajaxifying just about\r\nanything. With RichFaces you can easily create Web 2.0 applications\r\nwith a professional look and feel that let users forget that they're\r\nworking in a browser with a remote server. You can use context menus,\r\nmodal dialogs, sortable, filterable, and pageable tables, rich text\r\neditor, cool visual effects, and more.</p>\r\n<p>RichFaces isn't the only such library, another popular one is\r\nICEfaces, which has been embraced by Sun. But RichFaces is supported\r\nby JBoss and works well with its server, portal, and Seam. Remember I\r\ntold you Seam is an integration framework?</p>\r\n<h5 class=\"western\">Why Liferay portal?</h5>\r\n<p>Though developing portlet applications is considerably more\r\ndifficult than plain old web applications as has been <a href=\"http://www.jroller.com/holy/entry/are_portlets_dead_jsr168_and\">discussed\r\nrecently</a> and as we will certainly yet see, there are also the\r\nbenefits of content integration, unified front-end to applications\r\netc. that sometimes outweigh the problems.</p>\r\n<p>I use Liferay because that's the portal chosen (for the majority\r\nthat can't afford WebSphere Portal) by the bright guys in the portal\r\ngroup of my company, <a href=\"http://www.ibacz.eu/-English-\">IBA CZ</a>.\r\nAnd also because, as a user, I find it more appealing than JBoss\r\nPortal.</p>\r\n<h2 class=\"western\">Environment setup</h2>\r\n<p>You will need the software listed below. Make\r\nsure to have the same versions or&nbsp; unexpected problems may happen (examples\r\nlater).</p>\r\n<ul><li><p><a href=\"http://downloads.sourceforge.net/jboss/jboss-portal-2.7.1.zip?modtime=1232471311&amp;big_mirror=1\">JBoss Portal 2.7.1</a>\r\n (with bundled JBoss AS 4.2.3)</p>\r\n\t</li><li><p><a href=\"http://java.sun.com/javase/downloads/index_jdk5.jsp\">JDK 1.5</a> (mine is jdk1.5.0_17 )\r\n</p>\r\n\t</li><li><p align=\"left\"><a href=\"https://sourceforge.net/project/showfiles.php?group_id=22866&amp;package_id=163777&amp;release_id=602455\">Seam 2.0.2 SP1</a> (I've preferred this to the latest 2.1.1 GA as it works better with JBoss Tools)It's already bundled with RichFaces, no separate download of them needed.</p><ul><li>Check the unpacked folder - there most interesting things are the documentation example applications.<br /></li></ul></li><li>Eclipse Ganymede for Java EE v. <a href=\"http://www.eclipse.org/downloads/packages/eclipse-ide-java-ee-developers/ganymedesr1\">3.4.1</a> (SR1) though you can prefer to try your luck with the <a href=\"http://www.eclipse.org/downloads/packages/\">latest one</a> (3.4.2 as of today).<br /></li><li><p>JBoss Tools as of 2008-12-19  - Seam Tools and JBoss Tools RichFaces 3.0.0\r\n\tCR1-R200, JBossAS Tools 2.0.0 CR1-R200, JBoss Portlet 1.0.0 CR1-R200, plus some others. I've installed them via Eclipse Update Manager (Help &gt; Software Updates) from the update site http://download.jboss.org/jbosstools/updates/development/ Today it contains an updated version CR2 from 2009-01-28. You can install an older version after unchecking &quot;Show only the latest versions ...&quot;<br /></p></li></ul>\r\n<p>For the sake of completeness I should say that I'm developing\r\nunder Linux, namely Ubuntu 8.04 Hardy.</p>\r\n<p>I won't describe how to install Eclipse and JBoss Tools, you'll\r\nsurely manage that :-). The other items you can just download and\r\nunpack somewhere. for example to /tmp/tutorial/.</p>\r\n<h2 class=\"western\">Eclipse preparation</h2>\r\n<p>After having installed Eclipse and its JBoss Tools plugins:</p>\r\n<ol><li><p>Let Eclipse know about the JDK 1.5: Window &gt; Preferences &gt;\r\n\tJava &gt; Installed JREs &gt; Add... &gt; Standard VM &gt; enter\r\n\tpath to the unpacked JDK etc. <br />Name it “<i>jholy-jdk1.5.0_17</i>”<span> (sorry, I was lazy to rename mine for this tutorial).</span></p>\r\n\t</li><li><p>Let Eclipse know about the JBoss server: Window &gt;\r\n\tPreferences &gt; Server &gt; Runtime Environments &gt; Add... &gt;\r\n\tselect JBoss, a division of Red-Hat – JBoss 4.2 runtime, ...,\r\n\tbrowse to/enter the directory where you unpacked JBoss to\r\n\t(/tmp/tutorial/jboss-portal-2.7.1/), and make sure select the previously defined\r\n\tJRE (JDK) 1.5. &quot;jholy-jdk1.5.0_17&quot;.<br />Name it “<i>JBoss 4.2.3 Runtime and Portal\r\n\t2.7.1</i>”.</p>\r\n</li></ol>\r\n<h2 class=\"western\">Creating the project</h2>\r\n<p>Create the project: <i>File &gt; New &gt; Project &gt; Seam &gt; Seam\r\nWeb Project</i></p><br><br><ul><li><p>Project name: <i>seamTutorial1<br /></i><span style=\"font-style:normal;\">Note:\r\n\tSeam requires the project name to start with a lower-case letter.</span></p>\r\n\t</li><li><p>Target Runtime: <i>JBoss 4.2.3 Runtime and Portal 2.7.1</i>\r\n\t</p>\r\n\t</li><li><p>Dynamic Web Module Version: 2.5</p>\r\n\t</li><li><p>Target Server: click New &gt; select JBoss AS 4.2, enter\r\n\tServer name <i>JBoss_4.2.3</i>, select the recently defined Server runtime environment\r\n\t<i>JBoss 4.2.3 Runtime and Portal 2.7.1</i>, click Next &gt;, enter\r\n\tName <i>JBoss_4.2.3</i>, Next, Finish.</p>\r\n\t</li><li><p>Configuration: select <i>Dynamic Web Project with Seam 2.0</i>\r\n\t(and not the default 1.2). <br /></p>\r\n</li></ul>\r\n<p><img vspace=\"0\" hspace=\"0\" border=\"0\" align=\"baseline\" alt=\"Screenshot - NewSeamProject 1 (Seam Web Project)\" src=\"http://jroller.com/holy/resource/seamTutorial1/Screenshot-NewSeamProject1.png\" /></p>\r\n<p>Click Next, don't modify anything</p>\r\n<p><img vspace=\"0\" hspace=\"0\" border=\"0\" align=\"baseline\" alt=\"Screenshot - NewSeamProject 2 (Web Module)\" src=\"http://jroller.com/holy/resource/seamTutorial1/Screenshot-NewSeamProject2.png\" /></p>\r\n<p>Click Next, don't modify anything</p>\r\n<p><img vspace=\"0\" hspace=\"0\" border=\"0\" align=\"baseline\" alt=\"Screenshot - NewSeamProject 1 (JSF Capabilities)\" src=\"http://jroller.com/holy/resource/seamTutorial1/Screenshot-NewSeamProject3.png\" /></p><br><br><p>Click Next to get to the Seam Facet page:</p>\r\n<ul><li><p>Seam Runtime: click Add..., browse to the directory where you\r\n\tunpacked Seam to (/tmp/tutorial/jboss-seam-2.0.2.SP1/), give it the\r\n\tname jboss-seam-2.0.2.SP1 and set version to 2.0.</p>\r\n\t</li><li><p>Deploy as: WAR</p>\r\n\t</li><li><p>Database</p>\r\n\t<ul><li><p>Database Type: Derby</p>\r\n\t\t</li><li><p>Connection profile: click New... &gt; select Derby, enter\r\n\t\tName <i>SeamTutorial1Derby</i>, Next &gt;, from Drivers select\r\n\t\t“Derby Embedded JDBC Driver 10.2 Default” (if you haven't it\r\n\t\tthere, download it and add it via the small (+) icon), enter a\r\n\t\tnon-existent folder as the Database location (e.g.\r\n\t\t/tmp/tutorial/SeamTutorial1Derby), User name <i>sa</i>, leave the password\r\n\t\tempty</p>\r\n\t\t<ul><li><p>Test Connection. This will fail if the database location\r\n\t\t\tfolder already exists otherwise it says Ping succeeded!</p>\r\n\t\t\t</li><li><p>Finish the connection profile creation.<br /></p>\r\n\t\t</li></ul>\r\n\t</li></ul>\r\n\t</li><li><p>Leave the other fields as they are and click Finish to finish the new Seam project wizard.<br /></p>\r\n</li>\r\n</ul><br><br><p><img vspace=\"0\" hspace=\"0\" border=\"0\" align=\"baseline\" alt=\"Screenshot - NewSeamProject 4 (Seam Facet)\" src=\"http://jroller.com/holy/resource/seamTutorial1/Screenshot-NewSeamProject4.png\" /></p><br><br><p>Two new projects are created: seamTutorial1 and\r\nseamTutorial1-test. The project seamTutorial1 contains quite a\r\nhandful of files:</p><br><br><p><img vspace=\"0\" hspace=\"0\" border=\"0\" align=\"baseline\" alt=\"Screenshot - Package Explorer view of the project seamTutorial1\" src=\"http://jroller.com/holy/resource/seamTutorial1/Screenshot-NewSeamTutorial1-PackageExplorer.png\" /></p><br><br><p>Open the Seam perspective: <i>Window &gt; Open &gt; Other... &gt;\r\nSeam</i>. This gives you some useful views, including Seam Components (shows name, scope) and (for page development) JBoss Tools Palette. I'd recommend you to open also JBoss Server View to view and manage your JBoss and Tomcat servers.<br /></p><h2 class=\"western\">Running the generated application</h2>\r\n<p>Attempt 1:</p>\r\n<ul><li><p>Right-click on the file  seamTutorial1/WebContent/home.xhtml &gt; Run As &gt; Run on Server &gt; select Choose an\r\n\texisting server and select the previously defined JBoss_4.2.3.</p>\r\n\t</li><li><p>Click Next, you should see the page Add and Remove Projects\r\n\twith the Configured projects\r\n\tseamTutorial1/resources/seamTutorial1-ds.xml and seamTutorial1,\r\n\tclick Finish.</p>\r\n\t</li><li><p>There may be the warning “The connection was refused when\r\n\tattempting to contact localhost:8080”. That's nothing to worry\r\n\tabout, the browser is just faster than the server.</p>\r\n\t</li><li><p>A Console view should pop up where you can see the log of the\r\n\tstarting JBoss application server.</p>\r\n\t<ul><li><p>If you see there errors similar\r\n\t\tto<br /><font color=\"#000000\"><font face=\"Monospace\"><font size=\"2\">UnsupportedOperationException:\r\n\t\tsetProperty must be overridden by all subclasses of\r\n\t\tSOAPMessage.</font></font></font><br />then you haven't been attentive<span style=\"background:rgb(255,255,0) none repeat scroll 0 0;\"></span> enough and are\r\n\t\trunning the server with Java 1.6 instead of 1.5. Either switch to\r\n\t\t1.5 or read the release notes of JBoss to learn how to fix this.</p>\r\n\t\t</li><li><p>You may see there <br /><font color=\"#000000\"><font face=\"Monospace\"><font size=\"2\">IllegalArgumentException:\r\n\t\tException setting property org.jboss.seam.core.init.jndiPattern on\r\n\t\tcomponent org.jboss.seam.core.init. Expression @jndiPattern@\r\n\t\tevaluated to null.</font></font></font></p>\r\n\t\t<ul><li><p style=\"margin-bottom:0;\">Seam applications are prepared for\r\n\t\t\tbeing deployed by Ant, which would replace the token @jndiPattern@ in\r\n\t\t\tcomponents.xml with a correct value. Unfortunately this version of\r\n\t\t\tJBoss Tools forgets to do it so you must do it manually.</p>\r\n\t\t\t</li><li><p style=\"margin-bottom:0;\">Replace the token @jndiPattern@\r\n\t\t\tin components.xml with a valid expression, for example #{ejbName}/local.\r\n\t\t\tSee Seam reference, chapter <a href=\"http://docs.jboss.com/seam/2.0.2.SP1/reference/en-US/html/configuration.html#d0e15261\"><i>26.1.5. Integrating Seam with your\r\n\t\t\tEJB container</i></a>.<br />Or better change the project's build path to WebContent/WEB-INF/classes to get this token replaced with a valid value automatically, see the update from 2009-03-23 at the end of this post.<br />\r\n</p>\r\n\t\t</li></ul>\r\n\t</li></ul>\r\n</li></ul>\r\n<p>Attempt 2:</p>\r\n<ul><li><p>Start the application as before. It may take over 7 minutes,\r\n\tget a cup of tee. You might notice in the Console view that Seam\r\n\tprints name, scope, and type of each installed component. The\r\n\tinteresting lines there are:<br /><font color=\"#000000\"><font face=\"Monospace\"><font size=\"2\">INFO\r\n\t [Server] JBoss (MX MicroKernel) [4.2.3.GA (build:\r\n\tSVNTag=JBoss_4_2_3_GA date=200807181417)] Started in\r\n\t4m:45s:459ms<br />...<br />INFO  [TomcatDeployer] deploy,\r\n\tctxPath=/seamTutorial1, warUrl=...<br />INFO  [ServletContextListener]\r\n\tWelcome to Seam 2.0.2.SP1<br />...<br />INFO  [SeamFilter] Initializing\r\n\tfilter: org.jboss.seam.debug.hotDeployFilter</font></font></font> (the last line)<br /></p>\r\n\t</li><li><p style=\"margin-bottom:0;\">Enter the address\r\n\t<a href=\"http://localhost:8080/seamTutorial1\">http://localhost:8080/seamTutorial1</a>\r\n\tto your browser. It may take a couple of minutes to load.</p>\r\n</li></ul><br><br><p><img vspace=\"0\" hspace=\"0\" border=\"0\" align=\"baseline\" alt=\"Screenshot -  seamTutorial1's home.xhtml running in Firefox\" src=\"http://jroller.com/holy/resource/seamTutorial1/Screenshot-seamTutorial1_home-Firefox.png\" /></p><br><br><h2 class=\"western\">Request for feedback</h2><p class=\"western\">If you find anything inaccurate or not enough clear in this tutorial or if you encounter some other problems that you would like to share with others to help them avoid these, please let me know. Make the continuous improvement through collaboration possible :-).<br /></p><h2 class=\"western\">Summary</h2>\r\n<p>We have set up a Seam development environment, overcame some\r\nproblems, and managed to get a simple application running.</p>\r\n<p>In the next part we will develop our own conversation-scope\r\nComponent and a page with a RichFaces paged table.</p><h3>Update 2009-03-23 <br /></h3><h4>Replacing&nbsp;<font color=\"#000000\"><font face=\"Monospace\"><font size=\"2\"> <font size=\"3\">@jndiPattern@ </font></font></font></font>with a valid value in the correct way</h4><p>During the first deploy we've got the following error:</p><p><font color=\"#000000\"><font face=\"Monospace\"><font size=\"2\">IllegalArgumentException:\r\n\t\tException setting property org.jboss.seam.core.init.jndiPattern on\r\n\t\tcomponent org.jboss.seam.core.init. Expression @jndiPattern@\r\n\t\tevaluated to null.</font></font></font> <br /></p><p>As Dan Allen has pointed out, the token @jndiPattern@ should be replaced by Seam in runtime using the property jndiPatter from components.properties. And actually this property is defined in the project's src/main/components.properties as jndiPattern=\\#{ejbName}/local ('\\' tells the properties that the # isn't a comment start). So why it doesn't replace the token? It turns out that the project has its compile path set incorrectly and a likely side effect is that this file isn't deployed to the server. </p><p>To fix it, In Project &gt; Properties &gt; Java Build Path &gt; Source change the Default output folder from seamTutorial1/build/classes to seamTutorial1/WebContent/WEB-INF/classes. After a redeployment, everything is suddenly working.<br /></p><p> By the way I really recommend you reading Allen's article about <a href=\"http://www.jsfcentral.com/articles/speed_up_your_jsf_app_1.html\">improving Seam application performance</a>.<br /></p><h4><br /></h4>",
  "excerpt": ""
 },
 {
  "title": "JSF: NullPointerException at FacesServlet.init line 144 / Can''t parse faces-config.xml - SocketException",
  "published": "2009-02-13 14:00:47",
  "postType": "post",
  "slug": "/2009/02/13/jsf-nullpointerexception-at-facess/",
  "status": "publish",
  "tags": [],
  "categories": [
   "j2ee"
  ],
  "content": "<h4>Problem <br /></h4><p>When deploying JSF 1.1 application to WebSphere 6.0 I got the following not much helpful exception: <br />\n</p><pre>java.lang.NullPointerException<br />        at javax.faces.webapp.FacesServlet.init(FacesServlet.java:144)</pre><p>Checking SystemErr.log revealed the following explanation: <br /></p><pre>javax.faces.FacesException: Can't parse configuration file:file:/usr/WebSphere/AppServer/profiles/profileNode1/installedApps/<br />a25ciwas005Network/jholy-GroovyConsole_temp.ear/GroovyConsole.war/WEB-INF/faces-config.xml<br />...<br />Caused by: java.net.SocketException: Connection timed out:could be due to invalid address</pre>\n<p>The explanation is that the XML parser cannot access http://java.sun.com/dtd/web-facesconfig_1_1.dtd referenced from the config file, presumabely due to firewall setup.</p><p>I should say that I've&nbsp; jsf-api.jar and jsf-impl.jar in the webapp.<br /></p><h4>Solution</h4><p>The solution is either to provide the DTD locally or perhaps to remove the &lt;!DOCTYPE ..&gt; declaration from the file. I've </p><p>1. downloaded the dtd and put it to WEB-INF/web-facesconfig_1_1.dtd and </p><p>2. modified the doctype declaration as follows:</p><p>\n</p><pre><span class=\"doctype\">&lt;!DOCTYPE faces-config SYSTEM &quot;web-facesconfig_1_1.dtd&quot;&gt;</span></pre><p>Voila, few hours of wasted time and problem is solved. I wish the responsible developer has thought a bit more.</p>",
  "excerpt": ""
 },
 {
  "title": "Are portlets dead? JSR168 and JSR286 versus reality.",
  "published": "2009-01-24 08:41:40",
  "postType": "post",
  "slug": "/2009/01/24/are-portlets-dead-jsr168-and-jsr28/",
  "status": "publish",
  "tags": [],
  "categories": [
   "Portlets"
  ],
  "content": "<p>Eric Spiegelberg, an experienced JEE and portlet developer, evaluates in his article <a href=\"http://today.java.net/pub/a/today/2009/01/20/jsr-286-portlet-irrelevance.html\">JSR-286: The Edge of Irrelevance</a> the changes brought to the portlet community by the &quot;new&quot; JSR 286 and comes to the sad conclusion that the portlet technology has missed its chance and is declining in interest and momentum and JSR 286 won't change that. Only rarely do the benefits of this technology outweigh the additional complexity, restricted programming model, and other drawbacks. He explains his opinions and gives reasons for them pretty well and I can only agree.</p><p>Some of the points we can make here are:</p><ul><li>The specification, when finally released, is already outdated. JSR168 needed nearly two years to reach the final release in Oct 2003, JSR286 released in Jan 2008 over two years. Add the time needed by portal vendors to implement it and to remove initial bugs and when you finally get to use it in production it lags like three years behind the present world. As Eric puts it: &quot;<i>Reading between the lines, this means that the stated primary goal\nof the recently released JSR-286 is to align itself with the latest\nand greatest Enterprise Java technology of 2003.</i>&quot;<br /></li><li>Portlet developers are 2nd class citizens, all the progress goes on in the web application space and they always have to wait for the &quot;goodies&quot; like JSF, Ajax, GWT, and when they finally get them - maybe after a year or years of delay - their integration into portlets/portals is usually at least flawed.</li><li>There is a portlet specification but no portal specification. If you want to build nontrivial (multi)portlet applications you will usually need to use your vendor's legacy portal API to do necessary things otherwise not possible, loosing the already uncertain benefit of portability.</li><li>Portlets are more difficult to learn and develop and a developer is more restricted than in a standalone web application. Eric writes: &quot;<i>Professional hands-on experience along with the above research\nled me to the conclusion that the portal architecture lacks\nenough technical advantages and distinguishing features to warrant\nan increase in acceptance. In practice, few applications can\nconstrain themselves to the isolated and disparate functionality of\nportlets, and relinquishing this degree of architectural control is\nunrealistic in enterprise-level software.</i>&quot; </li><li>Interest in portlets is clearly declining. As Eric finds out, &quot;<i>18 out of\n24 (75 percent) organizations that officially supported JSR-168 in\n2003 do not officially support JSR-286 today</i>&quot;.</li></ul><p>It's a pity that portals and portlets aren't easier to use and haven't made it into the mainstream, the abilities of content aggregation, personalization, uniform security etc. are promising and as we can see in the rise of personal mashups like iGoogle, the fundamental ideas behind portals are still valid and extremely attractive. I hope that some mashup technology will soon provide a viable, light-weight alternative to portals.</p><p>For the sake of completness I should say that I'm currently working on &quot;portletization&quot; of an application and that I spent some time on a JSR 168 portlet for WebSphere project.<br /></p>",
  "excerpt": ""
 },
 {
  "title": "Eclipse 3.4: New Update Manager and broken Extension Locations",
  "published": "2009-01-21 11:21:49",
  "postType": "post",
  "slug": "/2009/01/21/eclipse-3-4-new-update-manager-and/",
  "status": "publish",
  "tags": [],
  "categories": [
   "eclipse"
  ],
  "content": "<p>In Eclipse prior to 3.4 you could have a number of external &quot;Extension Locations&quot; for plugins/features you didn't want in the Eclipse installation directory or that you wanted to share among multiple Eclipse installations. In the Update Manager wizard you could have even selected that you want a plugin installed into a particular extension location. Since Eclipse 3.4 (Ganymede) this isn't possible anymore.</p><h3>Problem 1: Links to the external Extension Locations are ignored</h3><p>Prior to 3.4 you could have directories with plugins and features (extension locations) outside of the Eclipse installation directory ($ECLIPSE_HOME). To let Eclipse know about them you created a file in the directory $ECLIPSE_HOME/links/ containing the text path=/path/to/your/extension/location. Unfortunately Eclipse 3.4 ignores these links. But nothing is lost - move them into the new directory $ECLIPSE_HOME/dropins/ .</p><p>Actually you don't need to have only link files in the dropins directory, you can have there individual packed (.jar) or unpacked plugins or complete extension locations (eclipse/...) either directly under dropins/ or in some subdirectory, e.g. dropins/jboss-tools/eclipse/... .<br /></p><h3>Problem 2: The new update manager doesn't let me select where to install plugins</h3><p>The new plugins management (also known as provisioning system) installation wizard doesn't let you select where to install the downloaded plugins. It should support something called Bundle pools, that is shared plugin installation folders that can be used by multiple installations of Eclipse but the current user interface doesn't provide any such options and it also may not be exactly what you need.</p><p>If you don't want to simly forget about installing plugins outside of Eclipse itself, there is a solution - you may re-enable the old Update Manager and proceed as you're used to. To enable the Update Manager go to Window &gt; Preferences &gt; General &gt; Capablilities and check Classic Update. If you don't see the option Capabilities (e.g. if you've the Java EE Eclipse package) then you can:</p><p>1. Either Open the Help window and search for “Manage configuration”, then select ”  Enabling, disabling, and uninstalling features”. The help window gives a link to “Help &gt; Software Updates &gt; Manage Configuration.” (<a href=\"http://dayg.wordpress.com/2008/06/26/eclipse-34-ganymede-managing-extension-locations/#comment-285\">by Ronan</a>);</p><p>2. Or install Eclipse SDK and restart Eclipse.</p><h2>Mum, why did all this happen?</h2><p>All this happened because the old plugin management stuff was replaced by a more clever and capable <a href=\"http://wiki.eclipse.org/Equinox_p2_Getting_Started\">new provisioning system Equinox/p2</a>. I'd recommend you to read its <a href=\"http://wiki.eclipse.org/Equinox_p2_Getting_Started\">Getting Started</a> guide. You can learn there about the new directories dropins/ and p2/, about Bundle Pooling (sharing of plugins among Eclipses) and other features.<br /></p>",
  "excerpt": ""
 },
 {
  "title": "Migrating from JRoller to Wordpress",
  "published": "2010-05-22 17:56:27",
  "postType": "post",
  "slug": "/2010/05/22/migrating-from-jroller-to-wordpress/",
  "status": "publish",
  "tags": [
   "export",
   "groovy",
   "import",
   "jroller",
   "migrate",
   "migration",
   "wordpress"
  ],
  "categories": [
   "General"
  ],
  "content": "This post describes how to migrate a blog from <a href=\"http://jroller.com/\">JRoller.com</a> to WordPress.com. The steps are:\r\n<ol>\r\n\t<li>Backup JRoller via the util by La tortue cynique</li>\r\n\t<li>Export from WP</li>\r\n\t<li>Convert JRoller to a fragment of the WP format</li>\r\n\t<li>Add proper header and footer to the generated WP import file</li>\r\n\t<li>[optional] download images, perhaps upload them somewhere and modify URLs accordingly</li>\r\n\t<li>Import it into WP</li>\r\n\t<li>Check formatting, add tags...</li>\r\n</ol>\r\n<!--more-->\r\n<h2>0. Introduction</h2>\r\nI decided to move my blog from JRoller to Wordpress, especially because I missed a lot an easy blog backup tool, the platform is not managed actively (e.g. not updated in ages) and because I desired for an easy way to post source codes, which WordPress' shortcode [<a href=\"http://en.support.wordpress.com/code/posting-source-code/\">sourcecode</a>] makes possible (though sometimes it gets a bit confused). This blog describes the process to move a blog from JRoller to WP.\r\n<h2>1. Backup JRoller</h2>\r\nFollow the instructions at La tortue cynique - <a href=\"http://www.jroller.com/kame/entry/export_and_backup_your_jroller\">Export and backup your JRoller blog</a> . Namely:\r\n<ol>\r\n\t<li>Create a \"backup template\" called tetsuwan with content from the<em> jroller_atom_feed.tpl</em> included in the archive you can download from the La tortue's blog</li>\r\n\t<li>Run La tortue's backup java class with URL of this template, which <span style=\"text-decoration:underline;\">must be</span> in the form <em>http://jroller.com/page//tetsuwan </em>\r\n<ul>\r\n\t<li>Notice that the URL <span style=\"text-decoration:line-through;\">http://jroller.com//page/tetsuwan</span> would also work but accessing older entries by appending the date would not</li>\r\n\t<li>A single page displays at most the number of entries determined by the value of the configuration property \"Number of entries to display on weblog\" under Preferences / Settings, which can be set at most to 30. The downloader makes use of the fact that appending a date to a properly formatted URL returns entries not older than the date (such as http://jroller.com/page/holy/tetsuwan/20090121). See the <a href=\"http://archive.apache.org/dist/roller/roller-3/v3.1.0/docs/roller-user-guide.pdf\">Roller 3.1 user guide</a> - section 3.2.3 - Finding old entries using the pages of your weblog - point 3: Using URLs.</li>\r\n\t<li>Notice that URLs like http://jroller.com/page/holy/tetsuwan/20090121 are redirected to http://jroller.com/holy/page/tetsuwan?date=20090121 (anyway they work).</li>\r\n</ul>\r\n</li>\r\n\t<li>[optional] Merge the downloaded jroller_bak*.xml files into one if the program hasn't done that (for me it failed with StringIndexOutOfBoundsException, perhaps because the last page accessed had no blogs to show)\r\n<ul>\r\n\t<li>You may but don't need to merge all your your posts and commens into a single file, it's possible to import them into WordPress in sequence - which is great if any one would cross the WP's import file size (currently 15MB, I believe)</li>\r\n</ul>\r\n</li>\r\n</ol>\r\n<h2>2. Export from WP</h2>\r\nExport your current posts, pages, comments etc. from WordPress - we will need the header and footer of the export file and it's also a good idea to have a backup :-)<br><br>Login, go to the Dashboard, expand the Tools sections and click Export.\r\n<h2>3. Convert JRoller to a fragment of the WP format</h2>\r\nI've created a <a href=\"http://groovy.codehaus.org/\">Groovy</a> (a Java-like scripting language) script that converts the posts and comments exported from JRoller into a fragment of the WordPress export format (WXR). This fragment will only contain a list of &lt;item&gt;s representing your posts with comments embedded as &lt;wp:comment&gt;s. You will then need to add a proper header and footer to turn it into a valid import file.<br><br>Among others, the script tries to fix problems with tags within &lt;pre&gt;...&lt;/pre&gt;, namely it replaces &lt;br&gt; with a new line because this tag would be simply stripped by WP.<br><br>How to use it:\r\n<ol>\r\n\t<li><a href=\"http://groovy.codehaus.org/Download\">Download Groovy</a> 1.7.2 or higher, unpack it, run the Groovy console GUI (bin/groovyConsole[.bat]), paste there the script provided below</li>\r\n\t<li>Modify the configuration, namely  change <em>inputFileUrl</em> to point to your JRoller backup file, <em>outputFilePath</em> to where you want to store the output, and <em>defaultAuthor</em> to your WP user name\r\n<ul>\r\n\t<li>Note: The base url for  is not important as it will be replaced with the target blog's URL.</li>\r\n</ul>\r\n</li>\r\n\t<li>Run the script in the Groovy console (Script -&gt; Run); it should log something into the output window and the output file should be created</li>\r\n</ol>\r\nThe conversion  Groovy script (the code highlight isn't perfect, especially regarding multiline strings, you'd see it better in the Groovy console):<br><br><pre><code>\r\n// CONVERT JROLLER BACKUP TO WORDPRESS WXR FRAGMENT\r\n// CONFIGURATION SECTION ######################\r\nfinal int basePostId = 100 // I belive this isn't importatn as WP will assign an ID it sees fit...\r\nfinal String inputFileUrl = &quot;file:///tmp/jroller_bak1.xml&quot;\r\nfinal String outputFilePath = &quot;/tmp/wordpress_import-items_only-1.xml&quot;\r\nfinal String defaultAuthor = &quot;theholyjava&quot;\r\n// /CONFIGURATION SECTION ######################<br><br>// vars: entry, postId, postBody, postName, category, postDate\r\n// NOTE: WP uses regular expressions to read the input, not a XML parser =&gt; it's essential to keep the proper format including spaces etc.\r\ndef entryTplTxt = &quot;&quot;&quot;\r\n&lt;item&gt;\r\n&lt;title&gt;\\${entry.title}&lt;/title&gt;\r\n&lt;link&gt;/\\${postDate.format(&quot;yyyy/MM/dd&quot;)}/\\${postName}/&lt;/link&gt;\r\n&lt;pubDate&gt;\\${postDate.format(&quot;EEE, dd MMM yyyy HH:mm:ss&quot;)} +0000&lt;/pubDate&gt;\r\n&lt;dc:creator&gt;&lt;![CDATA[${defaultAuthor}]]&gt;&lt;/dc:creator&gt;\r\n&lt;category&gt;&lt;![CDATA[\\${category}]]&gt;&lt;/category&gt;\r\n&lt;category domain=&quot;category&quot; nicename=&quot;\\${category.toLowerCase()}&quot;&gt;&lt;![CDATA[\\${category}]]&gt;&lt;/category&gt;\r\n&lt;guid isPermaLink=&quot;false&quot;&gt;&lt;/guid&gt;\r\n&lt;description&gt;&lt;/description&gt;\r\n&lt;content:encoded&gt;&lt;![CDATA[\\${postBody}]]&gt;&lt;/content:encoded&gt;\r\n&lt;excerpt:encoded&gt;&lt;![CDATA[]]&gt;&lt;/excerpt:encoded&gt;\r\n&lt;wp:post_id&gt;\\$postId&lt;/wp:post_id&gt;\r\n&lt;wp:post_date&gt;\\${postDate.format(&quot;yyyy-MM-dd HH:mm:ss&quot;)}&lt;/wp:post_date&gt;\r\n&lt;wp:post_date_gmt&gt;\\${postDate.format(&quot;yyyy-MM-dd HH:mm:ss&quot;)}&lt;/wp:post_date_gmt&gt;\r\n&lt;wp:comment_status&gt;open&lt;/wp:comment_status&gt;\r\n&lt;wp:ping_status&gt;open&lt;/wp:ping_status&gt;\r\n&lt;wp:post_name&gt;\\${postName}&lt;/wp:post_name&gt;\r\n&lt;wp:status&gt;publish&lt;/wp:status&gt;\r\n&lt;wp:post_parent&gt;0&lt;/wp:post_parent&gt;\r\n&lt;wp:menu_order&gt;0&lt;/wp:menu_order&gt;\r\n&lt;wp:post_type&gt;post&lt;/wp:post_type&gt;\r\n&lt;wp:post_password&gt;&lt;/wp:post_password&gt;\r\n&lt;wp:is_sticky&gt;0&lt;/wp:is_sticky&gt;\r\n&quot;&quot;&quot; // close it with '&lt;/item&gt;' after adding comments!<br><br>// vars: comment, commentId &gt;= 1\r\ndef commentTplTxt = &quot;&quot;&quot;\r\n&lt;wp:comment&gt;\r\n&lt;wp:comment_id&gt;\\$commentId&lt;/wp:comment_id&gt;\r\n&lt;wp:comment_author&gt;&lt;![CDATA[\\${comment.author.name}]]&gt;&lt;/wp:comment_author&gt;\r\n&lt;wp:comment_author_email&gt;\\${comment.author.email}&lt;/wp:comment_author_email&gt;\r\n&lt;wp:comment_author_url&gt;\\${comment.author.url}&lt;/wp:comment_author_url&gt;\r\n&lt;wp:comment_author_IP&gt;&lt;/wp:comment_author_IP&gt;\r\n&lt;wp:comment_date&gt;\\${postDate.format(&quot;yyyy-MM-dd HH:mm:ss&quot;)}&lt;/wp:comment_date&gt;\r\n&lt;wp:comment_date_gmt&gt;\\${postDate.format(&quot;yyyy-MM-dd HH:mm:ss&quot;)}&lt;/wp:comment_date_gmt&gt;\r\n&lt;wp:comment_content&gt;&lt;![CDATA[\\${comment.content}]]&gt;&lt;/wp:comment_content&gt;\r\n&lt;wp:comment_approved&gt;1&lt;/wp:comment_approved&gt;\r\n&lt;wp:comment_type&gt;&lt;/wp:comment_type&gt;\r\n&lt;wp:comment_parent&gt;0&lt;/wp:comment_parent&gt;\r\n&lt;wp:comment_user_id&gt;0&lt;/wp:comment_user_id&gt;\r\n&lt;/wp:comment&gt;\r\n&quot;&quot;&quot;<br><br>def engine = new groovy.text.SimpleTemplateEngine()\r\ndef entryTpl = engine.createTemplate(entryTplTxt)\r\ndef commentTpl = engine.createTemplate(commentTplTxt)<br><br>def blog = new XmlSlurper(false,false).parse(inputFileUrl)\r\ndef output = new File(outputFilePath)\r\noutput.createNewFile()\r\n//assert 30 == blog.entry.size() : &quot;actual: ${blog.entry.size()}&quot;<br><br>// turn a post title into a string that can be used in the post's URL\r\nprivate String makePostName(String title, int postId, Set postNameSet) {<br><br>        def postName = java.net.URLEncoder.encode(\r\n            title.replaceAll(&quot;\\\\s&quot;, &quot;-&quot;)\r\n            ,&quot;UTF-8&quot;)\r\n            .replaceAll(&quot;%..&quot;,&quot;&quot;);\r\n        postName = postName.substring(0,Math.min(34, postName.length())).toLowerCase()<br><br>        // Ensure postName is unique:\r\n        while (! postNameSet.add(postName)) {\r\n            postName = postId + postName.substring(0, postName.length()-2)\r\n        }<br><br>        return postName\r\n}<br><br>// replace &lt;br&gt; and other formatting markup within &lt;pre&gt; segment with \\n, ' ' etc.;\r\n// WP would drop &lt;br&gt; thus destroying the formatting\r\nprivate String fixMarkupWithinPre(final String postContent) {\r\n        return postContent.replaceAll(/(?is)&lt;\\s*pre\\s*&gt;.*?&lt;\\s*\\/\\s*pre\\s*&gt;/,\r\n         { preFrag -&gt; return preFrag\r\n             .replaceAll(/(?ius)&lt;\\s*br\\s*\\/?\\s*&gt;/, '\\n')\r\n             .replaceAll(/(?ius)&amp;nbsp;/, ' ')\r\n             .replaceAll(/(?ius)&amp;quot;/, '&quot;')\r\n         })\r\n}<br><br>def postId = basePostId\r\ndef commentId\r\ndef postNameSet = [] as Set\r\ndef categories = [] as Set<br><br>blog.entry.each(){\r\n    it -&gt;\r\n    def postDate = Date.parse(&quot;yyyy-MM-dd'T'HH:mm:ss&quot;, it.issued.text())\r\n    // a comment?\r\n    if(it.annotate.size() &gt; 0) {\r\n        output.append commentTpl.make([comment:it, commentId:(++commentId), postDate:postDate]).toString()\r\n    } else {\r\n        // Close the previous post:\r\n        if (postId &gt; basePostId) {  output.append &quot;&lt;/item&gt;&quot; }\r\n        ++postId\r\n        commentId = 0 // reset for the next post<br><br>        def category = it.subject.text().replaceFirst(&quot;/&quot;,&quot;&quot;)\r\n        categories &lt;&lt; category\r\n        output.append entryTpl.make([\r\n            entry:it, postId:postId, postDate:postDate\r\n            , postName:makePostName(it.title.text(), postId, postNameSet)\r\n            , postBody: fixMarkupWithinPre(it.content.text())\r\n            , category:category])\r\n            .toString()\r\n    }\r\n}\r\n// Close the final post\r\nif (postId &gt; 0) {  output.append &quot;&lt;/item&gt;&quot; }<br><br>println &quot;The posts used the following categorie, which will be thus created in WP: $categories&quot;\r\n&quot;done; check $output&quot;\r\n</code></pre>\r\n<h2>4. Add proper header and footer to the generated WP import file</h2>\r\nOpen your WordPress export file and copy everything from the beginning till the first &lt;item&gt;, paste it at the beginning of the generated WP import file. Beware: Each &lt;item&gt; must start on a line of its own! (Avoid <span style=\"text-decoration:line-through;\">&lt;atom:link .../&gt;&lt;item&gt;</span> on the same line.) It will be st. like:<br><br><pre><code>\r\n&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;\r\n&lt;!-- This is a WordPress eXtended RSS file generated by WordPress as an export of your blog. --&gt;\r\n... many lines skipped ...\r\n\t&lt;atom:link rel=&quot;search&quot; type=&quot;application/opensearchdescription+xml&quot; href=&quot;/osd.xml&quot; title=&quot;The Holy Java&quot; /&gt;\r\n\t&lt;atom:link rel='hub' href='/?pushpress=hub'/&gt;<br><br></code></pre><br><br>It's pretty possible that some/most parts of the header aren't necessary or will be replaced based on your blog, but I haven't experimented with that. Copy &amp; paste all is safe.<br><br>Open your WordPress export file and copy everything following the last &lt;/item&gt; till the end of the file to the end of the generated WP import file. It should be:<br><br><pre><code><br><br>&lt;/channel&gt;\r\n&lt;/rss&gt;\r\n</code></pre><br><br>Make really sure that each &lt;item&gt; or &lt;/item&gt; tag is on the line of its own. WP doesn't use a XML parser to read the file but a couple of regular expression so white spaces and end of lines can make a big difference.\r\n<h2>5. [optional] download images, perhaps upload them somewhere and modify URLs accordingly</h2>\r\nYou may want to download any images you used in JRoller, upload them smewhere else (WP, Picasaweb, Flickr, ...) and modify links in the generated XML accordingly. I haven't done that so you are on your own :-).\r\n<h2>6. Import it into WP</h2>\r\nImport in WP normally adds the imported posts, pages and comments to the existing one unless WP detects that you're importing a post that exists already, in which case it's either ignored or overriden - I'm not sure. How this detection works I do not know either, I've only find out it is not based on equality of the numerical IDs (wp:post_id). Perhaps it is based on the wp:post_name? Anyway, this makes it possible to import your posts in several batches without destroying what is already there.<br><br>Login, go to the Dashboard, expand the Tools sections and click Import, select Wordpress as the format, follow the instructions. It will allow you to create or map post authors (you will want to map the creator/defaultAuthor from the import file to yourself). WP.com will send you an email when finished (usually immediately), a standalone installation of WP would present you with some statistics of the imported items.<br><br>If you want to know more about the import process, download Wordpress and check the file /wp-admin/import/<a href=\"http://phpxref.com/xref/wordpress/wp-admin/import/wordpress.php.source.html\">wordpress.php</a> (make sure to get the version corresponding your Wordpress version). As mentioned already, WP doesn't use a XML parser but regular expressions to parse the file so be careful not to break something.\r\n<h2>7. Check formatting, add tags...</h2>\r\nYou are done now. However I'd advice you to go through the imported posts, check that their formatting is OK (especially within &lt;pre&gt;), and perhaps add tags (they weren't exported from JRoller).\r\n<h2>Known limitations</h2>\r\n<ul>\r\n\t<li>Aside of not importing images, I haven't dealt with any attachements.</li>\r\n\t<li>This process has been applied successfully to WordPress.com in its version as of 5/2010 - I don't know which it is 9likely st. between 2.5 and 3). It also works with the standalone Wordpress in version 2.8.4.</li>\r\n</ul>",
  "excerpt": ""
 },
 {
  "title": "Book: Real World Java EE Patterns - Rethinking Best Practices (review & digest)",
  "published": "2010-05-08 14:54:34",
  "postType": "post",
  "slug": "/2010/05/08/book-real-world-java-ee-patterns-rethinking-best-practices-review-digest/",
  "status": "publish",
  "tags": [
   "book",
   "j2ee",
   "java",
   "javaEE",
   "patterns",
   "review"
  ],
  "categories": [
   "Languages"
  ],
  "content": "I'd like to make you aware of the excellent book Real World Java EE Patterns - Rethinking Best Practices by <a id=\"xf-_\" title=\"Adam Bien\" href=\"http://adam-bien.com/inhalte/about/\">Adam Bien</a> (<a id=\"zcnq\" title=\"blog\" href=\"http://blog.adam-bien.com/\">blog</a>), a Java Champion and renowned consultant, software architect and Java EE standardization comitee member. I'd absolutely recommend it to any architect or developer serious with Java EE 5 or 6 development, even to those not planning to use EJB 3.x (at least prior to reading the book :)). It's a must-read complement to the now a little outdated <a id=\"zbgs\" title=\"Core J2EE patterns\" href=\"http://www.corej2eepatterns.com/Patterns2ndEd/\">Core J2EE patterns</a> as it updates the patterns for the new bright world of EJB 3/3.1 while discarding some of them and introducing some new, extremely useful patterns and techniques.<br><br>The book starts with an overview of the evolution of Java Enterprise Edition and the hard issues it solves for us, continues with the new and updated patterns and strategies and concludes with an introduction of two opposite architectures you can build with Java EE 5/6, namely lean SOA and domain-driven (which itself makes it worth reading).<br><br>What I really appreciate in addition to that valuable content is that for each pattern there is a section on testing and documentation and a really good evaluation of consequences in terms of maintainability, performance and other such qualities. You will find there also many code samples and beautiful applications of the Builder and Fluent API patterns.<br><br>The main message is that EJB 3.x is so lean and powerful that we must justify why NOT using it - and when using it, you should be very pragmatic and only introduce patterns, layers and principles if they bring real value.<br><br><!--more-->\r\n<h1><strong>A summary of the patterns</strong></h1>\r\nBecause not only abstractions but also my memory is <a href=\"http://www.joelonsoftware.com/articles/LeakyAbstractions.html\">leaky</a> :-), I've written down the key points as a reference and a reminder. It will be of a rather limited value to anybody else as it's closely bound to the structure and content of my mind, yet I hope it could give you a good idea of what is inside the book and why you should go and pick it up immediately :-).<br><br>A general rule: \"An introduction of another layer of abstraction or encapsulation causes additional development and maintenace effort.\" [p137] Thus it must provide some real added value to be justifiable.<br><br>Notion: New or radically different patterns are marked with *<strong> </strong><br><br><strong> </strong>\r\n<h2>BUSINESS TIER</h2>\r\n<strong>Service Facade (Application Service?!)</strong>\r\n<ul>\r\n\t<li>[JH: The old name should likely be Session Facade, not A. S.]</li>\r\n\t<li>The boundary class used by UI</li>\r\n\t<li>A transaction boundary too (SOA: starts a new tx)</li>\r\n\t<li>Coarse-grained API</li>\r\n\t<li>Usually @Stateless</li>\r\n\t<li>Either contains a simple business logic (i.e. is merged w/ a Service) or delegates to Services/DAOs (incl. EntityManager)</li>\r\n</ul>\r\n<strong>Service (Session Facade?!)</strong>\r\n<ul>\r\n\t<li>[JH: The old name should likely be Application Service, not S.F.]</li>\r\n\t<li>Fine-grained, reusable logic in an EJB with local access only, product of decomposition</li>\r\n\t<li>Used by a Service Facade</li>\r\n\t<li>Usually @Stateless s Tx=Mandatory</li>\r\n\t<li>Uses EntityManager and/or specialized DAOs</li>\r\n\t<li>In SOA arch. w/ anemic objects the behavior is here contrary to the PDO below</li>\r\n</ul>\r\n<strong>Persistent Domain Object (Business Object)*</strong>\r\n<ul>\r\n\t<li>Rich domain object, ie. having rich behavior/bus.logic and persistent (x anemic structure of SOA)</li>\r\n\t<li>Forces:\r\n<ul>\r\n\t<li>Complex business logic</li>\r\n\t<li>Type-specific behavior necessary (profits from inehritance, polymorphism) - e.g. validation rules are domain object related and sophisticated</li>\r\n\t<li>DB may be adjusted for JPA needs</li>\r\n</ul>\r\n</li>\r\n\t<li>Solution: @Entity; getter/setters only when justified (x anemic structures, i.e. state is hidden), has methods modeling behavior and changing its state (creating other entities..); methods named fluently (domain-driven API)\r\n<ul>\r\n\t<li>Only the cross-cutting/orchestration logic impl. in a Service</li>\r\n\t<li>Created/maintained by a Service, S.Facade or Gateway (CR(U)D methods)</li>\r\n\t<li>Requires the entity to stay attached =&gt; buz.+present. tier in the same JVM</li>\r\n</ul>\r\n</li>\r\n</ul>\r\n<strong>Gateway*</strong>\r\n<ul>\r\n\t<li>Provides access to the root PDOs, exposes them to the present. tier (opposed to S.Facade, which hides the logic impl.)</li>\r\n\t<li>It's necessary to manage PDOs who're unaware of EntityManager and to hold client state (the PDOs) over conseq. executions</li>\r\n\t<li>The presentation tier must be in the same JVM</li>\r\n\t<li>Essential for the (rich) domain-driven architecture</li>\r\n\t<li>Forces:\r\n<ul>\r\n\t<li>PDOs are already well encapsulated, additional encaps./layering unnecess.</li>\r\n\t<li>DB may be changed as needed</li>\r\n\t<li>changes of UI are likely to affect DB anyway</li>\r\n\t<li>An interactive app., w/ non-trivial validations depending on objects' state</li>\r\n\t<li>Users decide when their changes are persisted, when not</li>\r\n</ul>\r\n</li>\r\n\t<li>Note: Not much suitable for RIA UI for they're running on the client = remotely</li>\r\n\t<li>Solution: @Stateful w/ Extended persist. context and tx=NONE and a single save() method that only starts a tx. (via annot. tx=Req.New) and thus forces Ent.Man. to commit changes performed so far</li>\r\n\t<li>Consequences:\r\n<ul>\r\n\t<li>Scalability: Doesn't scale as well as stateless but still absolutely sufficient for most apps; depends on cache size, length of sessions; need to find out via load tests</li>\r\n\t<li>Performance may be better as PDOs are loaded only once and accessed locally per ref.</li>\r\n\t<li>Need a well defined strategy for handling stale objects, i.e. the OptimisticLockException, test early</li>\r\n\t<li>Maint.: \"In non-trivial, problem-solving applications, a Gateway can greatly improve the maintainability. It simplifies the architecture and makes the intermediary layers superfluous.\" [114] Unsuitable for SOA arch.w/ many externally exposed services.</li>\r\n\t<li>Productivity, ease of use much higher</li>\r\n</ul>\r\n</li>\r\n</ul>\r\n<strong>Fluid Logic</strong>\r\n<ul>\r\n\t<li>Inclusion of scripting for algorithms/bus.logic that change often so that recompilation/redeployment aren't necessary - JSR-223 (Scripting for the Java Platform)</li>\r\n\t<li>Executed from a Service</li>\r\n</ul>\r\n<strong>Paginator and Fast Lane Reader</strong>\r\n<ul>\r\n\t<li>A Service/S.F. allowing for efficient access to large amounts of mostly read-only data [subset]</li>\r\n\t<li>Former motivation: in EJB 2, a FLR accessed huge quantities of read-only data via JDBC directly for efficiency - JPA is efficient enough in this, providing a way to extract only some attributes and paginate over large results</li>\r\n\t<li>Valid motivation: \"JPA is not able to stream objects, rather than load the entire page into memory at once. For some use cases such as exports, batches, or reports direct access to the database cursor would provide better performance.\" [123]</li>\r\n\t<li>Forces: iteration over large amount of data needed; it cannot be sent at once to the client and must be cached on the server; the client needs only some attributes of the entity; the access is mostly read-only</li>\r\n\t<li>Solution - not a single one but different strategies w/ +/-\r\n<ul>\r\n\t<li>Paginator and Value List Handler Strategy: sess. bean implementing an Iterator of list of lists of domain objects (a list = a page); either Stateful holding internally the current position or Stateless; uses Query.setFirstResult + setMaxResults. May use Persist.Ctx.EXTENDED to be updatable.</li>\r\n\t<li>Live Cursor and F.L.R. Str(eaming?): to get as fast access as possible when conversion into objects isn't necessary, we may let inject DataSource via a @Resource directly into an EJB and use JDBC; will share Connection w/ any Ent.Mgr. in the same tx</li>\r\n</ul>\r\n</li>\r\n\t<li>Paginator in a domain-driven arch.: \"A Paginator is also an optimization, which should only be introduced in case the iteration over a collection of attached PDOs causes performance or resource problems.\" [p269]</li>\r\n</ul>\r\n<strong>Retired Patterns</strong>\r\n<ul>\r\n\t<li>Service Locator - replaced by DI</li>\r\n\t<li>Composite Entity - JPA entities completely different</li>\r\n\t<li>Value Object Assembler - VOs mostly not needed anymore as entities are POJOs; partly impl. by EntityManager</li>\r\n\t<li>Business Delegate - not needed thanks to DI injecting a Business interface's impl., which doesn't throw EJB-specific, checked exceptions anymore</li>\r\n\t<li>Domain Store -impl. by the EntityManager</li>\r\n\t<li>Value List Handler - implemented by EntityManager; it can also execute native SQL and convert them to entities or a list of primitives</li>\r\n</ul>\r\n<h2>Integration Tier</h2>\r\n<strong>Data Access Object (DAO)</strong><br><br><strong> </strong>\r\n<ul>\r\n\t<li>The J2EE 1.4 motivation for DAOs doesn't apply anymore:\r\n<ul>\r\n\t<li>JPA EntityManager is a DAO</li>\r\n\t<li>Encapsulation of a DB is leaky anyway; you will only rarely change your DB vendor and never a RDBMS for another storage type</li>\r\n</ul>\r\n</li>\r\n\t<li>Thus DAOs are only needed for non-JPA resources and at those rare occassions, where they provide a real added value, such as consolidating often repeated persistence logic to support DRY - or if you application has some special requirements that really justify the effort.</li>\r\n\t<li>Solution: A stateless EJB with @Local interface and @TransactionAttrbute(MANDATORY), accessed by Services/S.Facades.</li>\r\n\t<li>Note: Heavy use of JPA QL would blur the business logic so it might be better to move the creation of queries into dedicated query builders or other utility classes.</li>\r\n\t<li>Strategies (may be combined together, of course):\r\n<ul>\r\n\t<li>Generic DAO - the results of JPA queries aren't type-safe and a type-safe generic DAO (CrudService) for CRUD and named query search operations (such as &lt;T&gt; T create(T t)) could be more convenient.\r\n<ul>\r\n\t<li>Suggestion: Use entity class constants for named query names to avoid typos [and help to track their usage].</li>\r\n</ul>\r\n</li>\r\n\t<li>Domain-specific DAO - DAO for a particular entity, which provides an added value aside of wrapping JPA, such as prefetching of dependant objects, managing common relations, results filtering based on the current user etc.</li>\r\n\t<li>Attached-result DAO - the default behavior - JPA entities stay attached for the duration of the transaction and any changes to them will be commited to the DB</li>\r\n\t<li>Detached-result DAO - if it isn't possible to stay attached, e.g. due to the data source's limitations. A common case in JEE is to return a subset of managed entity object graph mapped to transient DTOs for optimization purposes (select new BookLiteView(...) ..).</li>\r\n\t<li>Back-end Integration DAO - encapsulates a Java Connector Architecture, Common Client Interface or similar adapter for a legacy resource to shield the developer from their low-level APIs.</li>\r\n\t<li>Abstract DAO - reusable data access logic can be also inherited instead of delegated to a helper DAO. Purists could complain but \"Inheriting from generic DAO functionality streamlines the code and is pragmatic.\" Especially suitable for DB-driven apps.</li>\r\n</ul>\r\n</li>\r\n</ul>\r\n<strong>Transfer Object (TO) and Data Transfer Object (DTO)</strong><br><br><strong> </strong>\r\n<ul>\r\n\t<li>Again, the J2EE 1.4 motivation for (D)TOs doesn't apply anymore because detached Entities aren't active elements and are POJOs</li>\r\n\t<li>There may be few reasons where (D)TOs may be appropriate:\r\n<ul>\r\n\t<li>To provide consumer-specific views to the persistence layer/send a subset of the data graph for performance reasons (see the Detached-result DAO above)</li>\r\n\t<li>To keep outside-facing services binary compatible, which may be necessary for long-lived SOA services that share the same domain model and need to be evolved independently. Adding/changing an entity field needed by a new service isn't possible if the entity is used also by older services/clients.\r\n<ul>\r\n\t<li>At times it may be necessary to decouple SOA services by replacing hard references to other entities with DTOs that carry their ID and type and act as a proxy for fetching those entities via their own services. Of course this is laborious to code/maintain and less efficient due to multiple service calls so you need a sound reason to justify it.</li>\r\n</ul>\r\n</li>\r\n\t<li>Transfering data from non-JPA sources.</li>\r\n\t<li>To transfer also presentation tier-specific metadata for building UIs on the fly (e.g. @LAbel(\"Enter password\"), @MinLength(4))</li>\r\n\t<li>To provide a simpler form for transfer over RESTFul/SOAP/CORBA/or even ASCII</li>\r\n</ul>\r\n</li>\r\n\t<li>Solution: A Serializable or Externalizable POJO. (Implementing Externalizable allows for providing faster to process and smaller serialized forms and may (should) be automated via code generation. But use with care - it adds lot of code that must be maintained and understood.)</li>\r\n\t<li>Strategies\r\n<ul>\r\n\t<li>Builder-style TO - fluent API simplifies its constructions and makes it easier to read. Ex.: MyDTO d = new MyDTO.Builder().name(\"Duke\").age(42).build(); (Builder is a nested static class)</li>\r\n\t<li>Builder-style Immutable TO - prescribe the setting of certain attributes - mark them final and only instantiate the DTO when build() is invoked.</li>\r\n\t<li>Client-specific TO - add metadata e.g. for dynamic UI construction and data validation [you likely don't want them in domain Entities] - annotations such as @Label(\"First Name\") are added to the DTO's getters (getFirstName()) . Check JSR-303 Bean Validation.</li>\r\n\t<li>Generic DTO - dynamic (basically a map of attributes), using reflection - for generic UIs. Cons: not type-safe, several times more objects (attribute name, type representation, metadata ..); see Apache BeanUtils.</li>\r\n</ul>\r\n</li>\r\n</ul>\r\n<strong>Legacy POJO Integration</strong>\r\n<ul>\r\n\t<li>If you need to integrate a legacy POJO into a JEE application and it needs to leverage the container services (e.g. security, lifecycle and concurrency management, DI) and participate in transactions, you can simply turn it into s Stateless session bean provided that it complies with the EJB 3 programming restrictions (has the default constructor and, prior to 3.1, an interface). Instead of adding annotations to its source code, which may be not accessible, you use ejb-jar.xml.</li>\r\n\t<li>The overhead introduced by turning it into an EJB is really low and comparable to other DI frameworks.</li>\r\n</ul>\r\n<strong>Generic JCA</strong>\r\n<ul>\r\n\t<li>\"It is not possible to access legacy resources such as files, native libraries, or starting new threads from EJBs without violating the programming restrictions.\" [p181] - see Chapter 21.1.2 of JSR 220</li>\r\n\t<li>Even if you do not care about violating those restrictions, you may care for making your application non-portable.</li>\r\n\t<li>Thus if you want to access a Java EE incompatible resource, perhaps transactionally, in a portable way, you need to use JCA (with the additional benefit of monitoring)</li>\r\n\t<li>The JEE restrictions do not apply to Servlets, MBeans and JCA connectors, of those only JCA can participate in transactions and within a security context.</li>\r\n\t<li>While complete JCA implementation is complex, a minimal one is \"surprisingly simple\" - it comprises of 2 interfcase, 4 classes, 1 XML file. Two of the classes are highly reusable, the remaining part is resource dependent.</li>\r\n\t<li>You don't even need to implement the Common Client Interface (CCI), which may be too abstract and complex, and provide your own one instead.</li>\r\n\t<li>Depending on your requiremements, you can choose which parts of JCA to implement [JH: perhaps e.g. javax.resource.spi.work when dealing with threads]</li>\r\n\t<li>Example: transactional file access:\r\n<ul>\r\n\t<li>a <em>Connection</em> {write(String), close() } interface (JCA is connection-oriented) and Connection factory interface to be put into JNDI: <em>DataSource</em> extends Serializable, Referenceable { getConnection() }</li>\r\n\t<li>a (simple) logic in the class <em>FileConnection</em> impl. Connection and javax.resource.spi.<a href=\"http://java.sun.com/javaee/5/docs/api/javax/resource/spi/LocalTransaction.html\">LocalTransaction</a>, delegating close() to the GenericManagedConnection (below) and using JCA's <a href=\"http://java.sun.com/javaee/5/docs/api/javax/resource/spi/ConnectionRequestInfo.html\">ConnectionRequestInfo</a> for implementing hashCode and equals to distinguish this connection from others</li>\r\n\t<li>a simple <em>FileDataSource</em> class impl. DataSource providing a custom ConnectionRequestInfo implementation (e.g. with equals returning true and hashCode 1 to make all connections equal) and using JCA's ConnectionManager to create a connection, casting its output to FileConnection, using the C.M. and a ManagedConnectionFactory supplied via the constructor</li>\r\n\t<li>a generic <em>GenericManagedConnection</em> class impl. ManagedConnection and LocalTransaction (to invoke the F.C.'s corresponding methods), which will actually instantiate the FileConnection and manage its listeners, while also providing a custom impl. of ManagedConnectionMetaData to describe it and returning null for getXAResource. Notice that the app. server uses the event notification to manage the connection.</li>\r\n\t<li>a generic <em>GenericManagedConnectionFactory</em> class impl. ManagedConnectionFactory, Serializable and creating the FileDataSource as the conn. factory and GenericManagedConnection as the ManagedConnection. (matchManagedConnections selects a connection with matching ConnectionRequestInfo from a set of candidates or throws a ResourceException.)</li>\r\n\t<li>an <em>ra.xml</em> file (def. by the <a href=\"http://java.sun.com/j2ee/connector/download.html\">specs</a>) containing all the interfaces and classes under resourceadapter/outbound-resourceadapter/connection-definition (managedconnectionfactory-class=GenericM.C.F., connectionfactory-interface=DataSource, connectionfactory-impl-class=FileD.S., connection-interface=Connection, connection-impl-class=FileC., transaction-support=LocalTransaction, authentication-mechanism/a.-m.-type=BasicPassword and /credential-interface=javax.resource.spi.security.PasswordCredential)</li>\r\n\t<li>Finally you pack it all into a .rar JAR, drop it to the server, and configure a connection pool and deploy the data source under some JNDI name, e.g. \"jca/FileDS\", to make it injectable via @Resource(name=\"jca/FileDS\")</li>\r\n\t<li>Note: Apache Commons File Transactions contains XA-compliant file access and could be easily wrapped w/ this connector</li>\r\n</ul>\r\n</li>\r\n\t<li>\"a partial implementation of a JCA adapter could be easier and faster than an attempt to build a comparable solution from scratch\" [p195]</li>\r\n</ul>\r\n<strong>Asynchronous Resource Integrator (Service Activator)</strong>\r\n<ul>\r\n\t<li>Invocation of a Service from a Message-Driven Bean (invoked by a messaging system via JMS), bound to a Topic (1/N:M) or Destination (1:1)</li>\r\n\t<li>Prior to EJB 3.1, Service Activator was a work-around to invoke a business method asynchronously by calling it via a MDB, now we've the much simpler @Asynchronous method/type annotation</li>\r\n\t<li>Since EJB 3.1, MDBs are only necessary for integration of front-end or back-end asynchronous clients/resources</li>\r\n\t<li>The MDB's task is to extract the \"payload\" (usually an Object, Text or BinaryMessage), convert it into meaningful parameters, forward it to a Service and handle errors and \"poison messages\" (wrong type/content leading to an exception and reprocessing of the message) correctly. It should contain no business logic.\r\n<ul>\r\n\t<li>A container starts a transaction before onMessage and removes the message when it ends w/o a rollback</li>\r\n</ul>\r\n</li>\r\n\t<li>Note: Some messaging providers such as openMQ provide REST-ful interface (yet not standardized, but watch amqp.org) and can be thus invoked from a presentation or client (browser - ajax) tier</li>\r\n\t<li>\"The importance of integration tests in an environment identical to production cannot be emphasized enough.\" [p201]</li>\r\n\t<li>MDB: \"... proper error handling is hard and the debug process a real challenge\"[p201]</li>\r\n\t<li>Strategies\r\n<ul>\r\n\t<li>Front-end Integration - asynch. messages from the presentation or client tier, likely Ajax; the payload is usually XML/JSON</li>\r\n\t<li>Back-end Integration - usually a legacy system; usually can't influence the message</li>\r\n</ul>\r\n</li>\r\n</ul>\r\n<h2>Infrastructural Patterns and Utilities</h2>\r\nPatterns that can be used at any layer or are not of architectural significance yet very useful.<br><br><strong>Service Starter</strong>\r\n<ul>\r\n\t<li>Initialize an EJB upon server start (e.g. to load a cache)</li>\r\n\t<li>EJB 3.1: @Singleton with @Startup. May also @DependsOn another one.</li>\r\n\t<li>pre-EJB 3.1: a HttpServlet with init() method and load-on-startup 1</li>\r\n</ul>\r\n<strong>Singleton</strong>\r\n<ul>\r\n\t<li>Standardized in EJB 3.1 with @Singleton (in the scope of a single JVM only)</li>\r\n\t<li>By default uses @Lock(LockType.WRITE) and thus can only be accessed by a single thread at a time; user READ for concurrent access</li>\r\n\t<li>Strategies (rather uses)\r\n<ul>\r\n\t<li>Gatekeeper - limit access to a legacy resource (e.g. due to limited # of licenses or its limited scalability) - this could be done in a JCA adapter but that's a lot more work. It can also serialize access to a single-threaded resource with LockType.WRITE</li>\r\n\t<li>Caching Singleton - holds a cache of mostly read-only data, likely initialized at startup, and accessed concurrently thanks to LockType.READ</li>\r\n</ul>\r\n</li>\r\n</ul>\r\n<strong>Bean Locator</strong> - encapsulates JNDI if DI not available (e.g. Stateful EJB can't be injected into a servlet).Use a Fluent GlobalJNDIName Builder to simplify the error-prone process of global JNDI name construction.<br><br><strong>Thread Tracker</strong> - name a thread after the bean and business method it's currently executing for easier monitoring/troubleshooting (instead of e.g. \"http-0.0.0.0-8180-1\") via an interceptor (but beware that the interception is several times slower than a direct call)<br><br><strong>Dependency Injection Extender</strong>\r\n<ul>\r\n\t<li>Integrate another DI fwrk's managed beans into an EJB via a custom Interceptor, which will invoke the DI framework to inject its beans into the EJB upon each call (e.g. via Guice's Injector.injectMember(invocationCtx.getTarget());)</li>\r\n\t<li>The interceptor must ensure proper bean's lifecycle w.r.t. its scope (request x session x ...)</li>\r\n\t<li>Strategies:\r\n<ul>\r\n\t<li>Stateful Session Bean Injector - can use per-instance injectors and cache the injected components for the EJB's lifetime</li>\r\n\t<li>Stateless Session Bean Injector - either all the members must be injected before each call or it's necessary to use smart proxies able to react e.g. to transactions for non-idempotent components</li>\r\n\t<li>Transactional Integration - \"the injected components already participate in a transaction started in the session bean\"</li>\r\n</ul>\r\n</li>\r\n\t<li>Performance - interceptors and DI rely on reflection which is slower than direct calls, yet still much faster than an average DB access</li>\r\n</ul>\r\n<strong>Payload Extractor</strong> - factor out the (reusable) type checking and error handling for a MDB message into a reusable interceptor; poison messages moved by the interceptor to a \"dead letter queue\" via a stateless EJB using the JMS API<br><br><strong>Resource Binder</strong> - put a custom resource into JNDI using a @Singleton with @Startup and the JNDI API (Context.(re)bind()). Notice that your app. server's proprietary JNDI impl. may enforce some restrictions on the resource object (such as serializability).<br><br><strong>Context Holder</strong> - you want to pass some context data yet not to add it as a param to each method on the call tree (S.Facade &gt; Service &gt; DAO, indirectly PDO) =&gt; use the standard @Resource TransactionSynchronizationRegistry, with the actual context set perhaps by an interceptor. Notice that ThreadLocal may be problematic if a S.Facade invokes a Service and each is from a distinct thread pool = diff. thread.\r\n<h2 id=\"PragmaticJavaEEArchitectures\">Pragmatic Java EE Architectures</h2>\r\nThere are two opposite approaches, with best practices in one being anti-patterns in the other: the SOA architecture and he Domain-driven architecture. Which one is better depends in your requirements.\r\n<h3>Lean Service-Oriented Architectures (<a href=\"http://www.javaworld.com/javaworld/jw-04-2009/jw-04-lean-soa-with-javaee6.html?page=1\">online article</a>)</h3>\r\n<ul>\r\n\t<li>JEE 5/6 can be used to build the leanest SOA impl. possible - (nearly) no XML, no external libraries, frameworks, only a JAR with a short persistence.xml, even more so in 3.1 where we can drop the @Local interfaces (though that makes testing more difficult)</li>\r\n\t<li>SOA implies coarse-grained, distributed, stateless, atomic, self-contained, independent services with a procedural nature\r\n<ul>\r\n\t<li>Though in JEE, local access shall be always preferred when possible (performance)</li>\r\n</ul>\r\n</li>\r\n\t<li>Building blocks:\r\n<ul>\r\n\t<li>Service Facade - @Stateless EJB with TransactionAttribute=REQUIRES_NEW - acts as a remoting and transaction boundary, hides implementation details while providing coarser-grained interface</li>\r\n\t<li>(optional) Services (with @Local and tx=MANDATORY) - implement the actual logic in a procedural way; in simple cases, the Facade may directly use a DAO to avoid a dumb Service w/o any added value</li>\r\n\t<li>(optional) DAOs (incl. EntityManager) - as needed</li>\r\n\t<li>Anemic persistent data structures - entities only hold data exposed via getters/setters, w/o any behavior\r\n<ul>\r\n\t<li>\"Although the anemic object model is considered to be an antipattern, it fits very well into an SOA. Most of the application is data-driven, with only a small amount of object-specific or type-dependent logic.\" [p260] Plus, for simple apps, they're easier to develop, can be generated, can be detached and sent to a client who won't get access to any business method (but beware the lazy-loading issue).</li>\r\n</ul>\r\n</li>\r\n\t<li>Transfer Objects - an essential pattern, a SOA service must stay binary compatible even if its domain objects change (e.g. a field added, needed by a new service) and thus can't expose directly JPA entities</li>\r\n</ul>\r\n</li>\r\n\t<li>The contract, represented by the Service Facade's @Remote interface and the TOs and visible to clients, is strictly separated from its realization</li>\r\n\t<li>Suitable e.g. if there are multiple different clients (i.e. not only a single web UI)</li>\r\n\t<li>Essential complexity of SOA\r\n<ul>\r\n\t<li>\"SOA aims for reuse, which causes more overhead and requires additional patterns. Service components are, on average, more complex than comparable domain components.\" [p264]</li>\r\n\t<li>The object graph sent to a client is detached (and serialized) =&gt; we must merge the changes when receiving it back, this is complex =&gt; added methods to update only parts of the obj.graph =&gt; code bloat [p101] - \"The essential complexity of service-oriented applications is the synchronization of the PDO graph with the persistent store.\" [p266] Both writes (client updates a part of the object graph, which must be merged back) and reads (because of unavailability of lazy-loading) are difficult.</li>\r\n\t<li>Lazy loading of detached objects (in the present. tier) impossible =&gt; must know/request in advance what to load (=&gt; code bloat)</li>\r\n</ul>\r\n</li>\r\n</ul>\r\n<h3>Objects- or Domain-Driven Design (<a href=\"http://www.javaworld.com/javaworld/jw-05-2009/jw-05-domain-driven-design.html\">online article</a>)</h3>\r\n<ul>\r\n\t<li>As opposed to SOA, it relies mainly on well-defined encapsulated (persistent) objects with state <em>and behavior</em> and tends to be stateful.</li>\r\n\t<li>Building blocks:\r\n<ul>\r\n\t<li>Entity - the (behavior-rich) Persistent Domain Object pattern. \"A real domain-driven architecture should actually only be comprised of Entities with aspects.\" [p256]</li>\r\n\t<li>(optional) Control - a Service/DAO - implements cross-cutting aspects (Entity-independent, reusable logic and orchestration of multiple PDOs) - often for reusable queries, data warehouse jobs, reports etc.; used only exceptionally in DDD</li>\r\n\t<li>Boundary - a Gateway - the border between the UI and the business logic, exposes PDOs as directly as possible; usually stateful (to keep PDOs attached); \"only necessary because of the Java EE 5/6 shortcomings ... In an ideal environment, a Gateway could also be implemented as an aspect, or even a static method on a PDO.\" [p266]</li>\r\n\t<li>(optional) TO - used for optimization purposes when there is a real need</li>\r\n</ul>\r\n</li>\r\n\t<li>Contrary to SOA, here is no separation between the specification and the realization (which is pragmatic, requires less effort)</li>\r\n\t<li>\"The main advantage of the stateful domain-driven approach is the transparent synchronization and lazy loading of dependent entities.\" [p267] [JH: Also, with direct access to PDOs, it's much easier to implement and evolve the UI - see Seam. We could say this is (much) more productive and \"agile\" than SOA.]</li>\r\n\t<li>Essential complexity of DDD\r\n<ul>\r\n\t<li>DDD requires a stateful Gateway holding a reference to an attached root PDO - \"The statefulness itself isn't a scalability problem, rather than the amount of attached entities during the transaction.\" [p266] (every entity used will stay cached till the session ends)</li>\r\n\t<li>\"... you will have to think about freeing the resources and detaching superfluous PDOs. This could become as complex as the synchronization of detached entities or loading of lazy relations in a service-oriented component.\" [p267]</li>\r\n\t<li>=&gt; perhaps necessary to tune the cache settings or use proxies (e.g. OIDs/References) instead of actual objects and load objects as needed.</li>\r\n\t<li>\"Whether the aggressive caching behavior of your provider becomes a problem or not depends on many factors, including the number of concurrent sessions, the session length, and the number of accessed PDOs per session.\" [p267]</li>\r\n</ul>\r\n</li>\r\n\t<li>It's necessary to find a good compromise regarding the coupling of different (sub)domain PDOs (such as Address, Customer), i.e. between independence of components and ease of use. We must also deal with circular dependencies (think of bidirectional dependencies) between PDOs and thus components. Be pragmatic:\r\n<ul>\r\n\t<li>\"Few bidirectional dependencies between components are harmless.\" [p268] - especially considering the unnecessary laboriousness and complexity of possible workarounds</li>\r\n\t<li>You can use a proxy that resolves the object on demand using a service, as SOA does, but this is not very transparent; \"it actually only obfuscates the dependency between two entities\" [p268]</li>\r\n\t<li>The favourite solution is to refactor/restructure your components to get the related PDOs into one, though that breaks the \"maximal cohesion\" principle</li>\r\n</ul>\r\n</li>\r\n</ul>\r\n<h2>Notes on Terminology</h2>\r\n<ul>\r\n\t<li>The term \"anemic domain model\" originates likely from Martin Fowler</li>\r\n\t<li>The term \"Domain-Driven Design\" has been made popular by Eric Evans via his book Domain-Driven Design: Tackling Complexity in the Heart of Software, published 2003</li>\r\n</ul>",
  "excerpt": ""
 },
 {
  "title": "Eclipse Profile configuration: The launch requires at least one data collector",
  "published": "2010-05-13 16:04:43",
  "postType": "post",
  "slug": "/2010/05/13/eclipse-profile-configuration-the-launch-requires-at-least-one-data-collector/",
  "status": "publish",
  "tags": [
   "error",
   "profile",
   "profiling",
   "TPTP"
  ],
  "categories": [
   "eclipse"
  ],
  "content": "I just installed TPTP into my Eclipse 3.5 under Ubuntu 9.04 and tried to profile a class. The Profile Configuration opened with a red warning reading \"<span style=\"color:#ff0000;\">the launch requires at least one data collector to be selected</span>\". Clicking the configuration's Monitor tab reveals a more detailed error (and nothing to select):\r\n<blockquote><span style=\"color:#ff0000;\">IWATO435E An error occured when connecting to the host.</span></blockquote>\r\nA quick check of the error log (Window - Show View - Other... - General - Error Log) reveals the cause:\r\n<blockquote>RAServer generated the following output:  [Error Stream]:ACServer: error while loading shared libraries: /home/jholy/development/tools/eclipse-ide/pulse2-2.4.2/Common/plugins/org.eclipse.tptp.platform.ac.linux_ia32_4.4.202.v201002100300/agent_controller/bin/../lib/libtptpUtils.so.4: file too short</blockquote>\r\nChecking the content of the lib/ folder revealed an interesting thing:\r\n<blockquote>-rw-r--r-- 1 jholy jholy   17 2010-02-16 23:16 libtptpUtils.so\r\n-rw-r--r-- 1 jholy jholy   21 2010-02-16 23:16 libtptpUtils.so.4\r\n-rwxr-xr-x 1 jholy jholy 100K 2010-02-16 23:16 libtptpUtils.so.4.5.0</blockquote>\r\nAs also the content of the two small files suggests (they contain a name of the corresponding file with a longer name), <strong>the *.so and *.so.4 files should have been links but the installer failed to create them</strong>.\r\n<h2>Solution</h2>\r\nList all files in the lib/ folder, you will see that there are many real files like libtptpUtils.so.4.5.0 and libxerces-c.so.26.0 and many should-be-links files. The solution is, of course, to replace all those files that shoud be links with actual links.<br><br>For me the solution was:\r\n<pre>$ cd .../plugins/org.eclipse.tptp.platform.ac.linux_ia32_4.4.202.v201002100300/agent_controller/lib\r\n# Move out the files that are OK\r\nlib$ mkdir tmp\r\nlib$ mv libswt-* libcbe.so tmp/\r\n# Fix the links\r\nlib$ for FILE in `ls *.so`; do ln -sf \"${FILE}.4.5.0\" $FILE; ln -sf \"${FILE}.4.5.0\" \"${FILE}.4\"; done\r\n# Move the correct files back\r\nlib$ mv tmp/* .\r\nlib$ rmdir tmp\r\n# Fix links for files with *.26 instead of *.4.5.0\r\nlib$ ln -sf libxerces-c.so.26.0 libxerces-c.so.26\r\nlib$ ln -sf libxerces-c.so.26.0 libxerces-c.so\r\nlib$ ln -sf libxerces-depdom.so.26.0 libxerces-depdom.so.26\r\nlib$ ln -sf libxerces-depdom.so.26.0 libxerces-depdom.so\r\nlib$ rm libxerces-depdom.so.4 libxerces-c.so.4\r\n# Done!\r\n</pre>\r\nTry to open the profile configuration now, the IWATO435E should have disappeared and you should be able to select a data collector.<br><br>If not, restart Eclipse, try again, check the error log.\r\n<h2>My environment</h2>\r\n<ul>\r\n\t<li>Ubuntu 9.04</li>\r\n\t<li>Eclipse 3.5</li>\r\n\t<li>TPTP - see above</li>\r\n</ul>\r\n<h2>Related</h2>\r\nThere is a similar post of the same problem but with different cause: <a href=\"https://guust.tuxes.nl/~bas/wordpress/?p=26\">Get Eclipse TPTP to run on Ubuntu Karmic Koala</a> - the cause was: \"the Agent Controller was built against old C++ libraries which were no longer available on my system (Ubuntu 9.10 Karmic Koala, amd64)\".",
  "excerpt": ""
 },
 {
  "title": "How Visual Paradigm (nearly) ruined my day and Dropbox (nearly) saved it",
  "published": "2010-05-16 14:16:24",
  "postType": "post",
  "slug": "/2010/05/16/how-visual-paradigm-nearly-ruined-my-day-and-dropbox-nearly-saved-it/",
  "status": "publish",
  "tags": [],
  "categories": [
   "Tools"
  ],
  "content": "For months I'm working on designing an architecture for a fictious system, which is required for the second part of the <a href=\"http://in.sun.com/training/certification/java/scea.xml\">Sun Certified Enterprise Architect</a> (SCEA) exam. Today I came to my computer to make few final but important finishing touches to my UML diagrams. The notebook run out of battery and thus lost its in-memory suspended state - nothing special, it happens. But what an horror! When I started Visual Paradigm (which was running when I suspended the computer), my UML tool, it asked me whether to restore the auto-saved project - which could have been expected, and I agreed - and opened the project - with all texts lost!<br><br><!--more--><br><br><a href=\"/images/2010/05/vp-tridy_bez_textu.png\"><img class=\"size-medium wp-image-205 \" title=\"VP screenshot - text-less class diagram\" src=\"/images/2010/05/vp-tridy_bez_textu.png?w=300\" alt=\"\" width=\"300\" height=\"264\" /></a><br><br>As you can see on the screenshot,even the package name got lost. It's not only that the text isn't visible - all the information about the model has simply disappeared from the project!<br><br>After a short period of panic I remembered that <a href=\"https://www.dropbox.com/\">Dropbox</a>, which I use to back up my SCEA folder and to share it with my home computer (I'm kind of paranoid since having may first computer that used to crash regularly due to overheating), <a href=\"https://www.dropbox.com/help/11\">keeps few recent versions</a> of each file. Of course the latest version was corrupted because the notebook has already synchronized with Dropbox, but there were also two previous versions and the originally added one - what a relief!!!<br><br>While exploring the folder, I noticed two strange files, namely &lt;my VP project file&gt;.vpp~270 and &lt;my VP project file&gt;.vpp~271. Looks like VP is keeping backups of its own! And indeed, when I renamed the .vpp~271 file to .vpp and opened it with VP, my lovely diagrams were back in their latest state with all other information in place! And thus VP hasn't ruined my day (rather many days) after all and I didn't need Dropbox to save me.<br><br>Conclusion: Back up, back up, back up!<br><br>For the curious: I use Visual Paradigm for UML Modeler Edition 3.6 (I've also tried the latest community edition but it allows only a very limited number of diagrams - perhaps one? - before putting an unacceptably obtrusive watermark on each). I've a couple of reservations against its usability, responsivness, unnecessary limitations of what can be done on a diagram and its behavior, but it is the best tool I have.",
  "excerpt": ""
 },
 {
  "title": "Webapp performance monitoring with Glassbox 2.0: How does it work?",
  "published": "2008-10-31 00:10:10",
  "postType": "post",
  "slug": "/2008/10/31/webapp-performance-monitoring-with/",
  "status": "publish",
  "tags": [
   "AOP",
   "java",
   "monitoring",
   "performance"
  ],
  "categories": [
   "Languages",
   "Tools"
  ],
  "content": "<p><b>A word of warning: </b>Information on this page originates from my exploration of Glassbox performed in Oct 2008 and may be inaccurate. Ron Bodkin, the mastermind behind Glassbox, was so kind as to review this but still there may be some mistakes or inexact informatiom left. In any case blame me :-)<br /></p><h1>Introduction <br /></h1><p>There're a few open source java webapp monitoring tools: <a href=\"http://www.glassbox.com/\">Glassbox</a> (latest release 2008-09-02), <a href=\"http://jamonapi.sourceforge.net/\">JAMon</a> (2007-09-20), <a href=\"http://infrared.sourceforge.net/versions/latest/\">InfraRED</a> (2006-05-17), <a href=\"http://code.google.com/p/usemon/\">UseMon</a> (2008-10-06). Among these, Glassbox is both still actively developed and mature. It has also nice though only basic <a href=\"http://downloads.sourceforge.net/glassbox/Glassboxv2.0UserGuide.pdf?modtime=1221448295&amp;big_mirror=0\" title=\"Glassboxv2.0UserGuide.pdf\">user documentation</a>. Unfortunately there is only little docs about its architecture and about customizing it for monitoring a specific webapp. Therefore I've decided to dive into its code to learn more about it to be able to decide whether it's suitable for our needs of monitoring the  <a title=\"wiki\" href=\"http://en.wikipedia.org/wiki/Pentaho\">Pentaho BI Platform</a> web application.</p><p>The unique features of Glassbox are that it tries to point out existing performance problems together with their likely causes and advices what to do about them and that it displays aggregated statistics about the high level &quot;operations&quot; in the monitored web app.<br /></p><h1>Basic Info about Glassbox </h1><p>Glassbox consists of a webapp UI that displays statistics and of a set of monitors that are injected into the observed webapp and collect data about its performance. Some of its characteristics are:<br /></p><ul><li>Simple installation (1.Deploy webapp; 2. Run postinstall script to copy jars etc.; 3. Restart AS with a command-line option to load glassbox aspects).<br /></li><li>AOP using AspectJ.</li><li>Preferably Java 5+ though it's also possible to use AspectJ with Java 1.4 and maybe 1.3.</li><li>Data not persistent (though this is on the roadmap). <br /></li><li>Layer aware (UI, logic - EJB, resources - DB, I/O, ...).</li><li>Customized monitors for popular frameworks (Spring MVC, ...).</li><li>UI concentrates on providing the right information at the right time with the necessary context. In other words it doesn't display tons of detailed data but a list of top-level operations highlighting the problematic (slow/failing) ones and providing detailes on likely cause(s) of the problems.</li></ul>If you are new to Glassbox I'd recommend you to have first a look at the presentation <a href=\"http://downloads.sourceforge.net/glassbox/glassboxIntro.ppt\">Glassbox Architecture &amp; Design</a> (Oct 25, 2008). You may also want to watch an older but still usefull <a href=\"http://video.google.co.uk/videoplay?docid=6266063760641634345\">Glassbox Tech Talk</a> video (Sep <span id=\"duration-and-date\"><span class=\"date\">25, 2006</span></span>). And if you're the visual type there's a <a href=\"http://sourceforge.net/project/screenshots.php?group_id=168588\">screenshot</a> of Glassbox UI.<br /><h1>How it works</h1><h2>Glossary<br /></h2><ul><li>Aspect (<a href=\"http://en.wikipedia.org/wiki/Aspect_%28computer_science%29\">wiki</a>): There're many definitions, for us this is a piece of code injected into the monitored application to perform the actual monitoring of a particular method in a particular class.</li><li>Components and resources: Glassbox breaks time spent in an operation down by the type of activity that consumed it distinguishing between 'components' such as database access or remote calls and 'resources' such as running java code, running native code, or thread waiting (usually I/O).</li><li>Layer: A monitored method can belong to one of application's layers of processing such as ui.controller or resource.database.statement.</li><li>Monitored method: Glassbox collect performance statistics only for selected important methods, for instance JDBC calls.<br /></li><li>Operation: An &quot;entry point&quot; of user requests into the application. Usually this is some high-level method such as a Struts Action's execute or JSP's service. Glassbox uses\noperations as the unit of monitoring service level agreements (SLA) and to analyze where time goes. Anything\nthat's used within an operation is considered a resource (EJB call, DB query...). (Though the notion of components shall be added in the future.)</li><ul><li>In the source code, the classes having Operation in their name are often also used to track monitored methods.<br /></li></ul><li>Request: a) Vaguely synonymous to a monitored method; b) In this text it often means a user-invoked request that resulted in some activity in the monitored web application (though I try to use the term <i>user request</i> to distinguish it from a) ).</li></ul><h2>Basic concepts</h2><p>Glassbox doesn't bother to monitor all methods that are invoked as a result of user request because it is not necessary and would incur higher overhead. It only monitors some especially significant methods of the call tree such as a Struts Action invocation or invocation of a data access method (being it simple JDBC or Hibernate). I call them &quot;<b>monitored methods</b>&quot;, while in Glassbox' terms they are either operations (the top-level ones) or resource/component request.<br /></p><p>The framework is aware of and takes care of tracking the <b>hierarchy of monitored methods</b> invoked during a single user request processing. This basically means that a monitored method may have a parent monitored method and that Glassbox stores both the aggregated duration of the higher level method and that of the nested one. For example, a JDBC executeQuery may be invoked from an EJB call, which is itself invoked from a Struts Action processing. Thus it can tell which processing layer or component/resource caused a particular top-level operation to be slow.</p><p>Glassbox is also aware of <b>layers</b> and monitored methods may be marked as belonging to a particular layer, e.g. the JDBC <font face=\"courier new,courier,monospace\">executeQuery</font> would belong to the layer resource.database.statement.</p><h2>Main components' behavior explained</h2><p>The main parts of Glassbox are:<br />\n</p><ul><ul><li>Monitors:\nPieces of code collecting detailed performance measurements of monitored methods. Usually they're implemented as aspects extending the glassbox framework,\nwhich are injected (woven) into the monitored webapp instance. But sometimes Glassbox uses also e.g. filters, listeners, callbacks, and timer tasks.<br /></li><li>Agent(s):\nHandle communication between the monitors and a client. In a\nclustered environment, a separate instance is on each server.<br /></li><li>Client: Collects monitoring data from agents and displays\nan aggregated view to a user. The most used one is the Glassbox web application but you can also use e.g. jconsole or implement another client. Usually you have only one client even in a clustered environment.<br /></li></ul></ul>\n<h3>Monitors</h3><p>Monitors are mostly aspects injected into a monitored web application or the related code. Usually a monitor observes one or few methods in a single class. When one of the method is invoked, it creates a Response object storing the details of the invocation (its id, parameters, ...) and, once it finishes, its performance data. If the method has been invoked as a part of processing of another monitored method, its Response will have the Response object of that method as its parent, in other words monitored methods can be (even indirectly) nested and this structure is preserved in the monitoring data structures. A typical example is a servlet calling an EJB doing some JDBC stuff.<br /></p><p>Responses are stored in a ThreadLocal stack, which makes it possible to really connect those Responses belonging to the processing of a single request, and once the top-level operation completes it can be considered as finished.<br /></p><h3>Agent</h3><p align=\"left\">There is one agent per server (i.e. JVM). It collects the detailed monitoring data from monitors and aggregates them by monitored method into &quot;statistics&quot; (Stats) objects. Stats contain summarized data for a monitored method over all of its execution (avg, min, max time...) together with detailed data for a limited number of those executions that were either slow or failed. There are statistics both for top-level monitored methods and for nested ones and they're aware of each other. These stats are stored in a global StatisticsRegistry (namely OperationTracker's registry).</p><p>There is also a special background job (ThreadMonitor) that monitors threads to detect CPU-intensive methods. This is done by taking snapshots of the thread stack in regular intervals and - if its execution time exceeds a predefined limit - by drawing a conclusion from these snapshots. (Note: This is an example of a timer task monitor.)<br /></p><h3>Web UI</h3><p>The Glassbox web user interface queries all registered agents for their data (see OperationsHelper.updateListOfOperations). The detailed and hierarchical statistics are turned into an OperationSummary for the top-level operation having also a list of &quot;findings&quot;, i.e. textual descriptions of problems with the operation. It contains average statistics and stats when slow and when failing.</p><p><br /></p><h2>Main components' behavior in detail<br /></h2><h3>Monitors</h3><p>To monitor a web application, Glassbox inserts\nmonitoring aspects into its code and related server code (e.g. its\njavax.servlet.Servlet implementation) during server startup using\nAspectJ. In its simplest form an aspect is nothing more than an XML\nfile mapping an existing aspect class to a method(s) of a particular\nclass.</p><p>The sequence of actions triggered by a user request towards a monitored webapp is:<br /></p><ol><li>A monitored method in the target web application is going to be invoked.</li><li>An\naspect associated with that method is invoked. It's connected to the\nmonitoring framework by extending a base monitor aspect class and\noptionally by calling some of the framework's methods.</li><li>The\nframework stores data about the monitored method/operation's name, layer and\ncomponent/resource and its start time. It also checks the thread local\nstack of responses to find out whether it's invoked as a\npart of processing some higher level monitored method and if it is the case\nthen it sets it as its parent.</li><li>The monitored method is\ninvoked and when it finishes, the framework stores its end time. If it\nfinished with an exception then it's first checked whether the\nexception should be indeed regarded as a failure and if yes, the\nexception data is stored as well. If the operation was slow or failed, the framework puts it on the list of slowest/recently failed operations and captures its parameters.<br /></li><li>When the original user\nrequest is processed completely, the framework aggregates data about\nits performance. This happens in StatsSummarizer, a ResponseListener. If the request processing was too slow with respect to&nbsp; predefined limits\n(SLA` usually &lt;1s in 90% of time) then it's stored into the slow operations list and the\nlayer/component that caused the delay is marked.</li></ol>Note: Monitors interact with a ResponseFactory to create and finish Responses and these actions trigger ResponseListener events. The most important ResponseListener is the StatsSummarizer but there're also others, for instance a listener that can log slow responses and a new one that captures a trace for a specific request. Since response listeners are invoked directly by the response factory, they execute in the same thread as the monitored method itself and therefore can safely use ThreadLocal variables to keep info of requests/responses belonging to a single user interaction.<br /><h3>Agent</h3><p>&nbsp;As said above, performance statistics are aggregated by monitored methods and are collected into a global statistics registry. The registry contains instances of PerfStats or CompositePerfStats, which also implements StatisticsRegistry to hold nested statistics, or a subclass such as OperationPerfStats. A registry is actualy a map of OperationDescriptions to their OperationPerfStats and can return a subset for a particular StatisticsType, for example UI, Database, Remote Call. </p><p>Let's see a partial example produced by OperationTracker.registry.dump(new StringBuffer(), 0):<br /><br /></p><pre>operation(type javax.servlet.Servlet; name org.pentaho.ui.servlet.AdhocWebService):glassbox.track.api.OperationPerfStatsImpl@12c3d18 operation(type javax.servlet.Servlet; name org.pentaho.ui.servlet.AdhocWebService)(# = 0, tm =0,00 ms,  #slow = 0, # fail = 0)\n    StatisticsTypeImpl 0 of class glassbox.track.api.UIStatisticsType:\n    StatisticsTypeImpl 1 of class glassbox.track.api.DatabaseStatisticsType:\n    StatisticsTypeImpl 2 of class glassbox.track.api.DatabaseConnectionStatisticsType:\n    StatisticsTypeImpl 3 of class glassbox.track.api.DatabaseStatementStatisticsType:\n    StatisticsTypeImpl 4 of class glassbox.track.api.SimpleStatisticsType:\n    StatisticsTypeImpl 5 of class glassbox.track.api.RemoteCallStatisticsType:\n    StatisticsTypeImpl 6 of class glassbox.track.api.TreeStatisticsTypeImpl:\n      time:Stats (tm=0,00 ms, slow=0)\n        StatisticsTypeImpl 0 of class glassbox.track.api.UIStatisticsType:\n        StatisticsTypeImpl 1 of class glassbox.track.api.DatabaseStatisticsType:\n        StatisticsTypeImpl 2 of class glassbox.track.api.DatabaseConnectionStatisticsType:\n        StatisticsTypeImpl 3 of class glassbox.track.api.DatabaseStatementStatisticsType:\n        StatisticsTypeImpl 4 of class glassbox.track.api.SimpleStatisticsType:\n        StatisticsTypeImpl 5 of class glassbox.track.api.RemoteCallStatisticsType:\n        StatisticsTypeImpl 6 of class glassbox.track.api.TreeStatisticsTypeImpl:</pre><p>An OperationPerfStats holds e.g. resourceTotalStats and otherComponentStats.<br /><br />*Stats also hold all other necessary information, for instance about slow/failing cases.<br /><br />OperationTracker also uses an instance of OperationAnalyzer, which is responsible for preparing data for all the nice output you can see in the UI. This includes summarizing the stats into OperationSummaries and detecting (based on the collected stats) what is the cause of a slow/failing operation and providing this info in the form of OperationAnalysis.<br /></p><h3>Web UI</h3><p>The web UI, aside of handling installation of Glassbox monitoring into a server, maintains connections to all the agents (or to the single local agent in a non-clustered environment) and retrieves all the needed summaries and analysis from them via its OperationHelper.</p><p>Currently the web UI only provides statistics about a top-level operation and its list of detected problems (slow SQL, excessive CPU in method XY, ...) with troubleshooting details but you cannot use it to view statistics for its nested monitored methods/components. However you can access those detailed statistics e.g. via the JMX interface.</p><p>&nbsp;</p><h2><b>Additional notes<br /></b></h2><ul><li>You can view results and manage Glassbox using JMX: <font face=\"courier new,courier,monospace\">jconsole\nservice:jmx:rmi:///jndi/rmi://localhost:7232/GlassboxTroubleshooter</font>&nbsp; . Check $jboss/lib/glassbox/glassbox.properties and glassbox.war/WEB-INF/lib/agent.jar/beans.xml for settings.<br /></li><li>You can disable/enable some monitors at runtime via JMX, for example RemoteCallMonitor or JdbcMonitor. I'm not sure whether there is a way to dis/enable on a more granular level.<br /></li></ul><h2>Glassbox API - Main classes</h2><p>Here we will learn about the most important Glassbox classes, what they can do for you, and how they relate to each other. <br />Classes without an extension are regular java classes while those with .aj are AspectJ classes and need to be compiled by the aspectj compiler.<br /></p><h3>Response API</h3><p>This API is used by the monitoring aspects to produce the monitoring data that is than further analyzed and presented to the user by Glassbox.<br /></p><ul><li>glassbox.response.<b>Response</b></li><ul><li>Collects data about the system's response while processing a request. These are typically nested, i.e., we track times, parameters, etc. for Servlet requests that result in Struts action requests that result in a database query. A response belongs to a particular layer and may have a parent response (when nested). It has also a duration and a status (processing/suceeded/failed/...). Actually it can hold any context, so a monitor can store whatever relevant data is\nneeded (e.g., this can be useful for a custom metric that your\napplication wants to track). <br /></li><li>get/setLayer, get/setParent(Response), duration, status (ok/failed/processing..), </li></ul><li>glassbox.response.<b>(Default)ResponseFactory.aj</b></li><ul><li>This is a helper class for manipulation requests including their creation while taking care about their proper nesting and setting their start/end times. It uses a thread local stack to keep track of nested requests and System.currentTimeMillis() for timing.</li><li>As noticed elsewhere, its used by monitors to create/finish Responses and produces the appropriate events for that and also manages a list of ResponseListeners.<br /></li></ul></ul><h3>Monitor API</h3><p>The monitoring aspects extend this API and it also includes many specific monitoring aspects such as EjbCallMonitor.aj and StrutsRequestMonitor.aj.<br /></p><ul><li>glassbox.monitor.<b>OperationFactory</b> - create OperationDescription(Impl) from JSP path or from a class name - see e.g. MvcFrameworkMonitor.aj</li><li>glassbox.monitor.<b>AbstractMonitorClass</b></li><ul><li>isEnabled (calls RuntimeControl.aspectOf(this).isEnabled()), setEnabled, setThisThreadEnabled, ...; failureDetectionStrategy (recordException: failureDetectionStrategy.getFailureDescription(throwable)); getLayer();</li><li>accesses &amp; modifies responseFactory.getLastResponse() - e.g. in endNormally (-&gt; response.complete()), endException(); begin(key, layer) -&gt; createResponse</li><li>Ron's note: One reason for having AbstractMonitorClass is to allow using Java-5\nannotation-based aspects with the Glassbox framework, either for\nAspectJ extensions written in that style or for Spring annotation-based\naspects.</li></ul></ul><h3>Tracking API</h3><p>An addition to the Response API to keep track of requests (monitored methods) etc.<br /></p><ul><li>glassbox.track.api.<b>Request</b> - represent a specific instance of a request to something, i.e. an invocation of a monitored method. They can be compared based on elapsed time.</li><li>glassbox.track.api.<b>FailureDetectionStrategy</b> - shall an exception thrown by a monitored method be regarded as its failure or not?</li><li>glassbox.track.api. Call/Failure/<b>Operation</b>/SQLFailure <b>Description</b> - OperationDescription has a type (e.g. &quot;HttpServlet&quot;), a name (e.g. the servlet's name), context (e.g. the web app's context root) and perhaps a parent OperationDescription if nested.</li><li>glassbox.track.api.SlowRequestDescriptor - describes a request whose processing was too slow; it has among others the attributes StackTraceElement slowestTraceElement and mean/slow/total counts.</li><li>glassbox.track.api.UsageTrackingInfo - attributes eventTime, eventCpuTime, eventUserCpuTime (uses ThreadMXBean)</li></ul><h3>Analysis API</h3><p>Used by the framework and UI to analyse the monitoring data and present an aggregated view to the user. These are mostly only value objects while the logic is in the Agent API.<br /></p><ul><li>glassbox.analysis.api.<b>TimeDecomposition</b> - Captures mutually exclusive breakdown of overall time by component/resource. Components: dispatch (in common code above operation), other (other, undefined areas), db access, remote calls; resources: running java code, running native code, waiting (I/O...), thread contention.</li><li>glassbox.analysis.api.<b>OperationAnalysis</b> - TimeDecomposition getComponentDecomposition() (db, cpu, i/o, dispatch...), TimeDecomposition getResourceDecomposition() (by thread use: runnable, blocked, waiting, etc.); getSlowThresholdMillis(); getMeanCpuTime() ...; isFailing(), isSlow();</li><li>glassbox.analysis.api.<b>SummaryStats</b> - aggregated statistics for a monitored method - its accumulatedTime, count (number of hits), mean time</li></ul><h3>Agent API</h3><p>Collect data from monitors, summarize it, analyze problems, and provide the outputs to the Web UI.<br /></p><ul><li>glassbox.client.persistence.jdbc.BackupDaemon - stores agent connections (but not any monitored data) into a database (by default an embedded hsqldb - see the <i>myDataSource</i> below).</li><li>glassbox.monitor.thread.<b>ThreadMonitor</b>15Impl: This monitor periodically grabs thread dumps for all threads that are processing user requests. It runs in a daemon thread collecting the dumps in preset intervals. Creates instances of glassbox.monitor.thread. <b>OperationSample</b> when sampling a monitored thread. When a monitored thread finishes, it results perhaps in a call to ThreadSummarizer.summarize, which updates the assoc. CompositePerfStats.<br /></li><li>glassbox.monitor.thread.ThreadMonitorIntegration.aj: starts a ThreadMonitor after StatsSummarizer.startTopLevelStats|startNestedLaterOperation</li><li>glassbox.summary.<b>StatsSummarizer</b>.aj (implements ResponseListener): ResponseFactory invokes its startedResponse/finishedResponse when appropriate; startedResponse =&gt; update ThreadStats including StatisticsRegistry, invoke startedStats which may results in starting a ThreadMonitor</li><ul><li>uses glassbox.track.api.StatisticsRegistry stored in a thread local variable of the type ThreadStats together with first/last operation key (OperationPerfStats)</li></ul><li>glassbox.track.<b>OperationTracker</b> (singleton): used by GlassboxServiceImpl to analyze/list/... operations. Holds a global StatisticsRegistry registry and an OperationAnalyzer.<br /></li><ul><li>glassbox.analysis.OperationAnalyzer: Analyses the collected statisticts to detect problems and their causes. It uses (Default)TimeDecomposition.It also makes OperationSummaries from the stats further used by the UI.</li></ul><ul><li>Note: in agent.jar the Spring config file beans.xml defines a bean <i>operationTracker</i> of the type glassbox.track.OperationTrackerImpl (implements OperationTracker, StatisticsRegistry) - this is used to collect all the stats in the monitored app. It's used by the bean <i>glassboxService</i> (glassbox.agent.control.GlassboxServiceImp).</li></ul><li>glassbox.agent.control.<b>GlassboxServiceImpl</b> (singleton): its listOperations() (delegation to OperationTrackerImpl.listOperations()) is invoked using a local/remote call from the glassbox UI webapp (OperationHelper) to collect operations (stats) from the given server and it also provides problem analysis to the UI in a similar manner.. I suppose that there is only a single instance of this class in a JVM.</li></ul><h3>UI Web App's API<br /></h3><p>The Spring configuration file glassbox.war/WEB-INF/applicationContext.xml&nbsp; defines among others the following beans:<br /></p><ul><li>a <i>backupDaemon</i> - regarding its function see glassbox.client.persistence.jdbc.BackupDaemon above. See also glassbox.client.persistence.jdbc.PersistChanges. It's schedule is def. ibidem by scheduledTask with the default period of 10000 and it uses indirectly <i>myDataSource</i> defined there as well. </li><ul><li>Note: To override the data source used to store client configuration\nincluding remote connections to open, you can define the System\nproperty glassbox.config.ds (this is configured in\nthe applicationContext.xml).</li></ul><li><i>agentManager</i> (glassbox.client.remote.DistributedAgentManager).</li><li><i>glassboxService</i> (org.springframework.remoting.httpinvoker.HttpInvokerProxyFactoryBean).</li></ul>Classes of interest:<br /><ul><li>glassbox.client.helper.<b>OperationHelper</b> - updates statistics to display by&nbsp; calling listOperations on the remote agents.</li><li>glassbox.client.pojo.OperationData - monit. data collected and used by the UI It only adds source and agent identification to its nested <b>OperationSummary</b>, holding the actual statistic (operation count, is failing, is slow, avg time; nested OperationDescription that might have a parent too).</li></ul><h1>Customizing Glassbox for your webapp</h1><p>There're two ways of customizing Glassbox for monitoring of a particular webapp:<br /></p><ol><li>Adding monitors<br /></li><li>Glassbox plugins mechanism for advanced customization.</li></ol><h2>1. Adding monitors </h2><p>You can apply an existing monitoring aspect to a new method using AspectJ weaving rules described in an aop.xml file thus turning the method into a monitored method or you can even create a new monitoring aspect extending a base Glassbox aspect, putting it - perhaps together with an aop.xml - on the monited webapp's classpath.</p><p>Very valuable and inspiring information about this are in the aforementioned presentation <a href=\"http://sourceforge.net/project/platformdownload.php?group_id=168588\">Glassbox Architecture &amp; Design</a>. <br /></p><h3>Coding-less addition of a monitor</h3><p> Quoting the User Guide:</p><p>--------&nbsp;</p><p><br><br><br><br><br><br>\t\n\t\n\t<br><br></p><p style=\"margin-bottom:0;\">You can simply extend the Glassbox\ndefinition of operations by creating a new XML file with these\ncontents:</p>\n<pre>&lt;aspectj&gt;\n  &lt;aspects&gt;\n      &lt;concrete-aspect name=\"ServiceProcessingMonitor\"\n\t    \t\textends=\"glassbox.monitor.ui.TemplateOperationMonitor\"&gt;\n          &lt;pointcut name=\"methodSignatureControllerExecTarget\"\n                    expression=\"within(com.myco.service..*)\"/&gt;\n      &lt;/concrete-aspect&gt;\n  &lt;/aspects&gt;\n&lt;/aspectj&gt;\n</pre>\n<p>Note: If you only want to monitor another method invoked during processing of something already regarded as an operation you should rather extend the glassbox.monitor.MethodMonitor.<br /></p><p>You can then add this file to a META-INF subdirectory of a\ndirectory on your classpath or add a jar containing the file at the\nlocation META-INF/aop.xml. For Tomcat, you might just create the\ndirectory common/classes/META-INF and install your custom aop.xml\nfile there.&nbsp;</p><h3>Implementing a new monitor</h3><p><i>Warning: This is only my idea what is necessary to be done and may contain mistakes and false ideas.</i> <br /></p><p>To implement a new monitoring aspect you should do at least the following: <br /></p><ul><li>Extend <font face=\"courier new,courier,monospace\">glassbox.monitor.AbstractMonitor</font></li><li>Define the pointcuts (i.e. to what methods to apply this monitor)</li><li>Redefine the abstract pointcut <font face=\"courier new,courier,monospace\">monitorEnd()</font> to apply to the monitored method(s) so that the parent class detects when it finishes.</li><li>Either redefine tha abstract pointcut <font face=\"courier new,courier,monospace\">monitorBegin(Object identifier)</font> to allow the parent class to automatically register the beginning of the monitored operation or define your own advice (method) that is run when a custom pointcut is encountered; usually this is a before advice. The <font face=\"courier new,courier,monospace\">identifier</font> should be e.g. an OperationDescription. Inside a custom advice:<br /></li><ul><li>(Re)implement some methods such as <font face=\"courier new,courier,monospace\">getLayer()</font>.<br /></li><li>Create an <font face=\"courier new,courier,monospace\">OperationDescription</font> for the operation, likely using the inherited <font face=\"courier new,courier,monospace\">operationFactory</font>.<br /></li><li>Call one of the inherited <font face=\"courier new,courier,monospace\">begin(..)</font> methods (see <font face=\"courier new,courier,monospace\">AbstractMonitorClass.aj</font>), passing the OperationDescription as the 1st argument, i.e. as a key. This will return a <font face=\"courier new,courier,monospace\">glassbox.response.Response</font> object.</li><li>Store some context data into the generated response, using e.g. <font face=\"courier new,courier,monospace\">response.set</font>(Response.PARAMETERS, &lt;the monitored method's arguments from AspectJ's thisJoinPoint.getArgs()&gt;).</li></ul></ul><p>Note:&nbsp; If you have it override getLayer() to return Response.RESOURCE_SERVICE and the monitored method is slow then Glassbox will report it as a slow remote call. <br /></p><h2>2. Glassbox plugins mechanism</h2><p>It's possible to extend Glassbox with application-specific extensions using the API glassbox.config.extension.api. Simply adding monitors doesn't need it: you can just deploy a monitor jar with aspects to the classpath, and an app can simply call on the response API. The PluginRegistry supports deeper extensions, like adding custom operations (see interface glassbox.config.extension.api.OperationPlugin).</p><p>Ron explains (2008-10-25): Glassbox lets you customize a variety of facets using plugins.\nOperation plugins let you add an operation type that can extend how\nGlassbox summarizes and analyzes the operation (to detect service level\nviolations) and how the UI renders these. Glassbox plugins also let you\ndefine a connection provider so you can write custom code to define\nwhat connections in a cluster/server farm should be opened (allowing\ndiscovery instead of manual configuration). Most recently I've also\nadded a runtime controller that lets you change behavior at runtime\n(e.g., requesting that a request on a specific thread be monitored). <br /></p><p>Operation plugins really shine if you need to add in different service levels, or\nwant a custom display to summarize problems (e.g., Ron used this to\ndetect an out of date cache for one custom project). <br /></p><p>Hopefully some documentation for creating plugins will be created soon.<br />&nbsp;</p><br><br><h2>3. Restricting what to monitor</h2><p>Currently Glassbox monitors any web application deployed on the app. server including itself and also some common code like JDBC drivers (which may be invoked not only from a web application but also by the server's daemons etc.). If you don't want to monitor all of that, for instance to decrease the overhead and to make the outputs easier to read, there are few things you can do.</p><p>Glassbox yet doesn't support any filtering but you can:</p><br><br><ol>\n<li>You can avoid instrumentation of specific\napplications on the server by deploying a META-INF/aop.xml file in\ntheir classpath that disables weaving into any classes (although that\nwould still track calls to common classes like JDBC drivers and app\nserver servlets).<br />Example (MyApp.war/WEB-INF/classes|MyApp.ear)/META-INF/aop.xml:\n<code></code><pre>&lt;aspectj&gt;\n   &lt;weaver&gt;\n      &lt;exclude within=\"*\"/&gt;\n   &lt;/weaver&gt;\n&lt;/aspectj&gt;\n</pre>\n</li>\n<li>Instead of load-time weaving (LTW) you can perform offline weaving of Glassbox aspects only into the code of the web applications that interest you and perhaps into some common server code that you also need to be monitored, for instance a JDBC driver. An additional benefit is that you'll get rid of the longer class loading at server startup.</li></ol><p> <br /></p><br><br><h1>A word about memory overhead</h1><br><br><p> According to the aforementioned presentation of Glassbox design &amp; architecture it can consume roughly 20% more memory than without Glassbox. Ron further explains:</p><br><br><blockquote cite=\"https://sourceforge.net/forum/message.php?msg_id=5582421\">\n<p>20% is a rough guideline - it varies quite a bit in specific cases. The\nbiggest area where Glassbox adds overhead is indeed from AspectJ\nload-time weaving, most specifically the memory overhead from handling\nJSP's - the load-time weaving system uses a little more than 1 megabyte\nof memory for each loader, and each JSP gets its own loader. The\nAspectJ project has been working on this area - see <a href=\"https://bugs.eclipse.org/bugs/show_bug.cgi?id=227484\" title=\"AspectJ issue\">Reducing weaver memory usage over time.</a>\nWe need to merge in the updated work on AspectJ to the version of\nAspectJ we're using with Glassbox, which also reduces memory overhead a\nlot. You could try the patch in that bug report with AspectJ 1.6.1's\naspectjweaver.jar to see if it has better memory performance.&nbsp;<br />\n&nbsp;<br />\nAnother approach that might be simpler and yet could help a lot is a\nhybrid one: if you just precompile your application's JSPs you will see\nfar lower overhead.&nbsp;<br />\n&nbsp;<br />\nGlassbox does work best if it is weaving some server classes, but in\nmany cases you can get the desired visibility if you do offline weaving\nof your application and a few key libraries, like your JDBC driver and\ne.g., web services callers. If you want to try that, I'd be glad to\nhelp. &nbsp;<br />\n&nbsp;<br />\nThere is one other area where Glassbox can consume significant memory:\nit records statistics based on the structure of components and\nresources and how calls are nested. For a fairly static application\nthis is normally constrained and quite small, but some applications\ngenerate names/queries/etc. dynamically and Glassbox can build\nincreasingly large trees of statistics, which consume memory also. We\ndefinitely want to address this area - I'm leaning towards not\nrecording details for quick operations, and only recording information\nfor things that run often and are taking noticeable time. We'd like to\nknow about cases where this happens so we can test better approaches. </p>\n</blockquote>\n<p>-</p><h2>&nbsp;Update 2009-01-21</h2><p>I've implemented persistence for the detailed monitoring data of Glassbox. Unfotunately Glassbox generates too <a href=\"https://sourceforge.net/forum/forum.php?thread_id=2514783&amp;forum_id=575670\">many uninteresting entries</a> and for the methods of interest it doesn't provide <a href=\"https://sourceforge.net/forum/forum.php?thread_id=2515080&amp;forum_id=575670\">enough data</a>, you can read more about this in the glassbox forums linked to above. I had unfortunately no time to try to deal with these problems.<br /></p><p align=\"left\">If you're anyway interested in the DB persistence, you can try it - <a href=\"http://jakubholy.net/source/GlassboxDbPersister.zip\">download GlassboxDbPersister.zip</a> and read the contained README.txt.</p><h2 align=\"left\">Resources</h2><ul><li><p align=\"left\">A nice article about <a href=\"http://viralpatel.net/blogs/2009/03/performance-monitoring-using-glassbox.html\">Performance Monitoring using Glassbox</a> (03-03-2009) with many screenshots and some code samples.<br /></p></li></ul>",
  "excerpt": ""
 },
 {
  "title": "Injecting better logging into a binary .class using Javassist",
  "published": "2008-10-02 08:48:39",
  "postType": "post",
  "slug": "/2008/10/02/injecting-better-logging-into-a-bi/",
  "status": "publish",
  "tags": [
   "AOP",
   "java",
   "logging"
  ],
  "categories": [
   "Languages"
  ],
  "content": "Have you ever been strucked by a completely useless exception message somewhere from the depth of a 3rd party application or library you had to use in your code? Have you ever wanted the bloody nameless programmer to have written a truly informative and helpful error message so that you wouldn't need to spend hours trying to figure out what was the problem that would have been easily discovered if only more context information available at the moment when the exception occured was included in its error message? Have you wondered how only you could inject the necessary logging into the spot? Read on to get the answer.<br><br>Update 6/2010: You may also want to read the follow-up blog <a title=\"Permanent link to Implementing build-time  bytecode instrumentation with Javassist\" rel=\"bookmark\" href=\"../2010/06/25/implementing-build-time-instrumentation-with-javassist/\">Implementing build-time  bytecode instrumentation with Javassist</a>.<br><br>Recently I was testing my extension to Saba, a monstrous J2EE learning management system, and got an exception from a Saba class saying that the expected and actual data types of a custom attribute don't match.  The problem was that I had no idea which one of the 10s of custom attributes could be the cause and I even wasn't sure which object's attributes I should check. It would be so much easier if the \"nameless bloody Saba programmer\" (no offense :-)) included the attribute's name and preferably also its actual &amp; expected data types and the actual and new values. How could I insert there logging of these properties? Needless to say that I had to use <strong>Java 1.4</strong> (no agents...) and couldn't afford more than modifying this single class file (i.e. no additional libraries etc.) because the changes I could do to the development environment where the application ran were limited.<br><br>Of course the easiest would have been to decomile the class, add the loging before the exception is thrown, recompile it and replace it on the server. But not only is decompiling illegal here, it also sometimes simply doesn't work. Fortunatelly there is another solution - <a title=\"Javassist home\" href=\"http://www.jboss.org/javassist/\">JBoss Javassist</a> is a byte code manipulation library that supports not only runtime manipulation but also post-comilation time manipulation, i.e. you can modify and save the class and use it to replace the original file. There are quite a few byte code manipulation libraries but Javassist has the great advantage that you don't need to know much about bytecode, you can simply pass a String with java statements that should be inserted before/after/... method call or into a new catch statement. There is a nice <a title=\"Javassist tutorial, page 2\" href=\"http://www.csg.is.titech.ac.jp/~chiba/javassist/tutorial/tutorial2.html\">tutorial</a> that describes it (see part 4.1, Inserting source text at the beginning/end of a method body):\r\n<pre>addCatch() inserts a code fragment into a method body so that the code fragment is executed when the method body\r\nthrows an exception and the control returns to the caller. In the source text representing the inserted code fragment,\r\nthe exception value is referred to with the special variable $e.<br><br>For example, this program:<br><br>      ClassPool pool = ClassPool.getDefault();\r\n      CtClass compiledClass = pool.get(\"mypackage.MyClass\");\r\n      CtMethod m = compiledClass.getDeclaredMethod(\"myExceptionThrowingMethod\");\r\n      CtClass etype = ClassPool.getDefault().get(\"java.io.IOException\");\r\n      m.addCatch(\"{ System.out.println($e); throw $e; }\", etype);<br><br>translates the method body represented by m into something like this:<br><br>      try {\r\n          the original method body\r\n      }\r\n      catch (java.io.IOException e) {\r\n          System.out.println(e);\r\n          throw e;\r\n      }<br><br>Note that the inserted code fragment must end with a throw or return statement.\r\n</pre>\r\nYou can use $e to access the exception, $0 to access \"this\", $1 to access the 1st parameter of the method etc. At the end you just call <span style=\"font-family:courier new, courier, monospace;\">compiledClass.writeFile();</span> and use the modified mypackage/MyClass.class to replace the original class in the application.<br><br>Lovely, isn't it?",
  "excerpt": ""
 },
 {
  "title": "Add method tracing (params, result) to existing application w/o modifying it",
  "published": "2008-09-26 13:55:49",
  "postType": "post",
  "slug": "/2008/09/26/add-method-tracing-params-result-t/",
  "status": "publish",
  "tags": [
   "AOP",
   "java"
  ],
  "categories": [
   "Languages"
  ],
  "content": "<p>\r\nHave you ever needed to learn what's going on in a 3rd-party java application and yet didn't want to debug it and step through it? Were you wishing to be able to see what methods get called in what order together with their actual parameters and return values? There is a &quot;simple&quot; solution: AspectWerkz.</p><p>Quick start:</p><ol><li>Download&nbsp; <a href=\"http://aspectwerkz.codehaus.org/\">AspectWerkz </a>(I had 2.0)</li><li>Create an aop.xml where you define what methods to observe</li><li>(Optional) Modify the tracer class</li><li>Run the target application with the aspect under Java 5 (AspectWerkz supports also older JVM but that's more tricky):</li></ol><p>$JRE5_HOME/bin/java <br />&nbsp;&nbsp;&nbsp; -javaagent:lib/aspectwerkz-jdk5-2.0.jar -Daspectwerkz.definition.file=/path/to/the/aop.xml<br />&nbsp;&nbsp;&nbsp; -cp &lt;some jars from lib/, see below&gt;:./bin:&lt;your classpath&gt;<br />&nbsp;&nbsp;&nbsp; yourpackage.YourMainClass</p><p>&nbsp;Classpath:<br />&nbsp;&nbsp; &nbsp;aspectwerkz-core-2.0.jar<br />&nbsp;&nbsp; &nbsp;aspectwerkz-2.0.jar<br />&nbsp;&nbsp; &nbsp;commons-collections.jar<br />&nbsp;&nbsp; &nbsp;commons-beanutils.jar<br />&nbsp;&nbsp; &nbsp;commons-logging.jar<br />&nbsp;&nbsp; &nbsp;dom4j-1.4.jar, qdox-1.4.jar, concurrent-1.3.1.jar, trove-1.0.jar (see aspectwerkz-2.0.jar's Manifest)</p><p>&nbsp;See: aspectwerkz-2.0\\src\\samples\\examples\\logging\\* , aspectwerkz-2.0\\src\\samples\\examples\\proxy\\tracing\\*<br /></p><p>aop.xml example:</p><pre>&lt;!--  the aspectwerkz.definition.file --&gt;\r\n&lt;aspectwerkz&gt;\r\n    &lt;system id=\"aopRunttimeLoggerExample\"&gt;\r\n        &lt;package name=\"net.jakubholy.jeeutils.injectedlogger\"&gt;\r\n            &lt;aspect class=\"TracingAspect \"&gt;\r\n                &lt;!-- Expression: any methods in the package including constructors and excluding the aspect class --&gt;\r\n                &lt;pointcut name=\"myPointcut\" expression=\"( execution(* org.hibernate...*(..)) OR execution(org.hibernate.tool.hbm2x...new(..)) ) AND !within(net.jakubholy.jeeutils.injectedlogger.TracingAspect) AND !within(org.hibernate.tool.hbm2x.TemplateHelper) AND !within(org.hibernate.tool.hbm2x.AbstractExporter)\"/&gt;\r\n                &lt;advice name=\"beforeMethod\" type=\"before\" bind-to=\"myPointcut\"/&gt;\r\n                &lt;advice name=\"afterMethod\" type=\"after\" bind-to=\"myPointcut\"/&gt;\r\n            &lt;/aspect&gt;\r\n        &lt;/package&gt;\r\n    &lt;/system&gt;\r\n&lt;/aspectwerkz&gt;\r\n</pre><p><br />And now the tracing class itself:</p>\r\n<pre><code>\r\npackage net.jakubholy.jeeutils.injectedlogger;<br><br>import java.util.Collection;\r\nimport java.util.Iterator;\r\nimport java.util.Map;\r\nimport org.apache.commons.beanutils.BeanUtils;\r\nimport org.codehaus.aspectwerkz.joinpoint.*;<br><br>/**\r\n * AspectWerkz aspect adding tracing of parameters and return values to methods.\r\n *\r\n * &lt;p&gt;\r\n * See aspectwerkz-2.0\\src\\samples\\examples\\proxy\\tracing\\TracingAspect.java -\r\n * some very good ideas.\r\n * &lt;/p&gt;\r\n *\r\n * &lt;p&gt;\r\n * In AspectWerkz definition file you should define this aspect like:\r\n * &lt;/p&gt;\r\n * &lt;pre&gt;&lt;code&gt;\r\n *      &lt;package name=&quot;net.jakubholy.jeeutils.injectedlogger&quot;&gt;\r\n            &lt;aspect class=&quot;TracingAspect &quot;&gt;\r\n                &lt;pointcut name=&quot;myPointcut&quot; expression=&quot;execution(* net.jakubholy...*(..)) AND !within(net.jakubholy.jeeutils.injectedlogger.TracingAspect)&quot;/&gt;\r\n                &lt;advice name=&quot;beforeMethod&quot; type=&quot;before&quot; bind-to=&quot;myPointcut&quot;/&gt;\r\n                &lt;advice name=&quot;afterMethod&quot; type=&quot;after&quot; bind-to=&quot;myPointcut&quot;/&gt;\r\n            &lt;/aspect&gt;\r\n       &lt;/package&gt;\r\n * &lt;/code&gt;&lt;/pre&gt;\r\n * &lt;p&gt;\r\n * Replace 'net.jakubholy' in the execution with the package you want to\r\n * enable tracing for. Examples:\r\n * &lt;/p&gt;\r\n * &lt;ul&gt;\r\n * &lt;li&gt;All subpackages of mypackage: &lt;code&gt;execution(* com.mycompany.mypackage...*(..)&lt;/code&gt;\r\n * &lt;li&gt;All methods in MyClass: &lt;code&gt;execution(* com.mycompany.mypackage.MyClass.*(..)&lt;/code&gt;\r\n * &lt;li&gt;All methods in MyClass: &lt;code&gt;execution(* ..MyClass.*(..)&lt;/code&gt;\r\n * &lt;li&gt;Only myMethod in MyClass: &lt;code&gt;execution(* com.mycompany.mypackage.MyClass.myMethod(..)&lt;/code&gt;\r\n * &lt;li&gt;Only public methods in mypackage: &lt;code&gt;execution(public * com.mycompany.mypackage...*(..)&lt;/code&gt;\r\n * &lt;li&gt;Constructors in mypackage and below: execution(com.mycompany.mypackage...new(..)) )\r\n * &lt;/ul&gt;\r\n *\r\n * TODO Add support for starting/stopping tracing when a configurable pattern (method+params+retval?) is encountered\r\n */\r\npublic class TracingAspect {\r\n    private boolean doTrace = false;<br><br>    private void log(String logMsg) {\r\n        final String threadId = &quot;thread #&quot; +\r\n            Thread.currentThread().getId() + &quot;(&quot; + Thread.currentThread().getName() + &quot;)&quot;;\r\n        // TODO use asynch. loggin e.g. via Log4J's asynch. appender\r\n        if (doTrace) System.err.println(&quot;[TracingAspect &quot;+threadId+&quot;] &quot; + logMsg);\r\n    }<br><br>    /**\r\n     * 'Advice' called before a method or constructor.\r\n     */\r\n     public void beforeMethod(JoinPoint joinPoint) {\r\n         Rtti rtti = joinPoint.getRtti();\r\n         if (rtti instanceof MethodRtti) {\r\n             MethodRtti methodRtti = (MethodRtti) rtti;<br><br>             if (!doTrace) {\r\n                 doTrace = isStartTracingSignatureMatch(methodRtti);\r\n                 log(&quot;INFO tracing enabled&quot;);\r\n             }<br><br>             log(&quot;{BEFORE method &quot; + methodRtti.getDeclaringType().getName() + &quot;.&quot; + methodRtti.getName());\r\n         } else if (rtti instanceof ConstructorRtti) {\r\n             ConstructorRtti methodRtti = (ConstructorRtti) rtti;\r\n             log(&quot;{BEFORE constructor &quot; + methodRtti.getName());\r\n         } else {\r\n             log(&quot;{ERROR: not a method! rtti=&quot; + rtti);\r\n         }\r\n     }<br><br>    /**\r\n     * 'Advice' called after a method or constructor.\r\n     */\r\n     public void afterMethod(JoinPoint joinPoint) {\r\n         Rtti rtti = joinPoint.getRtti();\r\n         StringBuffer sb = new StringBuffer();<br><br>         if (rtti instanceof MethodRtti) {\r\n             MethodRtti methodRtti = (MethodRtti) rtti;\r\n             Object[] params = methodRtti.getParameterValues();\r\n             Class[] ptypes = methodRtti.getParameterTypes();<br><br>             boolean stopTracing = doTrace &amp;&amp; isEndTracingSignatureMatch(methodRtti);<br><br>             if (doTrace) {\r\n                 sb.append(methodRtti.getDeclaringType().getName() + &quot;.&quot; + methodRtti.getName() + &quot;(&quot;);\r\n                 // Describe parameters\r\n                 for (int i = 0; i &lt; params.length; i++) {\r\n                     sb.append(ptypes[i].getName() + &quot;: &quot; + describe(params[i]))\r\n                         .append((i+1 &lt; params.length)? &quot;, &quot; : &quot;&quot;);\r\n                }<br><br>                 // Describe output\r\n                 Object output = methodRtti.getReturnValue();\r\n                 sb.append(&quot;): &quot;).append(methodRtti.getReturnType().getName()).append(&quot;: &quot;)\r\n                     .append(describe(output));<br><br>                 // Log\r\n                 log(&quot;AFTER method &quot; + sb + &quot;}&quot;);<br><br>                 if (stopTracing) {\r\n                     log(&quot;INFO: tracing disabled; method=&quot; + methodRtti.getName());\r\n                     doTrace = false;\r\n                 }\r\n             }\r\n         } else if (rtti instanceof ConstructorRtti) {\r\n             ConstructorRtti methodRtti = (ConstructorRtti) rtti;\r\n             Object[] params = methodRtti.getParameterValues();\r\n             Class[] ptypes = methodRtti.getParameterTypes();\r\n             sb.append(&quot;constructor &quot; + methodRtti.getName() + &quot;(&quot;);<br><br>             // Describe parameters\r\n             for (int i = 0; i &lt; params.length; i++) {\r\n                 sb.append(ptypes[i].getName() + &quot;: &quot; + describe(params[i]))\r\n                     .append((i+1 &lt; params.length)? &quot;, &quot; : &quot;&quot;);\r\n            }\r\n             sb.append(&quot;)&quot;);<br><br>             // Log\r\n             log(&quot;AFTER constructor &quot; + sb + &quot;}&quot;);\r\n         }\r\n     }<br><br>     /**\r\n      * Return a string representation of the &lt;var&gt;target&lt;/var&gt;\r\n      * containing its properties and their values.\r\n      * @param target\r\n      * @return\r\n      */\r\n     private String describe(Object target) {\r\n         String result;\r\n         StringBuffer sb = new StringBuffer();<br><br>         // SPECIAL: Hibernate &amp; hbm2java generation\r\n         // When running hbm2java, avoid InvocationTargetException &lt;- MappingException: entity class not found &lt;- ClassNotFoundException\r\n         // for a class yet to generate\r\n         if (target != null &amp;&amp; target.getClass().getName().startsWith(&quot;org.hibernate.mapping.&quot;)) {\r\n             return target.toString();\r\n         } // hibernate mapping<br><br>         if (target == null) {\r\n             result = &quot;null&quot;;\r\n         } else if (target.getClass().isArray()) {\r\n             // ARRAY\r\n             Object[] targetArray = (Object[]) target;\r\n             sb.append(&quot;#&quot;).append(targetArray.length).append(&quot;[&quot;);<br><br>             for (int i = 0; i &lt; targetArray.length; i++) {\r\n                sb.append(describe(targetArray[i]));\r\n                if (i &lt; targetArray.length - 1) {\r\n                    sb.append(&quot;, &quot;);\r\n                }\r\n            }<br><br>             sb.append(&quot;]&quot;);\r\n             result = sb.toString();\r\n         } else if (target instanceof Collection) {\r\n             Collection targetColl = (Collection) target;\r\n             sb.append(&quot;#&quot;).append(targetColl.size()).append(&quot;[&quot;);\r\n             for (Iterator iter = targetColl.iterator(); iter.hasNext();) {\r\n                Object element = (Object) iter.next();\r\n                sb.append(describe(element))\r\n                    .append(iter.hasNext()? &quot;, &quot; : &quot;&quot;);\r\n            }\r\n             sb.append(&quot;]&quot;);\r\n             result = sb.toString();\r\n         } else if (target instanceof String) {\r\n             result = &quot;'&quot; + target + &quot;'&quot;;\r\n         } else if (target.getClass().getName().startsWith(&quot;java.lang.&quot;)) {\r\n             result = target.toString();\r\n         } else {\r\n             sb.append(&quot;{&quot;);<br><br>             try {\r\n                 final String separ = &quot;, &quot;;\r\n                 Map props = BeanUtils.describe(target);\r\n                 for (Iterator iter = props.entrySet().iterator(); iter.hasNext();) {\r\n                    Map.Entry nameValue = (Map.Entry) iter.next();\r\n                    if (!&quot;class&quot;.equals(nameValue.getKey())) {\r\n                    sb\r\n                        .append(nameValue.getKey()).append('=')\r\n                        .append(nameValue.getValue())\r\n                        .append(separ);\r\n                    }\r\n                 } // for props<br><br>                 // remove trailing separator if present\r\n                if (separ.equals(sb.substring( Math.max(0, sb.length() - 2 )))) {\r\n                    sb.delete(sb.length() - 2, sb.length());\r\n                }<br><br>             } catch (Throwable e) {\r\n//                 e.printStackTrace();\r\n                 sb.append(&quot;Exception examining the object &quot;)\r\n                     .append(target)\r\n                     .append(&quot;: &quot;)\r\n                     .append(e);\r\n                 System.err.println(sb);\r\n             }\r\n             sb.append(&quot;}&quot;);\r\n             result = sb.toString();\r\n         } // switch<br><br>         return result;\r\n     }<br><br>     /**\r\n      * Does the current method being instrumented match the signature\r\n      * that should start tracing?\r\n     * @param methodRtti\r\n      * @return\r\n      */\r\n     private boolean isStartTracingSignatureMatch(MethodRtti methodRtti) {\r\n         return true;\r\n     }<br><br>     /**\r\n      * Does the current method being instrumented match the signature\r\n      * indicating we should stop tracing?\r\n      * @param methodRtti\r\n      * @return\r\n      */\r\n     private boolean isEndTracingSignatureMatch(MethodRtti methodRtti) {\r\n         return false;// isStartTracingSignatureMatch(methodRtti);\r\n     }\r\n}\r\n</code></pre>",
  "excerpt": ""
 },
 {
  "title": "The Ultimate Web UI Framework",
  "published": "2007-11-25 06:45:16",
  "postType": "post",
  "slug": "/2007/11/25/the-ultimate-web-ui-framework/",
  "status": "publish",
  "tags": [
   "framework",
   "java",
   "UI",
   "webapp"
  ],
  "categories": [
   "j2ee",
   "Languages"
  ],
  "content": "Recently I have found myself in the need of a framework for creating rich, responsive and highly interactive web-based user interfaces that would ideally be easy to use and fast to learn. I was basically only interested in the view part of the presentation tier, that's the UI running in user's browser and interacting with him/her. I had no preferences regarding the 'M' and 'C' of MVC, in other words the server-side of the presentation-tier.<br /><br />After doing some research I've found a couple of candidates:<br /><ul><li>Echo2</li><li>Google Web Toolkit (GWT) with the GWT-Ext components library<br /></li><li>JBoss RichFaces (it is based JSF; perhaps use with Seam)</li><li>OpenLaszlo/Flex</li><li>Others: Wicket, Grails, Struts 2, ...<br /></li></ul>The listed frameworks are quite different one from another. We can categorize them in a couple of ways w.r.t. different aspects:<br /><br><br><dl>\n<dt>Client-side versus server-side interaction handling</dt>\n<dd>Does the presentation logic that controlls user interaction and UI changes run on the client and only sends/receives data when it's necessary or does the presentation logic run on the server-side with (nearly) each action of the user resulting in a request?<br /></dd>\n<dt>Implementation language: Java, XML+JavaScript, html/css/js, other</dt>\n<dd>Is the interface described using the classical combination of JSP, HTML, CSS and Javascript, or is it described in pure Java, or does it use the combination of XML and JavaScript, or even something else?<br /></dd>\n<dt>Interaction model: event-based or request-driven</dt>\n<dt>And so on...</dt>\n</dl><br><br><p>Regarding the frameworks, which I'll describe later on, we can say:</p><ul><li>Client-side: GWT and OpenLaszlo or Flex run mainly on the client while the others more on the server</li><li>Language: With GWT &amp; Echo you define your UI in pure Java, with Flex/OpenLaszlo in xml+js, JSF uses the classical JSP &amp; co. combination.<br /></li></ul><h2>Introducing the frameworks</h2><p>Disclaimer: I'm no master of these frameworks. The information below is a compilation of opinions of their users and info from various sources like documentation, articles and blogs.<br /></p><p>All of these frameworks are open-source.<br /></p><h3><a href=\"http://www.nextapp.com/platform/echo2/echo/\">Echo 2</a> (<a href=\"http://www.nextapp.com/platform/echo2/echo/demo/\">demo</a>)</h3><ul><li>UI defined by Java classes as with Swing, event-based<br /></li><li>runs on the server-side and most user actions result in a request being sent to the server<br /></li><li>commercial IDE for - I suppose - graphical design of the UI; but you can code it without that in any editor</li></ul><p>Pros</p><ul><li>UI defined in Java <br /></li><ul><li>=&gt; you don't need to spend weeks learning JSP, JSTL, custom taglibs, HTML, CSS, JavaScript. This makes also developers cheaper.</li><li>=&gt; support for refactoring<br /></li></ul><li>A number of existing components<br /></li><li>Nice look&amp;feel</li><li>Only the code and content that is currently actually needed is downloaded to the client, other parts are downloaded as needed via Ajax - this should make the download of an echo 2 application and its start faster but may slow it later when you may need to wait for an additional stuff to be fetched</li><li>Backed by a commercial company, seems to be pretty alive with a reasonable community<br /></li></ul><p>Cons</p><ul><li>Runs mainly on the server-side, many user actions result in a request, which makes it slower and less responsive. For example switching a tab in the demo took usually around a second (this may be given by the current load, limits etc.of the server, but frameworks that handle this completely on the client side don't have any such problems)</li><li>the Eclipse-based EchoStudio 2 IDE for rapid visual development of Echo 2 UI is commercial though you can, of course, code your ui by hand in any editor</li><li>A new API to learn - it could be perhaps more similar to Swing API to make it easier for newcomers<br /></li></ul><h3><a href=\"http://code.google.com/webtoolkit/\">Google Web Toolkit</a> (GWT) with <a href=\"http://code.google.com/p/gwt-ext/\">GWT-Ext</a> components<br /></h3><p>As with Echo 2, you create your UI by writing Java classes, using a Swing-like API. But here the UI components (widgets) you've written are compiled at the development-time into html/css/javascript.</p><p>Pros</p><ul><li>Pure Java development =&gt; less knowledge required, support for refactoring - as with Echo 2</li><li>The components (widgets) are pure html/css/javascript and can be embedded into any page, even a static one or one created via another framework (you could e.g. place the component on a JSF page)</li><li>Runs on the client-side - a GWT application is a true rich UI running in the user's browser, the presentation flow and user interaction is handled locally as much as possible. The server-side is only called when data interchange in necessary.<br /></li><li>Backed by Google; no need to say more :) <br /></li><li>Steap learning curve - according to some you can start writing reasonable GWT applications in a week</li><li>A rich and growing set of components provided within GWT-Ext</li><li>Debugging: You can run the UI in a hosted mode within a special browser provided by Google without compilation into html/..., thus being able to use Java debugger etc. for it<br /></li></ul><p>Cons</p><ul><li>Java: provides only a subset of java.lang and java.util. Currently only works with Java 1.4, the upcomming GWT 1.5 will only work with Java 5.0..<br /></li><li>Closed-source Java to html/css/js converter</li><li>All the application files are donwloaded at once to the client, which can make its start slower; on the other hand Google is very good in optimizing the file sizes&nbsp; and the generated code from the donwload time perspective.</li><li>According to some people it isn't a good idea to have all the presentation logic on the client side for security reasons<br /></li></ul><h3>JBoss <a href=\"labs.jboss.com/jbossrichfaces/\">Rich Faces</a> (for JSF)<br /></h3><p>&nbsp;RichFaces is a JavaServer Faces (JSF) component library that heavily uses Ajax. But it goes beyond that and makes it possible to add Ajax support to existing components/applications, provides skinnable components, makes it possible to pack .js and .css into JAR archives together with your components.</p><p>JSF is &quot;the standard&quot;, component and event-oriented presentation framework. To get the maximum out of it, you can use RichFaces together with <a href=\"https://facelets.dev.java.net/\">Facelets</a> (see my <a href=\"http://www.jroller.com/holy/entry/introducing_facelets\">Facelets post</a>) and the application framework JBoss <a href=\"http://www.jboss.com/products/seam\">Seam</a>, which provides among others integration with EJB, business processes, and the &quot;conversation context&quot;.</p><p>Pros</p><ul><li>Builds on JSF, the &quot;new&quot; standard (JSR #127, v.1.2 <a href=\"http://jcp.org/en/jsr/detail?id=252\">#257</a>, the new v.2.0 <a href=\"http://jcp.org/en/jsr/detail?id=314\">#314</a>) for creating web UI and pluggable components. JSF can be also used for creating portlets (see JSR <a href=\"http://jcp.org/en/jsr/detail?id=301\">#301</a> - Portlet Bridge Specification for JavaServer Faces) though I don't know how much is this supported by RichFaces itself</li><li>RichFaces components and Ajax-support can be easily added to existing JSF applications and pages<br /></li></ul><p>Cons</p><ul><li>Runs on the server-side, most user actions result in a request, either via GET/POST or in the background via ajax.</li><li>It carries all the disadvantages of JSF (search on the web...)</li><li>You need to know JSF, html, css and either Facelets or JSP, JSTL etc.<br /></li></ul><h3><a href=\"http://www.openlaszlo.org/\">OpenLaszlo</a> or <a href=\"http://www.adobe.com/products/flex/\">Flex</a>&nbsp;</h3><p>Both these tools/frameworks let you create rich UI in Flash (or also DHTML with O.L.) using XML and JavaScript and both have no relation to Java - they provide for creating rich client-side applications that communicate to the server-side using some standard mechanism, for example web services or RESTful servlets returning xml or json.<br /></p><p>OpenLaszlo 4.x has the advantage of being able to compile the UI not only into Flash but also into DHTML (html/css/javascript). See <a href=\"http://www.openlaszlo.org/demos\">OpenLaszlo demos</a>.<br /></p><p>Adobe Flex is development framework for creating rich Internet applications using variations of XML (MXML) and JavaScript (ActionScript). The Flex SDK is open-source, the Eclipse-based Flex Builder IDE for rapid development of Flex applications is commercial. The famous author of Thinking in Java, Bruce <a href=\"http://www.artima.com/weblogs/viewpost.jsp?thread=193593\" title=\"Article - Bruce Eckel: Hybridizing Java\">Eckel, promotes Flex</a> and mentiones OpenLaszlo (recommended reading!; check also the <a href=\"http://www.artima.com/forums/flat.jsp?forum=106&amp;thread=193593\">comments</a>).</p><p>Pros</p><ul><li>Very rich UI with advanced capabilites regarding e.g. multimedia and vector graphics</li><li>Runs on the client side and only contacts the serer-side when necessary to get or send data<br /></li><li>You only need to learn the framework's xml and javascript, not the full stack of jsp/jstl/css/....</li><li>Can use back-ends not written in Java =&gt; encourages writting you server-side components in such a way that they can be used and reused in multiple ways. Because it isn't bound to any particular server-side framework or language, you can you is with any you like.</li><li>There is a fair number of existing components for both Flex and OpenLaszlo (especial\nly for Flex)</li><li>Flex is faster and richer than OpenLaszlo</li><li>You can nest Flex application into a page and integrate with it <br /></li></ul><p>Cons</p><ul><li>You need Flash plugin in the browser to use the UIs. OpenLaszlo can generate dhtml, but I'm not sure whether it's mature enough.</li><li>The startup may be a bit slower</li><li>Flesh isn't HTML and thus search engines like Google cannot search and index it so well</li><li>an IDE with visual UI builder and other support either isn't available or only for a fee (though people say you don't really need one)</li><li>Flex isn't completely free: is some cases, like using Flex Data Services on multiple CPUs, you must pay (but see the LGPL <a href=\"http://www.graniteds.org/confluence/display/INTRO/Granite+Data+Services\">Granite DS</a>)<br /></li></ul><h3>Others: Wicket, Grails, Struts 2, ...</h3><p>There are certainly other popular frameworks that may support rich user interface. But I've deliberately limited myself to the most famous ones and those that are somehow unique and catched my attention. <br /></p><h2>Criteria for&nbsp; evaluating web UI frameworks (draft)</h2><p>The following criteria could/should be used when deciding wheher a particular framework is suitable for an application and the problem it tries to solve.&nbsp;</p><p>Practical</p><ul><li>availability of developers familiar with the framework</li><li>tools support</li><li>existing components</li></ul><p>Learning &amp; using<br /></p><ul><li>support community</li><li>learning curve</li><li>documentation</li><li>rapid development: can write UI fast?</li><li>ease of use - principles like DRY, convention over configuration etc. that make it's use easier<br /></li></ul>Non-functional characteristics<br /><ul><li>flexibility (let me do st. unexpected that I really need)</li><li>performance, scalability</li><li>maintainability; refactoring supported?</li><li>suitable for large enterprise apps with many &quot;pages&quot;?</li><li>user experience (rich &lt;&gt; ajax)</li></ul><p>Other</p><ul><li>evolution: has it momentum? new versions backward compatible?</li><li>stable and proven framework?<br /></li></ul><p>Note: diffferent frameworks are suitable for different cases; there is no single framework that's the best fit for any problem. Still we would certainly like to keep the number of frameworks used as small as possible.<br /></p><h2>Summary/Conclusion</h2><p>I was searching for a framework that would allow me to create rich user interfaces that are very interactive and responsive and don't load the server too much. After examining some favourite frameworks I've decided for a few that I'd like to try.</p><p>Different applications have different architectural and UI requirements, which makes some frameworks suitable for the problem at hand and some not. But when we limit ourselves to a user-interaction centered application, I think that the classical frameworks like Struts 1/2 and JSF just aren't suitable, even with Ajax. They place to much burden on the server, aren't responsive and interactive enough and don't always provide for rapid creation of rich interfaces. I like the idea of user interface running on the client, as with GWT or OpenLaszlo, and having only the business logic on the server-side. This provides for richer and more responsive UI and places less burden on the server, which can thus serve more clients. Ganesh Prasad promotes such a solution in his blog entry &quot;<a href=\"http://wisdomofganesh.blogspot.com/2007/10/life-above-service-tier.html\" title=\"Ganesh - blog - introduction of the SOFEA arch.\">Life above the Service Tier</a>&quot; with the term Service-Oriented Front-End Architecture (SOFEA), a rich UI above a service layer. I indeed recommend reading it.</p><p>To conclude: I'd use either GWT or OpenLaszlo (or maybe Flex) when a true rich user interface is required and/or when this of technology and approaches isn't against internal standards of the company. If a more traditional approach is necessary, I'd prefer RichFaces because JSF is quite popular and standard.<br /></p><h2>Links and resources<br /></h2><ul><li><a href=\"http://labs.adobe.com/technologies/air/\">&nbsp;Adobe AIR</a> (former Apollo) - runtime for running web 2.0 and Flex applications as desktop application, with full integration, access, and support for running offline.</li><li><div align=\"left\"><a href=\"http://gears.google.com/\">Google Gears</a> - &quot;an open source browser extension that enables web applications to provide offline functionality&quot; by providing JavaScript API for storing &amp; serving resources (html, images...) locally, acess to an embedded database, and more.<br /></div></li><li>Microsoft <a href=\"http://en.wikipedia.org/wiki/Silverlight\">Silverlight</a> -  multiplatform and multibrowser plugin and runtime for running rich .NET applications from within a browser. It competes with Flesh (hence Flex) and the new mysterious Sun's <a title=\"JavaFX homepage\" href=\"http://www.sun.com/software/javafx/index.jsp\">JavaFX</a>.</li></ul><p>Articles, blogs etc.<br /></p><ul><li>Matt Raible: <a href=\"http://raibledesigns.com/rd/entry/comparing_web_frameworks_time_for\">Comparing Web Frameworks: Time for a Change?</a> - &quot;top 6 frameworks&quot; and an enlightening discussion.<br /><span class=\"entryTitle\"></span><a href=\"http://raibledesigns.com/rd/entry/comparing_jvm_web_frameworks_presentation\">Comparing JVM Web Frameworks Presentation</a> (Nov 14, 2007)<br /></li><li><a href=\"http://www.theserverside.com/news/thread.tss?thread_id=40804\">Comparing the Google Web Toolkit to Echo2</a> - by a developer of Echo</li><li>James Ward arguments <a href=\"http://www.jamesward.org/wordpress/2007/11/15/matt-raible-comparing-jvm-web-frameworks/\">why to use Flex</a> in a comment to Raible's Comparing JVM Web Frameworks</li><li>... and many more ...</li><li><a href=\"http://www.infoq.com/news/2008/01/gosling-on-flash\" title=\"article w/ link and comments on JG\">James Gosling on Adobe Flash / Flex / AIR</a><a href=\"http://blogs.pathf.com/agileajax/2007/11/thinking-of-alt.html\"></a></li><li><a href=\"http://blogs.pathf.com/agileajax/2007/11/thinking-of-alt.html\">Thinking of alternatives to GWT-RPC</a> - e.g. Jaxter, Enunciat</li><li>James Ward arguments <a href=\"http://www.jamesward.org/wordpress/2007/11/15/matt-raible-comparing-jvm-web-frameworks/\">why to use Flex</a> in a comment to Raible's Comparing JVM Web Frameworks</li><li>2008-04-01:&nbsp; Sajnvi Jivan: <a href=\"http://www.jroller.com/sjivan/entry/thoughts_on_java_webframeworks_and\">Thoughts on Java web frameworks and RIA </a>- recommends Flex&amp;GWT for dynamic apps and request-response frameworks for those needing SEO, bookmarkability, and RESTful services</li><li>Blog Evolutionary Goo: <a href=\"http://evolutionarygoo.com/blog/?p=233\">Choosing a Java Web Framework (Revisited)&nbsp;</a> (2008-09-18)<br /></li></ul>",
  "excerpt": ""
 },
 {
  "title": "Introducing Facelets",
  "published": "2007-11-19 06:44:47",
  "postType": "post",
  "slug": "/2007/11/19/introducing-facelets/",
  "status": "publish",
  "tags": [
   "framework",
   "java",
   "javaEE",
   "jsf",
   "UI",
   "webapp"
  ],
  "categories": [
   "j2ee",
   "Languages"
  ],
  "content": "<p>You might have already heard about <a title=\"Facelets - home\" href=\"https://facelets.dev.java.net/\">Facelets</a> (<a title=\"Facelets - user guide (though called developer doc.)\" href=\"https://facelets.dev.java.net/docs/dev/docbook.html\">docs</a>), a library for Java Server Faces (JSF), and wondered why it is popular and what it is good for. I've wondered too and now I want to share the answers with you.</p><p>Warning: I'm a novice to Facelets and some things may be not completely exact.&nbsp;</p><p>Facelets is</p><ul><li>an alternative, non-JSP view technology and handler for JSF that gives you the power of JSP while avoiding its inherent problems with JSF</li><li>a simple templating system similar partly to Tiles</li><li>a way to use newer JSF (1.2) in an older servlet container (below JSP 2.1) that couldn't support it otherwise</li><li>it's compatible with JSF 1.2 and can be used with Sun's RI or with Apache's MyFaces<br /></li></ul><h2>&nbsp;Facelets is an alternative, non-JSP view handler</h2><p>It's very difficult and error-prone to use JSP to define JSF views because they've different life-cycles and just don't fit together well. Result: you must enclose most non-jsf content by f:verbatim and you may be sometimes surprised by content appearing in a different order in the resulting html. See <a href=\"http://www.onjava.com/pub/a/onjava/2004/06/09/jsf.html\" title=\"On Java Article\">Improving JSF by Dumping JSP</a> by Hans Bergsten.</p><p>Facelets were designed as a view technology for JSF and let you define your views in XHTML and mix freely JSF components, xhtml, <a href=\"http://en.wikipedia.org/wiki/Unified_Expression_Language\" title=\"Wikipedia: about JSP 2.1's unified EL\">unified expression language</a> (including custom functions), and a subset of JSTL (core, functions; for example c:if). All of these are translated into a jsf component tree and go through the same life-cycle. No more problems with mixing jsf components and jsf-unaware html: everything is a part of a component with Facelets.</p><p>You can defined your views in .xhtml, or, if you want to keep your IDE's support including autocompletion, you can <a title=\"Tip: use JSP with xml syntax with Facelets to keep IDE's autocompletion etc.\" href=\"http://www.mojavelinux.com/blog/archives/2006/12/facelets_tag_completion_in_eclipse/\">use JSPX with Facelets</a> (JSPX = JSP with xml syntax; Facelets require its view definition to be a valid xml).</p><p>Example - mypage.jspx: </p><pre><code>&lt;?xml version=\"1.0\" encoding=\"UTF-8\" ?&gt;\n&lt;jsp:root xmlns:jsp=\"http://java.sun.com/JSP/Page\"\n  xmlns:ui=\"http://java.sun.com/jsf/facelets\"\n  xmlns:h=\"http://java.sun.com/jsf/html\"\n  xmlns:f=\"http://java.sun.com/jsf/core\"\n  version=\"2.0\"&gt;\n   &lt;html xmlns=\"http://www.w3.org/1999/xhtml\"&gt;\n      &lt;head&gt;&lt;title&gt;JSPX Facelets example&lt;/title&gt;&lt;/head&gt;</code>\n<code></code>      &lt;body&gt;\n<code>         &lt;ui:composition&gt;</code>\n<code>         </code><code></code><code>   &lt;h:messages id=\"messages1\" styleClass=\"messages\"&gt;\n</code><code>         </code><code>   </code><code>#{myManagedBean.sayHello}</code>\n<code>         &lt;/ui:composition&gt;</code>\n<code>      </code><code></code><code>&lt;/body&gt;\n</code><code>   </code><code></code><code>&lt;/html&gt;\n&lt;/jsp:root&gt;</code></pre><h2>Facelets as a templating system</h2><p>The framework provides a couple of tags that let you create and apply page templates: in a template you specify variable, page-dependant content (perhaps with some default content) using <font face=\"courier new,courier,monospace\">ui:insert name=&quot;...&quot;</font>, in a page (a template client) you enclose the code that shouldn't be ignored by <font face=\"courier new,courier,monospace\">ui:composition template=&quot;&lt;template file path&gt;&quot;</font>&nbsp; and finally use some <font face=\"courier new,courier,monospace\">ui:define name=&quot;...&quot;</font> to define content for the template's ui:inserts. This let you easily define e.g. common layout in for your pages.</p><p>The description is a very brief and simplified one, refer to the <a href=\"https://facelets.dev.java.net/nonav/docs/dev/docbook.html#template\">Facelets templating</a> docs to learn about its full power.<br /></p><h2>And even more...</h2><h3>&nbsp;Easy creation of composite components</h3><p>Another distinct advantage of Facelets is that it let you create extremely easily components composed from other components: you just define the composition as another xhtml fragment, define the tag to use for it in a Facelets tag library. An example from the Facelets docs:</p><p>Tag description from a Facelets taglib file mytags.taglib.xml (referenced by the context parameter facelets.LIBRARIES):</p><pre class=\"programlisting\">&lt;?xml version=&quot;1.0&quot;?&gt;<br />&lt;!DOCTYPE facelet-taglib PUBLIC &quot;-//Sun Microsystems, Inc.//DTD Facelet Taglib 1.0//EN&quot; &quot;facelet-taglib_1_0.dtd&quot;&gt;<br />&lt;facelet-taglib&gt;<br />  &lt;namespace&gt;http://example.com/my&lt;/namespace&gt;<br /><a id=\"taglib-create-source\">  &lt;tag&gt;<br />    &lt;tag-name&gt;echo&lt;/tag-name&gt;<br />    &lt;source&gt;tags/echo.xhtml&lt;/source&gt;<br />  &lt;/tag&gt;</a><br />&lt;facelet-taglib&gt;</pre><p>And the tag definition - tags/echo.xhtml:&nbsp;</p><pre class=\"programlisting\"><a id=\"taglib-create-source\">&lt;ui:composition xmlns:ui=&quot;http://java.sun.com/jsf/facelets&quot;&gt;<br />  &lt;span class=&quot;message&quot;&gt;#{msg}&lt;/span&gt;<br />&lt;/ui:composition&gt;</a></pre><p>&nbsp;Called as (notice how the varaible msg is passed; the namespace 'my' is defined by: xmlns:my=&quot;http://example.com/my&quot;):</p><pre class=\"programlisting\"><a id=\"taglib-create-source\">&lt;my:echo msg=&quot;#{bean.warningMessage}&quot;/&gt;</a></pre><h3>Debugging/devel support&nbsp;</h3><p>By setting the context param <font face=\"courier new,courier,monospace\">facelets.DEVELOPMENT</font> to <font face=\"courier new,courier,monospace\">true</font> you instruct Facelets to display a pretty useful information whenever a processing error occures, inlcuding the exact location of the error in the xhtml/jspx. The developers have indeed taken care of providing useful output here!</p><p>When using Sun's RI, you may also want to set the context params com.sun.faces.validateXml and com.sun.faces.verifyObjects to true.</p><h3>Deploying Facelets application to JBoss 4.0.4</h3><p>Notice: I've tried Facelets 1.0.10, but the latest version is 1.1.14 - you may prefer to try that one.&nbsp;</p><p>You need the following libraries in your WEB-INF/lib (versions may differ): jsf-facelets-1.0.10.jar, el-ri-1.0.jar, el-api-1.0.jar, jstl-1.1.2.jar (all included in the Facelets <a title=\"Downloaded Facelets 1.0.10\" href=\"https://facelets.dev.java.net/files/documents/3448/27389/facelets-1.0.10.zip\">download</a>). </p><p>You must not have there either Sun's RI of JSF 1.2 (jsf-api, jsf-impl) or MyFaces libs (myfaces-api-1.1.2-SNAPSHOT.jar, myfaces-impl-1.1.2-SNAPSHOT.jar). The RI requires Java 1.5 that may not be possible to use for political reasons and myfaces conflict with myfaces libraries bundled with JBoss in &lt;jboss&gt;\\server\\default\\deploy\\jbossweb-tomcat55.sar\\jsf-libs.</p><p>Note: If Tomcat&nbsp; cannot find the myfaces TLDs and complains about unmapped namespace http://java.sun.com/jsf/html or core, extract the TLDs from the myfaces jars and put them somewhere under your WEB-INF.<br /></p><p>That's all - assuming you've set your web.xml and faces-config.xml correctly. In web.xml you don't need anything special outside of normal JSF configuration (Faces servlet and startup listener) unless using extension mapping instead of the prefix /faces/* - in that case you must also specify .xhtml (or .jspx) as the default suffix of JSF pages using the context param. javax.faces.DEFAULT_SUFFIX. In faces-config.xml you need to set Facelets as the view handler (you may define for which resources it should be used, delegationg all others to the default jsp view handler, via its context param. facelets.VIEW_MAPPINGS): </p><pre><code>&lt;application&gt;\n   &lt;view-handler&gt;com.sun.facelets.FaceletViewHandler&lt;/view-handler&gt;\n&lt;/application&gt;</code></pre><p>&nbsp;That's all folks, thank you for attention!<br /></p>",
  "excerpt": ""
 },
 {
  "title": "Truncating UTF String to the given number of bytes while preserving its validity [for DB insert]",
  "published": "2007-11-02 08:03:46",
  "postType": "post",
  "slug": "/2007/11/02/truncating-utf-string-to-the-given/",
  "status": "publish",
  "tags": [
   "database",
   "java",
   "jdbc",
   "text",
   "utf8"
  ],
  "categories": [
   "Databases",
   "Languages"
  ],
  "content": "Often you need to insert a String from Java into a database column with a fixed length specified in bytes.\r\nUsing\r\n<pre>string.substring(0, DB_FIELD_LENGTH);</pre>\r\nisn't enough because it only cuts down the number of characters but in UTF-8 a single character may be represented by 1-4 bytes. But you cannot just turn the string into an array of bytes and use its first DB_FIELD_LENGTH elements because you could end up with an invalid UTF-8 character at the end (one that is represented by 2+ bytes while only its 1st byte fits into the field). There are two solutions for truncation the string in such a way, that it has at most DB_FIELD_LENGTH bytes and is a valid UTF-8 string.\r\n<h3>Approach 1: Replace the invalid trailing byte(s) with a 'rectangle'</h3>\r\nThis is as simple as:\r\n<pre>int maxLen = DB_FIELD_LENGTH-2;\r\nstring = new String( string.getBytes(\"UTF-8\") , 0, maxLen, \"UTF-8\");</pre>\r\nThe new String constructor will automatically replace any invalid character (i.e. incomplete utf-8 char; we may only have one at the end) with the character \\uFFFD, which looks like an empty rectangle. This character requires 3 bytes in utf-8 - therefore we decrease DB_FIELD_LENGTH by 2; the resulting string will have either exactly maxLen bytes if its last byte(s) is a valid utf-8 character or maxLen+2 bytes if it isn't valid and this 1 byte was replaced by \\uFFFD (3B).\r\n<h3>Approach 2: Skip the invalid trailing byte(s) altogether</h3>\r\nIf you don't want to have the rectangle character in the place of a split multibyte character, you must do yourself what the String constructor does internally, in a bit different way:\r\n<pre>import java.nio.*; import java.nio.charset.*;\r\nCharset utf8Charset = Charset.forName(\"UTF-8\");\r\nCharsetDecoder cd = utf8Charset.newDecoder();\r\nbyte[] sba = string.getBytes(\"UTF-8\");\r\n// Ensure truncating by having byte buffer = DB_FIELD_LENGTH\r\nByteBuffer bb = ByteBuffer.wrap(sba, 0, DB_FIELD_LENGTH); // len in [B]\r\nCharBuffer cb = CharBuffer.allocate(DB_FIELD_LENGTH); // len in [char] &lt;= # [B]\r\n// Ignore an incomplete character\r\ncd.onMalformedInput(CodingErrorAction.IGNORE)\r\ncd.decode(bb, cb, true);\r\ncd.flush(cb);\r\nstring = new String(cb.array(), 0, cb.position());</pre>\r\nThe string will end with the last valid character in the given range.\r\n<h3>Approach 3: Manually remove the invalid trailing bytes</h3>\r\nAs you can see, the approach 2 requires quite lot of coding and method calls. If you know the details of UTF-8, namely how to distinguish an invalid byte or byte sequence then you can simply truncate the byte array and then remove/replace the invalid bytes. I'd be glad for the code :-)",
  "excerpt": ""
 },
 {
  "title": "VMWare: Shrink image even though it’s a snapshot",
  "published": "2007-08-21 04:02:42",
  "postType": "post",
  "slug": "/2007/08/21/vmware-shrink-image-even-though-it/",
  "status": "publish",
  "tags": [
   "virtualization",
   "vmware"
  ],
  "categories": [
   "Tools"
  ],
  "content": "I needed to shrink a vmware image to save space but it wasn't possible because it wasn't an independent disk but a snapshot (rhel3_ws_u4-000001.vmdk etc.) dependant upon the original disk (rhel3_ws_u4-s001.vmdk etc). The steps were:<br><br><ol>\n<li>Join the snapshot and the parent disk into one: use the free VMWare Converter (see vmware.com) - perform transformation (import+export) from a standalone virt. machine to an stanalone virt. machine; it's necessary to import all the disk, preserving its size (by selecting \"select volumes and resize...\" I got an unbootable disk); than check \"Create a full clone\" and \"Allow virtual disk files to grow\" (don't pre-allocate space!!!).\n<li>Shrink: After the successfull conversion run the system and verify that the disk is of the type independant-persistent and perhaps disable snapshots). Iinstall there vmware tools (from the vmware menu while the system is running), run the command vmware-toolbox and in its user interface select \"shrink disk\".\n</ol>",
  "excerpt": ""
 },
 {
  "title": "Dependency Finder 1.2.0 for Java",
  "published": "2007-06-15 09:35:34",
  "postType": "post",
  "slug": "/2007/06/15/dependency-finder-1-2-0-for-java/",
  "status": "publish",
  "tags": [
   "analysis",
   "java",
   "reverse_engineering"
  ],
  "categories": [
   "Languages",
   "Tools"
  ],
  "content": "<p><a href=\"http://depfind.sourceforge.net/\">Dependency Finder</a>  for java can help you to find your way in unknown class files/library.\n</p>\n<p>Usage:</p>\n<ol>\n<li>Import the class files - <kbd>File &gt; Extract</kbd>; wait... Note: you may need to increase the JVM's memory.\n<li>Store the extracted information about the imported classes -  <kbd>File &gt; Save</kbd>\n<li>Select the programming elements to examine by selecting the proper checkboxes - by default it's set to packages, you may rather want classes or packages+classes.\n<li>Display a dependency 'graph' -  <kbd>File &gt; Dependency</kbd>. The symbol --&gt; means <em>uses</em>, &lt;-- means <em>is used by</em>.\n<li>You may want to limit the elements for which to show dependencies (the box <kbd>Select programming elements</kbd>) or their dependencies to show (the box <kbd>Show dependencies (stop for closure)</kbd>). The expressions use Perl regular expressions (RegExp): you specify 1 or more RegExp enclosed by '/' and '/' and separated by a comma. Example: classes containiny MyClass and (presumabely) packages starting with com.ibm: /MyClass/,/^com.ibm/\n</ol><br><br><p>To run it, execute a script similar to the one below from its bin directory:</p>\n<pre><code>\nset DEPENDENCYFINDER_HOME=c:DependencyFinder-1.2.0\njava %DEPENDENCYFINDER_OPTS% -Xms512m -Xmx1024m -classpath \"%DEPENDENCYFINDER_HOME%classes\";\"%DEPENDENCYFINDER_HOME%libDependencyFinder.jar\";\"%DEPENDENCYFINDER_HOME%liblog4j.jar\";\"%DEPENDENCYFINDER_HOME%libjakarta-oro.jar\";\"%CLASSPATH%\" com.jeantessier.dependencyfinder.gui.DependencyFinder\n</code></pre>",
  "excerpt": ""
 },
 {
  "title": "Troubleshooting Class/Resource Loading on an Application Server",
  "published": "2007-01-25 05:08:31",
  "postType": "post",
  "slug": "/2007/01/25/troubleshooting-classresource-load/",
  "status": "publish",
  "tags": [
   "classpath",
   "java",
   "javaEE",
   "troubleshooting"
  ],
  "categories": [
   "j2ee",
   "Languages"
  ],
  "content": "<p>\nIf you need to find out where is a certain class loaded from or where a class has loaded a resource (typically a configuration file) from, you can use the JSP below - just put it to your web app and point a browser to it.\n</p><br><br><p>Note: The resource loading tracking assumes that the loading class uses <code>getClass().getResource</code> - this doesn't need to be always the case, it could also use the context class loader (<code>Thread.currentThread().getContextClassLoader()</code>) or load it as a system resource (<code>ClassLoader.getSystemResource</code>).</p><p align=\"left\"><b>Update 08/11/06</b>:&nbsp; You can now <a href=\"https://sourceforge.net/project/showfiles.php?group_id=210989&amp;package_id=253883\">get the ClassLoaderViewer.jsp from SF.net</a>.<br /></p><br><br><hr />",
  "excerpt": ""
 },
 {
  "title": "WAS 6.0 ant tasks: Install an app with an external Ant",
  "published": "2006-12-15 06:26:33",
  "postType": "post",
  "slug": "/2006/12/15/was-6-0-ant-tasks-install-an-app-w/",
  "status": "publish",
  "tags": [
   "ant",
   "deployment"
  ],
  "categories": [
   "WebSphere"
  ],
  "content": "<p>There are special ant taks to install/start/.. an application to a\nWebSphere App Server 6.0. It's easy to run them with WAS's ant script\n(&lt;was&gt;/bin/was_ant.bat) but not so trivial to get them working with an\nexternal ant, which may be necessary because WAS has an old version of ant.\nSo lets see how to do it.</p><br><br><p>The important points are:</p>\n<ul>\n  <li>Use IBM JRE<br />\n    (or use Sun JRE but setup the environment first by running\n    &lt;WAS&gt;/profiles/&lt;your profile&gt;/bin/setupCmdLine in the same\n    shell/command line you'll use to start the ant)</li>\n  <li>Set the environmental variable\n    ANT_OPTS=\"-Duser.install.root=&lt;WAS&gt;/profiles/&lt;your profile&gt;\"\n    Strangely, it seems that no other way of passing it to the was ant tasks\n    works.</li>\n  <li>Tell Ant where to look for the libraries it needs:\n    <ol>\n      <li>Ant's own lib/ dir - it must be specified and it must come first\n        not to use WAS' ant</li>\n      <li>A directory with wsanttasks.jar itself and other jars it depends\n        upon (perhaps only wsprofile.jar) - you may specify\n      &lt;WAS&gt;/lib</li>\n      <li>If you want to use scripts in jython, you need to include also\n        &lt;WAS&gt;/optionalLibraries</li>\n    </ol>\n  </li>\n</ul><br><br><p>Example:</p><br><br><p><kbd>C:\\&gt; set\nPATH=C:\\development\\servers\\WebSphere6.0\\AppServer\\java\\jre\\bin;%PATH%<br />\nC:\\&gt; set\nJAVA_HOME=C:\\development\\servers\\WebSphere6.0\\AppServer\\java\\jre<br />\nC:\\&gt; set\nANT_OPTS=\"-Duser.install.root=C:\\development\\servers\\WebSphere6.0\\AppServer/profiles/jh-pokusy\"<br />\nC:\\&gt; c:\\apache-ant-1.6.5\\bin\\ant -verbose -lib ..\\apache-ant-1.6.5\\lib\n-lib c:\\development\\servers\\WebSphere6.0\\AppServer\\lib -lib\nc:\\development\\servers\\WebSphere6.0\\AppServer\\optionalLibraries -f\nmyBuild.xml myBuildTarget</kbd></p><br><br><p>myBuild.xml contains:</p>\n<pre>\n    &lt;property name=\"myWas.root\"     value=\"c:\\development\\servers\\WebSphere6.0\\AppServer\" /&gt;<br><br>    &lt;taskdef name=\"wsAdmin\"            classname=\"com.ibm.websphere.ant.tasks.WsAdmin\" /&gt;\n    &lt;taskdef name=\"wsInstallApp\" classname=\"com.ibm.websphere.ant.tasks.InstallApplication\" /&gt;\n    &lt;taskdef name=\"wsStartApp\" classname=\"com.ibm.websphere.ant.tasks.StartApplication\" /&gt;\n    &lt;taskdef name=\"wsUninstallApp\" classname=\"com.ibm.websphere.ant.tasks.UninstallApplication\"/&gt;<br><br>    &lt;target name=\"installStartUninstall\" depends=\"_installEarApp,_startEarApp,_uninstallEarApp\" /&gt;<br><br>    &lt;target name=\"_installEarApp\"  description=\"Deploy the app to WAS 6.0\"&gt;\n                &lt;echo message=\"Going to deploy '${earToDeploy}' to the server in ${wasroot}...\" /&gt;\n                        &lt;echo message=\"########## FIRST install ########### ${line.separator}\" /&gt;\n                        &lt;wsInstallApp wasHome=\"${myWas.root}\" conntype=\"SOAP\"\n                                      ear=\"c:\\tmp\\myApp.ear\"\n                                      host=\"localhost\" port=\"8881\"\n                                      user=\"me\" password=\"psw\"\n                                      failonerror=\"true\"\n                                      options=\"-appname MyAppName -verbose true -validateinstall fail -preCompileJSPs true\"\n                                      /&gt;\n                        &lt;!-- Note: Anttasks's wsadmin task from was 6.0.0.3 support the attr. profileName=\"jh-pokusy\" --&gt;<br><br>                &lt;!-- 1. Ryn my jython script that modifies configuration of the app:\n                     (todo: try the atribute: profile=\"${myWas.root}/bin/setupCmdLine.bat\")\n                --&gt;\n                &lt;wsAdmin wasHome=\"${myWas.root}\" conntype=\"SOAP\" host=\"localhost\" port=\"8881\"\n                         host=\"localhost\" port=\"8881\"\n                         user=\"me\" password=\"psw\"\n                         failonerror=\"true\"\n                         script=\"c:\\tmp\\configureApplication.jython\"\n                         lang=\"jython\"&gt;\n                               &lt;!-- See the script for the arguments it expects --&gt;\n                                &lt;arg value=\"MyAppName\"/&gt;&lt;!-- app name --&gt;\n                &lt;/wsAdmin&gt;\n        &lt;/target&gt;<br><br>    &lt;target name=\"_startEarApp\" depends=\"\" description=\"Start a deployed ear app on the WAS server\"&gt;\n            &lt;wsStartApp wasHome=\"${myWas.root}\" conntype=\"SOAP\"\n                        application=\"MyAppName\"\n                        host=\"localhost\" port=\"8881\"\n                        user=\"me\" password=\"psw\"\n                        failonerror=\"true\"\n                        /&gt;\n    &lt;/target&gt;<br><br>    &lt;target name=\"_uninstallEarApp\" depends=\"\" description=\"Start a deployed ear app on the WAS server\"&gt;\n            &lt;wsUninstallApp wasHome=\"${myWas.root}\" conntype=\"SOAP\"\n                        application=\"MyAppName\"\n                        host=\"localhost\" port=\"8881\"\n                        user=\"me\" password=\"psw\"\n                        failonerror=\"true\"\n                        options=\"-verbose true\"\n                        /&gt;\n    &lt;/target&gt;\n</pre><br><br><p>Information</p>\n<ul>\n  <li>host/port for the connection method: see\n    &lt;WAS&gt;\\profiles\\&lt;profile\n  name&gt;\\properties\\wsadmin.properties</li>\n  <li>paths to files (ear, script to execute) - must be absolute!!! - the was\n    ant tasks change the working directory =&gt; relative paths won't\n  work</li>\n</ul><br><br><p></p>",
  "excerpt": ""
 },
 {
  "title": "RAD, WAS 6 Test Env and J2EE security: getting rid of “No received or invocation credential exist on the thread”",
  "published": "2006-11-24 05:46:18",
  "postType": "post",
  "slug": "/2006/11/24/rad-was-6-test-env-and-j2ee-securi/",
  "status": "publish",
  "tags": [
   "development",
   "IDE",
   "javaEE",
   "security"
  ],
  "categories": [
   "eclipse",
   "WebSphere"
  ],
  "content": "Recently I started a new J2EE project that required j2ee security. Unfortunately Rational app. Developer 6 seemed to have some problems running a WAS Test Environment in this way, at least with the default setup. I encountered 2 problems:<br />\n<ol>\n<li>RAD wasn't able to connect to the server at all, throwing some security exceptions. <br />The solution (or rather work-around) was to switch the \"Server connection type..\" in the server's configuration in RAD from RMI to SOAP. It seems that RMI doesn§t support authetification. <br /></li>\n<li>After that, everything seemed to be ok, but an error was logged every few seconds with the cause \"<span style=\"font-family:Courier New,Courier,mono;\">No received or invocation credential exist on the thread</span>\". The stack trace pointed to a MBean (a part of JMX) being contacted via RMI. <br />Work-around: Disable an RMIConnector for JMX in WAS Console: log in, go to <br />Application servers &gt; server1 &gt; Administration&nbsp; &gt; Administration Services &gt; JMX connectors<br />And delete the RMIConnector - make first sure that you don't need it.<br /></li></ol>BTW, to enable the security, I enabled it first on the server via WAS admin console and then I created a new server configuration in RAD and set it to use security.<br /><br />Stack trace for issue 2:<br style=\"font-family:Courier New,Courier,mono;\" /><span style=\"font-family:Courier New,Courier,mono;\">com.ibm.ws.security.role.RoleBasedAuthorizerImpl.checkAccess(RoleBasedAuthorizerImpl.java(Compiled Code)) at com.ibm.ws.management.AdminServiceImpl.preInvoke(AdminServiceImpl.java:1696) at com.ibm.ws.management.AdminServiceImpl.preInvoke(AdminServiceImpl.java:1603) at com.ibm.ws.management.AdminServiceImpl.preInvoke(AdminServiceImpl.java:1533) at com.ibm.ws.management.AdminServiceImpl.preInvoke(AdminServiceImpl.java:1506) at com.ibm.ws.management.AdminServiceImpl.getAttribute(AdminServiceImpl.java:501) at com.ibm.ws.management.connector.AdminServiceDelegator.getAttribute(AdminServiceDelegator.java:99) at com.ibm.ws.management.connector.rmi.RMIConnectorService.getAttribute(RMIConnectorService.java:123) at com.ibm.ws.management.connector.rmi._RMIConnectorService_Tie.getAttribute(_RMIConnectorService_Tie.java:193) at com.ibm.ws.management.connector.rmi._RMIConnectorService_Tie._invoke(_RMIConnectorService_Tie.java:87) at com.ibm.CORBA.iiop.ServerDelegate.dispatchInvokeHandler(ServerDelegate.java:608) at com.ibm.CORBA.iiop.ServerDelegate.dispatch(ServerDelegate.java:461) at com.ibm.rmi.iiop.ORB.process(ORB.java:432) at com.ibm.CORBA.iiop.ORB.process(ORB.java:1728) at com.ibm.rmi.iiop.Connection.doWork(Connection.java:2229) at com.ibm.rmi.iiop.WorkUnitImpl.doWork(WorkUnitImpl.java:65) at com.ibm.ejs.oa.pool.PooledThread.run(ThreadPool.java:95) at com.ibm.ws.util.ThreadPool$Worker.run(ThreadPool.java(Compiled Code)) .&nbsp; </span><br />",
  "excerpt": ""
 },
 {
  "title": "RAD: Profiling a portlet",
  "published": "2006-11-14 07:26:26",
  "postType": "post",
  "slug": "/2006/11/14/rad-profiling-a-portlet/",
  "status": "publish",
  "tags": [
   "java",
   "performance",
   "profiling"
  ],
  "categories": [
   "eclipse",
   "Languages"
  ],
  "content": "Recently I needed to profile a portlet to find its time performance bottlenecks. Since I developed it in RAD using its WebSphere 5.1 Test Environment, I thought I'd run the server in the Profiling mode and would get the results. The profiler worked very hard, but at the end no results were displayed.&nbsp; I tried to profile a simple (non server) Java app. - again it seemed to do something but no results vere displayed. But finally I've found how to get the data using hprof:<br />\n<h5>Analyzing portlet performance with hprof</h5>\n<ol>\n<li>Create a normal Java app. that will call the portlet's code or a JUnit (or e.g. MockObjectTestCase, if you need&nbsp; JNDI and the like set up) test</li>\n<li>Write a <span style=\"font-family:Courier New, Courier, mono;\">main </span>method of the app. and call there the portlet code. If it's a test case, don't forget to call setUp before and tearDown after that.</li>\n<li>At the end of main call <span style=\"font-family:Courier New, Courier, mono;\">System.exit(0)</span> - otherwise it may happen that the thread will not actually finish and thus the output won't be completely generated (usually there will only be a header and names of threads that have started). Killing it via the red square button stops the threads but doesn't generate the output.</li>\n<li>Run the app./test case as a \"Java Application\" using a Sun JRE 1.4 (IBM JRE would fail) and passing the VM the option \"<span style=\"font-family:Courier New, Courier, mono;\">-Xrunhprof:cpu=samples,thread=y,file=cpu_profiling.hprof,depth=32</span>\"</li></ol>The important points: Call System.exit at the end and use Sun's JRE 1.4.<br />\n<h5>Analyzing the output of hprof<br /></h5>The best is to find a tool that analyzis the output of hprof. If you want to do it yourself, look first at the end of the file - there is a list of the most time consuming methods, each with a trace number. Find a stack trace of the method in the previous part of the file using that number. Note that the stack traces are not ordered w.r.t. the trace number.<br />\n<h5>Additional notes</h5>I've also tried Eclipse 3.2 and its profiling tool (TPTP). For a simple java application it displayed no output untill I changed the default options, setting polling frequency to 1sec (default: auto). I had also some problems trying to run it with JRE 5.0 but 1.4 was ok. So perhaps the RAD's profiling would display soem results if set correctly.<br /><br />",
  "excerpt": ""
 },
 {
  "title": "Kill a zombie database (not in the directory but can’t create it)",
  "published": "2006-11-02 07:00:00",
  "postType": "post",
  "slug": "/2006/11/02/kill-a-zombie-database-not-in-the/",
  "status": "publish",
  "tags": [
   "db2"
  ],
  "categories": [
   "Databases"
  ],
  "content": "I tried to create a database but couldn't because of \"<span style=\"font-family:Courier New,Courier,mono;\">SQL1005N&nbsp; The database alias \"W3IBMDB\" already exists in either the local database directory or system database directory.</span>\". I knew I had once such a database, but I thought it existed no more. And indeed \"<span style=\"font-family:Courier New,Courier,mono;\">list database directory</span>\" didn't list it. So it was there and it wasn't there.<br /><br />It seems that DB2 remembers the old databases if you don't remove them in the correct way (whatever that is). The steps to fix this were:<br />\n<ul>\n<li style=\"font-family:Courier New,Courier,mono;\">catalog db w3ibmdb</li>\n<li>check \"<span style=\"font-family:Courier New,Courier,mono;\">list database directory</span>\" to verify that it is listed now</li>\n<li style=\"font-family:Courier New,Courier,mono;\">drop database W3IBMDB</li>\n<li><span style=\"font-family:Courier New,Courier,mono;\">create database W3IBMDB</span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; -- Voila - no more error messages<br /></li></ul>",
  "excerpt": ""
 },
 {
  "title": "RAD: Server Configurations in Rational Developer 6.0: copy, repair...",
  "published": "2006-10-19 04:34:59",
  "postType": "post",
  "slug": "/2006/10/19/rad-server-configurations-in-ratio/",
  "status": "publish",
  "tags": [],
  "categories": [
   "eclipse"
  ],
  "content": "This article describes some tricks you can do with RAD's server configurations (mostly for WebSpehere App.Server/Portal Server).<br /><br />\n<h5>1. Problem: Create a new server config based on an old one.</h5>&nbsp;The view \"Servers\" only permits to create a new server configuration (R mouse - New - Server). To create it based on an existing configuration (called further \"source config\"):<br />Create a new server config, name it somehow. Exit RAD.<br />Goto &lt;WORKSPACE&gt;/.metadata/.plugins/com.ibm.wtp.server.core/ and find the id of the new configuration and theid of the source config. in configurations.xml <br />Copy the directory &lt;WORKSPACE&gt;/.metadata/.plugins/com.ibm.wtp.server.core/configs/&lt;source config id&gt;-data to the neighbouring &lt;new config id&gt;-data<br />Start RAD, make the adjustements needed.<br /><br />\n<h5>2. Remove a project from config's applications by force</h5>Go to &lt;WORKSPACE&gt;/.metadata/.plugins/com.ibm.wtp.server.core/configs/&lt;the config id&gt;-data/ (see above how to find the id): remove any reference to the given project in memento.xml and delete the sub-directory cells\\localhost\\applications\\&lt;project name&gt;<br />It may also help to clear all tmp*/ directories under &lt;WORKSPACE&gt;/.metadata/.plugins/com.ibm.wtp.server.core/<br /><br />UPDATE:<br />The steps above likely aren't necessary. The only necessary thing is to remove the entries from:<br />&nbsp;&lt;WORKSPACE&gt;/.metadata/.plugins/com.ibm.wtp.server.core/configs/&lt;the config id&gt;-data/cells/localhost/nodes/localhost/serverindex.xml <br />!!! Don't remove wmmApp - the server will fail to start w/o it.<br /><br />",
  "excerpt": ""
 },
 {
  "title": "DB2: Find out current locks, long transactions etc. [snapshot]",
  "published": "2006-10-19 02:25:13",
  "postType": "post",
  "slug": "/2006/10/19/db2-find-out-current-locks-long-tr/",
  "status": "publish",
  "tags": [
   "db2",
   "performance",
   "troubleshooting"
  ],
  "categories": [
   "Databases"
  ],
  "content": "To find out current locks in a DB and other information about its current state, you need to take a \"snapshot\":<br /><br /><pre>db2 \"attach to  user  using \"</pre><pre>db2 \"get snapshot for applications on \"  &gt; mydatabase_snapshot.txt</pre><br />Look into the resulting mydatabase_snapshot.txt for \"Application ID holding\"&nbsp; (if there is a lock, this will read the ID of the aplication holding the lock). To find long queries [that are currently running], look for \"Executing\".<br /><br />",
  "excerpt": ""
 },
 {
  "title": "Ant/Maven: Add build date/revision to the generated JAR''s Manifest",
  "published": "2006-10-19 04:11:33",
  "postType": "post",
  "slug": "/2006/10/19/antmaven-add-build-daterevision-to/",
  "status": "publish",
  "tags": [],
  "categories": [
   "Tools"
  ],
  "content": "I'll explain how to get build time info and svn revision into the buildedjar/ear in Maven or Ant.<br /><br><br>\n<h4>1. Maven</h4><br><br><p>If you want to have the build date of a JAR built by Maven in its Manifest\nfile, paste the following lines at the beginning of your maven.xml:</p>\n<pre><code>&lt;tstamp/&gt;\n&lt;j:set value=\"JarBuildDate var=\"maven.jar.manifest.attributes.list\" /&gt;\n&lt;j:set value=\"${DSTAMP}\" var=\"maven.jar.manifest.attribute.JarBuildDate\" /&gt;</code></pre><br><br><p>Explication:</p>\n<ol>\n  <li><code>&lt;tstamp/&gt;</code> executes the Ant's task Tstamp, which\n    defines the variables DSTAMP (date in the form YYYYMMDD), TODAY (MMMM dd\n    yyyy) and TSTAMP (hhmm).</li>\n  <li>The property <code>maven.jar.manifest.attributes.list</code> tells the\n    jar:jar goal what entries to add into the resulting manifest. Attention:\n    value=\"JarBuildDate\" and =\" JarBuildDate\" define 2 different variables,\n    i.e. whitespaces are very significant. You must also comply with the\n    definition of valid manifest entriy names. The variable may hold multiple\n    entries separated by a comma. Side note: what happens, if the variable is\n    already set? Is the old value preserved or overwritten?</li>\n  <li><code>maven.jar.manifest.attribute.JarBuildDate</code> sets the value\n    for the manifest entry defined in the ...list property.</li>\n</ol><br><br><h4>2. Ant</h4>\n<pre><code>&lt;!-- Create manifest with build time info --&gt;\n&lt;manifest file=\"ear-MANIFEST.MF\"&gt;\n                 &lt;attribute name=\"MyBuild-Date\" value=\"${DSTAMP}\" /&gt;\n                 &lt;attribute name=\"MyBuild-Time\" value=\"${TSTAMP}\" /&gt;\n                 &lt;attribute name=\"MyBuild-Svn-Revision\" value=\"${svn.version}\" /&gt;\n&lt;/manifest&gt;<br><br>&lt;jar manifest=\"ear-MANIFEST.MF\" .. /&gt; &lt;!-- the same for an &lt;ear .. --&gt;</code></pre><br><br><p>Explanation: It's basically the same as for maven. The task 'manifest'\ngenerates a manifest file.</p><br><br><h4>3. Get SVN revision</h4>\n<p>Warning:<em>This only works with the plain-text format of .svn/entries, not with the older XML format.</em></p>\n<p>To get an SVN revision of you project at the time of building, you can use\nthe following task to get the revision number into the property svn.version\n(requires ant &gt;= 1.6):</p>\n<pre><code>&lt;loadfile\n   property=\"svn.version\" srcFile=\".svn/entries\" failonerror=\"true\"&gt;\n   &lt;filterchain&gt;\n      &lt;headfilter lines=\"6\"/&gt;\n      &lt;tokenfilter&gt;\n         &lt;filetokenizer/&gt;\n         &lt;replaceregex pattern=\".*[\\r\\n]+dir[\\r\\n]+([0-9]+)[\\r\\n]+http://.*\"\n            flags=\"s\" replace=\"\\1\"/&gt;\n      &lt;/tokenfilter&gt;\n   &lt;/filterchain&gt;\n&lt;/loadfile&gt;</code></pre><br><br><p>Explanation:<br />\n.svn/entries is a SVN file having something like this somewhere at its\nbeginning:</p>\n<pre><code>8<br><br>\ndir\n7946\nhttp://example.com/svn/repos//Projects/MyProject</code></pre>\n<ul>\n  <li><code>headfilter</code> takes first 6 lines of the file</li>\n  <li><code>filetokenizer</code> gets all those lines into 1 string</li>\n  <li><code>replaceregexp</code> finds the revision number in it and replaces\n    all the string with this number</li>\n  <li>the result is stored into the property <code>svn.version</code></li>\n</ul>",
  "excerpt": ""
 },
 {
  "title": "Sending a SOAP request to a Web Service via URLConnection",
  "published": "2006-05-25 04:15:13",
  "postType": "post",
  "slug": "/2006/05/25/sending-a-soap-request-to-a-web-se/",
  "status": "publish",
  "tags": [
   "java",
   "javaEE",
   "Testing",
   "webservice"
  ],
  "categories": [
   "j2ee",
   "Languages"
  ],
  "content": "<p>\nYou may want to test you web service by sending it a manually composed request and reading the XML returned. Here's how to do it (e.g. using BeanShell in jEdit):\n</p><br><br><h3>The SOAP request</h3>\n<pre><span CLASS=\"syntax10\">&lt;?</span><span CLASS=\"syntax10\">xml</span><span CLASS=\"syntax10\"> </span><span CLASS=\"syntax10\">version=\"1.0\"</span><span CLASS=\"syntax10\"> </span><span CLASS=\"syntax10\">encoding=\"utf-16\"?</span><span CLASS=\"syntax10\">&gt;</span>\n<span CLASS=\"syntax17\">&lt;</span><span CLASS=\"syntax12\">soap</span><span CLASS=\"syntax17\">:</span><span CLASS=\"syntax17\">Envelope</span><span CLASS=\"syntax17\"> </span><span CLASS=\"syntax12\">xmlns</span><span CLASS=\"syntax17\">:</span><span CLASS=\"syntax17\">soap</span><span CLASS=\"syntax17\">=</span><span CLASS=\"syntax13\">\"</span><span CLASS=\"syntax13\">http://schemas.xmlsoap.org/soap/envelope/</span><span CLASS=\"syntax13\">\"</span><span CLASS=\"syntax17\"> </span><span CLASS=\"syntax12\">xmlns</span><span CLASS=\"syntax17\">:</span><span CLASS=\"syntax17\">xsi</span><span CLASS=\"syntax17\">=</span><span CLASS=\"syntax13\">\"</span><span CLASS=\"syntax13\">http://www.w3.org/2001/XMLSchema-instance</span><span CLASS=\"syntax13\">\"</span><span CLASS=\"syntax17\"> </span><span CLASS=\"syntax12\">xmlns</span><span CLASS=\"syntax17\">:</span><span CLASS=\"syntax17\">xsd</span><span CLASS=\"syntax17\">=</span><span CLASS=\"syntax13\">\"</span><span CLASS=\"syntax13\">http://www.w3.org/2001/XMLSchema</span><span CLASS=\"syntax13\">\"</span><span CLASS=\"syntax17\">&gt;</span>\n  <span CLASS=\"syntax17\">&lt;</span><span CLASS=\"syntax12\">soap</span><span CLASS=\"syntax17\">:</span><span CLASS=\"syntax17\">Body</span><span CLASS=\"syntax17\">&gt;</span>\n    <span CLASS=\"syntax17\">&lt;</span><span CLASS=\"syntax17\">getUserByEmail</span><span CLASS=\"syntax17\"> </span><span CLASS=\"syntax17\">xmlns</span><span CLASS=\"syntax17\">=</span><span CLASS=\"syntax13\">\"</span><span CLASS=\"syntax13\">http://service.w3.ibm.com</span><span CLASS=\"syntax13\">\"</span><span CLASS=\"syntax17\">&gt;</span>\n      <span CLASS=\"syntax17\">&lt;</span><span CLASS=\"syntax17\">iuser</span><span CLASS=\"syntax17\">&gt;</span>jholy@example.com<span CLASS=\"syntax17\">&lt;</span><span CLASS=\"syntax17\">/</span><span CLASS=\"syntax17\">iuser</span><span CLASS=\"syntax17\">&gt;</span>\n    <span CLASS=\"syntax17\">&lt;</span><span CLASS=\"syntax17\">/</span><span CLASS=\"syntax17\">getUserByEmail</span><span CLASS=\"syntax17\">&gt;</span>\n  <span CLASS=\"syntax17\">&lt;</span><span CLASS=\"syntax17\">/</span><span CLASS=\"syntax12\">soap</span><span CLASS=\"syntax17\">:</span><span CLASS=\"syntax17\">Body</span><span CLASS=\"syntax17\">&gt;</span>\n<span CLASS=\"syntax17\">&lt;</span><span CLASS=\"syntax17\">/</span><span CLASS=\"syntax12\">soap</span><span CLASS=\"syntax17\">:</span><span CLASS=\"syntax17\">Envelope</span><span CLASS=\"syntax17\">&gt;</span>\n</pre>\n<h3>The Java code</h3>\n<pre><code>\nString soapXml =   // jEdit: = buffer.getText(0,buffer.getLength())\njava.net.URL url = new java.net.URL(\"http://localhost:9081/myServiceWAR/services/MyService\");\njava.net.URLConnection conn = url.openConnection();\n// Set the necessary header fields\nconn.setRequestProperty(\"SOAPAction\", \"http://localhost:9081/myServiceWAR/services/MyService\");\nconn.setDoOutput(true);\n// Send the request\njava.io.OutputStreamWriter wr = new java.io.OutputStreamWriter(conn.getOutputStream());\nwr.write(soapXml);\nwr.flush();\n// Read the response\njava.io.BufferedReader rd = new java.io.BufferedReader(new java.io.InputStreamReader(conn.getInputStream()));\nString line;\nwhile ((line = rd.readLine()) != null) { System.out.println(line); /*jEdit: print(line); */ }\n</code></pre>",
  "excerpt": ""
 },
 {
  "title": "RAD, WebSphere and changing the classloader mode",
  "published": "2006-05-04 10:19:48",
  "postType": "post",
  "slug": "/2006/05/04/rad-websphere-and-changing-the-cla/",
  "status": "publish",
  "tags": [],
  "categories": [
   "WebSphere"
  ],
  "content": "<p>\nI've spent hours trying to change the classloader mode for a .war include in an .ear application and deployed to the WebSphere Portal v5.1 Test Environment by means of Rational Application Developer's server configuration editor. I was able to change to for the EAR, but when I changed the mode for a WAR of the EAR from PARENT_FIRST to PARENT_LAST and saved the configuration, I was required to republish, after doing this RAD promted me to reload the configuration from the disk because it has changed. I did so - and my change to parent_last was gone.\n</p><p>\nFinally i discovered that if I stop the server, remove the application (EAR), republish (?), add the application, change the classloader mode of all WARs in question (and perhaps the EAR as well), save the config. and republish, the change will really apply.\n</p><p>\nI'm looking forward to have even more fun with WebSphere and RAD... ;-)\n</p><p>\nRAD 6.0<br />\nWebSphere Portal v5.1 Test Environment\n</p>",
  "excerpt": ""
 },
 {
  "title": "Eclipse: Run => NoClassDefFoundError for an interface when loading a class implementing it",
  "published": "2006-04-21 02:42:08",
  "postType": "post",
  "slug": "/2006/04/21/eclipse-run-gt-noclassdeffounderro/",
  "status": "publish",
  "tags": [
   "classpath",
   "java"
  ],
  "categories": [
   "Languages"
  ],
  "content": "I had quite a hard time trying to run the following code in Eclipse (CollectionUserType implements UserType):<br /><pre>Class.forName(\"net.sf.hibernate.tap.CollectionUserType\");</pre>\n<p>The problem was:</p>Exception in thread \"main\" java.lang.NoClassDefFoundError: net/sf/hibernate/UserType<br />&nbsp;&nbsp;&nbsp; at java.lang.ClassLoader.findBootstrapClass(Native Method)<br />&nbsp;&nbsp;&nbsp; at java.lang.ClassLoader.findBootstrapClass0(ClassLoader.java:891)<br />&nbsp;&nbsp;&nbsp; at java.lang.ClassLoader.loadClass(ClassLoader.java:301)<br />&nbsp;&nbsp;&nbsp; at java.lang.ClassLoader.loadClass(ClassLoader.java:299)<br />&nbsp;&nbsp;&nbsp; at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:268)<br />&nbsp;&nbsp;&nbsp; at java.lang.ClassLoader.loadClass(ClassLoader.java:251)<br /><br />\n<p>The strange thing was that I could define instances of both UserType and CollectionUserType so it was clear that the classes are available. The evident conclusion was that CollectionUserType&nbsp; is loaded by a special classloader that doesn't have access to UserType.<br /><br />Examining closely the Run Configuration I've discovered the cause: the location of CollectionUserType  was among the <span style=\"font-weight:bold;\">Bootstrap Entries</span> while the location of UserType was among <span style=\"font-weight:bold;\">User Entries</span>. And since the bootstrap class loader is above other class loaders in the class loader hierarchy, it has no access to classes loaded by the subordinate class loaders (including UserType) while vice versa it's all right.&lt;</p>\n<p>So the solution was to move the entry from Bootstrap Entries to User Entries.</p>",
  "excerpt": ""
 },
 {
  "title": "Redeploy an application (ear/war/…) on JBoss",
  "published": "2006-04-12 08:02:57",
  "postType": "post",
  "slug": "/2006/04/12/redeploy-an-application-earwar/",
  "status": "publish",
  "tags": [
   "appserver",
   "deployment",
   "javaEE",
   "jboss"
  ],
  "categories": [
   "j2ee"
  ],
  "content": "<h3>A) Via JMX-console</h3>\n<ol>\n<li>find jboss.system:service=MainDeployer</li>\n<li>invoke listDeployed - find something like:<br /><pre>org.jboss.deployment.DeploymentInfo@d78e875f { url=file:/C:/jboss-3.2.3/server/default/deploy/tap.ear } </pre></li>\n<li>&nbsp; copy the url, go back and invoke Redeploy with the url (file:/C:/...) as the parameter.</li></ol>\n<h3>B) From the command line </h3>\n<p>The operations that can be invoked via the JBoss JMX console can also be invoked by the cmd line client <span style=\"font-family:Courier New,Courier,mono;\">&lt;jboss home&gt;/bin/twiddle</span>.</p>\n<h3>C) Manually</h3>Modify application.xml (or web.xml for .war) of the application if deployed in the expload mode (or modify/touch/ the .ear?)<span style=\"font-style:italic;\"><br /></span>",
  "excerpt": ""
 },
 {
  "title": "Access EJB on JBoss from outside",
  "published": "2006-04-10 09:59:09",
  "postType": "post",
  "slug": "/2006/04/10/access-ejb-on-jboss-from-outside/",
  "status": "publish",
  "tags": [
   "aapserver",
   "EJB",
   "javaEE",
   "jboss"
  ],
  "categories": [
   "j2ee"
  ],
  "content": "<p>\nHow to acces an enterprise java bean (EJB) running on JBoss from a standalone application running outside JBoss?\n</p><br><br><ol>\n<li>In the code you must, among others:<br><br><ol><br><br>\n<li>Set properties for a naming context and create one to be able to look the EJB up</li><br><br>\n<li>Authenticate by JBoss by means of JAAS</li></ol></li>\n<li>To run the application:<br><br><ol><br><br>\n<li>Set the classpath (-cp ...): it must contain jbosssx.jar (ClientLoginModule), jboss-common.jar and jnpserver.jar (naming stuff) from &lt;jboss home&gt;/server/default/lib </li><br><br>\n<li>Create the JAAS configuration file sample_jaas.config containing:\n<pre>\njboss_jaas { org.jboss.security.ClientLoginModule required; };\n</pre><br />\n<br />\nIf you ever wanted to run the application from JBoss, replace the JAAS config file by the following entry in &lt;JBoss home&gt;/server/default/conf/login-config.ml (application-policy name must be the same name as the one passed to the constructor of a LoginContext):\n<pre>\n&lt;application-policy name = \"tap_experiments\"&gt;\n       &lt;authentication&gt;\n          &lt;login-module code = \"org.jboss.security.ClientLoginModule\"  flag = \"required\"&gt;&lt;/login-module&gt;\n       &lt;/authentication&gt;\n    &lt;/application-policy&gt;\n</pre>\n</pre>\n</li><br><br>\n<li>Pass the file to the JVM: <kbd>-Djava.security.auth.login.config=sample_jaas.config</kbd> </li><br><br>\n<li>Set a security manager by passing the following options to the JVM:\n<kbd>-Djava.security.manager -Djava.security.policy=\"&lt;jboss home&gt;\\server\\default\\conf\\server.policy\"</kbd>\n </li></ol></li></ol><pre><span class=\"syntax9\">import</span> java.rmi.RemoteException;\n<span class=\"syntax9\">import</span> java.util.Properties;<br><br><span class=\"syntax9\">import</span> javax.ejb.CreateException;\n<span class=\"syntax9\">import</span> javax.naming.Context;\n<span class=\"syntax9\">import</span> javax.naming.InitialContext;\n<span class=\"syntax9\">import</span> javax.naming.NamingException;\n<span class=\"syntax9\">import</span> javax.rmi.PortableRemoteObject;\n<span class=\"syntax9\">import</span> javax.security.auth.callback.Callback;\n<span class=\"syntax9\">import</span> javax.security.auth.callback.CallbackHandler;\n<span class=\"syntax9\">import</span> javax.security.auth.callback.NameCallback;\n<span class=\"syntax9\">import</span> javax.security.auth.callback.PasswordCallback;\n<span class=\"syntax9\">import</span> javax.security.auth.callback.UnsupportedCallbackException;\n<span class=\"syntax9\">import</span> javax.security.auth.login.LoginContext;\n<span class=\"syntax9\">import</span> javax.security.auth.login.LoginException;<br><br><span class=\"syntax9\">import</span> com.teradata.tap.system.query.ejb.QueryEngineRemote;\n<span class=\"syntax9\">import</span> com.teradata.tap.system.query.ejb.QueryEngineRemoteHome;<br><br><span class=\"syntax3\">/**</span>\n<span class=\"syntax3\"> </span><span class=\"syntax3\">*</span><span class=\"syntax3\"> </span><span class=\"syntax3\">Call</span><span class=\"syntax3\"> </span><span class=\"syntax3\">a</span><span class=\"syntax3\"> </span><span class=\"syntax3\">business</span><span class=\"syntax3\"> </span><span class=\"syntax3\">method</span><span class=\"syntax3\"> </span><span class=\"syntax3\">of</span><span class=\"syntax3\"> </span><span class=\"syntax3\">an</span><span class=\"syntax3\"> </span><span class=\"syntax3\">EJB</span><span class=\"syntax3\"> </span><span class=\"syntax3\">running</span><span class=\"syntax3\"> </span><span class=\"syntax3\">on</span><span class=\"syntax3\"> </span><span class=\"syntax3\">JBoss</span>\n<span class=\"syntax3\"> </span><span class=\"syntax3\">*/</span>\n<span class=\"syntax8\">public</span> <span class=\"syntax10\">class</span> ExternalCallEjbSample <span class=\"syntax18\">{</span><br><br>        <span class=\"syntax8\">public</span> <span class=\"syntax8\">static</span> <span class=\"syntax10\">void</span> <span class=\"syntax6\">main</span>(String[] args) <span class=\"syntax18\">{</span>\n                <span class=\"syntax2\">//</span><span class=\"syntax2\"> </span><span class=\"syntax2\">1:</span><span class=\"syntax2\"> </span><span class=\"syntax2\">Get</span><span class=\"syntax2\"> </span><span class=\"syntax2\">the</span><span class=\"syntax2\"> </span><span class=\"syntax2\">naming</span><span class=\"syntax2\"> </span><span class=\"syntax2\">Context</span>\n                <span class=\"syntax2\">//</span><span class=\"syntax2\"> </span><span class=\"syntax2\">Required</span><span class=\"syntax2\"> </span><span class=\"syntax2\">JARs</span><span class=\"syntax2\"> </span><span class=\"syntax2\">(in</span><span class=\"syntax2\"> </span><span class=\"syntax2\">jboss/server/default/lib):</span><span class=\"syntax2\"> </span><span class=\"syntax2\">jboss-common.jar,</span><span class=\"syntax2\"> </span><span class=\"syntax2\">jnpserver.jar</span><span class=\"syntax2\"> </span>\n                Properties props <span class=\"syntax18\">=</span> <span class=\"syntax8\">new</span> <span class=\"syntax6\">Properties</span>();\n                <span class=\"syntax2\">//</span><span class=\"syntax2\">      </span><span class=\"syntax2\">Matches</span><span class=\"syntax2\"> </span><span class=\"syntax2\">the</span><span class=\"syntax2\"> </span><span class=\"syntax2\">java.naming.factory.initial</span><span class=\"syntax2\"> </span><span class=\"syntax2\">property</span><span class=\"syntax2\"> </span><span class=\"syntax2\">in</span><span class=\"syntax2\"> </span><span class=\"syntax2\">jndi.properties</span>\n                props.<span class=\"syntax6\">put</span>(Context.INITIAL_CONTEXT_FACTORY,\n                                <span class=\"syntax13\">\"</span><span class=\"syntax13\">org.jnp.interfaces.NamingContextFactory</span><span class=\"syntax13\">\"</span>);\n                <span class=\"syntax2\">//</span><span class=\"syntax2\">      </span><span class=\"syntax2\">Matches</span><span class=\"syntax2\"> </span><span class=\"syntax2\">the</span><span class=\"syntax2\"> </span><span class=\"syntax2\">java.naming.provider.url</span><span class=\"syntax2\"> </span><span class=\"syntax2\">property</span><span class=\"syntax2\"> </span><span class=\"syntax2\">in</span><span class=\"syntax2\"> </span><span class=\"syntax2\">jndi.properties</span>\n                props.<span class=\"syntax6\">put</span>(Context.PROVIDER_URL, <span class=\"syntax13\">\"</span><span class=\"syntax13\">jnp://localhost:1099</span><span class=\"syntax13\">\"</span>);\n                props.<span class=\"syntax6\">put</span>(Context.URL_PKG_PREFIXES,\n                                <span class=\"syntax13\">\"</span><span class=\"syntax13\">org.jboss.naming:org.jnp.interfaces</span><span class=\"syntax13\">\"</span>);\n                QueryEngineRemoteHome queryEngineHome <span class=\"syntax18\">=</span> <span class=\"syntax14\">null</span>;<br><br>                <span class=\"syntax8\">try</span> <span class=\"syntax18\">{</span><br><br>                        Context ctx <span class=\"syntax18\">=</span> <span class=\"syntax8\">new</span> <span class=\"syntax6\">InitialContext</span>(props);<br><br>                        <span class=\"syntax1\">/*</span><span class=\"syntax1\">/</span><span class=\"syntax1\"> </span><span class=\"syntax1\">Print</span><span class=\"syntax1\"> </span><span class=\"syntax1\">all</span><span class=\"syntax1\"> </span><span class=\"syntax1\">entries</span><span class=\"syntax1\"> </span><span class=\"syntax1\">in</span><span class=\"syntax1\"> </span><span class=\"syntax1\">the</span><span class=\"syntax1\"> </span><span class=\"syntax1\">JNDI</span>\n<span class=\"syntax1\">        </span><span class=\"syntax1\">        </span><span class=\"syntax1\">        </span><span class=\"syntax1\"> </span><span class=\"syntax1\">NamingEnumeration</span><span class=\"syntax1\"> </span><span class=\"syntax1\">ne</span><span class=\"syntax1\"> </span><span class=\"syntax1\">=</span><span class=\"syntax1\"> </span><span class=\"syntax1\">ctx.list(\"java:\");</span>\n<span class=\"syntax1\">        </span><span class=\"syntax1\">        </span><span class=\"syntax1\">        </span><span class=\"syntax1\"> </span><span class=\"syntax1\">while</span><span class=\"syntax1\"> </span><span class=\"syntax1\">(ne.hasMore())</span><span class=\"syntax1\"> </span><span class=\"syntax1\">{</span>\n<span class=\"syntax1\">        </span><span class=\"syntax1\">        </span><span class=\"syntax1\">        </span><span class=\"syntax1\"> </span><span class=\"syntax1\">System.out.println(\"A:</span><span class=\"syntax1\"> </span><span class=\"syntax1\">\"</span><span class=\"syntax1\"> </span><span class=\"syntax1\">+</span><span class=\"syntax1\"> </span><span class=\"syntax1\">ne.next().toString());</span>\n<span class=\"syntax1\">        </span><span class=\"syntax1\">        </span><span class=\"syntax1\">        </span><span class=\"syntax1\"> </span><span class=\"syntax1\">}</span><span class=\"syntax1\"> </span><span class=\"syntax1\">//</span><span class=\"syntax1\">*/</span><br><br>                        <span class=\"syntax2\">//</span><span class=\"syntax2\"> </span><span class=\"syntax2\">Look</span><span class=\"syntax2\"> </span><span class=\"syntax2\">up</span><span class=\"syntax2\"> </span><span class=\"syntax2\">and</span><span class=\"syntax2\"> </span><span class=\"syntax2\">instantiate</span><span class=\"syntax2\"> </span><span class=\"syntax2\">the</span><span class=\"syntax2\"> </span><span class=\"syntax2\">home</span><span class=\"syntax2\"> </span><span class=\"syntax2\">interface</span><span class=\"syntax2\"> </span><span class=\"syntax2\">of</span><span class=\"syntax2\"> </span><span class=\"syntax2\">the</span><span class=\"syntax2\"> </span><span class=\"syntax2\">EJB</span>\n                        <span class=\"syntax2\">//</span><span class=\"syntax2\"> </span><span class=\"syntax2\">IMPORTANT:</span><span class=\"syntax2\"> </span><span class=\"syntax2\">It</span><span class=\"syntax2\"> </span><span class=\"syntax2\">fails</span><span class=\"syntax2\"> </span><span class=\"syntax2\">if</span><span class=\"syntax2\"> </span><span class=\"syntax2\">no</span><span class=\"syntax2\"> </span><span class=\"syntax2\">SecurityManager</span><span class=\"syntax2\"> </span><span class=\"syntax2\">specified</span><span class=\"syntax2\"> </span><span class=\"syntax2\">for</span><span class=\"syntax2\"> </span><span class=\"syntax2\">RMI</span><span class=\"syntax2\"> </span><span class=\"syntax2\">class</span><span class=\"syntax2\"> </span><span class=\"syntax2\">loader</span><span class=\"syntax2\"> </span><span class=\"syntax2\">will</span><span class=\"syntax2\"> </span><span class=\"syntax2\">be</span><span class=\"syntax2\"> </span><span class=\"syntax2\">disabled</span>\n                        <span class=\"syntax2\">//</span><span class=\"syntax2\"> </span><span class=\"syntax2\">-&gt;</span><span class=\"syntax2\"> </span><span class=\"syntax2\">add</span><span class=\"syntax2\"> </span><span class=\"syntax2\">these</span><span class=\"syntax2\"> </span><span class=\"syntax2\">options</span><span class=\"syntax2\"> </span><span class=\"syntax2\">to</span><span class=\"syntax2\"> </span><span class=\"syntax2\">the</span><span class=\"syntax2\"> </span><span class=\"syntax2\">JVM:</span>\n                        <span class=\"syntax2\">//</span><span class=\"syntax2\"> </span><span class=\"syntax2\">-Djava.security.manager</span><span class=\"syntax2\"> </span><span class=\"syntax2\">-Djava.security.policy=\"</span><span class=\"syntax2\"> </span><span class=\"syntax2\">home&gt;\\server\\default\\conf\\server.policy\"</span>\n                        String beanName <span class=\"syntax18\">=</span> QueryEngineRemoteHome.JNDI_NAME;\n                        System.out.<span class=\"syntax6\">println</span>(<span class=\"syntax13\">\"</span><span class=\"syntax13\">Looking</span><span class=\"syntax13\"> </span><span class=\"syntax13\">up</span><span class=\"syntax13\"> </span><span class=\"syntax13\">'</span><span class=\"syntax13\">\"</span> <span class=\"syntax18\">+</span> beanName <span class=\"syntax18\">+</span> <span class=\"syntax13\">\"</span><span class=\"syntax13\">'</span><span class=\"syntax13\">\"</span>);\n                        Object lookup <span class=\"syntax18\">=</span> ctx.<span class=\"syntax6\">lookup</span>(beanName);<br><br>                        queryEngineHome <span class=\"syntax18\">=</span> (QueryEngineRemoteHome) PortableRemoteObject\n                                        .<span class=\"syntax6\">narrow</span>(lookup, QueryEngineRemoteHome.<span class=\"syntax10\">class</span>);<br><br>                <span class=\"syntax18\">}</span> <span class=\"syntax8\">catch</span> (NamingException e) <span class=\"syntax18\">{</span>\n                        System.out.<span class=\"syntax6\">println</span>(<span class=\"syntax13\">\"</span><span class=\"syntax13\">new</span><span class=\"syntax13\"> </span><span class=\"syntax13\">InitialContext</span><span class=\"syntax13\"> </span><span class=\"syntax13\">failed:</span><span class=\"syntax13\">\"</span> <span class=\"syntax18\">+</span> e);\n                <span class=\"syntax18\">}</span><br><br>                <span class=\"syntax2\">//</span><span class=\"syntax2\"> </span><span class=\"syntax2\">2.</span><span class=\"syntax2\"> </span><span class=\"syntax2\">Instantiate</span><span class=\"syntax2\"> </span><span class=\"syntax2\">the</span><span class=\"syntax2\"> </span><span class=\"syntax2\">(remote)</span><span class=\"syntax2\"> </span><span class=\"syntax2\">EJB</span><span class=\"syntax2\"> </span><span class=\"syntax2\">and</span><span class=\"syntax2\"> </span><span class=\"syntax2\">call</span><span class=\"syntax2\"> </span><span class=\"syntax2\">its</span><span class=\"syntax2\"> </span><span class=\"syntax2\">business</span><span class=\"syntax2\"> </span><span class=\"syntax2\">method(s)</span>\n                <span class=\"syntax2\">//</span><span class=\"syntax2\"> </span><span class=\"syntax2\">2.1</span><span class=\"syntax2\"> </span><span class=\"syntax2\">I</span><span class=\"syntax2\"> </span><span class=\"syntax2\">have</span><span class=\"syntax2\"> </span><span class=\"syntax2\">to</span><span class=\"syntax2\"> </span><span class=\"syntax2\">authenticate</span><span class=\"syntax2\"> </span><span class=\"syntax2\">unless</span><span class=\"syntax2\"> </span><span class=\"syntax2\">security</span><span class=\"syntax2\"> </span><span class=\"syntax2\">allows</span><span class=\"syntax2\"> </span><span class=\"syntax2\">anybody</span><span class=\"syntax2\"> </span><span class=\"syntax2\">to</span><span class=\"syntax2\"> </span><span class=\"syntax2\">call</span><span class=\"syntax2\"> </span><span class=\"syntax2\">create</span><span class=\"syntax2\"> </span><span class=\"syntax2\">on</span><span class=\"syntax2\"> </span><span class=\"syntax2\">the</span><span class=\"syntax2\"> </span><span class=\"syntax2\">EJB</span>\n                <span class=\"syntax2\">//</span><span class=\"syntax2\"> </span><span class=\"syntax2\">     </span><span class=\"syntax2\">Otherwise</span><span class=\"syntax2\"> </span><span class=\"syntax2\">an</span><span class=\"syntax2\"> </span><span class=\"syntax2\">EJBException:</span><span class=\"syntax2\"> </span><span class=\"syntax2\">checkSecurityAssociation</span><span class=\"syntax2\"> </span><span class=\"syntax2\">will</span><span class=\"syntax2\"> </span><span class=\"syntax2\">be</span><span class=\"syntax2\"> </span><span class=\"syntax2\">thrown.</span>\n                <span class=\"syntax2\">//</span><span class=\"syntax2\"> </span><span class=\"syntax2\">TODO:</span><span class=\"syntax2\"> </span><span class=\"syntax2\">JVM</span><span class=\"syntax2\"> </span><span class=\"syntax2\">option</span><span class=\"syntax2\"> </span><span class=\"syntax2\">-Djava.security.auth.login.config==sample_jaas.config</span><span class=\"syntax2\"> </span><span class=\"syntax2\">-</span><span class=\"syntax2\"> </span><span class=\"syntax2\">use</span><span class=\"syntax2\"> </span><span class=\"syntax2\">org.jboss.security.ClientLoginModule</span>\n                <span class=\"syntax2\">//</span><span class=\"syntax2\"> </span><span class=\"syntax2\">and</span><span class=\"syntax2\"> </span><span class=\"syntax2\">have</span><span class=\"syntax2\"> </span><span class=\"syntax2\"></span><span class=\"syntax2\"> </span><span class=\"syntax2\">home&gt;\\server\\default\\lib\\jbosssx.jar</span><span class=\"syntax2\"> </span><span class=\"syntax2\">on</span><span class=\"syntax2\"> </span><span class=\"syntax2\">the</span><span class=\"syntax2\"> </span><span class=\"syntax2\">path</span><span class=\"syntax2\"> </span><span class=\"syntax2\">(class</span><span class=\"syntax2\"> </span><span class=\"syntax2\">ClientLoginModule)</span>\n                <span class=\"syntax2\">//</span><span class=\"syntax2\"> </span><span class=\"syntax2\">Listing</span><span class=\"syntax2\"> </span><span class=\"syntax2\">of</span><span class=\"syntax2\"> </span><span class=\"syntax2\">sample_jaas.config:</span>\n                <span class=\"syntax2\">//</span><span class=\"syntax2\"> </span><span class=\"syntax2\">     </span><span class=\"syntax2\">jboss_jaas</span><span class=\"syntax2\"> </span><span class=\"syntax2\">{</span><span class=\"syntax2\"> </span><span class=\"syntax2\">org.jboss.security.ClientLoginModule</span><span class=\"syntax2\"> </span><span class=\"syntax2\">required</span><span class=\"syntax2\"> </span><span class=\"syntax2\">debug=true;</span><span class=\"syntax2\"> </span><span class=\"syntax2\">};</span>\n                LoginContext loginContext <span class=\"syntax18\">=</span> <span class=\"syntax14\">null</span>;\n                <span class=\"syntax10\">boolean</span> loggedIn <span class=\"syntax18\">=</span> <span class=\"syntax14\">false</span>;\n                <span class=\"syntax8\">try</span> <span class=\"syntax18\">{</span>\n                        CallbackHandler handler <span class=\"syntax18\">=</span> <span class=\"syntax8\">new</span> <span class=\"syntax6\">MyPresetCallbackHandler</span>(<span class=\"syntax13\">\"</span><span class=\"syntax13\">tapdev</span><span class=\"syntax13\">\"</span>,<span class=\"syntax13\">\"</span><span class=\"syntax13\">tapdev</span><span class=\"syntax13\">\"</span>);\n                        <span class=\"syntax2\">//</span><span class=\"syntax2\"> </span><span class=\"syntax2\">jboss_jaas</span><span class=\"syntax2\"> </span><span class=\"syntax2\">-</span><span class=\"syntax2\"> </span><span class=\"syntax2\">name</span><span class=\"syntax2\"> </span><span class=\"syntax2\">of</span><span class=\"syntax2\"> </span><span class=\"syntax2\">a</span><span class=\"syntax2\"> </span><span class=\"syntax2\">configuration</span><span class=\"syntax2\"> </span><span class=\"syntax2\">in</span><span class=\"syntax2\"> </span><span class=\"syntax2\">the</span><span class=\"syntax2\"> </span><span class=\"syntax2\">jaas</span><span class=\"syntax2\"> </span><span class=\"syntax2\">config</span><span class=\"syntax2\"> </span><span class=\"syntax2\">file</span><span class=\"syntax2\"> </span>\n                        loginContext <span class=\"syntax18\">=</span> <span class=\"syntax8\">new</span> <span class=\"syntax6\">LoginContext</span>(<span class=\"syntax13\">\"</span><span class=\"syntax13\">jboss_jaas</span><span class=\"syntax13\">\"</span>, handler);\n                        System.out.<span class=\"syntax6\">println</span>(<span class=\"syntax13\">\"</span><span class=\"syntax13\">Created</span><span class=\"syntax13\"> </span><span class=\"syntax13\">LoginContext</span><span class=\"syntax13\">\"</span>);\n                        loginContext.<span class=\"syntax6\">login</span>(); <span class=\"syntax2\">//</span><span class=\"syntax2\"> </span><span class=\"syntax2\">throws</span><span class=\"syntax2\"> </span><span class=\"syntax2\">LoginException</span>\n                        System.out.<span class=\"syntax6\">println</span>(<span class=\"syntax13\">\"</span><span class=\"syntax13\">Logged</span><span class=\"syntax13\"> </span><span class=\"syntax13\">in.</span><span class=\"syntax13\">\"</span>);\n                        loggedIn <span class=\"syntax18\">=</span> <span class=\"syntax14\">true</span>;\n                <span class=\"syntax18\">}</span> <span class=\"syntax8\">catch</span> (LoginException le) <span class=\"syntax18\">{</span>\n                        System.out.<span class=\"syntax6\">println</span>(<span class=\"syntax13\">\"</span><span class=\"syntax13\">Login</span><span class=\"syntax13\"> </span><span class=\"syntax13\">failed</span><span class=\"syntax13\">\"</span>);\n                        le.<span class=\"syntax6\">printStackTrace</span>();\n                <span class=\"syntax18\">}</span><br><br>                <span class=\"syntax2\">//</span><span class=\"syntax2\"> </span><span class=\"syntax2\">Create</span><span class=\"syntax2\"> </span><span class=\"syntax2\">&amp;</span><span class=\"syntax2\"> </span><span class=\"syntax2\">use</span><span class=\"syntax2\"> </span><span class=\"syntax2\">the</span><span class=\"syntax2\"> </span><span class=\"syntax2\">EJB:</span>\n                <span class=\"syntax8\">if</span> (loggedIn <span class=\"syntax18\">&amp;</span><span class=\"syntax18\">&amp;</span> queryEngineHome <span class=\"syntax18\">!</span><span class=\"syntax18\">=</span> <span class=\"syntax14\">null</span>) <span class=\"syntax18\">{</span>\n                        <span class=\"syntax8\">try</span> <span class=\"syntax18\">{</span>\n                                QueryEngineRemote queryEngine <span class=\"syntax18\">=</span> queryEngineHome.<span class=\"syntax6\">create</span>();\n                                System.out.<span class=\"syntax6\">println</span>(<span class=\"syntax13\">\"</span><span class=\"syntax13\">queryEngine</span><span class=\"syntax13\"> </span><span class=\"syntax13\">remote</span><span class=\"syntax13\"> </span><span class=\"syntax13\">created.</span><span class=\"syntax13\">\"</span>);\n                                <span class=\"syntax2\">//</span><span class=\"syntax2\"> </span><span class=\"syntax2\">TODO:</span><span class=\"syntax2\"> </span><span class=\"syntax2\">call</span><span class=\"syntax2\"> </span><span class=\"syntax2\">business</span><span class=\"syntax2\"> </span><span class=\"syntax2\">method(s)</span>\n                        <span class=\"syntax18\">}</span> <span class=\"syntax8\">catch</span> (RemoteException e1) <span class=\"syntax18\">{</span>\n                                e1.<span class=\"syntax6\">printStackTrace</span>();\n                        <span class=\"syntax18\">}</span> <span class=\"syntax8\">catch</span> (CreateException e1) <span class=\"syntax18\">{</span>\n                                e1.<span class=\"syntax6\">printStackTrace</span>();\n                        <span class=\"syntax18\">}</span>\n                <span class=\"syntax18\">}</span><br><br>                <span class=\"syntax2\">//</span><span class=\"syntax2\"> </span><span class=\"syntax2\">Log</span><span class=\"syntax2\"> </span><span class=\"syntax2\">out</span>\n                <span class=\"syntax8\">if</span> (loggedIn <span class=\"syntax18\">&amp;</span><span class=\"syntax18\">&amp;</span> loginContext <span class=\"syntax18\">!</span><span class=\"syntax18\">=</span> <span class=\"syntax14\">null</span>) <span class=\"syntax18\">{</span>\n                        <span class=\"syntax8\">try</span> <span class=\"syntax18\">{</span>\n                                loginContext.<span class=\"syntax6\">logout</span>();\n                        <span class=\"syntax18\">}</span> <span class=\"syntax8\">catch</span> (LoginException e) <span class=\"syntax18\">{</span>\n                                System.out.<span class=\"syntax6\">println</span>(<span class=\"syntax13\">\"</span><span class=\"syntax13\">Logout</span><span class=\"syntax13\"> </span><span class=\"syntax13\">failed:</span><span class=\"syntax13\">\"</span> <span class=\"syntax18\">+</span> e);\n                        <span class=\"syntax18\">}</span>\n                <span class=\"syntax18\">}</span><br><br>                System.out.<span class=\"syntax6\">println</span>(<span class=\"syntax13\">\"</span><span class=\"syntax13\">##</span><span class=\"syntax13\"> </span><span class=\"syntax13\">DONE!</span><span class=\"syntax13\"> </span><span class=\"syntax13\">##</span><span class=\"syntax13\">\"</span>);\n        <span class=\"syntax18\">}</span> <span class=\"syntax2\">//</span><span class=\"syntax2\"> </span><span class=\"syntax2\">main</span><br><br>        <span class=\"syntax3\">/**</span><span class=\"syntax3\"> </span><span class=\"syntax3\">Authentication</span><span class=\"syntax3\"> </span><span class=\"syntax3\">CallbackHandler</span><span class=\"syntax3\"> </span><span class=\"syntax3\">with</span><span class=\"syntax3\"> </span><span class=\"syntax3\">preset</span><span class=\"syntax3\"> </span><span class=\"syntax3\">username</span><span class=\"syntax3\">/</span><span class=\"syntax3\">password</span><span class=\"syntax3\">.</span><span class=\"syntax3\"> </span><span class=\"syntax3\">*/</span>\n        <span class=\"syntax8\">static</span> <span class=\"syntax10\">class</span> MyPresetCallbackHandler <span class=\"syntax8\">implements</span> CallbackHandler <span class=\"syntax18\">{</span>\n                String username;<br><br>                <span class=\"syntax10\">char</span>[] password;<br><br>                <span class=\"syntax8\">public</span> <span class=\"syntax6\">MyPresetCallbackHandler</span>(String username, String password) <span class=\"syntax18\">{</span>\n                        <span class=\"syntax14\">this</span>.username <span class=\"syntax18\">=</span> username;\n                        <span class=\"syntax14\">this</span>.password <span class=\"syntax18\">=</span> password.<span class=\"syntax6\">toCharArray</span>();\n                <span class=\"syntax18\">}</span><br><br>                <span class=\"syntax8\">public</span> <span class=\"syntax10\">void</span> <span class=\"syntax6\">handle</span>(Callback[] callbacks) <span class=\"syntax8\">throws</span> java.io.IOException,\n                                UnsupportedCallbackException <span class=\"syntax18\">{</span>\n                        <span class=\"syntax8\">for</span> (<span class=\"syntax10\">int</span> i <span class=\"syntax18\">=</span> <span class=\"syntax5\">0</span>; i <span class=\"syntax18\">&lt;</span> callbacks.length; i<span class=\"syntax18\">+</span><span class=\"syntax18\">+</span>) <span class=\"syntax18\">{</span>\n                                Callback callback <span class=\"syntax18\">=</span> callbacks[i];\n                                <span class=\"syntax8\">if</span> (callback <span class=\"syntax8\">instanceof</span> NameCallback) <span class=\"syntax18\">{</span>\n                                        ((NameCallback) callback).<span class=\"syntax6\">setName</span>(username);\n                                <span class=\"syntax18\">}</span> <span class=\"syntax8\">else</span> <span class=\"syntax8\">if</span> (callback <span class=\"syntax8\">instanceof</span> PasswordCallback) <span class=\"syntax18\">{</span>\n                                        ((PasswordCallback) callback).<span class=\"syntax6\">setPassword</span>(password);\n                                <span class=\"syntax18\">}</span> <span class=\"syntax8\">else</span> <span class=\"syntax18\">{</span>\n                                        <span class=\"syntax8\">throw</span> <span class=\"syntax8\">new</span> <span class=\"syntax6\">UnsupportedCallbackException</span>(callback,\n                                                        <span class=\"syntax13\">\"</span><span class=\"syntax13\">Unrecognized</span><span class=\"syntax13\"> </span><span class=\"syntax13\">Callback</span><span class=\"syntax13\">\"</span>);\n                                <span class=\"syntax18\">}</span>\n                        <span class=\"syntax18\">}</span>\n                <span class=\"syntax18\">}</span><span class=\"syntax2\">//</span><span class=\"syntax2\"> </span><span class=\"syntax2\">handle</span><span class=\"syntax2\"> </span>\n        <span class=\"syntax18\">}</span><span class=\"syntax2\">//</span><span class=\"syntax2\"> </span><span class=\"syntax2\">MyPresetCallbackHandler</span>\n<span class=\"syntax18\">}</span><br><br></pre>\n<p>\nSee <a href=\"http://jroller.com/resources/h/holy/EjbLocator.java\">EjbLocator.java</a>\nand <a href=\"http://jroller.com/resources/h/holy/EjbLocatorException.java\">EjbLocatorException.java</a>.\nWith them, you can replace all above with <code>QueryEngineRemote queryEngine = (QueryEngineRemote) EjbLocator.getInstance().locate( QueryEngineRemoteHome.JNDI_NAME );</code></p>",
  "excerpt": ""
 },
 {
  "title": "Most interesting links of May",
  "published": "2010-06-02 13:17:26",
  "postType": "post",
  "slug": "/2010/06/02/most-interesting-links-of-may/",
  "status": "publish",
  "tags": [
   "Git",
   "java",
   "monitoring",
   "nosql",
   "performance"
  ],
  "categories": [
   "General",
   "Languages",
   "Top links of month"
  ],
  "content": "The most interesting stuff I've read in May, in no particular order. You can easily guess I've been working on performance troubleshooting this month :-)\r\n<ul>\r\n\t<li><a href=\"http://blog.couch.io/post/511008668/nosql-is-about\">NoSQL is About…</a> - all the things NoSql databases are said to be about (and perhaps are not) and a good overview of the different goals and thus also features of the various implementations</li>\r\n\t<li><a href=\"http://aext.net/2010/05/mind-mapping-overview-benefits-tips-and-tools/\">Bulletproof of Mind Mapping: Overview, Benefits, Tips and Tools</a> - the article not only introduces mind maps (a structured way of recording ideas, much less limited than lists) but also describes over 30 desktop and web-based MM tools, both free and commercial (some of the descriptions come from the SW's web, some from the author - the distinction isn't clear)</li>\r\n\t<li><a href=\"http://www.azulsystems.com/blog/cliff-click/2009-09-06-java-vs-c-performanceagain\">Java vs. C Performance....Again.</a> (9/2009) - When C(++) is better than Java, when Java is more appropriate, and common flaws in comparions methodologies/false arguments.</li>\r\n\t<li><a href=\"http://reprog.wordpress.com/2010/05/12/still-hatin-on-git-now-with-added-actual-reasons/\">Why Learning Git is really, really hard part 1</a> and <a href=\"http://www.dzone.com/links/still_hatin_on_git_now_with_added_actual_reasons.html\">part 2 with actual reasons</a> - because it doesn't care enough for usability (unusual commands, cryptic error messages, impossibly to go to a \"simpler use mode\"). I'm intrigued by distributed SCM systems and tired of not-so-easy branching &amp; merging in SVN and its lovely problems with corrupted metadata (when you delete a folder...) and thus I was considering switching to Git that <a href=\"https://bugs.eclipse.org/bugs/show_bug.cgi?id=249745#c25.\">everybody is so excited about</a>. I still plan that but these articles warned me that it may be not so painless and easy. A good read.</li>\r\n\t<li><a href=\"http://java.sun.com/community/javavisualvm/\">Java VisualVM Blogging Contest results</a> - the best posts -\r\n<ul>\r\n\t<li>VisualVM - tool for profiling Java applications - nice, short intro with many pictures</li>\r\n\t<li>Analyzing Memory Leak in Java Applications using VisualVM</li>\r\n\t<li>(and others ... )</li>\r\n</ul>\r\n</li>\r\n\t<li><a href=\"http://www.johndcook.com/standard_deviation.html\">How to compute running mean/standard deviation</a> -  this page explains and in C implements an algorithm for computing a running estimate of mean and standard deviation, which minimizes accumulation of precision errors. A running estimation has the advantage that you do not need to store all the numbers and is thus suitable e.g. for continuous performance monitoring with a low memory overhead (buth the performance overhead of a division and multiplication it introduces is perhaps also something to consider - though for most application it's negligible)</li>\r\n\t<li>(Java) <a href=\"http://www.dzone.com/links/r/web_performance_in_seven_steps_2.html\">Web performance in seven steps</a> - a great article about the \"management of performance\" of a Web/JEE application from the definition of performance requirements up to continual performance monitoring with interesting war stories and links to various useful tools. I can sign the author's maxim \"measure, don't guess!\". The Java monitoring API <a href=\"http://code.google.com/p/javasimon/\">Java Simon</a> mentioned in the article is worth a look.</li>\r\n</ul>",
  "excerpt": ""
 },
 {
  "title": "Measure, don''t guess: A performance optimization war story",
  "published": "0000-00-00 00:00:00",
  "postType": "post",
  "slug": "/301",
  "status": "draft",
  "tags": [
   "java",
   "optimization",
   "performance"
  ],
  "categories": [
   "Languages"
  ],
  "content": "\"Measure, don't guess!\" is the golden rule of performance optimization and I'd like to share with you a real-world experience of mine that completely supports it. Read on to learn what tools and methods I applied to pinpoint the bottlenecks of a really slow batch job, transferring hundreds of thousands of records between two enterprise systems, and what surprises awaited me.<br><br><!--more-->\n<h2>Setting the scene: An incredibly slow batch job</h2>\n<a href=\"http://www.ibacz.eu/-English-\">Our</a> customer, a huge, global company, needs to synchronize employee data between its enterprise directory (LDAP) and a J2EE application. The directory has over 500,000 records and the synchronization batch job normally runs in a \"delta mode\", fetching only changes since the last run - but if it doesn't run for a few hours or even days, the number of changes can easily grow to tens or even hundreds of thousands. Transferring 100k records may take 2-4 days (and everybody prays for the job not to crash). Admittedly the job is poorly written (regarding its performance, monitoring capabilities and flexibility) and communication means are rather suboptimal as well.<br><br>The batch job works like this:\n<ol>\n\t<li>It looks up IDs of all the records to process in the LDAP server</li>\n\t<li>For each ID:\n<ol>\n\t<li>It fetches the record (employee) details and related entities (work location, department) from the LDAP server</li>\n\t<li>It performs some mapping and transformation magic</li>\n\t<li>When enough records aggregate, they're submitted in a batch to the target system via a web service call</li>\n\t<li>The web service uses J2EE 1.4 EJBs of the target application to update the employee data</li>\n</ol>\n</li>\n</ol>\nNot only is the job slow in itself but also it happens a couple of times per day that either the source or target systems are unresponsive and the job has to wait for 10 or 20 minutes to retry its request.\n<h2>Step 1: Guessing</h2>\n<ul>\n\t<li>WS overhead</li>\n\t<li>slow API for updates</li>\n\t<li>make asynchr. =&gt; not blocked by both end systems</li>\n</ul>\n// another feed: 80k records in few minutes (DB -&gt; DB)\n<h2>Step 2: Profiling</h2>\n<h2>Step 3: Monitoring</h2>\n<h2>Summing up the results</h2>\n<h2>Conclusion</h2>\n// Spring Batch",
  "excerpt": ""
 },
 {
  "title": "Webservice testing with JMeter: Passing data from a response to another request",
  "published": "2010-06-04 15:37:09",
  "postType": "post",
  "slug": "/2010/06/04/webservice-testing-with-jmeter-passing-data-from-a-response-to-another-request/",
  "status": "publish",
  "tags": [
   "java",
   "jmeter",
   "Testing",
   "webservice"
  ],
  "categories": [
   "Languages",
   "Testing"
  ],
  "content": "<a href=\"http://jakarta.apache.org/jmeter/\">JMeter</a> is great for functional and performance testing of many things, including web services (and to my surprise also LDAP). It also provides means for extracting data from a response and passing them to a subsequent request, which is exactly what I needed. There is already a good <a href=\"http://www.testingminded.com/2009/01/tutorial-on-testing-webservices-with.html\">tutorial on testing a WS with JMeter</a>, so I won't repeat the basic setup here. The steps are:\r\n<ol>\r\n\t<li>Create a webservice (WS) test plan, as described in the tutorial (in my case it contains two WS calls)</li>\r\n\t<li>Add the User Defined Variables config element to the test plan and define there a variable for transferring the response data</li>\r\n\t<li>Add an XPath Extractor Post Processor to the first WS call to extract the value of interest into the user defined variable (beware namespaces!)</li>\r\n\t<li>Add a BeanShell Pre Processor to the second call, which will replace a placeholder in the WS call's XML data with the value of that variable</li>\r\n</ol>\r\n<h2><!--more--></h2>\r\n<h2>About the webservice</h2>\r\nI needed to test a web service, which requires its client to call first its authenticate method, which returns an authentication token called 'certificate', which is then used in subsequent requests.\r\n<h2>A basic implementation</h2>\r\n<h3>0. Setup</h3>\r\nDownload <a href=\"http://trixes.net/pub/jakarta/jmeter/binaries/jakarta-jmeter-2.3.4.zip\">JMeter 2.3.4</a> and two dependencies, Java Mail API (<a href=\"http://java.sun.com/products/javamail/downloads/index.html\">mail.jar</a>) and JavaBeans Activation Framework (<a href=\"http://java.sun.com/javase/technologies/desktop/javabeans/jaf/downloads/index.html\">activation.jar</a>), necessary for the JMeter's webservice sampler. Put the JARs in JMeter's lib/ folder.\r\n<h3>1. Create a webservice (WS) test plan, as described in the tutorial (in my case it contains two WS calls)</h3>\r\nWell, <a href=\"http://www.testingminded.com/2009/01/tutorial-on-testing-webservices-with.html\">follow the utorial</a> :-). Then duplicate the webservice call sampler, call the first one <em>WS: Authenticate with Saba</em> and the other one <em>WS: PF - Update employees</em>.\r\n<h3>2. Add the User Defined Variables config element to the test plan and define there a variable for transferring the response data</h3>\r\nWe will need a variable to hold the data that we want to transfer from the 1st response to subsequent request. Therefore open the test plan, right-click on Thread Group &gt; Add &gt; Config Element &gt; User Defined Variables. Add there  a variable named <em>sabaCertificate</em>. You can leave its Value empty.\r\n<h3>3. Add an XPath Extractor Post Processor to the first WS call to extract the value of interest into the user defined variable</h3>\r\nNow we will extract the \"certificate\" data from the first response. The response may look like this (I used Eclipse' TCP Monitor to capture the SOAP communication):<br><br><pre><code>\r\n&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;\r\n&lt;soapenv:Envelope xmlns:soapenv=&quot;http://schemas.xmlsoap.org/soap/envelope/&quot; xmlns:xsd=&quot;http://www.w3.org/2001/XMLSchema&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;&gt;\r\n &lt;soapenv:Body&gt;\r\n \t&lt;saba:certificate xmlns:saba=&quot;http://www.saba.com/xml/infoservices&quot;&gt;31323930326436636637635&lt;/saba:certificate&gt;\r\n &lt;/soapenv:Body&gt;\r\n&lt;/soapenv:Envelope&gt;\r\n</code></pre><br><br>To extract the value of the element &lt;saba:certificate&gt;:\r\n<ol>\r\n\t<li>Right-click on the first WS call (<em>WS: Authenticate with Saba</em>) and Add &gt; Post Processors &gt; <a href=\"http://jakarta.apache.org/jmeter/usermanual/component_reference.html#XPath_Extractor\">XPath Extractor</a></li>\r\n\t<li>For the Reference Name, type sabaCertificate (the user variable we've created earlier)</li>\r\n\t<li>For the XPath query, type <em>//*[local-name()='certificate']/text()</em>\r\n<ul>\r\n\t<li>Problem with namespaces: Beware that JMeter 2.3.4 supports only namespaces declared on the root element and thus the XPath query <em>//saba:certificate</em> wouldn't work. The documentation for XPath Extractor's attribute \"Use Namespace?\" provides a workaround based on using the functions local-name() and namespace-uri() to match the local tag name and the URI associated with its namespace, which I've partly used.</li>\r\n\t<li>You can test your XPath for example in the <a href=\"http://www.mizar.dk/XPath/Default.aspx\">Allans Online XPath Tester</a></li>\r\n</ul>\r\n</li>\r\n</ol>\r\n<h3>4. Add a BeanShell Pre Processor to the second call, which will replace a placeholder in the WS call's XML data with the value of that variable</h3>\r\nNow we need to get the \"certificate\" into the subsequent web service request. I have put the placeholder \"#sabaCertificate#\" into the SOPA request, at the place where the actual authentication token shall be. Now we will arrange for its replacement with the actual value:\r\n<ol>\r\n\t<li>Right-click on the second WS call (<em>WS: PF - Update employees</em>) and Add &gt; Pre Processors &gt; <a href=\"http://jakarta.apache.org/jmeter/usermanual/component_reference.html#BeanShell_PreProcessor\">BeanShell PreProcessor</a> (<a href=\"http://www.beanshell.org/\">BeanShell</a> is a scripting language with Java syntax and is included in JMeter)</li>\r\n\t<li>Type in the following script (notice that <em>sampler</em> is a variable provided by JMeter and refers to the parent WS call; check JavaDoc for details on the <a href=\"http://jakarta.apache.org/jmeter/api/org/apache/jmeter/protocol/http/sampler/WebServiceSampler.html\">WebServiceSampler</a>):</li>\r\n</ol>\r\n<h4>Case 1: SOAP request specified directly in the attribute Soap/XML-RPC Data</h4>\r\n<pre><code>\r\nimport org.apache.jmeter.protocol.http.sampler.WebServiceSampler;\r\nWebServiceSampler wsSampler = (WebServiceSampler) sampler;\r\nString requestWithCertif = wsSampler.getXmlData().replaceFirst(&quot;#sabaCertificate#&quot;, vars.get(&quot;sabaCertificate&quot;));\r\nwsSampler.setXmlData(requestWithCertif);\r\n</code></pre>\r\n<h4>Case 2: The SOAP request is read from a file (attribute File with SOAP XML Data)</h4>\r\nIf the request data is read from a file then it's a bit more complex because we need to load its content.<br><br><pre><code>\r\nimport org.apache.jmeter.protocol.http.sampler.WebServiceSampler;\r\nimport java.io.*;<br><br>WebServiceSampler wsSampler = (WebServiceSampler) sampler;<br><br>BufferedReader xmlReader = new BufferedReader( new InputStreamReader(\r\n\tnew FileInputStream(wsSampler.getXmlFile())\r\n\t, java.nio.charset.Charset.forName(&quot;UTF-8&quot;)\r\n));<br><br>StringBuffer xmlData = new StringBuffer();<br><br>String line;\r\nwhile( (line = xmlReader.readLine()) != null) { xmlData.append(line).append('\\n'); }<br><br>String requestWithCertif = xmlData.toString().replaceFirst(&quot;#sabaCertificate#&quot;, vars.get(&quot;sabaCertificate&quot;));<br><br>wsSampler.setXmlData(requestWithCertif);\r\nwsSampler.setXmlFile(&quot;&quot;) ; // a file would override the data<br><br>// print(&quot;XML set: &quot; + requestWithCertif); // print to the console JMeter was started from\r\n</code></pre><br><br>Well, that's it!\r\n<h2>Going advanced: Reading requests from several files</h2>\r\nThe approach descibed above makes it possible to send a request based on a single file. But what if we want to send a different data with each repetition of the test, e.g. to negate effects of caching? Well, there is a couple of ways to achieve that. I've chosen the most flexible one, though absolutely not the easiest one to implement.<br><br>The trick is:\r\n<ol>\r\n\t<li>Create a <a href=\"http://jakarta.apache.org/jmeter/usermanual/component_reference.html#BeanShell_Sampler\">BeanShell Sampler</a>. The sampler will list all files in a particular directory and store their paths into a numbered variables (G_updateEmployeesWsRequestFile_1 etc., must start with 1), which will be then used by a ForEach Controller.</li>\r\n\t<li>Put all the test elements from the basic test plan under a <a href=\"http://jakarta.apache.org/jmeter/usermanual/component_reference.html#ForEach_Controller\">ForEach Controller</a> , which follows the BeanShell Sampler. Configure it to use the variables generated by the BeanShell Sampler and store the current file name in the variable G_updateEmployeesWsRequestFile.</li>\r\n\t<li>In the webservice request element, replace the content of the Filename field with a reference to that variable: ${G_updateEmployeesWsRequestFile}</li>\r\n</ol>\r\n<h3>The BeanShell Sampler \"<em>Generate WS request file names</em>\"</h3>\r\n<pre><code>\r\nimport java.io.*;<br><br>print(&quot;Generating files...&quot;);\r\nlog.info(&quot;BeanShell Sampler: Generating request file names...&quot;);<br><br>File requestsDir = new File(&quot;/tmp/wsRequests&quot;);\r\nString[] requestFiles = requestsDir.list();<br><br>for(int i=0; i&lt;requestFiles.length; ++i) {\r\n\tString varName = &quot;G_updateEmployeesWsRequestFile_&quot; + (i+1);\r\n\tvars.put(\r\n\t\tvarName\r\n\t\t, requestsDir.getAbsolutePath()  + File.separatorChar  + requestFiles[i]\r\n\t);\r\n\t// print(&quot;var created: &quot; + varName + &quot;=&quot; + vars.get(varName));\r\n}<br><br>log.info(&quot;BeanShell Sampler: FINISHED generating request file names from dir &quot; +\r\n\trequestsDir + &quot;; files are: &quot; + java.util.Arrays.asList(requestFiles));<br><br>return &quot;soap input files generated&quot;;\r\n</code></pre>\r\n<h3>The ForEach Controller \"<em>ForEach request file</em>\"</h3>\r\nThe controller's configuration is simple:\r\n<ul>\r\n\t<li>Input variable prefix: G_updateEmployeesWsRequestFile</li>\r\n\t<li>Output variable name: G_updateEmployeesWsRequestFile</li>\r\n\t<li>Add \"_\" before before number: [x] (checked)</li>\r\n</ul>\r\n<h3>Summary</h3>\r\nWe've parametrized the test by a set of files with SOAP requests that are read from a folder and supplied sequentially to the test thanks to the ForEach Controller.\r\n<h2>Resources</h2>\r\n<ul>\r\n\t<li>The <a href=\"http://blog.jakubholy.net/prilohy/04062010-jmeter-ws_testing.jmx\">final Basic JMeter Test Plan</a></li>\r\n\t<li>The <a href=\"http://blog.jakubholy.net/prilohy/04062010-jmeter-multiRequestFiles.jmx\">Advanced JMeter Test Plan</a> (SOAP requests read from files in a folder)</li>\r\n</ul>",
  "excerpt": ""
 },
 {
  "title": "Booting from a USB stick in VMware Player",
  "published": "2010-06-10 14:06:22",
  "postType": "post",
  "slug": "/2010/06/10/booting-from-a-usb-stick-in-vmware-player/",
  "status": "publish",
  "tags": [
   "boot",
   "usb",
   "vmware"
  ],
  "categories": [
   "General"
  ],
  "content": "It isn't possible to boot from a USB stick under VMware player 3.0.0, because its BIOS is ignorant of USB, but fortunately there is an easy workaround:\r\n<ol>\r\n\t<li>Download the <a href=\"http://www.plop.at/en/bootmanagerdl.html\">PLoP boot manager</a> (e.g. <a href=\"http://download.plop.at/files/bootmngr/plpbt-5.0.10.zip\" target=\"_blank\">plpbt-5.0.10.zip</a>), which supports <a href=\"http://www.plop.at/en/bootmanager.html#usbinfo\">usb booting</a></li>\r\n\t<li>Decide whether you want to install PLoP to the virtual hard disk (useful if you will boot from the USB stick more often) or not\r\n<ol>\r\n\t<li>Using PLoP without installing it to the virtual disk:\r\n<ol>\r\n\t<li>Extract the ISO image <em>plpbt-5.0.10/plpbt.iso</em> from the archive</li>\r\n\t<li>Attach the extraced ISO image to you VMware virtual machine as a CD/DVD</li>\r\n\t<li>Boot the vmware machine from this virtual CD. (VMware should automatically try it as a boot device, if not, press Esc at the virtual machine start to enter the boot device selection menu).</li>\r\n\t<li>PLoP will be started, ses below.</li>\r\n</ol>\r\n</li>\r\n\t<li>Installing PLoP to the virtual disk (you may want to check the <a href=\"http://www.plop.at/en/bootmanager.html#installhd\">PLoP installation guide</a>):\r\n<ol>\r\n\t<li>Extract the ISO image <em>plpbt-5.0.10/install/plpbtin.iso</em> from the archive</li>\r\n\t<li>Attach the extraced ISO image to you VMware virtual machine as a CD/DVD</li>\r\n\t<li>Boot the vmware machine from this virtual CD. (VMware should automatically try it as a boot device, if not, press Esc at the virtual machine start to enter the boot device selection menu).</li>\r\n\t<li>PLoP installation menu will show up, press 1 to select the option \"Full boot manager install\" and answer \"y\" to the question whether you want to proceed</li>\r\n\t<li>When the installation finishes, power off the virtual machine</li>\r\n\t<li>Remove the CD/DVD device from the virtual machine, we won't need it anymore</li>\r\n\t<li>Start the virtual machine, which will boot PLoP from the virtual hard disk.</li>\r\n</ol>\r\n</li>\r\n</ol>\r\n</li>\r\n\t<li>Once PLoP is started, it will give you a selection of devices to boot from including your USB stick. (Make sure that the USB stick is connected to the virtual machine, if not, connect it and restart the machine via the menu VM - Power - Reset).</li>\r\n</ol>\r\nPS: You can do the same for VirtualBox, which also doesn't support booting from USB.",
  "excerpt": ""
 },
 {
  "title": "Implementing build-time bytecode instrumentation with Javassist",
  "published": "2010-06-24 22:05:05",
  "postType": "post",
  "slug": "/2010/06/25/implementing-build-time-instrumentation-with-javassist/",
  "status": "publish",
  "tags": [
   "ant",
   "AOP",
   "java",
   "Javassist"
  ],
  "categories": [
   "Languages"
  ],
  "content": "If you need to modify the code in class files at the (post-)build time without adding any third-party dependencies, for example to inject cross-cutting concerns such as logging, and you don't wan't to deal with the low-level byte code details, Javassist is the right tool for you. I've already blogged about \"<a title=\"Permanent link to Injecting better logging into a  binary .class using Javassist\" rel=\"bookmark\" href=\"../2008/10/02/injecting-better-logging-into-a-bi/\">Injecting better logging into a binary  .class using Javassist</a>\" and today I shall elaborate on the instrumentation capabilities of Javassist and its integration into the build process using a custom Ant task.<br><br><!--more-->\r\n<h2>Terminology</h2>\r\n<ul>\r\n\t<li>Instrumentation - adding code to existing .class files</li>\r\n\t<li>Weaving - instrumentation of physical files, i.e. applying advices to class files</li>\r\n\t<li>Advice - the code that is \"injected\" to a class file; usually we distinguish a \"before\", \"after\", and 'around\" advice based on how it applies to a method</li>\r\n\t<li>Pointcut - specifies where to apply an advice (e.g. a fully qualified class + method name or a pattern the AOP tool understands)</li>\r\n\t<li>Injection - the \"logical\" act of adding code to an existing class by an external tool</li>\r\n\t<li>AOP - <a href=\"http://en.wikipedia.org/wiki/Aspect-oriented_programming\">aspect oriented programming</a></li>\r\n</ul>\r\n<h2>Javassist versus AspectJ</h2>\r\nWhy should you use Javassit over a classical AOP tool like AspectJ? Well, normally you wouldn't because AspectJ is easier to use, less error-prone, and much more powerful. But there are cases when you cannot use it, for example you need to modify bytecode but cannot afford to add any external dependencies. Consider the following when deciding between them:<br><br>Javassist:\r\n<ul>\r\n\t<li>Only basic (but often sufficient) instrumentation capabilities</li>\r\n\t<li>Build-time only - modifies .class files</li>\r\n\t<li>The modified code has no additional dependencies (except those you add), i.e. you don't need the javassist.jar at the run-time</li>\r\n\t<li>Easy to use but not as easy as AspectJ; the code to be injected is handled over as a string, which is compiled to bytecode by Javassist</li>\r\n</ul>\r\nAspectJ:\r\n<ul>\r\n\t<li>Very powerful</li>\r\n\t<li>Both build-time and load-time (when class gets loaded by the JVM) weaving (instrumentation) supported</li>\r\n\t<li>The modified code depends on the AspectJ runtime library (advices extend its base class, special objects used to provide access to the runtime information such as method parameters)</li>\r\n\t<li>It's use is no different from normal Java programming, especially if you use the annotation-based syntax (@Pointcut, @Around etc.). Advices are compiled before use and thus checked by the compiler</li>\r\n</ul>\r\nClassical bytecode manipulation library:\r\n<ul>\r\n\t<li>Too low-level, you need to define and add bytecode instructions, while Javassist permits you to add pieces of Java code</li>\r\n</ul>\r\n<h2>Instrumenting with Javassist</h2>\r\nAbout some of the basic changes you can do with Javassist. This by no means an exhaustive list.\r\n<h3>Declaring a local variable for passing data from a before to an after advice</h3>\r\nIf you need to pass some data from a before advice to an after advice, you cannot create a new local variable in the code passed to Javassist (e.g. \"int myVar = 5;\"). Instead of that, you must declare it via CtMethod.addLocalVariable(String name, CtClass type) and then you can use is in the code, both in before and after advices of the method.<br><br>Example:<br><br><pre><code><br><br>final CtMethod method = ...;\r\nmethod.addLocalVariable(&quot;startMs&quot;, CtClass.longType);\r\n method.insertBefore(&quot;startMs = System.currentTimeMillis();&quot;);\r\n method.insertAfter(&quot;{final long endMs = System.currentTimeMillis();&quot; +\r\n&quot;System.out.println(\\&quot;Executed in ms: \\&quot; + (endMs-startMs));}&quot;);<br><br></code></pre>\r\n<h3>Instrumenting a method execution</h3>\r\nAdding a code at the very beginning or very end of a method:<br><br><pre><code>\r\n// Advice my.example.TargetClass.myMethod(..) with a before and after advices\r\nfinal ClassPool pool = ClassPool.getDefault();\r\nfinal CtClass compiledClass = pool.get(&quot;my.example.TargetClass&quot;);\r\nfinal CtMethod method = compiledClass.getDeclaredMethod(&quot;myMethod&quot;);<br><br> method.addLocalVariable(&quot;startMs&quot;, CtClass.longType);\r\n method.insertBefore(&quot;startMs = System.currentTimeMillis();&quot;);\r\n method.insertAfter(&quot;{final long endMs = System.currentTimeMillis();&quot; +\r\n   &quot;System.out.println(\\&quot;Executed in ms: \\&quot; + (endMs-startMs));}&quot;);<br><br>compiledClass.writeFile(&quot;/tmp/modifiedClassesFolder&quot;);\r\n// Enjoy the new /tmp/modifiedClassesFolder/my/example/TargetClass.class<br><br></code></pre><br><br>There is also <em>CtMethod.insertAfter(String code, boolean asFinally)</em> - JavaDoc: if asFinally \"is true then the inserted bytecode is executed not only when the control normally returns but also when an exception is thrown. If this parameter is true, the inserted code cannot access local variables.\"<br><br>Notice that you always pass the code as either a single statement, as in \"System.out.println(\\\"Hi from injected!\\\");\" or as a <em>block</em> of statements, enclosed by \"{\" and \"}\".\r\n<h3>Instrumenting a method call</h3>\r\nSometimes you cannot modify a method itself, for example because it's a system class. In that case you can instrument all calls to that method, that appear in your code. For that you need a custom ExprEditor subclass, which is a Visitor whose methods are called for individual statements (such as method calls, or instantiation with a new) in a method. You would then invoke it on all classes/methods that may call the method of interest.<br><br>In the following example, we add performance monitoring to all calls to javax.naming.NamingEnumeration.next():<br><br><pre><code>\r\nfinal CtClass compiledClass = pool.get(&quot;my.example.TargetClass&quot;);\r\nfinal CtMethod[] targetMethods = compiledClass.getDeclaredMethods();\r\nfor (int i = 0; i &lt; targetMethods.length; i++) {\r\n  targetMethods[i].instrument(new ExprEditor() {\r\n    public void edit(final MethodCall m) throws CannotCompileException {\r\n      if (&quot;javax.naming.NamingEnumeration&quot;.equals(m.getClassName()) &amp;&amp; &quot;next&quot;.equals(m.getMethodName())) {\r\n        m.replace(&quot;{long startMs = System.currentTimeMillis(); &quot; +\r\n            &quot;$_ = $proceed($$); &quot; +\r\n            &quot;long endMs = System.currentTimeMillis();&quot; +\r\n            &quot;System.out.println(\\&quot;Executed in ms: \\&quot; + (endMs-startMs));}&quot;);\r\n      }\r\n    }\r\n  });\r\n}\r\n</code></pre><br><br>The call to the method of interest is replaced with another code, which also performs the original call via the special statement \"$_ = $proceed($$);\".<br><br>Beware: What matters is the declared type on which the method is invoked, which can be an interface, as in this example, the actual implementation isn't important. This is opposite to the method execution instrumentation, where you always instrument a concrete type.<br><br>The problem with instrumenting calls is that you need to know all the classes that (may) include them and thus need to be processed. There is no official way of listing all classes [perhaps matching a pattern] that are visible to the JVM, though ther're are some <a href=\"http://www.nakov.com/blog/wp-content/uploads/2008/08/classscopejava.html\">workarounds</a> (accessing the Sun's ClassLoader.classes private property). The best way is thus - aside of listing them manually - to add the folder or JAR with classes to Javassist ClassPool's internal classpath (see below) and then scan the folder/JAR for all .class files, converting their names into class names. Something like:<br><br><pre><code>\r\n// Groovy code; the method instrumentCallsIn would perform the code above:\r\npool.appendClassPath(&quot;/path/to/a/folder&quot;);\r\nnew File(&quot;/path/to/a/folder&quot;).eachFileRecurse(FileType.FILES) {\r\n file -&gt; instrumentCallsIn( pool.get(file.getAbsolutePath().replace(&quot;\\.class$&quot;,&quot;&quot;).replace('/','.')) );}\r\n</code></pre>\r\n<h3>Javassist and class-path configuration</h3>\r\nYou certainly wonder how does Javassist find the classes to modify. Javassist is actually extremely flexible in this regard. You obtain a class by calling<br><br><pre><code>\r\nprivate final ClassPool pool = ClassPool.getDefault();\r\n...\r\nfinal CtClass targetClass = pool.get(&quot;target.class.ClassName&quot;);\r\n</code></pre><br><br>The ClassPool can search a number of places, that are added to its internal class path via the simple call<br><br><pre><code>\r\n/* ClassPath newCP = */ pool.appendClassPath(&quot;/path/to/a/folder/OR/jar/OR/(jarFolder/*)&quot;);\r\n</code></pre><br><br>The supported class path sources are clear from the available implementations of  ClassPath: there is a ByteArrayClassPath, ClassClassPath, DirClassPath, JarClassPath, JarDirClassPath (used if the path ends with \"/*\"), LoaderClassPath, URLClassPath.<br><br>The important thing is that the class to be modified  or any class used in the code that you inject into it doesn't need to be on the JVM classpath, it only needs to be on the pool's class path.\r\n<h2>Implementing mini-AOP with Javassist and Ant using a custom task</h2>\r\nThis part briefly describes how to instrument classes with Javassist via a custom Ant task, which can be easily integrated into a build process.<br><br>The corresponding part of the build.xml is:<br><br><pre><code>\r\n&lt;target name=&quot;declareCustomTasks&quot; depends=&quot;compile&quot;&gt;\r\n   &lt;mkdir dir=&quot;${antbuild.dir}&quot;/&gt;<br><br>   &lt;!-- Javac classpath contains javassist.jar, ant.jar --&gt;\r\n   &lt;javac srcdir=&quot;${antsrc.dir}&quot; destdir=&quot;${antbuild.dir}&quot; encoding=&quot;${encoding}&quot; source=&quot;1.4&quot; classpathref=&quot;monitoringInjectorTask.classpath&quot; debug=&quot;true&quot; /&gt;<br><br> &lt;taskdef name=&quot;javassistinject&quot; classname=&quot;example.JavassistInjectTask&quot;\r\n   classpathref=&quot;monitoringInjectorTask.classpath&quot; loaderref=&quot;javassistinject&quot;/&gt;\r\n &lt;typedef name=&quot;call&quot; classname=&quot;example.JavassistInjectTask$MethodDescriptor&quot;\r\n   classpathref=&quot;monitoringInjectorTask.classpath&quot; loaderref=&quot;javassistinject&quot;/&gt;\r\n &lt;typedef name=&quot;execution&quot; classname=&quot;example.JavassistInjectTask$MethodDescriptor&quot;\r\n   classpathref=&quot;monitoringInjectorTask.classpath&quot; loaderref=&quot;javassistinject&quot;/&gt;\r\n &lt;/target&gt;<br><br> &lt;target name=&quot;injectMonitoring&quot; depends=&quot;compile,declareCustomTasks&quot; description=&quot;Process the compiled classes and inject calls to the performance monitoring API to some of them (currently hardcoded in PerfmonAopInjector)&quot;&gt;<br><br>  &lt;javassistinject outputFolder=&quot;${classes.dir}&quot; logLevel=&quot;info&quot;&gt;\r\n    &lt;fileset dir=&quot;${classes.dir}&quot; includes=&quot;**/*.class&quot;&gt;\r\n    &lt;!-- method executions to inject with performance monitoring --&gt;\r\n    &lt;execution name=&quot;someSlowMethod&quot; type=&quot;my.MyClass&quot; /&gt;\r\n    &lt;!-- method calls to inject with performance monitoring --&gt;\r\n    &lt;call name=&quot;search&quot; type=&quot;javax.naming.directory.InitialDirContext&quot; metric=&quot;ldap&quot; /&gt;\r\n    &lt;call name=&quot;next&quot; type=&quot;javax.naming.NamingEnumeration&quot; metric=&quot;ldap&quot; /&gt;\r\n    &lt;call name=&quot;hasMore&quot; type=&quot;javax.naming.NamingEnumeration&quot; metric=&quot;ldap&quot; /&gt;\r\n  &lt;/javassistinject&gt;<br><br> &lt;/target&gt;\r\n</code></pre><br><br>Noteworthy:\r\n<ul>\r\n\t<li>I've implemented a simple custom Ant task with the class example.JavassistInjectTask, extending org.apache.tools.ant.Task (see the code below). It has setters for attributes and nested elements and uses the custom class PerfmonAopInjector (not shown) to perform the actual instrumentation via Javassist API. Attributes/nested elements:\r\n<ul>\r\n\t<li>setLoglevel(EchoLevel level) - see the EchoTask</li>\r\n\t<li>setOutputFolder(File out)</li>\r\n\t<li>addConfiguredCall(MethodDescriptor call)</li>\r\n\t<li>addConfiguredExecution(MethodDescriptor exec)</li>\r\n\t<li>addFileset(FileSet fs) - use fs.getDirectoryScanner(super.getProject()).getIncludedFiles() to get the names of the files under the dir</li>\r\n</ul>\r\n</li>\r\n\t<li>MethodDescriptor is a POJO with a no-arg public constructor and setters for its attributes (name, type, metric), which is introduced to Ant via &lt;typedef&gt; and its instances are passed to the JavassistInjectTask by Ant using its addConfigured&lt;name&gt;, where the name equlas the element's name, i.e. the name specified in the typedef</li>\r\n\t<li>PerfmonAopInjector is another POJO that uses Javassist to inject execution time logging to method executions and calls as shown in the previous section, applying it to the classes/methods supplied by the JavassistInjectTask based on its &lt;call .. /&gt; and &lt;execution ... /&gt; configuration</li>\r\n\t<li>The fileset element is used both to tell Javassist in what directory it should look for classes and to find out the classes that may contain calls that should be instrumented (listing all the .class files and converting their names to class names)</li>\r\n\t<li>All the typedefs use the same ClassLoader instance so that the classes can see each other, this is ensured by <code>loaderref=\"javassistinject\"</code> (its value is a custom identifier, same for all three)</li>\r\n\t<li>The monitoringInjectorTask.classpath contains javassist.jar, ant.jar, JavassistInjectTask, PerfmonAopInjector and their helper classes</li>\r\n\t<li>The classes.dir contains all the classes that may need to be instrumented and the classes used in the injected code, it's added to the Javassist's internal classpath via ClassPool.appendClassPath(\"/absolute/apth/to/the/classes.dir\")</li>\r\n</ul>\r\nNotice that System.out|err.println called by any referenced class are automatically  intercepted by Ant and changed into Task.log(String msg, Project.MSG_INFO) and will be thus included in Ant's output (unless -quiet).<br><br><strong>JavassistInjectTask.java (click it to expand):</strong><br><br><pre><code>\r\npackage example;<br><br>import java.io.File;\r\nimport java.util.*;\r\nimport javassist.CannotCompileException;\r\nimport org.apache.tools.ant.*;\r\nimport org.apache.tools.ant.types.*;<br><br>/**\r\n * Invoke PerfmonAopInjector on a set of classes to instrument some\r\n * methods and calls to some methods.\r\n * &lt;p&gt;\r\n * The Javassist library must be on the classpath.\r\n */\r\npublic class JavassistInjectTask extends Task {<br><br>    /**\r\n     * The destination of the stream. If &lt;code&gt;null&lt;/code&gt;, the system\r\n     * console is used.\r\n     */\r\n    private File outputFolder = new File(&quot;instrumented&quot;);<br><br>    /**\r\n     * Stores a collection of file sets and/or file lists, used to\r\n     * select multiple files for concatenation.\r\n     */\r\n    private Vector inputFilesets = new Vector();<br><br>\tprivate int logLevel = PerfmonAopInjector.LOG_INFO;<br><br>\tprivate List interceptedExecutions = new LinkedList();\r\n\tprivate List interceptedCalls = new LinkedList();<br><br>    /**\r\n     * Sets the destination file, or uses the console if not specified.\r\n     * @param destinationFile the destination file\r\n     */\r\n    public void setOutputFolder(File destinationFile) {\r\n        this.outputFolder = destinationFile;\r\n    }<br><br>    /**\r\n     * Set of files to concatenate.\r\n     * @param set the set of files\r\n     */\r\n    public void addFileset(FileSet set) {\r\n        inputFilesets.addElement(set);\r\n    }<br><br>    public void execute() throws BuildException {\r\n    \ttry {\r\n    \t\ttryExecute();\r\n    \t} catch (BuildException e) {\r\n    \t\tlog(&quot;TASK FAILED: &quot; + e, Project.MSG_ERR);\r\n    \t\te.printStackTrace();\r\n    \t\tthrow e;\r\n    \t} catch (RuntimeException e) {\r\n    \t\tlog(&quot;TASK FAILED: &quot; + e, Project.MSG_ERR);\r\n    \t\te.printStackTrace();\r\n    \t\tthrow e;\r\n    \t}\r\n    }<br><br>    public void tryExecute() throws BuildException {<br><br>        log(&quot;STARTING TO INJECT MONITORING...&quot;, Project.MSG_WARN);<br><br>        verifyInputs();<br><br>        // Iterate thru the sources - paths, filesets and filelists\r\n        final List inClassFileDirs = collectTargetClassFileDirs();<br><br>        log(&quot;Loaded class dirs: &quot; + inClassFileDirs, Project.MSG_INFO);<br><br>        final PerfmonAopInjector perfmonAopInjector = createPerfmonAopInjector();\r\n        setInjectorClassPath(perfmonAopInjector, inClassFileDirs);<br><br>        injectMethodExecutionsMonitoring(perfmonAopInjector);<br><br>        injectMethodCallsMonitoring(perfmonAopInjector, inClassFileDirs);<br><br>        log(&quot;DONE. Classes and methods modified:\\n&quot; + perfmonAopInjector.getAllLogMessages(), Project.MSG_INFO);\r\n    }<br><br>\tprivate PerfmonAopInjector createPerfmonAopInjector() {\r\n\t\tfinal PerfmonAopInjector perfmonAopInjector = new PerfmonAopInjector();\r\n        perfmonAopInjector.setLogLevel(logLevel);\r\n        perfmonAopInjector.setOutputFolder(this.outputFolder);\r\n        log(&quot;createPerfmonAopInjector: method executions to instrument: &quot; + interceptedExecutions, Project.MSG_DEBUG);\r\n        perfmonAopInjector.setInstrumentedMethodExecutions(toArray(interceptedExecutions));\r\n        log(&quot;createPerfmonAopInjector: method calls to instrument: &quot; + interceptedCalls, Project.MSG_DEBUG);\r\n        perfmonAopInjector.setInstrumentedMethodCalls(toArray(interceptedCalls));\r\n\t\treturn perfmonAopInjector;\r\n\t}<br><br>\tprivate MonitoredMethodDescriptor[] toArray(final List monitoredMethodDescriptors) {\r\n\t\treturn (MonitoredMethodDescriptor[]) monitoredMethodDescriptors.toArray(\r\n\t\t\t\tnew MonitoredMethodDescriptor[monitoredMethodDescriptors.size()]);\r\n\t}<br><br>\tprivate void injectMethodCallsMonitoring(\r\n\t\t\tfinal PerfmonAopInjector perfmonAopInjector,\r\n\t\t\tfinal List inClassFileDirs) {\r\n\t\tlog(&quot;Going to inject monitoring of method *calls*...&quot;, Project.MSG_INFO);<br><br>\t\tfor (Iterator iterator = inClassFileDirs.iterator(); iterator.hasNext();) {\r\n        \tfinal ClassFileDir classFileDir = (ClassFileDir) iterator.next();\r\n        \tinjectCallMonitoringForClasses(perfmonAopInjector, classFileDir.getClassFiles() );\r\n\t\t}\r\n\t}<br><br>\tprivate void injectMethodExecutionsMonitoring(\r\n\t\t\tfinal PerfmonAopInjector perfmonAopInjector) {<br><br>\t\tlog(&quot;Going to inject monitoring into method *executions*...&quot;, Project.MSG_INFO);<br><br>\t\ttry {\r\n\t\t\tperfmonAopInjector.monitorConfiguredMethodExecutions();\r\n\t\t} catch (Exception e) {\r\n\t\t\tString msg = e.toString();\r\n\t\t\tif (e instanceof CannotCompileException) {\r\n\t\t\t\tif (e.getMessage().indexOf(&quot;no such class&quot;) &gt;= 0) {\r\n\t\t\t\t\tmsg = &quot;A class cannot be found. Make sure that not only the classes to be &quot; +\r\n\t\t\t\t\t\t\t&quot;instrumented but also the classes used in the injected code are &quot; +\r\n\t\t\t\t\t\t\t&quot;in the class file file set. Cause: &quot; + e;\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t\tthrow new BuildException(&quot;Injecting monitoring into methods failed: &quot; + msg, e);\r\n\t\t}\r\n\t}<br><br>    private void injectCallMonitoringForClasses(final PerfmonAopInjector perfmonAopInjector,\r\n    \t\tfinal List classFiles) {\r\n    \tfor (Iterator iterator = classFiles.iterator(); iterator.hasNext();) {\r\n\t\t\tfinal File classFile = (File) iterator.next();\r\n\t\t\tinjectCallsMonitoringForClass(perfmonAopInjector, classFile);\r\n\t\t}\r\n\t}<br><br>    private void setInjectorClassPath(final PerfmonAopInjector perfmonAopInjector,\r\n    \t\tfinal List classFileDirs) {<br><br>    \tfor (Iterator iterator = classFileDirs.iterator(); iterator.hasNext();) {\r\n\t\t\tfinal ClassFileDir clasDir = (ClassFileDir) iterator.next();\r\n\t    \tperfmonAopInjector.addClassDir(clasDir.getBaseDir());\r\n\t\t}\r\n\t}<br><br>\tprivate void injectCallsMonitoringForClass(final PerfmonAopInjector perfmonAopInjector, final File classFile) {\r\n\t\tlog(&quot;Processing file &quot; + classFile.getName() + &quot;...&quot;, Project.MSG_DEBUG);\r\n\t\tfinal String targetClass = relativeFileToClass(classFile);\r\n\t\ttry {\r\n\t\t\tperfmonAopInjector.monitorConfiguredMethodCallsIn(targetClass);\r\n\t\t} catch (Exception e) {\r\n\t\t\tthrow new BuildException(&quot;Injecting method calls monitoring into the class &quot; +\r\n\t\t\t\t\tclassFile + &quot; failed.&quot;, e);\r\n\t\t}\r\n    }<br><br>\tprivate String relativeFileToClass(final File classFile) {\r\n\t\tfinal String dotSeparatedName = classFile.getPath()\r\n\t\t\t.replace(File.separatorChar, '.')\r\n//\t\t\t.replace('$', '.')\r\n\t\t\t;\r\n\t\tlog(&quot;relativeFileToClass: Converting file '&quot; + classFile + &quot;' to '&quot; + dotSeparatedName +\r\n\t\t\t\t&quot;'.substring&quot;, Project.MSG_DEBUG);\r\n\t\treturn dotSeparatedName.substring(\r\n\t\t\t\t0, dotSeparatedName.indexOf(&quot;.class&quot;));\r\n\t}<br><br>\tprivate List collectTargetClassFileDirs() {\r\n    \tfinal List allClassFileDirs = new Vector();\r\n\t\tfor (Enumeration e = inputFilesets.elements(); e.hasMoreElements();) {\r\n        \tfinal FileSet fileSet = (FileSet) e.nextElement();\r\n            final DirectoryScanner scanner =\r\n                    fileSet.getDirectoryScanner(getProject());<br><br>            final File classesDir = fileSet.getDir(getProject());\r\n\t\t\tfinal List inClassFiles = checkAddFiles(\r\n            \t\tclassesDir,\r\n            \t\tscanner.getIncludedFiles());<br><br>\t\t\tallClassFileDirs.add(new ClassFileDir(classesDir, inClassFiles));\r\n        }\r\n\t\treturn allClassFileDirs;\r\n\t}<br><br>\tprivate void verifyInputs() {\r\n\t\tif (inputFilesets.size() == 0) {\r\n            throw new BuildException(\r\n                &quot;At least one class folder must be provided&quot;);\r\n        }\r\n\t\tif(outputFolder == null || !outputFolder.isDirectory()) {\r\n\t\t\tthrow new BuildException(&quot;The attribute outputFolder must be set to an existing folder; is: &quot; + outputFolder);\r\n\t\t}\r\n\t}<br><br>    /**\r\n     * Reset state to default.\r\n     */\r\n    public void reset() {\r\n        outputFolder = null;\r\n        inputFilesets.removeAllElements();\r\n    }<br><br>    private List checkAddFiles(final File classDir, final String[] classesRelative) {\r\n    \tfinal List inClassFiles = new Vector();<br><br>        for (int i = 0; i &lt; classesRelative.length; ++i) {\r\n            final File file = new File(classesRelative[i]);\r\n            if (!file.getName().endsWith(&quot;.class&quot;)) {\r\n            \tlog(&quot;checkAddFiles: Ignoring non-class file &quot; + file, Project.MSG_WARN);\r\n            } else if (file.getName().matches(&quot;.*\\\\$[0-9]+.class&quot;)) {\r\n            \tlog(&quot;checkAddFiles: Ignoring the anonymous inner class &quot; + file, Project.MSG_WARN);\r\n            } else {\r\n            \tinClassFiles.add(file);\r\n            }\r\n        }\r\n        return inClassFiles;\r\n    }<br><br>    /**\r\n     * Set the logging level. Level should be one of\r\n     * &lt;ul&gt;\r\n     *  &lt;li&gt;error&lt;/li&gt;\r\n     *  &lt;li&gt;warning&lt;/li&gt;\r\n     *  &lt;li&gt;info&lt;/li&gt;\r\n     *  &lt;li&gt;debug&lt;/li&gt;\r\n     * &lt;/ul&gt;\r\n     * &lt;p&gt;The default is &amp;quot;info&amp;quot;.&lt;/p&gt;\r\n     * @param echoLevel the logging level\r\n     */\r\n    public void setLoglevel(final LogLevel echoLevel) {\r\n        String option = echoLevel.getValue();\r\n        if (option.equals(&quot;error&quot;)) {\r\n            logLevel = PerfmonAopInjector.LOG_WARN;\r\n        } else if (option.equals(&quot;warning&quot;)) {\r\n            logLevel = PerfmonAopInjector.LOG_WARN;\r\n        } else if (option.equals(&quot;info&quot;)) {\r\n            logLevel = PerfmonAopInjector.LOG_INFO;\r\n        } else {\r\n            // must be &quot;debug&quot;\r\n        \tlogLevel = PerfmonAopInjector.LOG_DEBUG;\r\n        }\r\n    }<br><br>    public void addConfiguredExecution(final MethodDescriptor methodExecution) {\r\n    \taddCallOrExecution(interceptedExecutions, methodExecution);\r\n    }<br><br>    public void addConfiguredCall(final MethodDescriptor methodCall) {\r\n    \taddCallOrExecution(interceptedCalls, methodCall);\r\n    }<br><br>    private void addCallOrExecution(final List destination, final MethodDescriptor method) {\r\n    \tmethod.validate();\r\n    \tdestination.add(new MonitoredMethodDescriptor(\r\n    \t\t\tmethod.getType(), method.getName(), method.getMetric()));\r\n    }<br><br>    //@Override\r\n    public void log(String msg, int msgLevel) {\r\n    \tint actualLogLevel = msgLevel;\r\n    \t// Increase debug to info to make sure it's logged if desired level is debug\r\n    \tif (msgLevel == Project.MSG_DEBUG &amp;&amp; this.logLevel == PerfmonAopInjector.LOG_DEBUG) {\r\n    \t\tactualLogLevel = Project.MSG_INFO;\r\n    \t}\r\n    \tsuper.log(msg, actualLogLevel);\r\n    }<br><br>    /**\r\n     * Represents folder containing .class files.\r\n     */\r\n    public static class ClassFileDir {\r\n    \tprivate List classFiles;\r\n    \tprivate File baseDir;<br><br>\t\tpublic ClassFileDir(File baseDir, List classFiles) {\r\n\t\t\tthis.baseDir = baseDir;\r\n\t\t\tthis.classFiles = classFiles;\r\n\t\t}\r\n\t\tpublic List getClassFiles() {\r\n\t\t\treturn classFiles;\r\n\t\t}\r\n\t\tpublic File getBaseDir() {\r\n\t\t\treturn baseDir;\r\n\t\t}\r\n\t\tpublic String toString() {\r\n\t\t\treturn &quot;[dir=&quot; + baseDir + &quot;,classes=&quot; + classFiles + &quot;]&quot;;\r\n\t\t}\r\n    }<br><br>    /**\r\n     * The enumerated values for the level attribute.\r\n     */\r\n    public static class LogLevel extends EnumeratedAttribute {\r\n        /**\r\n         * @see EnumeratedAttribute#getValues\r\n         * @return the strings allowed for the level attribute\r\n         */\r\n        public String[] getValues() {\r\n            return new String[] {&quot;error&quot;, &quot;warning&quot;, &quot;info&quot;, &quot;debug&quot;};\r\n        }\r\n    }<br><br>    public static class MethodDescriptor {\r\n    \tprivate String type;\r\n    \tprivate String name;\r\n    \tprivate String metric;\r\n\t\tpublic String getType() {\r\n\t\t\treturn type;\r\n\t\t}\r\n\t\tpublic void setType(String type) {\r\n\t\t\tthis.type = type;\r\n\t\t}\r\n\t\tpublic String getName() {\r\n\t\t\treturn name;\r\n\t\t}\r\n\t\tpublic void setName(String name) {\r\n\t\t\tthis.name = name;\r\n\t\t}\r\n\t\tpublic String getMetric() {\r\n\t\t\treturn metric;\r\n\t\t}\r\n\t\tpublic void setMetric(String metric) {\r\n\t\t\tthis.metric = metric;\r\n\t\t}\r\n    \tpublic void validate() throws BuildException {\r\n    \t\tString error = &quot;&quot;;\r\n    \t\tif (name == null) {\r\n    \t\t\terror += &quot;The attribute name is required for a method.&quot;;\r\n    \t\t}\r\n    \t\tif (type == null) {\r\n    \t\t\terror += &quot; The attribute type is required for a method.&quot;;\r\n    \t\t}<br><br>    \t\tif (error.length() &gt; 0) {\r\n    \t\t\tthrow new BuildException(error);\r\n    \t\t}\r\n    \t}\r\n    }<br><br>}<br><br></code></pre><br><br>PS: If using maven, you'll be happy to know that Javassist is in a Maven repository (well, at least it has a pom.xml, so I suppose so).\r\n<h3>Ant custom task resources</h3>\r\n<ol>\r\n\t<li>Ant manual: <a href=\"http://ant.apache.org/manual/develop.html\">Writing Your Own Task</a> - incl. <a href=\"http://ant.apache.org/manual/develop.html#nested-elements\">Supporting nested elements</a> (you only need create&lt;name&gt;, add&lt;name&gt;,  or addConfigured&lt;name&gt;)</li>\r\n\t<li>Rob Lybarger: <a href=\"http://www.developer.com/java/article.php/3630721/Introduction-to-Custom-Ant-Tasks.htm\">Introduction  to Custom Ant Tasks</a> (2006) - the basics</li>\r\n\t<li>Rob Lybarger: <a href=\"http://www.developer.com/java/ent/article.php/10933_3636196_1/More-on-Custom-Ant-Tasks.htm\">More on Custom Ant Tasks</a> (2006) - about nested elements</li>\r\n\t<li>Stefan Bodewig: <a href=\"http://www.oracle.com/technology/pub/articles/bodewig_taskwriters.html\">Ant 1.6 for Task Writers</a> (2005)</li>\r\n</ol>",
  "excerpt": ""
 },
 {
  "title": "Most interesting links of June",
  "published": "2010-07-09 10:12:42",
  "postType": "post",
  "slug": "/2010/07/09/most-interesting-links-of-june/",
  "status": "publish",
  "tags": [
   "html5",
   "java",
   "refactoring"
  ],
  "categories": [
   "Languages",
   "Top links of month"
  ],
  "content": "The last month's list of interesting articles is a bit shorter due to off-line holidays, which I enjoyed much more then reading articles :-)\r\n<ul>\r\n\t<li><a href=\"http://blog.solidcraft.eu/2010/05/boy-scout-rule-in-practice.html\">Boy Scout Rule in practice</a> - improving the code on the go with respect to the <a href=\"http://www.amazon.com/Clean-Code-Handbook-Software-Craftsmanship/dp/0132350882\">Clean Code</a>'s and similar best practices: 1) If you spot a piece of code to improve, don't add a TODO there - fix it immediately; 2) A nice example of refactoring a 30 lines method based on the Single Responsibility and Short Method principles</li>\r\n\t<li><a href=\"http://www.ibm.com/developerworks/java/library/j-jtp05236.html\">Java theory and practice: Dealing with InterruptedException - You caught it, now what are you going to do with it?</a> - why not to swallow an InterruptedException and how to deal with it properly (namely by rethrowing it or calling Thread.currentThread().interrupt() to reset the Thread's interrupted status). This is not a new article, but the subject is little known yet raher important.</li>\r\n\t<li><a href=\"http://www.focus.com/images/view/11905/\">WTF is HTML5 and why we should care?</a> - a visually appealing 1-page summary of what HTML 5 brings and its current and future support in major browsers and IE. Related: <a href=\"http://www.whatwg.org/specs/web-apps/current-work/multipage/index.html#contents\">the current draft of the HTML5 spec</a>.</li>\r\n\t<li><a href=\"http://www.drdobbs.com/web-development/225300318?pgno=1\">Dr Dobbs' HTML 5 Primer</a> - an overview of the technologies and standards that form the \"HTML 5 Family\" and are commonly referred to as HTML 5 though not being a part of the core HTML 5 standard. Not long and good to make the HTML5 fuss a bit clearer.</li>\r\n</ul>",
  "excerpt": ""
 },
 {
  "title": "My path to SCEA 5",
  "published": "2010-07-21 15:32:03",
  "postType": "post",
  "slug": "/2010/07/21/my-path-to-scea-5/",
  "status": "publish",
  "tags": [
   "architecture",
   "certification",
   "java",
   "javaEE",
   "sun"
  ],
  "categories": [
   "j2ee",
   "Languages"
  ],
  "content": "I'd like to share with you my experience with the <a href=\"http://en.wikipedia.org/wiki/Sun_Certified_Professional#Sun_Certified_Enterprise_Architect_.28SCEA.29\">Sun Certified Enterprise Architect for the Java Platform, Enterprise Edition 5</a> (SCEA 5) [<a href=\"http://education.oracle.com/pls/web_prod-plq-dad/db_pages.getpage?page_id=326\">1</a>] certification. There was a couple of unclear things regarding the assignment and its deliverables and I've learned some interesting things (mostly about hardware estimation and deployment environments such as the \"clouds\"), both of which may be of an interest to somebody aiming at this certification. I only know that I passed but not how well, so my way of doing things, though sufficient, may not be the best one.<br><br><!--more-->\r\n<h2>The value of the certification</h2>\r\nThis certification was really valuable for me, because:\r\n<ul>\r\n\t<li>I had to read a couple of important books that I always wanted to read but never found the time to do so (including Real World Java EE Patterns - Rethinking Best Practices,  EJB 3 in Action, UML 2 and the Unified Process: Practical Object-Oriented Analysis and Design (2nd Edition), Architecting Enterprise Solutions: Patterns for High-Capability Internet-based Systems, Design Patterns: Elements of Reusable Object-Oriented Software by the Gang of Four, Core J2EE Patterns)</li>\r\n\t<li>I got an overview of the complete Java EE landscape and the non-functional characteristics of a Java EE application and how they are impacted by the individual technological and architectural choices</li>\r\n\t<li>I had finally an opportunity to use UML in practice, including the determination of the appropriate level of detail and the proper ways to represent some concepts (like non-intrusive representation of an <a href=\"http://www.informit.com/articles/article.aspx?p=360441&amp;seqNum=5\">iteration over a collection</a>)</li>\r\n</ul>\r\nAnd I believe that it is also valuable for an employer because even though it doesn't prove you to be an architect, it does prove that you have a good overview of the complete JEE landscape, that you are aware of architectonic concerns and the necessity to evaluate the pros and cons of any technological choice, and that you have some basic proficiency with UML and some general knowledge beyond the technologies themselves, such as about design patterns.\r\n<h2>Step 1: The knowledge test</h2>\r\nAbout <a href=\"https://www.suntrainingcatalogue.com/eduserv/client/loadCourse.do?coId=cz_CZ_CX-310-052&amp;coCourseCode=CX-310-052\">the test</a>: You get 64 questions and 2 hours and need 57% (37 q.) to pass. About half of the questions are multiple-choice and you must select all the correct answers to get the points (I believe that they tell you how many correct answers there are).<br><br>The test was quite challenging even though I answered ~ 3/4 questions correctly. Paradoxically, the least I gained in Web Tier Technologies, which in practice I use the most. The main problems were:\r\n<ul>\r\n\t<li><em>Missing knowledge</em> - my resources (the book Sun Certified Enterprise Architect for J2EE Technology Study Guide and an additional material regarding tiered architectures (this is a really important topic), EJB3 and JPA) were pretty good, but I completely missed information about JCA and few \"obscure\" topics like the security limitations of Java Web Start and JVM's bytecode verification, I estimate that in total I missed about 10% of the knowledge needed.  It's important not to skip the less used parts of Java EE, like those mentioned above, JAX-WS etc. You should know about Ajax support in JSF and of course you must know the essential changes between EJB 2.x and 3.0.</li>\r\n\t<li><em>Multiple-choice test</em> - as mentioned, most questions have several correct answers and you must select all. Selecting the first ones is easy but the last one is sometimes/often difficult to choose, see the next point. It's better to concentrate first on the questions with 1 or only few responses because there is a higher probability that you will get it right.</li>\r\n\t<li><em>Unclear questions and answers</em> - as usual with tests, if you aren't on the same \"brain wave\" as the test author, some questions and answers will not be sufficiently clear to you, which is further complicated if you aren't native English speaker. The key is in determining correctly what, in the question or answers, is really important and what is only a \"decoration\". Inevitably, due to a missing knowledge, practice, or a different thinking process than the author's,  you will sometimes put too much stress on an unimportant fact or, conversely, neglect something that the author considered to be essential.  For example:\r\n<ul>\r\n\t<li>Does the emphasis on \"ease of development\" imply the preference of JPA over JDBC? I guess so but who knows what the author thinks?</li>\r\n\t<li>A JEE application needs to communicate with an old terminal server, will you use a session-bean using a screen-scraper or JDBC to access directly the DB of the server? - In the description there was no mention of the server having any database, so how may I know whether it has one? On the other hand, screen-scraping seems to be something more suitable for a JCA adapter than a @Stateless bean... .</li>\r\n\t<li>A couple of questions required that I select the proper combination of competing technologies (such as JPA vs. JDBC) for a particular model situation. Because each technology has some benefits and disadvantages, it was difficult to pick the right one because the short problem statement didn't give <em>me</em> enough information to be sure how these pluses and minuses are important for the author.</li>\r\n</ul>\r\n</li>\r\n</ul>\r\nAdvices:\r\n<ul>\r\n\t<li>Learn the advantages and disadvantages of the alternative technologies in each layer (JSF vs. JSP with JSTL etc.) and when one is more suitable than the other. You will employ this knowledge also in the parts 2 and 3, so it's really important. After all, you want to be an architect :-) .</li>\r\n\t<li>Though this is Java EE exam, don't push the \"cool\" technologies (JSF, EJB, JPA, ...) everywhere and don't do or avoid doing something only because in general it is considered to be a good or bad practice, you have to really decide based on the actual situation at hand and a rational consideration of the pros and cons. For example even using JSP with JSTL tags to do database queries may be the most suitable solution in some special case.</li>\r\n\t<li>As usually: read the problem statement and the answers thoroughly and don't let your pre-existing preferences and concepts to form your decision.</li>\r\n\t<li>It's important to have some general knowledge outside of the scope of the exam preparation books. For example you should know what spoofing and tampering are.</li>\r\n\t<li>Read sample questions with answers or a discussion on the Internet (e.g. the <a href=\"http://www.coderanch.com/forums/f-26/java-Architect-SCEA\">JavaRanch  SCEA forum</a>) - having seen a couple of similar questions and learning what others consider important in the questions and their answers will make it easier to understand and assess correctly a question you might get. (Thanks to David Z. for this advice.)</li>\r\n</ul>\r\n<h2>Step 2: The assignment</h2>\r\nThis <a href=\"https://www.suntrainingcatalogue.com/eduserv/client/loadCourse.do?coCourseCode=CX-310-301A\">assignment</a> is the core of the certification, and it took me a considerable amount of time, lot of it spent by searching for UML wisdom (how to express some specific ideas in an appropriate way on a particular diagram), by estimating the resource requirements of the application and by exploring and comparing deployment environments and their non-functional characteristics (Amazon Cloud &amp; other offerings, various physical and virtual server providers etc.). I could spend a lot less time on the deployment part but I really wanted to go into the detail to make it clear for myself.<br><br>First of all, make sure to <strong>read the documents [1] and [2]</strong> (see Resources below) thoroughly, they will make many things clear. Both are created by Humphrey Sheil, one of the essential people behind SCEA 5.\r\n<h3>Deliverables</h3>\r\nYou will receive a brief introduction to the customer's company and her needs for a Java EE application, a structured description of the main requirements, a domain model, and few use case diagrams. And you are expected to deliver the following:\r\n<ul>\r\n\t<li>A class diagram</li>\r\n\t<li>A component diagram</li>\r\n\t<li>A deployment diagram that describes the proposed physical layout of the major tiers</li>\r\n\t<li>A Sequence or Collaboration diagram for each use case</li>\r\n\t<li>The top three technical risks &amp; their mitigation strategies</li>\r\n</ul>\r\n<h3>Understanding what to do</h3>\r\nThe assignment is quite vague and only specifies a very high-level description of the main use cases and thus there are many open many questions:\r\n<ul>\r\n\t<li>The assignment itself seems to be incomplete, the requirements (\"Workshop Output\") mention things that are not reflected by its other parts, namely the use case diagrams, and miss information necessary for the design. For example it mentioned that a visualisation of the \"product\" that users may design for themselves via the webapp under construction is very important and that the customer has therefore procured a modeling tool, which can render various visualizations from an XML input. But no UC contained an invocation of the visualization and there were no details regarding the communication means supported by the tool (webservice, something else, command line, or only GUI?). Therefore you have to fill the missing parts for yourself and replace the missing information with assumptions, perhaps adding the unclear element to the list of risks.</li>\r\n\t<li>What about all the common parts of an enterprise web application that aren't mentioned explicitly in the assignment, like user registration/login, administration?  Answer as per [1]: You should include them. So I added few JSPs and one or two manager EJBs without going into any detail, providing only a draft of the functionality to present that I'm aware of it.</li>\r\n\t<li>What should be the level of detail of the Class and Component diagrams? (See [4] for the distinction between analytical, design and implementation classes and the corresponding level of detail/abstraction.) According to [1], quite a low one, but still on the design level.\r\n<ul>\r\n\t<li>My domain model provided with the assignment had 11 entities and the class diagram I've produced had 25 classes plus 8 views (namely JSPs). The level of detail of the class diagram was limited by the need to fit it on a single page, so it was on quite a high level, including the entities, important manager EJBs and few other classes representing important architectural concepts (a cache, an interceptor, a DAO for accessing an external tool,...).</li>\r\n\t<li>The domain model maps to classes nearly directly, only with few small modifications and extensions (like introducing a parent class) , of course with the important added information of @Entity or @Embeddable, where appropriate.</li>\r\n</ul>\r\n</li>\r\n\t<li>Sequence Diagrams (SD) - shall the UI controller be included? Or even the JSPs? I did include both.\r\n<ul>\r\n\t<li>I kept SDs on a rather high level, using only as little special constructs as possible, like once a <em>loop</em> for expressing that something is done for each item of a collection, a <em>ref </em>to express the fact that an SD depends on the outcome of another SD, <em>opt</em> and <em>alt</em>, both once, where I wanted to depict an important operation that doesn't need to be performed and to stress  alternative paths.</li>\r\n</ul>\r\n</li>\r\n\t<li>Component Diagram (CD) - what is a component, i.e. the proper level of detail?\r\n<ul>\r\n\t<li>According to the instructions in the assignment itself: \"Examples of components are Enterprise JavaBean<sup>TM</sup> (EJB<sup>TM</sup>), servlets, ...\"</li>\r\n\t<li>According to [1] and [2], the CD should be more like a package diagram, i.e. components should be on a higher level than a single class (EJB/JSP/...), and that's what I did, creating components (as empty boxes) like \"Design Logic and Persistence\", \"Customer Search\", \"Admin UI\", \"User Management and Persistence\", \"LDAP DAO\", in total 14 of them in 3 layers plus 3 external systems, connecting them only with the <em>uses</em> relationship (----&gt;), i.e. no interfaces, ports etc.</li>\r\n\t<li>[1] suggests depicting security constraints on admin pages, more detailed JSPs etc., but this isn't in [2]; I followed [2]</li>\r\n</ul>\r\n</li>\r\n</ul>\r\n<h3>Designing the solution</h3>\r\nThe key part is of course the solution itself, the various diagrams are only its visible manifestation, not the thing itself. You have to decide what parts should the system have, how will they interact, how will that ensure that the non-functional and functional requirements are met etc. Note down any risk you discover or an assumption that you make.\r\n<h3>The diagrams</h3>\r\nOnce the proper level of detail is clear and you have the solution in you mind, it isn't too difficult to draw the class, component, sequence (or collaboration), and deployment diagrams. You may be sometimes unsure how to depict something while keeping the same level of detail, so a good UML book is handy. A good UML editor is also necessary. I used Visual Paradigm (Modeller Edition), which drove me nuts sometimes, being more of a hindrance than a help, but it was certainly better than Paintbrush.\r\n<h3>The deployment: Resource estimation and hardware selection</h3>\r\nEstimating the resources needed by the application and proposing a hardware providing them was perhaps the most difficult and time-consuming task for me, because all of that was completely new to me. Actually it isn't that important part of the assignment, you can perhaps just guess something and do not need to propose any particular hardware (as H. Sheil says in [2] at the page 7, no significant marks are allocated to this), but for me the main purpose of the certification was to learn.<br><br>The important questions here are:\r\n<ul>\r\n\t<li>How to estimate the resource requirements?</li>\r\n\t<li>Should we consider horizontal SW scaling, namely multiple AS instances on a single physical node?</li>\r\n\t<li>What HW and deployment environment (physical, virtual dedicated server(s), a cloud) to choose?</li>\r\n</ul>\r\n<h4>How to estimate the resource requirements?</h4>\r\nHow to assess the HW necessary? Is there enough input information? I think it isn't, also, you can't really know the real resource requirements without a proper load testing. But you can and should perform an \"informed guess\".\r\n<ul>\r\n\t<li>See an explanation why <a href=\"http://www.coderanch.com/t/486213/Architect-Certification-SCEA/certification/servers#2185471\">you can't really estimate the HW</a> in a JavaRanch forum. And a disagreeing follow-up: \"Yes. The exam specifies the no. of concurrent users, the required up time or words to that effect. At least mine did. The size of a typical request can be reasonably guessed from the estimated maximum size of the web page in the application . The tps [transactions per second] can be derived from the above two.\"</li>\r\n</ul>\r\nI had only a little idea of what the resource requirements of an enterprise web application may be, even knowing the availability requirements and number of concurrent users from the assignment. The requirements of each application are of course different but I wanted to find out at least some limits within which my estimate should be, and fortunately I had competent colleagues willing to help (thanks you, David, Alda and Mishanek!). So below are two examples that can give you an idea what you may or may not need.\r\n<h5>Example 1: A very high-traffic enterprise web application</h5>\r\nThe application is a J2EE learning management software that must support 2000 concurrent users with the availability of 24/7. It's use of the DB is far from being efficient and thus the DB HW must be very powerful. The infrastructure is:\r\n<ul>\r\n\t<li>2 physical Websphere nodes (and it's been considered to have 2 AS instances on each)\r\n<ul>\r\n\t<li>4 GB heap (this proved to be enough; 2GB are left for the OS)</li>\r\n\t<li>can use up to 8 virtual processors</li>\r\n\t<li>no session failover due to inability of the JEE application itself</li>\r\n\t<li>Scalability: WebSphere needs for double users approx. 2.5 increase in CPU (verified in this case, likely not generally applicable)</li>\r\n\t<li>Websphere itself can scale nearly linearly with factor 0.9 - 0.95  but it also depends a lot on the application</li>\r\n</ul>\r\n</li>\r\n\t<li>Database\r\n<ul>\r\n\t<li>master-slave with automatic fail-over</li>\r\n\t<li>32 GB RAM</li>\r\n\t<li>24 (virtual) processors</li>\r\n</ul>\r\n</li>\r\n</ul>\r\n<h5>Example 2: Sizing HW for the Liferay Portal</h5>\r\nLiferay Portal for 5000 registered users with 500 of them accessing it concurrently would need an application server with 4GB memory and a 3GHz quad-core Xeon processor; for the database, a server below 4GB/1-quad 3GHz would suffice.\r\n<h5>Example 3: Recommended minimum for a production WebSphere AS</h5>\r\nIBM recommends: \"Typical deployments of IBM WebSphere Application Server v7.0 <em>require  at least a High-CPU Medium instance</em> to have access to enough  physical memory and computing power. A small instance type is sufficient  for development, single-user purposes only.\" That means 1.7GB RAM and 2 (virtual) cores each with the power of 2.5-3.0 GHz 2007 Opteron or Xeon processor.<br><br>Because this is the minimum production configuration to run WebSphere, we can take is as the minimum configuration for any \"standard\" Java EE web application.\r\n<h5>Conclusion</h5>\r\nGiven the examples above, other information, and my requirement for 200 concurrent users doing no resource-intensive actions and 10h/day availability,  I believe one 4GB, 2-core 2.5GHz machine   running both a single AS and the DB would be able to satisfy the   (rather friendly) performance requirements in my assignment. If running   on Amazon EC2 with their great SLA, it would be also available enough   with future scalability possible either by increasing the resources or by   splitting the DB out of the machine - but such a single machine solution   doesn't sound enough \"enterprisy\" so I've chosen a more classical one with multiple but weak (not to waste money) virtual machines from Amazon EC2.<br><br>Quote: \"Oftentimes installations find that their database server runs out of capacity much sooner than the WebLogic Server does. You must plan for a database server that is sufficiently robust to handle the application. Typically, a good application will require a database three to four times more powerful than the application server hardware.\" [the source is unknown]\r\n<h4>Should we consider running multiple AS instances  on a single physical node?</h4>\r\n\"It is usually sufficient to create a single server instance on a machine, since the Application Server and accompanying JVM are both designed to scale to multiple processors. However, it can be beneficial to create multiple instances on one machine for application isolation and rolling upgrades.\" [Sun Java System Application Server 9.1 Deployment Planning Guide, p22]<br><br>\"2 processes can utilize CPU and memory better than 1 (rule of thumb: 1 instance for every 2 CPUs)\" [I haven't noted down the source of this advice :(]<br><br>I used a low-resource machines so running multiple SW instances was not an option for me anyway.<br><br><strong>Update</strong>: A recent blog comments on <a href=\"http://blog.terracottatech.com/2010/09/bigmemory_explained_a_bit.html\">64b JVM issues and recommends to use several 2GB instances</a> instead of one multi-GB one.\r\n<h4>What HW and deployment environment to choose?</h4>\r\nTo simplify my life, I didn't consider all the applicable hardware that you can buy but only the offerings of a few providers of physical and virtual server hosting and cloud environments.<br><br>You may choose on of three deployment environments (provided that you don't want to run your own one):\r\n<ol>\r\n\t<li>Hire a <strong>physical server</strong> - the most expensive but may be more cost-effective in the long-term, especially if there is permanent high load</li>\r\n\t<li>Hire a <strong>Virtual Private Server</strong> (VPS) - the virtual servers offerings have usually rather low resources (such as 0.5-1.5 GB, ~ 1 GHz) and are thus rarely suitable for Java EE</li>\r\n\t<li>Hire a <strong>virtual server running in a cloud</strong> - very flexible (easy addition of a new instance, scale an instance up/down only with a restart), may provide very good SLA, but the final price may be much higher than the price of the virtual server itself due to various small fees that accumulate a lot. See Stack Overflow: <a href=\"http://stackoverflow.com/questions/2638073/is-the-cloud-ready-for-an-enterprise-java-web-application-seeking-a-jee-hosting\">Is the Cloud ready for an Enterprise Java web application? Seeking a JEE hosting advice</a>.</li>\r\n</ol>\r\nLet's have a look at some of the <strong>physical and VPS offerings</strong>:\r\n<ul>\r\n\t<li><a href=\"http://www.servint.net/vps.php\">ServInt VPS</a>: Unlimited VPS: 2GB, RADI 10, $129/m, or Super VPS with 4GB but still only a 1 single-core CPU</li>\r\n\t<li><a href=\"http://www.abchost.cz/\">AbcHost.cz</a> - lease and hosting of a dedicated physical server, including\r\n<ul>\r\n\t<li>2*dual core AMD Opteron 2,6GHz, 8GB RAM - 4800 CZK/$230 (Sun Fire X2200 M2 with Opteron 2218)</li>\r\n\t<li>2*quad core AMD Opteron 2,2GHz, 8GB RAM - 5800 CZK/$290 (Sun Fire X2200 M2 with Opteron 2354)</li>\r\n\t<li>BM xSeries 335 1U server,  CPU Intel Xeon 2,4 GHz, 2GB RAM, 2*36GB HDD@10k w/ RAID 1 (mirroring) - 2890CZK/$146</li>\r\n\t<li>IBM xSeries 335 1U server, CPU Intel Xeon 2,8 GHz (otherwise as above) - 3190CZK/$155</li>\r\n\t<li>Connectivity 100 Mbps</li>\r\n</ul>\r\n</li>\r\n\t<li><a href=\"http://www.rackspace.com/managed_hosting/configurations.php\">Rackspace as a dedicated server provider</a>:\r\n<ul>\r\n\t<li>Basic One dedicated server: 1xDual-Core AMD Opteron, 3.5GB RAM, 2x250GB, 7.2K, SATA (RAID1), 2TB Bandwidth - $419/month</li>\r\n\t<li>Basic Two dedicated server: 1xQuad-Core AMD Opteron, 8GB RAM, 3x250GB, 7.2K, SATA (RAID5), 2TB bandwith - $529/mo</li>\r\n</ul>\r\n</li>\r\n\t<li><a href=\"http://journal.uggedal.com/vps-performance-comparison\">VPS Performance Comparison</a> (11/2009)</li>\r\n</ul>\r\nAnd some <strong>cloud offerings</strong>:\r\n<ul>\r\n\t<li><a href=\"http://www.rackspacecloud.com/\">Rackspace as a cloud VPS provider</a>:\r\n<ul>\r\n\t<li>Rackspace uses Xen, RAID10, every cloud server gets 4 virtual CPUs, 64b. The virtual CPU is *perhaps* an equivalent of Opteron 2347 HE, i.e. 2GHz</li>\r\n\t<li>A basic VPS: 1024 MB RAM, 40 GB HDD ~ $44/mo (the cost of data transfer is perhaps negligible)</li>\r\n\t<li>A more powerful VPS: 4 GB RAM, 160 GB HDD -  $175/mo</li>\r\n\t<li>Rackspace vs. Amazon EC2:\r\n<ul>\r\n\t<li>(<a href=\"http://www.rackspacecloud.com/cloud_hosting_products/servers/compare\">According to Rackspace</a>): the server is persistent, RAID10 storage; EC2 is cheaper but RS has higher performance &amp; higher disk throughput and thus it pays off\r\n<ul>\r\n\t<li>\"Most common VPS offerings only offer the equivalent of 128MB up to 512MB RAM at most. With most VPS offerings, you are not guaranteed the resources that you are paying for,..\"</li>\r\n\t<li>\"Cloud Server host machines have dual quad core processors. Each Cloud Server is assigned four virtual cores and the amount of CPU cycles allocated to these cores is weighted based on the size of the Cloud Server. For example a 4G Cloud Server will have twice the weight of a 2G Cloud Server.\"</li>\r\n</ul>\r\n</li>\r\n\t<li><a href=\"http://www.thebitsource.com/featured-posts/rackspace-cloud-servers-versus-amazon-ec2-performance-analysis/\">Rackspace Cloud Servers versus Amazon EC2: Performance Analysis</a> at The Bitsource</li>\r\n\t<li>Some <a href=\"http://www.elucidsoft.com/blog/2010/03/05/amazon-cloud-vs-rackspace-cloud/\">negative experience with Rackspace (in the comment #1)</a> - poor support, problems with crashes and a \"totally dysfunctional staff and broken support system\"</li>\r\n\t<li><a href=\"http://code.mixpanel.com/amazon-vs-rackspace/\">Why Mixpanel migrated from Rackspace to Amazon</a> (11/2010) - EBS more powerful and flexible than disks, variety of instance types, likely less outages, (much) better control tools, easier backups thanks to no 2G limit, pricing (reserved and bidded instances, A. constuntly  reduces its prices); main reason: \"Amazon just iterates on their product faster than anyone else and has the best one.\".</li>\r\n</ul>\r\n</li>\r\n</ul>\r\n</li>\r\n\t<li><a href=\"http://aws.amazon.com/ec2/\">Amazon EC2</a>\r\n<ul>\r\n\t<li>VPS instances of interest:\r\n<ul>\r\n\t<li>High-CPU Medium: 1.7GB RAM, 2 virtual cores each w/ 2.5 EC CU; reserved: ~ $96/month (plus traffic etc.)</li>\r\n\t<li>Large instance: 7.5GB, 4 CU (2 virtual cores with 2 CU each); reserved: ~ $190/month (plus traffic etc.)</li>\r\n\t<li>Notice that you can either pay standard hour rates or \"reserve\" the instance for  a 1 or 3 years fee to get lower hourly rates (which I've done when computing the price per month)</li>\r\n</ul>\r\n</li>\r\n\t<li>1 EC CU (compute unit) = 1.0-1.2 GHz 2007 Opteron or 2007 Xeon processor</li>\r\n\t<li>I/O shared, two priorities: medium or high (i.e. better I/O access)</li>\r\n\t<li>The instances are not persistent, any changes to the filesystem will be lost after a restart, you must use Amazon EBS for a permanent storage (and an extra fee)</li>\r\n</ul>\r\n<ul>\r\n\t<li>Additional advantages/offerings (for extra money):\r\n<ul>\r\n\t<li>Elastic  Load Balancing =&gt; not necessary to include a load balancer of my own</li>\r\n\t<li>Amazon Relational Database Service (RDS) [beta] = MySQL 5.1 running  in its own instance + advantages: auto backup, easy storage/mem/cpu  scaling [restart required] - e.g. Large DB Instance: (7.5 GB memory, 4  ECUs ~ 2 cores 2GHz each, 64b) . High Availability is being prepared.  Check the <a href=\"http://developer.amazonwebservices.com/connect/entry.jspa?externalID=2936\">Amazon  RDS DB Instance Sizing Guide</a>.</li>\r\n\t<li>...</li>\r\n</ul>\r\n</li>\r\n</ul>\r\n<ul>\r\n\t<li>Interesting\r\n<ul>\r\n\t<li>JBoss middleware for EC2 (beta): JBoss Enterprise Application Platform is built on open standards and integrates JBoss Application Server, Clustering, Cache, Messaging, Hibernate, Seam and JBoss Transactions JTA</li>\r\n\t<li>Websphere at EC2: \"Typical deployments of IBM WebSphere Application Server v7.0 <em>require at least a High-CPU Medium instance</em> to have access to enough physical memory and computing power. A small instance type is sufficient for development, single-user purposes only.\" A note from Amazon: \"The WebSphere Application Server AMI is 32 bit and works with Small and High-CPU Medium EC2 instance sizes. \"</li>\r\n\t<li><a href=\"http://forums.mysql.com/read.php?165,207970,207970#msg-207970\">MySQL on Amazon EC2: Articles, Blogs, Docs, FAQs</a></li>\r\n\t<li><a href=\"http://blog.rightscale.com/2007/08/20/redundant-mysql-set-up-for-amazon-ec2/\">MySQL master-slave setup for EC2</a> - but \"We currently don’t automatically promote the slave to master as this is a very delicate operation. Gotta ensure the master is really not servicing requests first, etc.\"</li>\r\n\t<li><a href=\"http://developer.amazonwebservices.com/connect/thread.jspa?messageID=120911&amp;#120911\">JBoss@EC2 perfromance problems discussion</a> (using a large instance)</li>\r\n</ul>\r\n</li>\r\n</ul>\r\n</li>\r\n</ul>\r\nGiven these offerings, I've opted for Amazon EC2 and its two medium high-cpu instances for the AS and a large instance for the DB, assuming some secure communication channel (e.g. via VPN) with the external back-end enterprise systems used by the application.\r\n<h3>Resources:</h3>\r\n[1] A presentation of Humphrey Sheil (one of the major figures behind SCEA 5): <a href=\"http://www.box.net/shared/i5eoqntdaf\">scea-part-two-2009-bof.pdf</a> - a MUST READ and re-read a couple of times; 27 slides only<br><br>[2] <a href=\"http://www.box.net/shared/2s55mfkogg\">Chapter 9 of Sun Certified Enterprise Architect for Java™ EE Study Guide</a>, Second Edition, M. Cade, H. Sheil, Prentic Hall 2010, ISBN 0-13-148203-3 - a completely worked-out SCEA assignment whose parts are in [1]; 11 pages. Note: Also in <a href=\"http://safaribooksonline.com/\">safaribooksonline.com</a>, where you can  get 10-days trial access allowing you to read up to 100 pages from not more than 10 books<br><br>[3] <a href=\"http://www.coderanch.com/forums/f-26/java-Architect-SCEA\">JavaRanch SCEA forum</a> - a really valuable source<br><br>[4] UML 2 and the Unified Process: Practical Object-Oriented Analysis and  Design (2nd Edition)<br><br>[5] Architecting Enterprise Solutions: Patterns for High-Capability  Internet-based Systems\r\n<h4>And even more resources</h4>\r\nthat you perhaps don't need and don't want to study (which I've done neither, I only looked into them here or there)\r\n<ul>\r\n\t<li>Pro Java EE 5 Performance Management and Optimization, Apress</li>\r\n\t<li><a href=\"www.sun.com/servers/midrange/pdfs/scalability-sizing-guide.pdf\">SUN SERVER SCALABILITY AND SIZING GUIDE</a></li>\r\n\t<li><a href=\"http://tomcat.apache.org/articles/performance.pdf\">Tomcat: So You Want High Performance</a></li>\r\n\t<li><a href=\"http://docs.hp.com/en/5992-4859/5992-4859.pdf\">HP OSMS: Tomcat Sizing Guide for HP ProLiant c-Class Blade Servers</a></li>\r\n\t<li><a href=\"http://www.docs.hp.com/en/5992-4100/5992-4100.pdf\">MySQL HA with HP</a></li>\r\n\t<li><a href=\"http://www.ibm.com/developerworks/opensource/library/os-perfbenchmk/index.html\">JBoss x WAS CE benchmark</a> and its preparation guide, 11/2009</li>\r\n\t<li><a href=\"http://blogs.msdn.com/b/gregleak/archive/2009/05/13/latest-websphere-7-and-net-benchmark-results-stir-debate.aspx\">Latest WebSphere 7 and .NET Benchmark Results Stir Debate</a></li>\r\n\t<li>Java EE application server benchmark SPECjAppServer (note: JOPS = jAppServer Operations Per Second): <a href=\"http://www.spec.org/jAppServer2004/results/jAppServer2004.html\">all results</a> (metric, # AS/DB nodes, #cores...), <a href=\"http://www.spec.org/jAppServer2004/results/res2009q3\">Sun HW+WebLogic+Oracle, 32 core</a>, <a href=\"http://www.spec.org/jAppServer2004/results/res2009q2/jAppServer2004-20090324-00129.html\">Glassfish, tomcat, MySQL 64b, 8 cores, 4 AS instances, 1 DB instance</a>, a blog regarding the benchmark of <a href=\"http://blogs.sun.com/tomdaly/entry/sun_pushing_price_performance_curve\">Solaris+Glassfish+Postgres</a> with links to how to scale of Postgres</li>\r\n\t<li>IBM: <a href=\"http://www-03.ibm.com/systems/bladecenter/resources/benchmarks/about/\">a list and description of various benchmarks</a> (see especially TPC-E, TPC-App, SPECjbb2005 - order processing app [DB in mem])</li>\r\n\t<li><a href=\"http://java.dzone.com/articles/introduction-jboss-cloud\">Introduction to JBoss Cloud</a></li>\r\n\t<li>Wikipedia - workstation and server CPU brands - <a href=\"http://en.wikipedia.org/wiki/Xeon\">Intel Xeon</a> and <a href=\"http://en.wikipedia.org/wiki/Opteron\">AMD Opteron</a> - evolution, individual processors, ... . Current popular server Opterons have speed mostly between cca 1.7 and 3.2 GHz, Xeon between 1.7 and 3.8 GHz (the continual popularity of 1.7 GHz as well as the history of the competition of the processors from this brands show that speed is not everything).</li>\r\n</ul>\r\n<h3>The risks and assumptions</h3>\r\nYou should have collected a list of risks and assumptions already during the design process. Most, if not all, application will share some risks common to all (enterprise) web application (security, performance etc.) but usually you will also have few specific ones. Select the three most likely and dangerous ones, decide, how to mitigate them.\r\n<h2>Step 3: The essay</h2>\r\nAt present you have to complete the essay before submitting the assignment, but you should do it only after actually finishing the assignment. That's because even though the questions are generic, the answers are closely related to your particular solution.<br><br><a href=\"https://www.suntrainingcatalogue.com/eduserv/client/loadCourse.do?coId=cz_CZ_CX-310-062&amp;coCourseCode=CX-310-062&amp;l=cz_CZ\">The  essay</a> consists of 8 questions and you have 90 minutes to answer  them, few sentences for each. For me the time was just right (though  usually I tend to finish well ahead of a limit :-)). If you are well  prepared, it is not too difficult. The best preparation for the essay is to consider\r\n<ol>\r\n\t<li>How and why you do meet the individual non-functional requirements (performance, security, ...)</li>\r\n\t<li>What were the individual technological choices you have done and the other possible alternatives and why you've rejected them. You want to be an architect so you must prove that you are able to come up with alternative solutions and select the best one based on sound arguments. Consider the choices pertaining to:\r\n<ol>\r\n\t<li>The non-functional requirements in your solution</li>\r\n\t<li>The communication with external systems</li>\r\n\t<li>The patterns that you applied</li>\r\n\t<li>Frameworks that you applied (even beyond the level of detail of the assignment deliverables, for  example what presentation framework you've selected)</li>\r\n</ol>\r\n</li>\r\n</ol>\r\nMost questions ask you what choice regarding a particular design issue you have made, what were the alternatives, and why you have rejected them. Some may ask also about the risks and mitigation strategies and what would you do if some non-functional requirement changes considerably (such as having few times more users than expected).<br><br>To give you a better idea of what is the essay like, I've made up two questions and answers pretty similar to what you might encounter.\r\n<h4>Example question 1</h4>\r\n<strong>Question</strong> What framework or technology have you chosen for the persistence layer? What alternatives did you consider and why have you rejected them?<br><br><strong>Answer</strong> I considered JPA, JDBC, MyBatis (being on a level of abstraction somewhere between JDBC and JPA), and a combination of JPA and JDBC. I've decided to use JPA for most of the application mostly for its ease of use and thus higher productivity and better maintainability and to use JDBC for the reporting module because it has to process large quantities of data and the JPA's overhead like conversion into objects would be too much while its benefits here are negligible. I've rejected MyBatis because the JPA's level of abstraction is more suitable and I don't need to have control over everything, also JPA is a standard and thus more people know it.\r\n<h4>Example question 2</h4>\r\n<strong>Question</strong> The customer decides to expand into China and thus the application's availability must be close to 24/7 instead of 8am - 5 pm Pacific Time because the Chinese work non-stop. How would you handle that? Justify your decision.<br><br><strong>Answer</strong> Each element is already redundant and therefore there is no single point of failure, however I'd add another application server node to make sure that the application can continue normally if one of the ASs fails (if there were only two, the remaining would suddenly need to handle 200% load, which could easily crash it). I'd also extract the business rules hardcoded in the Java code of the DiscountComputation module and move them into the database (for example in the form of Groovy code snippets) so that they can be changed without restarting the application, because currently the frequent rules changes are the main reason for restarts.\r\n<h2>Conclusion</h2>\r\nThe exam takes time and requires some experience, but it is a good motivation and opportunity to learn, both theoretically and practically. It doesn't prove that you are an architect, but it shows, that you know enough to be able to communicate with one and perhaps once become a real architect, and of course it also shows that you are a determined person :-)",
  "excerpt": ""
 },
 {
  "title": "An encrypted backup of a disk/partition to a Samba share with Clonezilla",
  "published": "2010-08-10 11:07:59",
  "postType": "post",
  "slug": "/2010/08/10/disk-backup-with-clonezilla/",
  "status": "publish",
  "tags": [
   "backup",
   "encryption",
   "linux"
  ],
  "categories": [
   "Tools"
  ],
  "content": "You will learn how to customize <a href=\"http://clonezilla.org/\">Clonezilla</a> Live (v. 1.2.5-24) for an easy backup of a partition (or a disk) to an encrypted file stored on a remote Samba server and how to test the backup by restoring it to a VMware virtual machine. We will few scripts to simplify the task, including a custom Clonezilla startup script to mount a TrueCrypt volume on a Samba share.<br><br><strong>Content</strong>: <a href=\"#What-is-Clonezilla\">What is Clonezilla?</a> | <a href=\"#Customizing-Clonezilla\">Preparing Clonezilla for a custom backup</a> | <a href=\"#Backup-and-restore\">Backup</a> | <a href=\"#Encryption-of-the-backup\">Encryption of the backup</a> | <a href=\"#Testing-the-backup\">Restoration and testing of the backup</a> | <a href=\"#The-complete-backup-encrypt-test-cycle\">The complete backup - encrypt - test cycle</a> | <a href=\"#Summary\">Summary</a><br><br>PS: If you are scared by the length of this post then read only \"The complete backup – encrypt – test cycle\" :-)<br><br><strong>Update 2010-09-23</strong>: Added \"The complete backup – encrypt – test cycle\", little reorganization.\r\n<h2 id=\"What-is-Clonezilla\">What is Clonezilla?</h2>\r\nClonezilla is a live Linux distribution containing tools for performing backup and restoration of disks and partitions. It is basically a collection of various open-source tools such as partimage and gzip and custom scripts that \"glue\" them together to create a single backup tool driven by a wizard-like user interface. You install it to a CD or USB flash disk, boot from that medium, answer few questions and a backup or a restoration may start.<br><br><!--more-->The normal mode of operation of Clonezilla is:\r\n<ol>\r\n\t<li>You boot from the Clonezilla live CD or USB (<a title=\"Screenshot: clonezilla-live-boot-menu\" href=\"http://clonezilla.org/screenshot/?in_path=/00_Clonezilla#02_clonezilla-live-boot-menu-gra.png\">screenshot</a>)</li>\r\n\t<li>(Network connection may be or may be not set up based on the kernel boot parameters.)</li>\r\n\t<li>The Clonezilla script specified in the kernel boot parameters (default: ocs-live-general) is executed; it does a few things:\r\n<ol>\r\n\t<li>It asks what to do (<a title=\"Screenshot: Start Clonezilla or console?\" href=\"http://clonezilla.org/screenshot/?op=show&amp;filepath=album//00_Clonezilla/06_clonezilla-live-start-ocs-or-shell.png\">screenshot</a>): start Clonezilla (the wizard) or enter command line; choose to start Clonezilla</li>\r\n\t<li>Use an image file or a physical partition (<a href=\"http://clonezilla.org/screenshot/?op=show&amp;filepath=album//00_Clonezilla/07_clonezilla-live-image-or-onthefly.png\">screenshot</a>) as the target/source of the backup/restore?</li>\r\n\t<li>Next you are asked where to store the backup (<a href=\"http://clonezilla.org/screenshot/?op=show&amp;filepath=album//00_Clonezilla/08_prep-ocsroot.png\">screenshot</a>).  The target device must be mounted as /home/partimag/. You can select a  local disk (such as a portable external disk connected via USB) or  select to enter the command line to mount something (e.g. a remote Samba  folder) manually.</li>\r\n\t<li>You are asked about what to do (<a href=\"http://clonezilla.org/screenshot/?op=show&amp;filepath=album//00_Clonezilla/09_ocs-sr-x.png\">screenshot</a>): backup a disk, backup selected partition(s), restore a disk, restore partition(s), etc.</li>\r\n\t<li>You can select either Beginner or Advanced mode; the latter let you choose the compression algorithm and modify other options.</li>\r\n\t<li>Next, when doing a backup, you must choose the disk or partition to back up.</li>\r\n\t<li>Finally you can choose what to do when the operation is finished, such as turning the computer off, rebooting or nothing.</li>\r\n\t<li>After few confirmations the backup starts. The Clonezilla command created based on your choices is shown and also stored to a temporary file - you may want to run it directly from the command line the next time without going through the wizard (though you will still need to mount the target device).</li>\r\n</ol>\r\n</li>\r\n\t<li>Before, during, or after the backup you can enter the command line to do anything you need.</li>\r\n</ol>\r\nTo become root in the command line execute \"sudo su -\".\r\n<h3>Selected features</h3>\r\n<ul>\r\n\t<li>Backup the whole disk or only a selected partition(s)</li>\r\n\t<li>Compression of the backup</li>\r\n\t<li>Works on the raw disk level, i.e. below the filesystem level</li>\r\n\t<li>Only backs up the used blocks on the source disk/partition, unused space of the disk doesn't add to the backup size</li>\r\n\t<li>Incremental backup is not supported</li>\r\n</ul>\r\n<h3>Limitations</h3>\r\n<ul>\r\n\t<li>Cannot restore to a disk smaller than the backed-up disk even if the data on the original disk are smaller than the target disk (Actually a limitation of partimag.)</li>\r\n\t<li>Doesn't support encryption - but that can be added externally, see below</li>\r\n\t<li>Cannot restore to a partition of a different number (sda1 x sda2) or on a different disk (sda1 x sdb1) - but we will learn how to work around that</li>\r\n</ul>\r\n<h2 id=\"Customizing-Clonezilla\">Preparing Clonezilla for a custom backup</h2>\r\nFirst of all, download the USB flash disk version of Clonezilla Live (easier to customize), i.e. the .zip version (mine was clonezilla-live-1.2.5-24-i686.zip, with clonezilla 2.3.something installed) and unpack it to a USB flash disk (USB stick).<br><br>For setup and testing it's comfortable to be able to run Clonezilla in a VMware. My blog <a href=\"/2010/06/10/booting-from-a-usb-stick-in-vmware-player/\">Booting from a USB stick in VMware Player</a> explains how to run an operating system installed on a USB flash disk in VMware, which doesn't support that out of the box.<br><br>The customizations:\r\n<ul>\r\n\t<li><strong>Adding custom files</strong>: Most files in the Clonezilla distribution are read-only and any changes to them are ignored. There is a single folder where changes are persistent: &lt;USB stick with Clonezilla&gt;/live/, which is accessible as /live/image/live/ from within Clonezilla Live when it's running.\r\n<ul>\r\n\t<li>Add here the necessary files: truecrypt (see <em>Encryption of the backup</em> - <em>TrueCrypt</em> below), scripts jh-my-mounts, jh-ocs-live-general (shown below)</li>\r\n</ul>\r\n</li>\r\n\t<li><strong>Customizing Clonezilla boot menu</strong> in /syslinux/syslinux.cfg (shown below): We will add our own entries to the boot menu with customized kernel startup parameters to set our prefered  default values for some options not to be asked for them each time, to  tune the environment (switch numlock on etc.), and to tell Clonezilla  what script it should run instead of its default one. Points of interest:\r\n<ul>\r\n\t<li>Common customized boot parameters:\r\n<ul>\r\n\t<li><code>ocs_numlk=on</code> - enable Num Lock upon startup</li>\r\n\t<li><code>ocs_live_keymap=\"NONE\" ocs_lang=\"en_US.UTF-8\"</code> - provide values for these options so that Clonezilla doesn't ask for them</li>\r\n\t<li><code>vga=normal</code> - on one PC I had some problems with the graphics in Clonezilla (likely something between framebuffer and NVidia), this setting resolved that</li>\r\n</ul>\r\n</li>\r\n\t<li>The boot configuration \"<em>JH Clonezilla for Samba (Safe graphic)</em>\"\r\n<ul>\r\n\t<li>Networking is enabled (the default), Clonezilla will try to connect using DHCP</li>\r\n\t<li><code>ocs_live_run=\"/live/image/live/jh-ocs-live-general\"</code> -  this script will be run upon startup instead of the default ocs-live-general; the main change being that when you select Start Clonezilla then it will mount the preconfigured Samba share as /mnt/backupbytovka/ and the latest TrueCrypt volume on it (if any) as /home/partimag using the functions from jh-my_mounts.sh</li>\r\n</ul>\r\n</li>\r\n\t<li>The boot configuration \"<em>JH Clonezilla offline (Safe graphic)</em>\"\r\n<ul>\r\n\t<li><code>ip=frommedia</code> - disables network</li>\r\n</ul>\r\n</li>\r\n\t<li>Important: don't forget to comment out MENU DEFAULT for the original Clonezilla entry by inserting # in front of it</li>\r\n</ul>\r\n</li>\r\n</ul>\r\n<h3>Custom(ized) files</h3>\r\n<h4>Customized syslinux/syslinux.cfg:</h4>\r\n<ul>\r\n\t<li>Only the added/modified part displayed</li>\r\n\t<li>We add two entries and comment out an existing entry's line \"MENU DEFAULT\" by prepending it with #</li>\r\n</ul>\r\n<pre><code><br><br>...\r\nlabel Clonezilla live without framebuffer\r\n MENU DEFAULT\r\n MENU LABEL JH Clonezilla for Samba (Safe graphic)\r\n kernel /live/vmlinuz\r\n append initrd=/live/initrd.img boot=live ocs_numlk=on noswap nolocales edd=on noprompt ocs_live_run=&quot;/live/image/live/jh-ocs-live-general&quot; ocs_live_extra_param=&quot;&quot; ocs_live_keymap=&quot;NONE&quot; ocs_live_batch=&quot;no&quot; ocs_lang=&quot;en_US.UTF-8&quot; vga=normal nomodeset nosplash\r\n TEXT HELP\r\n Disable console frame buffer support\r\n ENDTEXT<br><br>label Clonezilla live without framebuffer\r\n MENU DEFAULT\r\n MENU LABEL JH Clonezilla offline (Safe graphic)\r\n kernel /live/vmlinuz\r\n append initrd=/live/initrd.img boot=live ip=frommedia   ocs_numlk=on noswap nolocales edd=on noprompt ocs_live_run=&quot;ocs-live-general&quot; ocs_live_extra_param=&quot;&quot; ocs_live_keymap=&quot;NONE&quot; ocs_live_batch=&quot;no&quot; ocs_lang=&quot;en_US.UTF-8&quot; vga=normal nomodeset nosplash\r\n TEXT HELP\r\n Disable console frame buffer support\r\n ENDTEXT<br><br># Since no network setting in the squashfs image, therefore if ip=frommedia, the network is disabled. That's what we want.\r\nlabel Clonezilla live\r\n # MENU DEFAULT\r\n # MENU HIDE\r\n...<br><br></code></pre>\r\n<h4>Custom Clonezilla script live/jh-ocs-live-general:</h4>\r\nThis script is run by Clonezilla when it boots and displays a menu-driven wizard. The modified parts are marked with ### JHn BEGIN ... ### JHn END. The important changes are:\r\n<ol>\r\n\t<li>A script with helper functions is sourced</li>\r\n\t<li>When Start Clonezilla is invoked, the hardwired Samba share is mounted</li>\r\n\t<li>Then the latest TrueCrypt volume on the Samba share is mounted to /home/partimag</li>\r\n\t<li>When Clonezilla finishes the TrueCrypt volume and Samba share will be unmounted.</li>\r\n</ol>\r\n<pre><code>\r\n#!/bin/bash\r\n# Author: Steven Shiau\r\n# License: GPL\r\n# Description: Program to start saving or restoring image in Clonezilla live.<br><br># Load DRBL setting and functions\r\nDRBL_SCRIPT_PATH=&quot;${DRBL_SCRIPT_PATH:-/opt/drbl/}&quot;<br><br>. $DRBL_SCRIPT_PATH/sbin/drbl-conf-functions\r\n. $DRBL_SCRIPT_PATH/conf/drbl-ocs.conf\r\n. $DRBL_SCRIPT_PATH/sbin/ocs-functions<br><br># load the setting for clonezilla live.\r\n[ -e /etc/ocs/ocs-live.conf ] &amp;&amp; . /etc/ocs/ocs-live.conf<br><br># Get the live media mount point.\r\nget_live_media_mnt_point<br><br># prepare the clonezilla live environment.\r\nocs-live-env-prepare<br><br>### JH1 BEGIN - mount my mounts [displays after the start clonezilla/enter shell dialog]\r\n. /live/image/live/jh-my_mounts.sh\r\necho &quot;&gt;&gt;&gt;JH: Mounting Samba...&quot;\r\n# mount_remote_samba2backupbytovka\r\nmount_remote_samba2backupbytovka\r\necho &quot;&gt;&gt;&gt;JH: Going to mount TrueCrypt, provide its password when asked...&quot;\r\nmount_truecrypt\r\n### JH1 END<br><br># Do not ask powerer/reboot/choose (-p) in ocs-sr,  just use &quot;-p true&quot;. Since it might be in bterm, and Debian live &quot;Press Enter&quot; message when poweroff/shutdown might be coverd by bterm and user will not have any idea what's happening after choose poweroff/reboot.\r\n# ocs_lang and ocs_live_extra_param are loaded from /etc/ocs/ocs-live.conf\r\n# &quot;-n&quot; was added since we will run show-general-ocs-live-prompt after command clonezilla\r\nclonezilla -l $ocs_lang -p true -n $ocs_live_extra_param<br><br>### JH2 BEGIN - umount my mounts...\r\necho &quot;&gt;&gt;&gt;JH: Umounting Truecrypt and Samba drives...&quot;\r\numount_all\r\n### JH2 END<br><br># Show prompt\r\nshow-general-ocs-live-prompt\r\n</code></pre>\r\n<h4>Helper mount script live/jh-my_mounts.sh:</h4>\r\nNoteworthy: we use whiptail to show a dialog that asks the user for his/her TrueCrypt volume password.<br><br><pre><code>\r\n#!/bin/bash<br><br>##\r\n## MOUNT THE ENCRYPTED SAMBA FOLDER FOR STORING BACKUPS\r\n##\r\n## Run as root. You may want to add it to the boot parameters as:\r\n## ocs_prerun=&quot;/live/image/live/mount_backupbytovka.sh&quot;<br><br># 1. Mount the hardwired Samba share to the given mount point [default: /mnt/backupbytovka]\r\nmount_remote_samba2backupbytovka() {\r\n\tif [ ! -z &quot;$1&quot; ]; then mpoint=&quot;$1&quot;; else mpoint=/mnt/backupbytovka; fi\r\n\tif [ ! -e &quot;$mpoint&quot; ]; then sudo mkdir &quot;$mpoint&quot; || die &quot;Failed to create the mountpoint '$mpoint'&quot;; fi<br><br>\tsudo mount -t cifs -o username=&quot;bob&quot;,password=&quot;secret&quot; &quot;//172.24.4.77/bob&quot; $mpoint || die &quot;samba mount failed for mount point '$mpoint'&quot;\r\n}<br><br>mnt_samba() {\r\n\tmount_remote_samba2backupbytovka &quot;$@&quot;\r\n}<br><br># 2. Mount TrueCrypt the most recent TC volume in /mnt/backupbytovka to the given mount point [default: /home/partimag]\r\nmount_truecrypt() {\r\n\t# IN PARAMS\r\n\tif [ ! -z &quot;$1&quot; ]; then mpoint=&quot;$1&quot;; else mpoint=/home/partimag; fi\r\n\tif [ ! -e &quot;$mpoint&quot; ]; then die &quot;The mountpoint '$mpoint' doesn't exist!&quot;; fi\r\n\tif [ ! -z &quot;$2&quot; ]; then tcVolumeFolder=&quot;$2&quot;; else tcVolumeFolder=/mnt/backupbytovka; fi\r\n\tif [ ! -d &quot;$tcVolumeFolder&quot; ]; then die &quot;The folder '$tcVolumeFolder', expected to containt the TrueCrypt volume, doesn't exist!&quot;; fi<br><br>\ttcVolume=$(ls -1 -t &quot;$tcVolumeFolder&quot;/*.tc | head -n1)\r\n\tif [ ! -f &quot;$tcVolume&quot; ]; then die &quot;The Truecrypt volume '$tcVolume' (I looked for *.tc in $tcVolumeFolder) doesn't exist.&quot;; fi<br><br>\techo &quot;&gt;&gt;&gt;JH: Going to mount Truecrypt, provide its password when asked...&quot;\r\n\ttruecryptPsw=$(whiptail --passwordbox &quot;Truecrypt Password&quot; 10 30 3&gt;&amp;1 1&gt;&amp;2 2&gt;&amp;3)\r\n\t# Mount a volume prompting for nothing (no password, keyfile, whether to protect a hidden part.):\r\n\t# (Notice that specifying the psw on the command line isn't secure as it can be seen e.g. in the output of ps)\r\n\t/live/image/live/truecrypt/truecrypt -t -k &quot;&quot; --protect-hidden=no --password=&quot;$truecryptPsw&quot; &quot;$tcVolume&quot; &quot;$mpoint&quot;\r\n}\r\numount_truecrypt() {\r\n\t# Dismount all mounted TC volumes:\r\n\t/live/image/live/truecrypt/truecrypt -t -d\r\n}<br><br>die() {\r\n\techo &quot;FATAL FAILURE: $1&quot;\r\n\texit 1\r\n}<br><br># 3. END\r\numount_all() {\r\n\tumount_truecrypt  || echo &quot;WARN: Truecrypt umount failed (/home/partimag)&quot;\r\n\tsudo umount /mnt/backupbytovka  || echo &quot;WARN: Samba umount failed (/mnt/backupbytovka)&quot;\r\n}\r\n</code></pre>\r\n<h3>About Clonezilla file system customization</h3>\r\nAs  mentioned, with the exception of the folder live/, the Clonezilla  filesystem is read-only. During boot it is extracted from  live/filesystem.squashfs. It is <a href=\"http://drbl.sourceforge.net/faq/fine-print.php?fullmode=1&amp;path=./2_System/81_add_prog_in_filesystem-squashfs.faq\">possible to modify this Squash file system used by Clonezilla</a> but I found it rather cumbersome and difficult and therefore recommend  to avoid it. (You need to install some tools with the correct versions,  \"unsquash\" the filesystem, modify it, \"squash\" it again, and use the  outcome file to replace the original one.)\r\n<h2 id=\"Backup-and-restore\">Backup</h2>\r\nRestart your PC, boot from the USB flash disk with Clonezilla Live and  start the Clonezilla program - or your customized script - to perform  the backup.<br><br>Notice that by default Clonezilla splits the backup files into 2GB pieces, which  is very useful because we will store them to a TrueCrypt volume with  the FAT file system, which can't handle larger files.\r\n<h3>Back up to a TrueCrypt volume on a Samba share or to an external disk?</h3>\r\nIf your space is limited you may want to do the backup in one step by storing it directly into a (new or existing) TrueCrypt volume on a Samba share. However I prefer first to create an unencrypted backup on an external disk connected directly to the computer and only then create a TrueCrypt volume on the share and move the backup there. That way the several hours long backup can't be interrupted by a network/Samba/TrueCrypt failure and also I know exactly how large TC volume I need to create to hold the backup.<br><br>Therefore I use the boot configuration \"JH Clonezilla offline (Safe graphic)\" to back-up to a local external disk and the boot config. \"JH Clonezilla for Samba (Safe graphic)\" to either back-up to Samba or to restore the encrypted remote backup.\r\n<h3>Compression - observations</h3>\r\nClonezilla offers several compression algorithms differing in speed and compression ratio in the advanced mode. I've tried three of them:\r\n<ul>\r\n\t<li>gzip: ~ 350MB/min, compressed to ~ 70% (ex.: 108 to 77GB, done in ~ 3hrs)</li>\r\n\t<li>lzo: ~ 650MB/m, compressed to 86%</li>\r\n\t<li>lzma? ~ the slowest compression is indeed slower by one order (few tens of MB/m)</li>\r\n</ul>\r\nThe speed is from my Intel Core 2 Duo (2 cores at 2.1GHz) with a 5400 disk and may be quite different based on the power of your CPU and perhaps also disk speed.\r\n<h2 id=\"Encryption-of-the-backup\">Encryption of the backup</h2>\r\nClonezilla doesn't support encryption of the backup but you can use an external solution such as an encrypted volume or filesystem. I've considered <a href=\"https://help.ubuntu.com/9.04/serverguide/C/ecryptfs.html\">eCryptfs</a>, which I normally use under Linux, and TrueCrypt.<br><br>Personally I'd prefer eCryptfs because it encrypts each file  individually and you don't need to create a container of a fixed size  but it only works under Linux and is more difficult to install (you need to include a support in the kernel etc.) and when I tried it the backup to an eCryptfs folder failed with the error \"NT_STATUS_ACCESS_DENIED -&gt; CIFS VFS send error in read = -13\". I guess there is some issue between eCryptfs and Samba. Therefore I've chosen TrueCrypt, which worked well.\r\n<h3>TrueCrypt</h3>\r\n<a href=\"http://www.truecrypt.org/\">Truecrypt</a> makes it possible to create an encrypted \"container\", i.e. an encrypted file that can contain a filesystem and be mounted as a physical volume.<br><br>Advantages of truecrypt: mature and stable, cross-platform, all that is needed is a single binary.<br><br>Disadvantages: The size of the container must be specified in advance and be large enough to hold all the content, manipulation with such a large file is difficult. Under Linux it has only a command-line interface.<br><br>Working with TrueCrypt:\r\n<ul>\r\n\t<li>Download Truecrypt 6.3a, the console-only version</li>\r\n\t<li>Run the extracted file and select not to install but to extract  .tar.gz; unpack it and move the bin/truecrypt to  /live/truecrypt/truecrypt</li>\r\n\t<li>Create an encrypted container on the Samba share either using the wizard (truecrypt -c mycontainer.tc) or by specifying all options on the command line\r\n<ul>\r\n\t<li>During the process, select the defaults (AES, RIPEMD-160, fs FAT), enter 320 random characters</li>\r\n\t<li>Specifying all the options on the command line (in bash use $[77*1024**3] to convert 77GB to bytes):\r\n<pre><code> truecrypt-console-6.3a --volume-type=normal --size=[size in  bytes] --encryption=AES --hash=RIPEMD-160 --filesystem=FAT -k &quot;&quot; -c truecryptvol.empty.tc</code></pre></li>\r\n\t<li>Creating a container of the size 110GB will take a couple of hours  based on the network/HDD speed (4h with 6.8MB/s) - TC must create and  write random data all over the disk</li>\r\n\t<li>Note: According to one source, <a href=\"http://homes.esat.kuleuven.be/~bosselae/ripemd160.html#Speed\">SHA-1 is  slightly faster than RIPEMD</a> (~ by 1/6 under ideal conditions</li>\r\n\t<li>Note: You can of course choose other than the default options but I prefered to stick with them so that I don't need to remember what options I've chosen</li>\r\n</ul>\r\n</li>\r\n\t<li>Mount the volume: <em>truecrypt truecryptvol.tc /home/partimag</em>\r\n<ul>\r\n\t<li>You'll be asked first for the truecrypt container password (\"Enter password for\r\ntruecryptvol.tc:\") and then for your user or administrator password (\"Enter your user password or administrator password:\"), unless running as root, because it's required to use/mount the loop device or so something.</li>\r\n</ul>\r\n</li>\r\n\t<li>Unmount all truecrypt volumes: <em>truecrypt -d</em></li>\r\n</ul>\r\nLater on we will see a script that helps to simplify the creation of a new volume with a sufficient size to put a backup image into it.\r\n<h4>TrueCrypt Linux command-line options</h4>\r\nThe official documentation only describes rather limited Windows command-line options. Execute  <em>truecrypt -h</em> to learn about the options available under Linux (or see TrueCrypt's Main/CommandLineInterface.cpp).\r\n<h2 id=\"Testing-the-backup\">Restoration and testing of the backup</h2>\r\n<h3>How to restore to a different disk and/or partition</h3>\r\nNormally you can only restore to the same disk or partition. To go around this limitation you need to modify the backup files:\r\n<ol>\r\n\t<li>To restore to a <strong>different disk</strong>, use (from within Clonezilla) the command  <em>cnvt-ocs-dev</em> to rename the backup files (you could also do it manually but this is a supported way). Example: <pre><code>cnvt-ocs-dev 2010-06-15-16-img sda sdb</code></pre></li>\r\n\t<li>To restore to a <strong>different partition</strong> you must change the partition number(s) manually by renaming for instance sda1.* to sda2.*:\r\n<pre><code>for BKP in $(ls sda1.*); do BKPNEW=$(echo $BKP | sed &quot;s/sda1/sda2/&quot;); mv $BKP $BKPNEW; done</code></pre></li>\r\n</ol>\r\nIf you try to restore a partition image to a different partition,  such as the backup of sda2 to sda1 then you will get an error like:<br><br><pre><code>Failed to restore partition image file /home/partimag/2010-06-15-16-img/sda1/* to /dev/sda1! Maybe this image is corrupt!</code></pre><br><br>Resources: The discussion <a href=\"http://sourceforge.net/projects/clonezilla/forums/forum/663168/topic/3657440\">Restore partition to new harddrive</a>, another <a href=\"http://sourceforge.net/projects/clonezilla/forums/forum/663168/topic/2121018\">related forum question</a>, and a <a href=\"http://drbl.sourceforge.net/one4all/techrpt.php?c=cnvt-ocs-dev\">description of the cnvt-ocs-dev</a> utility.\r\n<h3 id=\"Manualrestoreofthebackup\">Manual restore of the backup</h3>\r\nThere are several cases when you may prefer to have full control over the restoration process, for example if <a href=\"https://bugs.launchpad.net/ubuntu/+source/linux-source-2.6.20/+bug/88746\">Clonezilla's kernel causes the source/target USB disk to get disconnected</a> before it finishes (\"usb 1-1: reset high speed USB device using ehci_hcd and address 2\"). The process is well described in the Clonezilla FAQ <a href=\"http://drbl.org/faq/fine-print.php?path=./2_System/68_manually_partclone_restore.faq#68_manually_partclone_restore.faq\">How to restore backup manually into a mountable .img file</a> (if partclone was used for the backup; it's <a href=\"http://drbl.org/faq/fine-print.php?path=./2_System/43_read_ntfsimg_content.faq#43_read_ntfsimg_content.faq\">similar for ntfsclone</a> and thate are also <a href=\"http://www.idealworldinc.com/partclone-utils/\">partclone-utils</a> that can read the image directly though you'll likely need to uncompress it  anyway ) - you need to join all the parts (.aa, .ab etc.) via cat and pass them to  the proper un-archiver and either store the complete uncompressed image or pass it directly tto the cloning tool for restoration.\r\n<h4>Decompression</h4>\r\nYou need to join the backup parts (.aa, .ab, up to perhaps, .zz) and uncompress them. You can recognize the compression algorithm from the backup part name, for example sda1.ext4-ptcl-img.lzo.aa was copressed wih lzo, or by running the command file on the first part: file sda1.ext4-ptcl-img.lzo.aa =&gt; \"sda1.ext4-ptcl-img.lzo.aa: lzop compressed data - version 1.020, LZO1X-1, os: Unix\".<br><br><pre><code>cat sda1.ext4-ptcl-img.lzo.* | lzop -d -vvv &gt; sda1.ext4-ptcl-img</code></pre><br><br>Few notes\r\n<ul>\r\n\t<li>I had to rename *.aa to *.a1 - for some reason bash didn't list is as the first file.</li>\r\n\t<li>To me it took ~ 13h to decompress an lzo-compressed image of the  output  size 197GB on 2-core Intel Atom 230 (1.6GHz) PC while reading   from&amp;writting to an external 5400 RPM disk</li>\r\n</ul>\r\n<h4>Restoration</h4>\r\nYou can recognize the tool used to create the image from its name, for example the name contains \"ptcl\" then Partclone was used to create it.<br><br>To restore the uncompressed image with partclone:<br><br><pre><code>sudo partclone.restore --restore_row_file -C -s sda1.ext4-ptcl-img -o sda1.ext4-ptcl-restored2.img</code></pre>\r\n<ul>\r\n\t<li>To me it took &gt; 14h to restore  my image of a device with the size 282GB (70GB of that free) on 2-core Intel Atom 230 (1.6GHz) PC while reading    from&amp;writting to an external 5400 RPM disk</li>\r\n\t<li>The flag<strong> --restore_row_file</strong>, available since Partclone 0.2.16, is essential if you want to mount the image and avoid the following:\r\n<pre><code>\r\nshell$ mount -t ext4 -o loop,nosuid,nodev /media/mydisk/sda1.ext4-ptcl-restored.img /mnt\r\nmount: wrong fs type, bad option, bad superblock on /dev/loop0,\r\n       missing codepage or helper program, or other error\r\n...\r\nshell$ dmesg | tail\r\nEXT4-fs (loop0): bad geometry: block count 16544941 exceeds size of device (16257568 blocks)\r\n</code></pre><br><br>Many thanks to senden9 (Stefano Probst?) <a href=\"http://forum.ubuntuusers.de/topic/daten-aus-einem-clonzilla-image-holen/#post-2742750\">for finding this solution</a>!!!</li>\r\n</ul>\r\n<h4>Access</h4>\r\nTo access the content of the restored image:<br><br><pre><code>sudo mount -t ext4 -o loop,nosuid,nodev /media/mydisk/sda1.ext4-ptcl-restored.img /mnt</code></pre>\r\n<h4>Booting from the restored image with VMWare</h4>\r\n<strong>TBD</strong>\r\n<h3>Testing by restoring to VMWare</h3>\r\nTo test the backup, we will restore it to a virtual harddisk of a VMware virtual machine. It will be simpler if the disk name (such as sda or sdb) and the partition numbers match those of the backup. If not, you will need to modify the backup to match the name and number(s) as described above.<br><br>0. Preparation\r\n<ul>\r\n\t<li>Add a virtual disk to a new or an existing VMware machine; it must be at least as large as the backed-up partition. I think it is unnecessary to allocate all the space immediately because the main bottleneck of the restoration will be the network and not the dynamic expansion of the harddisk file. Also, it may take few hours to create.</li>\r\n</ul>\r\nI. Restore the backup\r\n<ul>\r\n\t<li>Run the vmware machine with that disk, booting from the USB stick with Clonezilla Live (see <a href=\"/2010/06/10/booting-from-a-usb-stick-in-vmware-player/\">how to boot from an USB in VMware</a>)\r\n<ul>\r\n\t<li>In the Clonezilla boot menu, choose the option that starts networking (JH Clonezilla for Samba)</li>\r\n</ul>\r\n</li>\r\n\t<li>Mount the volume holding the backup as /home/partimag; for a TrueCrypt volume on a Samba share:\r\n<ul>\r\n\t<li><strong>Start Clonezilla</strong>, select the <strong>device-image</strong> mode, on the screen \"Mount Clonezilla image directory\" select \"<strong>enter_shell</strong>\"</li>\r\n\t<li>Thanks to the customized Clonezilla script, the Samba share should be mounted as /mnt/backupbytovka when you select to Start Clonezilla. You can also do it manually: <pre><code>cd /live/image/live; . jh-my_mounts.sh; mnt_samba</code></pre></li>\r\n\t<li>Mount the most recent TrueCrypt volume on the share to /home/partimag:\r\n<pre><code>cd /live/image/live; . jh-my_mounts.sh; mount_truecrypt</code></pre><br><br>(you will be asked for a TC password)</li>\r\n\t<li>Verify the backup: ls /home/partimag/ =&gt; should contain files like sda2.ext3-ptcl-img.gz.aa, .ab etc.</li>\r\n\t<li>Execute 'exit' twice to get back to the Clonezilla dialog</li>\r\n</ul>\r\n</li>\r\n\t<li>Use <strong>fdisk to create a partition</strong> on the new large virtual disk for the backup restoration (you may want to do this and make a copy of the disk for future tests)\r\n<ul>\r\n\t<li>You may want to create some small partitions first so that the actual target partition has the same number as the backed-up partition to avoid the need to adjust the backup</li>\r\n\t<li>To find the right disk, as root: # lsscsi - look for lines like \"[...] disk VMWare, VMware Virtual S 1.0 /dev/sda\"; use fdisk -l  to find out the disk size, which should be enough to recognize the right one</li>\r\n\t<li>Execute e.g. fdisk /dev/sdb and then\r\n<ul>\r\n\t<li>Execute the commands 'c', 'u' as suggested by fdisk</li>\r\n\t<li>Create a partition with 'n' (select p as primary, the part. nr. 1, size as desired, ...) ...</li>\r\n\t<li>Make the partition bootable with 'a'</li>\r\n\t<li>Finally store the configuration with 'w'</li>\r\n</ul>\r\n</li>\r\n\t<li>If the disk name differs from the backup source disk, modify the backup using cnvt-ocs-dev as described above</li>\r\n</ul>\r\n</li>\r\n\t<li>Use clonezilla to restore to the disk (Example duration - estim. time &gt; 6h with 290MB/min, i.e. &lt;5MB/s)</li>\r\n</ul>\r\nII. Verify the restored backup\r\n<ul>\r\n\t<li>Restart VMware and when booting press Esc to display the Boot menu (you may want to <a href=\"http://www.howtogeek.com/howto/16876/how-to-increase-the-vmware-boot-screen-delay/\">increase the boot screen delay</a> to have enough time for that). You should be able to select a boot disk here but I wasn't able to expand the Hard Drive section =&gt; select &lt;Enter Setup&gt;  and on the Boot tab move the Hard Drive with the restored backup to the first place, F10 to save and boot from it.</li>\r\n</ul>\r\n<h2 id=\"The-complete-backup-encrypt-test-cycle\">The complete backup - encrypt - test cycle</h2>\r\nTo sum it up, this is how I proceed with my backups:\r\n<h3>1. Backup to a localy mounted flash disk</h3>\r\n<ol>\r\n\t<li>Boot Clonezilla in the mode \"JH Clonezilla offline (Safe graphic)\"</li>\r\n\t<li>Backup a partition (sda2) to a localy mounted flash disk:\r\n<ol>\r\n\t<li>Run the Clonezilla user interface (UI) and instruct it to mount the flash disk as the image storage</li>\r\n\t<li>Either continue with the UI or quit it and run manually the command saved from the previous run, in my case (slightly improved):\r\n<pre><code>/opt/drbl/sbin/ocs-sr -q2 -c -j2 -z1 -i 2000 -p true saveparts $(date &quot;+%Y-%m-%d-%H&quot;)-img sda2</code></pre></li>\r\n</ol>\r\n</li>\r\n</ol>\r\n<h3>2. Move the backup image to a new remote TrueCrypt volume</h3>\r\n<ol>\r\n\t<li>Boot your computer normally and run a terminal (of course you could do it from Clonezilla Live too)</li>\r\n\t<li>Start bash inside bash for further operations (the functions call <em>exit</em> upon failure and would thus close the terminal window)</li>\r\n\t<li>Mount the remote Samba folder:\r\n<pre><code>$ source &lt;Clonezilla USB&gt;/live/jh-my_mounts.sh; mnt_samba</code></pre></li>\r\n\t<li>Create a TrueCrypt volume on it (for me this takes couple of hours, such as 5-6h for 90GB):\r\n<pre><code>$ &lt;Clonezilla USB&gt;live/truecrypt/tc-create-volume-on-samba.sh &lt;size in GB or path to the Clonezilla image folder&gt;</code></pre></li>\r\n\t<li>Mount the TC volume:\r\n<pre><code>$ mkdir /tmp/tcmount; mount_truecrypt /tmp/tcmount</code></pre></li>\r\n\t<li>Move the backup image folder into the volume:\r\n<pre><code>$ mv &lt;Clonezilla image folder&gt; /tmp/tcmount/</code></pre></li>\r\n\t<li>Umount TrueCrypt and Samba:\r\n<pre><code>$ umount_all</code></pre></li>\r\n</ol>\r\nNote: The functions mnt_samba, mount_truecrypt, umount_all are defined in &lt;Clonezilla USB&gt;/live/jh-my_mounts.sh.<br><br>The script live/truecrypt/<strong>tc-create-volume-on-samba.sh</strong>:<br><br><pre><code>\r\n#!/bin/bash\r\n## Create a new TrueCrypt volume on an already mounted Samba share\r\n## with size either given or determined from the size of a folder given<br><br>die() {\r\n\techo &quot;FATAL FAILURE: $1&quot;\r\n\texit 1\r\n}<br><br>## CHECK INPUTS\r\nif [ $# -ne 1 ]; then\r\n\tdie &quot;Usage: $0 &lt;size in GB or a path to a Clonezilla image folder&gt;&quot;\r\nfi<br><br>SIZE_PARAM=&quot;$1&quot;\r\nif [ &quot;$(echo '$SIZE_PARAM' | grep &quot;^[ [:digit:] ]*$&quot;)&quot; ]\r\nthen\r\n\tSIZE_GB=$SIZE_PARAM\r\n\techo &quot;Volume size source: size in GB specified directly&quot;\r\nelse\r\n\tif [ -d &quot;$SIZE_PARAM&quot; ]\r\n\tthen\r\n\t\tSIZE_GB=$(du -s -B 1G &quot;$SIZE_PARAM&quot; | cut -f1)\r\n\t\techo &quot;Volume size source: computed from the size of the given folder&quot;\r\n\telse die &quot;Parameter 1 must be either the desired volume size in GB (an integer) or a folder whose size will be used to determine the volume size; was: '$SIZE_PARAM'&quot;\r\n\tfi\r\nfi<br><br>SIZE_BYTES=$[$SIZE_GB*1024**3]\r\necho &quot;Volume size will be $SIZE_GB GB = $SIZE_BYTES B; based on $SIZE_PARAM&quot;<br><br>## CHECK ENVIRONMENT\r\nMPOINT=/mnt/backupbytovka\r\nif [ ! &quot;$(mount | grep $MPOINT)&quot; ]; then die &quot;The place where to create the volume, '$MPOINT', isn't ready: either it doesn't exist or Samba isn't mounted there&quot;; fi<br><br>TODAY=$(date &quot;+%F&quot;)\r\nVOLUME=&quot;$MPOINT/truecryptvol.$TODAY.tc&quot;\r\necho &quot;&gt;&gt;&gt; Going to create the TrueCrypt volume ${VOLUME}. You'll be asked for a password for the volume and few other question. The creation may take few hours.&quot;\r\n$(dirname $0)/truecrypt --volume-type=normal --size=$SIZE_BYTES --encryption=AES --hash=RIPEMD-160 --filesystem=FAT -k &quot;&quot; -c &quot;$VOLUME&quot;\r\n</code></pre>\r\n<h3>3. Verify the backup</h3>\r\n<ol>\r\n\t<li>Boot Clonezilla as \"JH Clonezilla for Samba (Safe graphic)\" in a vmware image with a new, empty disk of a sufficient size\r\n<ul>\r\n\t<li>This calls the custom Clonezilla startup script, which will mount Samba and the latest TrueCrypt volume</li>\r\n\t<li>Alternatively you could mount them manually:\r\n<pre><code>$ cd /live/image/live; . jh-my_mounts.sh; mnt_samba &amp;&amp; mount_truecrypt</code></pre></li>\r\n</ul>\r\n</li>\r\n\t<li>Partition the new, empty vmware disk via <em>fdisk</em> as described above</li>\r\n\t<li>If needed, modify the backuped partition to have the same name as the target one\r\n<ul>\r\n\t<li>To change the disk from <em>sda</em> to <em>sdb</em>: cnvt-ocs-dev &lt;image folder name&gt; sda sdb</li>\r\n\t<li>To change the partition number, rename all the files within the image folder:\r\n$ for BKP in $(ls sda1.*); do BKPNEW=$(echo $BKP | sed \"s/sda1/sda2/\"); mv $BKP $BKPNEW; done</li>\r\n</ul>\r\n</li>\r\n\t<li>Run restore, i.e. exit the command prompt(s), which will return you back to the Clonezilla user interface, and instruct it to restore the partition (or I might save the command for that and run it from the command line)</li>\r\n</ol>\r\n<h2 id=\"Summary\">Summary</h2>\r\nWe have learned how to add files to Clonezilla Live and modify its boot parameters to execute a customized script, and in general how to simplify the backup/restoration process tailored to our environment - namely using an encrypted TrueCrypt volume on a remote Samba share. We've also learned how to test the backup with Clonezilla and VMware by restoring it to a virtual disk and booting it with VMware.\r\n<h2>Related resources</h2>\r\nClonezilla FAQ\r\n<ul>\r\n\t<li><a href=\"http://drbl.org/faq/fine-print.php?path=./2_System/68_manually_partclone_restore.faq#68_manually_partclone_restore.faq\">How to restore backup manually into a mountable .img file</a> (if partclone was used for the backup; it's <a href=\"http://drbl.org/faq/fine-print.php?path=./2_System/43_read_ntfsimg_content.faq#43_read_ntfsimg_content.faq\">similar for ntfsclone</a> and <a href=\"http://www.idealworldinc.com/partclone-utils/\">partclone-utils</a> can read the image directly though you'll likely need to uncompress it anyway ) - join all the parts (.aa, .ab etc.) via cat and pass that to the proper un-archiver and the result to the cloning tool\r\n<ul>\r\n\t<li>To me it took ~ 13h to decompress an lzo-compressed image of the output size 197GB on 2-core Intel Atom 230 (1.6GHz) PC while reading from&amp;writting to an external 5400 RPM disk</li>\r\n\t<li>If your image names contains \"ptcl\" then Partclone was used to create it</li>\r\n</ul>\r\n</li>\r\n</ul>\r\nPossible problems\r\n<ul>\r\n\t<li>Source/target USB disk disconnects after some time with st. like \"usb 1-1: reset high speed USB device using ehci_hcd and address 2\"  - this is likely caused by a bug in the USB 2 driver ehci_hcd present in some old and also new  (incl. some 2.6.31) kernels. See this <a href=\"https://bugs.launchpad.net/ubuntu/+source/linux-source-2.6.20/+bug/88746\">bug and comments</a>. The only solution I can see is to try different kernel.</li>\r\n</ul>",
  "excerpt": ""
 },
 {
  "title": "Mobile learning application MiniPauker 1.1.05 released - please test!",
  "published": "2010-07-25 12:26:26",
  "postType": "post",
  "slug": "/2010/07/25/mobile-learning-application-minipauker-1-1-05-released-please-test/",
  "status": "publish",
  "tags": [
   "j2me",
   "java",
   "learning",
   "midlet",
   "open_source"
  ],
  "categories": [
   "Languages"
  ],
  "content": "<img title=\"MiniPauker 1.1.05\" src=\"http://lh6.ggpht.com/_btcPMCQkYvg/TEwnMWe4wfI/AAAAAAAABYs/XRA1z6Ggi84/s400/minipauker1105-remembered.png\" alt=\"\" width=\"198\" height=\"400\" /><br><br><a href=\"http://pauker.sourceforge.net/pauker.php?target=home&amp;ang=en&amp;project=minipauker\">MiniPauker</a> 1.1.05, the final milestone before 1.1.1, has just been released. MiniPauker is a \"flashcard learning\" application for cell phones, which means that you can use it to learn or repeat any pairs of information, such as French vocabulary or terms and their definitions. The \"cards\" that you have troubles remembering are repeated often while the ones well remembered less and less frequently. It's a mobile version of the desktop application <a href=\"http://pauker.sourceforge.net/pauker.php?target=home&amp;lang=en\">Pauker</a>.<br><br>The version 1.1.05, and thus also 1.1.1, brings many new features and enhancements, especially regarding usability, and some important fixes, such as:\r\n<ul>\r\n\t<li>The \"lesson\" (previously known as \"session\") last used is automatically re-opened when you start MiniPauker</li>\r\n\t<li>Possibility to save &amp; quit with a single key (namely 5) press while learning/repeating, or via a new main menu item \"Save &amp; Quit\"</li>\r\n\t<li>Possibility to edit or delete a card while learning/repeating</li>\r\n\t<li>When there are any cards to learn or repeat, the corresponding menu item is emphasized with a red font, and when there is nothing, invoking that menu item will inform you when the next cards expire and will thus require to be repeated</li>\r\n\t<li>Support for long cards: you can easily page up/down using the keys 2 and 5 and the typing limit for adding or editing a card was increased to 10,000</li>\r\n\t<li>When a call arrives, the application should be able to stop and later resume without any loss of data (unless you inadvertently close it)</li>\r\n</ul>\r\nSee the <a href=\"http://sourceforge.net/projects/minipauker/files/minipauker%20-%20devel%20snapshot/1.1.05%20-%20preview%2005%20of%201.1.1/release_notes_1.1.05.txt/view\">release notes</a> for the complete list.<br><br>The \"general availability\" release 1.1.1 will be published based on 1.1.05 after thirty days without any new bug report and we are therefore asking everybody to <a href=\"http://sourceforge.net/projects/minipauker/files/\">download MiniPauker 1.1.05</a> (either the normal or the -debug version) and try it out to discover and <a href=\"http://sourceforge.net/tracker/?limit=25&amp;func=&amp;group_id=159194&amp;atid=810862&amp;assignee=&amp;status=&amp;category=&amp;artgroup=&amp;keyword=&amp;submitter=&amp;artifact_id=&amp;assignee=&amp;status=1&amp;category=&amp;artgroup=&amp;submitter=&amp;keyword=&amp;artifact_id=&amp;submit=Filter\">report</a> as many problems, unexpected behavior etc. as possible. Don't miss your chance to influence the look&amp;feel and behavior of the application! Read more about how to <a href=\"http://sourceforge.net/news/?group_id=159194&amp;id=289595\">help with testing</a>. Thanks a lot!",
  "excerpt": ""
 },
 {
  "title": "Most interesting links of July",
  "published": "2010-08-02 10:56:44",
  "postType": "post",
  "slug": "/2010/08/02/most-interesting-links-of-july/",
  "status": "publish",
  "tags": [
   "IO",
   "java",
   "jdbc",
   "patterns",
   "performance"
  ],
  "categories": [
   "Languages",
   "Top links of month"
  ],
  "content": "This month about performance, the Java language and patterns, the development process, and a few interesting news.<br><br><!--more--><br><br>Performance\r\n<ul>\r\n\t<li><a href=\"http://www.dzone.com/links/r/jdbc_performance_tuning_with_fetch_size.html\">JDBC performance tuning with fetch size</a> - how a query processing was reduced from 45m to 35s by increasing the fetch size from 10 to 5000 (it returns 500k records and runs fast on the DB server but slow on the app. server)</li>\r\n\t<li><a href=\"http://cacm.acm.org/magazines/2010/7/95061-youre-doing-it-wrong/fulltext#F1\">You're Doing it Wrong - Think you've mastered the art of server performance? Think again.</a> An (theoretically) efficient algorithm is not enough, algorithms must take into account the hardware and how it is used to be truly efficient - \"What good is an O(log2(n)) algorithm if those operations cause page faults and slow disk operations? For most relevant datasets an O(n) or even an O(n^2) algorithm, which avoids page faults, will run circles around it.\"</li>\r\n\t<li><a href=\"http://www.dzone.com/links/r/java_io_faster_than_nio_old_is_new_again.html\">Java IO Faster Than NIO – Old is New Again!</a> - demystyfying NIO - surprisingly, contrary to the widespread belief, asynchronous IO is usually by 25% faster than blocking IO. By the author of a mail server handling large load. See also the comments (when NIO can be faster, the influence of kernel, JVM versions, ...)</li>\r\n</ul>\r\nJava &amp; patterns\r\n<ul>\r\n\t<li><a href=\"http://www.dzone.com/links/r/java_quicktip_fluent_interfaces.html\">Java QuickTip: Fluent Interfaces</a> - I like Fluent interfaces a lot, because, well, they're so fluent, meaning easy to read and nice to work with. This article is only a short example, a real-world API using the fluent concept is e.g. <a href=\"http://mockito.googlecode.com/svn/tags/latest/javadoc/org/mockito/Mockito.html#3\">Mockito</a>.</li>\r\n\t<li><a href=\"http://jeremymanson.blogspot.com/2008/11/what-volatile-means-in-java.html\">What Volatile Means in Java</a> - something we should all know but only few really do; applies since JVM 1.5</li>\r\n\t<li><a href=\"http://www.martinfowler.com/ap2/range.html\">M. Fowler - the Range pattern</a> - a great example of object-oriented thinking and Clean Code(TM) where abstraction hides implementation details, provides a much more readable code and a base for a really powerful object (think pen/closed ranges, comparing ranges), plus, of course, you have all the operations within the object and not in your business code that uses the Range. BTW, <a href=\"http://groovy.codehaus.org/Collections#Collections-Ranges\">Groovy has ranges</a> as an element of the languages itself</li>\r\n</ul>\r\nThe development process\r\n<ul>\r\n\t<li><a href=\"http://www.dzone.com/links/r/clean_code_and_clean_tdd_cheat_sheets.html\">Clean Code and Clean TDD Cheat Sheets</a></li>\r\n\t<li><a href=\"http://www.infoq.com/presentations/responsive-design\">Kent Beck: Responsive Design</a> - this 1h presentation is really worth the time spent watching it; actually even if you watch only the first 7 minutes, where Kent talks about how he extracted the design and implementation patterns, you will gain a lot. A responsive design is a design that evovles through the time, always just \"at the right moment\", by responding to the feedback from customers, other people, the system etc. Kent talks about all the elements that take part in the design process, such as values, principles, patterns, design evolution strategies. Do not miss it!</li>\r\n\t<li><a href=\"http://www.dzone.com/links/r/why_i_dont_like_pair_programming_and_why_i_left_p.html\">Why I Don't Like Pair Programming (and Why I Left Pivotal)</a> - It's always good to read about the dark side of any practice. The comments are also very useful, there are even links to two (not very positive) pair programming studies.</li>\r\n</ul>\r\nOther stuff &amp; news\r\n<ul>\r\n\t<li><a href=\"http://www.dzone.com/links/r/the_five_most_important_algorithms.html\">The most important algorithms in CS and maths</a> as candidates for the 5 most important algorithms. In other words, a lot of algorithms that I either knew and completely forgot or never knew at all. Sometimes it feels that the 5 years at uni were a waste ;-)</li>\r\n\t<li><a href=\"http://www.dzone.com/links/r/google_wants_you_to_be_an_html5_ninja.html\">Introducing the Google's new web portal \"HTML5 Rocks,\"</a> which aggregates information on HTML5 and the latest web technologies and standards.</li>\r\n\t<li><a href=\"http://www.dzone.com/links/r/openstack_one_giant_leap_for_cloud_computing.html\">OpenStack: One Giant Leap for Cloud Computing</a> - a new open-source cloud infrastructure project contributed to by Rackspace and NASA, joined by Citrix, Dell, Intel, AMD &amp; others</li>\r\n</ul>",
  "excerpt": ""
 },
 {
  "title": "Most interesting links of August",
  "published": "2010-08-31 14:03:58",
  "postType": "post",
  "slug": "/2010/08/31/most-interesting-links-of-august/",
  "status": "publish",
  "tags": [
   "eclipse",
   "java",
   "jdbc",
   "unicode"
  ],
  "categories": [
   "Languages",
   "Tools",
   "Top links of month"
  ],
  "content": "I hope everybody is enjoying the holiday and not spending hours on tech blogs and sites. At least I do :-) and thus this month's list is a short one:\r\n<ul>\r\n\t<li><a href=\"http://piotrjagielski.com/blog/working-with-static-imports-in-eclipse/\">Working With Static Imports in Eclipse</a> - how to make working with static imports (nearly) as easy as with the normal ones (especially useful for fluent interfaces and \"DSLs\"), mainly by adding types like JUnit's Assert and Mockito to your favorite imports and setting Eclipse to always generate static imports in the form &lt;type&gt;.*</li>\r\n\t<li><a href=\"http://www.dzone.com/links/r/5_things_you_didnt_know_about_java_database_conne.html\">5 things you didn't know about ... Java Database Connectivity</a> - it was interesting to learn that JDBC specifies some scalar functions that drivers <em>may</em> support and translate into the DB's language such as \"{CURRENT_DATE()}\"; for common functions supported by most drivers this should make your implementation more portable</li>\r\n\t<li><a href=\"http://www.dzone.com/links/r/four_things_to_remember_about_javalangstring.html\">Four Things to Remember about java.lang.String</a> - a really good one thanks to information on how to compare correctly the same Unicode character/string that can be encoded in different ways with java.text.Normalizer.normalize and Locale-sensitive comparison ignoring optionally unimportant differences such as letter size and accents (using a Collator)</li>\r\n</ul>",
  "excerpt": ""
 },
 {
  "title": "Implementing retrial with a MDB or an MQ batch job? (WAS 7, MQ 6)",
  "published": "2010-09-13 10:09:41",
  "postType": "post",
  "slug": "/2010/09/13/implementing-retrial-with-a-mdb-or-an-mq-batch-job-was-7-mq-6/",
  "status": "publish",
  "tags": [
   "batch",
   "java",
   "javaEE",
   "MDB",
   "MQ",
   "WebSphere"
  ],
  "categories": [
   "j2ee",
   "Languages"
  ],
  "content": "We need to listen for messages distributed via Websphere MQ to get informed when an employee joins or leaves IBM. And because the resources used in the processing (a database, a webservice) may be temporarily unavailable, we must be able to deal with such outages, which may range from minutes to hours, by repeatedly retrying the processing after some delay. And we must be also able to deal with \"poison messages\", that means messages whose processing always fails either because their content is invalid or because their data isn't consistent with the database. The question is whether this would be better implemented as a Message-Driven Bean (MDB) or a batch job regularly checking its queue given that we have Websphere Application Server 7 (and thus Java EE 5) and Websphere MQ 6, which both have some important changes compared to the previous versions. It turns out that it depends - both approaches have some advantages and disadvantages and so it's a question of the likelihood of particular problems and business requirements and priorities.\r\n<h1><!--more-->Setting the scene</h1>\r\n<h2>MDB vs. a batch job: the decision factors</h2>\r\nWhether we should select the MDB or the batch job approach depends on a number of factors, some of them are:\r\n<ul>\r\n\t<li>Requirements\r\n<ul>\r\n\t<li>Quantity: What quantity of messages do we need to handle?</li>\r\n\t<li>Error likelihood: What's the probability that a resource will be  temporarily unavailable or that a message will contain data that can't be  processed correctly and how soon such a problem needs to be resolved?  ﻿I.e. can we wait to another day or shall we get going as soon as the  resource is up again? This will tell us how often we need to retry and whether a manual handling of an issue is sufficient.</li>\r\n</ul>\r\n</li>\r\n\t<li>Support for error handling/retrial logic</li>\r\n\t<li>Ease of use/development/maintenance</li>\r\n\t<li>Performance: We need to handle all the incoming messages and to have minimal negative impact on the  performance of the target system</li>\r\n\t<li>Speed of processing of the incoming messages (immediate vs. once or few times per day)</li>\r\n\t<li>Integration with our operations monitoring (logging, our Operations Dashboard webapp)</li>\r\n</ul>\r\n<h2>The problems to deal with</h2>\r\nThere are three types of problems that can occur:\r\n<ol>\r\n\t<li>A failure to communicate with MQ, for instance because a network connection got interrupted</li>\r\n\t<li>Inability to process a message due to a resource (a DB or a WS) being temporary unavailable</li>\r\n\t<li>A poison (invalid) message (wrong data type, unexpected content) leading to   an exception during its processing</li>\r\n</ol>\r\n<h1>The two approaches</h1>\r\n<h2>Approach 1: A Message-Driven Bean (MDB)</h2>\r\nA MDB is hosted by an application server that does a lot of work on behalf of the bean (such as transaction and concurrency management) thus simplifying its development and configuration. It may be as simple as writing<br><br><pre><code>\r\n@javax.ejb.MessageDriven\r\npublic class SimpleMessageBean implements javax.jms.MessageListener {\r\n    public void onMessage(javax.jms.Message inMessage) {\r\n    final javax.jms.TextMessage msg = (javax.jms.TextMessage) inMessage;\r\n    final String msgBody = msg.getText();\r\n    // handle the msgBody ...\r\n   }\r\n}\r\n</code></pre><br><br>and configuring the ActivationSpecification for the MDB in JNDI via the app. server's administration UI.<br><br>The question is, of course, how well it can handle poison messages and retrial when resources are temporarily unavailable.\r\n<h3>MDB error handling and configuration in Websphere 7</h3>\r\nLet's have a look how Websphere deals with various kinds of errors related to MDBs and how we do configure a MDB in this application server, especially with regard to error handling.\r\n<h4>MDB error handling in Websphere</h4>\r\n<strong>What happens when an error occurs</strong>?<br><br>Normally an Application Server starts an MQ <strong>transaction</strong> before it invokes a MDB and it either commits it when the MDB finishes or rolls it back when it throws an exception. If the transaction succeeds then the message is removed from the MDB's queue otherwise it will be returned there and processed again in the future. This is the default behavior corresponding to configuring container-managed transactions (tx) with the type of  'required'. Notice that also <a title=\"Visit page outside WikiCentral\" rel=\"nofollow\" href=\"http://publib.boulder.ibm.com/infocenter/wasinfo/v7r0/topic/com.ibm.websphere.express.doc/info/exp/ae/cmb_trans.html\">DB operations can participate in this transaction<sup><img src=\"https://w3.tap.ibm.com/w3ki/images/icons/linkext7.gif\" border=\"0\" alt=\"\" width=\"7\" height=\"7\" align=\"absmiddle\" /></sup></a> and thus be committed/rolled back as well, which might be useful.\r\n<ol>\r\n\t<li>In the case of an MQ communication/connection failure, WAS logs the  exception and retries the connection later based on its configuration.  It's also possible to set an <a title=\"Visit page outside WikiCentral\" rel=\"nofollow\" href=\"http://download-llnw.oracle.com/javaee/5/api/javax/jms/ExceptionListener.html\">ExceptionListener<sup><img src=\"https://w3.tap.ibm.com/w3ki/images/icons/linkext7.gif\" border=\"0\" alt=\"\" width=\"7\" height=\"7\" align=\"absmiddle\" /></sup></a> that would be called with the exception as a parameter in such a case.</li>\r\n\t<li>In the case of an exception during message processing (or due to a manual  setRollbackOnly invocation) the current transaction is rolled back, the  message is put back to the queue and the MDB is restarted. When the  queue is re-checked, the message is found again and passed to another  MDB. If the cause of the problem persists, this will fail again - and so  on.</li>\r\n</ol>\r\nWe have two ways how to deal with a failed message:\r\n<ol>\r\n\t<li><strong>Remove the message</strong> from the queue either by discarding it or  by moving it to the queue's \"back-out queue\". This is appropriate when  the message itself is the problem (e.g. contains data inconsistent with  the DB ...).</li>\r\n\t<li><strong>Stop processing messages</strong> from the queue (pause the  Activation Specification) and restart it later when the problem is  resolved. This is appropriate when a necessary resource is temporarily  unavailable.</li>\r\n</ol>\r\n<h4>Messaging provider and JMS resources configuration related to error handling</h4>\r\nWe will use JCA 1.5 Activation Specification (and not <a title=\"Visit page outside WikiCentral\" rel=\"nofollow\" href=\"http://publib.boulder.ibm.com/infocenter/wasinfo/v7r0/topic/com.ibm.websphere.nd.doc/info/ae/ae/cmb_aslp.html\">Listener Ports that are deprecated<sup><img src=\"https://w3.tap.ibm.com/w3ki/images/icons/linkext7.gif\" border=\"0\" alt=\"\" width=\"7\" height=\"7\" align=\"absmiddle\" /></sup></a> since WAS 7) with Websphere MQ as the provider, which limits our <a href=\"http://publib.boulder.ibm.com/infocenter/wasinfo/v7r0/topic/com.ibm.websphere.nd.multiplatform.doc/info/ae/ae/tmj_adm20.html\">configuration options</a> to those described below.\r\n<ul>\r\n\t<li>Disabling (temporarily) the whole queue, more exactly shutting down the MDB\r\n<ul>\r\n\t<li>\"Number of sequential delivery failures before suspending endpoint\" - on an MQ Activation Specification</li>\r\n\t<li>\"Stop endpoint if message delivery fails\" - if true, message  delivery suspended when the Number of sequential delivery failures...  exceeded\r\n<ul>\r\n\t<li>Prior to the Fix Pack 7.0.1.0 this only applies when either the  MDB throws an exception or an internal error happens, not when the  transaction is marked for rollback (Issue <a title=\"Visit page outside WikiCentral\" rel=\"nofollow\" href=\"http://www-01.ibm.com/support/docview.wss?rs=171&amp;uid=swg1IC60714\">IC60714<sup><img src=\"https://w3.tap.ibm.com/w3ki/images/icons/linkext7.gif\" border=\"0\" alt=\"\" width=\"7\" height=\"7\" align=\"absmiddle\" /></sup></a>).</li>\r\n\t<li>When the endpoint is stopped, a JMX notification can be sent so  that somebody is informed that the endpoint will need to be re-enabled.  Perhaps we could automate this re-activation with a scheduled stateless  EJB using Websphere JMX to perform the reactivation after a delay.</li>\r\n</ul>\r\n</li>\r\n</ul>\r\n</li>\r\n\t<li>Removing problematic messages (this is done by Websphere MQ itself, not WAS)\r\n<ul>\r\n\t<li>\"Backout threshold\" (BOTHRESH; a property of a queue, configured via  MQ)  specifies the maximum number of times a message can be put onto a  queue  before it is moved to the specified backout requeue queue.   Default: 0  or unset?! =&gt; never re-delivered</li>\r\n\t<li>\"Backout requeue queue\" (BOQNAME; a property of a queue, configured  via MQ) - the queue where to put the failed messages; default:  SYSTEM.DEAD.LETTER.QUEUE</li>\r\n\t<li>WARNING: This seems to apply only to a queue, not to a topic. But  underneath topics use (likely dynamic) queues anyway so it should be  possible somehow.\r\n<ul>\r\n\t<li>See <a title=\"Visit page outside WikiCentral\" rel=\"nofollow\" href=\"http://publib.boulder.ibm.com/infocenter/wmqv6/v6r0/topic/com.ibm.mq.csqzaw.doc/uj25590_.htm\">poison messages handling in WMQ<sup><img src=\"https://w3.tap.ibm.com/w3ki/images/icons/linkext7.gif\" border=\"0\" alt=\"\" width=\"7\" height=\"7\" align=\"absmiddle\" /></sup></a> v6.</li>\r\n</ul>\r\n</li>\r\n</ul>\r\n</li>\r\n\t<li>Other related settings\r\n<ul>\r\n\t<li>There is <strong>no way to configure how often WAS should check for new messages</strong>, at least none I could find. There is a \"<a title=\"Visit page outside WikiCentral\" rel=\"nofollow\" href=\"http://publib.boulder.ibm.com/infocenter/wasinfo/v7r0/topic/com.ibm.websphere.base.iseries.doc/info/iseries/ae/umj_pasm_advprops.html\">rescan interval<sup><img src=\"https://w3.tap.ibm.com/w3ki/images/icons/linkext7.gif\" border=\"0\" alt=\"\" width=\"7\" height=\"7\" align=\"absmiddle\" /></sup></a>\"  that tells WAS how long to wait before checking another queue but seems  only to apply when there are more queues than scanning threads. The  default value is 5s and according to some posts it can't be increased  (though this might not be true anymore in our version/fixpack level).</li>\r\n</ul>\r\n</li>\r\n</ul>\r\nInteresting resources:\r\n<ul>\r\n\t<li><a title=\"Visit page outside WikiCentral\" rel=\"nofollow\" href=\"http://publib.boulder.ibm.com/infocenter/wmqv7/v7r0/topic/com.ibm.mq.explorer.doc/e_properties_queues.htm\">MQ v7: Queue properties<sup><img src=\"https://w3.tap.ibm.com/w3ki/images/icons/linkext7.gif\" border=\"0\" alt=\"\" width=\"7\" height=\"7\" align=\"absmiddle\" /></sup></a> (I couldn't find it for WMQ 6)</li>\r\n</ul>\r\n<h3>Design of the MDB approach</h3>\r\n<h4>Error handling design</h4>\r\nThe main problem with the MDB approach is that it doesn't support  retrying an operation after a delay (either for a single failing message  or for the whole queue, if a resource is temporarily unavailable). There  are some workarounds, but not very nice.\r\n<ul>\r\n\t<li>For a single message I couldn't find a way to implement retrials  after some, preferably increasing, delay; the only thing we can do is to  retry it few times with the default Websphere's delay, which seems to be  5s, and if it still doesn't succeed then move it into a special queue that  would be processed manually while perhaps also sending an email  notification.</li>\r\n\t<li>If there is some global problem, such as an unavailable resource,  indicated by several consecutive failures of one or more messages  (depending on the content of the queue), we could let WAS stop the MDB  and re-enable it later either automatically after a delay or manually  when the problem gets fixed.</li>\r\n</ul>\r\n<h4>MDB design</h4>\r\n<ul>\r\n\t<li>When resource unavailability is detected, let WAS stop the MDB automatically  via the setting \"Number of sequential delivery failures before  suspending endpoint\". It will need to be re-enabled either manually or  automatically.\r\n<ul>\r\n\t<li>Manual re-activation of the MDB: We have to somehow detect that  the MDB was disabled (the only option is perhaps by watching the log),  find out why it failed, and re-enable it via the Websphere Administration  Console.</li>\r\n\t<li>Automated re-activation: Implement a scheduled stateless EJB,  which re-enables the MDB after few tens of minutes - preferably do this  few times with increasing delay, if still failing, give up and notify an  admin.\r\n<ul>\r\n\t<li>To find out when reactivation is necessary, the re-activating EJB  can either regularly check the status of the MDB (which is feasible) or listen for JMX notifications issued by the logging system and  <a title=\"Visit page outside WikiCentral\" rel=\"nofollow\" href=\"http://www.ibm.com/developerworks/forums/thread.jspa?messageID=14489302\">watch for a deactivation<sup><img src=\"https://w3.tap.ibm.com/w3ki/images/icons/linkext7.gif\" border=\"0\" alt=\"\" width=\"7\" height=\"7\" align=\"absmiddle\" /></sup></a> notification. (The log watching approach isn't very elegant, the EJB  would receive many unrelated notification, which is an unnecessary work  for the server. Unfortunately the endpoint doesn't produce any special  JMX notification, just a log record.)</li>\r\n\t<li>The re-activation itself is performed via JMX by invoking resume() on the appropriate <a href=\"http://publib.boulder.ibm.com/infocenter/wasinfo/v7r0/topic/com.ibm.websphere.javadoc.doc/web/mbeanDocs/J2CMessageEndpoint.html\">J2CMessageEndpoint MBean</a> (see the link above for how to get a handle to it).</li>\r\n\t<li>In any case the application would need the permission to perform  some WAS administration operations, namely to re-activate the MDB,  and perhaps also to access JMX or the AdminServiceFactory/AdminService,  which might be a problem if corporate security rules do not allow that.</li>\r\n</ul>\r\n</li>\r\n</ul>\r\n</li>\r\n\t<li>When there is a poison message, move it to the backout queue and  notify somebody to handle it (e.g. via email)\r\n<ul>\r\n\t<li>If the queue contains only one message there is no generic way how  to find out whether the problem is within the message or in some  resource, the MDB would need to find this out and communicate it. If there are multiple messages and only one fails, we know it's a poison message and it could be automatically removed by means of the \"Backout threshold\". (Beware of the interaction  between the message's redelivery count/backout threashold and the   \"Number of sequential delivery failures...\" - the letter is reset when  either a message processing succeeds or when the MDB is  stopped/restarted.)</li>\r\n</ul>\r\n</li>\r\n\t<li>(Perhaps we could use JMS <a title=\"Visit page outside WikiCentral\" rel=\"nofollow\" href=\"http://publib.boulder.ibm.com/infocenter/wmqv6/v6r0/topic/com.ibm.mq.csqzaw.doc/uj25420_.htm\">selectors<sup><img src=\"https://w3.tap.ibm.com/w3ki/images/icons/linkext7.gif\" border=\"0\" alt=\"\" width=\"7\" height=\"7\" align=\"absmiddle\" /></sup></a> on <a title=\"Visit page outside WikiCentral\" rel=\"nofollow\" href=\"http://publib.boulder.ibm.com/infocenter/wmqv6/v6r0/topic/com.ibm.mq.csqzaw.doc/uj25450_.htm\">JMS header properties<sup><img src=\"https://w3.tap.ibm.com/w3ki/images/icons/linkext7.gif\" border=\"0\" alt=\"\" width=\"7\" height=\"7\" align=\"absmiddle\" /></sup></a> (e.g. JMSRedeliveredto, JMSXDeliveryCount) but the possibilities are  rather limited because both the selector query and the properties are  static (e.g. something like MyRetryTime &gt;= now() isn't possible).  Note: MQ V7 has a major <a title=\"Visit page outside WikiCentral\" rel=\"nofollow\" href=\"http://www.mqseries.net/phpBB2/viewtopic.php?t=44609\">rewrite of the selectors<sup><img src=\"https://w3.tap.ibm.com/w3ki/images/icons/linkext7.gif\" border=\"0\" alt=\"\" width=\"7\" height=\"7\" align=\"absmiddle\" /></sup></a> support and their handling was moved from the Java client directly to the queue manager.)</li>\r\n</ul>\r\n<h3>MDB approach evaluation</h3>\r\n<h4>Key MDB issues</h4>\r\n<ul>\r\n\t<li>Permissions to perform a WAS administration operation required.</li>\r\n\t<li>Difficult to distinguish a poison message from a resource outage without additional logic when the queue contains only one element.\r\n<ul>\r\n\t<li>But see the batch job design below, which also requires to be able to distinguish these two types of problems.</li>\r\n</ul>\r\n</li>\r\n\t<li>Inefficient determination of MDB's status for the delay reactivation  logic: either polling its status regularly or watching the log with  many unrelated messages that can't be filtered out.</li>\r\n</ul>\r\n<h4>Key MDB advantages and disadvantages</h4>\r\n<ul>\r\n\t<li>Advantages\r\n<ul>\r\n\t<li>The data is processed and reaches the destination system soon after it is published</li>\r\n\t<li>Key characteristics are configurable via UI (Number of sequential  delivery failures, Backout threshold, MQ connection data, MQ  security/SSL, processing concurrency, DataSource  configuration/injection, ...). Actually this is also a disadvantage due  to needing an admin, see below</li>\r\n\t<li>Logging configurable at the runtime (Java logging, levels can be set in WAS console)</li>\r\n</ul>\r\n</li>\r\n\t<li>Disadvantages\r\n<ul>\r\n\t<li>Any configuration requires a WAS administrator and thus lot of time due to the IBM bureaucracy and ceremony</li>\r\n\t<li>Difficult to collect and communicate statistics for our Operations  Dashboard because (a) there are frequent fine-grained changes instead  of 1/day batch changes and (b) there is no support for the Job logging  framework of ours (a possible but laborious solution is to gather statistics in  an instance variable and log them in regular intervals into the job  tables using JDBC and some code extracted from the job framework)</li>\r\n\t<li>Necessary to somehow configure the reactivation EJB (the reactivation delay, number of attempts before giving up)</li>\r\n</ul>\r\n</li>\r\n</ul>\r\n<strong>MDB design questions:</strong>\r\n<ul>\r\n\t<li> Do we need automated reactivation of a disabled MDB? Perhaps not  if: (1) a resource outage happens rarely and/or (2) the administration  team spots this automatically and can handle it automatically without  any bureaucracy and consumption of our resources.</li>\r\n</ul>\r\n<h3>MDB resources</h3>\r\nEssential docs\r\n<ul>\r\n\t<li> <a title=\"Visit page outside WikiCentral\" rel=\"nofollow\" href=\"http://www-01.ibm.com/support/docview.wss?uid=swg27016582&amp;aid=1\">Using an MDB that always rolls back a message to test the handling of poison messages<sup><img src=\"https://w3.tap.ibm.com/w3ki/images/icons/linkext7.gif\" border=\"0\" alt=\"\" width=\"7\" height=\"7\" align=\"absmiddle\" /></sup></a> (IBM Techdoc: 7016582)</li>\r\n</ul>\r\nOther (not all docs available for our version, namely MQ v6 and WAs v7)\r\n<ul>\r\n\t<li><a title=\"Visit page outside WikiCentral\" rel=\"nofollow\" href=\"http://www.ibm.com/developerworks/websphere/library/techarticles/0803_titheridge/0803_titheridge.html\">How WebSphere Application Server V6 handles poison messages<sup><img src=\"https://w3.tap.ibm.com/w3ki/images/icons/linkext7.gif\" border=\"0\" alt=\"\" width=\"7\" height=\"7\" align=\"absmiddle\" /></sup></a></li>\r\n\t<li><a title=\"Visit page outside WikiCentral\" rel=\"nofollow\" href=\"http://publibz.boulder.ibm.com/epubs/pdf/csqzaw15.pdf\">WebSphere MQ: Using Java, Version 6.0<sup><img src=\"https://w3.tap.ibm.com/w3ki/images/icons/linkext7.gif\" border=\"0\" alt=\"\" width=\"7\" height=\"7\" align=\"absmiddle\" /></sup></a></li>\r\n\t<li>WAS 7 InfoCentral - <a title=\"Visit page outside WikiCentral\" rel=\"nofollow\" href=\"http://publib.boulder.ibm.com/infocenter/wasinfo/v7r0/topic/com.ibm.websphere.pmc.express.doc/tasks/tjn_mdb_0001_Ex2.html\">Example 2: Automatically stopping an MDB when a system resource becomes unavailable<sup><img src=\"https://w3.tap.ibm.com/w3ki/images/icons/linkext7.gif\" border=\"0\" alt=\"\" width=\"7\" height=\"7\" align=\"absmiddle\" /></sup></a> (useful even though it doesn't use MQ)</li>\r\n\t<li><a title=\"Visit page outside WikiCentral\" rel=\"nofollow\" href=\"http://publib.boulder.ibm.com/infocenter/wasinfo/v7r0/index.jsp\">WebSphere Application Server Version 7.0 Information Center<sup><img src=\"https://w3.tap.ibm.com/w3ki/images/icons/linkext7.gif\" border=\"0\" alt=\"\" width=\"7\" height=\"7\" align=\"absmiddle\" /></sup></a></li>\r\n\t<li><a title=\"Visit page outside WikiCentral\" rel=\"nofollow\" href=\"http://www.redbooks.ibm.com/redbooks/pdfs/sg247615.pdf\">WebSphere Application Server V7 Administration and Configuration Guide<sup><img src=\"https://w3.tap.ibm.com/w3ki/images/icons/linkext7.gif\" border=\"0\" alt=\"\" width=\"7\" height=\"7\" align=\"absmiddle\" /></sup></a> and <a title=\"Visit page outside WikiCentral\" rel=\"nofollow\" href=\"http://www.redbooks.ibm.com/redbooks/pdfs/sg247770.pdf\">WebSphere Application Server V7 Messaging Administration Guide<sup><img src=\"https://w3.tap.ibm.com/w3ki/images/icons/linkext7.gif\" border=\"0\" alt=\"\" width=\"7\" height=\"7\" align=\"absmiddle\" /></sup></a></li>\r\n</ul>\r\n<h2>Approach 2: A batch job checking MQ regularly</h2>\r\nA batch job is a command-line application that is regularly, for example once a day, run by cron and actively scans its incoming queue/topic for new messages and processes them all at once. All the JMS communication and management and configuration must be implemented from scratch. (Though utilities such as <a href=\"http://static.springsource.org/spring/docs/2.5.x/api/org/springframework/jms/core/JmsTemplate.html\">Spring JMS template</a> may simplify it.)\r\n<h3>Job error handling and configuration</h3>\r\n<h4>Error handling<strong> </strong></h4>\r\nThe problems and ways to deal with errors are the same as when running in an application server, only we have to do everything ourselves. That means we need to manually start a transaction, catch exception and commit/roll back and configure the topic/queue for poison messages.<br><br>We would need to implement a problem cause detection logic to distinguish whether  there is a temporary resource outage or whether there is a problem with  the message itself (either incorrect data type or data inconsistent with the target DB ). There is no other good way to deal with these distinct kinds of  problems without really knowing which of them it is.<br><br>We would deal with the problems as follows:\r\n<ul>\r\n\t<li>For a resource outage, retry few times with an increasing delay, then quit and postpone the processing till the next scheduled execution</li>\r\n\t<li>For a poison message, move it to the backout queue and notify an administrator</li>\r\n</ul>\r\n<h4>JMS configuration in a batch job</h4>\r\nWe have two ways to configure the JMS resources (a Topic and a (Topic)ConnectionFactory) and their options related to error handling:\r\n<ol>\r\n\t<li>Use MQ provider-specific APIs to create the objects and configure them. See this <a href=\"http://hursleyonwmq.wordpress.com/2007/05/29/simplest-sample-applications-using-websphere-mq-jms/\">JMS + MQ API example</a>.</li>\r\n\t<li>Configure the provider-specific resources in JNDI and use only the standardized JNDI and JMS APIs. This is very easy with Sun's <a href=\"http://publib.boulder.ibm.com/infocenter/iseries/v5r3/index.jsp?topic=/rzaha/dasrjndi.htm\">filesystem-based JNDI provider</a> (<a href=\"http://java.sun.com/products/jndi/downloads/index.html\">fscontext.jar and providerutil.jar</a>) and vendor-supplied tools for generating the JNDI .bindings file for existing JMS resources . In the case of MQ you can <a href=\"http://publib.boulder.ibm.com/infocenter/wmqv7/v7r0/index.jsp?topic=/com.ibm.mq.csqzaw.doc/jm35200_.htm\">do it in the MQ Explorer</a> GUI or with the command-line utility JMSAdmin (a <a href=\"http://blog.testsautomation.com/2009/02/ibm-websphere-mq-testing-using-loadrunner/\">JMSAdmin example</a>, <a href=\"http://drugsearch.eof.gr/jms/queue/simple/docs/3_ConfigMQSeries.html\">another one</a>).</li>\r\n</ol>\r\nYou can create the JNDI configuration via the MQ Explorer wizards - after having added a new JNDI \"context\" using fscontext and a local directory - either by first creating the JMS resource and then letting the wizard generate an MQ resources for it and adjusting it as needed:<br><br><img class=\"alignnone\" title=\"MQ Explorer: Create a new JMS Destination\" src=\"http://lh3.ggpht.com/_btcPMCQkYvg/TI3xeIEBRTI/AAAAAAAABZc/BC-omVRZ-GM/s800/MQ_EXplorer-new_jndi_destination.PNG\" alt=\"\" width=\"553\" height=\"344\" /><br><br>Or by creating the JMS resource from an existing MQ resource:<br><br><img class=\"alignnone\" title=\"MQ Explorer: Create a JMS Topic from an existing MQ Topic\" src=\"http://lh4.ggpht.com/_btcPMCQkYvg/TI3xeQg93OI/AAAAAAAABZk/0hmV5jkhonE/s800/MQ_EXplorer-create_jms_topic_from_topic.PNG\" alt=\"\" width=\"519\" height=\"314\" /><br><br>Provided that the FsContext configuration file .bindings produced by JMSAdmin/MQ Explorer is in the folder /etc/mqJndiconfig, we would connect to the MQ as follows:<br><br><pre><code>\r\nfinal Hashtable&lt;String, String&gt; env = new Hashtable&lt;String, String&gt;();\r\nenv.put(Context.INITIAL_CONTEXT_FACTORY, &quot;com.sun.jndi.fscontext.RefFSContextFactory&quot;);\r\nenv.put(Context.PROVIDER_URL, &quot;file:/etc/mqJndiconfig&quot;);<br><br>final InitialContext context = new InitialContext(env);\r\nConnectionFactory qcf = (javax.jms.ConnectionFactory) context.lookup(&quot;MyConnectionFactory&quot;);\r\n // Note: I set the channel property MCAUSER so it actually isn't necessary to supply credentials below:\r\nfinal Connection connection = qcf.createConnection(&quot;anna&quot;, &quot;password ignored&quot;);<br><br>// Client ID is necessary for a durable subscr.\r\n// We could alternatively set in on the ConnectionFactory - the CLIENTID  property\r\nconnection.setClientID(&quot;MyCoolApplication&quot;);<br><br>final Session session = connection.createSession(true, -1); // the param 2 is ignored for durable subscr.<br><br>final Topic destination = (Topic) context.lookup(JNDI_PREFIX + TOPIC);\r\nfinal MessageConsumer receiver = subscribe(session, destination);<br><br>try {\r\n\tconnection.start();\r\n} catch (javax.jms.JMSException e) {\r\n\tthrow new RuntimeException(&quot;Failed to start the JMS connection&quot;, e);\r\n}\r\n</code></pre><br><br>We would then read the messages via:<br><br><pre><code>\r\nwhile ((msg= receiver.receiveNoWait()) != null) {\r\n\t\t\thandleMessage(msg);\r\n}\r\n</code></pre><br><br>The dependencies include <a href=\"http://java.sun.com/products/jms/docs.html\">jms.jar</a>, fscontext.jar and providerutil.jar. You can find them either <a href=\"http://publib.boulder.ibm.com/infocenter/wmqv6/v6r0/topic/com.ibm.mq.csqzaw.doc/uj10310_.htm\">in the WMQ installation</a> or on the web.<br><br>You may want to have a look at <a href=\"http://publib.boulder.ibm.com/infocenter/wmqv6/v6r0/index.jsp?topic=/com.ibm.mq.csqzaw.doc/uj24660_.htm\">Writing a simple publish/subscribe application connecting through WebSphere MQ</a> in WMQ help, which discusses some of the code above in more detail.\r\n<h3>Job design</h3>\r\n<ul>\r\n\t<li>Set a reasonable backout threshold and a suitable backout queue on the queue used by the Topic so that <strong>problematic messages are removed automatically</strong> after few failed attempts\r\n<ul>\r\n\t<li>Some monitoring of the backout queue would be necessary. If the MQ  infrastructure doesn't provide it then we can implement another MQ/JMS  reader that would send an email when there are some new messages in the  queue.</li>\r\n\t<li>Regarding the type of the topic queue:\r\n<ul>\r\n\t<li>Either we can use the shared JMS queue (SYSTEM.JMS.D.SUBSCRIBER.QUEUE) for the topic</li>\r\n\t<li>Or we can use a non-shared queue unique for our application,  which would be actually better and more aligned with IBM standards. It's  achieved by setting a broker durable subscription queue pattern in the  form \"SYSTEM.JMS.D..*\" (notice the trailing *) on the JMS ConnectionFactory when  defining it in JNDI or in the Java code. Upon the first  connection a permanent dynamic queue is generated for the client. We can  then set the backout options on it (or the administrators may define a  model queue for these dynamic queues with this setting already applied).</li>\r\n</ul>\r\n</li>\r\n</ul>\r\n</li>\r\n\t<li>Read and <strong>process each message in a new MQ transaction</strong> so  that if the processing fails it will be put back into the queue (and its  delivery count will be increased, thus making it perhaps eligible for  the backout queue)\r\n<ul>\r\n\t<li>ISSUE: The <strong>failed message would be obtained again on the next read</strong> (because it goes to the front, not to the end of the subscriber's  queue) and thus we can't process any other message before dealing with  it. Possible solutions:\r\n<ol>\r\n\t<li>Fail immediately, try again during the next regular run. If this  happens several times in a row for a particular message then it will be  moved to the backout queue by MQ (w.r.t. the settings above).</li>\r\n\t<li>Wait for a while such as 10-20m and try it again. If it still fails, continue as in #1.</li>\r\n</ol>\r\n</li>\r\n\t<li>Notice that <strong>DB transactions are not a part of the MQ transaction</strong> (unless we use some external transaction manager and XA resource  managers, which would require more work) but that shouldn't be a problem  for us. If the DB tx fails then we will manually roll back the MQ tx.  If the DB tx succeeds but later we fail to communicate the success to MQ  then the message will stay in the queue and be processed again, which  isn't a big problem in our particular case. (<ins>Global transactions</ins> with DB operations being a part of the MQ tx are supported only either <a title=\"Visit page outside WikiCentral\" rel=\"nofollow\" href=\"http://publib.boulder.ibm.com/infocenter/wmqv6/v6r0/topic/com.ibm.mq.amqzag.doc/fa13470_.htm\">(1) for a \"server application\"<sup><img src=\"https://w3.tap.ibm.com/w3ki/images/icons/linkext7.gif\" border=\"0\" alt=\"\" width=\"7\" height=\"7\" align=\"absmiddle\" /></sup></a> running on the MQ machine or <a href=\"http://publib.boulder.ibm.com/infocenter/wmqv6/v6r0/index.jsp?topic=/com.ibm.mq.csqzaf.doc/cs10270_.htm\">(2) with an external XA tx manager</a>, such as in WAS.)</li>\r\n</ul>\r\n</li>\r\n</ul>\r\n<h3>Batch job approach evaluation</h3>\r\n<ul>\r\n\t<li>Advantages\r\n<ul>\r\n\t<li><strong>Simple implementation of</strong> <strong>flexible</strong> <strong>delayed retrials</strong> - upon a resource outage, end the job and try again during the next  scheduled run or, perhaps, retry first after a manual delay  (Thread.sleep(); beware connection timeouts).</li>\r\n\t<li><strong>Simple integration into our monitoring</strong>/logging framework incl. the Operations Dashboard.</li>\r\n</ul>\r\n</li>\r\n\t<li>Disadvantages\r\n<ul>\r\n\t<li><strong>More coding</strong> to set up/clean the resources and handle errors, which is not trivial, and thus also <strong>more bug prone</strong>.</li>\r\n\t<li><strong>Concurrent processing</strong> of the messages would be considerably <strong>more difficult</strong> to implement correctly if possible at all (if MQ JMS does implement the  necessary optional methods). We would need to use the advanced methods  targeted at app. server vendors - there is a non-MQ example of a <a title=\"Visit page outside WikiCentral\" rel=\"nofollow\" href=\"http://www.novell.com/documentation/extend52/Docs/help/MP/jms/tutorial/connConsumer-1.htm\">multithreaded (non-durable subscription) consumer<sup><img src=\"https://w3.tap.ibm.com/w3ki/images/icons/linkext7.gif\" border=\"0\" alt=\"\" width=\"7\" height=\"7\" align=\"absmiddle\" /></sup></a>. Hopefully it could be modified for a durable one using <a title=\"Visit page outside WikiCentral\" rel=\"nofollow\" href=\"http://bit.ly/d1iucS\">Connection.createDurableConnectionConsumer<sup><img src=\"https://w3.tap.ibm.com/w3ki/images/icons/linkext7.gif\" border=\"0\" alt=\"\" width=\"7\" height=\"7\" align=\"absmiddle\" /></sup></a> with the same simple implementation of ServerSessionPool.\r\n<ul>\r\n\t<li>Impl. details: The \"pool\" would always create a new custom  ServerSession implementation. instance, whose getSession() would simply  create a new transacted TopicSession, set its MessageListener, and run  the session in a new Thread when start() called. Notice that  (Topic)Session implements Runnable, whose run() invokes the provided  listener sequentially for available messages. The listener would process a  message and call commit/rollback on its owning session (see this <a title=\"Visit page outside WikiCentral\" rel=\"nofollow\" href=\"http://www.magpiebrain.com/2005/04/04/jms-transactions-and-exception-handling/\">transactional listener example<sup><img src=\"https://w3.tap.ibm.com/w3ki/images/icons/linkext7.gif\" border=\"0\" alt=\"\" width=\"7\" height=\"7\" align=\"absmiddle\" /></sup></a>).</li>\r\n\t<li>Important: <strong>Handling of failed messages</strong> would need to be  considered carefully as returning a message to the queue would lead to  its immediate re-processing and likely rejection by one of the other  threads, exceeding its backout treshold in a few seconds and thus  subverting the delayed retrial processing. On the other hand, as  mentioned above, we should anyway be able to distinguish resource  outage, in which case we would stop processing immediately, and a  problematic message, which would anyway end up in the backout queue so  this is perhaps not a real issue.</li>\r\n\t<li>Note: When using MessageListeners, it's important to set an  ExceptionListener on the connection because some errors can only be  communicated this way.</li>\r\n</ul>\r\n</li>\r\n</ul>\r\n</li>\r\n</ul>\r\n<h1>Summary and conclusion</h1>\r\nThe version and fixpack level of WMQ/WAS is very important.<br><br>﻿Both the approaches have some pros and cons and it depends on the requirements and their priority which one would be more suitable.<br><br>MDB: ﻿It's more difficult to implement delayed retrial if it is required - it may be implemented via a scheduled EJB automatically re-enabling the MDB stopped by WAS after a number of failures (one issue is that we'd need WAS admin rights for the EJB to do that; another is performance due to the need to either monitor logs or check the MDB's status regularly). On the other hand, concurrent processing is available out of the box and also implementing a bean notifying about problematic messages in the backout queue is simpler thanks to the injection of the mail API resources. This solution may thus require some JMX and Java EE (scheduled EJB) magic and there may be unexpected problems with that.<br><br>﻿JOB: Concurrency: it's more difficult to implement processing of the messages in parallel, there is even a slight chance that it's impossible. Also  more coding is required and thus there will be more bugs. On the other hand we can implement delayed retrials as we want. Thus if concurrent processing isn't critical while the automatic delayed retrial may be then this would be the best approach.",
  "excerpt": ""
 },
 {
  "title": "SSH magic: Authorize only once for multiple ssh/scp invocations",
  "published": "2010-09-10 13:45:09",
  "postType": "post",
  "slug": "/2010/09/10/ssh-magic-authorize-only-once-for-multiple-sshscp-invocations/",
  "status": "publish",
  "tags": [
   "linux",
   "sharing",
   "ssh",
   "unix"
  ],
  "categories": [
   "General"
  ],
  "content": "OpenSSH has a nice feature that makes it possible to open one \"master connection\", which can be shared by multiple subsequent ssh/scp/sftp \"slave connections\". The advantage is that you need to supply password only when opening the master connection and thus you can easily perform a sequence of remote commands without constant re-authentication. Let's see how to do it in such a way that it can be used in a script.\r\n<!--more-->\r\n<h2>1. Open the master connection</h2>\r\nWe will open an SSH connection that sets up the shared channel and puts itself into the background when authenticated and does nothing else:<br><br><pre><code>\r\nSSHSOCKET=~/.ssh/myUsername@targetServerName\r\nssh -M -f -N -o ControlPath=$SSHSOCKET myUsername@targetServerName\r\n</code></pre><br><br>The options have the following meaning:\r\n<ul>\r\n\t<li>-M instructs SSH to become the master, i.e. to create a master socket that will be used by the slave connections</li>\r\n\t<li>-f makes SSH to go into the background after the authentication</li>\r\n\t<li>-N tells SSH not to execute any command or to expect an input from the user; that's good because we want it only to manage and keep open the master connection and nothing else</li>\r\n\t<li>-o ControlPath=$SSHSOCKET - this defines the name to be used for the socket that represents the master connection; the slaves will use the same value to connect via it</li>\r\n</ul>\r\nThanks to -N and -f the SSH master connection will get out of the way but will stay open and such usable by subsequent ssh/scp invocations. This is exactly what we need in a shell script. If you just do something manually than you can leave out -N and -f and use directly this connection for whatever you need while you can also open a slave connection in another terminal window. Just don't forget that once the master connection exits slaves won't work.\r\n<h2>2. Open and close other connections without re-authenticating as you like</h2>\r\nNow you can do as many ssh/scp operations as you like and you won't be prompted for a password. You only always have to provide the command with the same ControlPath, which we ensure by having stored it into the variable SSHSOCKET:<br><br><pre><code>\r\nssh -o ControlPath=$SSHSOCKET myUsername@targetServerName &quot;echo 'Hello from the remote server!'; ls&quot;\r\n...\r\nscp -o ControlPath=$SSHSOCKET myUsername@targetServerName:remoteFile.txt ./\r\n</code></pre><br><br><h2>3. Close the master connection</h2>\r\nYou likely don't want to keep the master connection open forever. And it's better to close it properly beause otherwise the socket file would not be deleted and would prevent the master connection from opening in the future.<br><br>You <a href=\"https://bugzilla.mindrot.org/show_bug.cgi?id=1473\">close the connection by sending the control command <em>exit</em></a> to the socket:<br><br><pre><code>\r\nssh -S $SSHSOCKET -O exit myUsername@targetServerName\r\n</code></pre><br><br>Notes:\r\n<ul>\r\n\t<li>This time time we use -S instead of  \"-o ControlPath=\" because we intend to use the socket for controlling the master SSH instance</li>\r\n\t<li>-O &lt;command name&gt; is used to send a command to the master SSH instance; the commands allowed are \"exit\" and \"check\"</li>\r\n</ul><br><br><h2>Conclusion</h2>\r\nThis is a neat way how to execute multiple ssh/scp/... commands while only supplying a password once. There are also other ways how to do it, such as putting you key into the ~/.ssh/authorized_keys at the host or using the ssh-agent and ssh-add.<br><br>It should be noted that at least some older versions of OpenSSH have the limitation that slave connections cannot set up port forwarding.<br><br>See the <a href=\"http://linuxmanpages.com/man1/ssh.1.php\">ssh manpage</a> and the ControlMaster section on <a href=\"http://linuxmanpages.com/man5/ssh_config.5.php\">ssh_config</a> for details.",
  "excerpt": ""
 },
 {
  "title": "Jetty-maven-plugin: Running a webapp with a DataSource and security",
  "published": "2010-09-10 15:20:39",
  "postType": "post",
  "slug": "/2010/09/10/jetty-maven-plugin-running-a-webapp-with-a-datasource-and-security/",
  "status": "publish",
  "tags": [
   "datasource",
   "development",
   "java",
   "javaEE",
   "jetty",
   "Maven",
   "security"
  ],
  "categories": [
   "j2ee",
   "Languages",
   "Tools"
  ],
  "content": "This post describes how to configure the <a href=\"http://mojo.codehaus.org/jetty-maven-plugin/usage.html\">jetty-maven-plugin</a> and the <a href=\"http://jetty.codehaus.org/jetty/\">Jetty</a> servlet container to run a web application that uses a data source and requires users to log in, which are the basic requirements of most web applications. I use Jetty in development because it's fast and easy to work with.<!--more-->\r\n<h1>Why Jetty?</h1>\r\nWell, because it's much faster then the Websphere AS I normally use and it really well supports fast (or shall I say agile? :-)) development thanks to its fast turnaround. And because it's simply cool to type<br><br><pre><code>\r\nbash$ svn checkout http://example.com/repo/trunk/mywebapp\r\nbash$ cd mywebapp\r\nbash$ mvn jetty:run\r\nbash$ firefox http://localhost:8080/mywebapp\r\n</code></pre><br><br>and to be able to immediatelly log into and interact with the application.<br><br>However it should be noted that Jetty isn't a full-featured JavaEE server and thus may not be always usable.\r\n<h1>Project setup</h1>\r\n<h2>General configuration</h2>\r\nYou need to add the Jetty plugin to your <strong>pom.xml</strong>:<br><br><pre><code>\r\n&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;\r\n  xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd&quot;&gt;\r\n  &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;\r\n  &lt;groupId&gt;com.example&lt;/groupId&gt;\r\n  &lt;artifactId&gt;mywebapp&lt;/artifactId&gt;\r\n  &lt;packaging&gt;war&lt;/packaging&gt;\r\n  ...\r\n  &lt;build&gt;\r\n  \t...\r\n  \t&lt;plugins&gt;\r\n    &lt;plugin&gt;\r\n      &lt;groupId&gt;org.mortbay.jetty&lt;/groupId&gt;\r\n      &lt;artifactId&gt;maven-jetty-plugin&lt;/artifactId&gt;\r\n      &lt;version&gt;6.1.0&lt;/version&gt;\r\n      &lt;configuration&gt;\r\n        &lt;scanIntervalSeconds&gt;3&lt;/scanIntervalSeconds&gt;\r\n          ...\r\n      &lt;/configuration&gt;\r\n      ...\r\n    &lt;/plugin&gt;\r\n    ...\r\n  &lt;/plugins&gt;<br><br>  &lt;/build&gt;\r\n&lt;/project&gt;\r\n</code></pre><br><br>As you can see, I'm using Jetty 6.1.0.\r\n<h2>Defining a DataSource</h2>\r\nLet's assume that the application uses a DataSource configured at the server and accesses it normally via JNDI. Then we must define a reference to the data source in src/main/webapp/<strong>WEB-INF/web.xml</strong>:<br><br><pre><code>\r\n&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;\r\n&lt;web-app id=&quot;WebApp_ID&quot; version=&quot;2.4&quot;\r\n\txmlns=&quot;http://java.sun.com/xml/ns/j2ee&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;\r\n\txsi:schemaLocation=&quot;http://java.sun.com/xml/ns/j2ee http://java.sun.com/xml/ns/j2ee/web-app_2_4.xsd&quot;&gt;\r\n\t...\r\n\t&lt;servlet&gt;...&lt;/servlet&gt;\r\n\t...\r\n\t&lt;resource-ref&gt;\r\n\t\t&lt;res-ref-name&gt;jdbc/LMSDB&lt;/res-ref-name&gt;\r\n\t\t&lt;res-type&gt;javax.sql.DataSource&lt;/res-type&gt;\r\n\t\t&lt;res-auth&gt;Container&lt;/res-auth&gt;\r\n\t\t&lt;res-sharing-scope&gt;Shareable&lt;/res-sharing-scope&gt;\r\n\t&lt;/resource-ref&gt;\r\n&lt;/web-app&gt;\r\n</code></pre><br><br>Next we need to describe the DataSource to Jetty. There are multiple ways to do that, I've chosen to do so in src/main/webapp/<strong>WEB-INF/jetty-env.xml</strong>:<br><br><pre><code>\r\n&lt;?xml version=&quot;1.0&quot;?&gt;\r\n&lt;!DOCTYPE Configure PUBLIC &quot;-//Mort Bay Consulting//DTD Configure//EN&quot; &quot;http://jetty.mortbay.org/configure.dtd&quot;&gt;\r\n&lt;Configure class=&quot;org.mortbay.jetty.webapp.WebAppContext&quot;&gt;\r\n  &lt;New id=&quot;LMSDB&quot; class=&quot;org.mortbay.jetty.plus.naming.Resource&quot;&gt;\r\n    &lt;Arg&gt;jdbc/LMSDB&lt;/Arg&gt;\r\n    &lt;Arg&gt;\r\n    \t&lt;New class=&quot;com.ibm.db2.jcc.DB2SimpleDataSource&quot;&gt;\r\n                 &lt;Set name=&quot;DatabaseName&quot;&gt;LMSDB&lt;/Set&gt;\r\n                 &lt;Set name=&quot;User&quot;&gt;myUser&lt;/Set&gt;\r\n                 &lt;Set name=&quot;Password&quot;&gt;secret&lt;/Set&gt;\r\n                 &lt;Set name=&quot;ServerName&quot;&gt;db.toronto.ca.ibm.com&lt;/Set&gt;\r\n                 &lt;Set name=&quot;PortNumber&quot;&gt;3711&lt;/Set&gt;\r\n     &lt;/New&gt;\r\n    &lt;/Arg&gt;\r\n  &lt;/New&gt;\r\n&lt;/Configure&gt;\r\n</code></pre><br><br>Notice that the class used is DB2SimpleDataSource and not a JDBC driver. That is, of course, because we need a DataSource, not a Driver. The Jetty wiki pages also contain examples of <a href=\"http://docs.codehaus.org/display/JETTY/DataSource+Examples\">DataSource configuration for other DBs</a>.<br><br>Finally we must make the corresponding JDBC implementation available to Jetty by adding it to the plugin's dependencies in the <strong>pom.xml</strong>:<br><br><pre><code>\r\n&lt;plugin&gt;\r\n  &lt;groupId&gt;org.mortbay.jetty&lt;/groupId&gt;\r\n  &lt;artifactId&gt;maven-jetty-plugin&lt;/artifactId&gt;\r\n  &lt;version&gt;6.1.0&lt;/version&gt;<br><br>  &lt;configuration&gt;\r\n\t&lt;...\r\n  &lt;/configuration&gt;<br><br>  &lt;dependencies&gt;\r\n\t&lt;dependency&gt;\r\n\t\t&lt;groupId&gt;com.ibm.db2&lt;/groupId&gt;\r\n\t\t&lt;artifactId&gt;db2jcc&lt;/artifactId&gt;\r\n\t\t&lt;version&gt;9.7&lt;/version&gt;\r\n\t\t&lt;type&gt;jar&lt;/type&gt;\r\n\t\t&lt;scope&gt;system&lt;/scope&gt;\r\n\t\t&lt;systemPath&gt;${basedir}/../lms.sharedlibraries/db2/db2jcc.jar&lt;/systemPath&gt;\r\n\t&lt;/dependency&gt;\r\n\t&lt;dependency&gt;\r\n\t\t&lt;groupId&gt;com.ibm.db2&lt;/groupId&gt;\r\n\t\t&lt;artifactId&gt;db2jcc_license_cisuz&lt;/artifactId&gt;\r\n\t\t&lt;version&gt;9.7&lt;/version&gt;\r\n\t\t&lt;type&gt;jar&lt;/type&gt;\r\n\t\t&lt;scope&gt;system&lt;/scope&gt;\r\n\t\t&lt;systemPath&gt;${basedir}/../lms.sharedlibraries/db2/db2jcc_license_cisuz.jar&lt;/systemPath&gt;\r\n\t&lt;/dependency&gt;\r\n  &lt;/dependencies&gt;\r\n&lt;/plugin&gt;\r\n</code></pre><br><br>Please do not scorn me for using system-scoped dependencies ;-), sometimes that is unfortunatelly the most feasible way.\r\n<h2>Enabling security and configuring an authentication mechanism</h2>\r\nWe would like to limit access to the application only to the authenticated users in the ADMIN role with the exception of pages under public/. Therefore we declare the appropriate security constraints in web.xml:<br><br><pre><code>\r\n...\r\n&lt;security-constraint&gt;\r\n\t&lt;display-name&gt;authorizedUsers&lt;/display-name&gt;\r\n\t&lt;web-resource-collection&gt;\r\n\t\t&lt;web-resource-name&gt;ALL URLs&lt;/web-resource-name&gt;\r\n\t\t&lt;url-pattern&gt;/*&lt;/url-pattern&gt;\r\n\t&lt;/web-resource-collection&gt;\r\n\t&lt;auth-constraint&gt;\r\n\t\t&lt;role-name&gt;ADMIN&lt;/role-name&gt;\r\n\t&lt;/auth-constraint&gt;\r\n\t&lt;!--user-data-constraint&gt;\r\n\t\t&lt;transport-guarantee&gt;CONFIDENTIAL&lt;/transport-guarantee&gt;\r\n\t&lt;/user-data-constraint--&gt;\r\n&lt;/security-constraint&gt;<br><br>&lt;security-constraint&gt;\r\n\t&lt;display-name&gt;publicAccess&lt;/display-name&gt;\r\n\t&lt;web-resource-collection&gt;\r\n\t\t&lt;web-resource-name&gt;Public pages&lt;/web-resource-name&gt;\r\n\t\t&lt;url-pattern&gt;/public/*&lt;/url-pattern&gt;\r\n\t&lt;/web-resource-collection&gt;\r\n&lt;/security-constraint&gt;<br><br>&lt;login-config&gt;\r\n\t&lt;auth-method&gt;BASIC&lt;/auth-method&gt;\r\n\t&lt;realm-name&gt;Learning@IBM Mini Person Feed Management&lt;/realm-name&gt;\r\n&lt;/login-config&gt;<br><br>&lt;security-role&gt;\r\n\t&lt;description&gt;administrator access&lt;/description&gt;\r\n\t&lt;role-name&gt;ADMIN&lt;/role-name&gt;\r\n&lt;/security-role&gt;\r\n...\r\n</code></pre><br><br>Beware that Jetty doesn't support HTTPS out of the box and thus if you will add the data constraint CONFIDENTIAL to any resource, you will automatically get HTTP 403 FORBIDDEN no matter what you do.  That's why I've commented it out above. It is possible to <a href=\"http://docs.codehaus.org/display/JETTY/How+to+configure+SSL\">enable SSL in Jetty</a> but I didn't want to bother with certificate generation etc.<br><br>Next we need to tell Jetty how to authenticate users. This is done via <a href=\"http://docs.codehaus.org/display/JETTY/Realms\">realms</a> and we will use the simplest, file-based one. Again there are multiple ways to configure it, for example in the <strong>pom.xml</strong>:<br><br><pre><code>\r\n&lt;plugin&gt;\r\n  &lt;groupId&gt;org.mortbay.jetty&lt;/groupId&gt;\r\n  &lt;artifactId&gt;maven-jetty-plugin&lt;/artifactId&gt;\r\n  &lt;version&gt;6.1.0&lt;/version&gt;<br><br>  &lt;configuration&gt;\r\n\t&lt;scanIntervalSeconds&gt;3&lt;/scanIntervalSeconds&gt;\r\n\t  &lt;userRealms&gt;\r\n\t\t&lt;userRealm implementation=&quot;org.mortbay.jetty.security.HashUserRealm&quot;&gt;\r\n\t\t  &lt;name&gt;Learning@IBM Mini Person Feed Management&lt;/name&gt;\r\n\t\t  &lt;config&gt;src/test/resources/jetty-users.properties&lt;/config&gt;\r\n\t\t&lt;/userRealm&gt;\r\n\t  &lt;/userRealms&gt;\r\n  &lt;/configuration&gt;<br><br>  &lt;dependencies&gt;...&lt;/dependencies&gt;\r\n&lt;/plugin&gt;\r\n</code></pre><br><br>The name must match exactly the realm-name in web.xml. You then define the users and their passwords and roles in the declared file, in this case in src/test/resources/<strong>jetty-users.properties</strong>:<br><br><pre><code>\r\nuser=psw,ADMIN\r\n</code></pre><br><br>The format of the file is username=password[,role1,role2,...].<br><br>When you download Jetty, you will find a fine example of using <a title=\"Jetty JAAS configuration\" href=\"http://docs.codehaus.org/display/JETTY/JAAS\">JAAS</a> with a file-based back-end for authentication and authorization under examples/test-jaas-webapp (invoke mvn jetty:run from the folder and go to http://localhost:8080/jetty-test-jaas/). However it seems that JAAS causes an additional overhead visible as a few-seconds delay when starting the server so it might be preferrable not to use it.\r\n<h1>Conclusion</h1>\r\nWith Jetty it's easy to enable security and create a data source, which are the basic requirements of most web applications. Anybody can then very easily run the application to test and develop it. Development is where Jetty really shines provided that you don't need any feature it doesn't have.<br><br>When troubleshooting, you may want to tell Jetty to <a href=\"http://docs.codehaus.org/display/JETTY/Debugging\">log at the debug level</a> with mvn -DDEBUG .. or to <a href=\"http://docs.codehaus.org/display/JETTY/Logging+Requests\">log requests</a>, which can be also configured in the jetty-env.xml.<br><br>Beware that this post describes configuration for Jetty 6.1.0. It can be different in other versions and it certainly is different in Jetty 7.",
  "excerpt": ""
 },
 {
  "title": "Exposing a POJO as a JMX MBean easily with Spring",
  "published": "2010-09-16 08:59:19",
  "postType": "post",
  "slug": "/2010/09/16/exposing-a-pojo-as-a-jmx-mbean-easily-with-spring/",
  "status": "publish",
  "tags": [
   "exception",
   "java",
   "jmx",
   "mbean",
   "rmi",
   "spring"
  ],
  "categories": [
   "Languages"
  ],
  "content": "JMX is a great way to check or change state variables or invoke a method in a (remote) running application via a management GUI such as JConsole. And Spring makes it trivial to expose any POJO as a JMX MBean with only little configuration in a few minutes. The <a href=\"http://static.springsource.org/spring/docs/2.5.x/reference/jmx.html\">Spring JMX documentation</a> is very good, however there are few points that I struggled with for a while and would therefore like to record here the right solutions.<br><br>I needed to monitor a command-line java application using Spring 2.5 on IBM JVM <span style=\"text-decoration:line-through;\">1.4</span> 1.5 running on a server with a jconsole on Sun JVM 1.6 as the JMX client on my PC.<br><br><!--more-->All the XML snippets are from a Spring application-context.xml. If you haven't used Spring before, read a tutorial on its configuration and dependency injection.\r\n<h2>Turning a POJO into an MBean</h2>\r\nJMX makes it possible to expose getters, setters and operations taking primitive or <a href=\"http://java.sun.com/javase/technologies/core/mntr-mgmt/javamanagement/best-practices.jsp#mozTocId931827\">complex data types as parameters</a> (though types other then few special ones require the client to have the classes). You tell Spring to expose a POJO as an MBean as follows:<br><br><pre><code>\r\n&lt;bean id=&quot;myMBean&quot;\r\n\tclass=&quot;my.package.JobPerformanceStats&quot;\r\n\tfactory-method=&quot;instance&quot; /&gt;<br><br>&lt;bean class=&quot;org.springframework.jmx.export.MBeanExporter&quot; lazy-init=&quot;false&quot;&gt;\r\n\t&lt;property name=&quot;beans&quot;&gt;\r\n\t  &lt;map&gt;\r\n\t\t&lt;entry key=&quot;bean:name=MyMBeanName&quot; value-ref=&quot;myMBean&quot;/&gt;\r\n\t  &lt;/map&gt;\r\n\t&lt;/property&gt;\r\n&lt;/bean&gt;\r\n</code></pre><br><br>First you declare an instance of the POJO class - the <em>myMBean</em> (for other reasons I've an old-fashioned singleton and use JobPerformanceStats.instance() to access the bean). Next you declare an MBeanExporter with lazy-init=\"false\" and tell it about your bean. (There are also other ways to do it, including auto-discovery.) The bean will be then visible under its key, i.e. \"bean:name=MyMBeanName\", which JConsole displays as \"MyMBeanName\".<br><br>Notice that the MBeanExporter only works under JVM 1.5+ because it uses the new java.lang.management package. Under 1.4 Spring would fail with\r\n<blockquote><pre><code>java.lang.NoClassDefFoundError: javax/management/MBeanServerFactory\r\n at org.springframework.jmx.support.MBeanServerFactoryBean.createMBeanServer\r\n</code></pre></blockquote>\r\nBy default it will expose all public methods and attributes. You can change that in various ways, for example with the help of an interface.<br><br>If you are not running in a container that already provides an MBean server, which is my case here, you must tell Spring to start one:<br><br><pre><code>\r\n&lt;bean class=&quot;org.springframework.jmx.support.MBeanServerFactoryBean&quot;/&gt;\r\n</code></pre>\r\n<h2>Enabling remote access</h2>\r\nTo make the MBean accessible from another machine, you must expose it to the world by declaring a ConnectorServerFactoryBean configured with an appropriate communication mechanism.\r\n<h3>Remote access over JMXMP</h3>\r\nBy default the ConnectorServerFactoryBean exposes MBeans over JMXMP with the address <em>service:jmx:jmxmp://localhost:9875</em> :<br><br><pre><code>\r\n&lt;bean class=&quot;org.springframework.jmx.support.ConnectorServerFactoryBean&quot; /&gt;\r\n</code></pre><br><br>However this protocol <a href=\"http://forums.sun.com/thread.jspa?threadID=5204940\">isn't supported out of the box</a> and you must include <a href=\"https://opendmk.dev.java.net/download/\">jmxremote_optional.jar, a part of OpenDMK</a>, on the classpath of both the MBean application and the jconsole client to avoid the exception\r\n<blockquote>org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'org.springframework.jmx.support.ConnectorServerFactoryBean#0' defined in class path resource [application-context.xml]: Invocation of init method failed; nested exception is <strong>java.net.MalformedURLException: Unsupported protocol: jmxmp</strong></blockquote>\r\n<h3>Remote access over RMI</h3>\r\nAlternatively you can expose the MBeans over RMI, which has no additional dependencies:<br><br><pre><code>\r\n&lt;!--\r\nNow expose the server for remote access via RMI\r\nLocal access:\tservice:jmx:rmi://localhost/jndi/rmi://localhost:10099/myconnector\r\nRemote access: \tservice:jmx:rmi:///jndi/rmi://your.host:10099/myconnector\r\nor service:jmx:rmi://localhost/jndi/rmi://localhost:10099/myconnector\r\n--&gt;\r\n&lt;bean\r\n class=&quot;org.springframework.jmx.support.ConnectorServerFactoryBean&quot;\r\n depends-on=&quot;rmiRegistry&quot;&gt;\r\n &lt;property name=&quot;objectName&quot; value=&quot;connector:name=rmi&quot; /&gt;\r\n &lt;property name=&quot;serviceUrl&quot;\r\n value=&quot;service:jmx:rmi://localhost/jndi/rmi://localhost:10099/myconnector&quot; /&gt;\r\n&lt;/bean&gt;<br><br>&lt;bean id=&quot;rmiRegistry&quot;\r\n class=&quot;org.springframework.remoting.rmi.RmiRegistryFactoryBean&quot;&gt;\r\n &lt;property name=&quot;port&quot; value=&quot;10099&quot; /&gt;\r\n&lt;/bean&gt;\r\n</code></pre><br><br>However there are also some catches you must avoid:\r\n<ol>\r\n\t<li>You must <strong>start an RMI registry</strong> so that the connector can register the MBean there; it won't start one for you</li>\r\n\t<li>You must <a href=\"http://marxsoftware.blogspot.com/2008/02/spring-jmx-rmi-and-depends-on.html\">make sure that the registry is started before the connector</a> tries to use either by declaring it before the connector or by making this dependency explicit with the <strong>depends-on</strong> attribute</li>\r\n</ol>\r\nIf you don't set it up correctly you will get an exception like\r\n<blockquote>org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'org.springframework.jmx.support.ConnectorServerFactoryBean#0' defined in class path resource [application-context.xml]: Invocation of init method failed; nested exception is java.io.IOException: Cannot bind to URL [rmi://localhost:10099/jmxrmi]: javax.naming.ServiceUnavailableException [Root exception is java.rmi.ConnectException: Connection refused to host: localhost; nested exception is:<strong> java.net.ConnectException: Connection refused: connect</strong>].</blockquote>\r\n<h3>Local MBean server accessed over an SSH tunnel</h3>\r\nFor increased security you may want to prefer not to expose your MBeans to remote access by making them accessible only from the local machine (127.0.0.1) and use na SSH tunnel so that a remote JConsole can access them as a local application. This is certainly possible but may be difficult because normally JMX goes over RMI, which <a href=\"http://forums.sun.com/thread.jspa?messageID=10742673#10752047\">uses two ports</a>: one for the RMI Registry and another one for the actual service (MBean server here), which is usually chosen randomly at the runtime, and you'd need to tunnel both. Fortunately, <a href=\"http://forum.springsource.org/archive/index.php/t-28002.html\">Spring makes it possible to configure both the ports</a>:<br><br><pre><code>\r\n&lt;bean\r\n\tclass=&quot;org.springframework.jmx.support.ConnectorServerFactoryBean&quot;\r\n\tdepends-on=&quot;rmiRegistry&quot;&gt;\r\n\t&lt;property name=&quot;objectName&quot; value=&quot;connector:name=rmi&quot; /&gt;\r\n\t&lt;property name=&quot;serviceUrl&quot;\r\n\t\tvalue=&quot;service:jmx:rmi://127.0.0.1:STUBPORT/jndi/rmi://localhost:REGISTRYPORT/myconnector&quot; /&gt;\r\n&lt;/bean&gt;<br><br>&lt;bean id=&quot;rmiRegistry&quot;\r\n\tclass=&quot;org.springframework.remoting.rmi.RmiRegistryFactoryBean&quot;&gt;\r\n\t&lt;property name=&quot;port&quot; value=&quot;REGISTRYPORT&quot; /&gt;\r\n&lt;/bean&gt;\r\n</code></pre><br><br>Replace STUBPORT and REGISTRYPORT with suitable numbers and tunnel those two. Notice that the REGISTRYPORT number is same in the connector's serviceUrl and in the RMI registry's port attribute.<br><br><strong>WARNING</strong>: The configuration above actually <em>doesn't prevent direct access from a remote</em> application. To really force the RMI registry to only listen for connection from the local host we would likely need to set - under Sun JVM without Spring - the system property com.sun.management.jmxremote. Additionally, to force the registry to use the IP 120.0.0.1, we'd need to set java.rmi.server.hostname=localhost (applies to Spring too). See this <a href=\"http://forums.sun.com/thread.jspa?threadID=5131562\">discussion about forcing local access</a>. I'm not sure how to achieve the same result with Spring while still preserving the ability to specify both the RMI ports. Check also the JavaDoc for Spring's <a href=\"http://static.springsource.org/spring/docs/2.5.x/api/org/springframework/remoting/rmi/RmiServiceExporter.html\">RmiServiceExporter </a>.<br><br>Related posts and docs:\r\n<ul>\r\n\t<li><a href=\"http://jared.ottleys.net/alfresco/tunneling-debug-and-jmx-for-alfresco\">Tunneling Debug and JMX for Alfresco</a> (A. uses Spring)- see the second section, SSH Tunneling for JMX</li>\r\n\t<li><a href=\"http://confluence.sakaiproject.org/display/QA/Remote+JVM+profiling+via+SSH+tunnels\">A custom tunneling RMI agent</a> - uses a configured port instead of a random one</li>\r\n\t<li><a href=\"http://codedependents.com/2009/05/23/monitoring-activemq-using-jmx-over-ssh/\">Monitoring ActiveMQ Using JMX Over SSH</a></li>\r\n\t<li><a href=\"http://jcp.org/aboutJava/communityprocess/final/jsr003/index3.html\">JMX 1.2 specification</a> and <a href=\"http://jcp.org/en/jsr/summary?id=160\">JMX 1.2 Remote API specification</a>; from the JMX spec.: \"The MBean server relies on <em>protocol adaptors</em> and <em>connectors</em> to make the agent\r\naccessible from management applications <strong>outside the agent’s JVM</strong>.\" On the other hand, the <a href=\"http://download.oracle.com/javase/1.5.0/docs/guide/management/agent.html#local\">Oracle JMX page</a> reads that if you set com.sun.management.jmxremote (as opposed to ...jmxremote.port), you make it possible \"to monitor a local Java platform, that is, a <strong>JVM running on the same machine</strong>\" - thus not necessarily from the same JVM.</li>\r\n</ul>\r\n<h2>Connecting with JConsole</h2>\r\nFire up JConsole and type the appropriate remote address, for example service:jmx:rmi:///jndi/rmi://your.server.com:10099/myconnector, if connecting to an application on the remote machine your.server.com accessible via RMI.<br><br>Regarding the connection URL, if you have a a connector with the serviceUrl of \"service:jmx:rmi://<em>myhost:9999</em>/jndi/rmi://<em>localhost:10099</em>/myconnector\" then, from a client, you can use either service:jmx:rmi://<em>myhost:9999</em>/jndi/rmi://<em>your.server.com:10099</em>/myconnector or simply service:jmx:rmi:///jndi/rmi://<em>your.server.com:10099</em>/myconnector because, according to the <a href=\"http://jcp.org/en/jsr/summary?id=160\">JMX 1.2 Remote API specification</a> (page 90):\r\n<blockquote>... the hostname and port number\r\n# (myhost:9999 in the examples) are not used by the client and, if\r\n# present, are essentially comments. The connector server address\r\n# is actually stored in the serialized stub (/stub/ form) or in the\r\n# directory entry (/jndi/ form).</blockquote>\r\n<h2>IBM JVM, JConsole and JMX configuration</h2>\r\nThe IBM JVM 5 SDK guide indicates that the <a href=\"https://www.ibm.com/developerworks/java/jdk/aix/j532/sdkguide.aix32.html#sdktools\">IBM SDK also contains JConsole</a> and recognizes <a href=\"https://www.ibm.com/developerworks/java/jdk/aix/j532/sdkguide.aix32.html#cmdline\">the same JMX-related system properties</a>, namely com.sun.management.jmxremote.* (though \"com.sun.management.jmxremote\" itself isn't mentioned).<br><br>Notice that the IBM JConsole is a bit different, for instance it's missing the Local tab, which is replaced by specifying the command-line option connection=localhost (search the SDK guide for \"JConsole monitoring tool Local tab\").\r\n<h2>Further improvements</h2>\r\n<h3>JVM 1.5: Exposing the MemoryMXBean</h3>\r\nSince Java 5.0 there is a couple of useful platform MBeans that provide information about the JVM, including also the <a href=\"http://download.oracle.com/javase/1.5.0/docs/api/java/lang/management/MemoryMXBean.html\">java.lang.management.MemoryMXBean</a>, that let you see the heap usage, invoke GC etc.<br><br>You can make it available to JConsole and other JMX agents as follows (though there must be an easier way):<br><br><pre><code>\r\n&lt;bean class=&quot;org.springframework.jmx.export.MBeanExporter&quot; lazy-init=&quot;false&quot;&gt;\r\n\t&lt;property name=&quot;beans&quot;&gt;\r\n\t  &lt;map&gt;\r\n\t\t&lt;entry key=&quot;bean:name=Memory2&quot; value-ref=&quot;memProxy&quot;/&gt;\r\n\t\t&lt;!-- other exported beans may follow ... --&gt;\r\n\t  &lt;/map&gt;\r\n\t&lt;/property&gt;\r\n&lt;/bean&gt;<br><br>&lt;bean id=&quot;memProxy&quot;\r\n\tclass=&quot;java.lang.management.ManagementFactory&quot;\r\n\tfactory-method=&quot;getMemoryMXBean&quot;\r\n\t/&gt;\r\n</code></pre><br><br><strong>Update</strong>: There indeed seems to be a <a href=\"http://forum.springsource.org/showthread.php?t=90640\">better way of exposing the platform MBeans directly</a> by replacing the Spring's MBeanServerFactoryBean with java.lang.management.ManagementFactory using its factory-method getPlatformMBeanServer. Of course this requires JVM 1.5+.\r\n<h3>Improving security with password authentication</h3>\r\nAccess to your MBeans over RMI may be protected with a password. According to a discussion, <a href=\"http://forum.springsource.org/archive/index.php/t-28002.html\">authentication is configured on the server connector</a>:\r\n<blockquote><pre><code>\r\n&lt;bean\r\n\tclass=&quot;org.springframework.jmx.support.ConnectorServerFactoryBean&quot;\r\n\tdepends-on=&quot;rmiRegistry&quot;&gt;\r\n\t&lt;property name=&quot;objectName&quot; value=&quot;connector:name=rmi&quot; /&gt;\r\n\t&lt;property name=&quot;serviceUrl&quot;\r\n\t\tvalue=&quot;service:jmx:rmi://localhost/jndi/rmi://localhost:10099/myconnector&quot; /&gt;\r\n    &lt;property name=&quot;environment&quot;&gt;\r\n    &lt;!-- the following is only valid when the sun jmx implementation is used --&gt;\r\n        &lt;map&gt;\r\n            &lt;entry key=&quot;jmx.remote.x.password.file&quot; value=&quot;etc/security/jmxremote.password&quot;/&gt;\r\n            &lt;entry key=&quot;jmx.remote.x.access.file&quot; value=&quot;etc/security/jmxremote.access&quot;/&gt;\r\n        &lt;/map&gt;\r\n    &lt;/property&gt;\r\n&lt;/bean&gt;\r\n</code></pre><br><br>The passwd and access files follow the templates that can be found in the JDK/jre/lib/management folder.</blockquote>\r\n<h2>Summary</h2>\r\nExposing a POJO as a MBean with Spring is easy, just don't forget to start an MBean server and a connector. For JMXMP, include the jmxmp impl. jar on the classpath and for RMI make sure to start a RMI registry before the connector.",
  "excerpt": ""
 },
 {
  "title": "The power of batching or speeding JDBC by 100",
  "published": "2010-09-20 09:38:34",
  "postType": "post",
  "slug": "/2010/09/20/the-power-of-batching-or-speeding-jdbc-by-100/",
  "status": "publish",
  "tags": [
   "java",
   "jdbc",
   "performance",
   "sql"
  ],
  "categories": [
   "Databases",
   "Languages"
  ],
  "content": "We all know that one coarse-grained operation is more efficient than a number of fine-grained ones when communicating over the network boundary but until recently I haven't realized how big that difference may be. While performing a simple query individually for each input record proceeded with the speed of <strong>11k records per hour</strong>, when I grouped each 100 queries together (with \"... WHERE id IN (value1, .., value100)), all <strong>200k</strong> records were processed <strong>in 13 minutes</strong>. In other words, using a batch of the size 100 led to the speed-up of nearly two orders of magnitude!<br><br>The moral: It really pays of to spend a little more time on writing the more complex batch-enabled JDBC code whenever dealing with larger amounts of data. (And it wasn't that much more effort thanks to <a href=\"http://www.ibm.com/developerworks/java/library/j-pg01115.html\">Groovy SQL</a>.)",
  "excerpt": ""
 },
 {
  "title": "Most interesting links of September",
  "published": "2010-09-30 20:33:30",
  "postType": "post",
  "slug": "/2010/09/30/most-interesting-links-of-september/",
  "status": "publish",
  "tags": [
   "business",
   "google",
   "java",
   "javaEE",
   "jvm",
   "performance",
   "sofware_engineering",
   "spring",
   "tdd"
  ],
  "categories": [
   "General",
   "Languages",
   "Testing",
   "Tools",
   "Top links of month"
  ],
  "content": "The most interesting articles and other IT resources I've encountered the previous month, delayed a bit due to my holiday in Andalusia. In no particular order. Included some performance stuff, few tools and few general SW engineering things.\r\n<ul>\r\n\t<li><a href=\"http://www.objectmentor.com/resources/articles/ocp.pdf\">The Open-Closed Principle</a> , i.e. open to extension, closed to modification - one of the basic principles in OOP underlying many best practices such as \"make all member variables private\" nicely explained, with code samples with and without O/CP applied.  Noteworthy: The principle is implemented with abstractions (abstract classes defining the constant part with subclasses being the extensions). You can't \"close\" your design against all changes and must thus choose the ones that are more likely, i.e. create a \"strategic closure\".</li>\r\n\t<li><a href=\"http://www.adam-bien.com/roller/abien/entry/java_ee_6_xor_spring\">Java EE 6 xor Spring</a> by A. Bien - the main difference is in the philosophy behind - Java EE is based on Convention over Configuration. The decision factor is usually the support policy, though. Also the tc Server is certainly better than a \"custom\" Tomcat with Spring.</li>\r\n\t<li><a href=\"http://www.thoughtworks.com/radar\">ThoughtWorks Technology Radar</a> - to help decision-makers from CIOs to developers understand emerging technologies and trends that affect the market today; though their assignment of GWT under hold is disputable (http://www.dzone.com/links/r/thoughtworks_radar_demystified_gwt.html); TW answers: \"As it turned out the conciseness of the text didn’t allow us to adequately make our points so that they were not misunderstood. We are interested in a discussion but our opinion about the suitability and usability of GWT has still not changed.\"\r\n<ul>\r\n\t<li>JavaScript as a 1st-class language w/ the same best practices (unit t., refact.,...); functional languages (Clojure &gt; Scala)</li>\r\n\t<li>WS-* beyond the basic profile, GWT, RIA on hold</li>\r\n</ul>\r\n</li>\r\n\t<li><a href=\"http://blog.asmartbear.com/virtual-assistant-startup.html\">\"Agile Business\" for a startup with \"Virtual Assistants\"</a>: outsource (to an \"Virtual Assistant\") what you can, only do what's necessary at the time even if that means doing manually (outsourced) st. that could be automated; this helped to decrease time from 160 MH to 10 MH.\r\n\"The lesson is that before you launch your product, think about the processes you can avoid automating. How about reminder emails? How about monthly billing? Could a human being run a report once a month and send emails or charge credit cards?\" , \"Every hour spent writing code is wasted time if that code could be replaced by a human being doing the same task until your product proves itself.\"</li>\r\n\t<li><a href=\"http://wiki.github.com/mchr3k/org.inmemprofiler/identifying-memory-allocators\">InMemProfiler: Identifying Memory Allocators</a> - tool to track memory allocation capable of attributing it to the classes (i.e. packages) of interest without blurring the results with char[] and all the java.lang.* classes</li>\r\n\t<li><a href=\"http://blog.codecentric.de/en/2010/08/easy-performance-analysis-with-appdynamics-lite/\">Easy Performance Analysis with AppDynamics Lite</a> - I'm fond of performance troubleshooting tools and AppDynamics Lite looks really cool. The post includes two very short yet very informative and nice screencast showing its installation and usage. App. D. automatically discovers Struts actions, JDBC calls, webservices etc. and captures slow operations with the necessary details; this is quite similar to what the open-source <a href=\"http://www.glassbox.com/\">Glassbox.com</a> does. The monitoring web UI is very nice and user friendly. See the white box on the right side at http://www.appdynamics.com/lite.php to see what JVMs, ASs and frameworks it supports. Check also the <a href=\"http://www.appdynamics.com/upgrade/\">comparison of the lite and standard versions</a> (max 30 transactions, max 2 hours if diagnostics data, ...).</li>\r\n\t<li><a href=\"http://googlewebtoolkit.blogspot.com/2010/09/google-relaunches-instantiations.html\">Google Relaunches Instantiations Developer Tools</a> - Now Available for Free - incl. the static code analysis tool (Eclipse plugin) <a href=\"http://code.google.com/intl/fr/webtoolkit/tools/download-codepro.html\">CodePro AnalytiX</a></li>\r\n\t<li>A blog about Terracota's new BigMemory (commercial) claims that <a href=\"http://www.dzone.com/links/r/bigmemory_explained_a_bit.html\">64b JVM with heap over few GB may be a nightmare</a> - \"<em>... not all people know about 64-bit JVMs and the nightmare these things can cause. Contrary to what other vendors are claiming, most shops such as Unibet, PartyPoker, Expedia, Sabre Holdings, Intercontinental Hotels Group, JP Morgan, Goldman, and more will tell you a 64-bit JVM pauses unpredictably and for minutes at a time. even when a 64 bit JVM is small (&lt;2GB) it takes 30+% more RAM than a 32-bit equivalent JVM running under the same app.</em>\"</li>\r\n\t<li>Presentation <a href=\"http://confreaks.net/videos/282-lsrc2010-real-software-engineering\">Real Software Engineering</a> by Glenn Vanderburg  - the talk is pretty interesting and I recommend it. Few, subjectively selected and interpreted points:\r\nThe SW engineering as taught in universities doesn't work, it's actually a caricature of \"engineering\" (that is, established practices that work). The reason is that SwE is unreasonably fascinated by (ideally mathematical) modeling and precise, repeatable processes. This is not how real SW development can or does work. Given the complexity and uncertainty, an empirical process, based on frequent feedback and continual adjustment, is much more suitable. Also we don't need complex models because prototyping and testing is nearly \"free\", compared e.g. to spacecraft engineering. And with BDD and tools like RSpec and FitNesse we may have both readable and executable specifications - the code becomes the model.</li>\r\n\t<li><a href=\"http://justinbozonier.posterous.com/monte-carlo-analysis-of-the-zero-defect-menta\">Monte Carlo Analysis of the Zero Defect Mentality of TDD</a> - conclusion: TDD pays off in the long run even though being slower [learning curve; 0-value bringing defect fixing] Fow short life time, TDD may be not worth it. Don't argue, simulate :-)</li>\r\n</ul>",
  "excerpt": ""
 },
 {
  "title": "Tip: Retrieving server certificate used in SSL communication (e.g. POP3s)",
  "published": "2010-10-21 09:37:59",
  "postType": "post",
  "slug": "/2010/10/21/tip-retrieving-server-certificate-used-in-ssl-communication-e-g-pop3s/",
  "status": "publish",
  "tags": [
   "certificate",
   "security",
   "SSL"
  ],
  "categories": [
   "General"
  ],
  "content": "If you would like to get the security <a href=\"http://en.wikipedia.org/wiki/Public_key_certificate\">certificate</a> used by a server in communication over SSL, such as with the HTTPS or POP3s protocols, for instance to install it on a client device that needs to talk to the server, you can use <a href=\"http://openssl.org/\">OpenSSL</a> to retrieve it:<br><br><pre><code><br><br>bash$ openssl s_client -connect pop.gmail.com:995 -showcerts<br><br></code></pre><br><br>You then store the text starting with \"-----BEGIN CERTIFICATE-----\" and ending with \"-----END CERTIFICATE-----\" (inclusive) into a file with the extension .pem.<br><br>You can also use openssl to convert the certificate into another format, e.g.:<br><br><pre><code><br><br>bash$ openssl x509 -in mycertificate.pem -inform PEM -out mycertificate.der -outform DER<br><br></code></pre><br><br>The information originates from the page <a href=\"http://www.axllent.org/docs/networking/gmail_pop3_with_fetchmail\">Gmail POP3 with Fetchmail</a> where you can find a more detailed description and also instructions for testing the certificate.",
  "excerpt": ""
 },
 {
  "title": "Most interesting links of October",
  "published": "2010-10-31 12:45:14",
  "postType": "post",
  "slug": "/2010/10/31/most-interesting-links-of-october/",
  "status": "publish",
  "tags": [
   "clojure",
   "gradle",
   "html",
   "java",
   "JavaScript",
   "JCP",
   "Maven",
   "Oracle",
   "tdd"
  ],
  "categories": [
   "General",
   "Languages",
   "Testing",
   "Tools",
   "Top links of month"
  ],
  "content": "Few of my favourite themes this month - TDD, performance, build tools/Maven. Plus a usefel JS library, news from the Java community x Oracle world etc.\r\n<ul>\r\n\t<li><a href=\"http://www.infoq.com/news/2010/10/can-oracle-save-java\">About dying JCP and too silent Oracle</a> (or <a href=\"http://blogs.oracle.com/henrik/2010/10/doug_lea_leaves_the_jcp_ec.html\">mostly silent</a>) - a summary of the latest issues and hot topics in the Java community that cause lot of rumor but still no reaction from Oracle including the criticism of JCP and its proclaimed decline. Update 11/1: The article about <a href=\"http://www.ibm.com/developerworks/java/library/j-openjdkroundup/index.html\">IBM, Oracle and OpenJDK</a> has links to many related resources and a section on JCP future.</li>\r\n\t<li><a href=\"http://debuggable.com/posts/test-driven-development-at-transloadit:4cc892a7-b9fc-4d65-bb0c-1b27cbdd56cb\">A fair evaluation of TDD</a> - Test driven development at Transloadit (\"honest assessment of the beauty and pain of tdd\" - <a href=\"http://twitter.com/KentBeck\">Kent Beck</a>) - according to the author, TDD requires a lot of discipline and is a pain to do but it really pays off if your risks are high, basically it's something like an insurance - there are people living without it but to some it can save life. I miss there a thing I find essential about good test coverage - namely that it forces you to write a better code (more modular, following the single responsibility principle etc.).</li>\r\n\t<li><a href=\"http://www.dzone.com/links/r/dear_javascript_guru_please_stop_using_the_hash_s.html\">Dear Javascript Guru: Please Stop Using The Hash Symbol For No-Op HREFs</a> - don't use href=\"#\" for it modifies the browsing history and makes the browser scroll to the top. Prefer &lt;a href=\"javascript:void(0);\" ... &gt; or just use the javascript: protocol for a function call that returns false (you can force it like this: &lt;a href=\"javascript:doSomething(); void(0);\"&gt;).</li>\r\n\t<li><a href=\"http://community.jboss.org/wiki/Gradlewhy\">Why Hibernate 4 switches to Gradle instead of Maven 3</a> - \"a means to describe the issues and frustrations I have seen in my 2.5+  years of using Maven for Hibernate builds; in many cases the cause is  simply an assumption or concept in Maven itself which did not line up  cleanly with how I wanted to do build stuff in Hibernate.\" The main issues were that Hibernate is a very specific project, which doesn't line up very well with the Maven philosophy and, at the same time, Maven is very strict at forcing it and not really flexible to accommodate to unusual needs (and if Maven is, its plugin often aren't). For example Hibernate is composed of modules that depend on each other while Maven really supports only an aggregation of independent projects. Also, \"the release plugin is completely worthless\". On the other hand, Gradle is very flexible and - among others - offers powerful scripting, doesn't enforce its way of doing things at all cost (i.e. directory structure), let you also define dependencies on tasks, modules, directories, etc.</li>\r\n\t<li><a href=\"http://code.google.com/p/flot/\">Flot - JavaScript plotting library for jQuery</a>, which <a href=\"http://en.blog.wordpress.com/2010/09/30/sexy-stats/\">has replaced Flash at WordPress.com</a> (so it must be really good!) for blog statistics visualization. Main points: simple usage (all settings are optional), attractive looks and interactive features like zooming and mouse tracking. Really nice one! <a href=\"http://people.iola.dk/olau/flot/examples/\">Check Flot examples</a>.</li>\r\n\t<li><a href=\"http://www.liferay.com/web/shuyang.zhou/blog/-/blogs/string-performance\">String Concatenation Performance vs. String Builder/Buffer</a> and how <a href=\"http://www.liferay.com/web/shuyang.zhou/blog/-/blogs/embed-stringbundler-into-app-server\">Liferay 6 achieved a speedup by not using S.B.</a> [that much] - StringBuilder/Buffer has lot of overhead and thus String.concat or custom code can be faster sometimes. Also see the linked ticket, esp. the comment 'most javac will try to translate \"+\" to StringBuilder whenever possible. So if you do need to use String.concate(), you'd better use it explicitly.'</li>\r\n\t<li><a href=\"http://www.paulgraham.com/avg.html\">Paul Graham - Beating the Averages</a> - why it's good to learn Lisp. (Because it makes you able to see the limitations of you current language as it's most likely superior to it - among others thanks to <a href=\"http://en.wikipedia.org/wiki/Common_Lisp#Macros\">Lisp macros</a>.) A really good essay on the power of programming languages, which has persuaded me about some year ago, when I've originally read it, to learn <a href=\"http://en.wikipedia.org/wiki/Clojure\">Clojure</a> (a modern Lisp dialect running on the JVM).</li>\r\n</ul>",
  "excerpt": ""
 },
 {
  "title": "Tip: Enable a shortcut for Occurrences in File in Eclipse under Gnome (default C+S+u)",
  "published": "2010-11-02 12:58:01",
  "postType": "post",
  "slug": "/2010/11/02/tip-enable-a-shortcut-for-occurrences-in-file-in-eclipse-under-gnome/",
  "status": "publish",
  "tags": [
   "gnome"
  ],
  "categories": [
   "eclipse",
   "Tools"
  ],
  "content": "The useful Eclipse action <strong>Search - Occurrences in File - Identifier</strong> has by default the shortcut Control+Shift+U. But under Gnome the shortcut <a href=\"https://help.ubuntu.com/community/ComposeKey#Unicode%20composition\">Control+Shift+U is used for Unicode character input</a>, indicated by an underlined <span style=\"text-decoration:underline;\">u</span> when pressed. Assigning a different shortcut is easy but there are few \"traps\":\r\n<ol>\r\n\t<li>In Eclipse, go to Window - Preferences - General - Keys</li>\r\n\t<li>Type  the filter <em>occurr</em> and click on \"<em>Shows the Occurrences in File Quick  Menu</em>\". Do not confuse it with \"Occurences in File\" (binding C+S+A, when  Editing in Structured T. Ed.)!\r\n<ol>\r\n\t<li>Make sure that When is \"<em>In Windows</em>\", Category is \"<em>Search</em>\"</li>\r\n\t<li>Click [Unbind Command], click into the Binding field and type the keys  that you want. Beware that some keys could conflict with existing bindings  or global Gnome/system bindings. For me e.g. Control+Shift+S or F8 worked (though I might have to unbind conflicting bindings, I don't remember anymore).</li>\r\n</ol>\r\n</li>\r\n</ol>\r\nEnvironment: Eclipse 3.5, Gnome 2.30.2, Ubuntu 10.04.",
  "excerpt": ""
 },
 {
  "title": "Knowing I''m Bad Programmer Makes Me Good Programmer",
  "published": "2010-11-17 16:33:21",
  "postType": "post",
  "slug": "/2010/11/17/knowing-im-bad-programmer-makes-me-good-programmer/",
  "status": "publish",
  "tags": [
   "development",
   "opinion"
  ],
  "categories": [
   "General"
  ],
  "content": "I know that I'm not a good programmer and this knowledge makes me actually a very good one. As Kent Beck says: \"I'm not an excellent programmer, I'm just a good one with excellent habits.\" [1] I know I'm a bad (read \"a little above average\", if you plan to hire me ;-)) programmer and therefore my code will contain bugs. So I like to write unit tests even before the code itself, and I prefer having the test fail first for thus I'm sure that it works (well, at least in a basic way). Being a bad programmer I also know that my design isn't perfect and no matter how hard I try it's very likely that it will need to be changed in the future. I therefore don't try to account for all possible future changes and to make it so flexible that it could deal with all of them because I know I'd be wrong in this. Instead, I prefer simple designs and well isolated parts of code so that it will be easy to reorganize and refactor them as needed. Last but not least, knowing my weaknesses I appreciate very much when somebody else reviews my design and code and I'm very receptive of different points of view and ideas. For the same reason I do not hesitate to ask my collegues for an opinion or an advice when I'm unsure. (Kent Beck yeasterday twittered: \"amazing how fast you can finish if you care more about feedback than avoiding criticism\".)<br><br>The net result is that I create a simple, well-tested code open to changes (i.e. easy to change in a safe manner), which is easy to read an understand (for I know that somebody will need to modify it many times, often the somebody being an older myself). And because I'm not afraid to ask, I've better and more suitable designs than I could create just by myself. Thus I produce a good, clean code as a good programmer would write.<br><br>[1] M. Fowler - Refactoring, page 73 in the Czech translation\r\n[2] R.C. Martin (ed.) - Clean Code: A Handbook of Agile Software Craftsmanship",
  "excerpt": ""
 },
 {
  "title": "If You Don''t Use Pair Programming and Code Reviews as Teaching Tools You Waste Money",
  "published": "2010-11-18 21:37:20",
  "postType": "post",
  "slug": "/2010/11/18/if-you-dont-do-pair-programming-and-code-reviews-as-teaching-tools-you-waste-money/",
  "status": "publish",
  "tags": [
   "opinion"
  ],
  "categories": [
   "General"
  ],
  "content": "There is an easy way how to save many man-days and thus also money on a  project by adding some work to the key team members. You must be  thinking that I'm crazy if I want to add even more work to the already  overloaded senior developers and an architect but I'm sure you will  agree at the end. The additional work, which will later save you many,  many more, are<strong> </strong>code reviews and pair programming of an inexperienced and a senior developer.<!--more-->\r\n<h2>Bad Code Can Kill You</h2>\r\nMy experiences from a few long-running small- and medium-size projects,  where I'm every day struggling with five or nine years old code written  by inexperienced developers, lead me to the clear conclusion that if  somebody had taught them how to write a clean, high-quality code, we  would have saved lot of time wasted later on trying to understand the  code and to modify it for new requirements without breaking there  something else. And, of course, a bad code has a strong tendency to rot  even more because, due to its incomprehensibility, people are afraid of  touching it and thus create complex constructions to minimize the extent  of necessary modifications and also because, due to its insufficient  flexibility and evolvability, new or changed requirements lead to a  rapid growth of its complexity.  The aforementioned problems are caused by the fact that such bad code  doesn't follow the best practices and ideals of object-oriented  programming, such as:\r\n<ul>\r\n\t<li>Small classes with a small number of short methods</li>\r\n\t<li>Classes having each only one clearly defined responsibility</li>\r\n\t<li>Each class has usually only few dependencies and is unaware of most of the other classes and objects</li>\r\n\t<li>Modularity resulting from this good distribution of responsibilities and good encapsulation of data inside the classes</li>\r\n\t<li>(Thanks to these characteristics it's also very easy to write unit tests.)</li>\r\n</ul>\r\nOn the other hand, you can usually see a handful of anti-patterns in a bad code, for example:\r\n<ul>\r\n\t<li>God Class is a very large class that does nearly  anything (there is actually also an opposite anti-pattern that I've  encountered, \"Functor\" or how to call it, i.e. each method has its own  class, usually named doIt or similarly)</li>\r\n\t<li>God Method - too long method doing too much - usually within a God Class</li>\r\n\t<li>Copy &amp; Paste Programming and the resulting repetition of code and C&amp;P errors</li>\r\n\t<li>Monolithic code, where everything depends on everything else (and unit testing is thus essentially impossible)</li>\r\n\t<li>Hard-coded data about the environment (path to a log file, DB driver class, ...)</li>\r\n\t<li>Reuse of variables - the same variable or object's  property (or DB column) is used for different purposes so that it's  difficult to understand its actual meaning (wouldn't you be surprised to  find out that SSN actually holds employee's organization code?)</li>\r\n\t<li>Procedural programing and overuse of static methods  where all (usually many) data is passed via parameters instead of an  efficient use of the object's properties</li>\r\n\t<li>...</li>\r\n</ul>\r\nAnd yes, if you have a weak hearth or a tendency to explode with anger, maintaining a bad code can really kill you ;-)\r\n<h2>Learning Clean Coding via Pair Programming and Code Reviews</h2>\r\nThis is by no means to say that inexperienced developers are stupid or  that they don't care for high quality code (I've actually regularly met  traces of their - though not always successful - attempts at quality).  They just had no practical opportunity to learn how to bring code  quality to life and praxis is here the only way how to really learn it.  And here we are getting to the point - I firmly believe that code  reviews and especially pair programming with a senior developer are by  far the most efficient and fast techniques for learning how to create  good-quality, clean code. Even just few days of pair programming can  open the eyes of the youngling and set him/her on the right track.<br><br>By observing the way of working and thinking of a developer who is  already a clean code practicioner or even master, and by working under  his/her supervision with an instantaneous feedback, I can learn in a  rather short time the most important habits (integration of unit tests,  starting with a simple design and refactoring as needed, ...), the clean  code mode of thinking and developing and the most frequent design and  implementation patterns as well as the ability to analyse and evaluate  the task at hand and to distinguish the important from the unimportant.  There is no more effective way of learning this than by personally  cooperating with an experienced person on a solution of a real problem  and then trying to apply the learned stuff with him/her providing a  feedback. You could read many books but they couldn't give you anything  near this experience. After an initial period we can loose the contact  and cooperation (unless we are lucky to work in an XP shop) and replace  the shared development with code reviews and discussions.\r\n<h2>Selling the Idea to the Management</h2>\r\nIt's understandeable that a manager would hesitate to use the scarce  time of his/her best people on such a low productivity effort as  teaching newcomers. But it's necessary to realize few basic facts,  namely that code is written just once but read many times and that the  life span of a typical software is usually a couple of years, let's say  5-10. Thus every time saving during its development at the expense of  its readibility and quality will be repaid by a multiple of that time  later on. One IBM statistics claims that the cost of maintenance (and  further development) is typically considerably higher than the cost of  the development of the initial version. You can save during the  development for the price of later (much) higher maintenance costs but  it's like living on a loan - by lending from a bank it seems that you  have more money now (more time till the deadline in our domain) but you  will highly repay it later. It's the task of a responsible and able  manager to explain to a customer that if she sacrifices quality for time  or budget, it will cost her much more later. (And any such saving is  actually doubtable for on any larger project the bad quality of its  codebase will affect you already during its development.)<br><br>The top management should thus encourage and support the process of  introduction of new developers based on pair programming and code  reviews to prevent later considerable losses. And what happens if you  teach them but they leave? Well, you should rather ask what if you do  not teach them but they stay! (As somebody has pointed out recently on  the internet.)\r\n<h2>Post Scriptum</h2>\r\nI'd like to make clear that I do not consider myself as a master of  clean code. I sometimes write terrible code and never a perfect one. But  I believe that during my ogoing quest for code quality I've learned a  few good things that I can help to spread further.\r\n<h2>Summary</h2>\r\nYoung developers usually don't learn how to create a high quality and  clean code at the university and thus in spite of all their efforts they  sometimes write code of poor quality, which then causes headakes to  many other people and makes maintenance and evolution of the software  more error-prone, expensive and slow. But young developers are smart and  given the right example and an opportunity to see and apply clean code  practices in the real life they can improve a lot in a short while. The  best way to give them this opportunity is to let them work in a pair  with an experienced developer and later, when they've already gaind the  right mind set, they can be kept on the right track and encouraged  towards further development via code reviews.<br><br>Of course both the pair programming (or mentoring) and code reviews must  be open, friendly activities where both parties are given equal rights  to express themselves and be listened to. The experienced ones shouldn't  forget that they too can be mistaken and that they can sometimes learn a  great deal from the young ones.<br><br><em>The main message of this post is that we should not neglect the  practical education of young developers because by investing little  initial time of our experienced stuff we can enable them to make huge  progress and by investing a little more of it continually we can enable  them to keep growing rapidly. This will result in a considerably higher  quality of their products and consequently will prevent a lot of wasted  time and money.</em>\r\n<h2>Resources</h2>\r\n<ul>\r\n\t<li>experience :-)</li>\r\n\t<li>R.C. Martin (ed.) - Clean Code: A Handbook of Agile Software Craftsmanship</li>\r\n\t<li>M. Fowler - Refactoring</li>\r\n\t<li><a href=\"http://stevesmithblog.com/blog/principles-patterns-and-practices-of-mediocre-programming/\">Principles, Patterns, and Practices of Mediocre Programming</a></li>\r\n\t<li><a href=\"http://www.developer.com/tech/article.php/3579756\">Effective Code Reviews Without the Pain</a></li>\r\n</ul>",
  "excerpt": ""
 },
 {
  "title": "SOAP/SAAJ/XML Issues When Migrating to Java 6 (with Axis 1.2)",
  "published": "2010-11-19 17:50:13",
  "postType": "post",
  "slug": "/2010/11/19/soapsaajxml-issues-when-migrating-to-java-6-with-axis-1-2/",
  "status": "publish",
  "tags": [
   "java",
   "java6",
   "migration",
   "soap",
   "xml"
  ],
  "categories": [
   "Languages"
  ],
  "content": "When you migrate an application using Apache Axis 1.2 from Java 4 or 5 to Java 6 (JRE 1.6) you will most likely encounter a handful of strange SOAP/SAAJ/XML errors and ClassCastExceptions. This is due to the fact that Sun's implementation of <a href=\"http://download.oracle.com/javase/6/docs/api/javax/xml/soap/package-summary.html#package_description\">SAAJ 1.3 has been integrated directly into the 1.6 JRE</a>. Due to this integration it's loaded by the bootstrap class loader and thus cannot see various classes that you might be referencing in your old code.<br><br>As mentioned on <a href=\"http://static.springsource.org/spring-ws/sites/1.5/faq.html#java-1.6\">Spring pages</a>:\r\n<blockquote>Java 1.6 ships with SAAJ 1.3, JAXB 2.0, and JAXP 1.4 (a custom version of Xerces and Xalan). Overriding these libraries by putting different version on the classpath will result in various classloading issues, or exceptions in org.apache.xml.serializer.ToXMLSAXHandler. The only option for using more recent versions is to put the newer version in the endorsed directory (see above).</blockquote>\r\nFortunately, there is a simple solution, at least for Axis 1.2.<!--more-->\r\n<h2>Some of the exceptions that we've encountered</h2>\r\n<h3>Sample Axis code</h3>\r\n<pre><code>\r\nimport javax.xml.messaging.URLEndpoint;<br><br>import javax.xml.soap.MessageFactory;\r\nimport javax.xml.soap.SOAPConnection;\r\nimport javax.xml.soap.SOAPConnectionFactory;\r\nimport javax.xml.soap.SOAPMessage;<br><br>...<br><br>public static callAxisWebservice() {\r\n\tSOAPConnectionFactory soapconnectionfactory = SOAPConnectionFactory.newInstance();\r\n\tSOAPConnection soapconnection = soapconnectionfactory.createConnection();\r\n\tMessageFactory messagefactory = MessageFactory.newInstance();\r\n\tSOAPMessage soapmessage = messagefactory.createMessage();\r\n\t...\r\n\tURLEndpoint urlendpoint = new URLEndpoint(string);\r\n\tSOAPMessage soapmessage_18_ = soapconnection.call(soapmessage, urlendpoint);\r\n\t...\r\n}\r\n</code></pre>\r\n<h3>SOAPExceptionImpl: Bad endPoint type</h3>\r\n<pre>﻿com.sun.xml.internal.messaging.saaj.SOAPExceptionImpl: Bad endPoint type http://example.com/ExampleAxisService\r\n at com.sun.xml.internal.messaging.saaj.client.p2p.HttpSOAPConnection.call(HttpSOAPConnection.java:161)</pre>\r\nThis extremely confusing error is caused by the following, seemingly innocent code above, namely by the '... new URLEndpoint(string)' and the call itself. The problem here is that Sun's <em>HttpSOAPConnection can't see the javax.xml.messaging.URLEndpoint because it is not part of the JRE</em> and is contained in another JAR, not visible to the classes loaded by the bootstrap loader.<br><br>If you check the <a href=\"http://grepcode.com/file/repository.grepcode.com/java/root/jdk/openjdk/6-b14/com/sun/xml/internal/messaging/saaj/client/p2p/HttpSOAPConnection.java#HttpSOAPConnection.call%28javax.xml.soap.SOAPMessage%2Cjava.lang.Object%29\">HttpSOAPConnection's code</a> (this is not exactly the version I have but close enough) you will see that it calls \"Class.forName(\"javax.xml.messaging.URLEndpoint\");\" on line 101. For the reason mentioned it fails with a ClassNotFoundException (as indicated by the log \"URLEndpoint is available only when JAXM is there\" when you <a href=\"http://www.javapractices.com/topic/TopicAction.do?Id=143\">enable the JDK logging</a> for the finest level)  and thus the method isn't able to recognize the type of the argument and fails with the confusing Bad endPoint message.<br><br>A soluti0n in this case would be to pass a java.net.URL or a String instead of a URLEndpoint (though it might lead to other errors, like the one below).<br><br>Related: <a href=\"http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=6619327\">Oracle saaj:soap1.2 bug SOAPExceptionImpl: Bad endPoint type</a>.\r\n<h3>DOMException: NAMESPACE_ERR</h3>\r\n<pre>org.w3c.dom.DOMException: NAMESPACE_ERR: An attempt is made to create or change an object in a way which is incorrect with regard to namespaces.\r\n at org.apache.xerces.dom.AttrNSImpl.setName(Unknown Source)\r\n at org.apache.xerces.dom.AttrNSImpl.&lt;init&gt;(Unknown Source)\r\n at org.apache.xerces.dom.CoreDocumentImpl.createAttributeNS(Unknown Source)</pre>\r\nWe got this when calling an Axis web service via a proxy object, I've no idea why it is thrown. The solution is as below, to set the SOAP implementation properties either upon start or at the runtime.\r\n<h3>Bonus: Conflict between Axis and IBM WebSphere JAX-RPC \"thin client\"</h3>\r\nAdditionally, if you happen to have com.ibm.ws.webservices.thinclient_7.0.0.jar somewhere on the classpath, you may get this funny exception:\r\n<pre>java.lang.ClassCastException: org.apache.axis.Message incompatible with com.ibm.ws.webservices.engine.Message\r\n at com.ibm.ws.webservices.engine.soap.SOAPConnectionImpl.call(SOAPConnectionImpl.java:198)</pre>\r\nYou may wonder why Java tries to use Axis Message with WebSphere SOAP connection. Well, it's because the SAAJ lookup mechanism prefers the websphere implementation, for it declares itself via META-INF/services/javax.xml.soap.SOAPFactory pointing to com.ibm.ws.webservices.engine.soap.SOAPConnectionFactoryImpl, but instantiates the org.apache.axis.soap.MessageFactoryImpl for message creation for the websphere thin client doesn't provide an implementation of this factory.<br><br>The solution here is the same as for all the other exception, to use exclusively Axis. But if you are interested, check the description how to correctly create a Message with the websphere runtime on page 119 of the <a href=\"http://www.redbooks.ibm.com/abstracts/sg247758.html?Open\">IBM WebSphere Application Server V7.0 Web Services Guide</a> (md = javax.xml.ws.Service.create(serviceName).createDispatch(portName, SOAPMessage.class, Service.Mode.MESSAGE);  ((SOAPBinding) ((BindingProvider) md).getBinding()).getMessageFactory();).\r\n<h2>Solution</h2>\r\nThe solution that my collegue Jan Nad has found is to<strong> force JRE to use the SOAP/SAAJ implementation provided by Axis</strong>, something like:<br><br><pre><code>java -Djavax.xml.soap.SOAPFactory=org.apache.axis.soap.SOAPFactoryImpl -Djavax.xml.soap.MessageFactory=org.apache.axis.soap.MessageFactoryImpl -Djavax.xml.soap.SOAPConnectionFactory=org.apache.axis.soap.SOAPConnectionFactoryImpl example.MainClass</code></pre><br><br>Alternatively, at the runtime:\r\n<pre><code>System.setProperty(&quot;javax.xml.soap.SOAPFactory&quot;, &quot;org.apache.axis.soap.SOAPFactoryImpl&quot;);\r\nSystem.setProperty(&quot;javax.xml.soap.MessageFactory&quot;,&quot;org.apache.axis.soap.MessageFactoryImpl&quot;);\r\nSystem.setProperty(&quot;javax.xml.soap.SOAPConnectionFactory&quot;,&quot;org.apache.axis.soap.SOAPConnectionFactoryImpl&quot;);\r\n</code></pre><br><br>It's also <a href=\"https://issues.apache.org/jira/browse/AXIS-2777\">described in issue AXIS-2777</a>.<br><br>Check <a href=\"http://download.oracle.com/javase/6/docs/api/javax/xml/soap/SOAPFactory.html#newInstance%28%29\">details of the lookup process in the SOAPFactory.newInstance() JavaDoc</a>.",
  "excerpt": ""
 },
 {
  "title": "svn fun: <path> has no ancestry information",
  "published": "2010-11-23 09:50:15",
  "postType": "post",
  "slug": "/2010/11/23/svn-fun-path-has-no-ancestry-information/",
  "status": "publish",
  "tags": [
   "scm",
   "subversion"
  ],
  "categories": [
   "Tools"
  ],
  "content": "Subversion is at times really annoying and difficult to use due to its cryptic and confusing error messages and unnecessary failures. An example is when you have an svn-managed folder ('svnProject') where svn -u status and svn info and even commiting individual files work correctly but commit of the complete folder (which is necessary e.g. if you've changes some SVN proprties such as svn:ignore) fails:<br><br><pre><code>\r\n.../rootFolder/svnProject$ svn commit .\r\nsvn: '/path/to/my/rootFolder' has no ancestry information\r\n</code></pre><br><br>There is an easy fix.\r\n<!--more-->Notice that the error is reported for the parent folder of the svn-managed one (from) which we've tried to commit. It actually seems that SVN checks the folder structure and <a href=\"http://victorhurdugaci.com/svn-no-ancestry-information/\">fails if some parts of the folder tree above the folder being commited have svn metadata and some do not</a> (<a href=\"http://svn.haxx.se/users/archive-2007-04/0039.shtml\">another example</a>):\r\n<ul>\r\n\t<li>/path/to/my - has .svn/ folder (a totaly unrelated one, a left-over from the old times)\r\n<ul>\r\n\t<li>rootFolder - no .svn here\r\n<ul>\r\n\t<li>svnProject - has a valid .svn/ metadata folder, this is the project/folder we're trying to commit</li>\r\n</ul>\r\n</li>\r\n</ul>\r\n</li>\r\n</ul>\r\n<strong>Verification</strong>: You can verify that by moving the folder that you are trying to commit to some other location (e.g. /tmp or even /) and retrying to commit it from there. If it succeeds then you've encountered this problem. If not then you have likely some other issue.<br><br><strong>Solution</strong>: Check the ancestor folders (especially above the one reported in the commit failure message) and if you find an .svn/ folder in any of them, as I suppose, remove it. Alternatively, move the folder of interest into another location where it has no ancestor folder with .svn/ within it.<br><br>Environment: SVN 1.4.6, on Ubuntu 10.04.",
  "excerpt": ""
 },
 {
  "title": "More Eclipse & svn fun: Can''t share a project (only Team - Apply Patch)",
  "published": "2010-11-23 10:57:05",
  "postType": "post",
  "slug": "/2010/11/23/more-eclipse-svn-fun-cant-share-a-project-only-team-apply-patch/",
  "status": "publish",
  "tags": [
   "subversion",
   "subversive"
  ],
  "categories": [
   "eclipse",
   "Tools"
  ],
  "content": "With Subversive it may happen that it completely ignores some projects while it perfectly works for other ones. If a project seems to have no SVN information in Eclipse (thoug it actually contains all the .svn/ folders) and the Team context manu only contains Apply Patch... (i.e. especially not Share project...) then you have likely mixed up Eclipse metadata about the project (for instance by sharing it previously with Subclipse).<br><br>This is a well known problem and <a href=\"http://www.eclipse.org/forums/index.php?t=msg&amp;goto=20669\">the solution is to Delete the project (without deleting its content) and to re-import it into Eclipse</a>. Also make sure that the Subversive back-end version supports the version of Subversion (too many *versions here :)) recorded in the project metadata. If needed, you can use a <a href=\"http://subversion.apache.org/faq.html#working-copy-format-change\">script to up/down-grade the SVN metadata</a>, as described in a FAQ.",
  "excerpt": ""
 },
 {
  "title": "Book review: Refactoring by Martin Fowler",
  "published": "2010-11-25 08:05:41",
  "postType": "post",
  "slug": "/2010/11/25/book-review-refactoring-by-martin-fowler/",
  "status": "publish",
  "tags": [
   "book",
   "java",
   "refactoring",
   "review"
  ],
  "categories": [
   "Languages"
  ],
  "content": "I had high expectations for Martin Fowler's <a href=\"http://www.amazon.com/gp/product/0201485672?ie=UTF8&amp;tag=martinfowlerc-20&amp;linkCode=as2&amp;camp=1789&amp;creative=9325&amp;creativeASIN=0201485672\">Refactoring</a> (1999/2002) but it turned out that both me and the book are too old. It had some interesting parts, but the main one - the refactoring catalog itself - had little new for me because I already know most of the refactorings and the description of steps how to perform them safely is nowadays essentially useless as they're already automatically and safely performed by our IDEs.<br><br>I've enjoyed chapter 1 with a nice example of how bad code is turned into a nice one via a series of refactorings and I'd recommend it to any beginning developer. For others than me also chapter 2 may be useful, it explains why and when to refactor, how it impacts your development speed and how to justify it to the manager. I'd skip chapter 3 - bad smells in the code - and read instead of it the Uncle Bob's lovely <a href=\"http://www.amazon.com/Clean-Code-Handbook-Software-Craftsmanship/dp/0132350882/ref=sr_1_1?s=books&amp;ie=UTF8&amp;qid=1290639929&amp;sr=1-1\">Clean Code</a> , which is a great justification and basis for refactoring anyway.<br><br>In the catalog I've appreciated the description of some refactorings for various reasons, such as 6.4 Replace Temp with Query, 8.14 Replace Type Code with Subclasses, 9.7 Introduce Null Object, 9.8 Introduce Assertion. Of course also the other ones are good but they are just too familiar to me and my IDE to draw my attention anymore.<br><br>Chapter 12, Big Refactorings, is quite interesting, especially Tease Apart Inheritance.<br><br>Finally there are some good advices in Putting It All Together by Kent Beck, such as that it's good to know when to stop and to be able to resist the temptation to refactor too much at once.<br><br>I've also appreciated the \"war stories\", especially regarding performance tuning, where once again it's demonstrated that a guess (however founded) is incomparable to hard evidence.\r\n<h2>Conclusion</h2>\r\nIf you do refactorings daily, perhaps skip the book. If not, read chapter 1, perhaps browse through 2 and 12, check whether anything catches your eye in the <a href=\"http://www.amazon.com/gp/reader/0201485672/ref=sib_dp_ptu#reader-link\">refactoring catalog table of content</a>, read Kent's closing chapter and return the book to the local museum.",
  "excerpt": ""
 },
 {
  "title": "Most interesting links of November",
  "published": "2010-11-30 21:15:32",
  "postType": "post",
  "slug": "/2010/11/30/most-interesting-links-of-november/",
  "status": "publish",
  "tags": [
   "java",
   "javaEE",
   "jvm",
   "Maven",
   "performance",
   "spring",
   "tdd",
   "xml"
  ],
  "categories": [
   "j2ee",
   "Languages",
   "Top links of month"
  ],
  "content": "This month has been quite interesting, among others I 've picked up several blogs by Adam Bien. I really like his brief, practical and insightful posts :-)<br><br>Java, Jave EE, architecture etc.\r\n<ul>\r\n\t<li><a href=\"http://www.adam-bien.com/roller/abien/entry/ejb_3_1_hessian_almost\">EJB 3.1 + Hessian = (Almost) Perfect Binary Remoting</a> - \"With hessian it is very easy to expose existing Java-interfaces with almost no overhead. Hessian is also extremely (better than IIOP and far better than SOAP) fast and scalable.\" See also the discussion regarding a \"DynamicHessianServlet\" (which would be more comfortable then creating a new servlet for each service).</li>\r\n\t<li><a href=\"https://fi.dev.java.net/performance.html\">Binary XML - Fast Infoset performance results</a> - FI is the name of a standard for binary XML encoding and also of its OSS implementation; according to these measurements (with default settings, compared to Xerces 2.7.1), on average: The FI SAX parser  is about <strong>5 times faster</strong> than the Xerces SAX parser, the FI DOM serializer (using default settings) is 25% to 30% faster than the Xerces DOM XMLSerializer, and FI documents are 40% to 60% smaller than XML documents (i.e. it can provide modest to good compression). And: \"The use of external vocabularies can be a very effective way to increase the efficiency of parsing, serializing and size at the expense of the fast infoset documents no longer being self-describing ... .\"\r\nFor the interested ones: FI is built on <a href=\"http://en.wikipedia.org/wiki/ASN.1\">ASN.1</a>, a standard for describing data structures in a way that is independent of machine architecture and implementation language, it also includes a selection on different binary encoding rules, e.g. DER (triplets tag id - length - value).</li>\r\n\t<li><a href=\"http://www.adam-bien.com/roller/abien/entry/ejb_3_1_and_rest\">EJB 3.1 And REST - The Lightweight Hybrid - Why to use @Stateless</a> - there have been recently discussion about Spring vs. EJB and whether @Stateless is of any use. According to this article, the added value of EJB (though some are provided also by Spring) include injection capabilities, transactions, single threading model (for why that is good see #2 on <a href=\"http://www.adam-bien.com/roller/abien/entry/why_i_like_ejb_3\">Why I like EJB 3.0/3.1</a>), visibility in JMX, concurrency restriction via thread/bean pools.</li>\r\n\t<li><a href=\"http://www.adam-bien.com/roller/abien/entry/why_service_isn_t_a\">Why Service Isn't A ServiceFacade, But ServiceFacade Is Sometimes A Service...</a></li>\r\n\t<li><a href=\"http://blog.springsource.com/2010/11/10/hyperic-4-5-released/\">Experiences from migrating Hyperic 4.5 from EJB/JBoss to Spring/Tomcat</a>,  what good has it brought - simplified unit and integration tests,  simplified code thanks to Jdbc/JmsTemplate, ... (My comment: EJB 3.1 would  certainly bring at least some of the advantages too.)</li>\r\n</ul>\r\nPerformance - large JVM heaps are very much feasible\r\n<ul>\r\n\t<li><a href=\"http://www.nearinfinity.com/blogs/aaron_mccurry/tuning_the_ibm_jvm_for_large_h.html\">Tuning the IBM JVM for large heaps</a> - tuning 64b IBM JVM 6 with <strong>100GB heap</strong> to have acceptable GC times (~ 1/2s as opposed to 25s with the default settings)</li>\r\n\t<li><a href=\"http://www.enigmastation.com/?p=532\">BigMemory: Heap Envy</a> - there have been recently a lot of fuss about Terracotta's new  BigMemory, a  GC-resistent many GB cache space (using NIO byte buffer).  This post discusses it's disadvantages and compares it with a solution  based on ConcurrentHashMap, comming to the conclusion that the old good  ConcurrentHashMap outperforms BigMemory considerably.</li>\r\n</ul>\r\nOther\r\n<ul>\r\n\t<li><a href=\"http://gojko.net/2009/02/27/thought-provoking-tdd-exercise-at-the-software-craftsmanship-conference/\">Mind-breaking TDD exercise - Thought-provoking TDD exercise at the Software Craftsmanship conference</a> - a TDD exercise with strict rules requiring to only write implementation in the test itself and then refactor it out as needed. I'd strongly suggest that you try to do it by yourself. There is a <a href=\"http://gojko.net/2009/08/02/tdd-as-if-you-meant-it-revisited/\">more detailed report from a tic-tac-toe version</a> and a bit about <a href=\"http://www.markhneedham.com/blog/2009/04/30/coding-dojo-13-tdd-as-if-you-meant-it/\">implementing a message interceptor in this way</a>. An interesting observation: \"<em>differences from a pre-conceived design and the one that emerges from code are considerable, the latter being a lot more elegant and better suited to describe a problem.</em>\"</li>\r\n\t<li><a href=\"http://www.whattofix.com/blog/archives/2010/11/to-code-quickly.php\">To code quickly, you must quit coding (Pomodoro etc.)</a> - why Pomodoro technique (concentrate 25m on work rejecting interruptions, then take a break) and similar ones work</li>\r\n\t<li><a href=\"http://ju-n.net/colorize-maven-output\">Colorize Maven output in Linux/bash via filtering</a> of Maven’s mvn command output using sed. (Thanks to Alda for the link.)</li>\r\n</ul>",
  "excerpt": ""
 },
 {
  "title": "Joshua Bloch: Performance Anxiety - on Performance Unpredictability, Its Measurement and Benchmarking",
  "published": "2010-12-10 17:14:01",
  "postType": "post",
  "slug": "/2010/12/10/joshua-bloch-performance-anxiety-on-unpredictability/",
  "status": "publish",
  "tags": [
   "benchmarking",
   "java",
   "performance",
   "profiling"
  ],
  "categories": [
   "Languages"
  ],
  "content": "Joshua Bloch had a great <a href=\"http://www.dzone.com/links/r/performance_anxiety_with_googles_josh_bloch.html\">talk called Performance Anxiety</a> (30min, via Parleys; <a title=\"PerformanceAnxiety2010.pdf\" href=\"http://wiki.jvmlangsummit.com/images/1/1d/PerformanceAnxiety2010.pdf\">slides</a> also available ) at Devoxx 2010, the main message as I read it was\r\n<ol>\r\n\t<li>Nowadays, performance is completely non-predictable. You have to measure it and employ proper statistics to get some meaningful results.</li>\r\n\t<li>Microbenchmarking is very, very hard to do correctly. No, you misunderstand me, I mean even harder than that! :-)</li>\r\n\t<li>From the resources: Profiles and result evaluation methods may be very misleading unless used correctly.</li>\r\n</ol>\r\n<!--more-->There have been <a href=\"http://www.frogcake.net/blog/2010/11/17/devoxx-performance-anxiety\">another blog about it</a> but I'd like to record here more detailed remarks.<br><br>Today we can't estimate performance, we must measure it because the systems (JVM, OS, processor, ...) are very complex with many different heuristics on various levels and thus the <strong>performance is highly unpredictable</strong>. This doesn't apply only to Java, but also to C, C++, even to assembly code.<br><br><strong>Example</strong>: Results during a single JVM run may be consistent (warm-up, then faster) but can vary between JVM executions even by 20%. One of the causes may be Compilation Planning (what's inlined, ...) - it's done in a background thread and thus is inherently non-deterministic.<br><br>Therefore <strong>don't estimate but measure</strong> and not only that - also do <strong>statistical processing</strong> of the data (how often diff. values appear, what they are, ... - mean, median, standard deviation etc.).<br><br>\"<strong>Profiles don't help much</strong>; in fact, they can mislead\" - Mytkowicz, Diwan etc. - <a rel=\"nofollow\" href=\"http://www-plan.cs.colorado.edu/klipto/mytkowicz-pldi10.pdf\">\"Evaluating the Accuracy of Java Proﬁlers\"</a>, PLDI '10 - in their experiment, each of 4 leading profiles identified a different hotspot. I'd really recommend you reading the related <a href=\"http://stackoverflow.com/questions/4387895/if-profiler-is-not-the-answer-what-other-choices-do-we-have\">StackOverflow discussion \"If profiler is not the answer, what other choices do we have?\"</a> (the answer is: profilers have their value, but use the correct ones and use them correctly). The conclusion of the original paper:\r\n<blockquote>Our results are disturbing because they indicate that proﬁler  incorrectness is pervasive—occurring in most of our seven benchmarks and  in two production JVM—-and signiﬁcant—all four of   the state-of-the-art proﬁlers produce incorrect proﬁles. Incorrect   proﬁles can easily cause a performance analyst to spend time  optimizing cold methods that will have minimal effect on performance.   We show that a proof-of-concept proﬁler that does not use yield   points for sampling does not suffer from the above problems.</blockquote>\r\n\"Benchmarking is really, really hard!\" and \"<strong>Most benchmarks are seriously broken</strong>\". Broken means that either the measurement's error is higher than the value being measured or that the results obtained are unrelated to intended measurements. It seems that it is actually really hard to find a (micro)-benchmark, which isn't broken. Joshua recommends Cliff Click's JavaOne 2009 presentation <a href=\"http://developers.sun.com/learning/javaoneonline/sessions/2009/pdf/TS-5391.pdf\">The Art of (Java) Benchmarking</a> (see also an interesting <a href=\"http://java.sun.com/javaone/2009/articles/rockstar_click.jsp\">related interview</a> with Cliff), which I belive to have seen and which points out the various traps here. Joshu also mentiones that some frameworks, such as <a href=\"http://code.google.com/p/caliper/\">Google Caliper</a> may help you to avoid the pitfalls, though I'm quite sure they can't protect you from all.<br><br>Joshua mentiones a couple of <strong>interesting papers</strong>, you should check the <a title=\"PerformanceAnxiety2010.pdf\" href=\"http://wiki.jvmlangsummit.com/images/1/1d/PerformanceAnxiety2010.pdf\">slides</a> for them. One which sounds really interesting to me is by Georges, Buytaert and Eeckhout - <a href=\"http://itkovian.net/base/files/papers/oopsla2007-georges-preprint.pdf\">Statistically Rigorous Java Performance Evaluation</a>, OOPSLA07 (20 pages). They mention there that you need to run VM 30 times to get meaningful data. From the <a href=\"http://www.itkovian.net/base/statistically-rigorous-java-performance-evaluation/\">abstract</a>:\r\n<blockquote>This paper shows that prevalent methodologies can be misleading, and can  even lead to incorrect conclusions. The reason is that the data  analysis is not statistically rigorous. In this paper, we present a  survey of existing Java performance evaluation methodologies and discuss  the importance of statistically rigorous data analysis for dealing with  non-determinism. We advocate approaches to quantify startup as well as  steady-state performance, and, in addition, we provide the JavaStats  software to automatically obtain performance numbers in a rigorous  manner. Although this paper focuses on Java performance evaluation, many  of the issues addressed in this paper also apply to other programming  languages and systems that build on a managed runtime system.</blockquote>\r\n<h2>Personal touch</h2>\r\nI find this subject very interesting because for over a year I'm involved in performance optimization of one of our data feeds, which used to run for couple of days (latest results: 1/2h [with a bit of cheating]). My experience completely supports what Joshua says - don't guess but measure, profilers may be misleading, performance is unpredictable. Though as a collegue mentioned, in the domain of enterprise Java, our performance problems are usually caused by the database and communication with it (which 100% applies to that feed too).<br><br>I've already blogged about some experiences, e.g. in <a href=\"/2010/09/20/the-power-of-batching-or-speeding-jdbc-by-100/\">The power of batching or speeding JDBC by 100</a> (inspired by <a href=\"http://www.dzone.com/links/r/jdbc_performance_tuning_with_fetch_size.html\">JDBC performance tuning with fetch size</a>), check also the <a href=\"/tag/performance/\">performance tag</a> for interesting links. I also appreciated and applied the knowledge from <a href=\"http://www.johndcook.com/standard_deviation.html\">Accurately computing running variance</a> (I often wish I have slept less and paid attention more during the uni math lectures :-)).\r\n<h2>Conclusion</h2>\r\nThe higher complexity, the higher unpredictability =&gt;\r\n<ul>\r\n\t<li>As an application programmer, use high-level, declarative constructs where posible to push the responsability for performance one level down to library and JVM authors, who should know better.</li>\r\n\t<li>Measure repeatedly and process the results with proper statistics. Don't forget to repeat them over time, the platform evolves with every release.</li>\r\n</ul>\r\nOnce again, microbenchmarking is hard! :-) If you have to play with it, use something like Caliper and be aware that your results are most likely wrong anyway.<br><br>Closing words: Merry Christmas!",
  "excerpt": ""
 },
 {
  "title": "Most interesting links of December",
  "published": "2010-12-31 21:59:29",
  "postType": "post",
  "slug": "/2010/12/31/most-interesting-links-of-december/",
  "status": "publish",
  "tags": [
   "best practices",
   "java"
  ],
  "categories": [
   "Languages",
   "Top links of month"
  ],
  "content": "In the last month of 2010 I've stumbled upon surprisingly few intersting articles, partly due to having a lot to do in my job.\r\n<ul>\r\n\t<li><a href=\"http://mooneyblog.mmdbsolutions.com/index.php/2010/07/30/reusable-code-is-bad/\">Reusable Code Is Bad</a> (for advanced developers only!) - we know duplication is bad but \"premature enabling for reuse\" is equally bad - or ewen worse - because it introduces more complexity and you most likely aren't going to need it anyway. Apply your experience and knowledge to detect when you will <em>actually benefit</em> from reuse and <em>reduce overall maintenance and complexity</em>. Read the comments too, there're some interesting ones.</li>\r\n</ul>",
  "excerpt": ""
 },
 {
  "title": "Apache Ivy: First Impressions",
  "published": "0000-00-00 00:00:00",
  "postType": "post",
  "slug": "/652",
  "status": "draft",
  "tags": [
   "build",
   "java"
  ],
  "categories": [
   "Languages",
   "Tools"
  ],
  "content": "<h1>Unsorted</h1>\n<strong>Nexus x Artifactory</strong>: Artifactory supports Ivy nativaly but many people seem to be content with using Ivy with Nexus using Ivy's Maven compatibility mode - see the article <a href=\"http://java.dzone.com/articles/maven-repository-manager-nexus\">Maven Repository Manager: Nexus Vs. Artifactory</a> and its comments<br><br><strong>Impressions</strong>: Ivy is nice and very flexible though it takes some time to learn. But I still love Maven for its convention over configuration and common tasks being available and working out of the box (such as 'mvn package' to create a JAR).\n<h2>Nexus repository</h2>\nDiscussion: <a href=\"http://mail-archives.apache.org/mod_mbox/ant-ivy-user/201008.mbox/%3C258752.21399.qm@web30807.mail.mud.yahoo.com%3E\">Publishing from IVY to Maven/Sonatype Nexus</a> -&gt; Ivy's own <a href=\"http://svn.apache.org/viewvc/ant/ivy/core/trunk/ivysettings-release.xml?view=markup\">ivysettings for publishing to Nexus</a> (notice that a URL resleover and not ibiblio is used for publishing) and its <a href=\"http://svn.apache.org/viewvc/ant/ivy/core/trunk/build-release.xml?view=markup\">build xml for the publishing</a> (see the target upload-nexus).<br><br>Publishing\n<ul>\n\t<li>authentication</li>\n\t<li>POM generation</li>\n</ul>",
  "excerpt": ""
 },
 {
  "title": "Ivy resolve downloads but ignores some artifacts (though not modules)",
  "published": "2010-12-23 13:21:54",
  "postType": "post",
  "slug": "/2010/12/23/ivy-resolve-downloads-but-ignores-some-artifacts-though-not-modules/",
  "status": "publish",
  "tags": [
   "classpath",
   "issue",
   "ivy"
  ],
  "categories": [
   "Tools"
  ],
  "content": "I've had a strange issue with <a href=\"http://ant.apache.org/ivy/\">Apache Ivy</a>'s <a href=\"http://ant.apache.org/ivy/history/latest-milestone/use/resolve.html\">resolve task</a> - it resolved and downloaded all my dependencies but didn't put some of them to the classpath (via ivy:cachepath) and certainly wouldn't copy them either (via ivy:retrieve). An indicia was that in the resolve report the number of \"artifacts\" was zero while the number of \"modules\" matched the number of the dependencies. The issue was caused by my defaultconfmapping=\"*-&gt;compile\" - it turned out that most modules, as interpreted by Ivy, produce their artifacts only for the configuration \"master\" and not for compile.<br><br><!--more--><br><br>In my case, with <em>ivy.xml</em> (definition of the configurations compile, provided, and test not shown) containing<br><br><pre><code>\r\n...\r\n&lt;dependencies defaultconf=&quot;compile&quot;&gt;\r\n   &lt;dependency conf=&quot;provided&quot; org=&quot;log4j&quot; name=&quot;log4j&quot; rev=&quot;1.2.14&quot; /&gt;\r\n   &lt;dependency conf=&quot;test&quot; org=&quot;net.jakubholy.testing&quot; name=&quot;dbunit-embeddedderby-parenttest&quot; rev=&quot;1.1.0&quot; /&gt;\r\n    &lt;dependency conf=&quot;test&quot; org=&quot;org.mockito&quot; name=&quot;mockito-all&quot; rev=&quot;1.8.5&quot; /&gt;\r\n &lt;/dependencies&gt;\r\n...\r\n</code></pre><br><br>the test-scoped dependencies <em>net.jakubholy.testing:dbunit-embeddedderby-parenttest:1.1.0</em> and <em>org.mockito:mockito-all:1.8.5</em> were included in the classpath together with their dependencies as expected while <em>log4j:log4j:1.2.14</em> was ignored no matter what I did (even changing its conf to test).<br><br>The problem was indicated by &lt;ivy:resolve /&gt; producing an output like:<br><br><pre><code>\r\n[ivy:resolve] :: resolution report :: resolve 951ms :: artifacts dl 20ms\r\n\t---------------------------------------------------------------------\r\n\t|                  |            modules            ||   artifacts   |\r\n\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\r\n\t---------------------------------------------------------------------\r\n\t|      compile     |   0   |   0   |   0   |   0   ||   0   |   0   |\r\n\t|       test       |   13  |   0   |   0   |   1   ||   10  |   0   |\r\n\t|     provided     |   1   |   0   |   0   |   0   ||   0   |   0   |\r\n\t|      runtime     |   0   |   0   |   0   |   0   ||   0   |   0   |\r\n\t---------------------------------------------------------------------\r\n</code></pre><br><br>- notice that the number of provided modules is 1 but provided artifacts is 0\r\n<h2>Troubleshooting</h2>\r\nChecking the <strong>resolve report</strong> in <em>&lt;user home&gt;/.ivy2/cache/resolved-&lt;org&gt;-&lt;artifact&gt;-&lt;revision&gt;.xml </em>revealed the full definition of configurations (included from another file), dependencies and especially dependencies/defaultconfmapping, which was rather useful later. The defaultconfmapping<br><br><pre><code>...\r\n&lt;dependencies defaultconf=&quot;compile&quot; defaultconfmapping=&quot;*-&gt;compile&quot;&gt;\r\n...</code></pre><br><br>seemed to be OK but was not, as further exploration revealed.<br><br>Next I've checked the <strong>Ivy descriptor for the log4j</strong> \"module\" generated by Ivy from its pom.xml in .ivy2/cache/log4j/log4j/ivy-1.2.14.xml and its publications tag caught my eye:<br><br><pre><code>...\r\n&lt;publications&gt;\r\n   &lt;artifact name=&quot;log4j&quot; type=&quot;jar&quot; ext=&quot;jar&quot; conf=&quot;master&quot;/&gt;\r\n   &lt;artifact name=&quot;log4j&quot; type=&quot;source&quot; ext=&quot;jar&quot; conf=&quot;sources&quot; m:classifier=&quot;sources&quot;/&gt;\r\n&lt;/publications&gt;\r\n...</code></pre><br><br>- notice that <em><strong>the JAR artifact (i.e. log4j.jar) is produced only for the configuration 'master'</strong></em>! But due to the innocently looking default mapping of \"*-&gt;compile\" we are taking into account only artifacts produced in the configuration \"compile\", which is zero. Mystery solved!\r\n<h2>Fix</h2>\r\nThe fix (not necessarily the best one) is to include all configurations of interest in the default mapping (either on <em>dependencies</em> or on <em>configurations</em> in ivy.xml):<br><br><pre><code>&lt;dependencies defaultconf=&quot;compile&quot; defaultconfmapping=&quot;*-&gt;compile,master,default&quot;&gt;</code></pre>",
  "excerpt": ""
 },
 {
  "title": "Tip: Multiple webservice implementation classes available at the same time under WAS7",
  "published": "2010-12-29 19:42:36",
  "postType": "post",
  "slug": "/2010/12/29/tip-multiple-webservice-implementation-classes-available-at-the-same-time-under-was7/",
  "status": "publish",
  "tags": [
   "java",
   "jaxws",
   "webservice"
  ],
  "categories": [
   "j2ee",
   "Languages",
   "WebSphere"
  ],
  "content": "If you want to experiment with webservices by providing several alternative implementations of the same webservice (represented by the &lt;wsdl:service&gt; element), each having its own URL, and you're using Websphere 7 and JAX-WS, then:\r\n<ol>\r\n\t<li>For each alternative implementation, add &lt;wsdl:port&gt; with a unique name under the &lt;wsdl:service&gt; element in the WSDL file. Beware: This is essential to enable multiple implementations.</li>\r\n\t<li>For each alternative implementation, define a servlet and servlet mapping in web.xml like this:\r\n<pre><code>&lt;servlet id=&quot;$IMPLEMENTATION_CLASS_NAME$&quot;&gt;\r\n\t\t&lt;servlet-name&gt;$IMPLEMENTATION_CLASS_NAME$&lt;/servlet-name&gt;\r\n\t\t&lt;servlet-class&gt;$IMPLEMENTATION_CLASS_NAME$&lt;/servlet-class&gt;\r\n\t\t&lt;load-on-startup&gt;1&lt;/load-on-startup&gt;\r\n\t&lt;/servlet&gt;\r\n\t&lt;servlet-mapping&gt;\r\n\t\t&lt;servlet-name&gt;$IMPLEMENTATION_CLASS_NAME$&lt;/servlet-name&gt;\r\n\t\t&lt;url-pattern&gt;/$DESIRED_UNIQUE_URL$&lt;/url-pattern&gt;\r\n\t&lt;/servlet-mapping&gt;</code></pre></li>\r\n\t<li>Create the implementations - likely as POJOs denoted with the @WebService annotation - and set the corresponding portName for each of them (<em>@WebService(</em>portName=\"&lt;unique port name&gt;\", ...<em>)</em>)</li>\r\n\t<li>Deploy and use<!--more--></li>\r\n</ol>\r\n<h2>1. Define a unique wsdl:port for each implementation</h2>\r\nAs mentioned, it's necessary to define a unique wsdl:port for each implementation.<br><br>We define two ports, <em>LearningActivityPort1</em> and <em>LearningActivityPort2</em>, using the same port type (i.e. the same transport protocol etc.).<br><br><strong>LearningActivity.wsdl</strong>:<br><br><pre><code>\r\n&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;\r\n&lt;wsdl:definitions ...&gt;\r\n\t&lt;wsdl:types&gt;...&lt;/wsdl:types&gt;\r\n\t&lt;wsdl:message ...&gt;...&lt;/wsdl:message&gt;\r\n\t&lt;wsdl:portType name=&quot;DefaultPortType&quot;&gt;...&lt;/wsdl:portType&gt;\r\n\t&lt;wsdl:binding name=&quot;LearningActivityHttpBinding&quot; type=...&gt;...&lt;/wsdl:binding&gt;\r\n\t&lt;wsdl:service name=&quot;LearningActivityHttpService&quot;&gt;\r\n\t\t&lt;wsdl:port binding=&quot;tns:LearningActivityHttpBinding&quot; name=&quot;LearningActivityPort1&quot;&gt;\r\n\t\t\t&lt;soap:address location=&quot;http://example.com/myApp/LearningActivityHttpService&quot; /&gt;\r\n\t\t&lt;/wsdl:port&gt;\r\n\t\t&lt;wsdl:port binding=&quot;tns:LearningActivityHttpBinding&quot; name=&quot;LearningActivityPort2&quot;&gt;\r\n\t\t\t&lt;soap:address location=&quot;http://example.com/myApp/LearningActivityRawXmlService&quot; /&gt;\r\n\t\t&lt;/wsdl:port&gt;\r\n\t&lt;/wsdl:service&gt;\r\n&lt;/wsdl:definitions&gt;\r\n</code></pre>\r\n<h2>2. Define a servlet and servlet mapping for each implementation</h2>\r\nNext we need to declare each of the webservice implementation classes as a servlet and define a servlet mapping to assign a unique URL to that implementation <a href=\"http://publib.boulder.ibm.com/infocenter/wasinfo/v7r0/index.jsp?topic=/com.ibm.websphere.express.doc/info/exp/ae/twbs_customwebxml.html\">as described in WAS help</a>:\r\n<strong>web.xml</strong>:<br><br><pre><code>\r\n&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;\r\n&lt;web-app id=&quot;WebApp_ID&quot; version=&quot;2.5&quot;\r\n\txmlns=&quot;http://java.sun.com/xml/ns/javaee&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;\r\n\txsi:schemaLocation=&quot;http://java.sun.com/xml/ns/javaee http://java.sun.com/xml/ns/javaee/web-app_2_5.xsd&quot;&gt;\r\n\t&lt;display-name&gt;pokusWeb4was7&lt;/display-name&gt;<br><br>\t&lt;servlet id=&quot;LearningActivityHttpBindingImpl&quot;&gt;\r\n\t\t&lt;servlet-name&gt;LearningActivityHttpBindingImpl&lt;/servlet-name&gt;\r\n\t\t&lt;servlet-class&gt;example.LearningActivityHttpBindingImpl&lt;/servlet-class&gt;\r\n\t\t&lt;load-on-startup&gt;1&lt;/load-on-startup&gt;\r\n\t&lt;/servlet&gt;\r\n\t&lt;servlet-mapping&gt;\r\n\t\t&lt;servlet-name&gt;LearningActivityHttpBindingImpl&lt;/servlet-name&gt;\r\n\t\t&lt;url-pattern&gt;/LearningActivityJaxbService&lt;/url-pattern&gt;\r\n\t&lt;/servlet-mapping&gt;<br><br>\t&lt;servlet id=&quot;LearningActivityRawXmlServiceImpl&quot;&gt;\r\n\t\t&lt;servlet-name&gt;LearningActivityRawXmlServiceImpl&lt;/servlet-name&gt;\r\n\t\t&lt;servlet-class&gt;example.LearningActivityRawXmlServiceImpl&lt;/servlet-class&gt;\r\n\t\t&lt;load-on-startup&gt;1&lt;/load-on-startup&gt;\r\n\t&lt;/servlet&gt;\r\n\t&lt;servlet-mapping&gt;\r\n\t\t&lt;servlet-name&gt;LearningActivityRawXmlServiceImpl&lt;/servlet-name&gt;\r\n\t\t&lt;url-pattern&gt;/LearningActivityRawXmlService&lt;/url-pattern&gt;\r\n\t&lt;/servlet-mapping&gt;<br><br>\t&lt;welcome-file-list&gt;...&lt;/welcome-file-list&gt;\r\n&lt;/web-app&gt;\r\n</code></pre><br><br>When deployed, the two implementation will be thus available under http://localhost:9080/pokusWeb4was7/LearningActivityHttpService and http://localhost:9080/pokusWeb4was7/LearningActivityRawXmlService.\r\n<h2>3. Create each implementation linking it to its port name</h2>\r\nFinally we write the two implementation, each being assigned to a different port name:\r\n<strong>example.LearningActivityHttpBindingImpl</strong>:<br><br><pre><code>\r\n@javax.jws.WebService (serviceName=&quot;LearningActivityHttpService&quot;, portName=&quot;LearningActivityPort1&quot;)\r\npublic class LearningActivityHttpBindingImpl{<br><br>    public TransactionResponseMessage updateLearningActivity(LearningActivityMessage learningActivityMsg) {\r\n        //...\r\n\treturn response;\r\n    }\r\n}\r\n</code></pre><br><br><strong>example.LearningActivityRawXmlServiceImpl</strong>:<br><br><pre><code>\r\n@javax.jws.WebService (serviceName=&quot;LearningActivityHttpService&quot;, portName=&quot;LearningActivityPort2&quot;)\r\npublic class LearningActivityRawXmlServiceImpl{<br><br>    public TransactionResponseMessage updateLearningActivity(LearningActivityMessage learningActivityMsg) {\r\n        //...\r\n\treturn response;\r\n    }\r\n}\r\n</code></pre>\r\n<h2>Closing notes</h2>\r\nNotice that with JAX-WS\r\n<ul>\r\n\t<li>You don't need webservice.xml - all the necessary information is (may be) provided via annotations</li>\r\n\t<li>You don't need to declare the web services in web.xml unless you need some special configuration (as we do here)</li>\r\n</ul>",
  "excerpt": ""
 },
 {
  "title": "Howto: JAX-WS service with XML Source input instead of JAXB-produced POJOs (similar to JAX-RPC with SOAPElement input)",
  "published": "2010-12-29 20:21:39",
  "postType": "post",
  "slug": "/2010/12/29/implementing-jax-ws-webservice-accessing-its-input-as-xml-source-similar-to-jax-rpc-with-soapelement-input/",
  "status": "publish",
  "tags": [
   "java",
   "jaxws",
   "webservice",
   "xml"
  ],
  "categories": [
   "j2ee",
   "Languages"
  ],
  "content": "Sometimes you may want to create a JAX-WS webservice with its input defined by a proper, structured XSD yet accessing the input as raw XML object and not as POJOs produced by JAXB, similarly as with a JAX-RPC webservice having input of the type SOAPElement. This is possible using @WebServiceProvider with javax.xml.ws.Service.Mode.PAYLOAD.<br><br><!--more--><br><br><strong>JAXB input</strong> Normally you create a JAX-WS webservice by annotating a POJO with @WebService and related annotations and use JAXB annotations on your domain classes used in input and output of the web service (or you use wsimport and the JAXB compiler to produce these from a WSDL file).<br><br><strong>XML input</strong> But there is also an alternative way for accessing the input as XML data (not just a string containing XML!), in which case you basically bypass JAXB binding and thus you also don't need to generate any domain classes for your wsdl.<br><br>JAX-WS 2.0 specification, section 5.1 javax.xml.ws.Provider (page 77) explains the difference:\r\n<blockquote>Java SEIs [JH: a native Java service endpoint interface] provide a high level Java-centric abstraction that hides the details of converting between Java objects and their XML representations for use in XML-based messages. However, in some cases it is desirable for services to be able to operate at the XML message level. The Provider interface offers an alternative to SEIs and may be implemented by services wishing to work at the XML message level.</blockquote>\r\n<h2>Implementation example</h2>\r\nThis is how you would create such a web service, accessing its input as XML data represented by javax.xml.transform.Source:<br><br><strong>ExampleRawXmlServiceImpl.java:</strong><br><br><pre><code>\r\npackage example;<br><br>import javax.xml.transform.Source;\r\nimport javax.xml.ws.Provider;<br><br>@javax.xml.ws.ServiceMode(value=javax.xml.ws.Service.Mode.PAYLOAD)\r\n@javax.xml.ws.WebServiceProvider(wsdlLocation=&quot;WEB-INF/wsdl/learningActivity/LearningActivity.wsdl&quot;\r\n\t, targetNamespace=&quot;http://w3.ibm.com/xmlns/ibmww/hr/learning/lms/br/la&quot;\r\n\t, serviceName=&quot;LearningActivityHttpService&quot;\r\n\t, portName=&quot;LearningActivityRawXml&quot;)\r\npublic class ExampleRawXmlServiceImpl implements Provider&lt;Source&gt; {\r\n\t@Override\r\n\tpublic Source invoke(final Source request) {\r\n\t\t// ...\r\n\t\treturn null;\r\n\t}\r\n}\r\n</code></pre><br><br>(You perhaps don't need all the @WebServiceProvider attributes.)<br><br>The important things to notice:\r\n<ul>\r\n\t<li>@WebServiceProvider is used instead of @WebService</li>\r\n\t<li>The ServiceMode is set to Payload and therefore the class has to implement Provider&lt;javax.xml.transform.Source&gt;. You could set it also to Message, in which case you'd get a complete SOAPMessage and thus you'd need to implement Provider&lt;SOAPMessage&gt;.</li>\r\n</ul>\r\n<h2>Working with the XML data (Source)</h2>\r\nYou will likely need to convert the input javax.xml.transform.Source to something usable. Here are few examples:\r\n<strong>Converting Source to XML string:</strong><br><br><pre><code>\r\nimport java.io.StringWriter;\r\nimport import javax.xml.transform.*;\r\nimport javax.xml.transform.stream.StreamResult;\r\n...\r\nfinal StringWriter requestXmlWriter = new StringWriter();\r\nfinal Transformer trans = TransformerFactory.newInstance().newTransformer();\r\ntrans.transform(request, new StreamResult(requestXmlWriter));\r\nfinal String requestXml = requestXmlWriter.toString();\r\n</code></pre><br><br><strong>Converting Source to DOM</strong> (copied from [1]):<br><br><pre><code>\r\nimport javax.xml.transform.dom.*;\r\nimport org.w3c.dom.Node;\r\n...\r\nDOMResult dom = new DOMResult();\r\nTransformer trans = TransformerFactory.newInstance().newTransformer();\r\ntrans.transform(source, dom);\r\nNode node = dom.getNode();\r\n// do something with it ...\r\nDOMSource src = new DOMSource (node);\r\n</code></pre><br><br>Notice there is also javax.xml.transform.sax containing SAXResult and SAXSource.\r\n<h2>Resources</h2>\r\n<ol>\r\n\t<li>Article <a href=\"http://java.sun.com/developer/technicalArticles/xml/jaxrpcpatterns3/\">Realizing Strategies for Document-Based Web Services With JAX-WS 2.0: Part 3 in a Series</a> by Sameer Tyagi, 2005 - section Switching Off Data Binding</li>\r\n\t<li>Blog <a href=\"http://blogs.sun.com/artf/entry/operating_at_the_xml_message\">Operating at the XML Message Level in JAX-WS 2.0</a> by Art Frechette, 2006</li>\r\n\t<li>JAX-WS 2.0 specification (JSR 224)</li>\r\n</ol>",
  "excerpt": ""
 },
 {
  "title": "Creating JAX-WS webservice using Service Data Objects (SDO) instead of JAXB-bound POJOs",
  "published": "2010-12-29 21:28:49",
  "postType": "post",
  "slug": "/2010/12/29/creating-jax-ws-webservice-using-service-data-objects-sdo-instead-of-jaxb-bound-pojos/",
  "status": "publish",
  "tags": [
   "EMF",
   "java",
   "jaxws",
   "sdo"
  ],
  "categories": [
   "j2ee",
   "Languages",
   "WebSphere"
  ],
  "content": "If you need to invoke a logic using <a href=\"http://osoa.org/display/Main/Service+Data+Objects+Home\">Service Data Objects (SDOs)</a> from a JAX-WS webservice under Websphere 7 without the SCA Feature Pack, it is possible to do it similarly to the old approach of generating a JAX-RPC webservice from a WSDL with an SDO facade (actually building on it).<br><br>The steps are:\r\n<ol>\r\n\t<li>Use RAD to <a href=\"http://publib.boulder.ibm.com/infocenter/radhelp/v7r0m0/index.jsp?topic=/com.ibm.etools.webservice.was.atk.ui.doc/tasks/tsdofacade.html\">generate a JAX-RPC webservice from a WSDL with an SDO facade</a>.</li>\r\n\t<li><a href=\"/2010/12/29/implementing-jax-ws-webservice-accessing-its-input-as-xml-source-similar-to-jax-rpc-with-soapelement-input/\">Implement a JAX-WS webservice accessing directly its input as XML data</a> (i.e. implement is as a WebServiceProvider for message payload)\r\n<ul>\r\n\t<li>Use Transformer and StreamSource/Result to convert from/to String containing XML</li>\r\n</ul>\r\n</li>\r\n\t<li>Copy the SDO-related classes from the JAX-RPC webservice to the JAX-WS one, exclude just the JAX-RPC webservice interface and implementation</li>\r\n\t<li>Adjust the generated EMFSOAPElementUtil - change (de)serialize methods to expect/produce a String instead of SOAPElement</li>\r\n\t<li>Put it all together in the WS implementation class created in #2</li>\r\n\t<li>Finishing touches - add conversion of org.eclipse.emf.ecore.xml.type.internal.XMLCalendar to javax.xml.datatype.XMLGregorianCalendar</li>\r\n</ol>\r\n<!--more-->The help of Rational Application Developer (RAD) describes how to <a href=\"http://publib.boulder.ibm.com/infocenter/radhelp/v7r0m0/index.jsp?topic=/com.ibm.etools.webservice.was.atk.ui.doc/tasks/tsdofacade.html\">generate a JAX-RPC webservice from a WSDL with an SDO facade</a> but provides no clues for how to use SDOs with a JAX-WS based webservice. The trick is simple: similarly as in the JAX-RPC case, create a JAX-WS webservice that accesses its input as XML data (represented by javax.xml.transform.Source) and use the generate SDO facade code from JAX-RPC to convert the XML from/to SDO.\r\n<h2>Implementation steps in detail</h2>\r\n<h3>1. Generating JAX-RPC webservice with an SDO facade</h3>\r\nFollow the link above.<br><br>Notice that it generates POJO interfaces for the data objects, their implementations that actually implement the required SDO's <a title=\"Visit page outside WikiCentral\" rel=\"nofollow\" href=\"http://publib.boulder.ibm.com/infocenter/iadthelp/v7r0/index.jsp?topic=/org.eclipse.emf.ecore.sdo.doc/references/javadoc/commonj/sdo/DataObject.html\">commonj.sdo.DataObject</a>, and some factories for instantiating them.\r\n<h3>2. Implementing a JAX-WS webservice accessing its data as XML (javax.xml.transform.Source)</h3>\r\nAgain, follow the corresponding link above.<br><br>At the end, the code should look like this:\r\n<strong>LearningActivityRawXmlServiceImpl.java, part 1</strong>:<br><br><pre><code>\r\njavax.xml.ws.ServiceMode(value=javax.xml.ws.Service.Mode.PAYLOAD)\r\n@javax.xml.ws.WebServiceProvider(...)\r\npublic class LearningActivityRawXmlServiceImpl implements Provider&lt;Source&gt; {<br><br>\tprivate LearningActivityHttpBindingImplSDO sdoInstance_ = new LearningActivityHttpBindingImplSDO();\r\n\tprivate LaSOAPElementUtil laUtil_ = new LaSOAPElementUtil();<br><br>\t@Override\r\n\tpublic Source invoke(final Source request) {\r\n\t\tfinal DataObject requestSDO = convertRequest(request);\r\n\t\tfinal DataObject responseSDO = sdoInstance_.updateLearningActivity(requestSDO);\r\n\t\tfinal Source response = convertResponse(responseSDO);\r\n\t\treturn response;\r\n\t}<br><br>\t// ... other methods omitted ...\r\n}\r\n</code></pre><br><br>The class<em>LaSOAPElementUtil</em>has been created by the JAX-RPC generator. <em>LearningActivityHttpBindingImplSDO</em> represents the code that accepts and produces an SDO.<br><br><strong>To transform the Source to XML and DataObject:</strong><br><br><pre><code>\r\nprivate DataObject convertRequest(final Source request) {\r\n\tfinal StringWriter requestXmlWriter = new StringWriter();\r\n\ttry {\r\n\t\tfinal Transformer trans = TransformerFactory.newInstance().newTransformer();\r\n\t\ttrans.transform(request, new StreamResult(requestXmlWriter));\r\n\t\tfinal String requestXml = requestXmlWriter.toString();\r\n\t\tfinal DocumentRoot laRoot = (DocumentRoot) laUtil_.deserialize(requestXml);\r\n\t\tfinal UpdateLearningActivityType updateLearningActivityParametersSDO = laRoot.getUpdateLearningActivity();\r\n\t\treturn (UpdateLearningActivityTypeImpl) updateLearningActivityParametersSDO;\r\n\t} catch (Exception e) {\r\n\t\t// TransformerException, IOException, SAXException\r\n\t\tthrow new RuntimeException(&quot;Conversion failed: &quot; + e + &quot;, in: &quot; + request, e);\r\n\t} catch (TransformerFactoryConfigurationError e) {\r\n\t\tthrow new RuntimeException(&quot;Transformation during conversion failed: &quot; + e + &quot;, in: &quot; + request, e);\r\n\t}\r\n}\r\n</code></pre><br><br>The classes <em>com.ibm.w3.xmlns.ibmww.hr.learning.lms.br.la.DocumentRoot</em> and <em>...la.UpdateLearningActivityType</em> have been created by the JAX-RPC generator based on the WSDL and XSDs. <em>laUtil_.deserialize(..)</em> only invokes the (also generated) <em>EMFSOAPElementUtil.deserialize(..)</em>, which we will adjust later on. Notice that we need to cast from the generated pure java interface to the implementation class (UpdateLearningActivityTypeImpl) because only it does implement DataObject.<br><br><strong>To transform DataObject to XML and Source:</strong><br><br><pre><code>\r\nprivate Source convertResponse(final DataObject responseSDO) {\r\n\ttry {\r\n\t\tfinal String responseXml = laUtil_.serialize((EDataObjectImpl) responseSDO);\r\n\t\tfinal Source response = new StreamSource(new StringReader(responseXml));\r\n\t\treturn response;\r\n\t} catch (IOException e) {\r\n\t\tthrow new RuntimeException(&quot;Conversion failed: &quot; + e + &quot;, in: &quot; + responseSDO, e);\r\n\t} catch (SOAPException e) {\r\n\t\tthrow new RuntimeException(&quot;Conversion failed: &quot; + e + &quot;, in: &quot; + responseSDO, e);\r\n\t}\r\n}\r\n</code></pre><br><br>Again, <em>laUtil_.serialize(..)</em> only invokes the <em>EMFSOAPElementUtil.serialize(..)</em>.\r\n<h3>4. Adjust the generated EMFSOAPElementUtil to use XML String instead of SOAPElement</h3>\r\nWhile the JAX-RPC generated EMFSOAPElementUtil uses SOAPElement, we need to use Strings containing XML and therefore will adjust the signature and bodies of the (de)serialization methods slightly:<br><br><strong>EMFSOAPElementUtil.java (part):</strong><br><br><pre><code>\r\n  public EDataObjectImpl deserialize (final String xml)\r\n  throws IOException, SAXException\r\n  {\r\n    // Change: the inputStream is created from a String and not from a SOAPElement\r\n    final XMLResourceImpl res = (XMLResourceImpl)factory.createResource(URI.createURI(&quot;*.xml&quot;));\r\n    final InputStream inputStream = new ByteArrayInputStream(xml.getBytes(&quot;UTF-8&quot;));\r\n    res.load(inputStream, null);\r\n    final EDataObjectImpl document = (EDataObjectImpl)res.getContents().get(0);\r\n    return document;\r\n  }<br><br>  public String serialize ( EDataObjectImpl document )\r\n  throws IOException, SOAPException\r\n  {\r\n    XMLResourceImpl res = (XMLResourceImpl)factory.createResource(URI.createURI(&quot;*.xml&quot;));\r\n    res.getContents().add(document);\r\n    res.getDefaultSaveOptions().put(XMLResource.OPTION_DECLARE_XML,Boolean.FALSE);\r\n    res.setEncoding(&quot;UTF-8&quot;);\r\n    // Changed below - save into a StringWriter\r\n    final StringWriter outputXmlWriter = new StringWriter();\r\n    res.save(outputXmlWriter,null);\r\n    return outputXmlWriter.toString();\r\n  }\r\n</code></pre><br><br>Don't worry about the XMLResourceImpl and similar stuff, it has been generated by the JAX-RPC tool.\r\n<h3>6. Finishing touches - add conversion of XML Calendar</h3>\r\nWhile JAX-RPC uses javax.xml.datatype.XMLGregorianCalendar, the EMF-based SDO implementation uses an incompatible <a href=\"http://download.eclipse.org/modeling/emf/emf/javadoc/2.4.2/org/eclipse/emf/ecore/xml/type/internal/XMLCalendar.html\">org.eclipse.emf.ecore.xml.type.internal.XMLCalendar</a> and it's therefore necessary to convert the former to the latter in each eSet(..) method of the generated data objects.<br><br>Of course this is necessary only if any of the JAX-RPC generated data objects use XMLGregorianCalendar.<br><br>The conversion utility <strong>ConversionUtils.java</strong>:\r\n<pre><code>\r\nimport java.util.GregorianCalendar;\r\nimport java.util.TimeZone;\r\nimport javax.xml.datatype.DatatypeConfigurationException;\r\nimport javax.xml.datatype.DatatypeFactory;\r\nimport javax.xml.datatype.XMLGregorianCalendar;\r\nimport org.eclipse.emf.ecore.xml.type.internal.XMLCalendar;<br><br>public class ConversionUtils {\r\n\tpublic static XMLGregorianCalendar convertEmfToXmlCalendar(final XMLCalendar emfCalendar) {\r\n\t\tfinal GregorianCalendar gregCal = new GregorianCalendar();\r\n\t\tgregCal.setTime(emfCalendar.getDate());\r\n\t\tgregCal.setTimeZone(TimeZone.getTimeZone(&quot;GMT&quot;));\r\n\t\ttry {\r\n\t\t\tfinal XMLGregorianCalendar xmlGregCal = DatatypeFactory\r\n\t\t\t\t.newInstance().newXMLGregorianCalendar(gregCal);\r\n\t\t\treturn xmlGregCal;\r\n\t\t} catch (DatatypeConfigurationException e) {\r\n\t\t\te.printStackTrace();\r\n\t\t}\r\n\t\treturn null;\r\n\t}\r\n}\r\n</code></pre><br><br>Adding the conversion to each of the affected data objects' eSet method:\r\n<pre><code>\r\n// In a generated data class extending org.eclipse.emf.ecore.sdo.impl.EDataObjectImpl\r\n public void eSet(int featureID, Object newValue)\r\n  {\r\n\t  if (newValue instanceof XMLCalendar) {\r\n\t\t  newValue = ConversionUtils.convertEmfToXmlCalendar((XMLCalendar) newValue);\r\n\t  }\r\n    switch (featureID)\r\n    {\r\n        ...\r\n    }\r\n    super.eSet(featureID, newValue);\r\n}\r\n</code></pre>\r\nThat's it, folks.",
  "excerpt": ""
 },
 {
  "title": "2010 in review",
  "published": "2011-01-03 08:18:50",
  "postType": "post",
  "slug": "/2011/01/03/2010-in-review/",
  "status": "publish",
  "tags": [],
  "categories": [
   "General"
  ],
  "content": "The stats helper monkeys at WordPress.com mulled over how this blog did in 2010, and here's a high level summary of its overall blog health:<br><br><img style=\"border:1px solid #ddd;background:#f5f5f5;padding:20px;\" src=\"http://s0.wp.com/i/annual-recap/meter-healthy5.gif\" alt=\"Healthy blog!\" width=\"250\" height=\"183\" /><br><br>The <em>Blog-Health-o-Meter™</em> reads Wow.\r\n<h2>Crunchy numbers</h2>\r\n<div style=\"width:288px;float:right;border:1px solid #ddd;background:#fff;margin:0 0 1em 1em;padding:6px;\"><br><br><img src=\"http://s0.wp.com/i/annual-recap/abstract-stats-2.png\" alt=\"Featured image\" /><br><br><em>A helper monkey made this abstract painting, inspired by your stats.</em><br><br></div>\r\nThe average container ship can carry about 4,500 containers.  This blog was viewed about <strong>18,000</strong> times in 2010.  If each view were a shipping container, your blog would have filled about 4 fully loaded ships.<br><br>&nbsp;<br><br>In 2010, there were <strong>43</strong> new posts, growing the total archive of this blog to 86 posts. There were <strong>5</strong> pictures uploaded, taking up a total of 895kb.<br><br>The busiest day of the year was December 13th with <strong>321</strong> views. The most popular post that day was <a style=\"color:#08c;\" href=\"/2010/12/10/joshua-bloch-performance-anxiety-on-unpredictability/\">Joshua Bloch: Performance Anxiety - on Performance Unpredictability, Its Measurement and Benchmarking</a>.\r\n<h2>Where did they come from?</h2>\r\nThe top referring sites in 2010 were <strong>java.dzone.com</strong>, <strong>reddit.com</strong>, <strong>dzone.com</strong>, <strong>jroller.com</strong>, and <strong>google.com</strong>.<br><br>Some visitors came searching, mostly for <strong>clonezilla samba restore speed</strong>, <strong>vmware player boot from usb</strong>, <strong>@conversationscoped component in conversation scope</strong>, and <strong>eclipse create seam portlet enter project name</strong>.\r\n<h2>Attractions in 2010</h2>\r\nThese are the posts and pages that got the most views in 2010.\r\n<div style=\"clear:left;float:left;font-size:24pt;line-height:1em;margin:-5px 10px 20px 0;\">1</div>\r\n<a style=\"margin-right:10px;\" href=\"/2010/12/10/joshua-bloch-performance-anxiety-on-unpredictability/\">Joshua Bloch: Performance Anxiety - on Performance Unpredictability, Its Measurement and Benchmarking</a> <span style=\"color:#999;font-size:8pt;\">December 2010</span>\r\n2 comments\r\n<div style=\"clear:left;float:left;font-size:24pt;line-height:1em;margin:-5px 10px 20px 0;\">2</div>\r\n<a style=\"margin-right:10px;\" href=\"/2010/06/04/webservice-testing-with-jmeter-passing-data-from-a-response-to-another-request/\">Webservice testing with JMeter: Passing data from a response to another request</a> <span style=\"color:#999;font-size:8pt;\">June 2010</span>\r\n4 comments\r\n<div style=\"clear:left;float:left;font-size:24pt;line-height:1em;margin:-5px 10px 20px 0;\">3</div>\r\n<a style=\"margin-right:10px;\" href=\"/2010/05/08/book-real-world-java-ee-patterns-rethinking-best-practices-review-digest/\">Book: Real World Java EE Patterns - Rethinking Best Practices (review &amp; digest)</a> <span style=\"color:#999;font-size:8pt;\">May 2010</span>\r\n1 comment\r\n<div style=\"clear:left;float:left;font-size:24pt;line-height:1em;margin:-5px 10px 20px 0;\">4</div>\r\n<a style=\"margin-right:10px;\" href=\"/2010/06/10/booting-from-a-usb-stick-in-vmware-player/\">Booting from a USB stick in VMware Player</a> <span style=\"color:#999;font-size:8pt;\">June 2010</span>\r\n2 comments\r\n<div style=\"clear:left;float:left;font-size:24pt;line-height:1em;margin:-5px 10px 20px 0;\">5</div>\r\n<a style=\"margin-right:10px;\" href=\"/2009/03/23/seam-tutorial-1-2-richfaces-and-pa/\">Seam Tutorial 1.2: RichFaces and paged table (datascroller)</a> <span style=\"color:#999;font-size:8pt;\">March 2009</span>\r\n4 comments",
  "excerpt": ""
 },
 {
  "title": "Draft",
  "published": "2011-12-14 21:54:24",
  "postType": "post",
  "slug": "/2011/12/14/draft/",
  "status": "private",
  "tags": [],
  "categories": [
   "Uncategorized"
  ],
  "content": "<h2>BLOG</h2>\r\n<h2>Spisesteder etc.</h2>\r\n======<br><br>Aaron - vynikajici pizza delana na kameni - http://www.villaparadiso.no/index.htm<br><br>For taste of Norway you should go to Strand Restaurant, which has high standards, uses natural, Norwegian ingredients and also has a beautiful location by the fjord:\r\nhttp://www.restaurantstrand.no...<br><br>(It's however a few kilometers out of town)<br><br>---<br><br>One of my favorite places!  http://www.villaparadiso.no/  Its Italian but high quality pizzas (including vegan :) )<br><br>---<br><br>Ekebergrestauranten has Oslo's best view. The food is OK, and I'm sure they will have something vegetarian. It's also easy to get there by tram, making the Oslo experience complete :) http://www.ekebergrestauranten.com/no/<br><br>---<br><br>for et overblikk over Oslo: den siste stasjonen av T-banen 1 til Frognerseteren, der har du et versthus hvor du kan spise en eplekake og overblikke Oslo\r\n(med bussen 30 eller 31? kan du dra til Bygdoy - siste stasjonen er Huk, der kan du se Fjorden;\r\nog vigelandsparken er også veldig interessant for den første gangen i Oslo<br><br>---<br><br>Ta en tur opp til Holmenkollen - dere kan ta en måltid oppe på Soria Moria Hotellet, de burde ha noen lunsj tilbud. Buffet koster 250 stk, men det er alt man kan spise (litt dyrt men tross alt så er dette norge) :-) Nydelig utsikt ut mot Oslo Fjorden, spesielt fra tryvanstårnet.\r\nhttp://www.soriamoria.no/no/Ferie_og_fritid/Restauranttilbud/Sondagsbuffet/\r\nhttp://www.tryvann.no/tryvann-vinterpark/spise/tryvannstua<br><br>Kan tenke meg han har interesse i den andre verdenskrig - Nazi Tyskland okkuperte norge etter Polen hvet du - kanskje ta han med til Akershus ferstning, bra musee og kafeer i nærheten\r\nhttp://www.nasjonalefestningsverk.no/akershus/emner_akershus/Serveringssteder<br><br>Noe annet er Blücher Krisgskipet til Nazi Tyskland som ble senket av en norsk torpedo på sin jomfrureise. Musee i Drøbak 1/2 time sør mot sverige.<br><br>---<br><br>Det er gratis å gå\r\ntil Stortinget, kjempefint der!!! I tilegg, Nobel Fredsenteren i Aker Brygge.<br><br>---<br><br>#####<br><br>kultura:<br><br>Denne hendelsen står sentralt i den samisk-norske historien: http://www.filmweb.no/skolekino/incoming/article226162.ece",
  "excerpt": ""
 },
 {
  "title": "The Invisible Nenefits ",
  "published": "0000-00-00 00:00:00",
  "postType": "post",
  "slug": "/3167",
  "status": "draft",
  "tags": [],
  "categories": [
   "Uncategorized"
  ],
  "content": "",
  "excerpt": ""
 },
 {
  "title": "Tips For Effective Development On (Embedded) Jetty With Maven",
  "published": "2013-08-02 08:00:13",
  "postType": "post",
  "slug": "/3254",
  "status": "draft",
  "tags": [
   "java",
   "jetty",
   "Maven",
   "productivity",
   "webapp"
  ],
  "categories": [
   "Languages"
  ],
  "content": "Few tips for speeding up your feedback cycle when developing a Java webapp on an <a href=\"http://www.eclipse.org/jetty/documentation/current/embedding-jetty.html\">emebedded Jetty</a> (though it partially applies also to other and non-mebedded servers).<br><br>Running <code>mvn package; java -jar target/my-app-standalone.jar</code> is very time-consuming. What can we do to get our changes to static files and classes into the webapp faster?\n<ol>\n\t<li>Run the exploded webapp via Maven, withou re-packaging</li>\n\t<li>Enable class reloading in Jetty</li>\n\t<li>Use JRebel, i.e. class reloading on steroids with support for classes in JARs and many frameworks</li>\n</ol>\n<!--more-->\n<h2>Run the exploded webapp via Maven, withou re-packaging</h2>\nPackiging the app is very time-consuming and requires to be done again when a static file changes. So instead of\n<del><code>mvn package; java -jar target/my-app-standalone.jar --myOpt1=xyz --myOpt2=42</code></del><br><br>do this:\n<code>mvn compile exec:java -Dexec.mainClass=my.jetyapp.Main -Dexec.args=\"--myOpt1=xyz --myOpt2=42\"</code><br><br>The classes will be read directly from target/classes and static resources from wherever they are in your project.<br><br>Alternative: You can also use the <a href=\"http://www.eclipse.org/jetty/documentation/current/jetty-maven-plugin.html\">jetty-maven-plugin</a> if you don't start an embedded Jetty yourself.\n<h2>Enable class reloading in Jetty</h2>\nEven though mvn compile and exec:java is much faster then package, it is even better if Jetty reloads changed classes automatically. This solution has of course its challenges but works just fine in most cases:\n<h2>Use JRebel, i.e. class reloading on steroids with support for classes in JARs and many frameworks</h2>\n&nbsp;\n<h2>Related</h2>\n<ul>\n\t<li><a href=\"http://zeroturnaround.com/forums/topic/jetty-8-embedded-jrebel-static-files-maven/\">Jetty 8 embedded + JRebel + Static files + Maven</a></li>\n\t<li><a href=\"https://gist.github.com/naaman/1053217\">Hot Swapping With Maven, Jetty and IntelliJ</a></li>\n</ul>",
  "excerpt": ""
 },
 {
  "title": "My Year 2013 in Review",
  "published": "0000-00-00 00:00:00",
  "postType": "post",
  "slug": "/3693",
  "status": "draft",
  "tags": [],
  "categories": [
   "Uncategorized"
  ],
  "content": "<ul>\r\n\t<li>DevOps,</li>\r\n\t<li>Amazon Cloud</li>\r\n\t<li>Tech: Puppet, Zabbix, Hive, Hadoop, ...</li>\r\n\t<li>Puppet course</li>\r\n\t<li><a title=\"Seek Understanding\" href=\"/2014/02/23/seek-understanding/\">Seek Understanding</a></li>\r\n\t<li>Big data?</li>\r\n\t<li>Japan</li>\r\n\t<li>Agile Coach Camp Norway?, NDC (-&gt; embrace uncertainty, ladder of xxx, generative testing, <a href=\"http://leanprocrastination.com/blog/2012/08/real-options-a-mindset/\">Real Options</a>, Dan North, ..)</li>\r\n\t<li>TBD: Go through articles</li>\r\n\t<li>Books: The Project Phoenix, coaching, Thinking, Fast and Slow;</li>\r\n\t<li>Clojure &amp; Incanter dev, Python</li>\r\n\t<li>Prefer simple solutions - microservices with embdded jetty that kan be spawned and killed at will, .., plain java over DI fwrks,</li>\r\n\t<li>Lean thinking, more humane workplaces, change of management paradigm: Deming, Ch. Argyris,no-mgmt,</li>\r\n\t<li>Reactive programming course</li>\r\n\t<li>5/2013 birth of  <a href=\"http://wondersofcode.wordpress.com/\">Wonders of Code</a></li>\r\n\t<li>EuroClojure</li>\r\n</ul>\r\nLinks\r\n<ul>\r\n\t<li><a href=\"http://blogs.hbr.org/2012/09/want-to-build-resilience-kill-the-complexity/\">HBR: Want to Build Resilience? Kill the Complexity</a> – a highly interesting, thought provoking article relevant both to technology in particular and the society in general; f.ex.: more security features are bad for they make us behave less safely (risk compensation) and are more fragile w.r.t. unexpected events. “<em>Complexity is a clear and present danger to both firms and the global financial system: it makes both much harder to manage, govern, audit, regulate and support effectively in times of crisis. [..] Combine complex, Robust-Yet-Fragile systems, risk-compensating human psyches, and risk-homeostatic organizational cultures, and you inevitably get catastrophes of all kinds: meltdowns, economic crises, and the like.</em>” The solution to future financial crisis is primarily not more regulation but <strong>simplification of the system</strong> – to make it easier to police, tougher to game. We also need to <strong>decrease interconnectednes</strong> (of banks etc.), one of the primary sources of complexity. Also a great example of US Army combatting complex, high-risk situations by employing “devil’s advocates / <strong>professional skeptics</strong>” trained to help “<em>avoid the perils of overconfidence, strategic brittleness, and groupthink. The goal is to respectfully help leaders in complex situations unearth untested assumptions, consider alternative interpretations and “think like the other”</em>“.</li>\r\n\t<li><a href=\"http://5whys.com/blog/technical-disobedience.html\">Roy Osherove: Technical Disobedience</a> – take nothing for granted, don’t let the system/process stop you, be creative about finding ways to improve your team’s productivity; there always is a way. Nice examples.</li>\r\n\t<li><a href=\"http://2013.jsconf.eu/speakers/pete-hunt-react-rethinking-best-practices.html\">Pete Hunt: React: Rethinking best practices</a> (JSConf 2013, 30 min) – one of the most interesting talks about frontend development, design, and performance I have heard this year, highly recommended. Facebook’s <a href=\"http://facebook.github.io/react/\">React</a> JavaScript framework  is a fresh and innovative challenger in the MVC field. It is worthwile to learn why they parted ways with the popular approach of templates (spoiler: concern separation, cohesion x coupling, performance). Their approach with virtual DOM enables some cool things (run in Node, provide HTML5-like events in any browser with consistent behavior, …). Key: templates are actually tightly coupled to display logic (controllers) via the model view tailored for them (i.e. Controller must know what specific data &amp; in what form View needs) =&gt; follow cohesion and keep them together componets, separate from other components and back-end code. Also, state changing over time at many places is hard =&gt; re-render the whole app rather than in-place updates. Also, the <a href=\"https://github.com/swannodette/om/blob/master/README.md\">ClojureScript Om wrapper</a> enables even more performance optimizations thanks to immutable data structures etc.</li>\r\n\t<li>Bob Marshall: <a href=\"http://flowchainsensei.wordpress.com/2013/10/12/the-antimatter-principle/\">The Antimatter Principle</a> – “<em>the only principle we need for becoming wildly effective at collaborative knowledge work</em>” – can be summarized as “attend to folks’ needs” (importantly, including your own) =&gt; find out what people actually need, interpret their behavior (including anger, seemingly irrational or stupid requests etc.) in terms of needs; mastering this will make you excell in communication and effective work. Read the post to find out more.</li>\r\n\t<li>Book: <a href=\"http://aosabook.org/en/index.html\">The Architecture of Open Source Applications</a> (via <a href=\"https://twitter.com/rmz/status/380498719629512704\">@rmz</a>) – learn by studying architectures of existing systems – “<em>In these two books, the authors of four dozen open source applications explain how their software is structured, and why. What are each program’s major components? How do they interact? And what did their builders learn during their development?</em>“</li>\r\n\t<li>Book: <a href=\"http://pragprog.com/book/pb7con/seven-concurrency-models-in-seven-weeks\">Seven Concurrency Models in Seven Weeks: When Threads Unravel</a> – “<em>how to exploit different parallel architectures to improve your code’s performance, scalability, and resilience</em>” – threads &amp; locks, actors, FP + immutability/futures/promisses, Software Transactional Memory etc., GPU, MapReduce on clusters, … (<a href=\"http://media.pragprog.com/titles/pb7con/intro.pdf\">intro</a>) Personally, I would prefer from theory to practice approach and mention of <a title=\"Communicating sequential processes\" href=\"http://en.wikipedia.org/wiki/Communicating_sequential_processes\">CSP</a> (-&gt; Go’s channels, core.async) and more.</li>\r\n\t<li>One of the most valuable talks I’ve seen, in just 18 min: <a href=\"http://www.youtube.com/embed/XD6N8bsjOEE\">The Progress Principle</a> – about the disengagement crisis and motivation at work by Teresa Amabile at TEDx Atlanta (via <a href=\"https://twitter.com/thovden\">@thovden</a>). Disengagement from work is increasing, at all age and salary levels, and leads to unhappy people, low productivity, huge financial losses. Based on analysing diaries of 12k participants, the single <strong>most important engaging and motivating factor is making progress in a meaningful work</strong> (including small wins). A culture of management by fear and punishment for failure creates disengagement and can crush even an innovative, profitable, praised company in a few years. Everybody, though especially the management, creates the culture through their everyday, small actions. If everybody focuses on catalysing progress and supporting their fellow humans through good and bad times, engagement and success will follow. Remove progress inhibitors, nourish the human spirit (acknowledge what we humans value, encourage people). Yet of the managers asked, very few knew of the significance of making progress (or, I can assume, of supporting people and making them happy(er) and the impact of our inner work life (perceptions, emotions, etc.) on our productivity and creativity). The study included two seemingly similar, successfull companies, one with great engagement, another with a new management that managed to destroy the engagement and thus eventually the company. Actions to take: catalyse progress, celebrate wins, encourage and support your colleagues.</li>\r\n\t<li><a href=\"http://onstartups.com/tabid/3339/bid/97052/Screw-You-Joel-Spolsky-We-re-Rewriting-It-From-Scratch.aspx\">How To Survive a Ground-Up Rewrite Without Losing Your Sanity</a> (recommended by Kent Beck) – sometimes you need to actually rewrite an important <em>part</em> of a system; here we learn about two such rewrites, one which went well and one that failed badly – and what are the important differences.</li>\r\n\t<li><a href=\"http://youtu.be/502ILHjX9EE\">Agile in a Nutshell</a> (originally Agile Product Ownership in a Nutshell) by Henrik Kniberg – the best explanation of the agile development process ever, in just 15 minutes and with wonderful animation; every developer should see this. Some highlights: the most important task of product owner is to say NO so that backlog doesn’t grow infinitely; at start, the estimates of size and value will suck and that’s OK because the value is in the conversation, not in the numbers (that are anyway just relative); the goal is to maximize outcome (value), not output (# features). Compromises between short-term vs. long-term goals, knowledge vs. customer value building etc. Build the right thing (PO) x build it right (devs) x build it fast (SM). Technical debt x sustainable pace. As I said – you MUST see it.</li>\r\n\t<li><a href=\"http://flowchainsensei.wordpress.com/rightshifting/\">Bob Marshall: Rightshifting</a> – according to the author, 80% of knowledge work organizations are very ineffective, wasting resources on non-value-adding activites; only few are effective, even fewer highly effective. Rightshifting is the attempt at shiting them to the right, towards higher effectiveness. Links to a few videos explaining it more. Related: Steve McConnell’s <a href=\"http://www.stevemcconnell.com/psd/13-businesscase.htm\">Business Case for Better Software Practices</a>, referring to a study by <a href=\"http://www.sei.cmu.edu/\">SEI</a>; “The actual distribution of software effectiveness is asymmetric. Most organizations perform much closer to the worst practice than to the best.” – the best performing 10 times better then the worst/average (productivity, speed, defects, value)</li>\r\n\t<li><a href=\"http://ecorner.stanford.edu/authorMaterialInfo.html?mid=3103\">Tim O’Reilly: Create More Value Than You Capture</a> (30 min + questions) – build apps that matter, that change how we do things. Thinking just about money is bad. Try to make the society better, smart, create more value than you capture, solve important problems, help people.</li>\r\n\t<li><a href=\"http://www.inc.com/suzanne-lucas/why-you-should-work-with-someone-you-hate.html\">Why You Should Work With Someone You Hate</a> – working with people we like and do not have conflicts with is nice but we are likely to have similar views and ideas and miss the broader picture. Working with somebody that drives you crazy while being able to respect each other is very valuable because it opens you to different views and forces you to really defend yours. Recommended!</li>\r\n\t<li><a href=\"http://server.dzone.com/articles/how-completely-fail-bdd\">How to Completely Fail at BDD</a> – a story of an enthusiastic developer who tried to make everyone’s life better by introducing automated BDD tests and failed due to differences in culture (and inability to change thinking from the traditional testing), a surprising lack of interest in the tool and learning how to write good tests: “Culturally, my current team just isn’t ready or interested in something like this.” Morale: It is hard to <a href=\"http://www.amazon.com/Switch-Change-Things-When-Hard/dp/0385528752/\">change people</a>, good ideas are not enough.</li>\r\n\t<li><a href=\"http://blogs.hbr.org/2013/01/how-to-have-a-year-that-matter/\">How to Have a Year that Matters</a> (via <a href=\"https://twitter.com/gbrindusa\">@gbrindusa</a>) - do you want to just survive and collect possessions or do you want to make a difference? Some questions everybody should pose to him/herself.</li>\r\n</ul>\r\nMy Posts\r\n<ul>\r\n\t<li><a title=\"Permanent link to Patterns of Effective Delivery – Challenge Your Understanding Of Agile (RootsConf 2011)\" href=\"/2013/06/22/patterns-of-effective-delivery-challenge-your-understanding-of-agile-rootsconf-2011/\" rel=\"bookmark\">Patterns of Effective Delivery – Challenge Your Understanding Of Agile (RootsConf 2011)</a></li>\r\n\t<li><a title=\"Permanent link to Ignore requirements to gain flexibility, value, insights! The power of why\" href=\"/2013/06/01/ignore-requirements-to-gain-flexibility-value-insights-the-power-of-why/\" rel=\"bookmark\">Ignore requirements to gain flexibility, value, insights! The power of why</a></li>\r\n\t<li><a title=\"Permanent link to Books Our Developers Should Read\" href=\"/2013/03/12/books-our-developers-should-read/\" rel=\"bookmark\">Books Our Developers Should Read</a></li>\r\n\t<li><a title=\"Permanent link to The Sprinting Centipede Strategy: How to Improve Software Without Breaking It\" href=\"/2013/01/14/the-sprinting-centipede-strategy-how-to-improve-software-without-breaking-it/\" rel=\"bookmark\">The Sprinting Centipede Strategy: How to Improve Software Without Breaking It</a></li>\r\n\t<li><a title=\"Permanent link to Fast Code To Production Cycle Matters: For Pleasure, Productivity, Profit\" href=\"/2013/01/05/fast-code-to-production-cycle-matters-for-pleasure-engagement-profit/\" rel=\"bookmark\">Fast Code To Production Cycle Matters: For Pleasure, Productivity, Profit</a></li>\r\n</ul>",
  "excerpt": ""
 },
 {
  "title": "Minimalism & Focus: Re-implementing a Webshop One Tiny Step at a Time",
  "published": "0000-00-00 00:00:00",
  "postType": "post",
  "slug": "/4300",
  "status": "draft",
  "tags": [
   "agile",
   "experience",
   "opinion"
  ],
  "categories": [
   "SW development"
  ],
  "content": "<blockquote>You will be surprised how little you actually need to implement *now*.</blockquote><br><br>This is a story of a truly agile development, that our team is living. I am learning a lot when developing this product and want to share that experience with you.<br><br>We are a small team with a challenging task and the secret mission to revolutionize our organization and the way it does go around work. Colleagues called as \"extreme\" when we delivered the first tiny slice of our product to users - and we were flattered. Our monitoring guys were shocked when asking about our going-live date and instead of the expected answer of some months I said \"next Monday.\" Being truly agile is not simple, especially in a rather traditional organization. It requires a lot of support, some tough choices, lazer-sharp focus, competence, passion. The most surprising thing to me was how much we (= developers + business) managed <em>not</em> to do - postpone, hardcode, skip.<br><br><!--more--><br><br><h1>What was it all about?</h1><br><br>We got three months to prove that having developers together with the business people will enable us to experiment and evolve our webshop fast and thus make it ever more attractive for customers - leading to measurably more satisfied customers and better sales. Enough so to make up for the much higher cost of local developers.<br><br>A complication: We had to write our own webshop instead of the large, inflexible, hosted beast the company is currently using.<br><br>The company itself is a big, sleepy animal that only recently started to stirr and wake up and grow to a more agile way of living. We are lucky enough to work mostly with supportive, open-minded, agile leaders and business people.<br><br><h1>How to implement a webshop and increase user satisfaction in three months?</h1><br><br>Frankly, I was scared and sceptical. Replacing a huge webshop software and the tools supporting the process around it in three people in 1-2 months (we also needed time to show results, don't we?) - that sounded impossible and shouted \"scope creep\" in big, bold, blinking, red letters. And we could hardly do anything without the help of the small, overworked Ops department restricted by many rules and dependant on the remote and not very responsive IT department of the mother company. Yet, we managed (or so it seems so far). How?<br><br>The recipe is simple:<br><br><ol>\n    <li>Minimize and decouple dependencies</li>\n    <li>Focus, focus, focus (a lot to learn from the Lean Startup folks!)</li>\n    <li>Luck; a lot of luck</li>\n</ol><br><br>Due to sheer luck, we were able to minimize our dependency on the Ops department and move in our own speed. We made alternative plans to bypass possible organizational obstacles. And we worked very hard on focusing on the next milestone and doing the absolutely minimal amount of work necessary - more on that later.<br><br>A cornestone of our approach was to release the absolutely minimal \"viable product\" (MVP) - in our case that meant creating only a product details page and doing so for just a single product. The plan was to redirect users that access that product to our page and, when they click on \"[Buy!],\" sending them back to the checkout process in the existing webshop. Technically, this is easy if you have a web proxy in front of the webshop - it could simply forward requests matching a given expression to the new backend.\nThe MVP is actually not that minimal since it needs to provide the same functionality as the existing product page: select the product and configure its options, buy related accessories and services. It has to fetch data from various REST services; additionally, these data are frequently modified and enhanced by the webshop team using the webshop's CMS. And it has to look nice and by trackable through monitoring so that we could compare its effectivness against the old page.But before we explore the MVP approach and other guiding principles in more detail, let's watch the story evolve.<br><br><h1>Timeline</h1><br><br><ol>\n    <li>Februray 1st: Arrival; we learn the context, discuss risks and how to address them.</li>\n    <li>2 weeks in: Everybody has finally access card, access to internal system and VPN. Ugh.</li>\n    <li>After days of waiting, back-and-forth communication, and sacrificial documents to satisfy the Process, we finally got a test virtual machine (VM). But ouch, it has no SW installed, no access to anywhere, is not accessible from the Internet, and we do not have admin rights. (Though a friendly local ops person helps us with that, bypassing the mother company rules.)</li>\n    <li>The revolution: One of the (newly hired) high bosses proposes that we use the cloud, namely AWS. Everybody is shocked, we would never believe such an escape from the tightly restricted corporate IT environment to be possible. A ray of hope shines on us.</li>\n    <li>Our epiphany: If cloud, why not Node.js? Nobody has ever done it, the Ops have no experiences operating it, it doesn't fit into the Java-focused infrastructure. But that applies to AWS as well and having the same language at the front-end and back-end makes perfect sense and would solve our problems with server-side rendering. (The application uses React.js at front-end and server-side rendering is important for performance and SEO.)</li>\n    <li>Februry 9th: Our Node.js server is born.</li>\n    <li>??? Our first demo: We only use mock data, and only have the first of the two pages that we need.</li>\n    <li>March 4th: We finally have all the code to use live data from the REST services.</li>\n    <li>March 10th: We decide to go live with our page on 3/23, no matter what.</li>\n    <li>Some time in March: We were still not able to test our inject-via-proxy solution and we finally learn that, though technically simple and possible, it is not politically feasible. Luckily, there is an ugly workaround: change selected links in the existing webshop. (Surprisingly enough, this can be done in minutes by our people. No \"deployment in 2 months\".)</li>\n    <li>Still in March: We decide that we are not going to support overriding data from the backend (yet). We will have to live with whatever data we get - or hardcode their modification in the app if it is critical.</li>\n    <li>March 16th, D-7: We got access to the production REST services from AWS. (Well, to most of them - but that is soon sorted out.)</li>\n    <li>Friday, March 20th: The corporate DNS has been finally configured to point to Amazon DNS for our subdomain, after all the bosses have approved this \"risky business.\" We have a domain! But still no SSL certificate...</li>\n    <li>Monday, March 23rd, 3 minutes to the demonstration of our live site: last deployment finished and the site is restarted to take in use our new, shiny SSL certificate. We are live!</li>\n    <li>Tuesday, March 24th: We are somewhat tired but happy. But no time to <a href=\"http://slack.com/\">Slack</a> :), we have to go on iteratively removing all the hardcoded stuff and improving the page.</li>\n    <li>Wednesday, March 25th: A new milestone in the history of the company - we are deploying important fixes in the middle of the day, while driving a car:</li>\n</ol><br><br>https://twitter.com/alex_york/status/580674090144542721<br><br><h1>Minimalism and focus</h1><br><br><h2>We did implement a lot:</h2><br><br><ul>\n    <li>A beautiful page based on a new design</li>\n    <li>Fetching and consolidating data from 4 REST services in a resilient manner</li>\n    <li>UI for selecting the product and its various configurations and buying related services and accessories</li>\n    <li>A high-availability environment</li>\n    <li>Basic monitoring of the environment via AWS CloudWatch and its notification service (number of instances able to serve requests, 5xx responses, later also high latency)</li>\n    <li>Client-side and server-side error reporting, automatic aggregation, and notification via <a href=\"http://yellerapp.com/\">Yeller</a></li>\n    <li>Sending of access logs to the corporate monitoring system (though the Ops hadn't time yet to actually start receiving the logs)</li>\n    <li>Server-side rendering</li>\n</ul><br><br><h2>We did not need surprisingly many things:</h2><br><br><ul>\n    <li>Services for the product are currently hard-coded</li>\n    <li>What accessories apply to the product is hard-coded</li>\n    <li>We have no \"CMS\" where the business people could modify the data from the back-end (but we can modify them in the code and deploy in few minutes)</li>\n    <li>VPN access between AWS and the company - it was deemed necessary for security reasons at first but the selected REST calls we need are not that sensitive so we were able to get them exposed to us using only HTTPS and authorization</li>\n    <li>Integration with the existing operations infrastructure (monitoring etc.) - the Ops just do not have time for us; so we monitor ourselves and take responsibility for keeping the site up ourselves</li>\n    <li>Performance testing</li>\n    <li>Continuous Deployment (CD) - my dream was to implement proper CD pipeline with automatic deployment and good unit/integration/acceptance testing; however we don't really need it yet, we can deploy and test manually quickly enough</li>\n</ul><br><br><h1>Conclusion</h1><br><br>TBD",
  "excerpt": ""
 },
 {
  "title": "You don''t need to understand every damn line of code",
  "published": "0000-00-00 00:00:00",
  "postType": "post",
  "slug": "/4619",
  "status": "draft",
  "tags": [
   "opinion"
  ],
  "categories": [
   "SW development",
   "Uncategorized"
  ],
  "content": "<p class=\"p1\"><span class=\"s1\">Sometimes a colleague says:</span></p><br><br><blockquote>\n<p class=\"p1\"><span class=\"s1\">This piece of code is too complex, I do not understand it so I cannot use it. I have written my code without it (contrary to the rest of what is in that module).</span></p>\n</blockquote><br><br><p class=\"p1\"><span class=\"s1\">Now, I have a shocking proposition: <em>You don't need to understand every piece of code you are using.</em> You don't go and read every line of every library you are using, do you?</span></p><br><br><p class=\"p1\"><span class=\"s1\">Now don't get me wrong. You can learn a lot from reading the code of libraries you depend on and it is really beneficial to know the libraries well. But you obviously don't need to do so to use them. Also I am not suggesting you should write crappy code nobody can understand - readability and maintainability are really important. We should strive to write simple and easy to understand code.</span></p><br><br><p class=\"p1\"><!--more--></p><br><br><p class=\"p1\"><span class=\"s1\">I want to suggest that some pieces of code may play the same role as a library, even though they are not packed and installed separately. You can occasionally write more advanced code to address complex concerns, if you take care to make it well documented, high quality, and easily usable without requiring knowledge of the details. Especially if it is utility code, not really related to you business logic - perhaps a testing or data utility.</span></p><br><br><p class=\"p1\"><span class=\"s1\">So what do you need to be able to use a library?</span></p><br><br><ul class=\"ul1\">\n    <li class=\"li1\"><span class=\"s1\">Small, clear API with functions (and arguments) so well-named, that it is clear what they do</span></li>\n    <li class=\"li1\"><span class=\"s1\">Comments (JSDoc, JavaDoc, ....) that explain How and Why to use the functions, the corner cases, expected inputs and outputs, limits</span></li>\n    <li class=\"li1\"><span class=\"s1\">Perhaps a few examples</span></li>\n</ul><br><br><p class=\"p1\"><span class=\"s1\">That's it. That should be enough, if done well. You don't need to read the code.</span></p><br><br><p class=\"p1\"><span class=\"s1\">Let's have a look at an example of a librarish piece of code, intended to simplify testing:</span></p><br><br><p class=\"p1\"><span class=\"s1\">TODO GA tests' objectDiff</span></p><br><br><p class=\"p1\"><span class=\"s1\">I have taken an effort to provide good library-grade code - a good name, explaining comments, examples (not that it could not be improved!).</span></p><br><br><p class=\"p1\">I get really irritated if you say that you don't understand the code and thus cannot use it despite all the effort I made to make it unnecessary to read the code. Especially if I believe you would have no problems with using it if it was not a part of the codebase but an external library. But what is the difference? It is only a mental one.</p><br><br><h2 class=\"p1\">Summary</h2><br><br>We have different requirements on different code. We typically want to understand all of our codebase - while for libraries we typically only require that they work, have good API, and good documentation. Perhaps we can also have \"embedded libraries,\" i.e. library-type and quality code that we can use without feeling obligated to understand every line of it (without nontrivial effort). What do you think?",
  "excerpt": ""
 },
 {
  "title": "EMF: Reading a model from XML - how to correctly declare its namespace - variants",
  "published": "2011-01-03 12:21:57",
  "postType": "post",
  "slug": "/2011/01/03/emf-reading-a-model-from-xml-how-to-correctly-delcare-a-namespace-variants/",
  "status": "publish",
  "tags": [
   "eclipse",
   "EMF",
   "java",
   "xml"
  ],
  "categories": [
   "Languages"
  ],
  "content": "When you use the <a href=\"http://en.wikipedia.org/wiki/Eclipse_Modeling_Framework\">Eclipse Modeling Framework</a> (EMF) to read a model instance from an XML file, such as a webservice call message payload, it's essential for EMF to be able to match the root XML element with the model's \"ePackage\" that should be used for (re)constructing the model instance from the XML and this is done by matching the root element's and the ePackage's namespaces (as in XSD). So it's very important to have proper configuration of EMF and proper content of the XML. Since there ale multiple variations of both, there are more ways to get it wrong than right. To learn what I've discovered regarding the valid combinations suitable at different situations, read on.<!--more-->\r\n<h2 id=\"emfintro\">EMF micro-introduction</h2>\r\nIn Java you can define <em>models</em> by creating classes with attributes (such as Book with a name, an Author, a Library) and connecting them together. You can then create an <em>instance of the model</em> by creating instances of the classes (Book: Clean Code, Author: Uncle Bob, ...). The <em>meta-model</em> you use for defining the models is defined by the Java language and consists of classes etc.<br><br>EMF is Java API which makes it also possible to define models and create, save, and load their instances in various formats (for example native EMF, UML, XSD). The main differences to Java are that models can be defined not only statically but also dynamically at runtime (and I suppose that the syntax may be richer than Java's as EMF is more general-purpose), that EMF supports multiple formats for model and model instance input and output, that there is a better reflection-like API, and that you can easily generate editors for your models. The generic meta-model for defining models consists of elements like EClass, EAttribute, EOperation etc. and these elements are grouped in so-called EPackages, each identified uniquely by a namespace URI as you might know it from XSD. Instances of a model are composed of EObjects (and supporting classes like EList). Each of this elements is represented by a Java class.<br><br>Nano-glossary: <em>Feature</em> (or structural feature) is, simply said, an attribute.\r\n<h2>Assumptions</h2>\r\nIn this post I'll suppose that you've already defined your model, for  example dynamically by reading it from an XSD or statically by  generating it based on UML, and that you want to read an XML file  representing an instance of the model and transform it into the runtime  EMF representation composed of EObjects. The XML may be for example a  part of a SOAP message.<br><br>For simplicity we may assume that all your model  elements are within a single EPackage, under a single namespace, though  there is no problem with having them distributed among multiple  packages provided that each top-most XML element belonging to another  package has proper namespace information so that EMF can match it to the  correct EPackage.\r\n<h2>Proper EMF configurations and namespace declarations</h2>\r\nThere are basically three options regarding the XML root element's namespace declaration:\r\n<ol>\r\n\t<li>It declares its namespace with an explicit prefix</li>\r\n\t<li>It declares its namespace without any prefix, i.e. it declares its namespace as the default one since that on</li>\r\n\t<li>There is no namespace information at all in the XML</li>\r\n</ol>\r\nBased on where you're getting the XML from you may encounter any of these situation and you will need to configure EMF accordingly. If you get EMF wrong then you will get strange results such as\r\n<ul>\r\n\t<li>null</li>\r\n\t<li>a valid root EObject without any attributes for the nested elements or the failure \"unknown feature\"</li>\r\n\t<li>an EObject without any EClass information (signifying that EMF failed to match the root XML element with the EPackage that you wanted and used its defaults instead)</li>\r\n</ul>\r\n<h3>1. XML root element in a namespace with a prefix (xmlns:ns=\"...\"&gt;)</h3>\r\nEMF normally expects the input XML to have the target namespace declared with a prefix on the root element and the nested elements to have neither the prefix nor any namespace declaration (and thus these <em>local</em> elements are <em>unqualified</em> in the XSD language). Example:<br><br><pre><code>\r\n&lt;myRootElement xmlns:ns=&quot;http://example.com/myXml&quot; someAttribute=&quot;value&quot;&gt;\r\n   &lt;myAnotherElement anotherAttribute=&quot;value 2&quot;/&gt;\r\n&lt;myRootElement&gt;\r\n</code></pre><br><br>This is what you would get if you saved an EMF model using its serialization API (<a href=\"http://www.cise.ufl.edu/mirrors/eclipse/modeling/emf/emf/javadoc/2.2.5/org/eclipse/emf/ecore/resource/Resource.html#save(java.io.OutputStream, java.util.Map)\">Resource.save(..)</a>).<br><br>The root element's namespace - http://example.com/myXml in this case - must correspond to the namespace URI of a registered EPackage in the <a href=\"http://www.cise.ufl.edu/mirrors/eclipse/modeling/emf/emf/javadoc/2.2.5/org/eclipse/emf/ecore/EPackage.Registry.html\">EMF package registry</a> (via put(namespaceUri, anEPackageInstance)).\r\n<h3>2. XML root element in the default namespace(&lt;elm xmlns=\"...\"&gt;)</h3>\r\nAnother, a bit more tricky option is to declare the namespace without any prefix at all:<br><br><pre><code>\r\n&lt;myRootElement xmlns=&quot;http://example.com/myXml&quot; someAttribute=&quot;value&quot;&gt;\r\n   &lt;myAnotherElement anotherAttribute=&quot;value 2&quot;/&gt;\r\n&lt;/myRootElement&gt;\r\n</code></pre><br><br>Beware that having the root element without any prefix and with a declaration of the default NS as here may cause a strange behavior, namely the root object being loaded but without any content, producing the error \"unknown feature\" for the 1st nested element.<br><br>It's important to know how namespaces and qualified elements work. In the case #1 (explicit prefix) you have only the root element in a namespace (NS) while the nested elements, having no prefix, have null NS. Therefore if you declare a default NS on the root element you have a totally different situation because now all elements without a prefix - including the nested ones - have a namespace. And from the point of view of XML and thus also EMF the elements \"myAnotherElement from the namespace XY\" and \"myAnotherElement from the null namespace\" are completely different and you will thus get the rather confusing error \"unknown feature myAnotherElement\".<br><br>The solution is to tell EMF that it should suppose that the nested elements are qualified with a namespace name instead of having a null NS. I don't know how to do that in general but if you load your model from an XSD then you can do it by adding the attribute 'elementFormDefault=\"qualified\"' to the xsd:schema element to tell it that even local elements (those within a complexType) should be qualified:<br><br><pre><code>\r\n&lt;xsd:schema xmlns:xsd=&quot;http://www.w3.org/2001/XMLSchema&quot;\r\n targetNamespace=&quot;http://example.com/myXml&quot;\r\n elementFormDefault=&quot;qualified&quot;&gt;\r\n\t  &lt;xsd:complexType name=&quot;myRootElement&quot;&gt;\r\n\t\t&lt;xsd:sequence&gt;\r\n\t\t\t&lt;xsd:element name=&quot;myAnotherElement&quot; type=&quot;xsd:string&quot; /&gt;\r\n\t\t\t...\r\n\t\t&lt;/xsd:sequence&gt;\r\n\t&lt;/xsd:complexType&gt;\r\n&lt;/xsd:schema&gt;\r\n</code></pre><br><br>(Setting the elementFormDefault attribute was really the only change I had to do to get EMF working again.)<br><br><a href=\"http://www.eclipse.org/forums/index.php?t=tree&amp;th=129347&amp;S=4a71b44b5931c4dbe7bac446b6ee10c6\">This tip comes from a forum post</a> and its response. See the <a href=\"http://www.w3.org/TR/2004/REC-xmlschema-0-20041028/#UnqualLocals\">XSD spec. - 3.1 Target Namespaces &amp; Unqualified Locals</a> for details.<br><br>Notice that <em>qualified</em>, in XML terms, means \"Associated with a namespace, either  by the use of a declared prefix or via a default namespace declaration\". All \"unqualified\" elements and attributes are in no (null) namespace. By default, all global elements and attributes are qualified.\r\n<h4>Why you may need this</h4>\r\n<ul>\r\n\t<li>Either you receive input in this format</li>\r\n\t<li>Or you receive input without any namespace information and you  want to add it there with the least effort (adding just a namespace  declaration is easier than also needing to change element's namespace  prefix)</li>\r\n</ul>\r\n<h3>3. No namespace information in the XML (&lt;elm&gt;)</h3>\r\nThis is the worst case because the input XML doesn't describe itself sufficiently and you need to know or guess the right EPackage to parse it, it would be certainly better if it had a namespace information. But sometimes you are not able to influence the input yet still want to read it with EMF.<br><br><pre><code>\r\n&lt;myRootElement someAttribute=&quot;value&quot;&gt;\r\n   &lt;myAnotherElement anotherAttribute=&quot;value 2&quot;/&gt;\r\n&lt;/myRootElement&gt;\r\n</code></pre><br><br>If the root XML element has no prefix and no associated namespace information then EMF won't be\r\nable to match it with the corresponding model EPackage and thus won't be able to load it properly unless <em>you register the target EPackage with the ResourceSet's/</em><em>global</em><em> package registry (also) under the null URI</em>:<br><br><pre><code>\r\nfor (EPackage ePackage: eCorePackages) {\r\n\tresourceSet.getPackageRegistry().put(null, ePackage);\r\n\t// alternatively could call EPackage.Registry.INSTANCE.put(..)\r\n}\r\n</code></pre><br><br>This <a href=\"http://www.eclipse.org/forums/index.php?t=tree&amp;th=128831\">tip comes from an Eclipse forum thread</a>.\r\n<h3 id=\"xmlDeSerializationOptions\">General notes on XML saving/loading in EMF</h3>\r\nWhen loading/saving model instance from/to a XML you will likely want to pass some of the following options to the save or <a href=\"http://www.cise.ufl.edu/mirrors/eclipse/modeling/emf/emf/javadoc/2.2.5/org/eclipse/emf/ecore/resource/Resource.html#load(java.io.InputStream, java.util.Map)\">load method</a>s:<br><br><pre><code>\r\nMap&lt;String, Object&gt; options = new HashMap&lt;String, Object&gt;();\r\noptions.put(XMLResource.OPTION_EXTENDED_META_DATA, Boolean.TRUE);\r\n// options.put(XMLResource.OPTION_RECORD_UNKNOWN_FEATURE, Boolean.TRUE);\r\noptions.put(XMLResource.OPTION_ENCODING, &quot;UTF-8&quot;);\r\n</code></pre>\r\n<ol>\r\n\t<li> OPTION_EXTENDED_META_DATA - create nested elements rather than attributes; I'm not sure whether it has any effect when loading</li>\r\n\t<li>OPTION_RECORD_UNKNOWN_FEATURE - when loading and an unknown element is encountered (see #2), do not throw the \"unknown feature\" exception but simply skip it</li>\r\n\t<li>OPTION_ENCODING - the encoding of the generated XML, default is ASCII; not sure what it does when loading</li>\r\n</ol>\r\n<h2>Environment</h2>\r\nEMF version: 2.2.1\r\n<h2>Summary</h2>\r\nEMF needs to map the root element of an XML being loaded to a registered EPacakge by matching their namespaces. In the XML, the namespace may be declared with a prefix or it may be the default namespace - in which case EMF must be informed that the nested elements are qualified too - or, finally, there may be no namespace information, in which case you need to register the \"default EPackage\" to be used under the null namespace URI.<br><br>The documentation and <a href=\"http://www.cise.ufl.edu/mirrors/eclipse/modeling/emf/emf/javadoc/2.2.5/\">JavaDoc</a> of EMF 2.2 is not very good but fortunately you can find most answers in the Eclipse and EclipseZone forums.<br><br>In the next post I'll describe how to create a dynamic EMF model based on XSD schemas and how to use it to load model instances from XML either into the standard EObjects or into EMF SDO implementation's EDataObjects.",
  "excerpt": ""
 },
 {
  "title": "Creating dynamic EMF model from XSDs and loading its instances from XML as SDOs",
  "published": "2011-01-03 16:32:07",
  "postType": "post",
  "slug": "/2011/01/03/creating-dynamic-emf-model-from-xsds-and-loading-its-instances-from-xml-as-sdos/",
  "status": "publish",
  "tags": [
   "eclipse",
   "EMF",
   "java",
   "model",
   "sdo",
   "xml",
   "XSD"
  ],
  "categories": [
   "Languages"
  ],
  "content": "This post describes how to read a dynamic EMF model from a set of XML schema files (XSDs) and how to use that model to transform XMLs to SDO DataObjects or EMF EObjects, all this in a stand-alone environment.<!--more--><strong></strong><br><br><strong>A little EMF reminder</strong>: With EMF you first declare a model, for example based on UML or XSDs (check my previous post for a <a href=\"/2011/01/03/emf-reading-a-model-from-xml-how-to-correctly-delcare-a-namespace-variants/#emfintro\">general, brief EMF introduction</a>). The model may be either static, in which case a Java class is generated for each model EClass with normal getters and setters, or it may be dynamic, which doesn't require any code generation and attributes are accessible only via the generic eGet, eSet methods. You can then create, load and save instances of the model, for example from/to XML.<br><br>To get from an XSD to XML transformed into a runtime E[Data]Object you need to:\r\n<ol>\r\n\t<li>Load the model elements defined in the XSDs into EPackages</li>\r\n\t<li>Register the loaded packages either in the global package registry or with the package registry of ResourceSet to be used for loading XMLs</li>\r\n\t<li>Tell EMF what objects to produce for the model (EMF EObjects or SDO EDataObjects)</li>\r\n\t<li>Load a model instance XML</li>\r\n</ol>\r\n<h2>Why to bother?</h2>\r\nYou may wonder why to do such a complicated thing like this. Well, for us the answer is simple - we want to reuse some old code, which uses SDO DataObjects, and it needs to be exposed via webservices. The simplest way to achieve that without adding other dependencies such as Apache Tuscany or Websphere SCA fix pack is this. We're running it on Websphere and thus EMF 2.2.1 is at our disposal. But there are certainly other cases where at least part of this approach may be useful.<br><br>You may also ask why to use a dynamic model, which is less efficient than a static one (though EMF reflection access is still faster than native Java one) and certainly much less readable and easy to use with its strange <a href=\"http://www.cise.ufl.edu/mirrors/eclipse/modeling/emf/emf/javadoc/2.2.5/org/eclipse/emf/ecore/EObject.html#eSet(org.eclipse.emf.ecore.EStructuralFeature, java.lang.Object)\">eSet</a>(EStructuralFeature feature, Object newValue). Well, the reason is flexibility - if your model changes then you only need to update your XSDs (which could be downloaded from somewhere or stored in a database). You don't need to regenerate any classes and redeploy your application. If you know the bureaucracy of large companies, you understand it can save you weeks or even months. Of course everything is a question of pros and cons.\r\n<h2>Load the model elements defined in the XSDs into EPackages</h2>\r\nFirst of all you need to create a dynamic EMF model from the XSDs, which is done with the help of an <a href=\"http://download.eclipse.org/modeling/mdt/xsd/javadoc/2.3.0/org/eclipse/xsd/ecore/XSDEcoreBuilder.html\">XSDEcoreBuilder</a>:<br><br><pre><code>\r\nimport org.eclipse.xsd.ecore.XSDEcoreBuilder;\r\nimport org.eclipse.emf.ecore.EPackage;\r\n...\r\npublic class EmfSdoModel {\r\n\t...\r\n\tprivate ResourceSet loadedModelResources = null;<br><br>\t/** Load EMF/SDO model from XSDs and set the this.loadedModelResources ResourceSet with the EPackages found. */\r\n\tpublic void initModelFromXsd() {\r\n\t\tfinal Collection&amp;amp;lt;Object&amp;amp;gt; loadedPackagesEtc = new XSDEcoreBuilder().generate(getSchemaUris());<br><br>\t    final Collection&amp;amp;lt;EPackage&amp;amp;gt; eCorePackages = new LinkedList&amp;amp;lt;EPackage&amp;amp;gt;();\r\n\t    for (Object loadedObject : loadedPackagesEtc) {\r\n\t\t\tif (loadedObject instanceof EPackage) {\r\n\t\t\t\teCorePackages.add((EPackage) loadedObject);\r\n\t\t\t} else {\r\n\t\t\t\tfinal String typeInfo = (loadedObject == null)?\r\n\t\t\t\t\t\t&amp;amp;quot;N/A&amp;amp;quot; : loadedObject.getClass().getName();\r\n\t\t\t\tLOG.info(&amp;amp;quot;initModelFromXsd: A non-EPackage in the input: &amp;amp;quot; + typeInfo);\r\n\t\t\t}\r\n\t\t}\r\n\t    // TODO Fail if no packages found\r\n\t    this.loadedModelResources = registerDynamicPackages(eCorePackages);\r\n\t}\r\n\t...\r\n}\r\n</code></pre><br><br>If you're interested in loading XSDs from an InputStream, check the EMF FAQ <a href=\"http://wiki.eclipse.org/index.php/EMF-FAQ#How_can_I_load_a_XSDSchema_from_a_simple_Java_String_or_from_a_DOM_Tree.3F\">How can I load a XSDSchema from a simple Java String or from a DOM Tree?</a>.<br><br>Next the loaded EPackages must be registered with EMF under their namespace URIs so that it can find an appropriate package when parsing an XML (see my previous post regarding <a href=\"/2011/01/03/emf-reading-a-model-from-xml-how-to-correctly-delcare-a-namespace-variants/\">namespace declarations and EMF</a>). But let's first see how the XSDs to be loaded are referenced:<br><br><pre><code>\r\nimport org.eclipse.emf.common.util.URI;\r\n...\r\nprivate Collection&amp;amp;lt;URI&amp;amp;gt; getSchemaUris() {\r\n\tfinal Collection&amp;amp;lt;URI&amp;amp;gt; result = new LinkedList&amp;amp;lt;URI&amp;amp;gt;();\r\n\tfor (String schemaOnCp : this.schemasOnClasspath) {\r\n\t\tfinal URL xsdUrl = getClass().getResource(schemaOnCp); // fail if null\r\n\t\tresult.add(URI.createURI(\r\n\t\t\t\txsdUrl.toExternalForm()));\r\n\t}\r\n\treturn result;\r\n}\r\n</code></pre><br><br>The XSDs are located on the classpath (under WEB-INF/classes/) and their paths like \"/xsd/AbstractBridgeMessage.xsd\" are turned to absolute URLs and then to EMF URIs.\r\n<h3>Dealing with types defined in a WSDL</h3>\r\nIf you want to use EMF to create model instances based on a webservice message and some of the types - likely the \"container\" types for the request and response - are defined in an embedded xsd:schema in its WSDL file as below:<br><br><pre><code>\r\n&amp;amp;lt;?xml version=&amp;amp;quot;1.0&amp;amp;quot; encoding=&amp;amp;quot;UTF-8&amp;amp;quot;?&amp;amp;gt;\r\n&amp;amp;lt;wsdl:definitions ...&amp;amp;gt;\r\n\t&amp;amp;lt;wsdl:types&amp;amp;gt;\r\n\t\t&amp;amp;lt;xsd:schema targetNamespace=&amp;amp;quot;http://w3.ibm.com/xmlns/ibmww/hr/learning/lms/br/la&amp;amp;quot;\r\n\t\t\txmlns:bons1=&amp;amp;quot;http://w3.ibm.com/xmlns/ibmww/hr/learning/lms/br&amp;amp;quot;\r\n\t\t\txmlns:tns=&amp;amp;quot;http://w3.ibm.com/xmlns/ibmww/hr/learning/lms/br/la&amp;amp;quot;\r\n\t\t\txmlns:xsd=&amp;amp;quot;http://www.w3.org/2001/XMLSchema&amp;amp;quot;&amp;amp;gt;<br><br>\t\t\t&amp;amp;lt;xsd:import namespace=&amp;amp;quot;http://w3.ibm.com/xmlns/ibmww/hr/learning/lms/br&amp;amp;quot; schemaLocation=&amp;amp;quot;../xsd-includes/http.w3.ibm.com.xmlns.ibmww.hr.learning.lms.br.xsd&amp;amp;quot;/&amp;amp;gt;\r\n\t\t\t&amp;amp;lt;xsd:include schemaLocation=&amp;amp;quot;LearningActivityMessage.xsd&amp;amp;quot;/&amp;amp;gt;<br><br>\t\t\t&amp;amp;lt;xsd:element name=&amp;amp;quot;updateLearningActivity&amp;amp;quot;&amp;amp;gt;\r\n\t\t\t\t&amp;amp;lt;xsd:complexType&amp;amp;gt;\r\n\t\t\t\t\t&amp;amp;lt;xsd:sequence&amp;amp;gt;\r\n\t\t\t\t\t\t&amp;amp;lt;xsd:element name=&amp;amp;quot;learningActivityMsg&amp;amp;quot; nillable=&amp;amp;quot;true&amp;amp;quot; type=&amp;amp;quot;tns:LearningActivityMessage&amp;amp;quot;/&amp;amp;gt;\r\n\t\t\t\t\t&amp;amp;lt;/xsd:sequence&amp;amp;gt;\r\n\t\t\t\t&amp;amp;lt;/xsd:complexType&amp;amp;gt;\r\n\t\t\t&amp;amp;lt;/xsd:element&amp;amp;gt;\r\n\t\t\t&amp;amp;lt;xsd:element name=&amp;amp;quot;updateLearningActivityResponse&amp;amp;quot;&amp;amp;gt;\r\n\t\t\t\t&amp;amp;lt;xsd:complexType&amp;amp;gt;\r\n\t\t\t\t\t&amp;amp;lt;xsd:sequence&amp;amp;gt;\r\n\t\t\t\t\t\t&amp;amp;lt;xsd:element name=&amp;amp;quot;result&amp;amp;quot; nillable=&amp;amp;quot;true&amp;amp;quot; type=&amp;amp;quot;bons1:TransactionResponseMessage&amp;amp;quot;/&amp;amp;gt;\r\n\t\t\t\t\t&amp;amp;lt;/xsd:sequence&amp;amp;gt;\r\n\t\t\t\t&amp;amp;lt;/xsd:complexType&amp;amp;gt;\r\n\t\t\t&amp;amp;lt;/xsd:element&amp;amp;gt;<br><br>\t\t&amp;amp;lt;/xsd:schema&amp;amp;gt;\r\n\t&amp;amp;lt;/wsdl:types&amp;amp;gt;\r\n\t...\r\n&amp;amp;lt;/wsdl:definitions&amp;amp;gt;\r\n</code></pre><br><br>then one of the ways to let EMF know about them is to extract the schema manually into an XSD of its own and to declare types for the elements (the only change is the replacement of an xsd:element by its nested xsd:complexType while preserving the name):<br><br><pre><code>\r\n&amp;amp;lt;?xml version=&amp;amp;quot;1.0&amp;amp;quot; encoding=&amp;amp;quot;UTF-8&amp;amp;quot;?&amp;amp;gt;\r\n&amp;amp;lt;xsd:schema targetNamespace=&amp;amp;quot;http://w3.ibm.com/xmlns/ibmww/hr/learning/lms/br/la&amp;amp;quot;\r\n\txmlns:bons1=&amp;amp;quot;http://w3.ibm.com/xmlns/ibmww/hr/learning/lms/br&amp;amp;quot;\r\n\txmlns:tns=&amp;amp;quot;http://w3.ibm.com/xmlns/ibmww/hr/learning/lms/br/la&amp;amp;quot;\r\n\txmlns:xsd=&amp;amp;quot;http://www.w3.org/2001/XMLSchema&amp;amp;quot;&amp;amp;gt;<br><br>\t&amp;amp;lt;xsd:import namespace=&amp;amp;quot;http://w3.ibm.com/xmlns/ibmww/hr/learning/lms/br&amp;amp;quot;\r\n\t\tschemaLocation=&amp;amp;quot;../xsd-includes/http.w3.ibm.com.xmlns.ibmww.hr.learning.lms.br.xsd&amp;amp;quot; /&amp;amp;gt;\r\n\t&amp;amp;lt;xsd:include schemaLocation=&amp;amp;quot;LearningActivityMessage.xsd&amp;amp;quot; /&amp;amp;gt;<br><br>\t&amp;amp;lt;!-- Originally xsd.elements turned to xsd:complexType nam --&amp;amp;gt;\r\n\t&amp;amp;lt;xsd:complexType name=&amp;amp;quot;updateLearningActivity&amp;amp;quot;&amp;amp;gt;\r\n\t\t&amp;amp;lt;xsd:sequence&amp;amp;gt;\r\n\t\t\t&amp;amp;lt;xsd:element name=&amp;amp;quot;learningActivityMsg&amp;amp;quot; nillable=&amp;amp;quot;true&amp;amp;quot;\r\n\t\t\t\ttype=&amp;amp;quot;tns:LearningActivityMessage&amp;amp;quot; /&amp;amp;gt;\r\n\t\t&amp;amp;lt;/xsd:sequence&amp;amp;gt;\r\n\t&amp;amp;lt;/xsd:complexType&amp;amp;gt;<br><br>\t&amp;amp;lt;xsd:complexType name=&amp;amp;quot;updateLearningActivityResponse&amp;amp;quot;&amp;amp;gt;\r\n\t\t&amp;amp;lt;xsd:sequence&amp;amp;gt;\r\n\t\t\t&amp;amp;lt;xsd:element name=&amp;amp;quot;result&amp;amp;quot; nillable=&amp;amp;quot;true&amp;amp;quot;\r\n\t\t\t\ttype=&amp;amp;quot;bons1:TransactionResponseMessage&amp;amp;quot; /&amp;amp;gt;\r\n\t\t&amp;amp;lt;/xsd:sequence&amp;amp;gt;\r\n\t&amp;amp;lt;/xsd:complexType&amp;amp;gt;\r\n&amp;amp;lt;/xsd:schema&amp;amp;gt;\r\n</code></pre><br><br><strong>Beware class name case</strong> If your root element's name begins with a lower case (as in \"updateLearningActivityResponse\") then the complexType you create for it must also start with a lower case for EMF to be able to match the corresponding EClass with the element. But EClass.getName() will return the name with the first letter upper-cased so if you try to find the EClass in the EPackage by yourself, don't forget to search for it with this change.\r\n<h2>Register the loaded packages with a package registry</h2>\r\nThe aforementioned method <em>registerDynamicPackages</em> creates a <a href=\"../2010/12/29/creating-jax-ws-webservice-using-service-data-objects-sdo-instead-of-jaxb-bound-pojos/\">ResourceSet</a> and registers the imported dynamic EMF model with it so that it can be used for loading its model instances from XML (remember that EMF must be able to find the EPackage corresponding to any XML element it encounters, which is done via lookup in the registry):<br><br><pre><code>\r\nprivate ResourceSet registerDynamicPackages(\r\n\t\tfinal Collection&amp;amp;lt;EPackage&amp;amp;gt; eCorePackages) {\r\n\tfinal ResourceSet resourceSet = new ResourceSetImpl();<br><br>\t// This is necessary when running standalone for no factories have been registered yet:\r\n\tresourceSet.getResourceFactoryRegistry().getExtensionToFactoryMap().put( &amp;amp;quot;xml&amp;amp;quot;,\r\n\t\t\tnew XMLResourceFactoryImpl());<br><br>\tfor (EPackage ePackage: eCorePackages) {\r\n\t\tresourceSet.getPackageRegistry().put(ePackage.getNsURI(), ePackage);\r\n\t\t// or register globally: EPackage.Registry.INSTANCE.put(ePackage.getNsURI(), ePackage);<br><br>\t\t// Create SDO's EDataObjects or EMF's EObjects or st. else?\r\n\t\tePackage.setEFactoryInstance(createModelObjectFactory());\r\n\t}\r\n\treturn resourceSet;\r\n}\r\n</code></pre><br><br>The method <em>createModelObjectFactory</em>() is described in the next section.<br><br>Important: If the input XML has no namespace declared on the root element we would need to register the package to be used for parsing the XML  (also) as default for the null namespace, see my previous post about <a href=\"/2011/01/03/emf-reading-a-model-from-xml-how-to-correctly-delcare-a-namespace-variants/\">EMF and namespace declaration in input XMLs</a>.\r\n<h2>Tell EMF what objects to produce for the model</h2>\r\nBy default EMF 2.2 creates <a href=\"http://www.cise.ufl.edu/mirrors/eclipse/modeling/emf/emf/javadoc/2.2.5/org/eclipse/emf/ecore/EObject.html\">EObjects</a> when importing a model instance but we can force it to produce for example EMF SDO's <a title=\"Visit page outside WikiCentral\" rel=\"nofollow\" href=\"http://publib.boulder.ibm.com/infocenter/iadthelp/v7r0/index.jsp?topic=/org.eclipse.emf.ecore.sdo.doc/references/javadoc/commonj/sdo/DataObject.html\">commonj.sdo.DataObject</a> implementation, in particular the <a href=\"http://publib.boulder.ibm.com/infocenter/iadthelp/v7r0/index.jsp?topic=/org.eclipse.emf.ecore.sdo.doc/references/javadoc/org/eclipse/emf/ecore/sdo/impl/DynamicEDataObjectImpl.html\">DynamicEDataObjectImpl</a>, by setting a factory on each EPackage:<br><br><pre><code>\r\nimport org.eclipse.emf.ecore.sdo.impl.DynamicEDataObjectImpl;\r\n...\r\nprivate ResourceSet registerDynamicPackages(final Collection&amp;amp;lt;EPackage&amp;amp;gt; c) {\r\n   ...\r\n      ePackage.setEFactoryInstance(createModelObjectFactory());\r\n   ...\r\n}<br><br>private FactoryImpl createModelObjectFactory() {\r\n   return new DynamicEDataObjectImpl.FactoryImpl();\r\n}\r\n</code></pre>\r\n<h2>Load a model instance XML</h2>\r\nFinally, when we've imported the model and prepared the ResourceSet for loading its instances from XML, we can do so:<br><br><pre><code>\r\npublic DataObject loadFromXml(final InputStream xmlStream) throws IOException {\r\n\tfinal Resource resource = loadedModelResources.createResource(\r\n\t\t\tURI.createURI(&amp;amp;quot;inputStream://dummyUriWithValidSuffix.xml&amp;amp;quot;)); // fake URI<br><br>\tresource.load(xmlStream, createXmlResourceDeSerializationOptions());\r\n\t// May throw org.eclipse.emf.ecore.resource.Resource$IOWrappedException: Class 'myRootElement' not found.\r\n\t// &amp;amp;lt;= ecore.xmi.ClassNotFoundException: Class 'myRootElement' not found.\r\n\t// if no EClass found for the root XML element given its name and namespace<br><br>\tLOG.info(&amp;amp;quot;Resource loaded:&amp;amp;quot; + resource + &amp;amp;quot;, contents:&amp;amp;quot; + resource.getContents());\r\n\t// =&amp;amp;gt; [DynamicEObjectImpl (eClass: EClassImpl(name: myRootElement) (instanceClassName: null) (abstract: false, interface: false))]<br><br>\tfinal EDataObject loadedEObject = (EDataObject) resource.getContents().get(0);\r\n\treturn loadedEObject;\r\n}\r\n</code></pre><br><br>Notice that to load the XML from a stream we need to make a fake URI with an extension mapped to the desired resource factory (.xml in this case) and pass in an InputStream (<a href=\"http://www.eclipsezone.com/eclipse/forums/t55585.html\">source</a>).<br><br>The method <em>createXmlResourceDeSerializationOptions()</em> only sets the options OPTION_EXTENDED_META_DATA and OPTION_ENCODING <a href=\"/2011/01/03/emf-reading-a-model-from-xml-how-to-correctly-delcare-a-namespace-variants/#xmlDeSerializationOptions\">as described in my previous post</a> under General notes on XML saving/loading in EMF.\r\n<h2>Putting it all together</h2>\r\nFinally we will create a webservice that transform its XML input into an SDO object. I've left out the unrelated lines and methods, you can find them in my previous post <a href=\"/2010/12/29/creating-jax-ws-webservice-using-service-data-objects-sdo-instead-of-jaxb-bound-pojos/\">Creating JAX-WS webservice using Service Data Objects (SDO) instead of JAXB-bound POJOs</a>. The relevant code is:<br><br><pre><code>\r\n@javax.xml.ws.ServiceMode(value=javax.xml.ws.Service.Mode.PAYLOAD)\r\n@javax.xml.ws.WebServiceProvider(...)\r\npublic class MyRawXmlServiceImpl implements Provider&amp;amp;lt;Source&amp;amp;gt; {\r\n\t...\r\n\tprivate EmfSdoModel emfSdoModel;<br><br>\t@javax.annotation.PostConstruct\r\n\tpublic void initializeEmfModel() {\r\n\t\temfSdoModel = new EmfSdoModel();\r\n\t\temfSdoModel.initModelFromXsd();\r\n\t}<br><br>\tpublic Source invoke(final Source request) {\r\n\t\tfinal String requestXml = convertRequestToXml(request);<br><br>\t\tDataObject requestSDO;\r\n\t\ttry {\r\n\t\t\tfinal InputStream xmlStream = new ByteArrayInputStream(\r\n\t\t\t\trequestXml.getBytes(&amp;amp;quot;UTF-8&amp;amp;quot;));\r\n\t\t\trequestSDO = emfSdoModel.loadFromXml(xmlStream);\r\n\t\t} catch (IOException e) {\r\n\t\t\tthrow new RuntimeException(&amp;amp;quot;XML-&amp;amp;gt;SDO covnersion failed: &amp;amp;quot; + e, e);\r\n\t\t}<br><br>\t\tfinal DataObject responseSDO = sdoInstance_.updateLearningActivity(requestSDO);\r\n\t\treturn convertResponse(responseSDO);\r\n\t}\r\n\t...\r\n}\r\n</code></pre><br><br>Basically we just load the model at startup and then use it to parse XMLs.<br><br>When running this code under Websphere Application Server 7.0 you need no additional libraries. When running in another environment, <a href=\"http://wiki.eclipse.org/index.php/EMF-FAQ#I_want_to_use_EMF.2C_SDO.2C_or_XSD_in_my_standalone_project.2C_or_include_only_a_working_subset_of_the_code._What_libraries_.28jar_files.29_do_I_need_in_my_CLASSPATH.3F\">check the libs needed in EMF FAQ</a>.\r\n<h2>Summary</h2>\r\nI've demonstrated how to create a dynamic EMF model based on XSDs in a web application and how to use that model to parse XMLs into SDO DataObjects or EMF EObjects and also how to integrate that with a JAX-WS webservice.\r\n<h2>Resources</h2>\r\n<ul>\r\n\t<li>Article  <a href=\"http://www.ibm.com/developerworks/library/os-eclipse-dynamicemf/\">Build metamodels with dynamic EMF - Create dynamic Ecore-based models on demand without generating Java implementation classes</a> (2007) - Create EClasses, add EAttributes as EStructuralFeatures to them, create an EPackage and add the classes there)</li>\r\n\t<li><a href=\"http://www.eclipsezone.com/eclipse/forums/t76087.html\">How to create a dynamic DataObject with an e-enabled map attribute</a>, from an EclipseZone forum - I haven't used it but somebody may need it</li>\r\n\t<li><a href=\"http://www.ibm.com/developerworks/webservices/library/j-sdo/#N1031B\">How to create a dynamic SDO model</a> from the dW's article<a href=\"http://www.ibm.com/developerworks/webservices/library/j-sdo/\">Introduction to Service Data Objects </a></li>\r\n\t<li>EMF wiki: <a href=\"http://wiki.eclipse.org/Generating_Dynamic_Ecore_from_XML_Schema\">EMF/Generating Dynamic Ecore from XML Schema</a></li>\r\n\t<li>My related blog posts:\r\n<ul>\r\n\t<li><a title=\"Permanent link to EMF: Reading a model from XML – how to correctly declare its namespace – variants\" rel=\"bookmark\" href=\"../2011/01/03/emf-reading-a-model-from-xml-how-to-correctly-delcare-a-namespace-variants/\">EMF: Reading a model from XML – how to correctly declare its namespace – variants</a></li>\r\n\t<li><a title=\"Permanent link to Creating JAX-WS webservice using Service Data Objects (SDO) instead of JAXB-bound POJOs\" rel=\"bookmark\" href=\"../2010/12/29/creating-jax-ws-webservice-using-service-data-objects-sdo-instead-of-jaxb-bound-pojos/\">Creating JAX-WS webservice using Service Data Objects (SDO) instead of JAXB-bound POJOs</a></li>\r\n</ul>\r\n</li>\r\n</ul>",
  "excerpt": ""
 },
 {
  "title": "EMF tips: Accessing model meta data, serializing into element/attribute",
  "published": "2011-01-11 13:34:08",
  "postType": "post",
  "slug": "/2011/01/11/emf-tips-accessing-model-meta-data-serializing-into-elementattribute/",
  "status": "publish",
  "tags": [
   "EMF",
   "java"
  ],
  "categories": [
   "eclipse",
   "Languages"
  ],
  "content": "Two tips for the Eclipse Modeling Framework (EMF) 2.2.1:\r\n<ol>\r\n\t<li>Accessing model's meta model - accessing EClass/attribute by name - so that you can set an attribute when you only know its name and haven't its EAttribute</li>\r\n\t<li>How to force EMF to serialize an object as an XML element instead of an XML attribute</li>\r\n</ol>\r\n<!--more-->Excuse my rather liberal and slightly confusing use of the terms model, model instance and meta model.\r\n<h2>Tip 1: Accessing model's meta model - accessing EClass/attribute by name</h2>\r\nNormally you cannot do any operation on a dynamic EMF model instance - such as instantiating an EObject or settings its property via eSet - without the corresponding meta model objects such as EClass and EAttribute. But there is a solution - you can build an <a href=\"http://download.eclipse.org/modeling/emf/emf/javadoc/2.4.3/org/eclipse/emf/ecore/util/ExtendedMetaData.html\">ExtendedMetaData</a> instance and use its methods to find the meta model objects based on search criteria such as element name and namespace.\r\n<h3>Examples</h3>\r\n<h4>Create ExtendedMetaData from a model</h4>\r\nOne way to build a meta data instance is to instantiate <a href=\"http://download.eclipse.org/modeling/emf/emf/javadoc/2.4.3/org/eclipse/emf/ecore/util/BasicExtendedMetaData.html\">BasicExtendedMetaData</a> based on a Registry, containing all registered packages. This is usually available either via ResourceSet.<a href=\"http://download.eclipse.org/modeling/emf/emf/javadoc/2.4.3/org/eclipse/emf/ecore/resource/ResourceSet.html#getPackageRegistry%28%29\">getPackageRegistry</a>() or globally, via EPackage.Registry.<a href=\"http://download.eclipse.org/modeling/emf/emf/javadoc/2.4.3/org/eclipse/emf/ecore/EPackage.Registry.html#INSTANCE\">INSTANCE</a>.<br><br><pre><code>\r\nimport org.eclipse.emf.ecore.util.*;\r\n...\r\nExtendedMetaData modelMetaData = new BasicExtendedMetaData(myResourceSet.getPackageRegistry());\r\n</code></pre>\r\n<h4>Get EClass for a namespace and name</h4>\r\nProvided that your model contains an element with the name Book and namespace http://example.com/book:<br><br><pre><code>\r\nEClass bookEClass = (EClass) modelMetaData.getType(&quot;http://example.com/book&quot;, &quot;Book&quot;);\r\n</code></pre>\r\n<h4>Get EClass' attribute by name</h4>\r\nBeware: Some properties (such as those described by named complex types) are not represented by an <a href=\"http://download.eclipse.org/modeling/emf/emf/javadoc/2.4.3/org/eclipse/emf/ecore/EAttribute.html\">EAttribute</a> but an <a href=\"http://download.eclipse.org/modeling/emf/emf/javadoc/2.4.3/org/eclipse/emf/ecore/EReference.html\">EReference</a> (both extend <a href=\"http://download.eclipse.org/modeling/emf/emf/javadoc/2.4.3/org/eclipse/emf/ecore/EStructuralFeature.html\">EStructuralFeature</a>) and are accessible as the EClass' elements, not attributes, even though from developer's points of view they're attributes of the owning class.<br><br>Let's suppose that the book has the attribute name:<br><br><pre><code>\r\nEStructuralFeature nameAttr = modelMetaData.getElement(bookEClass, null, &quot;name&quot;);</code></pre><br><br>The namespace is null because normally attributes/nested elements are not classified with a schema.<br><br>Here is how you would print the name and namespace URI of an attribute/element:<br><br><pre><code>\r\nSystem.out.println(&quot;attr: &quot; + modelMetaData.getNamespace(nameAttr) + &quot;:&quot; + nameAttr.getName());\r\n// prints &quot;null:name&quot;\r\n</code></pre>\r\n<h2>Tip 2: How to force EMF to serialize an object as an XML element instead of an XML attribute</h2>\r\nNormally EMF stores simple Java properties as attributes of the XML element representing the owning class:<br><br><pre><code>\r\n&lt;b:Book b:xmlns=&quot;...&quot; name=&quot;The Book of Songs&quot; /&gt;\r\n</code></pre><br><br>but you might prefer to have it rather as a nested element:<br><br><pre><code>&lt;b:Book b:xmlns=&quot;...&quot;&gt;\r\n   &lt;name&gt;The Book of Songs&lt;/name&gt;\r\n&lt;/b:Book&gt;</code></pre><br><br>To achieve that:\r\n<ol>\r\n\t<li>Enable the save option OPTION_EXTENDED_META_DATA (so that extended meta data such as annotations and an XML map aren't ignored)</li>\r\n\t<li>Tell EMF that you want this property to be stored as an element\r\n<ol>\r\n\t<li>By attaching an eAnnotation to it (not shown)</li>\r\n\t<li>By supplying a XML Map with this information upon save</li>\r\n</ol>\r\n</li>\r\n</ol>\r\nTo enable the extended metadata:<br><br><pre><code>\r\nMap&lt;String, Object&gt; saveOptions = new HashMap&lt;String, Object&gt;();\r\nsaveOptions.put(XMLResource.OPTION_EXTENDED_META_DATA, Boolean.TRUE);\r\n</code></pre><br><br>According to some documentation the value should be an implementation of  ExtendedMetaData, according to others Boolean.TRUE is the correct choice - I use the latter for it's easier and works for me.<br><br>To tell EMF to write a property as an element when serailizing to XML:<br><br><pre><code>\r\nimport org.eclipse.emf.ecore.xmi.impl.*;\r\n...\r\nEAttribute bookNameEAttribute = ...; // retrieved e.g. from meta data, see Tip 1\r\nXMLMapImpl map = new XMLMapImpl();\r\nXMLInfoImpl x = new XMLInfoImpl();\r\nx.setXMLRepresentation(XMLInfoImpl.ELEMENT);\r\nmap.add(bookNameEAttribute, x);\r\nsaveOptions.put(XMLResource.OPTION_XML_MAP, map);\r\n</code></pre><br><br>The <a href=\"http://download.eclipse.org/modeling/emf/emf/javadoc/2.4.3/org/eclipse/emf/ecore/xmi/impl/XMLInfoImpl.html\">XMLInfoImpl</a> enables you to customize the namespace, name and representation of the element.<br><br>When saving you then just supply the save options:<br><br><pre><code>\r\nEObject target = ...;\r\norg.eclipse.emf.ecore.resource.Resource outResource = ...;\r\noutResource.getContents().add(target);\r\noutResource.save(saveOptions);\r\n</code></pre><br><br><strong>Reference</strong>: the Redbook <a href=\"http://www.redbooks.ibm.com/abstracts/sg246302.html\">Eclipse Development using the Graphical Editing Framework and the Eclipse Modeling Framework</a>, page 74, section 2.3.4",
  "excerpt": ""
 },
 {
  "title": "Most interesting links of January",
  "published": "2011-01-31 21:41:44",
  "postType": "post",
  "slug": "/2011/01/31/most-interesting-links-of-january/",
  "status": "publish",
  "tags": [
   "java",
   "tdd",
   "Testing"
  ],
  "categories": [
   "Languages",
   "Testing",
   "Top links of month"
  ],
  "content": "I'm moving to Norway and have thus little time for reading but still I've stumbled upon something really interesting.\r\n<ul>\r\n\t<li>Bob C. Martin (the Clean Code guy): <a href=\"http://cleancoder.posterous.com/the-transformation-priority-premise\">The Transformation Priority Premise</a> - with TDD the code goes through a series of transformations (similar to refactorings but they change the behaviour) that \"move the code from a <em>specific </em>form to a more <em>generic</em> form\" (from \"return 0;\" to \"return myFunc();\"). \"It also appears that these transformations have a preferred order based on complexity.\" (nothing =&gt; simple code with null; null =&gt; constant; ...). \"<em>It is the premise of this blog that if tests are chosen and implemented in this preferred order of transformations, then TDD impasses will be reduced or eliminated.</em>\"\r\nAlso the article explains nicely why the practice of writting simple, wrong (i.e. too specific) code is good.&nbsp;\r\n<ul>\r\n\t<li>Uncle Bob's TDD excercises (katas): <a href=\"https://docs.google.com/viewer?url=http://butunclebob.com/files/downloads/Prime%2520Factors%2520Kata.ppt\">Prime Factors kata</a> (<a href=\"http://butunclebob.com/files/downloads/Prime%2520Factors%2520Kata.ppt\">as .ppt</a>), <a href=\"https://docs.google.com/viewer?url=http://butunclebob.com/files/downloads/Bowling%2520Game%2520Kata.ppt\">The Bowling Game Kata</a> (<a href=\"http://butunclebob.com/files/downloads/Bowling%2520Game%2520Kata.ppt\">as .ppt</a>)</li>\r\n</ul>\r\n</li>\r\n\t<li><a href=\"http://www.javacodegeeks.com/2011/01/10-tips-proper-application-logging.html\">10 Tips for Proper Application Logging</a> - should be rather called 10 best practices for (enterprise Java) logging</li>\r\n\t<li><a href=\"http://www.agileproductdesign.com/blog/2009/kanban_over_simplified.html\">Kanban Development Oversimplified</a> - finally an explanation of Kanban for SW development I could understand, also thanks to the comparison with other agile approaches</li>\r\n</ul>",
  "excerpt": ""
 },
 {
  "title": "Using Ivy with pom.xml",
  "published": "2011-01-26 11:40:57",
  "postType": "post",
  "slug": "/2011/01/26/using-ivy-with-pom-xml/",
  "status": "publish",
  "tags": [
   "ivy",
   "Maven"
  ],
  "categories": [
   "Tools"
  ],
  "content": "It's possible to use Apache Ivy with dependencies defined in pom.xml instead of its native ivy.xml but you will need to apply some workarounds and you're loosing access to some functionality that you might (or might not) need.<br><br>The problem is that in a POM you can provide only a subset of settings available in ivy.xml and that Ivy understands only a subset of POM's syntax.<!--more--><br><br>The information here is based mostly on Ivy 2.1.0.<br><br>Disclaimer: I'm no Ivy expert and there are certainly better ways to achieve what I did. Also newer versions of Ivy may be better.\r\n<h2>Limitations of pom.xml usage</h2>\r\nIvy understands only a subset of POM's syntax: dependencies, dependencies of plugins or st. like that, parent module.<br><br>To learn exactly what parts of a pom.xml are processed by Ivy check the two main classes responsible for that (version 2.1.0): <a href=\"http://jarvana.com/jarvana/view/org/apache/ivy/ivy/2.1.0/ivy-2.1.0-sources.jar%21/org/apache/ivy/plugins/parser/m2/PomModuleDescriptorParser.java?format=ok\">PomModuleDescriptorParser.java</a> and <a href=\"http://jarvana.com/jarvana/view/org/apache/ivy/ivy/2.1.0/ivy-2.1.0-sources.jar%21/org/apache/ivy/plugins/parser/m2/PomReader.java?format=ok\">PomReader.java</a>.\r\n<h2>Issues &amp; solutions</h2>\r\n<h3>Referring to a parent POM</h3>\r\nIn general you can user a parent POM, for example do declare properties that you then use e.g. in dependecy declarations, but there are few issues with parent POMs:\r\n<ol>\r\n\t<li>Ivy ignores the relativePath element</li>\r\n\t<li>Ivy ignores the packaging=pom on the parent module</li>\r\n</ol>\r\n<h4>Ivy ignores the relativePath element</h4>\r\nYou can specify a parent project in your POM. Maven allows you to provide absolute or relative system path to the pom like this:<br><br><pre><code>\r\n&lt;parent&gt;\r\n\t&lt;groupId&gt;com.ibm.education&lt;/groupId&gt;\r\n\t&lt;artifactId&gt;lms-root-pom&lt;/artifactId&gt;\r\n\t&lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;\r\n\t&lt;relativePath&gt;../lms.build/lms-root-pom/pom.xml&lt;/relativePath&gt;\r\n&lt;/parent&gt;\r\n</code></pre><br><br>But Ivy will ignore the relativePath and will only try to find it via a resolver (which might be OK for you but wasn't for me).\r\n<h5>Workaround</h5>\r\n<ol>\r\n\t<li>Declare a special local file-system resolver for the parent pom</li>\r\n\t<li>Configure modules in ivysettings so that this resolver is used only for the parent pom module</li>\r\n</ol>\r\n<strong>The special FS resolver for the parent pom:</strong><br><br><pre><code>\r\n&lt;ivysettings&gt;\r\n  &lt;resolvers&gt;\r\n    &lt;filesystem name=&quot;local-lms.build&quot; force=&quot;true&quot; descriptor=&quot;required&quot;&gt;\r\n      &lt;ivy pattern=&quot;${ivy.settings.dir}/[module]/pom.xml&quot; /&gt;\r\n      &lt;artifact pattern=&quot;${ivy.settings.dir}/[module]/emptyJarToSatisfyIvy.jar&quot; /&gt;\r\n    &lt;/filesystem&gt;\r\n   ...\r\n  &lt;/resolvers&gt;\r\n&lt;/ivysettings&gt;\r\n</code></pre><br><br>(ivy.settings.dir is automatically set by Ivy based on the file attribute of the ivy:settings task; just make sure to use file= and not url=)<br><br><strong>Module declaration:</strong><br><br><pre><code>\r\n&lt;ivysettings&gt;\r\n\t...\r\n\t&lt;modules&gt;\r\n\t\t&lt;module organisation=&quot;com.ibm.education&quot; name=&quot;lms-root-pom&quot; resolver=&quot;local-lms.build&quot;/&gt;\r\n\t\t...\r\n\t&lt;/modules&gt;\r\n&lt;/ivysettings&gt;\r\n</code></pre><br><br><strong>File structure:</strong>\r\n<ul>\r\n\t<li>lms.build\r\n<ul>\r\n\t<li>lms-root-pom\r\n<ul>\r\n\t<li>pom.xml</li>\r\n\t<li>emptyJarToSatisfyIvy.jar (see below)</li>\r\n</ul>\r\n</li>\r\n</ul>\r\n</li>\r\n\t<li>your-dependant-module\r\n<ul>\r\n\t<li>pom.xml</li>\r\n</ul>\r\n</li>\r\n</ul>\r\n<h3>Ivy ignores the packaging=pom on the parent module</h3>\r\nIvy ignores the packaging=pom on the parent module and will always try to find a .jar for it, thus wasting precious time. The workaround is to create a fake, empty .jar, for example via echo \"\" &gt; emptyJarToSatisfyIvy.jar. You can see it above in the lms-root-pom file structure and resolver's configuration.\r\n<h3>Publishing pom.xml to a Maven repository and respecting the dependencies of your own modules</h3>\r\nI suppose you want to publish your own modules to a Maven repository manager such as Nexus or Artifactory. And you also want to publish module's pom.xml with its dependencies and when you have another module depending on this one, you want Ivy to be aware of the (transitive) dependencies from the pom.\r\n<h4>Publishing the pom.xml</h4>\r\nNormally Ivy publishes only the single artifact &lt;module name&gt;.&lt;packaging&gt;. If you used ivy.xml you could declare additional artifacts in its &lt;publications&gt;/&lt;artifact&gt; however pom.xml gives you no such possibility.<br><br>Fortunately, <em>since Ivy 2.2.0</em>, it's possible to declare the additional artifacts with the <a href=\"http://ant.apache.org/ivy/history/2.2.0/ivyfile/artifact.html\">&lt;artifact&gt;</a> element also under the Ant <a href=\"http://ant.apache.org/ivy/history/2.2.0/use/publish.html\">ivy:publish</a> task:<br><br><pre><code>\r\n&lt;ivy:publish resolver=&quot;shared-snapshot&quot;\r\n\tpubrevision=&quot;${ivy.revision}&quot; forcedeliver=&quot;true&quot;\r\n\tstatus=&quot;integration&quot; overwrite=&quot;true&quot;&gt;<br><br>\t&lt;artifacts pattern=&quot;${artifactspattern}&quot; /&gt;\r\n\t&lt;artifacts pattern=&quot;pom.xml&quot; /&gt;<br><br>\t&lt;!-- Additional artifacts to publish (since Ivy 2.2.0): --&gt;\r\n\t&lt;artifact name=&quot;${ivy.module}&quot; ext=&quot;pom&quot; type=&quot;pom&quot; /&gt;\r\n&lt;/ivy:publish&gt;\r\n</code></pre><br><br>It's essential that the name of the POM artifact is &lt;artifactId&gt;-&lt;version&gt;.pom, otherwise it won't be recognized as the artifact's POM when retrieving it. It is achieved by using the Ivy-provided property ivy.module and ext=pom. The attributes of ivy:publish are mostly unimportant, I've them like this for this is used for publishing snapshots.\r\n<h4>Configuring Ivy to fetch the POM and respect the dependencies</h4>\r\nIvy will automatically respect dependencies in a POM but it must know that it should look for this file. To do that you must use the <em>ibiblio resolver to retrieve</em> artifacts from the repository. And, of course, there must be an &lt;artifactId&gt;-&lt;version&gt;.pom file next to the main .jar. But it doesn't support publishing (at least so I believe) and therefore you also need to declare an <em>URL resolver for publishing</em> of your artifacts:<br><br><pre><code>\r\n&lt;ivysettings&gt;\r\n    &lt;property name=&quot;upload.root.url&quot; value=&quot;http://e25ciwas020.toronto.ca.ibm.com:8081/nexus/content/repositories&quot; /&gt;\r\n    ...\r\n    &lt;resolvers&gt;\r\n        &lt;chain name=&quot;shared&quot;&gt;\r\n        \t&lt;ibiblio name=&quot;shared-snapshot-retrieval&quot; m2compatible=&quot;true&quot; root=&quot;${upload.root.url}/snapshots&quot; /&gt;<br><br>\t        &lt;url name=&quot;shared-snapshot&quot; m2compatible=&quot;true&quot;&gt;\r\n\t          &lt;artifact pattern=&quot;${upload.root.url}/snapshots/[organisation]/[module]/[revision]/[artifact]-[revision](-[classifier]).[ext]&quot; /&gt;\r\n\t        &lt;/url&gt;\r\n        &lt;/chain&gt;\r\n    &lt;/resolvers&gt;\r\n&lt;/ivysettings&gt;\r\n</code></pre><br><br>To check it, look into /.ivy2/cache// - there should be ivy-.xml<strong> </strong>.original, which is actually a renamed pom.xml and ivy-&lt;version&gt;.xml, generated from that.<br><br>Especially look there into ivydata-&lt;version&gt;.xml, it contains information about the artifact's metadata etc. In the ideal case it is similar to:<br><br><pre><code>\r\n#ivy cached data file for com.ibm.education#lms.ab.common;40.0.0-SNAPSHOT\r\n#Wed Jan 26 12:11:17 CET 2011\r\nartifact\\:lms.ab.common\\#jar\\#jar\\#-869122099.is-local=false\r\nartifact.resolver=shared-snapshot-retrieval\r\nartifact\\:lms.ab.common\\#pom.original\\#pom\\#783440563.location=http\\://e25ciwas020.toronto.ca.ibm.com\\:8081/nexus/content/repositories/snapshots/com/ibm/education/lms.ab.common/40.0.0-SNAPSHOT/lms.ab.common-40.0.0-SNAPSHOT.pom\r\nartifact\\:lms.ab.common\\#pom.original\\#pom\\#783440563.is-local=false\r\nartifact\\:lms.ab.common\\#jar\\#jar\\#-869122099.location=http\\://e25ciwas020.toronto.ca.ibm.com\\:8081/nexus/content/repositories/snapshots/com/ibm/education/lms.ab.common/40.0.0-SNAPSHOT/lms.ab.common-40.0.0-SNAPSHOT.jar\r\nresolver=shared-snapshot-retrieval\r\nartifact\\:ivy\\#ivy\\#xml\\#1489462886.is-local=false\r\nartifact\\:ivy\\#ivy\\#xml\\#1489462886.location=http\\://e25ciwas020.toronto.ca.ibm.com\\:8081/nexus/content/repositories/snapshots/com/ibm/education/lms.ab.common/40.0.0-SNAPSHOT/lms.ab.common-40.0.0-SNAPSHOT.pom\r\n</code></pre>\r\n<h3>Mapping of configurations (scopes)</h3>\r\nWhile Ivy let you define which dependencies should be fetched in which situation including the transitive one so that you can easily declare that a dependency's \"provided\" dependencies should be respected during compilation and testing, with pom.xml you lose the ability to declare these configuration mappings and you have to live with the defaults. This means for example that a dependency's dependencies with the scope=provided are always ignored. The solution is to use only the scope=compile for dependencies in your modules/artifacts that should be reused and manually filter out the dependencies you don't want to include in your binary (e.g. a .war).\r\n<h2>Conclusion</h2>\r\nIt's possible to use Ivy <em>2.2.0</em> with Maven POMs but you should carefully explore the limitations of this approach and check them against your requirements. Good luck!",
  "excerpt": ""
 },
 {
  "title": "Manually restoring raw partclone partition image to a VMWare",
  "published": "2011-02-06 15:06:34",
  "postType": "post",
  "slug": "/2011/02/06/manually-restoring-raw-partclone-partition-image-to-a-vmware/",
  "status": "publish",
  "tags": [
   "backup",
   "clonezilla",
   "partclone",
   "vmware"
  ],
  "categories": [
   "Tools"
  ],
  "content": "This post sums up how to manually restore a partition backup create by Clonezilla (using partclone) into a VMware virtual machine, which can be then either executed or its (virtual) disk mounted. The difficult points are \"manual\" and \"partition backup\" (would be much easier with a full disk backup). Normally I restore a backup by running Clonezilla from a virtual machine with sufficiently large virtual disk, but at times it isn't possible, e.g. because the Clonezilla kernel has a buggy USB driver which tends to disconnect at times (at least with my version &amp; flash disk).<!--more-->\r\n<h2>Problems with VMware</h2>\r\n<ol>\r\n\t<li>VMware can boot from a raw partition, but it must be a physical one, not its image stored in a file</li>\r\n\t<li>VMware doesn't support loop devices for accessing such a partition (or disk) image - that's because loop devices don't behave as true physical disk, i.e. are missing support for some commands that VMware uses (though sb. has implemented a patch for VMware to work around this)</li>\r\n\t<li>VMware can boot from an image of a raw disk, but it must be a full disk (including MBR, partition table), not just a partition</li>\r\n</ol>\r\n<!-- https://github.com/vasi/vmdk-raw-parts#readme sudo ./vmdk-raw-parts /dev/sda sda.vmdk =&gt; sda.vmdk/ containing: mbr            regen.sh       sda.vmdk.vmdk  - ls -l  block-size=512 sda1.ext4-ptcl-restored2.img =&gt; 550177992 -->\r\n<h2>Failed attempt: Use VirtualBox's support for partitions</h2>\r\nIn theory, Virtual Box could be used with few tricks to mount from a raw partition image (by configuring it to boot from the original true raw partition and then changing the device in the configuration to a loop device) but for me VB was very unreliable, managed to boot correctly only occasionally and when it did then the graphics was a bit strange, which prevented me from logging in to the backed-up OS. Anyway, for those who're interested, I'll record my steps here.<br><br>See <a href=\"http://www.virtualbox.org/manual/ch09.html#rawdisk\">http://www.virtualbox.org/manual/ch09.html#rawdisk</a><br><br>0. Mount the restored partition:<br><br><pre><code>sudo mount -t ext4 -o loop,nosuid,nodev /media/jholy1g/sda1.ext4-ptcl-restored.img /mnt</code></pre><br><br># in my case mounted to /dev/loop0 as revealed by running <em>mount</em>.<br><br>1. Create vbox image from a physical disk where the backed-up partition comes from (/dev/sda, partition #5 in my case):<br><br><pre><code>sudo VBoxManage internalcommands createrawvmdk -filename vbox-sda.vmdk -rawdisk /dev/sda -partitions 5 -relative</code></pre><br><br>2. In the generated vbox-sda.vmdk, replace the physical /dev/sda5 with /dev/loop0<br><br>3. Start virtualbox from the commandline where you're sure to have access to /dev/loop0<br><br>(adduser myname disk; newgrp disk; virtualbox)<br><br>4. Create new VirtualBox virt. machine with an existing hard drive image, i.e. the one created above\r\n<h2>Success: Restoration to a mounted vmware partition</h2>\r\nSee <a href=\"http://cromoteca.com/en/blog/mountflatvmwarediskimagesunderlinux/\">http://cromoteca.com/en/blog/mountflatvmwarediskimagesunderlinux/</a><br><br>Summary:\r\n<ol>\r\n\t<li>Create a pre-allocated (non-growing) vmware disk of a sufficient size</li>\r\n\t<li>Run a virtual machine with e.g. an Ubuntu live CD and the disk, create there a partitiona and set its boot flag</li>\r\n\t<li>Stop the vmware VM</li>\r\n\t<li>Mount the virtual vmdk disk as a loop device from the host system</li>\r\n\t<li>Mount the vmdk's first partition as a loop device (beware you need to use the correct offset here!)</li>\r\n\t<li>Use partclone to restore the (joined &amp; decompressed) backup to the partition's loop device</li>\r\n\t<li>Umount the partition</li>\r\n\t<li>Install GRUB into the virtual disk and configure it to boot the 1st partition (either from the host system, or, which may be easier, from within vmware)</li>\r\n\t<li>Run the virtual machine, booting from the thus prepared disk</li>\r\n</ol>\r\n<h3>Restoring to a virtual vmware disk's partition</h3>\r\nCreate a pre-allocated (non-growing) vmware disk of a sufficient size in the VMWare Player.<br><br>This part is mostly taken over from <a href=\"http://cromoteca.com/en/blog/mountflatvmwarediskimagesunderlinux/\">Mount Flat VMWare Disk Images Under Linux</a>.<br><br>Mount the virtual disk:<br><br><pre><code>sudo losetup /dev/loop0 /media/MyBook-Linux/vmware/Ubuntu-candyRestore/Ubuntu-candyRestore-0-flat.vmdk</code></pre><br><br>Find out where the first partition of the virtual disk starts for correct offset when mounting it:<br><br><pre><code>\r\n$ sudo fdisk -lu /dev/loop0<br><br>Disk /dev/loop0: 306.0 GB, 306016419840 bytes\r\n97 heads, 12 sectors/track, 513477 cylinders, total 597688320 sectors\r\nUnits = sectors of 1 * 512 = 512 bytes\r\nDisk identifier: 0xaa3590f4<br><br>Device Boot      Start         End      Blocks   Id  System\r\n/dev/loop0p1   *        2048   597688319   298843136   83  Linux\r\n</code></pre><br><br>=&gt; 2048 * 512 = 1048576 bytes<br><br>Mount the VMDK partition, using the computed offset (in bytes):<br><br><pre><code>sudo losetup -v -o 1048576 /dev/loop1 /dev/loop0</code></pre><br><br>Restore the (joined and uncompressed) partclone backup to the virtual partition:<br><br><pre><code>sudo partclone.restore -C -s /media/jholy1g/sda1.ext4-ptcl-img -o /dev/loop1</code></pre><br><br>To verify, mount the restored filesystem:<br><br><pre><code>sudo mount /dev/loop1 /tmp/mpoint</code></pre><br><br>Further verification: Run the VM with a live CD, try to manually mount the partition similarly as above (or check whether the OS recognizes it as a valid, mountable one) - if not then perhaps the offset wasn't right.\r\n<h3>Making the virtual disk bootable from the restored partition</h3>\r\nNow that we have restored our backup to a VMDK's partition, we need to make it possible for VMWare to boot from the partition. To achieve that, we would need to install a boot manager such as Grub to the virtual image and configure it to use the partition.<br><br>There is a related blog describing <a href=\"http://www.praggo.com/2010/09/building-custom-linux-os-part-2-working.html\">how to install grub to a raw disk image</a> and <a href=\"http://grulicueva.homelinux.net/~mdione/glob/posts/create-a-disk-image-with-a-booting-running-debian/\">another similar article</a>, which is quite similar to our need here.<br><br><strong>TBD</strong>: I clearly won't have an opportunity to try this in the forseeable future but I suppose the easiest way would be to run the virtual machine with the disk booting from a Linux live CD and <a href=\"http://ubuntuforums.org/showthread.php?t=1195275\">install Grub</a> there (perhaps via the <a href=\"https://launchpad.net/~danielrichter2007/+archive/grub-customizer\">Grub Customizer</a> GUI).<br><br>Installing Grub without vmware, from the host system (having the vmdk partition mounted as a loop device as described above), should be also pretty much possible.<br><br>Sorry for leaving this unfinished. If I ever have time to come back to this, I'll update the post.\r\n<h2>Additional notes</h2>\r\n<ul>\r\n\t<li>VMWare comes with a tool for mounting its virtual disks from the host</li>\r\n</ul>",
  "excerpt": ""
 },
 {
  "title": "Goodby IBA, welcome, Norway and Iterate!",
  "published": "2011-01-28 11:30:37",
  "postType": "post",
  "slug": "/2011/01/28/goodby-iba-welcome-norway-and-iterate/",
  "status": "publish",
  "tags": [],
  "categories": [
   "General"
  ],
  "content": "I've spent great and inspiring years in <a href=\"http://www.ibacz.eu/-English-\">IBA CZ</a> while working also with IBM Austria and I'm very thankful to all the nice people there, but it's time to move on. I always wanted to spend couple of years abroad to broaden my views and finally our choice has fallen on Norway. So on 2/1 I'm starting to work in Oslo with <a href=\"https://www.iterate.no/\">Iterate AS</a> (<a href=\"http://www.iterate.pl/en/\">en</a>), which is a very attractive company, among others thanks to their true agile development involvement. You may not hear from me for a while as I'll be busy accommodating to the new environment and learning Norwegian but be sure that earlier or later I'll be back with more interesting blogs.<br><br>Ha det bra!",
  "excerpt": ""
 },
 {
  "title": "Clean Code: Four Simple Design Rules - Obligatory Read",
  "published": "2011-02-14 21:36:34",
  "postType": "post",
  "slug": "/2011/02/14/clean-code-four-simple-design-rules/",
  "status": "publish",
  "tags": [
   "book",
   "CleanCode",
   "design",
   "development",
   "opinion",
   "quality",
   "review"
  ],
  "categories": [
   "General"
  ],
  "content": "I consider the <a title=\"Amazon: R.C. Martin &amp; Co. - Clean Code: A Handbook of Agile Software Craftsmanship\" href=\"http://www.amazon.com/Clean-Code-Handbook-Software-Craftsmanship/dp/0132350882\">Clean Code book</a> to be obligatory for every programmer. And if you currently haven't the time to read it all at once then you should read - and take deep into your heart - at least the 12th chapter <em>Emergence</em> by Jeff Langr, which introduces Kent Beck's <a href=\"http://www.c2.com/cgi/wiki?XpSimplicityRules\">Four Simple Design Rules</a> and explains thoroughly what they mean and why they're so important. The rules, <strong>in the order of importance</strong>, are:\r\n<ol>\r\n\t<li>Runs all the tests</li>\r\n\t<li>Contains no duplications</li>\r\n\t<li>Expresses the intent of the programmers</li>\r\n\t<li>Minimizes the number of classes and methods (this isn't as controversial as it may sound, see below)</li>\r\n</ol>\r\nStated like this in simple sentences it's difficult to see the depth hidden behind them and thus their essential importance for clean, high-quality code with high-quality design and I'll therefore try to explain what they really mean in the full extent based on Clean Codes. I'll cite some parts of the book - for I can't find better words than the author - hoping for the author(s) and publisher graciously permitting it.<!--more--><br><br><strong>Runs all the tests</strong> - Why is it so important to have comprehensive tests<sup>1</sup>, which are run and pass all the time, as this rule implies? Foremost because <em>to be actually able to write unit tests, the code must follow the well-known high-quality design principles</em> such as simplicity, single responsibility (including dependency injection), low cohesion etc. - only small, on each other and on the environment maximally independent objects are easy to test.\r\n<blockquote>Remarkably, following a simple and obvious rule that says we need to have tests and run them continuously impacts our system's adherence to the primary OO goals of low coupling and high cohesion. Writing tests leads to better designs.</blockquote>\r\nThis is no theoretical statement - I've personally experienced it many times. See e.g. <a href=\"http://www.quora.com/In-Test-Driven-Development-how-do-unit-tests-help-drive-good-design\">In Test Driven Development, how do unit tests help drive good design?</a> (answer: they don't - but they make bad design so painful that you will want to change it).<br><br><strong>Contains no duplications</strong> - \"Duplication ... represents additional work, additional risk, and additional unnecessary complexity.\" It can have many forms - lines of code that are same (or similar - adepts for generalization), duplication of implementation (e.g. if a collection has int size() and bool isEmpty(), isEmpty shall be based on size() == 0 to reuse the implementation) and other ones. You usually apply abstractions such as Template Method to remove duplication. The true value is in how it leads to the reduction of complexity.\r\n<blockquote>As we extract commonality at this very tiny level, we start to recognize violations of <acronym title=\"Single Responsibility Principle\">SRP</acronym>. So we might move a newly extracted method to another class. That elevates its visibility. Someone else [...] may further abstract the new method and reuse it in a different context. <em>This \"reuse in the small\" can cause system complexity to shrink dramatically</em>.\r\n<em>Understanding how to achieve reuse in the small is essential to achieving reuse in the large</em>. [<em>Emphasis</em> by JH.]</blockquote>\r\n<strong>Expresses the intent of the programmers</strong> - Writing code that expresses well the intent of the programmer so that another person can easily understand it is important for many reasons, especially taking into account that \"the majority of the cost of a software project is in long-term maintenance\". Expressiveness is also one of the essential requirements of a clean code.\r\n<blockquote>The clearer the author can make the code, the less time others will have to spend understanding it. <em>This will reduce defects and shrink the cost of maintenance</em>.\r\n<em>\r\nYou can express yourself by choosing good names</em>. We want to be able to hear a class or function name and not be surprised when we discover its responsibilities.<br><br>You can also express yourself <em>by keeping your functions and classes small</em>. Small classes and functions are usually easy to name, easy to write, and easy to understand.<br><br>You can also express yourself by using standard nomenclature. Design patterns, for example, ... .<br><br>Well-written unit tests are also expressive. A primary <em>goal of tests is to act as documentation by example</em>. Someone reading our tests should be able to get a quick understanding of what a class is all about.<br><br>But the most important way to be expressive is to <em>try</em>. All too often we get our code working and then move on ... without giving sufficient thought to making that code easy for the next person to read. [<em>Emphasis</em> by JH.]</blockquote>\r\nI'd like to add here that the XP motto \"<a href=\"http://xprogramming.com/articles/expdocumentationinxp/#N65631\">the code is the documentation</a>\" doesn't mean, as some people read it, that you simply don't bother with any comments at all. This is not an elimination of some work, it's actually a challenging commitment to writing <em>code so, that it reads as documentation</em> - which essentially means that it is maximally expressive. And writing such code is much, much more difficult than typing whatever comes on your mind and then adding few comments here and there. Regarding comments and their replacement by expressive method names, the Clean Code book has a whole, highly inspiration chapter on that. (I have to mention a <a href=\"http://www.commonsense4commonpeople.net/2008/11/the-code-is-the-documentation.html\">nice post on why code isn't documentation</a>, which I've quite enjoyed.)<br><br><strong>Minimizes the number of classes and methods</strong> - The least important yet absolutely not negligible rule:\r\n<blockquote>Even concepts as fundamental as elimination of duplication, code expressiveness, and the <acronym title=\"Single Responsibility Principle\">SRP</acronym> can be taken too far. In an effort to make our classes and methods small, we might create to many tiny classes and methods. So this rule suggests that we also keep our function and class counts low.<br><br>High class and method counts are sometimes the result of pointless dogmatism. ...</blockquote>\r\nI like the mention of \"pointless dogmatism\". As too often in religion, pointless dogmatism is a sign of an insufficient, shallow understanding of a principle, its true purpose and the proper context of application. It requires experience, open mind, and reason to apply principles correctly. (By no means want I claim that I have that experience and bright reason :-).)<br><br>Please realize that this rule doesn't suggest you should have only few classes and methods - <em>the 4 rules are ordered by priority and the last one only applies if the previous ones are satisfied</em>. As you certainly noticed, e.g. rule #3 requires \"keeping your functions and classes small\" and thus also their counts high. <em>But it's also possible to have too many classes and methods</em> and rule #4 is here to remind you of that and to help you find the right balance. Small stuff is easier to understand - but if there is too many (though perfectly understandable) pieces, you won't be able to see the whole picture. To be concrete: I've seen code base where every method was in a class of its own. Wouldn't you agree it's too many?<br><br>The fourth rule is sometimes alternatively stated as \"Has no superfluous parts\", meaning that you should remove all classes and methods that you don't really need to get rid of unnecessary complexity and maintenance overhead. I'd suggest reading the <a href=\"http://c2.com/cgi/wiki?MinimumNumberOfClassesAndMethods\">discussion about what \"minimize the number of methods/classes\" really means</a>. But I feel that this new phrasing isn't an alternative but rather an addition to or a clarification of the original one for you should be really aware when optimally many classes/methods become too many.\r\n<h2>Notes</h2>\r\n<ol>\r\n\t<li>\"Comprehensive tests\" of course doesn't necessarily mean 100% coverage, which is at least sometimes both impossible and useless (think simple getters/setters, GUI). You have to <a href=\"http://www.infoq.com/news/2007/05/100_test_coverage\">find the right coverage for yourself</a> (though there are <a href=\"http://www.obishawn.com/2008/06/why-you-should-have-100-code-test.html\">arguments that 100% coverage is the ideal goal</a>).</li>\r\n</ol>\r\n<h2>Conclusion</h2>\r\nStudying, understanding, and finally applying the rules described above makes it possible to create much better (micro)designs and code and thus quality. As it is the case with Zen (as I've been told), the basic truths are very simple, but to understand them and to truly master them it takes years and a lot of effort. The important thing is, as the author himself mentions, to try. (I'm myself only somewhere at the beginning of the path. You'll know I'm there once you see me levitating above my notebook.)<br><br>I recommend the Clean Code book and especially chapter 12 to every programmer but I'm actually not really sure when it's the right time for a junior programmer to read it for I can imagine that for somebody without sound practical experience both with a beautiful, clean code and with a terrible, low-quality one, the guidelines in the book are way too abstract (however concrete they're) and difficult to grasp and appreciate - and their appreciation is perhaps the important factor for being motivated and able to put them into practice. But it certainly won't harm to read it as early as possible and come back to it now and then to discover new depths and resonance with one's recent experience.<br><br>Experience and craftmanship is also necessary to be able to apply the clean code principles and guidelines correctly and effectively because, to some extent, one rule always conflicts with another one and you must have some sensibility to the code to be able to find the proper balance between them and to avoid any trace of \"pointless dogmatism\".<br><br>Finally, I'd like to thank all those who help(ed) me understand that - and why - my code is bad and thus lead me towards better quality. Please keep on! I'd like to also thank <a title=\"Amazon: Zen and the Art of Motorcycle Maintenance: An Inquiry into Values\" href=\"http://www.amazon.com/Zen-Art-Motorcycle-Maintenance-Inquiry/dp/0553277472\">Rober Pirsig</a> for pointing out the importance of quality to me :-)<br><br><strong>Update</strong>: You may also want to <a href=\"/2011/02/19/hidden-dependencies-are-evil-arguing-with-the-clean-code/\">check my blog Hidden Dependencies Are Evil – Arguing With The Clean Code (Slightly)</a>, which deals with Clean Code’s chatper 14: Successive Refinement.\r\n<h2>Related</h2>\r\n<ul>\r\n\t<li><a href=\"http://agileinaflash.blogspot.com/2009/02/simple-design.html\">Jeff Langr's own summary of the 4 rules</a></li>\r\n\t<li>Current <a href=\"http://c2.com/cgi/wiki?XpSimplicityRules\">Xp Simplicity Rules</a> and <a href=\"http://c2.com/cgi/wiki?OlderWordingOfXpSimplicityRules\">Older Wording Of Xp Simplicity Rules</a> (still useful to read, I think)</li>\r\n</ul>",
  "excerpt": ""
 },
 {
  "title": "Most interesting links of February",
  "published": "2011-02-28 21:59:37",
  "postType": "post",
  "slug": "/2011/02/28/most-interesting-links-of-february/",
  "status": "publish",
  "tags": [
   "EJB",
   "Git",
   "javaEE",
   "performance",
   "scala",
   "technology",
   "Testing",
   "trends"
  ],
  "categories": [
   "General",
   "Testing",
   "Tools",
   "Top links of month"
  ],
  "content": "<h2>Articles, links etc.</h2>\r\nGit\r\n<ul>\r\n\t<li><a href=\"http://tom.preston-werner.com/2009/05/19/the-git-parable.html\">The Git Parable</a> (thx to Alexander) - a good and easy to understand explanation of the story behind Git and thus also its main goals and concepts. It really helps in understanding what makes Git different from Subversion and thus empowers you to use it to its full capabilities and in accordance with its philosophy and not (painfully) against it. Though I'd appreciate little more coverage of merging and cooperation in the Git world.</li>\r\n</ul>\r\nPerformance\r\n<ul>\r\n\t<li><a href=\"http://nico.vahlas.eu/2010/03/30/some-thoughts-on-stress-testing-web-applications-with-jmeter-part-2/\">Some thoughts on stress testing web applications with JMeter (part 2)</a> - what to measure, when to stop, what listeners to use, some practical  tips e.g. for using remote slave JMeter instances, how to interpret the  results (explanation of mean, std. deviation, confidence interval). By Nicolas Vahlas, 3/2010.</li>\r\n\t<li><a href=\"http://www.scribd.com/doc/3805411/Scalability-Factors-of-JMeter-in-Performance-Testing-projects\">Scalability Factors of JMeter in Performance Testing projects</a> (conference paper, 2008) - what factors determine what number of virtual users (VU) a load test tool can efficiently simulate and experiments to determine the impact of those factors on JMeter. Each VU has an associated cost in terms of CPU and memory (send, process, store request/response etc.) =&gt; number of VUs depends on the HW and the complexity of the messages and protocol and on the load test script complexity.\r\n<ul>\r\n\t<li>For example one commercial tool claims to support up to nearly 2k VUs on 1GHz PIII w/ 1GB but w/o stating the other factors.</li>\r\n\t<li>JMeter scalability experiments results (Def.: Scalability limit reached when additional VUs aren't increasing the server's load (i.e. the test tool has become the bottleneck)):\r\n<ul>\r\n\t<li>Response time: \"The optimal number of virtual users increases with increase in response time. It increases from around 180 virtual users to around 700 optimal virtual users when the response time changes from 500 ms to 1.5 seconds.\"</li>\r\n\t<li>Application response size: \"Application response size has a massive effect on the load generation capabilities of JMeter. The optimal # of virtual users drops from around 500 virtual users to a measly 115 virtual users when the application response size increases form 20 kb to 100kb.\"</li>\r\n\t<li>Communication protocol (HTTP x HTTPS): The load generation capability decreases by 50% or more when the protocol is HTTPS</li>\r\n</ul>\r\n</li>\r\n\t<li>HW used for the test machine: P4 2.4GHz, 2GB RAM.</li>\r\n</ul>\r\n</li>\r\n\t<li> A. Bien: <a href=\"http://www.adam-bien.com/roller/abien/entry/can_stateful_java_ee_6\">Can Stateful Java EE 6 Apps Scale? - Another Question Of The Week</a> - the answer: Yes. A.B. always starts with Gateway+PDO and measures the performance/overhead with VisualVM, JMeter. Don't forget that stateless applications usually just move the state and therefore scalability problem to the DB.</li>\r\n</ul>\r\nOther\r\n<ul>\r\n\t<li><a href=\"http://alarmingdevelopment.org/?p=562\">Switching to Plan J - isn't Scala good enough (yet)?</a> - by Jonathan Edwards. Really an interesting read including the comments (well, the first half - esp. Martin, Stuart R., Vincent etc.) - though very impressive, is Scala too complex and do we need <a href=\"http://www.scala-lang.org/node/8610\">syntax subsets</a> for normal people? The state of IDE support is bad but should be <a href=\"http://alarmingdevelopment.org/?p=562#comment-58901\">getting better</a>.</li>\r\n\t<li><a href=\"http://www.computerworld.com/s/article/print/9137708/Opinion_The_unspoken_truth_about_managing_geeks?taxonomyName=Management+and+Careers&amp;taxonomyId=14\">Opinion: The unspoken truth about managing geeks</a> - a great article on corporate culture and psychology, which turn people into stereotypical geeks - invaluable advices for managing IT professionals. And it's fun to read! (Well, at least if you're a geek observeing the very things he speaks about around you.)</li>\r\n\t<li><a href=\"http://www.thoughtworks.com/articles/technology-radar-january-2011\">ThoughtWorks Technology Radar, Januar 2011</a> - Scala up to Trial, DevOps, .... . Unchanged: ESB, GWT &amp; RIA on hold, Apache Camel (integration library) on Trial. Other interesting: CSS supersets supporting variables etc. like LESS.</li>\r\n</ul>\r\n<h2>Quotes of the month</h2>\r\nI've decided to add this occassional section to capture interesting or inspirational comments of famous as well as ordinary people.\r\n<ul>\r\n\t<li>\"<em>if i learn, i end up going fast. if i just try to go fast, i don't learn &amp; only go fast briefly.</em>\" (<a href=\"http://twitter.com/#!/KentBeck\">Kent Beck's Twitter</a>, 2/11). Reflects nicely a discussion I recently had with a colleague :-) I also like the follow-ups:\r\n<ul>\r\n\t<li>\r\n<div>Mike Hogan: any links/books you can suggest to help get more grounded in this mindset of valuing learning over trying to go fast?</div></li>\r\n\t<li>Kent Beck: \"zen in the art of archery\" is one classic that i've found helpful. that and endlessly trying to do it wrong...</li>\r\n</ul>\r\n</li>\r\n\t<li>\"<em>The computer industry is the only industry that is more fashion-driven than women's fashion.</em>\" - <a href=\"http://www.guardian.co.uk/technology/2008/sep/29/cloud.computing.richard.stallman\">by Richard Stallman</a> in Cloud computing is a trap, 2008-09-29. I might not agree with everything he says but there certainly is a seed of truth in that!</li>\r\n\t<li>\"<em>Shipping is a feature. A really important feature. Your product must have it.</em>\" <a href=\"http://www.joelonsoftware.com/items/2009/09/23.html\">by Joel Spolsky</a> in The Duct Tape Programmer, 2009-09-23. This is something we should really keep in mind and explain to the product owners too :-)</li>\r\n</ul>",
  "excerpt": ""
 },
 {
  "title": "Hidden Dependencies Are Evil - Arguing With The Clean Code (Slightly)",
  "published": "2011-02-19 01:30:15",
  "postType": "post",
  "slug": "/2011/02/19/hidden-dependencies-are-evil-arguing-with-the-clean-code/",
  "status": "publish",
  "tags": [
   "CleanCode",
   "java"
  ],
  "categories": [
   "Languages"
  ],
  "content": "Hidden dependencies are evil because two pieces of code influencing invisibly each other make it very hard to understand what the code is doing. There is an example of an unresolved hidden dependency in the presumabely perfected code in <a href=\"http://www.objectmentor.com/resources/articles/Clean_Code_Args.pdf\">Clean Code's chatper 14: Successive Refinement</a>. When I wrote the first draft of this post I thought I´d be arguing with the author on this point but after reading the next chapter (15) I found him propagating the very same idea. Of course no code is ever perfect but anyway I believe this is something that should have been improved. The final code actually looks really well, it's short, clean, and expressive, but there is this one thing that really troubles me for I find it difficult to understand (and thus quite \"unclean\"), and that is the method <em>parseArgumentStrings</em>. Perhaps I'm not smart enough but clean code should be dummy-proof anyway :-). The problem is caused by a hidden dependency between methods of the main class Args and between this class and another one, which is modifying Args' internal state variable.<!--more--><br><br>The Args class is supposed to pass command-line arguments for later retrieval. An example input:<br><br><pre><code>-n 42 -s &quot;hello!&quot; -bcd</code></pre><br><br>- you can see here two arguments with values (integer, string) and three boolean flags condensed into one argument.\r\n<h2>The relevant code</h2>\r\n<pre><code>\r\npublic class Args {\r\n   // ...\r\n   private ListIterator currentArgument;\r\n   // ...\r\n   public Args(String schema, String[] args) throws ArgsException {\r\n      // ...\r\n      parseArgumentStrings(Arrays.asList(args));\r\n   }<br><br>   private void parseArgumentStrings(List argsList)\r\n         throws ArgsException {\r\n      for (currentArgument = argsList.listIterator(); currentArgument\r\n            .hasNext();) {\r\n         String argString = currentArgument.next();\r\n         if (argString.startsWith(&quot;-&quot;)) {\r\n            parseArgumentCharacters(argString.substring(1));\r\n         } else {\r\n            currentArgument.previous();\r\n            break;\r\n         }\r\n      }\r\n   }<br><br>   private void parseArgumentCharacters(String argChars) throws ArgsException {\r\n      for (int i = 0; i &lt; argChars.length(); i++)\r\n         parseArgumentCharacter(argChars.charAt(i));\r\n   }<br><br>   private void parseArgumentCharacter(char argChar) throws ArgsException {\r\n      ArgumentMarshaler m = marshalers.get(argChar);\r\n      if (m == null) {\r\n         throw new ArgsException(UNEXPECTED_ARGUMENT, argChar, null);\r\n      } else {\r\n         argsFound.add(argChar);\r\n         try {\r\n            m.set(currentArgument);\r\n         } catch (ArgsException e) {\r\n            e.setErrorArgumentId(argChar);\r\n            throw e;\r\n         }\r\n      }\r\n   }\r\n   // ...\r\n}\r\n</code></pre>\r\n<h2>The unclarity and its (partial) explanation</h2>\r\nI can easily understand that <em>parseArgumentStrings</em> goes through all the individual arguments, calling <em>parseArgumentCharacters</em> to process each of them (whether a single-letter argument or a \"condensed\" one). What i find really confusing is the call to currentArgument.previous() followed by break to finish processing of the arguments prematurely:\r\n<ul>\r\n\t<li> * Why is the processing finished when an argument not starting with - is encountered? If it is an error situation, shouldn't we rather throw an exception? If it isn't an error situation, why do we ignore the rest of the input??</li>\r\n\t<li>How does a non-boolean argument get its value if we only accept arguments starting with a dash?</li>\r\n</ul>\r\nThen, on line 36, why do we set as the value of the argument marshaler the argument name (i.e. an iterator pointing to it)? It gets clear when we look into the implementation of some ArgumentMarshalers:<br><br><pre><code>\r\npublic class BooleanArgumentMarshaler implements ArgumentMarshaler {\r\n   private boolean booleanValue = false;\r\n   public void set(Iterator currentArgument) throws ArgsException {\r\n      booleanValue = true;\r\n   }\r\n}<br><br>public class StringArgumentMarshaler implements ArgumentMarshaler {\r\n   private String stringValue = &quot;&quot;;\r\n   public void set(Iterator currentArgument) throws ArgsException {\r\n      try {\r\n         stringValue = currentArgument.next();\r\n      } catch (NoSuchElementException e) {\r\n         throw new ArgsException(MISSING_STRING);\r\n      }\r\n   }\r\n}\r\n</code></pre><br><br>You can see that StringArgumentMarshaler itself retrieves the next argument, i.e. the value following the argument name, while the boolean argument marshaler (which expects no value) sets itself to true based just on the option name being present.\r\n<h2>The problem</h2>\r\nDo you see the problem? <strong>I had to look into another classes to understand Args' code</strong>. (And I still do not understand the call to previous() and break).<br><br>As I've said, the problem is caused by hidden dependencies and data interactions.\r\n<h3>Sin one: A hidden dependency between methods</h3>\r\n<em>parseArgumentCharacter(char argChar)</em> depends on the state of the <em>this.currentArgument</em> iterator - but this fact is obscured both by its signature (it only takes a character) and by its name, which suggests that it only operates on a single character. Thus a dumb reader like me has no clue that he should expect such a side-effect from the method.<br><br>I of course don't mean you should stop using instance variables but care should be taken that their use and changes are clear at a first glance.\r\n<h3>Sin two: External class changing secretly a private state variable</h3>\r\nEven worse, some of the ArgumentMarshallers, namely those requiring an input, advance Args' internal currentArgument pointer. How am I supposed to guess that some evil outsider is touching my class' internal variables?!\r\n<h2>Proposed solution</h2>\r\nI really don't like hidden dependencies like these ones because they make understanding code so much harder for simple people like me. I always prefer to make them explicit even if it means adding a parameter to a method or creating a new (ideally immutable, passed there and back) class for encapsulation of the state.<br><br>I've therefore wrapped the iterator into a class providing methods with names communicating the intent and pass it to the two parsing methods to make the dependency clear:<br><br><pre><code>\r\n   //...\r\n   private void parseArgumentStrings(List argsList)\r\n         throws ArgsException {\r\n      ArgumentIterator argumentIterator = new ArgumentIterator(argsList);\r\n      String argString;\r\n      while ((argString = argumentIterator.getNextUnprocessedOrNull()) != null) {\r\n         if (argString.startsWith(&quot;-&quot;)) {\r\n            parseArgumentCharacters(\r\n                  argString.substring(1), argumentIterator);\r\n         } else {\r\n            // The old inexplicable code; shouldn't it rather throw an\r\n            // exception?\r\n            argumentIterator.rollbackToPrevious();\r\n            break;\r\n         }\r\n      }\r\n   }<br><br>   private void parseArgumentCharacters(String argChars, ArgumentIterator argumentIterator) throws ArgsException {\r\n      for (int i = 0; i &lt; argChars.length(); i++)\r\n         parseArgument(argChars.charAt(i), argumentIterator);\r\n   }<br><br>   private void parseArgument(char argChar, ArgumentIterator argumentIterator) throws ArgsException {\r\n      ArgumentMarshaler m = marshalers.get(argChar);\r\n      if (m == null) {\r\n         throw new ArgsException(UNEXPECTED_ARGUMENT, argChar, null);\r\n      } else {\r\n         argsFound.add(argChar);\r\n         if (m.isValueRequired()) {\r\n            m.set(argumentIterator.getValueForArgumentOrFail(argChar));\r\n         }\r\n      }\r\n   }\r\n</code></pre><br><br>And the iterator:<br><br><pre><code>\r\n   public class ArgumentIterator {\r\n      private ListIterator currentArgument;<br><br>      public ArgumentIterator(List argsList) {\r\n         currentArgument = argsList.listIterator();\r\n      }<br><br>      public String getNextUnprocessedOrNull() {\r\n         if (currentArgument.hasNext())\r\n            return currentArgument.next();\r\n         else\r\n            return null;\r\n      }<br><br>      public void rollbackToPrevious() {\r\n         currentArgument.previous();\r\n      }<br><br>      public String getValueForArgumentOrFail(char argChar) throws ArgsException {\r\n         try {\r\n            return currentArgument.next();\r\n         } catch (NoSuchElementException e) {\r\n            throw new ArgsException(MISSING_ARGUMENT_VALUE, argChar);\r\n         }\r\n      }\r\n   }\r\n</code></pre><br><br>There is actually quite similar reasoning in CC chapter 15: JUnit internals, p. 259:\r\n<blockquote>Careful inspection of findCommonSuffix exposes a hidden temporal coupling [G31]; it depends on the fact that prefixIndex is calculated by findCommonPrefix. If these two functions were called out of order, there would be a difficult debugging session ahead. So, to expose this temporal coupling, let’s have findCommonSuffix take the prefixIndex as an argument.</blockquote>\r\nOf course I do not claim the code is perfect, there certainly is yet lot of space for further refinements but I believe that it is now much easier to understand.\r\n<h2>Conclusion</h2>\r\nHidden dependencies are a bad thing. I  firmly believe it's always better to try to make them explicit even if it means less clean code according to other guidelines (such as minimizing the number of method parameters - [F1]).<br><br>I've been little daring, correcting Uncle Bob's code, but let me excuse myself with his own words (p. 265):\r\n<blockquote>The authors had done an excellent job with it. But no module is immune from improvement, and each of us has the responsibility to leave the code a little better than we found it.</blockquote>\r\nIt is clear that code quality really requires continual refinement and that there is always something to improve. We must therefore know when is the right time to stop and move on to another task, it should be neither too early, leaving mess behind, nor too late, leaving the customer without the new features he desired. And whenever we come back to an old code, we should follow the <a href=\"http://www.hans-eric.com/2010/07/26/the-boy-scout-rule/\">Boy Scoute Rule</a> of software craftmanship.<br><br>Allow me one last quote from Clean Code:\r\n<blockquote>Often one refactoring leads to another that leads to the undoing of the first. Refactoring is an iterative process full of trial and error, inevitably converging on something that we feel is worthy of a professional.</blockquote>",
  "excerpt": ""
 },
 {
  "title": "Why not to be afraid of 2012",
  "published": "2011-03-12 14:39:14",
  "postType": "post",
  "slug": "/2011/03/12/why-not-to-be-afraid-of-2012/",
  "status": "publish",
  "tags": [
   "humor"
  ],
  "categories": [
   "General"
  ],
  "content": "You don't need to be afraid of the foretold end of the world in 2012. To end the world is a big project and I think we can easily compare it to large scale IT projects. Consequently:\r\n<ol>\r\n\t<li>Such a large-scale change certainly wont't be delivered on time. Most likely it will take several times longer, i.e. we can expect it around 2020 earliest.</li>\r\n\t<li>Anyway it will be necessary to downsize it considerably, so don't expect a complete destruction of everything to take place.</li>\r\n\t<li>Most likely the project will be canceled at the end.</li>\r\n</ol>\r\nSo calm down :-)<br><br>PS: I hope they won't try to go with agile, I wouldn't appreciate frequent deliveries :-)",
  "excerpt": ""
 },
 {
  "title": "Most interesting links of March",
  "published": "2011-03-31 21:59:14",
  "postType": "post",
  "slug": "/2011/03/31/most-interesting-links-of-march-2/",
  "status": "publish",
  "tags": [],
  "categories": [
   "General",
   "Testing",
   "Top links of month"
  ],
  "content": "<h2>Articles, links etc.</h2>\r\nN/A\r\n<h2>Quotes of the month</h2>\r\n<ul>\r\n\t<li>\"<em>I told them that quick-and-dirty is an oxymoron. Dirty <strong>always</strong> means slow.</em>\" by <a href=\"http://blog.objectmentor.com/articles/2007/12/13/business-software-is-messy-and-mgly\">Uncle Bob in his blog</a> on 12/13/2007</li>\r\n</ul>",
  "excerpt": ""
 },
 {
  "title": "Introduction to ObjectTeams/Java, a Role-Based Approach to Modularity With AOP",
  "published": "2011-03-27 16:59:51",
  "postType": "post",
  "slug": "/2011/03/27/introduction-to-objectteamsjava-a-role-based-approach-to-modularity-with-aop/",
  "status": "publish",
  "tags": [
   "AOP",
   "architecture",
   "eclipse",
   "java"
  ],
  "categories": [
   "Languages",
   "Tools"
  ],
  "content": "I've recently stumbled upon an interesting Eclipse project called <a href=\"http://www.eclipse.org/objectteams/\">ObjectTeams/Java</a> (OT/J), which promises improved reusability and maintenance and support for evolvable architectures by creating well-encapsulated bundles of behavior - modules - that can be applied to existing classes (via AOP), when they are in the appropriate context of interaction (and not simply always, as is the case with AOP). An example application is the <a href=\"http://www.dzone.com/links/r/bye_bye_null_pointer_exception.html\">addition of NonNull constraint to JDT via an OT/Equinox plugin</a>, without the necessity to modify JDT's base classes. I've decided to write down my discoveries as the project is missing a clear and brief introduction (though it has otherwise very good documentation). This blog borrows heavily from [1]. <!--more--><br><br>Disclaimer: By no means do I claim to understand OT/J completely :-)\r\n<h2>So what is OT/J about?</h2>\r\nThe key concepts are roles, contexts in which an entity is being used (\"teams\"), modules, and separation of concerns.<br><br><em>Roles</em> are traditionally used in domain modeling: the role Customer may be played by a physical person, by a company, ... . OT/J adds explicit support for roles so that behavior that is only relevant to a particular role is implemented in the class representing the role, which is than applied on the base entity class. We can see below in Fig. 1 that the entity Professor can play the roles Supervisor for some PhDs and also Lecturer in some courses, in this particular example Prof. Smith lectures OOP and Software Engineering. The lecturing-related behavior, such as \"write neatly on the blackboard\" (PhDs are there long enough to read his natural hand writing) and handing over of slides and handouts, is implemented in the Lecturer role class. Thanks to this separation of concerns, as the number of roles a particular entity may play grows, the base class doesn't get more and more bloated. Roles may modify or reuse behavior  of their base classes and may expose or hide any properties and methods of the base classes.\r\n<table style=\"width:auto;\">\r\n<tbody>\r\n<tr>\r\n<td><a href=\"https://picasaweb.google.com/lh/photo/w_noKigQrNnkBKnW0W-OkQ?feat=embedwebsite\"><img src=\"https://lh6.googleusercontent.com/_btcPMCQkYvg/TY81s_BDYrI/AAAAAAAABmY/6rSmXPVng_4/s640/objectteams-example_uml.png\" alt=\"\" width=\"640\" height=\"275\" /></a></td>\r\n</tr>\r\n<tr>\r\n<td style=\"font-family:arial, sans-serif;font-size:11px;text-align:right;\">Fig. 1 (Source: <a href=\"http://www.objectteams.org/publications/JAO07.pdf\">A Precise Model for Contextual Roles: The Programming Language ObjectTeams/Java</a>.)</td>\r\n</tr>\r\n</tbody>\r\n</table>\r\n<em>Contexts of interaction</em>, called <em>Teams</em> in the OT/J terminology, are the space where roles live, for a role is only meaningful in a particular context, such as teaching a course or participating in the PhD program - you may also think of high-level use cases. Teams serve basically two purposes in OT/J: First, they group related roles together (think of a package). Second, they make it possible to activate or deactivate all the roles at once - e.g. when a Professor and a bunch of Students enter a course room then the behavior defined by the Lecturer and Participant roles will activate and will modify/enhance their behavior for the duration of the lesson. This ability to switch on/off modifications of behavior based on the context where a class is used is pretty nice. Additionally a Team may have its own set of methods and properties because it is represented by a class.<br><br><em>Modularity</em> and reusability are achieved by implementing independent behaviors as roles grouped into teams and applied to base classes at the run-time. OT/J offers a middle road for modularization between white-box frameworks and black-box components and makes it possible to evolve and adapt a system while avoiding lot of changes to the base classes. One of the examples I've seen uses an abstract Team with a Subscriber, which collects credit for some BonusItems. The team is then specialized with a concrete FlightBonus team, which applies this behavior to the existing entity classes Passenger and Flight, where the \"credit\" being collected are bonus miles. The same abstract Team could be applied to a shop customer shopping with a customer card and collecting some bonus for each purchase.\r\n<h2>What is it good for?</h2>\r\nOT/J makes it possible to implement systems in a more natural way by supporting explicitly the notion of role, narrowing thus the gap between the business, business analysts and the developers. At the same time it helps to remove unnecessary coupling and to structure functionality in a better, more reusable way.<br><br>The authors themselves have experienced these benefits:\r\n<blockquote>At a technical level applying OT/J for the implementation of its own  tools Herrmann &amp; Mosconi (2007) has demonstrated significantly  improved maintainability of components that re-use and adapt existing  components.</blockquote>\r\n<h2>How is it implemented?</h2>\r\nOT/J extends Java syntax to support natively the concepts of a team, role, and extension/modification of existing behavior of base classes. You compile it with a special OT/J compiler and it then applies load-time weaving to actually enable the application of roles to their base classes. Teams and their roles are activated either implicitly when you call a method on a Team class, the activation lasting for the duration of the call, or explicitly, so that a role may apply even if the client of the entity is unaware of it (for instance a flight reservation system doesn't perhaps need to know or care that there is some support for collecting bonus miles).<br><br>An example of the syntax, showing a team and replacement of a method in the base class Main (an around advice in the AOP language):<br><br><pre><code>\r\npublic class Main { public String sayMore() {...} }\r\n...\r\npublic team class MyTeam {<br><br>   protected class MyRole playedBy Main {\r\n      callin static void sayMore() {\r\n         System.out.println(&quot;callin begins ...&quot;);\r\n         base.sayMore();\r\n         System.out.println(&quot;callin ends ...&quot;);\r\n      }\r\n   sayMore &lt;- replace sayHello;\r\n   }\r\n}\r\n</code></pre><br><br>Summary\r\n<ul>\r\n\t<li>Role is a class, which explicitly refers to the class that it modifies/enhances. At run-time, the modifications it introduces are injected into the base class when it is in the appropriate context.\r\n<ul>\r\n\t<li>Methods of the base class may be modified in the around-advice style (\"callin-binding\") using \"aRoleMethod &lt;- replace aBaseClassMethod\"</li>\r\n\t<li>Methods of the base class may be exposed by the role (\"callout-binding\"): \"aDelegatingRoleMethod -&gt; aBaseClassMethod\"</li>\r\n\t<li>Also properties of the base class may be exposed via getters/setters: \"getARoleGetter -&gt; get aBaseClassField\"</li>\r\n</ul>\r\n</li>\r\n\t<li>Team is a class, which may contain roles - either as nested classes or in a package-style folder/file structure - and its own methods and properties. Roles have a link to their Team. When a team is activated then OT/J tries to automatically apply its roles to the eligible interacting objects based on their types (the programmer may tune that with \"guard predicates\").</li>\r\n</ul>\r\n<h2>What's the difference between AOP and OT/J?</h2>\r\nAOP deals only with code injection and usually the same code (advice) is applied to multiple methods in multiple classes. OT/J is much more than that with its explicit support for roles and teams and their context-sensitive activation. Also a method in a Role normally only modifies one method in one base class, so the mapping isn't 1:N as in AOP but 1:1.<br><br>OT/J also supports the traditional modification of multiple joint points but this should be avoided as much as possible because it makes it more difficult to understand the runtime behavior and to refactor the code, OT/J is on purpose more explicit.<br><br>See [2] for a deeper discussion.\r\n<h2>Conclusion</h2>\r\nSeparation of concerns is not always easy because we often need to apply the same - or very similar - behavior at several places and OOP doesn't always lend itself to extraction and reuse of the behavior. AOP can help here by injecting the behavior defined at one place to all the places where it is needed but when its power is overused then it is very difficult to understand the runtime structure of a program from just looking at its source codes. OT/J makes a very good compromise here by allowing Roles to modify existing classes but making the application explicit and 1:1 (further reusability is possible by defining common functionality in an abstract team and binding it to different set of entities via concrete sub-teams, as in the FlightBonus example). By using the language of business analysis such as Roles, OT/J makes it easier to understand and apply this technique to real projects.<br><br>OT/J certainly looks very interestingly and can benefit a complex project greatly provided that it is applied correctly. Certainly it tends to be less obscure than low-level AOP with e.g. AspectJ.<br><br>OT/J ss currently in incubation due to its recent move to Eclipse, but the project is alive since around 2003, so it should be pretty mature. There is also tooling supporting it, for example a set of Eclipse plugins.<br><br>According to the developers, the project delivers what it promises:\r\n<blockquote>During several case studies we have collected data about code sizes, about structural properties of the code as well as about the development process regarding productivity and maintainability. All these data support our approach, ...</blockquote>\r\n<h2>Resources</h2>\r\n<ul>\r\n\t<li>[1] <a href=\"http://www.objectteams.org/publications/JAO07.pdf\">A Precise Model for Contextual Roles: The Programming Language ObjectTeams/Java</a>. - very good explanation of OT/J and the design decisions behind it, the only downside is the length of 25 pages</li>\r\n\t<li>[2] OT Blog: <a href=\"http://blog.objectteams.org/2010/02/compare-object-teams-to-aop/\">Compare Object Teams to AOP?</a> - it also explains very well what playing a role means</li>\r\n\t<li>[3] <a href=\"http://wiki.eclipse.org/Object_Teams_Quick-Start\">Object Teams Quick-Start</a> - a hands-on tutorial</li>\r\n\t<li><a href=\"http://trac.objectteams.org/ot/wiki/OtPatterns\">Patterns of good design with OT/J</a></li>\r\n</ul>",
  "excerpt": ""
 },
 {
  "title": "CKEditor: Scroll dialogs with the page, i.e. not fixed to the middle",
  "published": "2011-03-31 09:06:31",
  "postType": "post",
  "slug": "/2011/03/31/ckeditor-scroll-dialogs-with-page/",
  "status": "publish",
  "tags": [
   "ckeditor"
  ],
  "categories": [
   "General"
  ],
  "content": "Dialogs in the popular rich-text wysiwyg JavaScript editor <a href=\"http://ckeditor.com/\">CKEditor</a> 3.5.2 are fixed-positioned and thus when you scroll the editor's page they always stay in the middle as you can see in its <a href=\"http://ckeditor.com/demo\">demo</a>. That is a problem if the dialog is longer then the height of the page because you will be never able to scroll to its end (where the Ok/Cancle buttons are located).<br><br>It could be perhaps solved by adding a scrollbar to the dialog but I solved it by overriding the dialog's <em>position: fixed</em> with <em>position: absolute</em>. Here is how to do it.<!--more--><br><br>Add the following to the <a href=\"http://docs.cksource.com/CKEditor_3.x/Developers_Guide/Setting_Configurations\">CKEditor's configuration</a> (either directly when you instantiate it or into a custom config, if you have one):<br><br><pre><code>\r\nCKEDITOR.on('dialogDefinition', function(e) {\r\n    var dialogName = e.data.name;\r\n    var dialogDefinition = e.data.definition;\r\n    dialogDefinition.dialog.parts.dialog.setStyles(\r\n        {\r\n            position : 'absolute'\r\n        });\r\n});\r\n</code></pre><br><br>(I've copied the idea of using the on dialogDefinition event from a source I don't remember.)\r\n<h2>Explanation</h2>\r\nThe div and table, which constitute the two top-level elements of a dialog, are created in themes/default/theme.js in the method buildDialog(editor). This method is called from dialog/plugin.js where these elements are further modified, including the following:<br><br><pre><code>\r\nvar themeBuilt = editor.theme.buildDialog( editor );\r\n...\r\nthis.parts = themeBuilt.parts;\r\n...\r\n// Set the startup styles for the dialog, avoiding it enlarging the\r\n// page size on the dialog creation.\r\nthis.parts.dialog.setStyles(\r\n\t{\r\n\t\tposition : CKEDITOR.env.ie6Compat ? 'absolute' : 'fixed',\r\n\t\ttop : 0,\r\n\t\tleft: 0,\r\n\t\tvisibility : 'hidden'\r\n\t});\r\n...\r\nthis.definition = definition = CKEDITOR.fire( 'dialogDefinition', ...).definition;\r\n</code></pre><br><br>We make use of the fired event to modify the dialog's definition to our liking, overriding the position to be always absolute.<br><br><a href=\"http://dev.ckeditor.com/ticket/2127\">Why CKEditor uses position: fixed</a> is explained in its ticket #2127.",
  "excerpt": ""
 },
 {
  "title": "CKEditor: Collapsing only 2nd+ toolbar rows - howto",
  "published": "2011-04-01 14:01:59",
  "postType": "post",
  "slug": "/2011/04/01/ckeditor-collapsing-only-2nd-toolbar-rows-howto/",
  "status": "publish",
  "tags": [
   "ckeditor",
   "JavaScript",
   "UI"
  ],
  "categories": [
   "General"
  ],
  "content": "Normally CKEditor (v3.5.2) hides/shows all the toolbar buttons when you press the collapse/expand button but I needed to always show the first row with \"basic tools\" and only collapse the second and following rows with advanced functionality tool buttons. CKEditor doesn't have proper support for that but there is a simple workaround.<br><br><strong>Update: Example solution (CKEditor 3.6.1) published</strong>, <a href=\"https://github.com/jakubholynet/ex-ckeditor-collapsable-toolbar/commit/98404375dafaea0003896e9a998594effc33a400\">see the changes done</a> or <a href=\"https://github.com/jakubholynet/ex-ckeditor-collapsable-toolbar/archives/98404375dafaea0003896e9a998594effc33a400\">download the full source</a> and open _samples/replacebyclass.html.<br><br><!--more-->\r\n<h2>Introduction</h2>\r\nThe trick is to override the command <em>toolbarCollapse</em> not to hide the complete toolbox but only specific toolbars. Let's see what the toolbox looks like:<br><br><a href=\"https://lh5.googleusercontent.com/_btcPMCQkYvg/TZXFLqZ9u7I/AAAAAAAABp8/RdTYWdkYaCo/s800/ckeditor-toolbar.png\" target=\"_blank\"><img title=\"CKEditor 3.5.2 toolbox\" src=\"https://lh5.googleusercontent.com/_btcPMCQkYvg/TZXFLqZ9u7I/AAAAAAAABp8/RdTYWdkYaCo/s400/ckeditor-toolbar.png\" alt=\"\" width=\"400\" height=\"45\" /></a><br><br>The whole thing you can see on the image is the toolbox, which contains the following elements:\r\n<ul>\r\n\t<li>1 &amp; 2: a list of toolbars including optional line breaks to spread the toolbars across multiple lines; a toolbar may contain one or more buttons, such as (B I U) in the toolbar marked as #4</li>\r\n\t<li>Collapser - the button used to collapse and expand the toolbox</li>\r\n</ul>\r\nThe (generated) source code is something like this:<br><br><pre><code>\r\n&lt;td class=&quot;cke_top&quot; id=&quot;cke_top_newedittextarea&quot;&gt;\r\n  &lt;div class=&quot;cke_toolbox&quot;&gt;\r\n    &lt;span id=&quot;cke_6&quot; class=&quot;cke_voice_label&quot;&gt;Toolbar&lt;/span&gt;\r\n    &lt;span id=&quot;cke_7&quot; class=&quot;cke_toolbar&quot;&gt;...&lt;/span&gt;\r\n    ...\r\n    &lt;div class=&quot;cke_break&quot;&gt;\r\n    &lt;span id=&quot;cke_29&quot; class=&quot;cke_toolbar&quot;&gt;&gt;...&lt;/span&gt;\r\n    ...\r\n  &lt;/div&gt;\r\n  &lt;a id=&quot;cke_61&quot; class=&quot;cke_toolbox_collapser&quot; title=&quot;Collapse Toolbar&quot;&gt;▲&lt;/a&gt;\r\n&lt;/td&gt;<br><br></code></pre><br><br>The CKEditor's tool area, represented by a td, contains the toolbars contained in a div.cke_toolbox (#2) and a link representing the collapser (#10). The toolbox contains various elements, mostly span.cke_toolbar, representing the individual toolbars (such as #4 above), and some special ones such as div.cke_break (#6), which splits the toolbars into multiple lines.\r\n<h2>Implementation</h2>\r\nTo hide only the second and following rows, we will go through the list of toolbox' children and hide() each starting with the first div.cke_break. Add the following into your <a href=\"http://docs.cksource.com/CKEditor_3.x/Developers_Guide/Setting_Configurations\">CKEditor’s configuration</a>:<br><br><pre><code>\r\nconfig.toolbarStartupExpanded = false;\r\n</code></pre><br><br>and add there or somewhere else also the following:<br><br><pre><code>\r\n/**\r\n * Override the default 'toolbarCollapse' command to hide\r\n * only toolbars in the row two and onwards.\r\n */\r\nCKEDITOR.on('instanceReady', function(e) {<br><br>    function switchVisibilityAfter1stRow(toolbox, show)\r\n    {\r\n        var inFirstRow = true;\r\n        var elements = toolbox.getChildren();\r\n        var elementsCount = elements.count();\r\n        var elementIndex = 0;\r\n        var element = elements.getItem(elementIndex);\r\n        for (; elementIndex &lt; elementsCount; element = elements.getItem(++elementIndex))\r\n        {\r\n            inFirstRow = inFirstRow &amp;&amp; !(element.is('div') &amp;&amp; element.hasClass('cke_break'));<br><br>            if (!inFirstRow)\r\n            {\r\n                if (show) element.show(); else element.hide();\r\n            }\r\n        }\r\n    }<br><br>    var editor = e.editor;\r\n    var collapser = (function()\r\n    {\r\n        try\r\n        {\r\n            // We've HTML: td.cke_top {\r\n            //  div.cke_toolbox {span.cke_toolbar, ... }\r\n            //  , a.cke_toolbox_collapser }\r\n            var firstToolbarId = editor.toolbox.toolbars[0].id;\r\n            var firstToolbar = CKEDITOR.document.getById(firstToolbarId);\r\n            var toolbox = firstToolbar.getParent();\r\n            var collapser = toolbox.getNext();\r\n            return collapser;\r\n        }\r\n        catch (e) {}\r\n    })();<br><br>    // Copied from editor/_source/plugins/toolbar/plugin.js &amp; modified\r\n    editor.addCommand( 'toolbarCollapse',\r\n    {<br><br>        exec : function( editor )\r\n        {\r\n            if (collapser == null) return;<br><br>            var toolbox = collapser.getPrevious(),\r\n            contents = editor.getThemeSpace( 'contents' ),\r\n            toolboxContainer = toolbox.getParent(),\r\n            contentHeight = parseInt( contents.$.style.height, 10 ),\r\n            previousHeight = toolboxContainer.$.offsetHeight,<br><br>            collapsed = toolbox.hasClass('iterate_tbx_hidden');//!toolbox.isVisible();<br><br>            if ( !collapsed )\r\n            {\r\n                switchVisibilityAfter1stRow(toolbox, false);    // toolbox.hide();\r\n                toolbox.addClass('iterate_tbx_hidden');\r\n                if (!toolbox.isVisible()) toolbox.show(); // necessary 1st time if initially collapsed<br><br>                collapser.addClass( 'cke_toolbox_collapser_min' );\r\n                collapser.setAttribute( 'title', editor.lang.toolbarExpand );\r\n            }\r\n            else\r\n            {\r\n                switchVisibilityAfter1stRow(toolbox, true);    // toolbox.show();\r\n                toolbox.removeClass('iterate_tbx_hidden');<br><br>                collapser.removeClass( 'cke_toolbox_collapser_min' );\r\n                collapser.setAttribute( 'title', editor.lang.toolbarCollapse );\r\n            }<br><br>            // Update collapser symbol.\r\n            collapser.getFirst().setText( collapsed ?\r\n                '\\u25B2' :\t\t// BLACK UP-POINTING TRIANGLE\r\n                '\\u25C0' );\t// BLACK LEFT-POINTING TRIANGLE<br><br>            var dy = toolboxContainer.$.offsetHeight - previousHeight;\r\n            contents.setStyle( 'height', ( contentHeight - dy ) + 'px' );<br><br>            editor.fire( 'resize' );\r\n        },<br><br>        modes : {\r\n            wysiwyg : 1,\r\n            source : 1\r\n        }\r\n    } )<br><br>    // Make sure advanced toolbars initially collapsed\r\n    editor.execCommand( 'toolbarCollapse' );\r\n});\r\n</code></pre><br><br>Explanation:\r\n<ul>\r\n\t<li><strong>General</strong>: When the editor finishes its initialization, i.e. on the instanceReady event, we override the default toolbarCollapse command, defined in the toolbar plugin</li>\r\n\t<li>#07 function <strong>switchVisibilityAfter1stRow</strong>: A utility function to hide/show the toolbars that follow the first row of toolbars (including the line-break element)\r\n<ul>\r\n\t<li>#16 We start hiding/showing with the first div element having the class cke_break, which CKEditor uses to force line breaks</li>\r\n\t<li>#20 The actual change of visibility</li>\r\n\t<li>Notice that the elements are instances of <a href=\"http://www.churchcmshosting.com/ckeditor/_docs/api/symbols/CKEDITOR.dom.element.html\">CKEditor.dom.element </a></li>\r\n</ul>\r\n</li>\r\n\t<li>#26 <strong>collapser lookup</strong>: It's little complicated to locate the collapser for we have no way of learning its ID. Fortunately the editor object has some kind of object representation of its toolbox and toolbars. These are not the CKEditor.dom.elements we need but contain the actual ids, so we can get the id of a toolbar, use it to get its dom.element, and get the parent toolbox and its sibling collapser.</li>\r\n\t<li>#43 the actual <strong>re-definition of the toolbarCollapse command</strong>:\r\n<ul>\r\n\t<li>Only the highlighted lines have been added or changed, the rest is copied from the toolbar plugin.</li>\r\n\t<li>#48 We use the collapser element located above instead of finding it by its (unknown to us) id, as the original function did.</li>\r\n\t<li>#56, #61,70: We use a custom class - iterate_tbx_hidden - to make it easy to detect the current state.</li>\r\n\t<li>#62: A trick to show the toolbar hidden by having set config.toolbarStartupExpanded to false, explained later</li>\r\n</ul>\r\n</li>\r\n\t<li>#94 executing the command to display only the first toolbars row: explained below</li>\r\n</ul>\r\n<h3>Trick: Not hiding visible buttons while the user looks</h3>\r\nWe want to have the \"advanced\" buttons initially collapsed. If you tried to achieve it simply by calling editor.execCommand( 'toolbarCollapse' ) at the end of the instanceReady event handler then the user would initially see all rows, which would be then collapsed. This is little strange experience, we would prefer to hide the advanced rows before they are displayed. This is how to do it:\r\n<ol>\r\n\t<li>Tell CKEditor to initially collapse the toolbox (config.toolbarStartupExpanded=false). This happens before the instanceReady event and thus it executes the original toolbarCollapse command, which works by invoking hide() on the toolbar container (div.cke_toolbox). So all buttons will be hidden.</li>\r\n\t<li>However our new toolbarCollapse, which we invoke after instanceReady, will believe that the toolbox is not collapsed before it won't find the special marker class iterate_tbx_hidden on the toolbox. Little strangely it will anyway do exactly what we want: hide the 2nd row of buttons and set the collapser to the collapsed position (actually it just keeps it). We need only one thing more and that is to show the currently hidden content of the toolbox (line #62).</li>\r\n</ol>\r\n<h2>Conclusion</h2>\r\nIt is little cumbersome to make it possible to collapse/expand only the 2nd+ rows but it is possible. There are certainly other - and better - ways to do it but this worked fine for me.",
  "excerpt": ""
 },
 {
  "title": "Code quality matters to the customers. A lot.",
  "published": "2011-04-02 18:59:33",
  "postType": "post",
  "slug": "/2011/04/02/code-quality-matters-to-the-customers-a-lot/",
  "status": "publish",
  "tags": [
   "CleanCode",
   "opinion",
   "quality"
  ],
  "categories": [
   "General"
  ],
  "content": "Some people argue that the main taks of a developer is to deliever working, value-bringing software to the customer and idealistic concepts such as code quality should not hinder that primary task. They acknowledge that it is good to strive for good code quality but say that sometimes code quality must give way to the quick deliverance of outcomes to the customer. After having worked on the code base so rotten that it drove less resistant programmers mad I have to strongly disagree. Code quality is not an abstract concept that has a value only in the developers' world, it is a very real thing, which translates directly to money, namely if you are missing it, it translates into great financial losses over the time.<br><br><!--more--><br><br>I don't think I am an extremist. I know that code quality can never be perfect, it can always be improved (as Uncle Bob shows e.g. in CC's <a href=\"/2011/02/19/hidden-dependencies-are-evil-arguing-with-the-clean-code/\">Successive Refinement</a>) and thus it is always important to find the proper level of sufficient quality. And I admit that there is code where quality doesn't matter that much, like one-shot utilities which you use once and throw away. But when speaking about enterprise software, which will live or 5, 10, 20 years, code quality is not anything that can be sacrificed. You may gain temporary speedup by using a quick hack solution but you are thus creating a technical debt, which will be paid for several times most likely already during the development of the software and certainly during its maintenance and further development over its long life-span. Trust me, I've been there, I've seen it, I've paid the price and cursed the authors of the hack.\r\n<h2>What is code quality?</h2>\r\nTo make myself clear I should explain what I mean by the term code quality:\r\n<ul>\r\n\t<li>Proper structuring of the code\r\n<ul>\r\n\t<li>separation, isolation and \"condensation\" of individual concerns so that one piece of code does one particular thing, which is not done by any other piece of code - thus if you need to change that functionality, you have exactly one place you need to touch</li>\r\n\t<li>short, simple methods, relatively small classes (thanks to not mixing different concerns in the same class) - for long, overly complex classes and methods are very hard to understand and modify</li>\r\n\t<li>minimalization of dependencies between classes and modules so that it is simpler to change any part of the code</li>\r\n</ul>\r\n</li>\r\n\t<li>Readability - expressive method, class and variable names, structuring the code so that it reads as a story - during the lifetime of an enterprise project, many developers will come and go and the code will be read much more often than being written</li>\r\n\t<li>Tests - though not part of the code base directly, unit tests are an enabling and enforcing factor for many code quality characteristics</li>\r\n</ul>\r\nRegarding code quality, I really appreciate Kent Beck’s <a href=\"http://www.c2.com/cgi/wiki?XpSimplicityRules\">Four Simple Design Rules</a>.\r\n<h2>You will pay a lot for neglecting code quality</h2>\r\nIf you don't care for code quality you will end up with spaghetti code, where different concerns (presentation, business logic, security, logging, different business requirements, ...) are so much intertwined that nobody can ever separate them again. Long pieces of code doing thousand different things - the same things at many places via copy&amp;paste programming - containing complicated, multi-level if-else statements, preferably using magic constants and mysteriously named variables, blocks of code without any clear purpose that nobody knows what they are good for but nobody dares to remove them... . Changing anything in such code is highly risky because often you need to change it at many places (which you don't know about). Trying to understand the code will take you lot of time with the likely result that your brain will burn before you manage to grasp what, why, and how the code is doing. You run a high risk of inadverently breaking something and because you have no unit tests - and cannot create any because the code has no units, it is an organic, amorphic beast - there is nothing to notify you about the problem unless it is too late.<br><br>Of course this is worse case scenario, where quality has been neglected both in the large scale, i.e. the architectural structure of the code, and the micro-scale of individual objects and methods. Of those two the first one is worse for it makes it impossible to improve the code part by part but both of them tend to lead to further decay of the code. Developers working on it will learn the wrong habits and contribute further to the fall.<br><br>If the software is being used and further evoled during 5, 10 years, many people will try to work on it, and each of them will struggle with those problems and pay for them with time when trying to understand the code, when trying to modify the non-modular, amorphic, copy&amp;paste code absolutely unfit for any evolvability, and finally when hunting bugs caused by those failed attempts. And the time of those people is quite expensive and it is the customer, originaly supposed to profit from the quick hack solutions, who pays the bill.\r\n<h2>Conclusion</h2>\r\nCode quality, especially on the overall structural level, is an essential property of enterprise software, which translates directly to financial losses or gains as the software is further maintained, modified and adjusted. The customer may not understand this for him invisible property and thus it is our duty as techniciants to explain it and care for it. We must strive for good code quality so that the code will be able to live on without rotting over the time. The quality will never be perfect, but it must be good enough - and this is partly measurable with the various <a href=\"http://en.wikipedia.org/wiki/Software_metric\">complexity metrics etc.</a> - and we should follow the uncle Bob's boy scoute rule of code quality: when you are working on a piece of code, return it in a better (and never worse!) state then you got it. That means that you shouldn't hesistate to do small scale improvements when you see an opportunity for them. The result will be that the overall quality of the code will improve over the time instead of decaying, as is usually the case. The wallet of the customer will love you for that.<br><br><strong>Update</strong>: I've stumbled upon a blog documenting some of the abominations you can meet in a no-quality code: <a href=\"http://blog.cherouvim.com/the-worst-codebase-ive-seen-in-my-life/\">The worst codebase I’ve seen in my life</a><br><br><strong>Update 2</strong>: As one of the readers has pointed out, a product with a low-quality code can be very successful, as <a href=\"http://gojko.net/2011/04/05/how-is-it-even-possible-code-to-be-this-bad/\">Gojko Adzic shows on the example of Hudson</a> (I'm very glad I'll be on <a href=\"http://www.meetup.com/oslo-xp/events/17194842/\">his lecture</a> next We - living in Oslo is great :-)). However this can only hold for some time for the constantly growing technical debt will slowly make any change too expensive and will <a href=\"http://gojko.net/2011/04/05/how-is-it-even-possible-code-to-be-this-bad/#comment-125944\">bring the product to its knees</a>. We therefore must convey to the customer the cost of neglecting quality.<br><br>PS: I'd like like to thank Stig for inspiring me to write this post. Talking about traumatic stuff really helps to get over it ;-)",
  "excerpt": ""
 },
 {
  "title": "How to customize CKEditor with your own plugins, skins, configurations",
  "published": "2011-04-04 21:15:06",
  "postType": "post",
  "slug": "/2011/04/04/how-to-customize-ckeditor-with-your-own-plugins-skins-configurations/",
  "status": "publish",
  "tags": [
   "ckeditor"
  ],
  "categories": [
   "General"
  ],
  "content": "This post summarizes what I've learned about customizing the open-source WYSIWYG rich-text editor CKEditor 3.5.2 with one's own plugins, skins, and configurations. There is already a lot of good resources so wherever possible I will link to them and just summarize and/or supplement them. However I've found no overall guide for customizing CKEditor and thus intend to fill this vacancy.\r\n<!--more-->\r\n<h2>Introduction</h2>\r\nCKEditor is a popular rich-text editor implemented in JavaScript. Its architecture makes heavy use of plugins and events and it is very configurable and customizable. Its documentation is thousandfold better than in the 2.x version but still you can't find there everything you might want.<br><br>To try out check the <a href=\"http://ckeditor.com/demo\">CKEditor's demo</a>.\r\n<h2>Customizing CKEditor</h2>\r\n<h3>Layout of the customized CKEditor installation</h3>\r\nThe structure of our customized CKEditor is as follows:\r\n<ul>\r\n\t<li>&lt;my web root&gt;/myckeditor/\r\n<ul>\r\n\t<li>custom_configurations/</li>\r\n\t<li>custom_plugins/</li>\r\n\t<li>custom_skins/</li>\r\n\t<li>editor/ - the original distribution of CKEditor, i.e. the content of ckeditor_3.5.2.zip/ckeditor/\r\n<ul>\r\n\t<li>_samples</li>\r\n\t<li>_source/</li>\r\n\t<li>lang/</li>\r\n\t<li>ckeditor.js</li>\r\n\t<li>ckeditor_source.js</li>\r\n\t<li>...</li>\r\n</ul>\r\n</li>\r\n</ul>\r\n</li>\r\n</ul>\r\n<h3>Custom configurations</h3>\r\nYou will need to change CKEditor's configuration and the best way to do so is perhaps to create your own configuration file, as described on the <a href=\"http://docs.cksource.com/CKEditor_3.x/Developers_Guide/Setting_Configurations\">CKEditor's configuration page</a>. You then tell CKEditor to load it when initializing it:<br><br><pre><code>\r\n&lt;textarea name=&quot;newedittextarea&quot;&gt;initial content...&lt;/textarea&gt;\r\n&lt;script type=&quot;text/javascript&quot; src=&quot;/mywebapproot/myckeditor/editor/ckeditor.js&quot;&gt;&lt;/script&gt;\r\n&lt;script type=&quot;text/javascript&quot;&gt;//&lt;![CDATA[\r\nCKEDITOR.replace('newedittextarea', { &quot;customConfig&quot;: &quot;/mywebapproot/myckeditor/custom_configs/my_config.js&quot; , &quot;RootPath&quot;:&quot;/mywebapproot/&quot;});\r\n//]]&gt;&lt;/script&gt;\r\n</code></pre><br><br>I say \"configurations\" because we had two configurations (and two skins), a normal one and then a child version of the editor (less toolbars, bigger and friendlier icons, ...).<br><br>It's important to notice that the configuration file may contain any JavaScript code (incl. function declaration and use) and access variables and functions defined in the page prior to the inclusion of CKEditor and thus you can dynamically adjust the configuration based on the calling page. Possible use of this is shown in <a href=\"/2011/04/04/ckeditor-hide-some-toolbar-buttons-on-a-per-page-basis/\">CKEditor: Hide some toolbar buttons on a per page basis</a>.<br><br>You also need to be aware of the order of loading of the different configurations (in-page, custom file, in plugins) and ckeditor sources and its plugins (which differ between the production and development mode). So when something doesn't work as expected, make sure that you check the order in which things get applied and overridden.\r\n<h3>Custom skins</h3>\r\nThis is how you create a custom skin based on the default kama skin:\r\n<ol>\r\n\t<li>Copy myckeditor/editor/skins/kama/ (or ../editor/_source/skins/.. if you care more for readability than performance) to myckeditor/custom_skins/my_kama/</li>\r\n\t<li>Use a search &amp; replace tool to replace all occurences of \"kama\" with \"my_kama\" in the copied files (you can do it automatically, no need to manually confirm each of the few hundred replacements)\r\n<ul>\r\n\t<li>Thus you'll have the CSS class cke_skin_my_kama instead of cke_skin_kama etc.</li>\r\n\t<li>This renaming of all the classes is necessary for otherwise there will be conflicts between the default kama skin and the one of yours and things might not work (this applies at least when using the compressed production version of CKEditor, ckeditor.js)</li>\r\n\t<li>It's important to get this step right otherwise CKEditor may fail to load</li>\r\n</ul>\r\n</li>\r\n\t<li>Optional: Add a custom css to the skin:\r\n<ol>\r\n\t<li>Create the CSS, e.g. at myckeditor/custom_skins/my_kama/my_icons/my_icons.css</li>\r\n\t<li>Register it with the skin: In my_kama/skin.js, add it to the appropriate component, in my case it's the editor:\r\n<pre><code>\r\nCKEDITOR.skins.add('my_kama',(function(){var a='cke_ui_color';return{\r\neditor:{css:['my_icons/my_icons.css','editor.css']},dialog:...\r\n</code></pre></li>\r\n</ol>\r\n</li>\r\n\t<li>Tell CKEditor to use the skin: In myckeditor/custom_configs/my_config.js, add:\r\n<pre><code>\r\nvar ckeditorBasePath = CKEDITOR.basePath.substr(0, CKEDITOR.basePath.indexOf(&quot;editor/&quot;));\r\nCKEDITOR.editorConfig = function( config ) {\r\n   ...\r\n   config.skin = 'my_kama,' + ckeditorBasePath + 'custom_skins/my_kama/';\r\n   ...\r\n}\r\n</code></pre></li>\r\n</ol>\r\nCKEditor supports multiple ways of specifying your custom skin and I found this one to be working for me. The property CKEDITOR.basePath used above is set automatically based on the include path of the ckeditor.js file.\r\n<h3>Custom plugins</h3>\r\nCreating custom plugins for CKEditor is a huge topic, we will touch only some parts of it. Refer to the plugin creation section in the Resources for introduction into plugin creation.\r\n<h4>Dialog implementation options</h4>\r\n<h5 id=\"types-of-dialog-implementations\">Different types of dialog implementations</h5>\r\nAs far as I know you can create three types of dialogs with CKEditor 3.5:\r\n<ol>\r\n\t<li>Native dialogs defined with JavaScript only - this is used by all CKEditor's own plugins, check them under _source/plugins</li>\r\n\t<li>IFrame dialogs - the dialog system defines the common elements such as title and Ok/Cancel buttons but the content of the dialog isn't defined by JS but it's an iframe loading another page (see dialog.addIframeDialog and the content type 'iframe'); requires the plugin iframedialog (an example below)</li>\r\n\t<li>Custom dialogs - they do not use the dialog API at all but define a custom command whose exec function displays a new window/jQuery dialog/whatever you want and pass results back using standard CKEditor methods - see <a href=\"http://www.mikee.se/Archive.aspx/Details/plugin_existing_code_into_ckeditor_20100201\">[Eliasson10]</a></li>\r\n</ol>\r\nIFrame plugin example (showing only the dialog as there is nothing special in the plugin.js; config.RootPath is our custom config option set during the creation of the editor):<br><br><pre><code>\r\n// myckeditor/custom_plugins/my_plugin/dialogs/my_plugin.js:\r\nCKEDITOR.dialog.add( 'my_plugin', function( editor ) {\r\n   return {\r\n      title : 'My IFrame Plugin', minWidth : 390, minHeight : 230,\r\n      contents : [ {\r\n            id : 'tab1', label : '', title : '', expand : true, padding : 0,\r\n            elements : [ {\r\n                   type : 'iframe',\r\n                   src : editor.config.RootPath + 'myCustomDialog.phtml',\r\n                   width : 538, height : 478 - (CKEDITOR.env.ie ? 10 : 0)\r\n            } ]\r\n      } ]\r\n      , buttons : []   // don't show the default buttons\r\n   };\r\n} );\r\n</code></pre>\r\n<h5>Dialog's on OK handler options</h5>\r\nThe standard dialog API defines among others the events 'ok' and 'cancel' triggered when the corresponding dialog button is pressed (only available for native and iframe dialogs). You can (re)define their handler in two ways:\r\n<ol>\r\n\t<li>In the dialog definition function via \"<code>, onOk: function(event) {... /* using this.<a href=\"http://docs.cksource.com/ckeditor_api/symbols/CKEDITOR.dialog.html#getParentEditor\">getParentEditor()</a>*/}</code>\"</li>\r\n\t<li>Outside of the dialog definition, for example inside a dialog iframe (option #2 above) by registering and deregistering the listener via <code>CKEDITOR.dialog.getCurrent().on(\"ok\", okListener)</code> and <code>CKEDITOR.dialog.getCurrent().removeListener(\"ok\", okListener);</code> (okListener being a function reference). To access the editor:\r\n<pre><code>\r\nvar editor = window.parent.CKEDITOR.dialog.getCurrent()._.editor;\r\n</code></pre></li>\r\n</ol>\r\n<h4>How to add a custom plugin</h4>\r\n<a id=\"Registering_the_plugin_with_CKEditor_.26_enabling_it\" name=\"Registering_the_plugin_with_CKEditor_.26_enabling_it\"></a>\r\n<h5>Registering the plugin with CKEditor &amp; enabling it</h5>\r\nIn the custom CKEditor configuration file (myckeditor/custom_configs/my_config.js):\r\n<h6>1. Register the plugin:</h6>\r\n<pre><code>\r\nvar ckeditorBasePath = CKEDITOR.basePath.substr(0, CKEDITOR.basePath.indexOf(&quot;editor/&quot;));\r\nvar customPluginsRoot = ckeditorBasePath + 'custom_plugins/';<br><br>CKEDITOR.plugins.addExternal('my_plugin',customPluginsRoot+'my_plugin/', 'plugin.js');\r\nCKEDITOR.plugins.addExternal('another_custom_plugin',customPluginsRoot+'another_custom_plugin/', 'plugin.js');<br><br>CKEDITOR.editorConfig = function( config )\r\n{\r\n   ...\r\n</code></pre><br><br>Comments:\r\n<ul>\r\n\t<li>the first argument is the plugin name, as defined in its plugin.js (normally equal to its folder name)</li>\r\n\t<li>the second argument is the path to the plugin folder</li>\r\n\t<li>the third argument is always 'plugin.js'</li>\r\n</ul>\r\nThere are also other ways to call <a href=\"http://docs.cksource.com/ckeditor_api/symbols/CKEDITOR.resourceManager.html#addExternal\">CKEDITOR.plugins.addExternal</a> (borrowed from the ResourceManager) but this one has worked for us.\r\n<h6>2. Enable the plugin:</h6>\r\n<pre><code>\r\nCKEDITOR.editorConfig = function( config ) {\r\n   ...\r\n   config.extraPlugins = 'my_plugin,another_custom_plugin';\r\n  ...\r\n}\r\n</code></pre><br><br>Comments:\r\n<ul>\r\n\t<li>just specify the name of the (registered) plugin in a comma-separated string</li>\r\n</ul>\r\n<h6>3. Add it to the toolbar:</h6>\r\n<pre><code>\r\nCKEDITOR.editorConfig = function( config ) {\r\n   ...\r\n    config.toolbar_Default = [\r\n        ['Preview', 'Source','Link'],['MyPlugin', 'AnotherCustomPlugin']\r\n    ];\r\n   ...\r\n}\r\n</code></pre><br><br>Comments:\r\n<ul>\r\n\t<li>The name, 'MyPlugin', is the CKEDITOR.ui.button name specified as the first parameter to editor.ui.addButton in plugin.js. It is not the plugin name (my_plugin) - see below.</li>\r\n</ul>\r\n<a id=\"Plugin_structure_and_naming\" name=\"Plugin_structure_and_naming\"></a>\r\n<h5>Plugin structure and naming</h5>\r\nFiles:\r\n<ul>\r\n\t<li>custom_plugins/plugin_name/\r\n<ul>\r\n\t<li>plugin.js</li>\r\n\t<li>dialogs/plugin_name.js</li>\r\n</ul>\r\n</li>\r\n</ul>\r\nSample plugin.js for the my_plugin plugin:<br><br><pre><code>\r\nCKEDITOR.plugins.add( 'my_plugin',\r\n{\r\n   requires : [ 'iframedialog' ],\r\n   init : function( editor )\r\n   {\r\n      var command = editor.addCommand( 'my_plugin', new CKEDITOR.dialogCommand( 'my_plugin' ) );<br><br>      editor.ui.addButton( 'MyPlugin',\r\n         {\r\n         label : 'ids:My label...',\r\n         command : 'my_plugin'\r\n      });<br><br>      CKEDITOR.dialog.add( 'my_plugin', this.path + 'dialogs/my_plugin.js' );\r\n   }\r\n});\r\n</code></pre><br><br>Comments:\r\n<ul>\r\n\t<li>the names of the plugin, of its command, and of its dialog are all my_plugin</li>\r\n\t<li>the name of the plugin's toolbar button is MyPlugin - this may be added to config.toolbar_{name} in the ckeditor configuration</li>\r\n</ul>\r\nSample iframe plugin dialog:<br><br><pre><code>\r\n// myckeditor/custom_plugins/my_plugin/dialogs/my_plugin.js:\r\nCKEDITOR.dialog.add( 'my_plugin', function( editor ) {\r\n   return {\r\n      title : 'My IFrame Plugin', minWidth : 390, minHeight : 230,\r\n      contents : [ {\r\n            id : 'tab1', label : '', title : '', expand : true, padding : 0,\r\n            elements : [ {\r\n                   type : 'iframe',\r\n                   src : editor.config.RootPath + 'myCustomDialog.phtml',\r\n                   width : 538, height : 478 - (CKEDITOR.env.ie ? 10 : 0)\r\n            } ]\r\n      } ]\r\n      , buttons : []   // don't show the default buttons\r\n   };\r\n} );\r\n</code></pre><br><br>Comments:\r\n<ul>\r\n\t<li>Nothing special here except of the config option editor.config.RootPath which we set ourselves when instantiating the ckeditor</li>\r\n</ul>\r\n<a id=\"Plugin_toolbar_icon\" name=\"Plugin_toolbar_icon\"></a>\r\n<h5>Plugin toolbar icon</h5>\r\nThere are two ways to assign an icon to your plugin's button: either use the property <em>icon</em> when registering it, pointing to an image, or use the CSS class assigned to the \"button\".\r\n<h6>Using the icon property:</h6>\r\n(Copied from c_schmitz' comment on Voofie's plugin guide):<br><br><pre><code>\r\nCKEDITOR.plugins.add('myplugin',\r\n{\r\n    init: function(editor)\r\n    {\r\n        editor.ui.addButton('myplugin',\r\n            {\r\n                label: 'myplugin',\r\n                command: myplugin,\r\n                icon: CKEDITOR.plugins.getPath('myplugin') + 'myplugin.png'\r\n            });\r\n    }\r\n});\r\n</code></pre>\r\n<h6>Using the CSS class:</h6>\r\nCKEditor automatically assigns the CSS class \"cke_button_\" to toolbar elements representing plugin buttons, the command name being usually the same as the plugin name (e.g. \"cke_button_my_plugin\" for the plugin above) - though you can also<a href=\"http://docs.cksource.com/ckeditor_api/symbols/src/plugins_button_plugin.js.html\"> specify your own class via the className</a> property.<br><br>You then just need to define the class so that it contains a background image, likely from a sprite - see kama/icons.png and kama/editor.css.<br><br>Example custom css in myckeditor/custom_skins/my_kama/my_icons/my_icons.css using the sprite my_kama/my_icons/my_icons.png and registered with the custom skin as described above:<br><br><pre><code>\r\n/* Plugins re-using native CKEditor's icons (the default) */\r\n.cke_button_my_plugin .cke_icon {\r\n    background-position: 0 -528px !important;\r\n}<br><br>/* Plugins using our own icon sprite */\r\n.cke_button_another_custom_plugin .cke_icon {\r\n    background: url(&quot;my_icons.png&quot;) no-repeat scroll 0 -1232px transparent !important;\r\n}\r\n</code></pre><br><br>Comments:\r\n<ul>\r\n\t<li>ckeditor's own icon sprite is loaded as the background image by default, you need to use !important to override it</li>\r\n\t<li>the custom sprite image url is relative to the location of the css file</li>\r\n\t<li>to add this custom CSS to the skin you need to add it its skin.js as described above</li>\r\n</ul>\r\n<h3>Custom language</h3>\r\nCKEditor supports quite a number of languages out of the box and can auto-detect which one to use based on the users' browser settings. You can add a language of your own and tell CKEditor explicitly to use it:\r\n<ol>\r\n\t<li>Create myckeditor/editor/lang/mylanguage.js based e.g. on editor/_source/lang/en.js\r\n<ul>\r\n\t<li>It should include all the keys and certainly it must include all the sub-groups (such as contextmenu: {...}) to avoid errors because of undefined properties.</li>\r\n</ul>\r\n</li>\r\n\t<li>Tell CKEditor that the language is enabled and that it should be used by default:\r\n<pre><code>\r\n// myckeditor/custom_configs/my_config.js:\r\nCKEDITOR.editorConfig = function( config ) {\r\n   ...\r\n   CKEDITOR.lang.languages.mylanguage = 1;\r\n   config.language='mylanguage';\r\n   ...\r\n}\r\n</code></pre></li>\r\n</ol>\r\n(CKEditor will automatically look for mylanguage.js under its lang/ folder.)<br><br>We have actually used our own internationalization system to provide the translation suitable for the current user. It is generated dynamically by a file included before ckeditor.js and producing a JavaScript object in the form expected by CKEditor:<br><br><pre><code>\r\n// myckeditor/generate_mylanguage.js.php:\r\n// ... PHP code here ... - produces JavaScript code similar to this:\r\n// window.GENERATED_LANG = {dir:'ltr', editorTitle:'My Editor', ...};\r\n</code></pre><br><br>The language file mylanguage.js only copies the JavaScript object with translations into the place expected by CKEditor:<br><br><pre><code>\r\n// myckeditor/editor/lang/mylanguage.js:\r\nCKEDITOR.lang['mylanguage'] = GENERATED_LANG;\r\n</code></pre>\r\n<h3>Note on the CKEditor's modes: production vs. development</h3>\r\nIn the production you normally use a compressed version of CKEditor, which contains both the editor and its default plugins in one compressed file, <em>ckeditor.js</em>. On the other hand, during development, you use for the sake of easier debugging and troubleshooting the source version <em>ckeditor_source.js</em>, which reads the files under the _source/ folder. It's important to know that the two versions do not behave exactly the same and thus you need to test with both.<br><br>The main difference I've noticed with CKEditor 3.5.2 is that in the development mode plugins are loaded <em>after</em> the custom configuration file and thus you won't be able to override some of their settings, such as CKEDITOR.config.smiley_descriptions. In the production mode the plugins are loaded together with the editor itself <em>before</em> the custom configuration and thus everything will behave as expected.<br><br>If using both modes, you will need to synchronize same files, such as editor/lang/ with editor/_source/lang/ etc.\r\n<h2>Resources</h2>\r\n<strong>Warning: Some of the resources may be out-of-date. Always check their publication date and the current CKEditor APIs and docs.</strong>\r\n<h3>CKEditor in general</h3>\r\n<ul>\r\n\t<li><a title=\"http://docs.cksource.com/CKEditor_3.x/Developers_Guide/Minimum_Setup\" href=\"http://docs.cksource.com/CKEditor_3.x/Developers_Guide/Minimum_Setup\" rel=\"nofollow\">CKEditor installation - minimal setup</a></li>\r\n\t<li><a title=\"http://www.sayopenweb.com/ckeditor-faq/\" href=\"http://www.sayopenweb.com/ckeditor-faq/\" rel=\"nofollow\">CKEditor FAQ</a></li>\r\n\t<li><a href=\"http://alfonsoml.blogspot.com/2009/09/ckeditor-events.html\">Blog: CKEditor events</a> - description of available global events (I failed to found them in the documentation), example of usage and link to the CKEditor events docs</li>\r\n</ul>\r\n<h3>Building plugins</h3>\r\n<h4>Overall tutorials etc.</h4>\r\n<ul>\r\n\t<li><a href=\"http://www.voofie.com/content/2/ckeditor-plugin-development/\">voofie: CKEditor Plugin Development</a> - a pretty detailed one</li>\r\n\t<li><a href=\"http://syrinx.ph/articles/CkEditorPluginGuide.aspx\">Syrinx: Building Custom CK Editor Plug-ins</a> - incl. plugins with UI in a stand-alone window</li>\r\n\t<li><a href=\"http://cksource.com/forums/viewtopic.php?f=6&amp;t=15539\">discussion: Creating Plugins in CKeditor</a></li>\r\n\t<li><a href=\"http://cksource.com/forums/viewtopic.php?f=11&amp;t=18876\">Tutorial: create external plugin for CKEDITOR</a> - this looks pretty good and it also shows building an iframe dialog plugin (unfortunately without passing data from the dialog back to the editor)</li>\r\n\t<li><a title=\"http://docs.cksource.com/FCKeditor_3.x/Design_and_Architecture/Dialog_System\" href=\"http://docs.cksource.com/FCKeditor_3.x/Design_and_Architecture/Dialog_System\" rel=\"nofollow\">Dialog System (CKeditor 3.x Design and Architecture)</a> - perhaps look over it briefly; unfortunately it misses some interesting topics such as iframe dialogs</li>\r\n</ul>\r\n<h4>Specialized plugin topics</h4>\r\n<ul>\r\n\t<li><a href=\"http://www.mikee.se/Archive.aspx/Details/plugin_existing_code_into_ckeditor_20100201\">[Eliasson10] Plugin existing code into ckeditor</a> - doesn't use the dialog API but a simple command, whose exec function opens a custom dialog and uses the CKEditor's API to pass results back</li>\r\n\t<li><a title=\"http://alfonsoml.blogspot.com/2009/12/plugin-localization-in-ckeditor-vs.html\" href=\"http://alfonsoml.blogspot.com/2009/12/plugin-localization-in-ckeditor-vs.html\" rel=\"nofollow\">Plugin localization in CKEditor (vs FCKeditor)</a></li>\r\n\t<li><a title=\"http://stackoverflow.com/questions/4631852/can-i-control-where-ckeditor-finds-plugins-to-load\" href=\"http://stackoverflow.com/questions/4631852/can-i-control-where-ckeditor-finds-plugins-to-load\" rel=\"nofollow\">StackOverflow: Adding a plugin from an external location to CKEditor</a> (use CKEDITOR.plugins.addExternal)</li>\r\n</ul>\r\n<h4>IFrame dialogs</h4>\r\n<ul>\r\n\t<li><a title=\"http://stackoverflow.com/questions/1937527/variable-outside-event-handlers-scope\" href=\"http://stackoverflow.com/questions/1937527/variable-outside-event-handlers-scope\" rel=\"nofollow\">stackoverflow: Example of an iframe dialog with custom onOk listener</a> - setting a custom ok listener (to the CKEditor-provided OK button) is perhaps the best way to pass values from an iframe dialog back to the editor and it's also the standard way</li>\r\n\t<li><a title=\"http://cksource.com/forums/viewtopic.php?f=11&amp;t=16040&amp;sid=66f9602bb307c119baaae53c508c7788\" href=\"http://cksource.com/forums/viewtopic.php?f=11&amp;t=16040&amp;sid=66f9602bb307c119baaae53c508c7788\" rel=\"nofollow\">Forum: Working with iframe dialog plugins</a> - it's little chaotic and not all information there is true or the best solution possible but still it may be useful regarding how to react to the OK/Cancel buttons and how to pass data from the dialog back to the editor; generally the \"Tutorial: create external plugin for CKEDITOR\" referenced above is a more reliable source</li>\r\n</ul>\r\n<h3>Very special general/plugin topics that may be useful at some point</h3>\r\n<ul>\r\n\t<li><a title=\"http://cksource.com/forums/viewtopic.php?f=11&amp;t=18793\" href=\"http://cksource.com/forums/viewtopic.php?f=11&amp;t=18793\" rel=\"nofollow\">Forum: Inserting (and maintaining fake element placeholders)</a> - two important things here: a) adding a nested iframe to a dialog (CKEDITOR.dialog.addIframe) and b) using placeholder elements for normally content normally \"invisible\" while editing, for instance Flash (dataProcessor and editor.createFakeParserElement)</li>\r\n\t<li><a title=\"http://blog.ale-re.net/2010/06/ckeditor-context-menu.html\" href=\"http://blog.ale-re.net/2010/06/ckeditor-context-menu.html\" rel=\"nofollow\">Custom CKEditor Menu</a></li>\r\n\t<li><a title=\"http://cksource.com/forums/viewtopic.php?f=11&amp;t=18327\" href=\"http://cksource.com/forums/viewtopic.php?f=11&amp;t=18327\" rel=\"nofollow\">Tutorial: Extend the Links dialog to link to internal CMS pages</a></li>\r\n\t<li><a title=\"http://cksource.com/forums/viewtopic.php?f=11&amp;t=20253\" href=\"http://cksource.com/forums/viewtopic.php?f=11&amp;t=20253\" rel=\"nofollow\">Forum: Integration a custom iframe with dialog's OK button</a></li>\r\n\t<li><a title=\"http://cksource.com/forums/viewtopic.php?p=43402#p43402\" href=\"http://cksource.com/forums/viewtopic.php?p=43402#p43402\" rel=\"nofollow\">Adding the function getSelectedHtml to CKEditor</a></li>\r\n</ul>\r\n<h3>Additional unsorted links of interest</h3>\r\n<ul>\r\n\t<li><a title=\"http://alfonsoml.blogspot.com/2009/12/recompressing-ckeditorjs-to-fit-your.html\" href=\"http://alfonsoml.blogspot.com/2009/12/recompressing-ckeditorjs-to-fit-your.html\" rel=\"nofollow\">Recompressing ckeditor.js to fit your needs</a></li>\r\n\t<li><a title=\"http://cksource.com/forums/viewtopic.php?f=11&amp;t=20585&amp;hilit=ASPSpellCheck\" href=\"http://cksource.com/forums/viewtopic.php?f=11&amp;t=20585&amp;hilit=ASPSpellCheck\" rel=\"nofollow\">ASPSpellCheck plugin for CKEditor 3.x</a></li>\r\n\t<li><a title=\"http://alfonsoml.blogspot.com/2011/01/avoiding-extra-request-for-translation.html\" href=\"http://alfonsoml.blogspot.com/2011/01/avoiding-extra-request-for-translation.html\" rel=\"nofollow\">Blog: Avoiding extra request for the translation of a CKEditor plugin</a> - include translations directly in plugin.js</li>\r\n</ul>\r\n<h3>My other related blog posts</h3>\r\n<ul>\r\n\t<li><a href=\"/2011/04/04/ckeditor-hide-some-toolbar-buttons-on-a-per-page-basis/\">CKEditor: Hide some toolbar buttons on a per page basis</a></li>\r\n\t<li><a title=\"Permanent link to CKEditor: Collapsing only 2nd+ toolbar rows – howto\" href=\"/2011/04/01/ckeditor-collapsing-only-2nd-toolbar-rows-howto/\" rel=\"bookmark\">CKEditor: Collapsing only 2nd+ toolbar rows – howto</a></li>\r\n\t<li><a title=\"Permanent link to CKEditor: Scroll dialogs with the page, i.e. not fixed to the middle\" href=\"/2011/03/31/ckeditor-scroll-dialogs-with-page/\" rel=\"bookmark\">CKEditor: Scroll dialogs with the page, i.e. not fixed to the middle</a></li>\r\n\t<li><a title=\"Permanent link to Upgrading FCKeditor 2.x to CKEditor 3.x including plugins\" href=\"../2011/05/06/upgrading-fckeditor-2-x-to-ckeditor-3-x-including-plugins/\" rel=\"bookmark\">Upgrading FCKeditor 2.x to CKEditor 3.x including plugins</a> (+ a decoupling facade)</li>\r\n</ul>\r\n<h2>Post scriptum</h2>\r\nI'd like to thank my employer, <a href=\"http://iterate.no/\">Iterate AS</a>, for supporting me in writing this blog post and our client for giving me the opportunity to learn all this stuff.",
  "excerpt": ""
 },
 {
  "title": "CKEditor: Hide some toolbar buttons on a per page basis",
  "published": "2011-04-04 21:11:54",
  "postType": "post",
  "slug": "/2011/04/04/ckeditor-hide-some-toolbar-buttons-on-a-per-page-basis/",
  "status": "publish",
  "tags": [
   "ckeditor"
  ],
  "categories": [
   "General"
  ],
  "content": "In my project we had CKEditor with a common toolbar used on many pages and we needed to be able to hide some of the buttons on some pages (e.g. email editor didn't support some functionality/content). It took me a long time to figure a way to do it for CKEditor has no methods for simply removing/hiding buttons from a toolbar. My solution uses the fact that the configuration file can see variables defined in the including page and that it can contain functions - namely there is a function which takes the default toolbar definition and removes from it all the buttons mentioned in a variable, which is expected to be defined in the page.<br><br><!--more--><br><br>The page:\r\n<pre><code>\r\n...\r\n&lt;script type=&quot;text/javascript&quot;&gt;\r\n   // This must be defined before including ckeditor.js:\r\n   var removeButtons = &quot;Link,Preview&quot;;\r\n&lt;/script&gt;\r\n&lt;script type=&quot;text/javascript&quot; src=&quot;/mywebapproot/myckeditor/editor/ckeditor.js&quot;&gt;&lt;/script&gt;\r\n...\r\n</code></pre><br><br>My custom CKEditor configuration .js:\r\n<pre><code>\r\nfunction removeUnwantedTools( toolbar )\r\n{\r\n    if (typeof(removeButtons) == &quot;undefined&quot;) { return toolbar; }<br><br>    var filteredTools = new Array();\r\n    for(var i = 0, len = toolbar.length; i &lt; len; i++)\r\n    {\r\n        var element = toolbar[i];\r\n        if (element instanceof Array)\r\n        {\r\n            filteredTools.push(\r\n                removeUnwantedTools(element)); //perhaps don't add if empty\r\n        }\r\n        else if (removeButtons.indexOf(element) == -1)\r\n        {\r\n            filteredTools.push(element);\r\n        }\r\n        // else just ignore the element present on the removeButtons list\r\n    }\r\n    return filteredTools;\r\n}<br><br>CKEDITOR.editorConfig = function( config ) {\r\n   ...\r\n    config.toolbar_Default = removeUnwantedTools([\r\n        ['Preview', 'Source','Link'],['MyPlugin', 'AnotherCustomPlugin']\r\n    ]);\r\n   ...\r\n}\r\n</code></pre><br><br>The result will be that this plugin will only have the buttons [['Source'],['MyPlugin', 'AnotherCustomPlugin']].<br><br>It is not completely fool-proof but worked well for me.",
  "excerpt": ""
 },
 {
  "title": "Upgrading FCKeditor 2.x to CKEditor 3.x including plugins",
  "published": "2011-05-06 09:35:49",
  "postType": "post",
  "slug": "/2011/05/06/upgrading-fckeditor-2-x-to-ckeditor-3-x-including-plugins/",
  "status": "publish",
  "tags": [
   "ckeditor"
  ],
  "categories": [
   "General"
  ],
  "content": "Upgrading FCKEditor 2.x with custom plugins to CKEditor 3.x is a challenging task because so much has changed but it is possible. I'd like to share here few experiences from the upgrade and show how to map the most important API use cases from the old to the new version and ease the migration by first introducing a facade for (F)CKEditor APIs.\r\n<!--more-->\r\n<h2>The differences</h2>\r\nCKEditor 3.x is a great improvement over FCKEditor 2.x, mainly thanks to its modularity and much improved - though sometimes still lacking - documentation. There are large differences between the two:\r\n<ol>\r\n\t<li>The API has changed considerably</li>\r\n\t<li>The configuration options have changed, fortunately the develpers have provided a <a href=\"http://docs.cksource.com/CKEditor_3.x/Developers_Guide/FCKeditor_CKEditor_Configuration_Mapping\">configuration mapping document</a> to help with the upgrade</li>\r\n\t<li>Plugin dialogs don't use HTML anymore but are defined in JavaScript, dialogs aren't iframes anymore</li>\r\n\t<li>The HTML structure has changed a lot and thus it's practically impossible to migrate a custom skin to the new version, you have to re-create it from scratch</li>\r\n\t<li>Localization keys are different too so it takes an effort to migrate a custom translation</li>\r\n</ol>\r\n<h2>Upgrading the editor</h2>\r\nUpgrading the editor was quite easy for even though some things have changed, the way it is used and configured is pretty much the same. We use (F)CKEditor's PHP integration wrapped with our own class so we just needed to re-write the wrapper to support the new version, which was quite simple.\r\n<h2>Upgrading/migrating plugins</h2>\r\nDue to the numerous changes (dialog definition, editor API, localization, dropped iframes) it isn't trivial to migrate a plugin. You've a couple of options:\r\n<ol>\r\n\t<li>Re-write the plugin from scratch, perhaps based on an existing CKEditor plugin</li>\r\n\t<li>Drop the plugin and use a similar one for CKEditor - that was our case with the Smiley plugin, for the 3.x version is much more configurable and we therefore haven't needed to customize it anymore\r\n<ul>\r\n\t<li>\"The architecture in CKEditor allows for very flexible customization of the contents of the dialogs without any need to change the source files.\" - see the <a href=\"http://docs.cksource.com/CKEditor_3.x/Developers_Guide/Dialog_Customization\">Dialog Customization doc</a></li>\r\n</ul>\r\n</li>\r\n\t<li>Reuse your plugin's HTML via a <a title=\"How to customize CKEditor with your own plugins, skins, configurations\" href=\"/2011/04/04/how-to-customize-ckeditor-with-your-own-plugins-skins-configurations/#types-of-dialog-implementations\">custom dialog or an iframe dialog</a>, replacing FCKEditor API calls with their CKEditor versions</li>\r\n</ol>\r\nWe've applied all three approaches but mostly the last one for lot of our plugins actually just delegated the work to another page using an iframe. In this case you need to handle localization of the page for the method FCKLanguageManager.TranslatePage doesn't exist anymore and you need to map the old API calls to the new one.\r\n<h3>Mapping FCKEditor 2.x API to CKEditor 3.x</h3>\r\nTo ease the migration from FCKEditor to CKEditor and to protect our code from similar changes in the future I've created a facade, which provides a simplified API to our code and internally calls the proper FCKEditor or CKEditor functions.<br><br>(I should mention that I'm no expert on CKEditor and especially CKEditor so there are certainly better ways to do many things. Also, the facade covers only the needs we had and not the full range of (F)CKEditor's functionality.)\r\n<h3>An overview of the facade</h3>\r\n<ul>\r\n\t<li>The facade provides two public classes:\r\n<ul>\r\n\t<li>CKEDITOR_FACADE - the facade entry point, provides e.g. the functions getEditorContent, closeDialog, initialized</li>\r\n\t<li>CKEDITOR_FACADE.editorContent - API for manipulating the content of the rich text editor, provides e.g. the functions getSelectedElement, getSelectedText, insertElement, updateElement, insertElementHtml</li>\r\n</ul>\r\n</li>\r\n\t<li>There are two implementations of the facade and its editorContent, one for each supported editor (FCKEditor 2.x, CKEditor 3.x), which one to use is detected automatically based on the available window properties set by the editors</li>\r\n\t<li>The facade is only expected to be used and only works from the context of an editor popup dialog or a page included in a dialog via an iframe</li>\r\n</ul>\r\n<h3>How to use the facade</h3>\r\n1. Include the javascript file:\r\n<pre> &lt;script type='text/javascript' src='/path/to/ckeditor_facade.js'&gt;&lt;/script&gt;</pre>\r\n2. Verify that it is initialized, i.e. one of the 2 implementations is available:\r\n<pre> var editorContent = CKEDITOR_FACADE.initialized()? CKEDITOR_FACADE.getEditorContent() : null;</pre>\r\n3. Use it! Examples:\r\n<ul>\r\n\t<li>Close the dialog:\r\n<pre><code>\r\nif (CKEDITOR_FACADE.initialized()) { CKEDITOR_FACADE.closeDialog(); }\r\n</code></pre></li>\r\n\t<li>Insert a new element:\r\n<pre><code>\r\nvar oLink = editorContent.insertElement('a', 'click me!');\r\neditorContent.updateElement(oLink, {href: 'http://goo.gl/', target:'_blank'});\r\n</code></pre></li>\r\n\t<li>Update the selected element (of a particular type):\r\n<pre><code>\r\nvar oLink = editorContent.getSelectedElement('a');\r\neditorContent.updateElement(oLink, {href: newUri});\r\n</code></pre></li>\r\n</ul>\r\nThe facade exposes only a small subset of the available functionality but it was enough for us.\r\n<h3>The facade's code - ckeditor_facade.js</h3>\r\nThe interface of the facade itself:<br><br><pre><code>\r\nif (typeof(window.CKEDITOR_FACADE) == 'undefined' )\r\n{\r\n   window.CKEDITOR_FACADE = (function()\r\n   {\r\n        var _impl = null;<br><br>      var CKEDITOR_FACADE =\r\n      /** @lends CKEDITOR_FACADE */\r\n      {\r\n            _initialize : function(facadeImplementation) {_impl = facadeImplementation;}\r\n            ,<br><br>            /**\r\n             * The callbeck will be called with an instance of\r\n             * CKEDITOR_FACADE.editorContent when the dialog OK button is pressed.\r\n             * @param {function}\r\n             * @see CKEDITOR_FACADE.editorContent\r\n             */\r\n            setOnOkCallback : function(onOkCallback) {_impl.setOnOkCallback(onOkCallback)}\r\n            ,\r\n            getEditorContent : function() {return _impl.getEditorContent()}\r\n            ,\r\n            closeDialog : function() {_impl.closeDialog()}\r\n            ,\r\n            initialized : function() {return _impl != null}\r\n      };<br><br>      return CKEDITOR_FACADE;\r\n   })();\r\n</code></pre><br><br>The interface of the editorContent facade:<br><br><pre><code><br><br>    /**\r\n     * Facade for an editor instance available in the callbacks,\r\n     * used to add content to the editor and to update existing\r\n     * (selected) content.\r\n     *\r\n     * If it doesn't support something you need then you should add\r\n     * an appropriate method.\r\n     *\r\n     * Note: The actual implementations are provided by subclasses.\r\n     */\r\n    CKEDITOR_FACADE.editorContent = function(wrappedEditor)\r\n    {\r\n        this.wrappedEditor = wrappedEditor;\r\n    }<br><br>    CKEDITOR_FACADE.editorContent.prototype =\r\n    {\r\n        /**\r\n         * Insert HTML representing a single element\r\n         * into the current selection or where the cursor is.\r\n         * @param {string} html code\r\n         * @return nothing\r\n         */\r\n        insertElementHtml : function(html) {},\r\n        /**\r\n         * Get the currently selected element (or the one selection is inside of).\r\n         * @param {string} elementName - name of the html element, e.g. 'a'\r\n         * @return {Object} the element or null if not selected\r\n         */\r\n        getSelectedElement : function(elementName) {},\r\n        /**\r\n         * Update the given element with the new attributes,\r\n         * removing all existing ones first.\r\n         * @param {Object} element the existing element\r\n         * @param {Object} newAttributes An object containing the names and\r\n         *      values of the attributes.\r\n         * @return the input element\r\n         * @example\r\n         * var element = editorContent.getSelectedElement();\r\n         * &lt;strong&gt;editorContent.updateElement(element, {\r\n         *     'class' : 'myClass',\r\n         *     'title' : 'This is an example' })&lt;/strong&gt;;\r\n         */\r\n        updateElement : function(element, newAttributes) {},\r\n        /**\r\n         * Insert a new element of the given name and return it.\r\n         * @param {string} elementName - name of the html element, e.g. 'a'\r\n         * @param {string} (optional) inner html to be set\r\n         * @return {Object} the element created\r\n         */\r\n        insertElement : function(elementName, innerHtml) {},\r\n        /** Returns the currently selected text or null */\r\n        getSelectedText : function() {}\r\n    }\r\n</code></pre>\r\n<h4>CKEditor 3.x implementation</h4>\r\nFacade's CKEditor implementation\r\n<ul>\r\n\t<li>we first define the class, its constructor taking the global CKEDITOR object</li>\r\n\t<li>then we define the static method which tries to find out whether CKEDITOR instance is somewhere around and if it is then it instantiates this facade implementation</li>\r\n\t<li>the method getEditorContent tries to locate the actual instance of CKEditor editor to be used and instantiates an editorContent for it.</li>\r\n</ul>\r\n<pre><code>\r\n    CKEDITOR_FACADE.facade_CKEditor35Impl = function(editorClass) {\r\n        this.CKEDITOR_SINGLETON = editorClass;\r\n    }<br><br>    /**\r\n     * Create an instance if the base editor is defined.\r\n     * @private\r\n     * @static\r\n     */\r\n    CKEDITOR_FACADE.facade_CKEditor35Impl.instantiateIfAvailable = function()\r\n    {\r\n        var ckeditorDefined = typeof(window.parent.CKEDITOR) != 'undefined';\r\n        if (!ckeditorDefined) return null;<br><br>        var CKEDITOR = window.parent.CKEDITOR;\r\n        var insideCkDialog = ckeditorDefined?\r\n            (typeof(CKEDITOR.dialog) != 'undefined')\r\n            : false;<br><br>        if (insideCkDialog) return new CKEDITOR_FACADE.facade_CKEditor35Impl(CKEDITOR);\r\n        else return null;\r\n    }<br><br>    CKEDITOR_FACADE.facade_CKEditor35Impl.prototype = (function()\r\n    {<br><br>        return /** @lends CKEDITOR_FACADE.facade_CKEditor35Impl.prototype */ {\r\n            editorContent : null\r\n            ,\r\n            getEditorContent : function(){\r\n                if (this.editorContent == null)\r\n                {\r\n                    var editorSingleton = this.CKEDITOR_SINGLETON; // inside callbacks this referes to a dialog\r\n                    var dialog = editorSingleton.dialog.getCurrent();\r\n                    var editorInstance = dialog._.editor;\r\n                    var editorContent = new CKEDITOR_FACADE.editorContent_CKEditor35Impl(editorInstance, editorSingleton);\r\n                    this.editorContent = editorContent;\r\n                }\r\n                return this.editorContent;\r\n            }\r\n            ,\r\n            setOnOkCallback : function(onOkCallback)\r\n            {\r\n                // Copy fields of this: inside callbacks this referes to dialog\r\n                var editorSingleton = this.CKEDITOR_SINGLETON;\r\n                var editorContent = this.getEditorContent();<br><br>                var okListener = function(event)\r\n                {\r\n                    // Note: this is an instance of CKEDITOR.dialog\r\n                    onOkCallback(editorContent);\r\n                    editorSingleton.dialog.getCurrent().removeListener(&quot;ok&quot;, okListener);\r\n                };<br><br>                editorSingleton.dialog.getCurrent().on(&quot;ok&quot;, okListener); // only defined inside a dialog window\r\n            }\r\n            ,\r\n            closeDialog : function()\r\n            {\r\n                this.CKEDITOR_SINGLETON.dialog.getCurrent().hide();\r\n            }\r\n    };\r\n   })();\r\n</code></pre><br><br>EditorContent's CKEditor implementation\r\n<ul>\r\n\t<li>the implementation extends CKEDITOR_FACADE.editorContent and therefore its constructor calls first the parent's constructor and then it stores a reference to the global CKEDITOR object</li>\r\n</ul>\r\n<pre><code>\r\n    /**\r\n     * NEW CKEDITOR 3.5 IMPLEMENTATION OF CKEDITOR_FACADE.editorContent\r\n     */\r\n    CKEDITOR_FACADE.editorContent_CKEditor35Impl = function(wrappedEditor, editorSingleton)\r\n    {\r\n        CKEDITOR_FACADE.editorContent.call(this, wrappedEditor);\r\n        this.CKEDITOR_SINGLETON = editorSingleton;\r\n    }<br><br>    CKEDITOR_FACADE.editorContent_CKEditor35Impl.prototype =\r\n    {\r\n        insertElementHtml : function(elementHtml)\r\n        {\r\n            var element = this.CKEDITOR_SINGLETON.dom.element.createFromHtml(elementHtml);\r\n            this.wrappedEditor.insertElement(element);\r\n        }\r\n        ,\r\n        /**\r\n         * Return the (surrounding) selected element of the given name or null.\r\n         *\r\n         * Copied from CKEDITOR.plugins.link.getSelectedLink and adjusted.\r\n         */\r\n        getSelectedElement : function(elementName)\r\n        {\r\n            try\r\n            {\r\n                var selection = this.wrappedEditor.getSelection();\r\n                if ( selection.getType() == this.CKEDITOR_SINGLETON.SELECTION_ELEMENT )\r\n                {\r\n                    var selectedElement = selection.getSelectedElement();\r\n                    if ( selectedElement.is(elementName) )\r\n                        return selectedElement;\r\n                }<br><br>                // Handle cases like &quot;[&lt;a href=&quot;...&quot;&gt;li]nk&lt;/a&gt;&quot; ([..] is the selection)\r\n                var range = selection.getRanges(true)[0];\r\n                range.shrink( this.CKEDITOR_SINGLETON.SHRINK_TEXT );\r\n                var root = range.getCommonAncestor();\r\n                return root.getAscendant(elementName, true);\r\n            }\r\n            catch( e ) {return null;}\r\n        }\r\n        ,\r\n        updateElement : function(element, newAttributes)\r\n        {\r\n            // element shall be CKEDITOR.dom.element\r\n            element.removeAttributes(newAttributes);<br><br>            // !!! It seems that CKEditor ignores href and only\r\n            // changes the link's href according to the attribute data-cke-saved-href\r\n            if(newAttributes.href)\r\n            {\r\n                newAttributes['data-cke-saved-href'] = newAttributes.href;\r\n            }\r\n            element.setAttributes(newAttributes);<br><br>            return element;\r\n        }\r\n        ,\r\n        insertElement : function(elementName, innerHtml)\r\n        {\r\n            var element = new this.CKEDITOR_SINGLETON.dom.element(elementName);\r\n            if (typeof(innerHtml) != 'undefined') {\r\n                element.setHtml(innerHtml);\r\n            }\r\n            this.wrappedEditor.insertElement(element);\r\n            return element;\r\n        }\r\n        ,\r\n        getSelectedText : function()\r\n        {\r\n            try\r\n            {\r\n                var mySelection = this.wrappedEditor.getSelection();<br><br>                if (this.CKEDITOR_SINGLETON.env.ie) {\r\n                    mySelection.unlock(true);\r\n                    return mySelection.getNative().createRange().text.toString();\r\n                } else {\r\n                    return mySelection.getNative().toString();\r\n                }<br><br>            }\r\n            catch( e ) {return null;}\r\n        }\r\n    }\r\n</code></pre>\r\n<h4>FCKEditor 2.x implementation</h4>\r\nFacade's FCKEditor implementation<br><br><pre><code>\r\n    CKEDITOR_FACADE.facade_FCKEditor2xImpl = function(editorClass) {\r\n        this.FCKEDITOR = editorClass;\r\n    }<br><br>    /**\r\n     * Create an instance if the base editor is defined.\r\n     * @private\r\n     * @static\r\n     */\r\n    CKEDITOR_FACADE.facade_FCKEditor2xImpl.instantiateIfAvailable = function()\r\n    {\r\n        var fckDialogWindow = window.parent;\r\n        var editorInstance = null; // window with url similar to /editor/fckeditor.html?InstanceName=raw_body&amp;Toolbar=Default\r\n        if (typeof fckDialogWindow.oEditor != 'undefined')\r\n        {\r\n            editorInstance = window.parent.oEditor;\r\n        }\r\n        else if (typeof(fckDialogWindow.InnerDialogLoaded) == 'function') // try to load it ...\r\n        {\r\n            editorInstance = fckDialogWindow.InnerDialogLoaded();\r\n        }<br><br>        return editorInstance?\r\n            new CKEDITOR_FACADE.facade_FCKEditor2xImpl(editorInstance)\r\n            : null;\r\n    }<br><br>    CKEDITOR_FACADE.facade_FCKEditor2xImpl.prototype =\r\n    {\r\n        getEditorContent : function()\r\n        {\r\n            return new CKEDITOR_FACADE.editorContent_FCKEditor2xImpl(this.FCKEDITOR);\r\n        }\r\n        ,\r\n        setOnOkCallback : function(onOkCallback)\r\n        {\r\n            //@todo implement this if it is to be used\r\n        }\r\n        ,\r\n        closeDialog : function()\r\n        {\r\n            if (typeof(window.parent.dialog) != 'undefined')\r\n            {\r\n                window.parent.dialog.Cancel(); // normal situation\r\n            }\r\n            else if (typeof(window.parent.Cancel) == 'function')\r\n            {\r\n                window.parent.Cancel();\r\n            }<br><br>        }\r\n    }\r\n</code></pre><br><br>EditorContent's FCKEditor implementation<br><br><pre><code>\r\n    /**\r\n     * OLD FCKEDITOR 2.x IMPLEMENTATION OF CKEDITOR_FACADE.editorContent\r\n     */\r\n    CKEDITOR_FACADE.editorContent_FCKEditor2xImpl = function(wrappedEditor)\r\n    {\r\n        CKEDITOR_FACADE.editorContent.call(this, wrappedEditor);\r\n    }<br><br>    CKEDITOR_FACADE.editorContent_FCKEditor2xImpl.prototype =\r\n    {\r\n        _getDialog : function()\r\n        {\r\n            //The dialog window is an iframe with src=fckdialog.html\r\n            var dialogWindow = window.parent;\r\n            while(typeof(dialogWindow.FCKDialog) == 'undefined' &amp;&amp; dialogWindow.parent != dialogWindow)\r\n            {\r\n                dialogWindow = dialogWindow.parent;\r\n            }\r\n            return dialogWindow;\r\n        }\r\n        ,\r\n        insertElementHtml : function(elementHtml)\r\n        {\r\n            this.wrappedEditor.FCK.InsertHtml(elementHtml);\r\n        }\r\n        ,\r\n        //@see fckeditor/editor/dialog/fck_link/fck_link.js\r\n        getSelectedElement : function(elementName)\r\n        {\r\n            var oLink = this._getDialog().Selection.GetSelection().MoveToAncestorNode(elementName.toUpperCase()) ;\r\n            if (oLink) this.wrappedEditor.FCK.Selection.SelectNode(oLink) ;\r\n            return oLink;\r\n        }\r\n        ,\r\n        insertElement : function(elementName, innerHtml)\r\n        {\r\n            var element = this.wrappedEditor.FCK.InsertElement(elementName);\r\n            if(typeof(innerHtml) != 'undefined')\r\n            {\r\n                element.innerHTML = innerHtml;\r\n            }\r\n            return element;\r\n        }\r\n        ,\r\n        updateElement : function(element, newAttributes)\r\n        {\r\n            // element shall be an HTMLAnchorElement\r\n            /*var currentAttributes = new Array();\r\n            for (i = element.attributes.length - 1; i &gt;= 0; --i)\r\n            {\r\n                var attName = element.attributes[i].name;\r\n                element.removeAttribute( attName, 0 ) ;         // 0 : Case Insensitive\r\n            }*/\r\n            var caseSensitive = 0; // not c.s.<br><br>            // COPIED PATCH (applies to links): Save the innerHTML (IE changes it if it is like an URL).\r\n            var storedInnerHtml = null;\r\n            if (element.tagName.toLowerCase() == 'a') storedInnerHtml = element.innerHTML;<br><br>            for ( var name in newAttributes )\r\n            {\r\n                var attValue = newAttributes[ name ];<br><br>                if ( attValue == null || attValue.length == 0 ) element.removeAttribute( name, caseSensitive ) ;\r\n            else element.setAttribute( name, attValue, caseSensitive );\r\n            }<br><br>            // COPIED PATCH: restore html\r\n            if (storedInnerHtml) element.innerHTML = storedInnerHtml;      // Set (or restore) the innerHTML<br><br>            return element;\r\n        }\r\n        ,\r\n        getSelectedText : function()\r\n        {\r\n            try\r\n            {\r\n                var editorWindow = this.wrappedEditor.FCK.EditorWindow;\r\n                var selection = (editorWindow.getSelection\r\n                    ? editorWindow.getSelection()\r\n                    : editorWindow.selection);<br><br>                if (selection.createRange) {\r\n                    return selection.createRange().text.toString();\r\n                } else {\r\n                    return selection.toString();\r\n                }\r\n            }\r\n            catch( e ) {return null;}\r\n        }\r\n    }\r\n</code></pre>\r\n<h4>Instantiation of the proper implementation</h4>\r\nThe instantiation of the proper implementation - FCK or CK - happens at the very end of the file (after all the classes have been defined):<br><br><pre><code>\r\n    CKEDITOR_FACADE._initialize((function ()\r\n        {\r\n            var error = &quot;CKEDITOR_FACADE: Neither CKEditor 3.x nor FCKEditor 2.x instance found. \\\r\n    Make sure that this is called from a child dialog window/iframe of a window containing (F)CKEditor.&quot;;<br><br>            try {\r\n                // ! The order (ckeditor 1st, fckeditor 2nd) is important if you use\r\n                // both on the same page for only ckeditor checks for being in ckeditor dialog window\r\n                var facade = CKEDITOR_FACADE.facade_CKEditor35Impl.instantiateIfAvailable();<br><br>                // Try the old implementation if the new one unavailable:\r\n                if (facade == null)\r\n                {\r\n                    facade = CKEDITOR_FACADE.facade_FCKEditor2xImpl.instantiateIfAvailable();\r\n                }<br><br>                // Fail if neither new nor old (F)CKEditor found\r\n                if (facade == null)\r\n                {\r\n                    // fireBug log\r\n                    if (typeof(console) != 'undefined') console.error(error+&quot; This window:&quot;, window);\r\n                    else throw new Error(error);\r\n                }<br><br>                return facade;\r\n            } catch(e) {\r\n                alert(error+&quot; Error:&quot;+e);\r\n                return null;\r\n            }\r\n        }) ());<br><br>} /* if CKEDITOR undefined */\r\n</code></pre>\r\n<h4>Re-implementation of FCKEditor's utility methods</h4>\r\nFCKEditor had some global utility functions that your code may be using, we needed one - GetE:<br><br><pre><code>\r\nif (typeof(GetE) != 'function')\r\n{\r\n    /** Shorthand method from fck_dialog_common.js */\r\n    function GetE( elementId )\r\n    {\r\n        return document.getElementById( elementId )  ;\r\n    }\r\n}\r\n</code></pre><br><br>---",
  "excerpt": ""
 },
 {
  "title": "Practical Introduction into Code Injection with AspectJ, Javassist, and Java Proxy",
  "published": "2011-09-06 22:01:43",
  "postType": "post",
  "slug": "/2011/09/07/practical-introduction-into-code-injection-with-aspectj-javassist-and-java-proxy/",
  "status": "publish",
  "tags": [
   "AOP",
   "AspectJ",
   "java",
   "Javassist",
   "JavaZone"
  ],
  "categories": [
   "Languages",
   "Tools"
  ],
  "content": "The ability to inject pieces of code into compiled classes and methods, either statically or at runtime, may be of immense help. This applies especially to troubleshooting problems in third-party libraries without source codes or in an environment where it isn't possible to use a debugger or a profiler. Code injection is also useful for dealing with concerns that cut across the whole application, such as performance monitoring. Using code injection in this way became popular under the name <a href=\"http://en.wikipedia.org/wiki/Aspect-oriented_programming\" rel=\"nofollow\">Aspect-Oriented Programming</a> (AOP). Code injection isn't something used only rarely as you might think, quite the contrary; every programmer will come into a situation where this ability could prevent a lot of pain and frustration.<br><br>This post is aimed at giving you the knowledge that you may (or I should rather say \"will\") need and at persuading you that learning basics of code injection is really worth the little of your time that it takes. I'll present three different real-world cases where code injection came to my rescue, solving each one with a different tool, fitting best the constraints at hand.<br><br><!--more-->\r\n<h2><a name=\"JavaZoneProposal-AOP-WhyYouAreGoingtoNeedIt\"></a>Why You Are Going to Need It</h2>\r\nA lot has been already said about the <a class=\"external-link\" href=\"http://en.wikipedia.org/wiki/Aspect-oriented_programming#Motivation_and_basic_concepts\" rel=\"nofollow\">advantages of AOP</a> - and thus code injection - so I will only concentrate on a few main points from the troubleshooting point of view.<br><br>The coolest thing is that it <strong>enables you to modify third party, closed-source classes</strong> and actually even JVM classes. Most of us work with <a class=\"external-link\" href=\"/2011/04/18/what-do-i-mean-by-a-legacy-code/\" rel=\"nofollow\">legacy code</a> and code for which we haven't the source codes and inevitably we occasionally hit the limitations or bugs of these 3rd-party binaries and need very much to change some small thing in there or to gain more insight into the code's behavior. Without code injection you have no way to modify the code or to add support for increased observability into it. Also you often need to deal with issues or collect information in the production environment where you can't use a debugger and similar tools while you usually can at least manage somehow your application's binaries and dependencies. Consider the following situations:\r\n<ul>\r\n\t<li>You're passing a collection of data to a closed-source library for processing and one method in the library fails for one of the elements but the exception provides no information about which element it was. You'd need to modify it to either log the offending argument or to include it in the exception. (And you can't use a debugger because it only happens on the production application server.)</li>\r\n\t<li>You need to collect performance statistics of important methods in your application including some of its closed-source components under the typical production load. (In the production you of course cannot use a profiler and you want to incur the minimal overhead.)</li>\r\n\t<li>You use JDBC to send a lot of data to a database in batches and one of the batch updates fails. You would need some nice way to find out which batch it was and what data it contained.</li>\r\n</ul>\r\nI've in fact encountered these three cases (among others) and you will see possible implementations later.<br><br>You should keep the following advantages of code injection in your mind while reading this post:\r\n<ul>\r\n\t<li>Code injection enables you to modify binary classes for which you haven't the source codes</li>\r\n\t<li>The injected code can be used to collect various runtime information in environments where you cannot use the traditional development tools such as profilers and debuggers</li>\r\n\t<li>Don't Repeat Yourself: When you need the same piece of logic at multiple places, you can define it once and inject it into all those places.</li>\r\n\t<li>With code injection you do not modify the original source files so it is great for (possibly large-scale) changes that you need only for a limited period of time, especially with tools that make it possible to easily switch the code injection on and off (such as AspectJ with its load-time weaving). A typical case is performance metrics collection and increased logging during troubleshooting</li>\r\n\t<li>You can inject the code either statically, at the build time, or dynamically, when the target classes are being loaded by the JVM</li>\r\n</ul>\r\n<h2><a name=\"JavaZoneProposal-AOP-MiniGlossary\"></a>Mini Glossary</h2>\r\nYou might encounter the following terms in relation to code injection and AOP:<br><br><dl><dt>Advice</dt><dd>The code to be injected. Typically we talk about before, after, and around advices, which are executed before, after, or instead of a target method. It's possible to make also other changes than injecting code into methods, e.g. adding fields or interfaces to a class.</dd><dt>AOP (Aspect Oriented Programming)</dt><dd>A programming paradigm claiming that \"cross-cutting concerns\" - the logic needed at many places, without a single class where to implement them - should be implemented once and injected into those places. Check <a class=\"external-link\" href=\"http://en.wikipedia.org/wiki/Aspect-oriented_programming\" rel=\"nofollow\">Wikipedia</a> for a better description.</dd><dt>Aspect</dt><dd>A unit of modularity in AOP, corresponds roughly to a class - it can contain different advices and pointcuts.</dd><dt>Joint point</dt><dd>A particular point in a program that might be the target of code injection, e.g. a method call or method entry.</dd><dt>Pointcut</dt><dd>Roughly spoken, a pointcut is an expression which tells a code injection tool where to inject a particular piece of code, i.e. to which joint points to apply a particular advice. It could select only a single such point - e.g. execution of a single method - or many similar points - e.g. executions of all methods marked with a custom annotation such as @MyBusinessMethod.</dd><dt>Weaving</dt><dd>The process of injecting code - advices - into the target places - joint points.</dd></dl>\r\n<h2><a name=\"JavaZoneProposal-AOP-TheTools\"></a>The Tools</h2>\r\nThere are many very different tools that can do the job so we will first have a look at the differences between them and then we will get acquainted with three prominent representatives of different evolution branches of code injection tools.\r\n<h3><a name=\"JavaZoneProposal-AOP-BasicClassificationofCodeInjectionTools\"></a>Basic Classification of Code Injection Tools</h3>\r\n<h4><a name=\"JavaZoneProposal-AOP-I.LevelofAbstraction\"></a>I. Level of Abstraction</h4>\r\nHow difficult is it to express the logic to be injected and to express the pointcuts where the logic should be inserted?<br><br>Regarding the \"advice\" code:\r\n<ol>\r\n\t<li>Direct bytecode manipulation (e.g. ASM) - to use these tools you need to understand the bytecode format of a class because they abstract very little from it, you work directly with opcodes, the operand stack and individual instructions. An ASM example:\r\n<div style=\"border-width:1px;\">\r\n<div><pre><code>methodVisitor.visitFieldInsn(Opcodes.GETSTATIC, &quot;java/lang/System&quot;, &quot;out&quot;, &quot;Ljava/io/PrintStream;&quot;);</code></pre><br><br></div>\r\n</div>\r\nThey are difficult to use due to being so low-level but are the most powerful. Usually they are used to implement higher-level tools and only few actually need to use them.</li>\r\n\t<li>Intermediate level - code in strings, some abstraction of the classfile structure (Javassist)</li>\r\n\t<li>Advices in Java (e.g. AspectJ) - the code to be injected is expressed as syntax-checked and statically compiled Java</li>\r\n</ol>\r\nRegarding the specification of where to inject the code:\r\n<ol>\r\n\t<li>Manual injection - you have to get somehow hold of the place where you want to inject the code (ASM, Javassist)</li>\r\n\t<li>Primitive pointcuts - you have rather limited possibilities for expressing where to inject the code, for example to a particular method, to all public methods of a class or to all public methods of classes in a group (Java EE interceptors)</li>\r\n\t<li>Pattern matching pointcut expressions - powerful expressions matching joint points based on a number of criteria with wildcards, awareness of the context (e.g. \"called from a class in the package XY\") etc. (AspectJ)</li>\r\n</ol>\r\n<h4><a name=\"JavaZoneProposal-AOP-II.WhentheMagicHappens\"></a>II. When the Magic Happens</h4>\r\nThe code can be injected at different points in time:\r\n<ul>\r\n\t<li>Manually at run-time - your code has to explicitly ask for the enhanced code, e.g. by manually instantiating a custom proxy wrapping the target object (this is arguably not true code injection)</li>\r\n\t<li>At load-time - the modification are performed when the target classes are being loaded by the JVM</li>\r\n\t<li>At build-time - you add an extra step to your build process to modify the compiled classes before packaging and deploying your application</li>\r\n</ul>\r\nEach of these modes of injection can be more suitable at different situations.\r\n<h4><a name=\"JavaZoneProposal-AOP-III.WhatItCanDo\"></a>III. What It Can Do</h4>\r\nThe code injection tools vary pretty much in what they can or cannot do, some of the possibilities are:\r\n<ul>\r\n\t<li>Add code before/after/instead of a method - only member-level methods or also the static ones?</li>\r\n\t<li>Add fields to a class</li>\r\n\t<li>Add a new method</li>\r\n\t<li>Make a class to implement an interface</li>\r\n\t<li>Modify an instruction within the body of a method (e.g. a method call)</li>\r\n\t<li>Modify generics, annotations, access modifiers, change constant values, ...</li>\r\n\t<li>Remove method, field, etc.</li>\r\n</ul>\r\n<h3><a name=\"JavaZoneProposal-AOP-SelectedCodeInjectionTools\"></a>Selected Code Injection Tools</h3>\r\nThe best-known code injection tools are:\r\n<ol>\r\n\t<li>Dynamic Java Proxy</li>\r\n\t<li>The bytecode manipulation library <a class=\"external-link\" href=\"http://asm.ow2.org/\" rel=\"nofollow\">ASM</a></li>\r\n\t<li>JBoss Javassist</li>\r\n\t<li>AspectJ</li>\r\n\t<li>Spring AOP/proxies</li>\r\n\t<li>Java EE interceptors</li>\r\n</ol>\r\n<h3><a name=\"JavaZoneProposal-AOP-PracticalIntroductiontoJavaProxy,JavassistandAspectJ\"></a>Practical Introduction to Java Proxy, Javassist and AspectJ</h3>\r\nI've selected three rather different mature and popular code injection tools and will present them on real-world examples I've personally experienced.\r\n<h4><a name=\"JavaZoneProposal-AOP-TheOmnipresentDynamicJavaProxy\"></a>The Omnipresent Dynamic Java Proxy</h4>\r\n<a class=\"external-link\" href=\"http://download.oracle.com/javase/6/docs/api/java/lang/reflect/Proxy.html\" rel=\"nofollow\">Java.lang.reflect.Proxy</a> makes it possible to create dynamically a proxy for an interface, forwarding all calls to a target object. It is not a code injection tool for you cannot inject it anywhere, you must manually instantiate and use the proxy instead of the original object, and you can do this only for interfaces, but it can still be very useful as we will see.<br><br>Advantages:\r\n<ul>\r\n\t<li>It's a part of JVM and thus is available everywhere</li>\r\n\t<li>You can use the same proxy - more exactly an <a class=\"external-link\" href=\"http://download.oracle.com/javase/6/docs/api/java/lang/reflect/InvocationHandler.html\" rel=\"nofollow\">InvocationHandler</a> - for incompatible objects and thus reuse the code more than you could normally</li>\r\n\t<li>You save effort because you can easily forward all calls to a target object and only modify the ones interesting for you. If you were to implement a proxy manually, you would need to implement all the methods of the interface in question</li>\r\n</ul>\r\nDisadvantages\r\n<ul>\r\n\t<li>You can create a dynamic proxy only for an interface, you can't use it if your code expects a concrete class</li>\r\n\t<li>You have to instantiate and apply it manually, there is no magical auto-injection</li>\r\n\t<li>It's little too verbose</li>\r\n\t<li>Its power is very limited, it can only execute some code before/after/around a method</li>\r\n</ul>\r\nThere is no code injection step - you have to apply the proxy manually.\r\n<h5><a name=\"JavaZoneProposal-AOP-Example\"></a>Example</h5>\r\nI was using JDBC PreparedStatement's batch updates to modify a lot of data in a database and the processing was failing for one of the batch updates because of integrity constraint violation. The exception didn't contain enough information to find out which data caused the failure and so I've created a dynamic proxy for the PreparedStatement that remembered values passed into each of the batch updates and in the case of a failure it automatically printed the batch number and the data. With this information I was able to fix the data and I kept the solution in place so that if a similar problems ever occurs again, I'll be able to find its cause and resolve it quickly.<br><br>The crucial part of the code:\r\n<div style=\"border-width:1px;\">\r\n<div style=\"border-bottom-width:1px;\"><strong>LoggingStatementDecorator.java - snippet 1</strong></div>\r\n<div><pre><code>\r\nclass LoggingStatementDecorator implements InvocationHandler {<br><br>   private PreparedStatement target;\r\n   ...<br><br>   private LoggingStatementDecorator(PreparedStatement target) { this.target = target; }<br><br>   @Override\r\n   public Object invoke(Object proxy, Method method, Object[] args)\r\n         throws Throwable {<br><br>      try {\r\n         Object result = method.invoke(target, args);\r\n         updateLog(method, args); // remember data, reset upon successful execution\r\n         return result;\r\n      } catch (InvocationTargetException e) {\r\n         Throwable cause = e.getTargetException();\r\n         tryLogFailure(cause);\r\n         throw cause;\r\n      }<br><br>   }<br><br>   private void tryLogFailure(Throwable cause) {\r\n      if (cause instanceof BatchUpdateException) {\r\n         int failedBatchNr = successfulBatchCounter + 1;\r\n         Logger.getLogger(&quot;JavaProxy&quot;).warning(\r\n               &quot;THE INJECTED CODE SAYS: &quot; +\r\n               &quot;Batch update failed for batch# &quot; + failedBatchNr +\r\n               &quot; (counting from 1) with values: [&quot; +\r\n               getValuesAsCsv() + &quot;]. Cause: &quot; + cause.getMessage());\r\n      }\r\n   }\r\n...\r\n</code></pre><br><br></div>\r\n</div>\r\nNotes:\r\n<ul>\r\n\t<li>To create a proxy, you first need to implement an <em>InvocationHandler</em> and its invoke method, which is called whenever any of the interface's methods is invoked on the proxy</li>\r\n\t<li>You can access the information about the call via the java.lang.reflect.* objects and for example delegate the call to the proxied object via <em>method.invoke</em></li>\r\n</ul>\r\nWe've also an utility method for creating a proxy instance for a Prepared statement:\r\n<div style=\"border-width:1px;\">\r\n<div style=\"border-bottom-width:1px;\"><strong>LoggingStatementDecorator.java - snippet 2</strong></div>\r\n<div><pre><code>\r\npublic static PreparedStatement createProxy(PreparedStatement target) {\r\n  return (PreparedStatement) Proxy.newProxyInstance(\r\n      PreparedStatement.class.getClassLoader(),\r\n      new Class[] { PreparedStatement.class },\r\n      new LoggingStatementDecorator(target));\r\n};\r\n</code></pre><br><br></div>\r\n</div>\r\nNotes:\r\n<ul>\r\n\t<li>You can see that the <em>newProxyInstance</em> call takes a classloader, an array of interfaces that the proxy should implement, and the invocation handler that calls should be delegated to (the handler itself has to manage a reference to the proxied object, if it needs it)</li>\r\n</ul>\r\nIt is then used like this:\r\n<div style=\"border-width:1px;\">\r\n<div style=\"border-bottom-width:1px;\"><strong>Main.java</strong></div>\r\n<div><pre><code>\r\n...\r\nPreparedStatement rawPrepStmt = connection.prepareStatement(&quot;...&quot;);\r\nPreparedStatement loggingPrepStmt = LoggingStatementDecorator.createProxy(rawPrepStmt);\r\n...\r\nloggingPrepStmt.executeBatch();\r\n...\r\n</code></pre><br><br></div>\r\n</div>\r\nNotes:\r\n<ul>\r\n\t<li>You see that we have to manually wrap a raw object with the proxy and use the proxy further on</li>\r\n</ul>\r\n<h6><a name=\"JavaZoneProposal-AOP-AlternativeSolutions\"></a>Alternative Solutions</h6>\r\nThis problem could be solved in different ways, for example by creating a non-dynamic proxy implementing PreparedStatement and forwarding all calls to the real statement while remembering batch data but it would be lot of boring typing for the interface has many methods. The caller could also manually keep track of the data it has send to the prepared statement but that would obscure its logic with an unrelated concern.<br><br>Using the dynamic Java proxy we get rather clean and easy to implement solution.\r\n<h4><a name=\"JavaZoneProposal-AOP-TheIndependentJavassist\"></a>The Independent Javassist</h4>\r\n<a class=\"external-link\" href=\"http://www.javassist.org/\" rel=\"nofollow\">JBoss Javassist</a> is an intermediate code injection tool providing a higher-level abstraction than bytecode manipulation libraries and offering little limited but still very useful manipulation capabilities. The code to be injected is represented as strings and you have to manually get to the class-method where to inject it. Its main advantage is that the modified code has no new run-time dependencies, on Javassist or anything else. This may be the decisive factor if you are working for a large corporation where the deployment of additional open-source libraries (or just about any additional libraries) such as AspectJ is difficult for legal and other reasons.<br><br>Advantages\r\n<ul>\r\n\t<li>Code modified by Javassist doesn't require any new run-time dependencies, the injection happens at the build time and the injected advice code itself doesn't depend on any Javassist API</li>\r\n\t<li>Higher-level than bytecode manipulation libraries, the injected code is written in Java syntax, though enclosed in strings</li>\r\n\t<li>Can do most things that you may need such as \"advising\" method calls and method executions</li>\r\n\t<li>You can achieve both build-time injection (via Java code or a <a href=\"/2010/06/25/implementing-build-time-instrumentation-with-javassist/\" rel=\"nofollow\">custom Ant task to do execution/call advising</a>) and load-time injection (by implementing your own <a href=\"http://download.oracle.com/javase/1.5.0/docs/api/java/lang/instrument/package-summary.html\">Java 5+ agent</a> [thx to Anton])</li>\r\n</ul>\r\nDisadvantages\r\n<ul>\r\n\t<li>Still little too low-level and thus harder to use - you have to deal a little with structure of methods and the injected code is not syntax-checked</li>\r\n\t<li>Javassist has no tools to perform the injection and you thus have to implement your own injection code - including that there isn't support for injecting the code automatically based on a pattern</li>\r\n</ul>\r\n(See GluonJ below for a solution without most of the disadvantages of Javassist.)<br><br>With Javassist you create a class, which uses the Javassist API to inject code int targets and run it as a part of your build process after the compilation, for example as I once did via a custom Ant task.\r\n<h5><a name=\"JavaZoneProposal-AOP-Example\"></a>Example</h5>\r\nWe needed to add some simple performance monitoring to our Java EE application and we were not allowed to deploy any non-approved open-source library (at least not without going through a time-consuming approval process). We've therefore used Javassist to inject the performance monitoring code to our important methods and to the places were important external methods were called.<br><br>The code injector:\r\n<div style=\"border-width:1px;\">\r\n<div style=\"border-bottom-width:1px;\"><strong>JavassistInstrumenter.java</strong></div>\r\n<div><pre><code>\r\npublic class JavassistInstrumenter {<br><br>   public void insertTimingIntoMethod(String targetClass, String targetMethod) throws NotFoundException, CannotCompileException, IOException {\r\n      Logger logger = Logger.getLogger(&quot;Javassist&quot;);\r\n      final String targetFolder = &quot;./target/javassist&quot;;<br><br>      try {\r\n         final ClassPool pool = ClassPool.getDefault();\r\n         // Tell Javassist where to look for classes - into our ClassLoader\r\n         pool.appendClassPath(new LoaderClassPath(getClass().getClassLoader()));\r\n         final CtClass compiledClass = pool.get(targetClass);\r\n         final CtMethod method = compiledClass.getDeclaredMethod(targetMethod);<br><br>         // Add something to the beginning of the method:\r\n         method.addLocalVariable(&quot;startMs&quot;, CtClass.longType);\r\n         method.insertBefore(&quot;startMs = System.currentTimeMillis();&quot;);\r\n         // And also to its very end:\r\n         method.insertAfter(&quot;{final long endMs = System.currentTimeMillis();&quot; +\r\n            &quot;iterate.jz2011.codeinjection.javassist.PerformanceMonitor.logPerformance(\\&quot;&quot; +\r\n            targetMethod + &quot;\\&quot;,(endMs-startMs));}&quot;);<br><br>         compiledClass.writeFile(targetFolder);\r\n         // Enjoy the new $targetFolder/iterate/jz2011/codeinjection/javassist/TargetClass.class<br><br>         logger.info(targetClass + &quot;.&quot; + targetMethod +\r\n               &quot; has been modified and saved under &quot; + targetFolder);\r\n      } catch (NotFoundException e) {\r\n         logger.warning(&quot;Failed to find the target class to modify, &quot; +\r\n               targetClass + &quot;, verify that it ClassPool has been configured to look &quot; +\r\n               &quot;into the right location&quot;);\r\n      }\r\n   }<br><br>   public static void main(String[] args) throws Exception {\r\n      final String defaultTargetClass = &quot;iterate.jz2011.codeinjection.javassist.TargetClass&quot;;\r\n      final String defaultTargetMethod = &quot;myMethod&quot;;\r\n      final boolean targetProvided = args.length == 2;<br><br>      new JavassistInstrumenter().insertTimingIntoMethod(\r\n            targetProvided? args[0] : defaultTargetClass\r\n            , targetProvided? args[1] : defaultTargetMethod\r\n      );\r\n   }\r\n}\r\n</code></pre><br><br></div>\r\n</div>\r\nNotes:\r\n<ul>\r\n\t<li>You can see the \"low-levelness\" - you have to explicitly deal with objects like CtClass, CtMethod, explicitly add a local variable etc.</li>\r\n\t<li>Javassist is rather flexible in where it can look for the classes to modify - it can search the classpath, a particular folder, a JAR file, or a folder with JAR files</li>\r\n\t<li>You would compile this class and run its main during your build process</li>\r\n</ul>\r\n<h4><a name=\"JavaZoneProposal-AOP-JavassistonSteroids:GluonJ\"></a>Javassist on Steroids: GluonJ</h4>\r\n<a class=\"external-link\" href=\"http://www.csg.is.titech.ac.jp/projects/gluonj/documentation/tutorial.html\" rel=\"nofollow\">GluonJ</a> is an AOP tool building on top of Javassist. It can use either a custom syntax or Java 5 annotations and it's build around the concept of \"revisers\". Reviser is a class - an aspect - that revises, i.e. modifies, a particular target class and overrides one or more of its methods (contrary to inheritance, the reviser's code is physically imposed over the original code inside the target class).<br><br>Advantages\r\n<ul>\r\n\t<li>No run-time dependencies if build-time weaving used (load-time weaving requires the GluonJ agent library or gluonj.jar)</li>\r\n\t<li>Simple Java syntax using GlutonJ's annotation - though the custom syntax is also trivial to understand and easy to use</li>\r\n\t<li>Easy, automatic weaving into the target classes with GlutonJ's JAR tool, an Ant task or dynamically at the load-time</li>\r\n\t<li>Support for both build-time and load-time weaving</li>\r\n</ul>\r\nDisadvantages\r\n<ul>\r\n\t<li>An aspect can modify only a single class, you cannot inject the same piece of code to multiple classes/methods</li>\r\n\t<li>Limited power - only provides for field/method addition and execution of a code instead of/around a target method, either upon any of its executions or only if the execution happens in a particular context, i.e. when called from a particular class/method</li>\r\n</ul>\r\nIf you don't need to inject the same piece of code into multiple methods then GluonJ is easier and better choice than Javassist and if its simplicity isn't a problem for you then it also might be a better choice than AspectJ just thanks to this simplicity.\r\n<h4><a name=\"JavaZoneProposal-AOP-TheAlmightyAspectJ\"></a>The Almighty AspectJ</h4>\r\nAspectJ is a full-blown AOP tool, it can do nearly anything you might want, including the modification of static methods, addition of new fields, addition of an interface to a class' list of implemented interfaces etc.<br><br>The syntax of AspectJ advices comes in two flavours, one is a superset of Java syntax with additional keywords like <em>aspect</em> and <em>pointcut</em>, the other one - called @AspectJ - is standard Java 5 with annotations such as @Aspect, @Pointcut, @Around. The latter is perhaps easier to learn and use but also little less powerful as it isn't as expressive as the custom AspectJ syntax.<br><br>With AspectJ you can define which joint points to advise with very powerful expressions but it may be little difficult to learn them and to get them right. There is a useful Eclipse plugin for AspectJ development - the <a class=\"external-link\" href=\"http://www.eclipse.org/ajdt/\" rel=\"nofollow\">AspectJ Development Tools</a> (AJDT) - but the last time I've tried it it wasn't as helpful as I'd have liked.<br><br>Advantages\r\n<ul>\r\n\t<li>Very powerful, can do nearly anything you might need</li>\r\n\t<li>Powerful pointcut expressions for defining where to inject an advice and when to activate it (including some run-time checks) - fully enables <abbr title=\"Don't Repeat Yourself\">DRY</abbr>, i.e. write once &amp; inject many times</li>\r\n\t<li>Both build-time and load-time code injection (weaving)</li>\r\n</ul>\r\nDisadvantages\r\n<ul>\r\n\t<li>The modified code depends on the AspectJ runtime library</li>\r\n\t<li>The pointcut expressions are very powerful but it might be difficult to get them right and there isn't much support for \"debugging\" them though the AJDT plugin is partially able to visualize their effects</li>\r\n\t<li>It will likely take some time to get started though the basic usage is pretty simple (using @Aspect, @Around, and a simple pointcut expression, as we will see in the example)</li>\r\n</ul>\r\n<h5><a name=\"JavaZoneProposal-AOP-Example\"></a>Example</h5>\r\nOnce upon time I was writing a plugin for a closed-source <abbr title=\"Learning Management System\">LMS</abbr> J2EE application having such dependencies that it wasn't feasible to run it locally. During an API call, a method deep inside the application was failing but the exception didn't contain enough information to track the cause of the problem. I therefore needed to change the method to log the value of its argument when it fails.<br><br>The AspectJ code is quite simple:\r\n<div style=\"border-width:1px;\">\r\n<div style=\"border-bottom-width:1px;\"><strong>LoggingAspect.java</strong></div>\r\n<div><pre><code>\r\n@Aspect\r\npublic class LoggingAspect {<br><br>   @Around(&quot;execution(private void TooQuiet3rdPartyClass.failingMethod(..))&quot;)\r\n   public Object interceptAndLog(ProceedingJoinPoint invocation) throws Throwable {\r\n      try {\r\n         return invocation.proceed();\r\n      } catch (Exception e) {\r\n         Logger.getLogger(&quot;AspectJ&quot;).warning(\r\n            &quot;THE INJECTED CODE SAYS: the method &quot; +\r\n            invocation.getSignature().getName() + &quot; failed for the input '&quot; +\r\n            invocation.getArgs()[0] + &quot;'. Original exception: &quot; + e);\r\n         throw e;\r\n      }\r\n   }\r\n}\r\n</code></pre><br><br></div>\r\n</div>\r\nNotes:\r\n<ul>\r\n\t<li>The aspect is a normal Java class with the @Aspect annotation, which is just a marker for AspectJ</li>\r\n\t<li>The @Around annotation instructs AspectJ to execute the method instead of the one matched by the expression, i.e. instead of the failingMethod of the TooQuiet3rdPartyClass</li>\r\n\t<li>The around advice method needs to be public, return an Object, and take a special AspectJ object carrying information about the invocation - <a class=\"external-link\" href=\"http://www.eclipse.org/aspectj/doc/released/runtime-api/org/aspectj/lang/ProceedingJoinPoint.html\" rel=\"nofollow\">ProceedingJoinPoint</a> - as its argument and it may have an arbitrary name (Actually this is the minimal form of the signature, it could be more complex.)</li>\r\n\t<li>We use the ProceedingJoinPoint to delegate the call to the original target (an instance of the TooQuiet3rdPartyClass) and, in the case of an exception, to get the argument's value</li>\r\n\t<li>I've used an @Around advice though @AfterThrowing would be simpler and more appropriate but this shows better the capabilities of AspectJ and can be nicely compared to the dynamic java proxy example above</li>\r\n</ul>\r\nSince I hadn't control over the application's environment, I couldn't enable the load-time weaving and thus had to use <a class=\"external-link\" href=\"http://www.eclipse.org/aspectj/doc/released/devguide/antTasks-iajc.html\" rel=\"nofollow\">AspectJ's Ant task</a> to weave the code at the build time, re-package the affected JAR and re-deploy it to the server.\r\n<h6><a name=\"JavaZoneProposal-AOP-AlternativeSolutions\"></a>Alternative Solutions</h6>\r\nWell, if you can't use a debugger then your options are quite limited. The only alternative solution I could think of is to <a class=\"external-link\" href=\"http://java.decompiler.free.fr/\" rel=\"nofollow\">decompile</a> the class (illegal!), add the logging into the method (provided that the decompilation succeeds), re-compile it and replace the original .class with the modified one.\r\n<h2><a name=\"JavaZoneProposal-AOP-TheDarkSide\"></a>The Dark Side</h2>\r\nCode injection and Aspect Oriented Programming are very powerful and sometimes indispensable both for troubleshooting and as a regular part of application architecture, as we can see e.g. in the case of Java EE's Enterprise Java Beans where the business concerns such as transaction  management and security checks are injected into POJOs (though implementations actually more likely use proxies) or in Spring.<br><br>However there is a price to be paid in terms of <em>possibly</em> decreased understandability as the runtime behavior and structure are different from what you'd expect based on the source codes (unless you know to check also the aspects' sources or unless the injection is made explicit by annotations on the target classes such as Java EE's <a class=\"external-link\" href=\"http://download.oracle.com/javaee/6/api/javax/interceptor/Interceptors.html\" rel=\"nofollow\">@Interceptors</a>). Therefore you must carefully weight the benefits and drawbacks of code injection/AOP - though when used reasonably, they do not obscure the program flow more than interfaces, factories etc. The <a class=\"external-link\" href=\"http://www.ibm.com/developerworks/java/library/j-aopwork15/index.html#N10223\" rel=\"nofollow\">argument about obscuring code is perhaps often over-estimated</a>.<br><br>If you want to see an example of AOP gone wild, check the <a class=\"external-link\" href=\"http://sourceforge.net/projects/glassbox/files/glassbox/2.0/glassbox-src.zip/download\" rel=\"nofollow\">source codes</a> of <a class=\"external-link\" href=\"http://glassbox.sourceforge.net/\" rel=\"nofollow\">Glassbox</a>, a JavaEE performance monitoring tool (for that you might need a <a class=\"external-link\" href=\"/2008/10/31/webapp-performance-monitoring-with/\" rel=\"nofollow\">map</a> not to get too lost).\r\n<h2><a name=\"JavaZoneProposal-AOP-FancyUsesofCodeInjectionandAOP\"></a>Fancy Uses of Code Injection and AOP</h2>\r\nThe main field of application of code injection in the process of troubleshooting is logging, more exactly gaining visibility into what an application is doing by extracting and somehow communicating interesting runtime information about it. However AOP has many interesting uses beyond - simple or complex - logging, for example:\r\n<ul>\r\n\t<li>Typical examples: Caching &amp; et al (ex.: <a class=\"external-link\" href=\"http://www.theserverside.com/news/thread.tss?thread_id=39026#200714\" rel=\"nofollow\">on AOP in JBoss Cache</a>), transaction management, logging, enforcement of security, persistence, thread safety, error recovery, automatic implementation of methods (e.g. toString, equals, hashCode), remoting</li>\r\n\t<li>Implementation of <a class=\"external-link\" href=\"http://en.wikipedia.org/wiki/Role-oriented_programming\" rel=\"nofollow\">role-based programming</a> (e.g. <a class=\"external-link\" href=\"http://www.eclipse.org/objectteams/\" rel=\"nofollow\">OT/J</a>, using BCEL) or the <a class=\"external-link\" href=\"http://en.wikipedia.org/wiki/Data,_Context,_and_Interaction\" rel=\"nofollow\">Data, Context, and Interaction</a> architecture</li>\r\n\t<li>Testing\r\n<ul>\r\n\t<li>Test coverage - inject code to record whether a line has been executed during test run or not</li>\r\n\t<li><a class=\"external-link\" href=\"http://www.cs.gmu.edu/~offutt/rsrch/papers/mujava.pdf\" rel=\"nofollow\">Mutation testing</a> (<a href=\"http://www.cs.gmu.edu/~offutt/mujava/\">µJava</a>, <a href=\"http://jumble.sourceforge.net/\">Jumble</a>) - inject \"random\" mutation to the application and verify that the tests failed</li>\r\n\t<li><a class=\"external-link\" href=\"http://www.patterntesting.com/\" rel=\"nofollow\">Pattern Testing</a> - automatic verification that Architecture/Design/Best practices recommendations are implemented correctly in the code via AOP</li>\r\n\t<li>Simulate hardware/external failures by <a class=\"external-link\" href=\"http://www.eclipse.org/aspectj/sample-code.html#testing-inoculated-injectIOException\" rel=\"nofollow\">injecting the throwing of an exception</a></li>\r\n</ul>\r\n</li>\r\n\t<li>Help to achieve zero turnaround for Java applications - <a class=\"external-link\" href=\"http://www.zeroturnaround.com/forum/topic.php?id=1265&amp;replies=3#post-5207\" rel=\"nofollow\">JRebel uses an AOP-like approach</a> for framework and server integration plugins - namely its <a class=\"external-link\" href=\"http://www.zeroturnaround.com/jrebel/features/\" rel=\"nofollow\">plugins </a><a class=\"external-link\" href=\"http://www.zeroturnaround.com/resources/jrebel-plugins/\" rel=\"nofollow\">use Javassist</a> for \"binary patching\"</li>\r\n\t<li>Solving though problems and avoiding monkey-coding with AOP patterns such as Worker Object Creation (turn direct calls into asynchronous with a Runnable and a ThreadPool/task queue) and Wormhole (make context information from a caller available to the callee without having to pass them through all the layers as parameters and without a ThreadLocal) - described in the book AspectJ in Action</li>\r\n\t<li>Dealing with legacy code - overriding the class instantiated on a call to a constructor (this and similar may be used to break tight-coupling with feasible amount of work), <a class=\"external-link\" href=\"http://www.sonatype.com/people/2007/11/two-fantastic-uses-for-aspectj-part-one-backward-compatibility/\" rel=\"nofollow\">ensuring backwards-compatibility</a>  o , <a class=\"external-link\" href=\"http://www.sonatype.com/people/2007/12/two-fantastic-uses-for-aspectj-part-two-bridging/\" rel=\"nofollow\">teaching components to react properly</a> on environment changes</li>\r\n\t<li>Preserving backwards-compatibility of an API while not blocking its ability to evolve e.g. by adding backwards-compatible methods when return types have been narrowed/widened (<a class=\"external-link\" href=\"http://bridge-method-injector.infradna.com/\" rel=\"nofollow\">Bridge Method Injector</a> - uses ASM) or by <a class=\"external-link\" href=\"http://www.sonatype.com/people/2007/11/two-fantastic-uses-for-aspectj-part-one-backward-compatibility/\" rel=\"nofollow\">re-adding old methods</a> and implementing them in terms of the new API</li>\r\n\t<li>Turning POJOs into JMX beans</li>\r\n</ul>\r\n<h2><a name=\"JavaZoneProposal-AOP-Summary\"></a>Summary</h2>\r\nWe've learned that code injection can be indispensable for troubleshooting, especially when dealing with closed-source libraries and complex deployment environments. We've seen three rather different code injection tools - dynamic Java proxies, Javassist, AspectJ - applied to real-world problems and discussed their advantages and disadvantages because different tools may be suitable for different cases. We've also mentioned that code injection/AOP shouldn't be overused and looked at some examples of advanced applications of code injection/AOP.<br><br>I hope that you now understand how code injection can help you and know how to use these three tools.\r\n<h2><a name=\"JavaZoneProposal-AOP-SourceCodes\"></a>Source Codes</h2>\r\nYou can <a class=\"external-link\" href=\"https://github.com/jakubholynet/JavaZone-Code-Injection\" rel=\"nofollow\">get the fully-documented source codes of the examples</a> from GitHub including not only the code to be injected but also the target code and support for easy building. The easiest may be:\r\n<div style=\"border-width:1px;\">\r\n<div><pre><code>\r\ngit clone git://github.com/jakubholynet/JavaZone-Code-Injection.git\r\ncd JavaZone-Code-Injection/\r\ncat README\r\nmvn -P javaproxy test\r\nmvn -P javassist test\r\nmvn -P aspectj   test\r\n</code></pre><br><br></div>\r\n</div>\r\n(It may take few minutes for Maven do download its dependencies, plugins, and the actual project's dependencies.)\r\n<h2><a name=\"JavaZoneProposal-AOP-AdditionalResources\"></a>Additional Resources</h2>\r\n<ul>\r\n\t<li><a class=\"external-link\" href=\"http://static.springsource.org/spring/docs/3.0.x/reference/aop.html\" rel=\"nofollow\">Spring's introduction into AOP</a></li>\r\n\t<li>dW: <a class=\"external-link\" href=\"http://www.ibm.com/developerworks/java/library/j-aopwork15/index.html\" rel=\"nofollow\">AOP@Work: AOP myths and realities </a></li>\r\n\t<li><a class=\"external-link\" href=\"http://www.manning.com/laddad2/Samplechapter1.pdf\" rel=\"nofollow\">Chapter 1 of AspectJ in Action</a>, 2nd. ed.</li>\r\n</ul>\r\n<h2><a name=\"JavaZoneProposal-AOP-Acknowledgements\"></a>Acknowledgements</h2>\r\nI would like to thank all the people who helped me with this post and the presentation including my colleges, the JRebel folk, and GluonJ's co-author prof. Shigeru Chiba.",
  "excerpt": ""
 },
 {
  "title": "Real-world data prove that Agile, BDD & co. work - lecture by G. Adzic",
  "published": "2011-04-14 09:27:27",
  "postType": "post",
  "slug": "/2011/04/14/real-world-data-prove-that-agile-bdd-co-work-lecture-by-g-adzic/",
  "status": "publish",
  "tags": [
   "agile",
   "best practices",
   "book",
   "lean",
   "Testing"
  ],
  "categories": [
   "General",
   "Testing"
  ],
  "content": "I've attended a very inspirational lecture by <a href=\"http://gojko.net/\">Gojko Adzic</a>, organized by the Oslo XP Meetup. Many people including some respectable persons claim that Lean, Agile, and high-level testing based on specifications (whether you call it Agile acceptance testing, Acceptance-test driven development, Example-driven development, Story-testing, Behavior-driven development, or otherwise - let's call them all Specification by example) do not work.<br><br>To prove the contrary, Gojko has collected over 50 case studies of projects that were very successful thanks to using these methods. In his soon-to-be-published book, <a href=\"http://specificationbyexample.com/\">Specification by Example</a> (<a href=\"http://manning.com/adzic/\">download ch1</a>, a <a href=\"http://www.rapaul.com/2011/04/12/specification-by-example-review/\">review</a>), he investigates what these projects and teams had in common, which was missing in the failed ones. So it's great for two reasons: It documents how great success you can achieve with Specification by Example and it shows you how to implement it successfully.<br><br><!--more-->In the case you've never heard about Specification by Example before, the idea is (as I understand it with my limited knowledge) that the business users can express their requirements in such a way that it can be directly used for verifying that the system satisfies them. A popular tool in this area is <a href=\"http://fitnesse.org/\">FitNesse</a>, where tests are created as wiki pages with tables containing inputs and expected outputs.<br><br>According to Gojko, you can achieve great software quality - sometimes up to the point that you can abandon your issue tracking software - thanks to Specification by Example. However you must implement it properly. Some of the key points that he mentioned were (<em>beware: most of the text is what I understand under what he said, it doesn't necessarily mean what he actually meant :-)</em> ):\r\n<ul>\r\n\t<li>Don't start with user stories but <strong>understand the business goal</strong> - the desired effect - first because user stories may already imply a solution. This is, I'd say, rather known but perhaps too often forgotten wisdom.</li>\r\n\t<li><strong>Specify collaboratively</strong> - it's essential that business users, developers, and testers work together (ideally face to face) on creating the specification for thus a common understanding can arise (we all know that most projects fail due to wrong or misunderstood requirements) and each of them can contribute to increase the quality of the specifications thanks to his unique point of view.</li>\r\n\t<li><strong>Specification with examples</strong> - the user acceptance testing tools such as FitNesse are not intended for integration and full regression testing, it's nonsense to create tables with hundreds of rows. The \"test\" should first contain the specification itself in few sentences and then a table with few <em>key examples</em> so that anybody reading it - now or in one year - can easily understand the point. Such testable specification is maintainable and can serve its primary purpose of being means of communication between all involved parties and between their current and future selves)</li>\r\n\t<li><strong>Best specifications/tests are aligned with the business domain</strong>, using the same language, concepts, relationships, models as the business people. Thus they can understand them and use them as the primary source of documentation and, more importantly, - if you've really managed to preserve the models and relationships - a small change in requirements will require only a small change in the software and the tests and vice versa so the business people can directly estimate the impact of changes. One of the key enablers is that tests are not expressed in the terms of clics, CSS classes, and XPaths, because then it could easily happen that a small change to a webpage header would break hundreds of tests. (And many teams certainly fall into this trap.)</li>\r\n\t<li><strong>Living documentation</strong> - such tests become very valuable and easily accessible documentation of what the system does. Of course you must keep it alive, meaning that it must be updated as the system evolves, and the system itself must evolve as the business needs change (including removal of business functionality which is not anymore needed - something often neglected). Because the specifications are so close to the system, it's actually very easy to keep them synchronized, something that is a huge problem with standard documentation.</li>\r\n</ul>\r\nThese are just few points I've remembered and I've certainly omitted many important things and all the interesting real-world stories that accompany and exemplify.<br><br>Already for a long time I'm attracted by the concept of specification by example, but I was never sure whether it can really work. Thanks to Gojko and his book I know it can work and I also have guidance for avoiding the pitfalls and attaining a success. I'm therefore very much thankful to him and looking forward to reading his book.<br><br>PS: To be fair, I should mention that also the other lecture of the evening, \"Lead better - Essential Skills for Software Team Leadership\" by Roy Osherove was excellent and has brought me new insights into the role of a team leader. I've never before thought that team leader should so much care for the personal/professional development of his team members and that helping them grow is his main responsibility (provided that the team isn't anymore in chaos, having enough problems striving to survive). He shares his ideas about <a href=\"http://5whys.com/\">leadership in software teams via 5Whys.com</a>, which I'd recommend.",
  "excerpt": ""
 },
 {
  "title": "Refactoring the \"Legacy\" Hudson.java with the Mikado Method as a Coding Dojo",
  "published": "2011-04-16 16:08:36",
  "postType": "post",
  "slug": "/2011/04/16/refactoring-the-legacy-hudson-java-with-the-mikado-method-as-a-code-dojo/",
  "status": "publish",
  "tags": [
   "book",
   "java",
   "legacy",
   "quality",
   "refactoring"
  ],
  "categories": [
   "General",
   "Languages"
  ],
  "content": "I'm preparing a coding dojo for my colleges at <a href=\"http://iterate.no/\">Iterate</a> where we will try to collectively refactor the \"legacy\" Hudson/Jenkins, especially Hudson.java, to something more testable, using the <a href=\"http://mikadomethod.wordpress.com/\">Mikado Method</a>. I've got the idea after reading Gojko Adzic's blog on <a href=\"http://gojko.net/2011/04/05/how-is-it-even-possible-code-to-be-this-bad/\">how terrible the code is</a> and after discovering the Mikado Method by a chance. Since a long time I'm interested in code quality and since recently especially in improving the quality of legacy applications, where \"legacy\" means a terrible code base and likely insufficient tests. As consultants we often have to deal with such application and with improving their state into something easier and cheaper to maintain and evolve. Therefore such a collective practice is a good thing.\r\n<h2>The Mikado Method</h2>\r\nThe Mikado Method, which the authors describe as \"a tool for large-scale refactorings\", serves two purposes:<!--more-->\r\n<ol>\r\n\t<li>Exploring an unknown, legacy codebase with the aim of learning enough to be able to perform a particular change</li>\r\n\t<li>Performing the change with the minimal risk, that means especially without ever bringing the application into a broken state where it cannot be built or tested</li>\r\n</ol>\r\nThe method itself doesn't introduce any new refactorings, it is just a \"container\" for various well-known refactorings and servers as a guide or a map, adding the big picture of where we started, where we want to get, and where we are right now, thus helping us concentrate on that which is important and not loosing sight of our primary goal, which is otherwise rather easy once you enter the swamp of a rotten legacy code base.<br><br>The method is surprisingly simple, you need only a whiteboard and a version control system (VCS). The process is as follows:\r\n<ol>\r\n\t<li>Identify the goal you want to achieve - the Mikado Goal - and write it down on a whiteboard</li>\r\n\t<li>Implement a naive solution, i.e. try to do a rather simple solution</li>\r\n\t<li>If the changes broke your code - so that it doesn't compile or tests fail - add the things that must be done or satisfied before you can perform the change safely as child nodes to the Mikado Goal and <em>revert your changes</em> to the code base</li>\r\n\t<li>Pick one of the new child nodes and go to 2.</li>\r\n\t<li>Once you are actually able to do a change without breaking something, you can check the corresponding leaf node of the growing Mikado Graph and continue with another leaf until you eventually get to the original goal and get it implemented</li>\r\n</ol>\r\nFollowing these simple steps you go on discovering what needs to be changed without getting broken code base which is impossible to work on or without wandering too far away from the goal that you ultimately want to achieve. It may sound as a waste to undo changes on a regular basis but with modern automated refactorings and eventually backups in a VCS it is a small price to pay for the safety that non-broken code base provides.<br><br>The insistence on a naive solution is important because legacy code bases are often so intertangled and complex that whenever you try to outsmart their badness you usually fail, hitting again and again the walls of unforseen problems, dependencies and crazy design decisions. With a simple solution you are more likely to succeed or at least discover the hidden complications before you wasted too much effort and you avoid the trap of \"paralysis by analysis\". It doesn't mean that you should never think and analyse - but do it only when it really pays off, keeping in mind that the code base is usually yet worse than you expect.<br><br>To understand the benefits and proper application of the Mikado Method, read the <a href=\"http://mikadomethod.wordpress.com/book/\">freely available draft of the Mikado Method book</a> and <a href=\"http://mikadomethod.wordpress.com/exercises/\">try it on the \"code kata\" exercises</a> that the authors have prepared for you. Some interesting quotes from the book:\r\n<blockquote>Computer programs has to improve or they are doomed to a slow death. We, the developers, hold the fate of the code in our hands and we are the only ones that have the power to improve it. It is our responsibility to keep the code clean and fit for purpose. This means we have to be able to add code, improve our own code and the code of others.<br><br>The Mikado Method helps us visualize, plan and perform business- value-focused improvements over several iterations and increments of work, without ever having a broken code-base during the process. It enhances communication, collaboration and learning in software de- velopment teams. It also helps individuals or programming pairs stay on track while doing their day to day work. It provides us with frame- work to help us morph our system into the desired shape.<br><br>We naïvely try to implement a change, without analyzing too much in advance. By doing so, we don’t need to think about how this affect that or the other, something that keeps us from ending up in analysis paralysis.<br><br>The key to changing any system is to first change the restrictions enough to make the desired changes possible.<br><br>When there are errors we always roll back all our changes! This is extremely important! The reason is that we never want to edit the code when we don’t know what state it is in. Since we have made changes that resulted in errors, we don’t have a stable state to make changes from.</blockquote>\r\nPS: Two of my colleges have mentioned that they used something similar to the Mikado Method without knowing that it existed. That proves that the method is indeed very practical and useful.\r\n<h2>Conclusion</h2>\r\nThe conclusion is yet to be drawn :-). I'll publish a blog post with our experiences after the coding dojo. Stay tuned.<br><br><strong>Update</strong>: Outcomes in <a title=\"What I’ve Learned from (Nearly) Failing to Refactor Hudson\" href=\"/2011/04/28/what-ive-learned-from-nearly-failing-to-refactor-hudson/\">What I’ve Learned from (Nearly) Failing to Refactor Hudson</a>.",
  "excerpt": ""
 },
 {
  "title": "What Do I Mean by a Legacy Code?",
  "published": "2011-04-18 08:38:43",
  "postType": "post",
  "slug": "/2011/04/18/what-do-i-mean-by-a-legacy-code/",
  "status": "publish",
  "tags": [
   "book",
   "java",
   "opinion",
   "quality"
  ],
  "categories": [
   "Languages"
  ],
  "content": "I'm using the term \"legacy code\" quite a lot, what do I mean by it? I like most the R. C. Martin's description in his foreword to the Michael Feathers' book <a href=\"http://www.amazon.com/Working-Effectively-Legacy-Michael-Feathers/dp/0131177052/ref=sr_1_1?ie=UTF8&amp;qid=1303113906&amp;sr=8-1\">Working Effectively with Legacy Code</a>:\r\n<blockquote>It conjures images of slogging through a murky swamp of tangled undergrowth with leaches beneath and stinging flies above. It conjures odors of murk, slime, stagnancy, and offal.</blockquote>\r\n<!--more-->M. Feathers himself first repeates a common definition:\r\n<blockquote>Legacy code is code that we've gotten from someone else.</blockquote>\r\nHe then acknowledges that in programmer's mind the term legacy code means much more, something that has nothing to do with who wrote it:\r\n<blockquote>If you are at all like me, you think of tangled, unintelligible structure, code that you have to change but don't really understand. You think of sleepless nights trying to add in features that should be easy to add, and you think of demoralization, the sense that everyone on the team is so sick of a code base that it seems beyond care, the sort of code that you just wish would die. Part of you feels bad for even thinking about making it better. It seems unworthy of your efforts.</blockquote>\r\nIn summary, legacy code is \"used as a slang term for difficult-to-change code that we don't understand.\" But M. Feathers sumes up with a different definition he's arrived to over the years:\r\n<blockquote>To me, <em>legacy code</em> is simply code without tests.</blockquote>\r\nHe justifies his definition by explaining:\r\n<blockquote>Code without tests is bad code. It doesn't matter how well written it is; it doesn't matter how pretty or object-oriented or well-encapsulated it is. With tests, we can change the behavior of our code quickly and verifiably. Without them, we really don't know if our code is getting better or worse.</blockquote>\r\nI pretty much agree with all the descriptions and definitions. We could expand them a lot, talk about dependencies, insufficient abstractions etc., but I think that though not very scientific, the descriptions express very well what we mean by <em>legacy code</em> and Mike provides us with a very simple and easily verifiable definition.<br><br><strong>Update</strong>: To get a better grasp of what legacy code is, check the \"<a href=\"http://stackoverflow.com/questions/184618/what-is-the-best-comment-in-source-code-you-have-ever-encountered?page=1&amp;tab=votes#tab-top\">best comments ever</a>\" - some of them express it pretty well.",
  "excerpt": ""
 },
 {
  "title": "What I''ve Learned from (Nearly) Failing to Refactor Hudson",
  "published": "2011-04-28 09:02:51",
  "postType": "post",
  "slug": "/2011/04/28/what-ive-learned-from-nearly-failing-to-refactor-hudson/",
  "status": "publish",
  "tags": [
   "java",
   "legacy",
   "quality"
  ],
  "categories": [
   "General",
   "Languages"
  ],
  "content": "We've <a href=\"/2011/04/16/refactoring-the-legacy-hudson-java-with-the-mikado-method-as-a-code-dojo/\">tried to refactor Hudson.java</a> but without success; only later have I been able to refactor it successfully, thanks to the experience from the first attempt and more time. In any case it was a great learning <a href=\"http://dilbert.com/strips/comic/2009-09-24/\">opportunity</a>.\r\n<h2>Lessons Learned</h2>\r\nThe two most important things we've learned are:\r\n<ul>\r\n\t<li>Never underestimate legacy code. It's for more complex and intertwined than you expect and it has more nasty surprises up in its sleeves than you can imagine.</li>\r\n\t<li>Never underestimate legacy code.</li>\r\n</ul>\r\nAnd another important one: when you're tired and depressed, have some fun reading the \"<a href=\"http://stackoverflow.com/questions/184618/what-is-the-best-comment-in-source-code-you-have-ever-encountered\">best comments ever</a>\" at StackOverflow :-). Seeing somebody else' suffering makes one's own seem to be smaller.<br><br>I've also started to think that the refactoring process must be more rigorous to protect you from wandering too far your original goal and from getting lost in the eternal cycle of fixing something &lt;-&gt; discovering new problems. People tend to do depth-first refactoring changes that can easily lead them astray, far from where they actually need to go; it is important to stop periodically and look at where we are, where we are trying to get and whether we aren't getting lost and shouldn't just prune the current \"branch\" of refactorings and return to some earlier point and try perhaps a completely different solution. I guess that one of the key benefits of the <a href=\"http://danielbrolund.wordpress.com/2009/03/28/start-paying-your-technical-debt-the-mikado-method/\">Mikado method</a> is that it provides you with this global overview - which gets easily lost when it is only in your head - and with points to roll-back to.\r\n<h3>Evils of Legacy Code</h3>\r\nUse a dependency injection framework, for God's sake! Singletons and their manual retrieval really complicate testing and affect the flexibility of the code.<br><br>Don't use public fields. They make it really hard to replace a class with an interface.<br><br>Reflection and multithreading make it pretty difficult if not impossible to find out the dependencies of a particular piece of code and thus the impacts of its change. I'd hard time finding out all the places where Hudson.getInstance is invoked while its constructor is still running.\r\n<h2>Our Way to Failure and Success</h2>\r\nThere is a lot of refactoring that could be done with Hudson.java, for it is a typical <a href=\"http://c2.com/cgi/wiki?GodClass\">God Class</a> which additionally spreads its tentacles through the whole code base via its evil singleton instance being used by just about anyone for many different purposes. Gojko describes some of the <a href=\"http://gojko.net/2011/04/05/how-is-it-even-possible-code-to-be-this-bad/\">problems worth removing</a>.\r\n<h3>The Failure</h3>\r\nWe've tried to start small and \"normalize\" the singleton initialization, which isn't done in a factory method, but in the constructor itself. I haven't chosen the goal very well as it doesn't bring much value. The idea was to make it possible to have potentially also other implementations of Hudson - e.g. a MockHudson - but with respect to the state of the code it wasn't really feasible and even if it was, a simple Hudson.setInstance would perhaps suffice. Anyway we've tried to create a factory method and move the initialization of the singleton instance there but at the end we got lost in concurrency issues: there were either multiple instances of Hudson or the application deadlocked itself. We tried to move pieces of code around, but the dependencies wouldn't have let us do that.\r\n<h3>The Success</h3>\r\nWhile reflecting on our failure I've come to the realization that the problem was that Hudson.getInstance() is called (many times) already during the execution of the <a href=\"https://github.com/iterate/coding-dojo/blob/a83c202519bf693115bad05a19fceb7725876664/2011-04-26-refactoring_hudson/core/src/main/java/hudson/model/Hudson.java#L613\">Hudson's constructor</a> by the objects used there and threads started from there. It is of course a hideous practice to access a half-baked instance before it is fully initialized. The solution is then simple: <em>to be able to initialize the singleton field outside of the constructor, we must remove all calls to getInstance from its context</em>.<br><br><a href=\"https://lh5.googleusercontent.com/_btcPMCQkYvg/TbgptkOKaII/AAAAAAAABqc/qx6UEA4Wzno/s912/Introduce_Hudson_factory-mikadog.png\"><img title=\"Click for full size\" src=\"https://lh5.googleusercontent.com/_btcPMCQkYvg/TbgptkOKaII/AAAAAAAABqc/qx6UEA4Wzno/s640/Introduce_Hudson_factory-mikadog.png\" alt=\"\" width=\"640\" height=\"216\" /></a><br><br>The steps can be seen very well from the <a href=\"https://github.com/iterate/coding-dojo/commits/master/2011-04-26-refactoring_hudson\">corresponding GitHub commits</a>. Summary:\r\n<ol>\r\n\t<li>I used the \"introduce factory\" refactoring on the constructor</li>\r\n\t<li>I modified ProxyConfiguration not to use getInstance but to expect that the root directory will be set before its first use</li>\r\n\t<li>I moved the code that didn't need to be run from the constructor out, to the new factory method - this resulted in some, hopefully insignificant, reordering of the code</li>\r\n\t<li>Finally, I also moved the instance initialization to the factory method</li>\r\n</ol>\r\nI can't be 100% sure that the resulting code has the same semantic as far as it matters, for I had to do few changes outside of the safe automated refactorings and there are no useful tests except for trying to run the application (and, as is common with legacy applications, it wasn't feasible to create them beforehand).<br><br>The refactored code doesn't provide much added value yet but it is a good start for further refactorings (which I won't have the time to try :-( ), it got rid of the offending use of an instance while it is being created and the constructor code is simpler and better. The exercise took me about four <a href=\"http://www.pomodorotechnique.com/\">pomodoros</a>, i.e. little less than two hours.<br><br>If I had the time, I'd continue with extracting an interface from Hudson, moving its unrelated responsibilities to classes of their own (perhaps keeping the methods in Hudson for backwards compatibility and delegating to those objects) and I might even  use some AOP magic to get a cleaner code while preserving binary compatibility  (as Hudson/Jenkins actually <a href=\"http://bridge-method-injector.infradna.com/\">already does</a>).\r\n<h2>Try it for Yourself!</h2>\r\n<h3>Setup</h3>\r\n<h4>Get the code</h4>\r\n<a href=\"https://github.com/iterate/coding-dojo/zipball/INITIAL\">Get the code as .zip</a> or via git:<br><br><pre><code>\r\ngit@github.com:iterate/coding-dojo.git # 50MB =&gt; takes a while\r\ncd coding-dojo\r\ngit checkout -b mybranch INITIAL\r\n</code></pre>\r\n<h4>Compile the Code</h4>\r\nas described in the <a href=\"https://github.com/iterate/coding-dojo/blob/INITIAL/2011-04-26-refactoring_hudson/README-iteratedojo.rst\">dojo's README</a>.\r\n<h4>Run Jenkins/Hudson</h4>\r\n<pre><code>\r\ncd coding-dojo/2011-04-26-refactoring_hudson/\r\ncd maven-plugin; mvn install; cd ..       # a necessary dependency\r\ncd hudson/war; mvn hudson-dev:run\r\n</code></pre><br><br>and browse to <a href=\"http://localhost:8080/\">http://localhost:8080/</a> (Jetty should pick changes to class files automatically).\r\n<h3>Further Refactorings</h3>\r\nIf you're the adventurous type, you can try to improve the code more by splitting out the individual responsibilities of the god class. I'd proceed like this:\r\n<ol>\r\n\t<li>Extract an interface from Hudson and use it wherever possible</li>\r\n\t<li>Move related methods and fields into (nested) classes of their own, the original Hudson's methods just delegate to them (the move method refactoring should be useful); for example:</li>\r\n<ul>\r\n\t<li>Management of extensions and descriptors</li>\r\n\t<li>Authentication &amp; authorization</li>\r\n\t<li>Cluster management</li>\r\n\t<li>Application-level functionality (control methods such as restart, updates of configurations, management of socket listeners)</li>\r\n\t<li>UI controller (factoring this out would require re-configuration of Stapler)</li>\r\n</ul>\r\n\t<li>Convert the nested classes into top-level ones</li>\r\n\t<li>Provide a way to get instances of the classes without Hudson, e.g. as singletons</li>\r\n\t<li>Use the individual classes instead of Hudson wherever possible so that other classes depend only on the functionality they actually need instead of on the whole of Hudson</li>\r\n</ol>\r\n<h3>Learning about Jenkins/Hudson</h3>\r\nIf you want to understand mode about what Hudson does and how it works, you may check:\r\n<ul>\r\n\t<li><a href=\"http://wiki.hudson-ci.org/display/HUDSON/Architecture\">Hudson's Architecture</a> and optionally proceed with</li>\r\n<ul>\r\n\t<li><a href=\"http://wiki.hudson-ci.org/display/HUDSON/Remote+access+API\">Hudson's Remote Access API</a></li>\r\n\t<li><a href=\"http://wiki.hudson-ci.org/display/HUDSON/Extension+points\">Extension points</a></li>\r\n\t<li><a href=\"http://wiki.hudson-ci.org/display/HUDSON/Exposing+data+to+the+remote+API\">Exposing data to the remote API</a></li>\r\n</ul>\r\n\t<li><a href=\"http://wiki.hudson-ci.org/display/HUDSON/Building+Hudson\">Building Hudson</a></li>\r\n\t<li><a href=\"http://stapler.java.net/what-is.html\">Introduction into the UI framework Stapler</a> (its key feature is that it cleverly maps URLs to object hierarchies [and view files and action methods]), perhaps check also <a href=\"http://stapler.java.net/reference.html\">Stapler's reference</a></li>\r\n</ul>\r\n<h2>Sidenote: Hudson vs. Jenkins</h2>\r\nOnce upon time there was a continuous integration server called Hudson but after its patron Sun died, it ended up in the hands of a man called Oracle. He wasn't very good at communication and nobody really knew what he is up to so when he started to behave little weird - or at least so the friends of Hudson perceived it - those worried about Hudson's future (including most people originally working in the project) made its clone and named it Jenkins, which is another popular name for butlers. So now we have Hudson backed by Oracle and the maven guys from Sonatype and Jenkins, supported by a vivid community. This exercise is based on the source code of the Jenkins, but to keep the confusion level low I refer to it often as Hudson for that is how the package and main class are called.\r\n<h2>Conclusion</h2>\r\nRefactoring legacy code always turns out to be more complicated and time-consuming than you expect. It's important to follow some method - e.g. the Mikado method - that helps you to keep a global overview of where you want to go and where you are and to regularly consider what and why you're doing so that you don't get lost in a series of fix a problem - new problems discovered steps. It's important to realize when to give up and try a different approach. It's also very hard or impossible to write tests for the changes so you must be very careful (using safe, automated refactorings as much as possible and proceeding in small steps) but fear shouldn't stop you from trying to save the code from decay.",
  "excerpt": ""
 },
 {
  "title": "How stateless can you go?",
  "published": "2011-04-29 11:05:53",
  "postType": "post",
  "slug": "/2011/04/29/how-stateless-can-you-go/",
  "status": "publish",
  "tags": [
   "coding",
   "fp",
   "java"
  ],
  "categories": [
   "Languages"
  ],
  "content": "I've attended an Oslo Coding <a href=\"http://www.meetup.com/OsloCodingDojo/events/17242062/\">Dojo named \"How stateless can you go?\"</a> lead by <a href=\"http://kjeldahlnilsson.net/\">Thomas K. Nilsson</a>. The goal was to write a toString() method for a tree structure printing nodes with proper indentation w.r.t. their depth and then to make it as stateless as possible without any other regard (such as performance or cleanliness of the code).<br><br>It was very interesting to compare the original, stateful version and the resulting stateless one and to see the solution in various languages (Haskell, Clojure, Groovy, C#, Java, Scala) - it looked actually pretty similar in all.<br><br>What I've learned is that stateless (i.e. functional-style) code looks much cleaner for you get rid of lot of noise such as local variables and loops. In practice it is important to use a language with an efficient implementation of recursion (especially <a href=\"http://en.wikipedia.org/wiki/Tail_call\">tail-recursion</a>) and with data structures that lead themselves easily to recursive processing, i.e. make it easy and efficient to process the first element of a collection and do that recursively for the rest without modifying the collection (and providing utility methods like each). It is of course best to have languages that support map/reduce.<br><br>You can <a href=\"https://github.com/thomanil/osloCodingDojoApril2011\">check the slides and various solutions at GitHub</a> and see our primitive and stateless implementations below. (We did it in a nearly TDD-manner, but I won't include the test here as it isn't essential.)<br><br><strong>Update</strong>: There are <a href=\"http://www.meetup.com/OsloCodingDojo/events/17242062/\">more solutions</a> linked to from the meetup's comments - search for \"github\" - and there is also a link to an article series for <a href=\"http://prog21.dadgum.com/23.html\">deeper discussion of challenges in writing pure and stateless code</a>.<br><br><!--more-->\r\n<h2>Solution by Jakub &amp; Anders</h2>\r\n<h3>The Primitive Implementation</h3>\r\n<pre><code>\r\n// ...\r\n   @Override\r\n   public String toString() {\r\n      return toString(0);\r\n   }<br><br>   private String toString(final int nesting) {\r\n      String tabs = &quot;&quot;;\r\n      for (int i = nesting; i &gt; 0; i--)\r\n         tabs += &quot;\\t&quot;;<br><br>      return tabs + this.content + &quot;\\n&quot;\r\n         + printChildren(nesting + 1, new LinkedList(this.children));\r\n   }<br><br>   private String printChildren(int nesting, List children) {\r\n      String result = &quot;&quot;;\r\n      for (Node child : children) {\r\n         result += child.toString(nesting);\r\n      }\r\n      return result;\r\n   }\r\n// ...\r\n</code></pre>\r\n<h3>Going Stateless</h3>\r\nLoops removed:<br><br><pre><code>\r\n// ...\r\n@Override\r\n   public String toString() {\r\n      return toString(&quot;&quot;);\r\n   }<br><br>   private String toString(final String indentation) {\r\n      return indentation + this.content + &quot;\\n&quot;\r\n         + printList(indentation + &quot;\\t&quot;, new LinkedList(this.children));\r\n   }<br><br>   private String printList(String indentation, LinkedList children) {\r\n      if (children.isEmpty()) return &quot;&quot;;\r\n      return children.pop().toString(indentation) + printList(indentation, children);\r\n   }\r\n// ...\r\n</code></pre><br><br>Cloning the List is perhaps not a good thing from the performance point of view, but that wasn't the concern here; other languages can deal with that much more efficiently than Java. Anyway I've created a version without it (but with ugly integer constants instead):<br><br><pre><code>\r\n// ...\r\n   private String toString(final String indentation) {\r\n      return indentation + content + &quot;\\n&quot;\r\n         + printList(indentation + &quot;\\t&quot;, children);\r\n   }<br><br>   private String printList(String indentation, List children) {\r\n      if (children.isEmpty()) return &quot;&quot;;\r\n      return children.get(0).toString(indentation)\r\n         + printList(indentation, children.subList(1, children.size()));\r\n   }\r\n// ...\r\n</code></pre>\r\n<h3>Appendix: The Node Class</h3>\r\nThe rest of the Node class representing the tree to be printed is the same in all our solutions:<br><br><pre><code>\r\npackage scotsman;<br><br>import java.util.LinkedList;\r\nimport java.util.List;<br><br>public class Node {<br><br>   private String content;\r\n   private List children;<br><br>   public Node(String content) {\r\n      this(content, new LinkedList());\r\n   }<br><br>   public Node(String content, List children) {\r\n      this.content = content;\r\n      this.children = children;\r\n   }<br><br>   public Node withChild(Node child) {\r\n      children.add(child);\r\n      return this;\r\n   }<br><br>   // toString implementation comes here...<br><br>}\r\n</code></pre>\r\n<h2>Conclusion</h2>\r\nFunctional programming is cool. Being in Oslo is cool. :-)",
  "excerpt": ""
 },
 {
  "title": "Most interesting links of May",
  "published": "2011-05-31 21:59:17",
  "postType": "post",
  "slug": "/2011/05/31/most-interesting-links-of-may-2/",
  "status": "publish",
  "tags": [
   "BDD",
   "best practices",
   "book",
   "development",
   "Git",
   "java",
   "JavaScript",
   "lean",
   "logging",
   "refactoring",
   "Testing"
  ],
  "categories": [
   "General",
   "Languages",
   "Testing",
   "Tools",
   "Top links of month"
  ],
  "content": "<h2>Recommanded Readings</h2>\r\nAcceptance testing / Specification by example:\r\n<ul>\r\n\t<li><a href=\"http://gojko.net/2010/06/16/anatomy-of-a-good-acceptance-test/\" rel=\"bookmark\">Gojko Adzic: Anatomy of a good acceptance test</a> - an example of refactoring a bad acceptance test into a good one - good for learning about pitfalls and how a good one should look like</li>\r\n\t<li>Gojko: <a href=\"http://gojko.net/2009/09/24/top-10-reasons-why-teams-fail-with-acceptance-testing/\" rel=\"bookmark\">Top 10 reasons why teams fail with Acceptance Testing</a> - acceptance testing is great and brings lot of value but must not be underestimated; some of the problems are bad collaboration, focusing on \"how\" instead of \"what,\" confusing AT with full regression tests. Brief, worth reading.</li>\r\n\t<li><a href=\"http://watirmelon.com/2011/05/18/specification-by-example-a-love-story/\">Specification by Example: a love story</a> (go directly to the <a href=\"http://watirmelon.files.wordpress.com/2011/05/specificationbyexamplealovestory.pdf\">PDF with the story</a>): A nice, made-up story of going from low-level, workflow-based Selenium tests through similar Cucumber ones to true BDD tests describidng clearly what, not how - very well shows the point of specification by example and how it should (and should not) look like</li>\r\n</ul>\r\n(Enterprise) Java best practices:\r\n<ul>\r\n\t<li> <a href=\"http://nurkiewicz.blogspot.com/2010/05/clean-code-clean-logs-use-appropriate.html\">Clean code, clean logs: 10 brief posts on logging best-practices</a> - nothing really new here for me but in total it is a very good overview that every developer should know</li>\r\n\t<li><a href=\"http://continuousdelivery.com/2011/05/make-large-scale-changes-incrementally-with-branch-by-abstraction/\">Make Large Scale Changes Incrementally with Branch By Abstraction</a> - Continuous integration doesn't work well with branches but as this article shows, you can manage even large-scale refactorings without branches using \"branch by abstraction,\" an approach reminding me of Fowler's \"<a href=\"http://martinfowler.com/bliki/StranglerApplication.html\">strangler application</a>\" (an incremental replacement of a legacy system). The idea is: 1. Create an abstraction over the part of code to be changed;  2. Refactor the code to use it; 3. Implement new functionality using the new way / step by step move old functionality too, the abstraction layer delegating either to the new or old implementation ... . It may be more work but: 1) your software is always working and deliverable; 2) (side-effect) in the end it will be more decoupled</li>\r\n</ul>\r\nGit:\r\n<ul>\r\n\t<li>John Wiegley's <a href=\"http://ftp.newartisans.com/pub/git.from.bottom.up.pdf\">Git from the bottom upp</a> (31p, Git 1.5.4.5, PDF) - a useful explanation of the fundamentals of Git, i.e. how it is constructed and how it works, which makes it much easier to understand how to  use it properly (recommended by Pål R.). Reading the <a href=\"http://tom.preston-werner.com/2009/05/19/the-git-parable.html\">The Git Parable</a> first may be a good idea for an easy introduction into the fundamentals, though absolutely not necessary. This document introduces very well the important Git concepts (blob, index, commit, commit names such as branches, reflog) and how they cooperate to provide the rich set of functionality it has. It also explains well the value and usage of rebase. Among others I've appreciated the tip to use checkout, branch -m &lt;new-branch&gt; master, branch -D instead of the much more dangerous reset --hard and the tip to use stash / stash apply to create daily backups of your working tree in the reflog (with clearing it with '<em>git reflog expire --expire=30.days refs/stash</em>' instead of <em>stash clear</em>). Also git diff/log master..[HEAD] for reviewing work done in the current branch and and git diff/log ..master for checking the changes since the last merge/rebase after a fetch are interesting.</li>\r\n</ul>\r\nTools:\r\n<ul>\r\n\t<li><a title=\"Permanent Link to The secret power of bookmarklets\" href=\"http://www.webdesignerdepot.com/2011/05/the-secret-power-of-bookmarklets/\" rel=\"bookmark\">The secret power of bookmarklets</a> - bookmarklets are an indispensable tool for every developer who works with web applications (to fill in test data, speed up log in, ...), yet I'm sometimes surprised by meeting people who don't know or use them; this blog explains them nicely, links to some useful ones and some useful tools for building them</li>\r\n</ul>\r\n<h2>Recommended Books</h2>\r\n<ul>\r\n\t<li>(*****) <a href=\"http://www.amazon.com/gp/product/0321437381/\">Implementing Lean Software Development: From Concept to Cash</a> by Mary Poppendieck, Tom Poppendieck - A great introduction into lean thinking (the values and principles it is build upon), clearly communicated with the help of \"war stories\". I absolutely recommend it to anybody interested in lean/agile.</li>\r\n\t<li>(**** ) <a href=\"http://www.amazon.com/gp/product/073561993X/\">Agile Project Management with Scrum</a> (Microsoft Professional) by Ken Schwaber - Even though you can't understand Scrum without experiencing it, this book full of war stories will help you to avoid many Scrum implementation pitfalls and to understand its mantra of \"the art of the possible\" and will show you how to adapt Scrum to various situations. It's very easy to read thanks to its format of brief case studies organized by topics (team, product owner, ...).</li>\r\n</ul>\r\n<h2>Favourite Quotes of the Month</h2>\r\n<a href=\"http://www.linkedin.com/osview/canvas?_ch_page_id=2&amp;_ch_panel_id=3&amp;_ch_app_id=38374450&amp;_applicationId=2700&amp;_ownerId=19933118&amp;osUrlHash=Mt3-&amp;appParams=%7B%22screen_name%22%3A%22unclebobmartin%22%7D\" rel=\"{&quot;screen_name&quot; : &quot;unclebobmartin&quot;}\" target=\"_top\">@unclebobmartin</a>: Cleaning code does NOT take time. NOT cleaning code does take time.",
  "excerpt": ""
 },
 {
  "title": "Installing Java 1.4 to Mac OS X 10.6",
  "published": "2011-05-11 09:59:27",
  "postType": "post",
  "slug": "/2011/05/11/installing-java-1-4-to-mac-os-x-10-6/",
  "status": "publish",
  "tags": [
   "java",
   "mac"
  ],
  "categories": [
   "General",
   "Languages"
  ],
  "content": "Sometimes you really need java 1.4, mainly because just compiling with -target doesn't protect you from inadverently using an API that only exists in 1.5+.<br><br>Fortunately, <a href=\"http://jevopisdeveloperblog.blogspot.com/2010/06/install-strictly-j2se-14-compatible-jre.html\">Jens v. P. has described how to install Java 1.4 on Mac OS X</a> without destroying your current (latest) java installation - download Java_for_Mac_OS_X_10_5_Update_4 from Apple and use Pacifist to install only System/Library/Frameworks/JavaVM.framework/Versions/1.4.2 and 1.4. Thanks, Jens!",
  "excerpt": ""
 },
 {
  "title": "Discussion: Agile not suitable for governmental IT?",
  "published": "2011-05-06 15:43:00",
  "postType": "post",
  "slug": "/2011/05/06/discussion-agile-not-suitable-for-governmental-it/",
  "status": "publish",
  "tags": [
   "agile",
   "lean",
   "opinion"
  ],
  "categories": [
   "General"
  ],
  "content": "The recent article <a href=\"http://www.computerweekly.com/blogs/public-sector/2011/04/agile-will-fail-govit-says-cor.html\">Agile will fail GovIT, says corporate lawyer</a> is rather controversial but very valuable. Its value lays not in its claim that agile cannot work in governmental environment, something I quite disagree with, but in its presentation of how (inaccurately) agile is/may be perceived in this environment and of obstacles posed by such an environment to any (and especially to agile) development.<br><br>The article reveals a fundamentaly psychological and social issue. It doesn't question the ability of agile to deliver projects much more successfully than waterfall. The laywer, Alistair Maughan, doesn't speak at all about projects' results. He speaks about fear (to bear the consequences of a failure) and constraints present in governmental environment. Thus it's pointless to argue about benefits of the agile and absurdity of the waterfall approaches. The key to a successful project is to understand those constraints, lift them as much as possible, and create a security structure for both governmental officials and the supplier to be able to work within those constraints safely. We shouldn't forget that there are also smart people in the government agencies who will gladly accept a methodology that leads to better results as long as they are safe from being denounced on the front side of newspapers as bad public servants when something goes wrong.<br><br><!--more-->That, of course, isn't easy. But successful agile projects in the public domain prove that it is possible.<br><br>An agile approach will never be able to deliver a large, multi-year project within budget, with agreed upon (detailed) features, and on time. Of course a waterfall approach won't be able to do that either - but, contrary to agile, it can pretend that it can do it. It will fail (or maybe \"succeed,\" producing something that nobody really wants), but everybody concerned will be safe enough - only tax payers will mourn.<br><br>Perhaps the only feasible way to realize an agile project in the public domain is to break the task into multiple projects small enough to be estimated with sufficient reliability (and if the estimates are wrong, such short time frame that they cannot go too wrong) so that the supplier can commit to a fixed price and scope<sup>1</sup>. The customer would be then obliged to take over the deliverable and pay for it (to avoid \"it's great, but we need these two more features to make it usable\").<br><br>An experienced team, knowing both the domain and technology, can estimate quite reliably in perhaps a three months horizon. So the supplier can make an umbrella contract, which breaks the task into individual 3-months fix-price projects, each starting with a new detailed contract and ending with a working, paid-for deliverable. If the task cannot be broken into such incremental deliverables than it is heading into big troubles and you don't want to be there anyway.<br><br>There is a nice example of how to form a contract so that the customer can feel safe in the blog post <a href=\"http://zakholdsworth.com/tag/agile-contract-negotiation/\">Selling Software Projects by Demonstrating Value Early</a>. It also mentions the time &amp; material contract, mistakenly taken as an essential characteristics of \"agile\" by some, including likely the A. Maughan:\r\n<blockquote>We will work time and materials, it will cost you approximately this much per sprint, and we think it will take about this many sprints but are not really sure. Furthermore, we don’t know exactly how long it is going to take, or what we are going to deliver.</blockquote>\r\n<!--more-->Of course most customers - not only governmental ones - would have problems accepting this.<br><br>I will quote some interesting parts of the article and its comments, for a full picture I'd recommend you reading them for yourself.<br><br><em>1) The idea of breaking project down into fixed-price (1-)3 months projects doesn't come from me but one clever person who I'd need to ask for permission to name.</em>\r\n<h2>The Article</h2>\r\nQuotes:\r\n<blockquote>I'm prepared to accept on trust that, if all goes well, Agile may reduce the risk of project failure. But Agile simply won't work in the real world of government ICT.\r\n...<br><br>It means customers don't pay a fixed price for a complete project. They pay for a commitment of resources.<br><br>...<br><br>But the lack of clearly defined project roles and requirements is a problem for Agile.<br><br>...<br><br>Agile projects rely on decisions based on mutual trust. They are therefore well suited to in-house projects. But the faith they ask customers to have in service providers makes them ill-suited for external developments.<br><br>...<br><br>You can have an ICT project with a watertight contract, clear deliverables, openly and legally procured, with a fixed price and appropriate remedies if you don't get what you want. Or you can have an Agile project. You can't have both.</blockquote>\r\nAccording the the laywer, there are four clear reasons why Agile won't work in government ICT\r\n<ol>\r\n\t<li>Government customers want to know up-front how much a system will cost; \"Under Agile [..] can't guarantee a specified outcome for a specific price\"</li>\r\n\t<li>Government has to compare different bidders on a like-for-like basis but \"Agile can't give you a clear specification of outputs up-front. Nor can it give a definitive up-font price.\"</li>\r\n\t<li>\"Agile offers insufficient means of remedy if things go wrong\" - for \"Agile makes it hard to apportion blame because the customer is intimately involved in the work.\" (Wohoo - blame &amp; fear-driven development! :-))</li>\r\n\t<li>Decision-making is centralised in government, every important decision flows up to senior levels</li>\r\n</ol>\r\n<h3>Conclusion</h3>\r\nAs I understand it, the main challenge in governmental project is the bureaucratic nature of the customer. More exactly the following implications:\r\n<ol>\r\n\t<li>Requirement of fixed price, time and scope</li>\r\n\t<li>Paralyzed decision-making process - nobody but the top decision makers really dares to make a decision and they are not available and/or too far away from the problem beeing solved to be able to decide properly and timely</li>\r\n\t<li>Need to \"apportion blame,\" absence of trust</li>\r\n</ol>\r\nThese factors are very real and every project has to deal with them, being agile or not. Both the agile development methodology and the governmental environment must be adjusted to make a project possible at all.<br><br>Development happens in 4D space: time, money, scope, quality. You can ever fix only 3 of these axis (and it cannot be quality for quick&amp;dirty is a contradiction). Pretending that you can fix all of them is a lie. Agile can guarantee fixed price and time but the scope (expressed as a high-level business values and epics)  must vary - to a certain degree - to provide for  inherent complexity of the domain and to provide flexibility for finding out what the customer really needs. It should be noted that detailed up-front specifications lead to the customers trying to add any possible feature they may think of even though 45% of them will never be used and 19% only rarely (Standish Group Study reported at XP2002 by Jim Johnson, taken from Mary Poppendieck's Lean Software Development slides). Wouldn't it be better to develop only those ~ 20-35% features whose benefit justifies their cost to get the software at a much lower cost and shorter time?<br><br>Without some level of trust (which, of course, cannot just \"happen,\" but must be gradually built) and a decision structure that actually works, every project will most likely terribly fail. A \"watertight contract\" and \"clear deliverables\" are not a solution as the history of failed waterfall projects has shown because only rarely does the customer really know what exactly he needs and mis-trust based relation hinders cooperation and communication, the very essential precondition of a successfull project. \"Appropriate remedies\" won't really help anyone, even if the customer gets most money back, he will have wasted many resources. On the other hand, trust is not something you can expect from a bureaucratic ogranization so, as mentioned, you must construct a security structure to get rid of the fear preventing cooperation.<br><br>By the way, this reminds me of Mary Poppendieck's explanation while other US airlines cannot reproduce the success of the lean SouthWest Airlines - they are too much stuck where they are and driven by short-term profits and thus visions - due to their dependency on the short-sighted stock holders - rather than (potentially much higher)  long-term ones.<br><br>The culture in government agencies is often little suitable for agile development, but it is possible to a feasible way of introducing agile there by breaking projects into small, few-months ones or perhaps by using a hybrid agile approach, as described in the comments by Dylan Jay.\r\n<h2>The Comments</h2>\r\nI've extracted (for me) interesting parts of the comments; doing so I might have inadvertently changed what the author intended to express.<br><br>I've actually copied so much of the comments that the rest of this post feels more like a steal-work than a creation of my own. I hope the authors will forgive me, even though I've violated the basic rule of quoting and decency and failed to include their names for the most part.<br><br>You should absolutely check three comments - A. Maughan's reaction to the comments (right below), an overview of the DSDM method by the DSDM Consortium's Technical Director Andrew Craddock (<a href=\"http://www.computerweekly.com/blogs/public-sector/2011/04/agile-will-fail-govit-says-cor.html#comment-10131836\">original</a>), and Dylan Jay's description of a successful hybrid agile project (<a href=\"http://www.computerweekly.com/blogs/public-sector/2011/04/agile-will-fail-govit-says-cor.html#comment-10324667\">original</a>). You should also consider looking at the follow-up post by Nik Silver, <a href=\"http://niksilver.com/2011/04/27/agile-ukgovit/\">Agile government IT can succeed</a>.\r\n<h3>Author's response to the comments</h3>\r\nThe <a href=\"http://www.computerweekly.com/blogs/public-sector/2011/04/agile-will-fail-govit-says-cor.html#comment-10310814\">author, Alistair Maughan, responds to the comments</a> among others by saying:\r\n<blockquote>I don’t actually think Waterfall is the best idea since sliced bread, nor that Agile is the worst idea since the Sinclair C5.<br><br>But I really do believe the public sector environment leaves Agile little chance of being adopted properly, let alone applied widely.<br><br>[...]<br><br><strong>Project staff should be allowed to work without fear of procurement challenge, public humiliation and the blame culture that seems to come with major public sector projects. If that changes, Agile in Government may blossom. Sadly, there’s no chance of that happening, but it's a nice thought.*</strong></blockquote>\r\n<em>*) Emphasized by me</em><br><br>Among other problems, he mentions EU-mandated procurement regime and losing bidders challenging procurement awards, the centralization of ICT governance within (UK) government, the fear of failure caused among others by \"baying media, the hyper-critical Parliamentary Accounts Committee, and the National Audit Office\", the scrutinization of every penny spent to death andthe requirement of accounting each penny up-front.\r\n<h3>The commentators</h3>\r\nAbout waterfall:\r\n<blockquote>From what I've read in research literature (and heard anecdotally about failed government IT projects) I don't think the waterfall method has been particularly successful in guaranteeing a specified outcome either!</blockquote>\r\nAnother:\r\n<blockquote>government agencies  are \"a system whereby apportioning blame after the fact is more important than ever delivering anything\"</blockquote>\r\nOn outcome specification (btw, the <a href=\"http://www.dsdm.org/case-studies\">DSDM case studies</a> include a governmental agency):\r\n<blockquote>With the latter [the <a href=\"http://en.wikipedia.org/wiki/Dynamic_Systems_Development_Method\">DSDM</a> method] it is possible to guarantee a minimum specified outcome for a set price. (As much of a guarnatee as can be given for more tradtional methods at any rate).</blockquote>\r\nAt least some government agencies can succeed with agile:\r\n<blockquote>I have personally been involved in delivering a fixed price Agile project to a government customer. The project was a huge success that delivered something a traditional waterfall approach had spent 3 years trying to deliver and failing.</blockquote>\r\nAgile fails (too) simply because the customer is paralyzed by bureaucracy:\r\n<blockquote>I've worked on several \"agile\" public sector projects, and none of them have delivered any of the promised advantages of Agile. The reasons are probably familiar to anybody who's worked on government IT projects: slow and bureaucratic internal processes, inability to take decisions, inability to decide on requirements (ever), lack of commitment from business users, lack of understanding of Agile in IT departments, inability to deliver rapid iterations, lack of rapid feedback between users/developers, lack of empowered business representatives, [...]<br><br>\"[...] But you can't guarantee a specified outcome for a specific price.\"<br><br>That is true. It is equally true of the methods governments and others have used in the past, and of the methods recommended for government ICT today. It is true of all software development methods, past and present. Therefore, the statement does not distinguish between any two methods.</blockquote>\r\nAbout the faulty culture:\r\n<blockquote>I broadly agree with this article. It's clear to me the mismatch in social capital culture between government and the conditions under which Agile is designed to work.<br><br>[...]<br><br>Rob Knight's comment quoting DeMarco is correct. Managing cost is most relevant where the payoff is closely matched to the cost. Most IT projects have massive asymmetric payoffs. It is better to manage schedule and scope and to launch early in order to realize the opportunity \"costs\" of delay. Recognizing greater benefit early.<br><br>What this article does well is demonstrate that current government procurement procedures and governance are unsuitable for managing IT projects on behalf of tax payers.<br><br>It would be better to advocate for this change. [to align the governmental culture with Agile/Lean thinking]</blockquote>\r\nOn the contract:\r\n<blockquote>Of course, continuing to use old-style contracts won't work with lean &amp; agile approaches (of course, they mostly don't result in the desired outcomes anyway).<br><br>Hence, the move toward outcome-based agreements, predicated on output-based pricing regimes. These aren't new. They've been used for over 15 years to my knowledge. But they may be unfamiliar to specific individuals, naturally.<br><br>An 'agile contract' does not have to be an agreement to buy a certain amount of effort at an agreed price. That's not agile. That's 'time &amp; materials'.</blockquote>\r\nAnother success of agile @ governmental env.:\r\n<blockquote>[..] agile has been used very successfully in government projects by Valtech, see my blog post <a href=\"http://www.pharmarketeer.com/2010/05/16/agilenorth.html#agile-in-waterfall-case-studies\">http://www.pharmarketeer.com/2010/05/16/agilenorth.html#agile-in-waterfall-case-studies</a> [..]</blockquote>\r\nOn the \"Agile makes it hard to apportion blame [...]\"\r\n<blockquote>Yes its true that agile focuses on heading off problems early when they are still small problems rather than waiting until the end when its too late and you need to find someone else to sue and hold accountable for your disaster.</blockquote>\r\nOn non-agility of one of the two failed \"agile\" project cases:\r\n<blockquote>I worked on a system that was downstream from the one EDS built for Sky and I can assure you, whatever the publicity, that it didn't look Agile. From what I remember, the court case turned on the untrustworthiness of the lead salesman. No Agile project I've worked on could run to completion without that sort of issue being raised and addressed earlier.</blockquote>\r\nEx-public servant who experienced agile in the public domain:\r\n<blockquote>I am an ex-public servant who has worked in teams that have delivered highly successful agile projects using DSDM coupled with PRINCE2, and in the interests of being balanced, worked on a really bad ‘agile’ project that is currently stalled owing to procurement rules – note the ‘a’, but it still delivered a working product. In fact I learned my agile trade as a civil servant.</blockquote>\r\nFixed-price, fixed-scope projects results in additional hidden costs (making the described process open actually results in the proposed break down into multiple projects :-) ):\r\n<blockquote>With a typical fixed scope fixed price contract there is a lot of \"discussion\" between government purchaser and IT vendor to come to an arrangement of agreement that the delivery meets the initial scope requirements. Nobody in government wants to have backed a loser, so its best if the system is agreed to have met its scope. Once this has happened, then a number of expensive change requests are put through to change the system into one that is deployable. These change requests are often budgeted separately, so its harder to see the true cost of the system.</blockquote>\r\nIs it really necessary to blame somebody?\r\n<blockquote>Is it fair to label Agile projects as failed when all they did was surface issues much more quicker than in a traditional approach? And thereby save tons of money that would otherwise be wasted?</blockquote>\r\nFear-based culture of the bureaucratic agencies (the last sentence of the second paragraph made me really lough):\r\n<blockquote>This blog post isn't about succeeding at delivering useful working systems. It's about limiting the impact of inevitable failure.<br><br>I worked with a developer once who devoted most of his time to making sure when we failed he wouldn't get any of the blame. He was absolutely horrified when he realised we were actually setting out to succeed. He now works in the public sector, and is thriving.</blockquote>\r\nOn the DSDM method by Andrew Craddock, the DSDM Consortium's Technical Director (including partly as an overviw of DSDM):\r\n<div>\r\n<blockquote>Well, as a director of the DSDM Consortium I am delighted to say that for DSDM at least this 'fad' has now lasted well over 15 years and, during that time, has even been used successfully in government IT.<br><br>[..]<br><br>It is true to say that I have seen some very poorly controlled Agile projects in my time. I have also seen the ill-discipline of those projects being fraudulently passed of as ‘the way it is with Agile’. I can only assume that Messrs Maughan and/or Ballard have experienced this ‘cowboy’ agility and been suckered by the ‘that’s the way it is’ fob off.<br><br>DSDM Atern includes a clearly defined Foundations phase which considers, but avoids the detail of, business need and process, technical architecture and delivery approach, timelines and the precise way the project will be configured for success.<br><br>It has a set of 10 core roles each with clearly defined responsibilities. It is more complex than the role sets of other Agile approaches and for some smaller organisations running simpler projects it might be seen as over-kill but for large projects in complex environments such as those often a reality in government it is ideal.<br><br>It has a set of 5 core practices with MoSCoW Prioritisation and Timeboxing heading the charge in making a fixed time, fixed cost, fixed quality expectation for a project a reality. Iterative Development supported where appropriate by Modelling and Facilitated Workshops ensure that the right solution with the optimum value is delivered within these constraints.</blockquote>\r\nReality of development:\r\n<blockquote>Government then needs to accept what software development is. Software projects are never delivered [the author likely means that it is never finished, it always needs to evolve]. Maintenance will always cost, and changes will always be needed. Agile processes accept this from day one, Waterfall never faces this reality.</blockquote>\r\nA successful hybrid approach by Dylan Jay (full copy):\r\n<div>\r\n<blockquote>Hybrid Agile models can work and has worked very successfully for us with a large government project.\r\nIt worked liked this:<br><br>First the project was broken down to two phases, Business analysis and development. There was a fixed price for both BA and development. In BA we did upfront use case analysis to create an accurate spec and quote for the development phase, but this could have been tendered for and performed by another party.<br><br>For development we used a version of SCRUM. It was clear what was getting created but as others have pointed out it wasn't determined upfront how the functionality would be developed and when, just what the final cost was, and the number and length of the iterations. Progress payments were tied to the delivering each iteration however the success criteria for the progress payments was only determined when the contents of the iteration was determined at the beginning of that iteration, ie it was semi-dynamic user acceptance criteria.\r\nIn the end the scope of the project didn't change that much and when it did it was dealt with how it would in a normal fixed price contract, as a variation to the contract. The real advantage however was those variations were discovered much earlier and in many cases didn't result in increased cost to the customer as almost as many stories were discarded as were added. Fixed price waterfall models have equal chance of changing scope and all changes to scope will require contract variations and those variations result in more money being paid. The agile model above gave us the flexibility remove functionality the customer didn't need and replace it with functionality they did need.<br><br>There is a presentation on some aspects of this job but most of the focus of this presentation was on the way we combined usecase analysis with functional test driven development<br><br><a href=\"http://www.slideshare.net/djay/test-browser-driven-development\">http://www.slideshare.net/djay/test-browser-driven-development</a>\r\n<a href=\"http://www.ustream.tv/recorded/2445994\">http://www.ustream.tv/recorded/2445994</a></blockquote>\r\n</div>\r\n</div>",
  "excerpt": ""
 },
 {
  "title": "Most interesting links of April (renewed)",
  "published": "2011-04-30 21:59:44",
  "postType": "post",
  "slug": "/2011/04/30/most-interesting-links-of-april-renewed/",
  "status": "publish",
  "tags": [
   "BI",
   "lean",
   "Testing"
  ],
  "categories": [
   "General",
   "Testing",
   "Tools",
   "Top links of month"
  ],
  "content": "Only two articles this month:<br><br><a href=\"http://www.computerworld.com/s/article/9215504/22_free_tools_for_data_visualization_and_analysis\">Computerworld: 22 free tools for data visualization and analysis</a><br><br>- great review if different categories of data analysis and visualization tools. The tools I haven't known (i.e. excluding <a href=\"http://www.r-project.org/\">R</a>, Google Charts etc.) and found them especially interesting:\r\n<strong>Data web apps</strong>: <a href=\"http://code.google.com/p/google-refine/\">Google Refine</a> (data cleansing in a spreadsheet-like UI: clustering, data distribution overview, ...), <a href=\"http://www.google.com/fusiontables/Home\">Google Fusion Tables</a> (data =&gt; map etc., beta), <a href=\"http://www.impure.com/\" target=\"new\">Impure</a> (rich &amp; interactive data visualization via a drag-and-drop UI reminiscent of Yahoo Pipes; cons: lacking documentation, steep learning curve, check the <a href=\"http://www.youtube.com/user/impuremotion#p/u/0/ZdSgrFQmY74\">teaser video</a>).\r\n<strong>JS libraries</strong>: <a href=\"http://simile-widgets.org/exhibit\">Exhibit</a> (JavaScript library by MIT for creating interactive visualizations e.g. for articles - incl. maps, timeplots, calendars etc., supporting filtering, sorting, searching), <a href=\"http://thejit.org/\">InfoVis Toolit</a> (JS lib for interactive data visualizations; pros: beautiful, cons: choice of visualization types is somewhat limited), <a href=\"http://vis.stanford.edu/protovis/\" target=\"new\">Protovis</a> (by Stanford University's Visualization Group; one of the more popular JS libraries for turning data into visuals, great docs, robust); <a href=\"http://openlayers.org/\" target=\"new\">OpenLayers</a> ( <a href=\"http://wiki.openstreetmap.org/wiki/OpenLayers_Simple_Example\">example</a>; customize &amp; display a map, e.g. Open Street Map of Google), <a href=\"http://polymaps.org/\">Polymaps</a> (interactive maps with overlays)\r\n<strong>GIS</strong>: <a href=\"http://www.openheatmap.com/\" target=\"new\">OpenHeatMap</a> (webapp, \"astonishingly easy to create a color-coded map from many types of location data\")\r\n<strong>Other</strong>: Timelines with <a href=\"https://github.com/FlowingMedia/TimeFlow/wiki/\" target=\"new\">TimeFlow</a> (interesting desktop /java/ app x alpha) or <a href=\"http://www.simile-widgets.org/timeline/\" target=\"new\">SIMILE Timeline widget</a> (JS); Word clouds: <a href=\"https://www14.software.ibm.com/webapp/iwm/web/preLogin.do?source=AW-0VW\" target=\"new\">IBM Word-Cloud Generator</a> (free, desktop /java/); <a href=\"http://gephi.org/\">Gephi</a> (graph/network visualization &amp; exploration; desktop)<br><br><a href=\"http://www.catosplace.net/blogs/personal/?p=854\">The Evolution of Test Driven Developers</a><br><br>- an entertaining and enlightening article with valuable links to resources that can help you get to the next evolutionary step, one of its benefits is that it helps to understand the true value of the different types of tests (some -&gt; TDD -&gt; Behaviour Driven Development ('what' rather than 'how') -&gt; Acceptance Test Driven Development) and the shift from a technical to a business perspective along the line",
  "excerpt": ""
 },
 {
  "title": "Ivy: How to Retrieve Source Codes of Dependencies",
  "published": "2011-05-20 12:20:49",
  "postType": "post",
  "slug": "/2011/05/20/ivy-how-to-retrieve-source-codes-of-dependencies/",
  "status": "publish",
  "tags": [
   "ivy"
  ],
  "categories": [
   "Tools"
  ],
  "content": "<p style=\"text-align:center;\"><em>Summary: To download sources you must map the dependency's conf also to 'sources' (ex.: <code>conf=\"myScope-&gt;default,sources\"</code>).</em></p>\r\nIf you are using <a href=\"http://ant.apache.org/\">Apache Ivy</a> (2.2) for maintaining you dependencies, you may also want to retrieve source codes (or javadocs) of those dependencies, e.g. to get nice help pop-ups in Eclipse or to actually browse the sources. Provided that you're retrieving the dependencies from Maven repositories, the configuration required to enable retrieval of source codes is to map to the Ivy \"configuration\" (\"scope\", or perhaps more exactly classifier, in the Maven language) called \"<code>sources</code>\" (or \"<code>javadoc</code>\" to fetch JavaDocs).<br><br><!--more--><br><br>To find out what target configurations are defined, you may check the generated Ivy metadata for a downloaded Maven artifact, for example ~/.ivy2/cache/org.springframework/spring-context/ivy-2.5.6.xml - check &lt;configurations&gt; for (obviously) the configurations and &lt;publications&gt; to find out what artifacts are available in which configurations (ex.: ...name=\"spring-context\" type=\"source\" ext=\"jar\" conf=\"<em>sources</em>\"...).\r\n<h2>Example: Ivy.xml with non-standard configurations</h2>\r\n<pre><code>\r\n&lt;!-- ivy.xml --&gt;\r\n...\r\n   &lt;configurations&gt;\r\n      &lt;conf name=&quot;oracle-war&quot; description=&quot;Runtime dependencies for deploying to an Oracle container.&quot; /&gt;\r\n      &lt;conf name=&quot;compile&quot; extends=&quot;oracle-war&quot; visibility=&quot;private&quot; description=&quot;Additional compile time dependencies required to build the application.&quot; /&gt;\r\n   ...\r\n   &lt;/configurations&gt;<br><br>   &lt;dependencies&gt;\r\n      &lt;dependency org=&quot;org.springframework&quot; name=&quot;spring-webmvc&quot; rev=&quot;2.5.6&quot; conf=&quot;oracle-war-&gt;default,sources&quot; /&gt;\r\n...\r\n</code></pre><br><br>Notes:\r\n<ul>\r\n\t<li>We first define some custom configurations (scopes), including <em>oracle-war</em></li>\r\n\t<li>Next we define a dependency belonging into the configuration <em>oracle-war</em> and map it to the target configurations <em>default</em> and <em>sources</em>, i.e. we depend on anything which is published either in the default configuration (-&gt; spring-webmvc-2.5.6.jar) or in the sources configuration (-&gt; spring-webmvc-2.5.6-sources.jar)</li>\r\n\t<li>Notice that we could use <a href=\"http://ant.apache.org/ivy/history/2.2.0/ivyfile/configurations.html\">configurations' attributes</a> <em>defaultconf</em> (e.g. =\"oracle-war\") and <em>defaultconfmapping</em> (e.g. =\"*-&gt;default,sources\") to avoid unnecessary duplication in the file</li>\r\n</ul>\r\n<h2>Retrieving sources or binaries with Ant</h2>\r\nTo retrieve only the binary dependencies and put them inside the lib/ folder (notice type=\"jar\") with <a href=\"http://ant.apache.org/ivy/history/2.2.0/use/retrieve.html\">ivy:retrieve</a>:<br><br><pre><code>\r\n&lt;!-- build.xml --&gt;\r\n\t&lt;target name=&quot;ivy-get-binaries&quot;&gt;\r\n\t\t&lt;ivy:settings file=&quot;ivysettings.xml&quot; /&gt;\r\n\t\t&lt;ivy:retrieve pattern=&quot;lib/[artifact].[ext]&quot; type=&quot;jar&quot; /&gt;\r\n\t&lt;/target&gt;\r\n</code></pre><br><br>To retrieve source codes of the dependencies and put them inside the libsources/ folder:<br><br><pre><code>\r\n&lt;!-- build.xml --&gt;\r\n    &lt;target name=&quot;ivy-get-sources&quot; description=&quot;Fetch JARs with source codes for libraries that have them&quot;&gt;\r\n        &lt;ivy:settings file=&quot;ivysettings.xml&quot; /&gt;\r\n        &lt;ivy:retrieve pattern=&quot;libsources/[artifact]-[type].[ext]&quot; type=&quot;source&quot; /&gt;\r\n    &lt;/target&gt;\r\n</code></pre><br><br>To verify that some artifacts have been found, the resolution report in the log is useless for it sums all types of artifacts (i.e. binary and source ones) together. You have to check the last line, which shows count only for the artifacts of the requested type:\r\n<pre>[ivy:retrieve]     0 artifacts copied, 4 already retrieved (0kB/170ms)</pre>\r\n<h2>Limitations</h2>\r\n<h3>Ivy ignores some source attachements</h3>\r\nIvy sometimes ignores source artifacts, e.g. in the case of org.springframework:spring-webmvc:2.5.6 - when you check the Ivy-generated .ivy2/cache/org.springframework/spring-webmvc/ivy-2.5.6.xml, you will see that the publications section only lists ...type=\"jar\" conf=\"master\" even though <a href=\"http://repo1.maven.org/maven2/org/springframework/spring-webmvc/2.5.6/spring-webmvc-2.5.6-sources.jar\">spring-webmvc-2.5.6-sources.jar</a> certainly exists - I suppose that this is due to the MD5 checksum of the file being incorrect.\r\n<h3>Ivy can't fetch attachements for transitive dependencies</h3>\r\nI don't know any way how to force Ivy to retrieve source/javadoc attachements for transitive dependencies. The problem is that the dependencies always depend only on other binaries, never on sources/javadocs so Ivy has no reason to download those.\r\n<h2>Additional Notes</h2>\r\nThe Eclipse Ivy plugin <a href=\"http://ant.apache.org/ivy/ivyde/\">IvyDE</a> does <a href=\"http://www.mail-archive.com/ivy-user@incubator.apache.org/msg00104.html\">download sources/javadocs automatically</a>.\r\n<h2>References</h2>\r\n<a href=\"http://ant.apache.org/ivy/history/latest-milestone/concept.html\">Documentation of the Ivy pattern syntax</a> , description of <a href=\"http://ant.apache.org/ivy/history/latest-milestone/ivyfile/dependency.html\">how to define configuration mappings</a> (I've always troubles finding these).",
  "excerpt": ""
 },
 {
  "title": "Most interesting links of June",
  "published": "2011-06-30 21:59:52",
  "postType": "post",
  "slug": "/2011/06/30/most-interesting-links-of-june-2/",
  "status": "publish",
  "tags": [
   "tdd"
  ],
  "categories": [
   "General",
   "Testing",
   "Top links of month"
  ],
  "content": "<h2>Recommanded Readings</h2>\r\n<ul>\r\n\t<li><a href=\"http://www.infoq.com/news/2009/03/TDD-Improves-Quality\">Empirical Studies Show Test Driven Development Improves Quality</a> - brief summary of two researche papers comparing TDD/non-TDD, one paper with 1 case study from IBM and 3 from Microsoft (<a href=\"http://research.microsoft.com/en-us/projects/esm/nagappan_tdd.pdf\">get PDF</a>; conclusion: <em>The pre-release defect density of the four products, measured as defects per thousand lines of code, decreased between 40% and 90% relative to the projects that did not use TDD. The teams' management reported subjectively a 15–35% increase in initial development time for the teams using TDD, though the teams agreed that this was offset by reduced maintenance costs.</em>), one older summarizing 13 case studies (conclusion: <em>TDD seems to improve software quality, [...] there were indications that TDD does not necessarily decrease the developer productivity or extend the project leadtimes: In some cases, significant productivity improvements were achieved [...] However, in both of those studies the quality was improved.</em>).</li>\r\n\t<li><a href=\"http://venturebeat.com/2011/05/27/first-quantum-computer-sold/\">Quantum computers are reality: World’s first commercial quantum computer sold to Lockheed Martin</a> - this means that hard and <a href=\"http://www.csc.kth.se/%7Eviggo/wwwcompendium/\">NP-hard problems</a> become solvable or at least much easier to solve (this means incredibly lot, just think about optimization problems, scientific computations and simulations, ...) and that current security measures are becoming obsolete. It has \"only\" 128 qubits, which sounds small but is a big thing (competitive regime for quantum comp. is about 100).</li>\r\n\t<li><a href=\"http://jamesshore.com/Blog/The-Problems-With-Acceptance-Testing.html\">Fit co-author says acceptance testing costs more then it is worth</a> (i.e. there are <a href=\"http://jamesshore.com/Blog/Alternatives-to-Acceptance-Testing.html\">better alternatives</a>) - it's always good to learn from failures; the author, James Shore, has several pleas against A.T.: \"<em>[..] customers (a) weren't interested in doing that, and (b) often couldn't understand and didn't trust tests that were written by others. [..] Furthermore, acceptance testing tools are almost invariably used to create end-to-end integration tests, which are slow and brittle. Fit works best for targeted tests that describe the domain, but that's not how it's used. Also, tools like Fit [JH: which is based on HTML] don't work with refactoring tools.</em>\", summarized: non-participation of customers and maintenance burden. <a href=\"http://gojko.net/2010/03/01/are-tools-necessary-for-acceptance-testing-or-are-they-just-evil/\">Gojko Adzic opposes that we can avoid the pitfalls</a> while retaining the benefits - I guess his Specification by Example book is quite lot about this, as well as the last month mentioned post <a href=\"http://gojko.net/2009/09/24/top-10-reasons-why-teams-fail-with-acceptance-testing/\" rel=\"bookmark\">Top 10 reasons why teams fail with AT</a></li>\r\n</ul>\r\n<h2>Favourite Quotes</h2>\r\nUnit tests, [..], are so coupled to the low-level API that it is often hard for the developers to avoid the trap of proving that the solution works in a particular way, rather than asserting that is solves a particular problem.<br><br>- from the book <em>Continuous Delivery: Reliable Software Releases through Build, Test, and Deployment Automation</em>, published in an <a href=\"http://www.informit.com/articles/article.aspx?p=1621865&amp;seqNum=5\">InformIT article</a>",
  "excerpt": ""
 },
 {
  "title": "Version hell with JSFUnit, Arquillian, and (embedded) Glassfish and other containers",
  "published": "2011-06-07 10:19:56",
  "postType": "post",
  "slug": "/2011/06/07/version-hell-with-jsfunit-arquillian-and-embedded-glassfish-and-other-containers/",
  "status": "publish",
  "tags": [
   "java"
  ],
  "categories": [
   "j2ee",
   "Languages",
   "Testing"
  ],
  "content": "<a href=\"http://www.jboss.org/jsfunit\">JSFUnit</a> and the JBoss <a href=\"http://www.jboss.org/arquillian\">Arquillian</a> test framework for JavaEE look very promissing, but according to my experience there are good reasons why they are only beta and alpha versions. May be you can get them working but you must pick the right version of each dependency - for many things change between individual versions at this point - and be lucky to hit one of the \"happy paths\". At the end I nearly got JSFUnit 1.0.0.Beta1 running with Arquillian 10.0.0.Alpha4 and glassfish-embedded 3.0.1 but failed to deploy due to a strange parse exception of an arquillian's web fragment. I record this failure to help those who are struggling with this too.<br><br>There are the following fatal constraints:<br><br><!--more-->\r\n<ul>\r\n\t<li>JSFUnit 2.0.0.Beta1 is the latest available one (<a href=\"https://issues.jboss.org/secure/ReleaseNote.jspa?projectId=12310390&amp;version=12316240\">Beta2</a> should have been released in April but wasn't and it has still one issue opened - <a href=\"https://issues.jboss.org/browse/JSFUNIT-275\">JSFUNIT-275</a>]; <a href=\"https://issues.jboss.org/browse/JSFUNIT#selectedTab=com.atlassian.jira.plugin.system.project%3Aroadmap-panel\">2.0.0. Final is due on July 1st</a> but considering the delay of Beta2 and no progress in the final version, it will be certainly much later)</li>\r\n\t<li>JSFUnit 2.0.0.Beta1 requires Arquillian 1.0.0.Alpha4, support for Alpha5 comes with Beta2.</li>\r\n\t<li>Container selection:</li>\r\n<ul>\r\n\t<li>Tomcat 6 only supports servlet 2.5 while JSFUnit requires 3.0 for it uses web fragments; however this seems to be fixed in JSFUNIT 1.0.0.Beta2, see <a href=\"https://issues.jboss.org/browse/JSFUNIT-273\">JSFUNIT-273</a></li>\r\n\t<li>I wasn't able to get JBoss Embedded (6.0.0.Final), it tried to download quazillion dependencies and ultimately failed due to some version mismatches</li>\r\n\t<li>Embedded GlassFish (GF) - version 3.1 has a different API, which is supported only since Arq. Alpha5, and deployment to 3.0.1 fails due to \"<em>SAXParseException: src-resolve: Cannot resolve the name 'xml:lang' to a(n) 'attribute declaration' component.</em>\", solved only in GF 3.1 (<a href=\"http://java.net/jira/browse/GLASSFISH-13261\">GLASSFISH-13261</a>). Surprisingly I got 3.0.1 working with another project but there it failed due to JSF libraries mismatch (otherwise it might also come to this problem).</li>\r\n</ul>\r\n</ul>\r\nMy (not so well working) Ivy configuration thus was:<br><br><pre><code>\r\n...\r\n   &lt;dependency org=&quot;org.jboss.jsfunit&quot; name=&quot;jsfunit-arquillian&quot; rev=&quot;2.0.0.Beta1&quot; conf=&quot;webtest&quot; /&gt;\r\n   &lt;dependency org=&quot;org.jboss.arquillian&quot; name=&quot;arquillian-junit&quot; rev=&quot;1.0.0.Alpha4&quot; conf=&quot;webtest&quot; /&gt;\r\n   &lt;dependency org=&quot;org.jboss.arquillian.container&quot; name=&quot;arquillian-glassfish-embedded-3&quot; rev=&quot;1.0.0.Alpha4&quot; conf=&quot;webtest&quot; /&gt;\r\n   &lt;dependency org=&quot;org.glassfish.extras&quot; name=&quot;glassfish-embedded-all&quot; rev=&quot;3.0.1&quot; conf=&quot;webtest&quot; /&gt;\r\n...\r\n</code></pre><br><br>The accompanying settings.xml with repositories:<br><br><pre><code>\r\n&lt;ivysettings&gt;\r\n   &lt;settings defaultResolver=&quot;all_repositories&quot; /&gt;\r\n   &lt;resolvers&gt;\r\n      &lt;chain name=&quot;all_repositories&quot;&gt;\r\n         &lt;ibiblio name=&quot;ibiblio&quot; m2compatible=&quot;true&quot; /&gt;\r\n         &lt;ibiblio name=&quot;jboss&quot; m2compatible=&quot;true&quot; root=&quot;https://repository.jboss.org/nexus/content/repositories/releases&quot; /&gt; &lt;!-- JSFUnit etc. --&gt;\r\n         &lt;ibiblio name=&quot;sunJars&quot; m2compatible=&quot;true&quot; root=&quot;http://download.java.net/maven/2&quot; /&gt; &lt;!-- javax.* APIs etc. --&gt;\r\n         &lt;ibiblio name=&quot;glassfish-embedded&quot; m2compatible=&quot;true&quot; root=&quot;http://download.java.net/maven/glassfish/&quot; /&gt;\r\n      &lt;/chain&gt;\r\n   &lt;/resolvers&gt;\r\n&lt;/ivysettings&gt;\r\n</code></pre><br><br>-\r\n<h2>On JSF versions</h2>\r\nIt seems that you can test only JSF 2.0 applications (well, you hopefully will be able to test them once Beta2 is out); if you try to test a JSF 1.2 application you will run into conflicting APIs, resulting for example in <a href=\"http://www.mkyong.com/jsf2/java-lang-illegalargumentexception-javax-faces-context-exceptionhandlerfactory/\">IllegalArgumentException: javax.faces.context.ExceptionHandlerFactory</a>.\r\n<h2>Tip: Increasing logging in the embedded Glassfish</h2>\r\nGF uses java logging =&gt; copy glassfish/domains/domain1/config/logging.properties somewhere, replace INFO with FINE and run your test with the following setting:<br><br><pre><code><br><br>-Djava.util.logging.config.file=/path/to/your/glassfish/config/logging.properties<br><br></code></pre><br><br>If your test failes due to <em>IllegalStateException: Error launching test at http://localhost:8181/test/ArquillianServletRunner?.... Kept on getting 404s.</em> then likely the deployment of your application has failed and you should increase the logging level and check the issue.<br><br>Some entries of interest:\r\n<ul>\r\n\t<li>ClassName=com.sun.enterprise.deployment.node.web.WebCommonNode;MethodName=addDescriptor;|Adding web component ...</li>\r\n\t<li>javax.enterprise.system.tools.deployment.org.glassfish.deployment.common - some important exceptions may show here</li>\r\n\t<li>javax.enterprise.system.container.web.com.sun.enterprise.web|...;ClassName=com.sun.enterprise.web.WebModuleListener;MethodName=configureJsp;| sysClasspath for __default-web-module is\r\n... jsfunit-arquillian-2.0.0.Beta1.jar: ...</li>\r\n\t<li>There was a NPE which perhaps is actually OK: ClassName=org.glassfish.deployment.common.InstalledLibrariesResolver;MethodName=getInstalledLibraries;|InstalledLibrariesResolver : exception occurred : java.lang.NullPointerException|#]</li>\r\n</ul>\r\n<h2>Links</h2>\r\n<ul>\r\n\t<li><a href=\"http://docs.jboss.org/arquillian/reference/1.0.0.Alpha4/en-US/html/container.reference.html#container.glassfish-embedded-3.configuration\">Glassfish 3.0.1 embedded container configuration for Arquillian Alpha4</a> (use GF 3.0.1 instead of the 3.0.1-b2 mentioned there to avoid \"<em>SAXParseException: src-resolve: Cannot resolve the name 'xml:lang' to a(n) 'attribute declaration' component.</em>\" in arquillian-protocol.jar's web-fragment.xml.</li>\r\n\t<li><a href=\"http://www.jboss.org/jsfunit/gettingstarted_version_2-0-0\">Getting started with JSFUnit 2.0.0</a> (including a test project)</li>\r\n</ul>",
  "excerpt": ""
 },
 {
  "title": "Hacking Jasper to Get Object Model of a JSP Page",
  "published": "2011-06-10 15:46:00",
  "postType": "post",
  "slug": "/2011/06/10/hacking-jasper-to-get-object-model-of-a-jsp-page/",
  "status": "publish",
  "tags": [
   "analysis",
   "compilation",
   "jasper",
   "java",
   "JSP"
  ],
  "categories": [
   "j2ee",
   "Languages",
   "Tools"
  ],
  "content": "To perform some checks and statistical analysis on my JSPs I needed a DOM-like, hierarchical model of elements contained in them. But parsing JSP pages isn't trivial and is best left to a tool that excels in it - the Jasper JSP compiler used by Tomcat, Jetty, GlassFish and likely also by all others. There is an easy way to tweak it to produce whatever output you need nad to transform a JSP into whatever form you want, including an object model of the page:\r\n<ol>\r\n\t<li>Define a Node.Visitor subclass for handling the nodes (tags etc.) of a JSP</li>\r\n\t<li>Write a simple subclass of Compiler, overriding its generateJava() to invoke the visitor</li>\r\n\t<li>Subclass the compiler executor JspC overriding its method getCompilerClassName() to return the class of the Compiler of yours</li>\r\n</ol>\r\nLet's see the code.<br><br><!--more-->\r\n<h2>Implementation</h2>\r\n<h3>1. Custom Visitor</h3>\r\nA Visitor is invoked by the compiler to process a tree object model of a parsed JSP. This implementation just prints information about an interesting subset of nodes in the page, indented to make their nesting clear.<br><br><pre><code>\r\npackage org.apache.jasper.compiler;<br><br>import java.util.LinkedList;\r\nimport org.apache.jasper.JasperException;\r\nimport org.apache.jasper.compiler.Node.CustomTag;\r\nimport org.apache.jasper.compiler.Node.ELExpression;\r\nimport org.apache.jasper.compiler.Node.IncludeDirective;\r\nimport org.apache.jasper.compiler.Node.Visitor;\r\nimport org.xml.sax.Attributes;<br><br>public class JsfElCheckingVisitor extends Visitor {<br><br>    private String indent = &quot;&quot;;<br><br>    @Override\r\n    public void visit(ELExpression n) throws JasperException {\r\n        logEntry(&quot;ELExpression&quot;, n, &quot;EL: &quot; + n.getEL());\r\n        super.visit(n);\r\n    }<br><br>    @Override\r\n    public void visit(IncludeDirective n) throws JasperException {\r\n        logEntry(&quot;IncludeDirective&quot;, n, toString(n.getAttributes()));\r\n        super.visit(n);\r\n    }<br><br>    @Override\r\n    public void visit(CustomTag n) throws JasperException {\r\n        logEntry(&quot;CustomTag&quot;, n, &quot;Class: &quot; + n.getTagHandlerClass().getName() + &quot;, attrs: &quot;\r\n                + toString(n.getAttributes()));<br><br>        doVisit(n);<br><br>        indent += &quot; &quot;;\r\n        visitBody(n);\r\n        indent = indent.substring(0, indent.length() - 1);\r\n    }<br><br>    private String toString(Attributes attributes) {\r\n        if (attributes == null || attributes.getLength() == 0) return &quot;&quot;;\r\n        LinkedList&lt;String&gt; details = new LinkedList&lt;String&gt;();<br><br>        for (int i = 0; i &lt; attributes.getLength(); i++) {\r\n            details.add(attributes.getQName(i) + &quot;=&quot; + attributes.getValue(i));\r\n        }<br><br>        return details.toString();\r\n    }<br><br>    private void logEntry(String what, Node n, String details) {\r\n        System.out.println(indent + n.getQName() + &quot; at line:&quot;\r\n                + n.getStart().getLineNumber() + &quot;: &quot; + details);\r\n    }<br><br>}\r\n</code></pre><br><br>Notes:\r\n<ul>\r\n\t<li>The <em>Visitor</em> must be in the org.apache.jasper.compiler package because the essential class org.apache.jasper.compiler.Node is package-private</li>\r\n\t<li>The method <em>visitBody</em> triggers processing of the nested nodes</li>\r\n\t<li>There are more methods I could have overridden (and the catch-all method <em>doVisit</em>) but I've selected only those interesting for me</li>\r\n\t<li>The node's attributes are of the type ...sax.<a href=\"http://download.oracle.com/javase/1.4.2/docs/api/org/xml/sax/Attributes.html\">Attributes</a>, which contains attribute names and values as strings\r\n<ul>\r\n\t<li>attributes.getType(i) is usually CDATA</li>\r\n</ul>\r\n</li>\r\n\t<li>The Node structure contains information about the parent node, tag name, tag handler class, the corresponding line of the source file and the name of the source file and other useful information</li>\r\n\t<li><em>CustomTag</em> is likely the most interesting node type, e.g. all the JSF tags are of this type</li>\r\n</ul>\r\n<h4>Example Output (for a JSF Page)</h4>\r\n<pre><code>\r\njsp:directive.include at line:5: [file=includes/stdjsp.jsp]\r\njsp:directive.include at line:6: [file=includes/ssoinclude.jsp]\r\nf:verbatim at line:14: Class: com.sun.faces.taglib.jsf_core.VerbatimTag, attrs:\r\nhtm:div at line:62: Class: com.exadel.htmLib.tags.DivTag, attrs: [style=width:100%;]\r\n h:form at line:64: Class: com.sun.faces.taglib.html_basic.FormTag, attrs: [id=inputForm]\r\n  htm:table at line:66: Class: com.exadel.htmLib.tags.TableTag, attrs: [cellpadding=0, width=100%, border=0, styleClass=clear box_main]\r\n   htm:tr at line:71: Class: com.exadel.htmLib.tags.TrTag, attrs:\r\n    htm:td at line:72: Class: com.exadel.htmLib.tags.TdTag, attrs:\r\n    f:subview at line:73: Class: com.sun.faces.taglib.jsf_core.SubviewTag, attrs: [id=cars]\r\n      jsp:directive.include at line:74: [file=/includes/cars.jsp]\r\n      h:panelGroup at line:8: Class: com.sun.faces.taglib.html_basic.PanelGroupTag, attrs: [rendered=#{bookingHandler.flowersAvailable}]\r\n...\r\n   htm:tr at line:87: Class: com.exadel.htmLib.tags.TrTag, attrs: [style=height:5px]\r\n    htm:td at line:87: Class: com.exadel.htmLib.tags.TdTag, attrs:\r\n</code></pre><br><br>(I do not print \"closing tags\" for it's clear that a tag ends when another node with the same or smaller indentation appears or the output ends.)\r\n<h3>2. Compiler Subclass</h3>\r\nThe important part is <em>generateJava</em>, which I have just copied, removed some code from it and added an invocation of my <em>Visitor</em>. So actually only 3 lines in the listing below are new.<br><br><pre><code>\r\npublic class OnlyReadingJspPseudoCompiler extends Compiler {<br><br>    /** We're never compiling .java to .class. */\r\n    @Override protected void generateClass(String[] smap) throws FileNotFoundException,\r\n            JasperException, Exception {\r\n        return;\r\n    }<br><br>    /** Copied from {@link Compiler#generateJava()} and adjusted */\r\n    @Override protected String[] generateJava() throws Exception {<br><br>        // Setup page info area\r\n        pageInfo = new PageInfo(new BeanRepository(ctxt.getClassLoader(),\r\n                errDispatcher), ctxt.getJspFile());<br><br>        // JH: Skipped processing of jsp-property-group in web.xml for the current page<br><br>        if (ctxt.isTagFile()) {\r\n            try {\r\n                double libraryVersion = Double.parseDouble(ctxt.getTagInfo()\r\n                        .getTagLibrary().getRequiredVersion());\r\n                if (libraryVersion &lt; 2.0) {\r\n                    pageInfo.setIsELIgnored(&quot;true&quot;, null, errDispatcher, true);\r\n                }\r\n                if (libraryVersion &lt; 2.1) {\r\n                    pageInfo.setDeferredSyntaxAllowedAsLiteral(&quot;true&quot;, null,\r\n                            errDispatcher, true);\r\n                }\r\n            } catch (NumberFormatException ex) {\r\n                errDispatcher.jspError(ex);\r\n            }\r\n        }<br><br>        ctxt.checkOutputDir();<br><br>        try {\r\n            // Parse the file\r\n            ParserController parserCtl = new ParserController(ctxt, this);<br><br>            // Pass 1 - the directives\r\n            Node.Nodes directives =\r\n                parserCtl.parseDirectives(ctxt.getJspFile());\r\n            Validator.validateDirectives(this, directives);<br><br>            // Pass 2 - the whole translation unit\r\n            pageNodes = parserCtl.parse(ctxt.getJspFile());<br><br>            // Validate and process attributes - don't re-validate the\r\n            // directives we validated in pass 1\r\n            /**\r\n             * JH: The code above has been copied from Compiler#generateJava() with some\r\n             * omissions and with using our own Visitor.\r\n             * The code that used to follow was just deleted.\r\n             * Note: The JSP's name is in ctxt.getJspFile()\r\n             */\r\n            pageNodes.visit(new JsfElCheckingVisitor());<br><br>        } finally {}<br><br>        return null;\r\n    }<br><br>    /**\r\n     * The parent's implementation, in our case, checks whether the target file\r\n     * exists and returns true if it doesn't. However it is expensive so\r\n     * we skip it by returning true directly.\r\n     * @see org.apache.jasper.JspCompilationContext#getServletJavaFileName()\r\n     */\r\n    @Override public boolean isOutDated(boolean checkClass) {\r\n        return true;\r\n    }<br><br>}\r\n</code></pre><br><br>Notes:\r\n<ul>\r\n\t<li>I have deleted quite lot of code unimportant for me from generate Java; for a different type of analysis than I intend some of that code could have been useful, so look into the original Compiler class and decide for yourself.</li>\r\n\t<li>I do not really care about JSP ELs so it might be possible to optimize the compiler to need only one pass.</li>\r\n</ul>\r\n<h3>3. Compiler Executor</h3>\r\nIt is difficult to use a Compiler directly because it depends on quite a number of complex settings and objects. The easiest thing is thus to reuse the Ant task JspC, which has the additional benefit of finding the JSPs to process. As mentioned, the key thing is the overriding of <em>getCompilerClassName</em> to return my compiler's class.<br><br><pre><code>\r\nimport org.apache.jasper.JspC;<br><br>/** Extends JspC to use the compiler of our choice; Jasper version 6.0.29. */\r\npublic class JspCParsingToNodesOnly extends JspC {<br><br>    /** Overriden to return the class of ours (default = null =&gt; JdtCompiler) */\r\n    @Override public String getCompilerClassName() {\r\n        return OnlyReadingJspPseudoCompiler.class.getName();\r\n    }<br><br>    public static void main(String[] args) {\r\n        JspCParsingToNodesOnly jspc = new JspCParsingToNodesOnly();<br><br>        jspc.setUriroot(&quot;web&quot;); // where to search for JSPs\r\n        //jspc.setVerbose(1);     // 0 = false, 1 = true\r\n        jspc.setJspFiles(&quot;helloJSFpage.jsp&quot;); // leave unset to process all; comma-separated<br><br>        try {\r\n            jspc.execute();\r\n        } catch (JasperException e) {\r\n            throw new RuntimeException(e);\r\n        }\r\n    }\r\n}\r\n</code></pre><br><br>Notes:\r\n<ul>\r\n\t<li>JspC normally finds all files under the specified Uriroot but you can tell it to ignore all but some selected ones by passing their comma-separated names into <em>setJspFiles</em>.</li>\r\n</ul>\r\n<h2>Compile Dependencies</h2>\r\nIn thy Ivy form:\r\n<pre>&lt;dependency org=\"org.apache.tomcat\" name=\"jasper\" rev=\"6.0.29\" /&gt;\r\n&lt;dependency org=\"org.apache.tomcat\" name=\"jasper-jdt\" rev=\"6.0.29\" /&gt;\r\n&lt;dependency org=\"org.apache.ant\" name=\"ant\" rev=\"1.8.2\" /&gt;</pre>\r\n<h2>License</h2>\r\nAll the code here is directly derived from Jasper and thus falls under the same license, i.e. the <a href=\"http://www.apache.org/licenses/LICENSE-2.0\">Apache License, Version 2.0</a>.\r\n<h2>Conclusion</h2>\r\nJasper wasn't really designed for extension and modularity as documented by the fact that the crucial Node class is package private and by its API being so complex that reusing just a part of it is very hard. Fortunately the Ant task JspC makes it usable outside of a servlet container by providing some \"fake\" objects and there is a way to tweak it to our needs with very little work though it wasn't that easy to figure it out :-). I had to apply some dirty tricks, namely using stuff from a package-private class and overriding a method not intended to be overriden (<em>generateJava</em>) but it works and provides very valuable output, which makes it possible to do just anything you might want to do with the a JSP.\r\n<h2>Example Code</h2>\r\nMy <a href=\"https://github.com/jakubholynet/static-jsfexpression-validator\">Static JSF EL Expression Validator</a> uses this code to parse JSPs to find tags and EL expressions, you can check it out and try it. See the core module, especially the package <a href=\"https://github.com/jakubholynet/static-jsfexpression-validator/tree/master/static-jsfexpression-validator-core/src/main/java/org/apache/jasper/compiler\">org.apache.jasper.compiler</a> and the class <a href=\"https://github.com/jakubholynet/static-jsfexpression-validator/blob/master/static-jsfexpression-validator-core/src/main/java/net/jakubholy/jeeutils/jsfelcheck/AbstractJsfStaticAnalyzer.java\">AbstractJsfStaticAnalyzer</a> that makes use of it (the method createJsfElValidatingJspParser).",
  "excerpt": ""
 },
 {
  "title": "How to Fix Empty \"Show all bookmarks\" in Firefox 4",
  "published": "2011-06-20 14:49:52",
  "postType": "post",
  "slug": "/2011/06/20/how-to-fix-empty-show-all-bookmarks-in-firefox-4/",
  "status": "publish",
  "tags": [
   "bookmarks",
   "firefox"
  ],
  "categories": [
   "General"
  ],
  "content": "Since recently I was unable to edit my bookmarks because Bookmarks -&gt; Show all bookmarks displayed en empty list of bookmarks, though the bookmarks were under the bookmarks menu, B. toolbar etc. The Bookmarks side panel was also empty though.<br><br>The solution was to create a <strong>backup of my bookmarks</strong> (in the json format), stop FF, <strong>delete places.sqlite</strong> from my profile, start FF and <strong>restore</strong> bookmarks from the backup.<br><br><!--more-->I first tried to run FF in the <a href=\"http://support.mozilla.com/en-US/kb/Safe%20Mode\">safe mode</a> but it didn't help (yet it was useful for it ruled out an evil addon as the cause). I next <a href=\"http://kb.mozillazine.org/Profile_manager\">created a new profile</a> and found out that the bookmark manager behaved properly there (I had of course no bookmarks but \"All bookmarks\" contained the Bookmark Menu and B. Toolbar instead of being completely empty).",
  "excerpt": ""
 },
 {
  "title": "Validating JSF EL Expressions in JSF Pages with static-jsfexpression-validator",
  "published": "2011-06-22 16:00:09",
  "postType": "post",
  "slug": "/2011/06/22/validating-jsf-el-expressions-in-jsf-pages-with-static-jsfexpression-validator/",
  "status": "publish",
  "tags": [
   "java",
   "jsf",
   "project"
  ],
  "categories": [
   "j2ee",
   "Languages",
   "Tools"
  ],
  "content": "<strong><strong>Update: Version 1.0 was released in March 2012\r\nUpdate: Version 0.9.9 with finished basic support for Facelets</strong></strong> (autodetection of annotated beans, handling of ui:repeat) is available\r\n<strong>Update: Version 0.9.7 with experimental Facelets</strong> support and a fix of method binding validation released in Nov. (Not mentioning 0.9.5 and .6.) <a href=\"http://repo1.maven.org/maven2/net/jakubholy/jeeutils/jsfelcheck/static-jsfexpression-validator-jsf20/\">Always check the latest version available</a>! The text below would need to be updated for the new API, which will be done by the end of 2011.<strong>\r\nUpdate: Version 0.9.3 with new group/artifactId released</strong> on 7/25 including native support for JSF 1.2 (reflected below in the pom snippet).\r\n<strong>Update: Version 0.9.4 with function tolerance</strong> for JSF 1.2 released on 7/28 (it doesn't check functions are OK but checks their parameters etc.)<br><br><a href=\"https://github.com/jakubholynet/static-jsfexpression-validator\">static-jsfexpression-validator</a> is utility for verifying that EL expressions in JSF pages, such as <code>#{bean.property}</code>, are correct, that means that they don't reference undefined managed beans and nonexistent getters or action methods. The purpose is to make JSF-based web applications safer to refactor as the change of a method name will lead to the detection of an invalid expression without need for extensive manual UI tests. It can be run statically, for example from a test. Currently it builds on the JSF implementation v. 1.1 but can be in few hours (or days) modified to support newer version of JSF. How does it work?<br><br><!--more-->\r\n<ol>\r\n\t<li>Defined managed beans (name + type) are extracted from faces-config files and/or Spring application context files</li>\r\n\t<li>JSP pages are <a href=\"/2011/06/10/hacking-jasper-to-get-object-model-of-a-jsp-page/\">parsed by Jasper</a>, Tomcat's JSP parser</li>\r\n\t<li>For each JSF tag:</li>\r\n\t<li>If it defines local variables, they are recorded (such as <em>var</em> in <em>h:dataTable</em>)</li>\r\n\t<li>All JSF EL expressions in the tag's attributes are validated by a real EL resolver using two magic classes, namely custom VariableResolver and PropertyResolver, that - instead of looking up managed bean instances and invoking their getters - fabricate \"fake values\" of the expected types so that the \"resolution\" of an expression can proceed. The effect is that the existence of the referenced properties and action methods is verified against the target classes.\r\n<ul>\r\n\t<li>Sometimes it is not possible to determine the type of a JSF variable or property (e.g. when it's a Collection element), in which case it is necessary to declare it beforehand.</li>\r\n\t<li>You can also manually declare extra variables (managed beans) and override the detected type of properties.</li>\r\n</ul>\r\n</li>\r\n</ol>\r\n<h2>Minimal Setup</h2>\r\nAdd this dependency to your Maven/Ivy/... (update: Ant is not really needed if you are executing the validator only from ant):<br><br><pre><code><br><br>    net.jakubholy.jeeutils.jsfelcheck\r\n    static-jsfexpression-validator-jsf11\r\n    &lt;!-- &lt;artifactId&gt;static-jsfexpression-validator-jsf12&lt;/artifactId&gt; --&gt;\r\n    &lt;!-- &lt;artifactId&gt;static-jsfexpression-validator-jsf20&lt;/artifactId&gt; - now only reuses 1.2 --&gt;\r\n    0.9.3\r\n    test<br><br></code></pre><br><br>Alternatively, you can fetch <a href=\"http://repo1.maven.org/maven2/net/jakubholy/jeeutils/jsfelcheck/static-jsfexpression-validator-jsf11/0.9.3/static-jsfexpression-validator-jsf11-0.9.3.jar\">static-jsfexpression-validator-jsf11-0.9.3.jar</a> (or -jsf12- or -jsf20-) and its dependencies yourself, see the Appendix A.<br><br>Run it:<br><br><pre><code>java -cp static-jsfexpression-validator-jsf11-0.9.3.jar:... net.jakubholy.jeeutils.jsfelcheck.JsfStaticAnalyzer --jspRoot /path/to/jsp/files/dir </code></pre><br><br>Alternatively, run it from a Java class to be able to configure everything:<br><br><pre><code>\r\npublic class JsfElValidityTest {\r\n   @Test\r\n    public void should_have_only_defined_beans_and_valid_properties_in_jsf_el_expressions() throws Exception {\r\n        JsfStaticAnalyzer jsfStaticAnalyzer = new JsfStaticAnalyzer();\r\n        jsfStaticAnalyzer.setFacesConfigFiles(Collections.singleton(new File(&quot;web/WEB-INF/faces-config.xml&quot;)));\r\n        Map&gt; none = Collections.emptyMap();\r\n        CollectedValidationResults results = jsfStaticAnalyzer.validateElExpressions(&quot;web&quot;, none, none, none);\r\n        assertEquals(&quot;There shall be no invalid JSF EL expressions; check System.err/.out for details. FAILURE &quot; + results.failures()\r\n                , 0, results.failures().size());\r\n    }\r\n}\r\n</code></pre><br><br>Run it and check the standard error and output for results, which should ideally look something like this:<br><br><pre><code>\r\nINFO: &gt;&gt;&gt; STARTED FOR '/someFile.jsp #############################################\r\n...\r\n&gt;&gt;&gt; LOCAL VARIABLES THAT YOU MUST DECLARE TYPE FOR [0] #########################################<br><br>&gt;&gt;&gt; FAILED JSF EL EXPRESSIONS [0] #########################################\r\n(Set logging to fine for class net.jakubholy.jeeutils.jsfelcheck.validator.ValidatingJsfElResolver to se failure details and stacktraces)\r\n&gt;&gt;&gt; TOTAL EXCLUDED EXPRESIONS: 0 by filters: []\r\n&gt;&gt;&gt; TOTAL EXPRESSIONS CHECKED: 5872 (FAILED: 0, IGNORED EXPRESSIONS: 0) IN 0min 25s\r\n</code></pre>\r\n<h2>Standard Usage</h2>\r\nNormally you will need to configure the validator because you will have cases where property type etc. cannot be derived automatically.\r\n<h3>Declaring Local Variable Types, Extra Variables, Property Type Overrides</h3>\r\n<h4>Local Variables - h:dataTable etc.</h4>\r\nIf your JSP includes a JSF tag that declares a new local variable (typically h:dataTable), like <var>vegetable</var> in the example below:<br><br><pre><code><br><br>   ...<br><br></code></pre><br><br>where <var>favouriteVegetable</var> is a <code>Collection</code> of <code>Vegetable</code>s then you must tell the validator what type of objects the collection contains:<br><br><pre><code>\r\nMap&gt; localVariableTypes = new Hashtable&gt;();\r\nlocalVariableTypes.put(&quot;vegetarion.favouriteVegetable&quot;, Vegetable.class);\r\njsfStaticAnalyzer.validateElExpressions(&quot;web&quot;, localVariableTypes, extraVariables, propertyTypeOverrides);\r\n</code></pre><br><br>The failure to do so would be indicated by a number of failed expression validations and a suggestion to register type for this variable:<br><br><pre><code>\r\n&gt;&gt;&gt; LOCAL VARIABLES THAT YOU MUST DECLARE TYPE FOR [6] #########################################\r\nDeclare component type of 'vegetarion.favouriteVegetable' assigned to the variable vegetable (file /favourites.jsp, tag line 109)\r\n&gt;&gt;&gt; FAILED JSF EL EXPRESSIONS [38] #########################################\r\n(Set logging to fine for class net.jakubholy.jeeutils.jsfelcheck.validator.ValidatingJsfElResolver to se failure details and stacktraces)\r\nFailedValidationResult [failure=InvalidExpressionException [Invalid EL expression '#{vegetable.name}': PropertyNotFoundException - Property 'name' not found on class net.jakubholy.jeeutils.jsfelcheck.expressionfinder.impl.jasper.variables.ContextVariableRegistry$Error_YouMustDelcareTypeForThisVariable$$EnhancerByMockitoWithCGLIB$$3c8d0e8f]; expression=#{vegetable.name}, file=/favourites.jsp, tagLine=118]\r\n</code></pre>\r\n<h4>Defining Variables Not in faces-config</h4>\r\n<em>Variable: the first element of an EL expression.</em><br><br>If you happen to be using a variable that is not a managed bean defined in faces-config (or Spring config file), for example because you create it manually, you need to declare it and its type:<br><br><pre><code>\r\nMap&gt; extraVariables = new Hashtable&gt;();\r\nlocalVariableTypes.put(&quot;myMessages&quot;, Map.class);\r\njsfStaticAnalyzer.validateElExpressions(&quot;web&quot;, localVariableTypes, extraVariables, propertyTypeOverrides);\r\n</code></pre><br><br>Expressions like <code>#{myMessages['whatever.key']}</code> would be now OK.\r\n<h4>Overriding the Detected Type of Properties, Especially for Collection Elements</h4>\r\n<em>Property: any but the first segment of an EL expression (#{variable.propert1.property2['property3]....}).</em><br><br>Sometimes you need to explicitely tell the validator the type of a property. This is necessary if the poperty is an object taken from a Collection, where the type is unknown at the runtime, but it may be useful also at other times.<br><br>If you had:<br><br><pre><code><br><br></code></pre><br><br>then you'd need to declare the type like this:<br><br><pre><code>\r\nMap&gt; propertyTypeOverrides = new Hashtable&gt;();\r\npropertyTypeOverrides.put(&quot;vegetableMap.*&quot;, Vegetable.class);\r\n//or just for 1 key: propertyTypeOverrides.put(&quot;vegetableMap.carrot&quot;, Vegetable.class);\r\njsfStaticAnalyzer.validateElExpressions(&quot;web&quot;, localVariableTypes, extraVariables, propertyTypeOverrides);\r\n</code></pre><br><br>Using the .* syntax you indicate that all elements contained in the Collection/Map are of the given type. You can also override the type of a single property, whether it is contained in a collection or not, as shown on the third line.\r\n<h3>Excluding/Including Selected Expressions for Validation</h3>\r\nYou may supply the validator with filters that determine which expressions should be checked or ignored. This may be useful mainly if you it is not possible to check them, for example because a variable iterates over a collection with incompatible objects.<br><br>The ignored expressions are added to a separate report and the number of ignored expressions together with the filters responsible for them is printed.<br><br>Example: ignore all expressions for the variable <code>evilCollection</code>:<br><br><pre><code>\r\njsfStaticAnalyzer.addElExpressionFilter(new ElExpressionFilter(){\r\n   @Override public boolean accept(ParsedElExpression expression) {\r\n       if (expression.size() == 1\r\n          &amp;&amp; expression.iterator().next().equals(&quot;evilCollection&quot;)) {\r\n      return false;\r\n       }\r\n       return true;\r\n   }<br><br>   @Override public String toString() {\r\n       return &quot;ExcludeEvilCollectionWithIncompatibleObjects&quot;;\r\n   }\r\n});\r\n</code></pre><br><br>(I admit that the interface should be simplified.)\r\n<h3>Other Configuration</h3>\r\nIn JsfStaticAnalyzer:\r\n<ul>\r\n\t<li>setFacesConfigFiles(Collection&lt;File&gt;): faces-config files where to look for defined managed beans; null/empty not to read any</li>\r\n\t<li>setSpringConfigFiles(Collection&lt;File&gt;) Spring applicationContext files where to look for defined managed beans; null/empty not to read any</li>\r\n\t<li>setSuppressOutput(boolean) - do not print to System.err/.out - used if you want to process the produced CollectedValidationResults on your own</li>\r\n\t<li>setJspsToIncludeCommaSeparated(String) - normally all JSPs under the jspDir are processed, you can force processing only the ones you want by supplying thier names here (JspC setting)</li>\r\n\t<li>setPrintCorrectExpressions(boolean) - set to true to print all the correctly validated JSF EL expressions</li>\r\n</ul>\r\n<h2>Understanding the Results</h2>\r\njsfStaticAnalyzer.validateElExpressions prints the results into the standard output and error and also returnes them in a CollectedValidationResults with the following content:\r\n<ul>\r\n\t<li>ResultsIterable&lt;FailedValidationResult&gt; failures() - expressions whose validation wasn't successful</li>\r\n\t<li>ResultsIterable&lt;SuccessfulValidationResult&gt; goodResults() - expressions validated successfully</li>\r\n\t<li>ResultsIterable&lt;ExpressionRejectedByFilterResult&gt; excluded() - expressions ignored due to a filter</li>\r\n\t<li>Collection&lt;DeclareTypeOfVariableException&gt; - local variables (h:dataTable's var) for which you need to declare their type</li>\r\n</ul>\r\nThe ResultsIterable have size() and the individual *Result classes contain enough information to describe the problem (the expression, exception, location, ...).<br><br>Now we will look how the results appear in the output.\r\n<h3>Unknown managed bean (variable)</h3>\r\n<pre><code>\r\nFailedValidationResult [failure=InvalidExpressionException [Invalid EL expression '#{messages['message.res.ok']}': VariableNotFoundException - No variable 'messages' among the predefined ones.]; expression=#{messages['message.res.ok']}, file=/sample_failures.jsp, tagLine=20]\r\n</code></pre><br><br><strong>Solution</strong>: Fix it or add the variable to the <code>extraVariables</code> map parameter.\r\n<h3>Invalid property (no corresponding getter found on the variable/previous property)</h3>\r\n<h4>a) Invalid property on a correct target object class</h4>\r\nThis kind of failures is the raison d'être of this tool.<br><br><pre><code>\r\nFailedValidationResult [failure=InvalidExpressionException [Invalid EL expression '#{segment.departureDateXXX}': PropertyNotFoundException - Property 'departureDateXXX' not found on class example.Segment$$EnhancerByMockitoWithCGLIB$$5eeba04]; expression=#{segment.departureDateXXX}, file=/sample_failures.jsp, tagLine=92]\r\n</code></pre><br><br><strong>Solution</strong>: Fix it, i.e. correct the expression to reference an existing property of the class. If the validator is using different class then it should then you might need to define a propertyTypeOverride.\r\n<h4>b) Invalid property on an unknown target object class - MockObjectOfUnknownType</h4>\r\n<pre><code>\r\nFailedValidationResult [failure=InvalidExpressionException [Invalid EL expression '#{carList[1].price}': PropertyNotFoundException - Property 'price' not found on class net.jakubholy.jeeutils.jsfelcheck.validator.MockObjectOfUnknownType$$EnhancerByMockitoWithCGLIB$$9fa876d1]; expression=#{carList[1].price}, file=/cars.jsp, tagLine=46]\r\n</code></pre><br><br><strong>Solution</strong>: carList is clearly a List whose element type cannot be determined and you must therefore declare it via the <code>propertyTypeOverrides</code> map property.\r\n<h3>Local variable without defined type</h3>\r\n<pre><code>\r\nFailedValidationResult [failure=InvalidExpressionException [Invalid EL expression '   #{traveler.name}': PropertyNotFoundException - Property 'name' not found on class net.jakubholy.jeeutils.jsfelcheck.expressionfinder.impl.jasper.variables.ContextVariableRegistry$Error_YouMustDelcareTypeForThisVariable$$EnhancerByMockitoWithCGLIB$$b8a846b2]; expression=   #{traveler.name}, file=/worldtravels.jsp, tagLine=118]\r\n</code></pre><br><br><strong>Solution</strong>: Declare the type via the <code>localVariableTypes</code> map parameter.\r\n<h3>More Documentation</h3>\r\nCheck the JavaDoc, especially in <a href=\"https://github.com/jakubholynet/static-jsfexpression-validator/blob/master/src/main/java/net/jakubholy/jeeutils/jsfelcheck/JsfStaticAnalyzer.java\">JsfStaticAnalyzer</a>.\r\n<h2>Limitations</h2>\r\n<ol>\r\n\t<li>Currently only local variables defined by <em>h:dataTable</em>'s <em>var</em> are recognized. To add support for others you'd need create and register a class similar to DataTableVariableResolver</li>\r\n\t<li>Handling of included files isn't perfect, the don't know about local variables defined in the including file. But we have all info needed to implement this. Static includes are handled by the Jasper parser (though it likely parses the included files also as top-level files, if they are on its search path).</li>\r\n</ol>\r\n<h2>Future</h2>\r\nIt depends on my project's needs, your feedback and your contributions :-).\r\n<h2>Where to Get It</h2>\r\nFrom the <a href=\"https://github.com/jakubholynet/static-jsfexpression-validator\">project's GitHub</a> or from the <a href=\"http://repo1.maven.org/maven2/net/jakubholy/jeeutils/static-jsfexpression-validator/\">project's Maven Central</a> repository, snapshots also may appear in the <a href=\"https://oss.sonatype.org/content/repositories/jakubholy-snapshots/net/jakubholy/jeeutils/static-jsfexpression-validator/\">Sonatype snapshots repo</a>.\r\n<h2>Appendices</h2>\r\n<h3>A. Dependencies of v.0.9.0 (also mostly similar for later versions):</h3>\r\n(Note: Spring is not really needed if you haven't Spring-managed JSF beans.)\r\n<p style=\"padding-left:30px;\">aopalliance:aopalliance:jar:1.0:compile\r\ncommons-beanutils:commons-beanutils:jar:1.6:compile\r\ncommons-collections:commons-collections:jar:2.1:compile\r\ncommons-digester:commons-digester:jar:1.5:compile\r\ncommons-io:commons-io:jar:1.4:compile\r\ncommons-logging:commons-logging:jar:1.0:compile\r\njavax.faces:jsf-api:jar:1.1_02:compile\r\njavax.faces:jsf-impl:jar:1.1_02:compile\r\norg.apache.tomcat:annotations-api:jar:6.0.29:compile\r\norg.apache.tomcat:catalina:jar:6.0.29:compile\r\norg.apache.tomcat:el-api:jar:6.0.29:compile\r\norg.apache.tomcat:jasper:jar:6.0.29:compile\r\norg.apache.tomcat:jasper-el:jar:6.0.29:compile\r\norg.apache.tomcat:jasper-jdt:jar:6.0.29:compile\r\norg.apache.tomcat:jsp-api:jar:6.0.29:compile\r\norg.apache.tomcat:juli:jar:6.0.29:compile\r\norg.apache.tomcat:servlet-api:jar:6.0.29:compile\r\norg.mockito:mockito-all:jar:1.8.5:compile\r\norg.springframework:spring-beans:jar:2.5.6:compile\r\norg.springframework:spring-context:jar:2.5.6:compile\r\norg.springframework:spring-core:jar:2.5.6:compile\r\nxml-apis:xml-apis:jar:1.0.b2:compile</p>",
  "excerpt": ""
 },
 {
  "title": "Going to Present \"Programmer''s Survival Kit: Code Injection for Troubleshooting\" at JavaZone 2011",
  "published": "2011-07-18 08:32:50",
  "postType": "post",
  "slug": "/2011/07/18/going-to-present-programmers-survival-kit-code-injection-for-troubleshooting-at-javazone-2011/",
  "status": "publish",
  "tags": [
   "java"
  ],
  "categories": [
   "General",
   "Languages"
  ],
  "content": "I'm going to hold a lightning talk called <em>Programmer's Survival Kit: Code Injection for Troubleshooting</em> at JavaZone in Oslo in September. This presentation is aimed at giving the participants the knowledge of code injection that they may (or I should rather say \"will\") need and at persuading them that learning basics of code injection is really worth the little of the time that it takes. I'll present three different real-world cases where code injection came to my rescue, solving each one with a different tool, fitting best the constraints at hand. I'll also provide them with resources to learn the basics and tools easily and quickly. This will be a practical presentation; I won't introduce AOP and will explain code injection only briefly, plunging right into the tools and how they can help developers.\r\n<div>\r\n<h2>Outline</h2>\r\n<ul>\r\n\t<li>Why every developer should know the basics of code injection - its irreplaceable role in troubleshooting</li>\r\n\t<li>The power of code injection - what are the unique benefits of code injection</li>\r\n\t<li>3 tools, 2 (3) examples - I'll introduce three rather different tools with different areas of application on practical, real-world examples</li>\r\n\t<li>1. The omnipresent Java Proxy - pros &amp; cons, example of troubleshooting one failed batch update among many</li>\r\n\t<li>2. The independent Javassist - pros &amp; cons (example not presented but available online - performance monitoring)</li>\r\n\t<li>3. The almighty AspectJ - pros &amp; cons, example of forcing a 3rd party method to log its arguments upon failure</li>\r\n\t<li>End - link to a blog post with much broader and deeper explanation of the topic and expanded source codes of the examples including support for building and running them</li>\r\n</ul>\r\n</div>\r\n<h2>Expected Audience</h2>\r\nAny, especially enterprise, Java developers that either know nothing about code injection/AOP, or know the concepts but not how to apply them or know a code injection tool and want to learn about others and how to use them for troubleshooting.<br><br>Hope to see you there!",
  "excerpt": ""
 },
 {
  "title": "Most interesting links of July",
  "published": "2011-07-31 21:59:00",
  "postType": "post",
  "slug": "/2011/07/31/most-interesting-links-of-july-2/",
  "status": "publish",
  "tags": [
   "architecture",
   "continuous_deployment",
   "java",
   "Jenkins",
   "legacy",
   "quality",
   "scrum"
  ],
  "categories": [
   "Languages",
   "Testing",
   "Tools",
   "Top links of month"
  ],
  "content": "<h2>Recommanded Readings</h2>\r\n<ul>\r\n\t<li><a href=\"http://www.thoughtworks.com/perspectives/30-06-2011-continuous-delivery\">Martin Fowler, M. Mason: Why not to use feature branches and prefer feature toggles instead</a>, when branches can actually be used (video, 12min) - feature branches are pretty common yet they are a hindrance for a good and stable development pace due to \"merging hells\". With trusted developers, feature toggles are a much better choice.</li>\r\n\t<li><a href=\"http://martinfowler.com/articles/lmax.html\">M. Fowler: The LMAX Architecture</a> - Martin describes the innovative and paradigm shaking architecture of the high-performance, high-volume financial trading platform LMAX. The platform can handle 6 million orders per second - using only a <em>single java thread</em> and commodity hardware. I highly recommend the article for two reasons: First, it crashes the common view that to handle such volumes you need multithreading. Second, for the rigorous, scientific approach used to arrive to this architecture. The key enablers are: 1) The main processing component does no blocking operations (I/O), those are done outside (in other threads). 2) There is no database - the state of the processor can be recreated by replaying the (persistent) input events. 3) To get further from 10k to 100k TPS they \"just\" wrote good code - well-factored, small methods (=&gt; Hotspot more efficient, CPU can cache better). 4) To gain another multitude they implemented more efficient, cache-friendlier collections. All that was done based on evidence, enabled by thorough performance testing. 5) The processor and input/output components communicate without locking, using a shared (cyclic) array, where each of them operates on sum range of indexes and no element can ever be written by more than one component. Their internal range indexes do ever only increase so it is safe to read them without synchronization (at worst you will get old, lower value). The developers also tried Agents but found them in conflict with modern CPUs for their require context switch leading to emptying of the fast CPU caches.\r\nUpdated: Martin has published the post titled <a href=\"http://martinfowler.com/bliki/MemoryImage.html\">Memory Image</a> which discusses the LMAX approach to persistence in a more general way.</li>\r\n\t<li><a href=\"http://java.dzone.com/articles/working-legacy-code\">S. Mancuso: Working with legacy code</a> with the goal of continual quality improvement - this was quite interesting for me as our team is in the same situation and arrived to quite similar approach. According to the author, the basic rule is \"always first write tests for the piece code to be changed,\" even though it takes so much time - he justifies it saying \"when people think we are spending too much time to write a feature because we were writing tests for the existing code first, they are rarely considering the time spend elsewhere .. more time is created [lost] when bugs are found and the QA phase needs to be extended\". But it is also important to remember when to stop with refactoring to get also to creating business value and the rule for that is that quality improvements are done only with focus on a particular task. I like one of the concluding sentences: \"Constantly increasing the quality level in a legacy system can make a massive difference in the amount of time and money spend on that project.\"</li>\r\n\t<li><a href=\"http://www.scrumalliance.org/articles/300-the-land-that-scrum-forgot\">Uncle Bob: The Land that Scrum Forgot</a> - Scrum makes it possible to be very productive at the beginning but to be able to keep the productivity and continue meeting the expectations that are thus created we need to concentrate on some essential technical practices and code quality. Because otherwise we create a mess of growing complexity - the ultimate killer of productivity. Uncle Bob advices us what practices and how to apply to attain both high, sustainable productivity and (as required for it) high code quality. It's essential to realize that people do what they are incented to do and thus we must measure and reward both going fast and staying clean.\r\nHow do we measure quality? There is no perfect measure but we can build on the available established metrics - coverage, # (new) tests, # defects, size of tests (~ size of production code, 5-20 lines per method), test speed, cyclomatic complexity, function (&lt; 20) and class (&lt; 500) sizes, Brathwaite Correlation (&gt; 2), dependency metrics (no cycles, in the direction abstraction).\r\nThe practices that enable us to stay clean include among others TDD, using tools like Chceckstyle, FindBugs to find problems and duplication, implementing Continuous Integration.</li>\r\n\t<li><a href=\"http://thewonggei.wordpress.com/2011/07/18/getting-started-testing-concurrent-java-code/\">Getting Started: Testing Concurrent Java Code</a> - very good and worthy overview of tools for checking and testing of concurrent code with links to valuable resources. The author mentions among others FindBugs, concurrent test coverage (critical sections examined by multiple threads) measurement with IBM's ConTest, multithreaded testing with <a href=\"https://www.research.ibm.com/haifa/projects/verification/contest/index.html\">ConTest</a> (randomly tries to create thread interleaving situations; trial version - contact the authors for the full one) and <a href=\"http://www.cs.umd.edu/projects/PL/multithreadedtc/overview.html\">MultithreadedTC</a> (which divides time into \"ticks\" and enables you to fine-configure the interactions)</li>\r\n\t<li><a href=\"http://www.javacodegeeks.com/2011/07/top-97-things-every-programmer-or.html?m=1\">The top 9+7 things every programmer or architect should know</a> - quite good selection of nine, respectively 7 things from the famous (on-line available) books 97 Things every programmer/architect should know.</li>\r\n</ul>\r\nSome fun:\r\n<ul>\r\n\t<li><a href=\"http://www.uie.com/brainsparks/2011/07/08/beans-and-noses/\">Beans and noses - J. Spool reveals the First Rule of Consultancy</a>: \"<em>No matter how much you try, you can’t stop people from sticking beans up their nose.</em>\" In other words, sometimes your clients decide to do some very unwise thing and no amount of reasoning can discourage them from that (quite understandably, as already the way they got to this decision defies logic).  \"The only thing I can do in a beans-and-noses situation is wait. Wait until the bean is in its final resting place.\" Then you ask the person how it is working for him and \"... if sticking a bean deep into their nostril doesn’t meet the very high expectations they’d had, I can now start talking alternative approaches to reaching those expectations.\" Already before you can actually ask them about their expectations, in some cases (50:50) this discussion can lead them to realize they could achieve them with an alternative, less painful approach. Now, if you have read up to this point, you clearly have enough time, so go an read the article because it's really orth it!</li>\r\n</ul>\r\nFree e-Books\r\n<ul>\r\n\t<li><a href=\"http://www.wakaleo.com/download-jenkins-the-definitive-guide\">Jenkins: The Definitive Guide</a> - seems to be very good at a first glance</li>\r\n</ul>",
  "excerpt": ""
 },
 {
  "title": "Ivy: Retrieve Both .jar And -sources.jar Into A Folder - Note to Self",
  "published": "2011-07-25 09:09:18",
  "postType": "post",
  "slug": "/2011/07/25/ivy-retrieve-both-jar-and-sources-jar-into-a-folder-note-to-self/",
  "status": "publish",
  "tags": [
   "ivy"
  ],
  "categories": [
   "Tools"
  ],
  "content": "After some experimenting I've found out how to tell Ivy (2.2.0) to retrieve also .jar with source codes into a folder:<br><br>Ivy.xml:<br><br><pre><code>\r\n&lt;ivy-module version=&quot;2.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:noNamespaceSchemaLocation=&quot;http://ant.apache.org/ivy/schemas/ivy.xsd&quot;\r\n            xmlns:e=&quot;http://ant.apache.org/ivy/extra&quot;&gt;\r\n...\r\n   &lt;dependency org=&quot;net.jakubholy.testing&quot; name=&quot;dbunit-embeddedderby-parenttest&quot; rev=&quot;1.2.0&quot; conf=&quot;test&quot; &gt;\r\n\t&lt;artifact name=&quot;dbunit-embeddedderby-parenttest&quot; type=&quot;jar&quot; /&gt;\r\n\t&lt;artifact name=&quot;dbunit-embeddedderby-parenttest&quot; type=&quot;sources&quot; e:classifier=&quot;sources&quot;  ext=&quot;jar&quot; /&gt;\r\n\t&lt;exclude org=&quot;junit&quot; /&gt;\r\n   &lt;/dependency&gt;\r\n</code></pre><br><br>The important thing here is the second artifact line with type and classifier sources and extension jar.<br><br>Ant:<br><br><pre><code>\r\n&lt;target name=&quot;ivy&quot; description=&quot;Retrieve dependencies managed by Ivy into lib/&quot;&gt;\r\n\t&lt;ivy:settings file=&quot;ivysettings.xml&quot; /&gt;\r\n\t&lt;!-- Notice that with sync=true Ivy will also remove the files which do not need to be there --&gt;\r\n\t&lt;ivy:retrieve pattern=&quot;lib/[conf]/[artifact].[ext]&quot; sync=&quot;true&quot; type=&quot;jar&quot; /&gt;\r\n\t&lt;ivy:retrieve pattern=&quot;lib/[conf]/[artifact]-sources.[ext]&quot; sync=&quot;false&quot; type=&quot;sources&quot; /&gt;\r\n&lt;/target&gt;\r\n</code></pre><br><br>Notice the second retrieve line - the type is set to sources and we've changed also the pattern not to overwrite the normal .jar and we've also disabled sync for otherwise the normal .jar would be removed (I'm sure there must be a better way, perhaps combining the two into one line with type=\"jar,sources\" and a pattern which takes the type into account).",
  "excerpt": ""
 },
 {
  "title": "Having Database Test Ready in 10 Minutes with DbUnit Express",
  "published": "2011-07-27 08:25:32",
  "postType": "post",
  "slug": "/2011/07/27/having-database-test-ready-in-10-minutes-with-dbunit-express/",
  "status": "publish",
  "tags": [
   "dbunit",
   "java",
   "open_source",
   "Testing"
  ],
  "categories": [
   "Databases",
   "Languages",
   "Testing"
  ],
  "content": "<em>Update: The project has been renamed to dbunit-express.</em><br><br><a href=\"https://sourceforge.net/apps/mediawiki/jeeutils/index.php?title=DbUnit_Express\">DbUnit Express</a> is my wrapper around DbUnit that intends to make it extremely easy to set up a test of a code that interacts with a database. It is preconfigured to use an embedded <a href=\"http://db.apache.org/derby/\">Derby database</a> (a.k.a. <a href=\"http://www.oracle.com/technetwork/java/javadb/overview/index.html\">JavaDB</a>, part of SDK) and uses convention over configuration to find the test data. It can also with one call create the test DB from a .ddl file. Aside of simplifying the setup it contains few utilities to make testing easier such as getDataSource() (essential for testing <a href=\"http://static.springsource.org/spring/docs/3.0.x/reference/jdbc.html\">Spring JDBC</a>) and <a href=\"http://jeeutils.svn.sourceforge.net/viewvc/jeeutils/trunk/DbUnitTestSkeleton/src/main/java/net/jakubholy/testing/dbunit/embeddeddb/assertion/RowComparator.java?view=markup\">RowComparator</a>.<br><br>Originally I was using DbUnit directly but I found out that for every project I was copying lot of code and thus I decided to extract it into a reusable project. Since that it has further grown to be more flexible and make testing even easier.<br><br>Here are the seven easy steps to have a running database test:\r\n<!--more-->\r\n<ol>\r\n\t<li><strong>Add binaries:</strong> Add dbunit-embeddedderby-parenttest 1.2.0 to your dependencies (note: it has been renamed to dbunit-express in later versions)\r\n<pre><code>\r\n&lt;dependency&gt;\r\n \t&lt;groupId&gt;net.jakubholy.testing&lt;/groupId&gt;\r\n\t&lt;artifactId&gt;dbunit-embeddedderby-parenttest&lt;/artifactId&gt;\r\n\t&lt;version&gt;1.2.0&lt;/version&gt;\r\n\t&lt;scope&gt;test&lt;/scope&gt;\r\n&lt;/dependency&gt;<br><br>&lt;dependency&gt; &lt;!-- won't be required in future versions --&gt;\r\n\t&lt;groupId&gt;org.slf4j&lt;/groupId&gt;\r\n\t&lt;artifactId&gt;slf4j-simple&lt;/artifactId&gt;\r\n\t&lt;version&gt;1.5.6&lt;/version&gt;\r\n\t&lt;scope&gt;test&lt;/scope&gt;\r\n&lt;/dependency&gt;\r\n</code></pre></li>\r\n\t<li><strong>Create the folder</strong> <em>testData</em>/ under your project's root folder.</li>\r\n\t<li>(optional) <strong>Prepare .ddl</strong>: Copy the example testData/<a title=\"http://jeeutils.svn.sourceforge.net/viewvc/jeeutils/trunk/DbUnitTestSkeleton/testData/create_db_content.ddl?revision=HEAD\" href=\"http://jeeutils.svn.sourceforge.net/viewvc/jeeutils/trunk/DbUnitTestSkeleton/testData/create_db_content.ddl?revision=HEAD\" rel=\"nofollow\">create_db_content.ddl</a> into the new testData/ and modify it to fit your data schema needs</li>\r\n\t<li>(optional) <strong>Create &amp; initialize DB</strong>: Run DatabaseCreator#main from your project's root folder to create and initialize the test DB from the .ddl file.</li>\r\n\t<li><strong>Write a TestCase</strong>: Either subclass AbstractEmbeddedDbTestCase or create and use an instance of EmbeddedDbTester in your test class and implement your tests there. (See <a title=\"http://jeeutils.svn.sourceforge.net/viewvc/jeeutils/trunk/DbUnitTestSkeleton/src/test/java/net/jakubholy/testing/dbunit/embeddeddb/SimpleEmbeddedDbTest.java?view=markup\" href=\"http://jeeutils.svn.sourceforge.net/viewvc/jeeutils/trunk/DbUnitTestSkeleton/src/test/java/net/jakubholy/testing/dbunit/embeddeddb/SimpleEmbeddedDbTest.java?view=markup\" rel=\"nofollow\">SimpleEmbeddedDbTest.java</a> and <a title=\"http://jeeutils.svn.sourceforge.net/viewvc/jeeutils/trunk/DbUnitTestSkeleton/src/test/java/net/jakubholy/testing/dbunit/embeddeddb/SimpleNonExtendingEmbeddedDbTest.java?view=markup\" href=\"http://jeeutils.svn.sourceforge.net/viewvc/jeeutils/trunk/DbUnitTestSkeleton/src/test/java/net/jakubholy/testing/dbunit/embeddeddb/SimpleNonExtendingEmbeddedDbTest.java?view=markup\" rel=\"nofollow\">SimpleNonExtendingEmbeddedDbTest.java</a> for inspiration.) You may want to override its getDataSet() if you want to use st. else than the default testData/dbunit-test_data_set.xml.</li>\r\n\t<li><strong>Prepare test data</strong>: Copy the example testData/<a title=\"http://jeeutils.svn.sourceforge.net/viewvc/jeeutils/trunk/DbUnitTestSkeleton/testData/dbunit-test_data_set.xml?revision=HEAD&amp;content-type=text%2Fplain\" href=\"http://jeeutils.svn.sourceforge.net/viewvc/jeeutils/trunk/DbUnitTestSkeleton/testData/dbunit-test_data_set.xml?revision=HEAD&amp;content-type=text%2Fplain\" rel=\"nofollow\">dbunit-test_data_set.xml</a> into your new testData/ and modify it to fit your data needs. Any table mentioned in the file will be emptied prior to running test, if it has any rows defined than those will be also inserted\r\n<ul>\r\n\t<li>You may use e.g. <a title=\"http://jailer.sourceforge.net/\" href=\"http://jailer.sourceforge.net/\" rel=\"nofollow\">Jailer</a> (good <a title=\"http://jailer.sourceforge.net/exporting-data.htm\" href=\"http://jailer.sourceforge.net/exporting-data.htm\" rel=\"nofollow\">tutorial</a>) to produce a subset of your database in DbUnit XML format (unfortunately only Flat XML) or another tool supporting it such as <a title=\"http://quantum.sourceforge.net/\" href=\"http://quantum.sourceforge.net/\" rel=\"nofollow\">QuantumDB</a>.</li>\r\n</ul>\r\n</li>\r\n\t<li><strong>Run the test</strong>.</li>\r\n</ol>\r\nYou may <a href=\"https://sourceforge.net/apps/mediawiki/jeeutils/index.php?title=DbUnit_Express\">read more about DbUnit Express on its home page</a>.<br><br>PS: The last released version 1.2.0 is from 4/2010, a new version should be out in few weeks.",
  "excerpt": ""
 },
 {
  "title": "Simple Logging HTTP Proxy with Grinder ",
  "published": "2011-07-28 11:19:02",
  "postType": "post",
  "slug": "/2011/07/28/simple-logging-http-proxy-with-grinder/",
  "status": "publish",
  "tags": [
   "java",
   "networking",
   "proxy"
  ],
  "categories": [
   "Tools"
  ],
  "content": "Sometimes I need to observe HTTP communication between my and another machine. I usually use Eclipse' integrated TCP/IP monitor for it's simple and does its job well but today for a large response it just displayed \"The HTTP content is too large to display.\" so I started searching for alternatives and found the <a href=\"http://grinder.sourceforge.net/g3/tcpproxy.html\">Grinder TCPProxy</a>, written in Java and distributed under the BSD license.<br><br><a href=\"http://grinder.sourceforge.net/\">Grinder</a> is a Java load testing framework and the proxy is just a part of it. Here is how you would start the proxy to forward local port 6080 to the remote address example.webservices.com:80 and log the HTTP communication into a file:<br><br><pre><code>java -cp lib/grinder.jar net.grinder.TCPProxy -console -localhost 127.0.0.1  -localport 6080 -remotehost example.webservices.com -remoteport 80 &gt; http.log</code></pre><br><br>The optional flag <code>-console</code> makes it  to display a window for shutting it down cleanly (likely unnecessary under Linux/Mac). When you want it to log just into the console, add <code>-colour</code> for nicely colored output.<br><br>Run it with <code>-?</code> to see all the available options.",
  "excerpt": ""
 },
 {
  "title": "Experiencing JSF 1.2: Good but Needs a Framework",
  "published": "2011-07-30 11:06:40",
  "postType": "post",
  "slug": "/2011/07/30/experiencing-jsf-1-2-good-but-needs-a-framework/",
  "status": "publish",
  "tags": [
   "framework",
   "java",
   "jsf",
   "UI"
  ],
  "categories": [
   "j2ee",
   "Languages"
  ],
  "content": "I've got an opportunity to experiment with JSF 1.2 while preparing a lecture about <a href=\"https://sourceforge.net/apps/mediawiki/jeeutils/index.php?title=DbUnit_Express\">DbUnit Express</a> and test webapp for <a href=\"/2011/06/22/validating-jsf-el-expressions-in-jsf-pages-with-static-jsfexpression-validator/\">JSF EL Validator</a>. Same as JSF 1.1, it's much easier to use than the low level, too HTTP-ish servlets but still it is not flexible enough and usable per se, it is absolutely necessary to use a decent framework (such as Rich or ICE Faces) to be really productive. Automatic value and method binding is cool but not sufficient.<br><br>For example forcing dataTable to get filtered when you change selection in a select list was rather non-trivial and making the table sortable by every column required quite lot of work and if I wanted to have that for every table, I'd need to develop framework of my own. Of course with various JSF component libraries you get such things out of the box but still JSF 1.2 is little to rigid, for example methods that could take parameters (which came in JSF 2.0) would make things a lot simpler.<br><br>I've also considered using business objects - such as EJBs - directly as JSF backing beans but I feel that in this version it might be suitable only for small applications (where the overhead of concern separation doesn't pay off) or  some special ones. The problem is that even though backing beans are POJOs, JSF still forces them to a rather specific shape, which should be confined to the web layer  - such as having action methods that take no parameters and return an indication of which view to dislay next.<br><br>I would very much like to experiment with and compare other interesting frameworks such as Play!, Grails, and GWT (and given that I've finally got to learning Clojure, perhaps also Compojure), though I likely won't have time for that. If I do, you will come to know :-)\r\n<h2>Related posts</h2>\r\n<ul>\r\n\t<li><a href=\"http://www.dzone.com/links/r/hyperproductive_javaserver_faces.html\">Hyperproductive JavaServer Faces</a> - how to be productive with JSF 2 including the elimination of redeployments</li>\r\n</ul>",
  "excerpt": ""
 },
 {
  "title": "A Funny Story about the Pain of Monthly Deployments",
  "published": "2011-08-05 18:33:42",
  "postType": "post",
  "slug": "/2011/08/05/a-funny-story-about-the-pain-of-monthly-deployments/",
  "status": "publish",
  "tags": [
   "agile",
   "lean",
   "opinion"
  ],
  "categories": [
   "General"
  ],
  "content": "The end of our one-month iteration approached and the levels of fear and agitation started to rise. What will happen when we deploy it? Will everything crash? Will all hell break loose? Will there be a flood of midnight severity-one issues? Will the features developed work together or are there going to be unexpected and fatal interactions?<br><br>What is funny about this story, you certainly ask? You know these pains of deployment too and there is nothing funny about them.<br><br>Well, the funny thing is that I was used to quarterly releases and considered them completely normal and OK. Afterwards, I got used to bi-weekly releases and now I consider even monthly releases way too long (and I actually wouldn't mind weekly releases). The conclusion? Once you see how easy and better things can be, you will always feel pain when you need to step back.",
  "excerpt": ""
 },
 {
  "title": "DbUnit Express Tips: Setup Simplification, Custom Data File Convention",
  "published": "2011-08-05 21:16:40",
  "postType": "post",
  "slug": "/2011/08/05/dbunit-express-tips-setup-simplificatio-custom-data-file-convention/",
  "status": "publish",
  "tags": [
   "dbunit",
   "DbUnitExpress",
   "java"
  ],
  "categories": [
   "Databases",
   "Languages",
   "Testing"
  ],
  "content": "I've recently <a href=\"/2011/07/27/having-database-test-ready-in-10-minutes-with-dbunit-express/\"> introduced here DbUnit Express</a>, a wrapper around DbUnit intended to get you started with testing DB-related code in no time, and now I'd like to share two productivity tips: simplifying db tester setup with a parent test and implementing your own convention for data set files, for example one data set per test class.<br><br><!--more-->\r\n<h2>Define your own convention for data set names, e.g. per-test-class-data-set</h2>\r\nBy default DbUnit Express expects you to use dataset <em>testData/dbunit-test_data_set.xml</em>. However you might for example prefer each test to have its own data set, named for example &lt;test class name&gt;-test.xml.<br><br>The easiest solution without repeating yourself is to create a custom subclass of EmbeddedDbTester overriding its createDefaultDataSet():<br><br><pre><code>\r\npublic class PerTestDataSetEmbeddedDbTester extends EmbeddedDbTester {\r\n    @Override\r\n    protected IDataSet createDefaultDataSet() throws DatabaseUnitRuntimeException, DataSetException {\r\n\t\treturn createDataSetFromFile(getClass().getSimpleName() + &quot;-data.xml&quot;);\r\n\t}\r\n}\r\n</code></pre><br><br>Notice that if the data set cannot be found in the default location, i.e. testData/, then it is searched for on the classpath, so it is perfectly OK to have it next to the test class.\r\n<h2>Setup Simplification</h2>\r\nWhen using DbUnit Express with JUnit 4.x, you typically need to do three things in each test class:<br><br><pre><code>\r\npublic class SpringBookDaoImplTest {<br><br>    private EmbeddedDbTester testDb = new EmbeddedDbTester(); // 1<br><br>    @Before\r\n    public void setUp() throws Exception {\r\n        testDb.onSetup(); // 2\r\n    }<br><br>    @After\r\n    public void tearDown() throws Exception {\r\n        testDb.onTearDown(); // 3\r\n    }<br><br>    ...\r\n}\r\n</code></pre><br><br>That is lot of repeated coding and the best way to get rid of it is to create an abstract parent class of all your test classes working with DbUnit Express and moving the code there (changing the tester's visibility to protected, of course):<br><br><pre><code>\r\npublic abstract class AbstractMyApplicationDbTest {<br><br>    protected EmbeddedDbTester testDb = new EmbeddedDbTester(); // 1<br><br>    @Before\r\n    public final void setUpDbUnitExpress() throws Exception {\r\n        testDb.onSetup(); // 2\r\n    }<br><br>    @After\r\n    public final void tearDownDbUnitExpress() throws Exception {\r\n        testDb.onTearDown(); // 3\r\n    }<br><br>    ...\r\n}\r\n</code></pre>",
  "excerpt": ""
 },
 {
  "title": "Most interesting links of August",
  "published": "2011-08-31 21:59:33",
  "postType": "post",
  "slug": "/2011/08/31/most-interesting-links-of-august-2/",
  "status": "publish",
  "tags": [
   "agile",
   "design",
   "quality",
   "refactoring",
   "Testing"
  ],
  "categories": [
   "General",
   "Testing",
   "Tools",
   "Top links of month"
  ],
  "content": "<h2>Recommended Readings</h2>\r\n<ul>\r\n\t<li><a href=\"http://martinfowler.com/bliki/SoftwarePatent.html\">Martin Fowler on the problem of software patents</a> - \"... while patents (even software patents) are a good idea in principle, in practice they have turned into an unmitigated disaster and would be better scrapped.\"</li>\r\n\t<li><a href=\"http://drdobbs.com/architecture-and-design/231002664?pgno=1\">Discovering Hidden Design</a>, Michael Feathers - When refactoring complex code towards a better design with clearer separation of concerns, it may be sometimes worthwhile to factor out a more-less separated cluster of functionality even if it doesn't do just one thing (and this it is difficult to find a descriptive name for it). Comparing the cost and benefit of this and an \"ideal\" refactoring (where we get to single-responsibility factors), this one may prove better.</li>\r\n\t<li><a href=\"http://martinfowler.com/bliki/TradableQualityHypothesis.html\" target=\"_blank\">Martin Fowler: Tradable Quality Hypothesis</a> - Martin argues that we must claim that quality in software development is not tradable (even though we know that certain tradeoffs can be done). The reason is that people are used to quality (in food, clothing, ...) being pretty \"tradable\" and so it is very hard to persuade them that in the case of software development it is tradable much less (or not at all). And once your manager and customers view quality as tradable, you are doomed. They will force you to trade it for time, features, ... in a proportion that will harm the project (because, as already mentioned, in SW it is much less tradable then in other domains).</li>\r\n\t<li><a href=\"http://www.coregroup.no/2011/08/are-estimates-worthless/\">Are estimates worthless?</a>&amp; Magne's response - interesting discussion of the value and cost of estimation and its role in contracting w.r.t. trust - a nice addition to the <a title=\"Permanent link to Discussion: Agile not suitable for governmental IT?\" href=\"/2011/05/06/discussion-agile-not-suitable-for-governmental-it/\" rel=\"bookmark\">discussion: Agile not suitable for governmental IT?</a>.</li>\r\n\t<li><a href=\"http://java.dzone.com/articles/generate-test-data-datafactory\">Generate Test Data with DataFactory</a> - nice java library that generate \"random\" values of different types and optionally satisfying some constraints - f.ex. first/last name (using built-in or custom list), date (within a range, w.r.t. another date, ...), address (cities, streets etc.), email, random text/word/characters, number. Available <a href=\"https://github.com/andygibson/datafactory\">at GitHub</a>.</li>\r\n</ul>",
  "excerpt": ""
 },
 {
  "title": "Most interesting links of September",
  "published": "2011-09-30 21:59:22",
  "postType": "post",
  "slug": "/2011/09/30/most-interesting-links-of-september-2/",
  "status": "publish",
  "tags": [
   "agile",
   "CleanCode",
   "clojure",
   "lean",
   "refactoring",
   "scrum",
   "tdd"
  ],
  "categories": [
   "General",
   "Testing",
   "Top links of month"
  ],
  "content": "<h2>Recommended Readings</h2>\r\n<ul>\r\n\t<li><a href=\"http://martinfowler.com/articles/itsNotJustStandingUp.html\">J. Yip: It's Not Just Standing Up: Patterns for Daily Standup Meetings</a> - it isn't easy to make stand-up meetings short, focused, energizing, and centered around continuous improvements and team spirit. This description of an example good standup, the meeting's goals, and especially the \"patterns\" and \"bad smells\" can be pretty useful to get and keep on the track towards a brighter future. TBD: standup goals: GIFTs, team spirit, appreciation where we go and are.</li>\r\n\t<li><a href=\"http://www.leanessays.com/2011/08/dont-separate-design-from.html\">M. Poppendieck: Don’t Separate Design from Implementation</a> - according to Mary, (detailed) requirements - being it in the form of (backlog) user stories or any other - represent actually a design of the system, which shouldn't be done by the amateur product owner/business analyst but by professionals, meaning the developers, based on high-level goals and clear specification of the desired business value. She writes about a project that her factory outsourced and which she could have designed but didn't - yet it succeeded even though there were no detailed requirements. I've also read and unfortunately lost an interesting answer where the author argues that that is only possible if the developers are really experienced in the field. I tend to agree more with Mary though it is of course a question what \"high\" and \"low\" level goals/requirements are. But undeniably users/analysts tend to propose solutions disguised as requirements while often missing the technical insight to see possible other and better solutions. We also cannot expect the developers to produce a great SW if the true goals, needs, and business values behind the requested \"features\" aren't clearly communicated to them. (The best example - lost source again - is where a developer proposes to the client a simple process change that will solve the problem without writing a single line of code.)</li>\r\n\t<li>Mike Cohn: <a href=\"http://blog.mountaingoatsoftware.com/the-forgotten-layer-of-the-test-automation-pyramid\">The Forgotten Layer of the Test Automation Pyramid</a> - three levels of testing with increasing number of tests: UI/Service/Unit (or end-to-end instead of UI), each requiring a different approach. Unit tests are best because a failure points directly to its source (with higher level tests you don't immediately know the cause). The higher in the pyramid, the less tests we should have (e.g. because of their redundancy). It's important not to forget the middle, service layer - unit tests are too low-level, UI tests too difficult and brittle. Also Gojko in Specification by Examples says that acceptance/BDD tests should run mainly at the service layer because of the UI level issues.\r\n\"Although automated unit testing is wonderful, it can cover only so much of an application’s testing needs. Without service-level testing to fill the gap between unit and user interface testing, all other testing ends up being performed through the user interface, resulting in tests that are <em>expensive to run, expensive to write, and brittle</em>.\" [Emphasis JH.]</li>\r\n\t<li><a href=\"http://pauldyson.wordpress.com/2011/08/15/technical-debt-and-the-lean-startup/\">Technical Debt and the Lean Startup</a> - Paul Dyson remarks that while quality is an essential concern for projects in established environments, in the case of lean startups the primary goal is to find out whether a product is viable and what it should be like and thus it's reasonable to accept much higher technical debt by not spending too much time on ensuring scalability, de-duplication etc. - only when the product proves viable should we start to care for its long-evity by emphasizing the quality. But one thing can never miss and that is good test suite because this is the crucial factor that makes letter payment of the technical debt possible without ruining oneself.</li>\r\n\t<li><a href=\"http://johannesbrodwall.com/2011/06/22/real-time-coding-competition-with-extreme-startup/\">Coding dojo - Real time coding competition with Extreme Startup</a> - an inspiring report about a coding dojo lead by Johannes Brodwall in Bergen's JUG, the task being the implementation of a server that can respond to questions send over HTTP (that's all participants know at the beginning - they learn the rest during the iterations)</li>\r\n\t<li><a href=\"http://blogs.lessthandot.com/index.php/ITProfessionals/ProfessionalDevelopment/using-code-katas-to-improve\">Using Code Katas to Improve Programming Skills</a> - why to use code katas + links to different proposed katas</li>\r\n\t<li>Kent Beck: <a href=\"http://www.threeriversinstitute.org/blog/?p=594\">Don’t Cross the Beams: Avoiding Interference Between Horizontal and Vertical Refactorings </a>- when to do depth-first (more exploratory) refactoring and when to extend it into breadth (i.e. apply it to several similar objects)</li>\r\n</ul>\r\nLearning Clojure (maybe not so interesting for those not learning the language)\r\n<ul>\r\n\t<li>Phil Calçado: <a href=\"http://www.philcalcado.com/2011/08/29/my_experience_with_test/driven_development_in_clojure_and_functional_programming.html\">My Experience With TDD In Clojure</a> (via planetclojure) - nice example of how to decompose a task in functional programming to make it easy to test (via Midje), including useful testing-related links and a discussion of side-effect isolation and the building blocks of functional programs, i.e. function composition using combinators (i.e. functions producing functions)</li>\r\n\t<li><a href=\"http://fronx.posterous.com/how-to-learn-clojure-effectively\">How to learn Clojure effectively</a> (via planetclojure) - a very good description of how the task at  <a href=\"http://4clojure.com/\">4Clojure</a> (though I prefer <a href=\"https://github.com/functional-koans/clojure-koans\">Clojure koans</a>) should be solved to benefit one's learning the most plus some general tips on functional thinking</li>\r\n\t<li><a href=\"http://stackoverflow.com/questions/2444893/clojure-open-source-projects\">Clojure open source projects</a> for learning how to code it</li>\r\n</ul>",
  "excerpt": ""
 },
 {
  "title": "DbUnit Express 1.3 is Even Easier to Use and Still Better",
  "published": "2011-09-04 15:49:26",
  "postType": "post",
  "slug": "/2011/09/04/dbunit-express-1-3-is-even-easier-to-use-and-still-better/",
  "status": "publish",
  "tags": [
   "DbUnitExpress",
   "java",
   "project"
  ],
  "categories": [
   "Languages",
   "Testing"
  ],
  "content": "The <a href=\"https://sourceforge.net/apps/mediawiki/jeeutils/index.php?title=DbUnit_Express\">DbUnit Express</a> 1.3.0 (a thin wrapper around DbUnit to speed up DB testing) released today introduces features that make it even easier to write a DB unit test, the most interesting ones are the introduction of EmbeddedDbTesterRule which can automatically execute its onSetup thanks to JUnit's @Rule (<a href=\"https://github.com/jakubholynet/dbunit-express/blob/master/src/test/java/net/jakubholy/dbunitexpress/EmbeddedDbTesterRuleTest.java\">example</a>) and the addition of setDataSet(fileName), which searches for a data set file of the given name on the classpath etc. and loads it.<br><br>See the updated <a href=\"https://sourceforge.net/apps/mediawiki/jeeutils/index.php?title=DbUnit_Express\">project page</a> and <a href=\"https://github.com/jakubholynet/dbunit-express/tree/master/src/test/java/net/jakubholy/dbunitexpress\">example tests</a>.<br><br>Other changes of interest:\r\n<ol>\r\n\t<li>The project was now officially renamed to dbunit-express (and root package changed to net.jakubholy.dbunitexpress), so update your Maven dependencies and code</li>\r\n\t<li>Upgraded to latest DbUnit (2.4.8, was 2.4.7)</li>\r\n\t<li>Added slf4j-simple to dependencies so that users don't need to do it themselves anymore - those who don't want it may just exclude it</li>\r\n\t<li>Added EmbeddedDbTesterRule which can call its onSetup automatically under JUnit 4</li>\r\n\t<li>Added setDataSet(String) that tries to find a file of the given name in testData/ or on the classpath and loads it</li>\r\n\t<li>When there is a FileNotFoundException for the ddl, report the working directory, check if testData/ self exists</li>\r\n\t<li>Added comment to onTearDown() saying that it does nothing and thus doesn't need to be called, updated test classes accordingly</li>\r\n\t<li>Added SimpleNonExtendingEmbeddedDbJUnit4Test to show usage with JUnit 4</li>\r\n\t<li>When it is detected in onSetup() that the test database likely isn't initialized, we advice to use Db Creator and report the current working directory</li>\r\n\t<li>Added method findConfigFile(name) to simplify custom DataSet creation, location of DDL files etc.</li>\r\n\t<li>Added DatabaseCreator.loadDdl(name) to load an additional DDL, you can also use <em>new DatabaseCreator().setDdlFile(\"fileOnClasspathOrInTestData.ddl\").doCreateAndInitializeTestDb()</em> to init the DB from a custom DDL</li>\r\n</ol>\r\n<div>PS: As you might have noticed, the project was migrated to GitHub because I couldn't stand Subversion anymore. Its inability to deal with deleted folders was killing me.</div>",
  "excerpt": ""
 },
 {
  "title": "DRY: Use JUnit @Rule Instead of Repeating Setup/@Before in Each Test",
  "published": "2011-09-04 17:11:22",
  "postType": "post",
  "slug": "/2011/09/04/dry-use-junit-rule-instead-of-repeating-setupbefore-in-each-test/",
  "status": "publish",
  "tags": [
   "DbUnitExpress",
   "java",
   "junit"
  ],
  "categories": [
   "Languages",
   "Testing"
  ],
  "content": "I was for a long time unhappy that <a href=\"https://sourceforge.net/apps/mediawiki/jeeutils/index.php?title=DbUnit_Express\">DbUnit Express</a> users have to create a @Before method in each test just to get the test database initialized. Fortunately since version 1.3.0 they don't need to do it anymore thanks to <a href=\"http://kentbeck.github.com/junit/javadoc/4.9/org/junit/rules/package-summary.html\">JUnit Rules</a> (if you are not familiar with them, they are an alternative to @Before/@After and @BeforeClass/@AfterClass, read this <a href=\"http://blog.schauderhaft.de/2009/10/04/junit-rules/\">rules introduction</a>).<br><br>As true coders you are certainly annoyed by so many words so let get to the source code.\r\n<h2><!--more-->Code</h2>\r\n<h3>@Rule implementation</h3>\r\nFirst of all you must implement the rule and you setup/tear down code in it. I have done this directly in the class that my users use so that they don't need two instance variables (the rule and the actual db tester).<br><br><a href=\"https://github.com/jakubholynet/dbunit-express/blob/master/src/main/java/net/jakubholy/dbunitexpress/EmbeddedDbTesterRule.java\">EmbeddedDbTesterRule</a> (requires JUnit 4.9+):<br><br><pre><code>\r\npublic class EmbeddedDbTesterRule extends EmbeddedDbTester implements TestRule {<br><br>    private class DbInitializer extends ExternalResource {\r\n        @Override protected void before() throws Throwable {\r\n                EmbeddedDbTesterRule.this.onSetup();\r\n        };\r\n    }<br><br>    private final DbInitializer initializer = new DbInitializer();<br><br>    /** Ignore - for internal use by JUnit's Rule handling. */\r\n    public final Statement apply(Statement statement, Description description) {\r\n        return initializer.apply(statement, description);\r\n    }\r\n}\r\n</code></pre><br><br>Notes:\r\n<ul>\r\n\t<li><em>EmbeddedDbTester</em> is the class that my users uses. To make it self-initializing I had to create a subclass which implements JUnit's TestRule</li>\r\n\t<li>The implementation is simplified by reusing one of the predefined rules, <em>ExternalResource</em>, and just delegating to it</li>\r\n\t<li>JUnit calls the <em>apply</em> method at different times, of them the @Before call is propagated to us via <em>ExternalResource.before</em>. We don't really need to understand what a Statement or Description is and what to do with it.</li>\r\n\t<li>Similarly we could execute some code after each test method or before/after each test class (in which case you'd need to use @ClassRule, I'm not sure how/whether it can be combined with @Rule)</li>\r\n</ul>\r\n<h3>Rule usage in a test class</h3>\r\n<a href=\"https://github.com/jakubholynet/dbunit-express/blob/master/src/test/java/net/jakubholy/dbunitexpress/EmbeddedDbTesterRuleTest.java\">EmbeddedDbTesterRuleTest</a>:<br><br><pre><code>\r\npublic class EmbeddedDbTesterRuleTest {<br><br>    @Rule public EmbeddedDbTesterRule testDb = new EmbeddedDbTesterRule();<br><br>    /**\r\n     * onSetup should have been executed automatically thanks to the @Rule and thus\r\n     * our data should be in the DB.\r\n     */\r\n    @Test\r\n    public void should_execute_onSetup_automatically() throws Exception {\r\n        testDb.createCheckerForSelect(&amp;quot;select some_text from my_test_schema.my_test_table&amp;quot;)\r\n                .withErrorMessage(&amp;quot;No data found =&amp;gt; onSetup wasn't executed as expected&amp;quot;)\r\n                .assertRowCount(1)\r\n                .assertNext(&amp;quot;EmbeddedDbTesterRuleTest data&amp;quot;);\r\n    }\r\n}\r\n</code></pre><br><br>Notes:\r\n<ul>\r\n\t<li>To use it, you must declare a public, non-static field annotated with @Rule and its declared type must implement TestRule (formerly MethodRule)</li>\r\n\t<li>You then use the instance as you would the original parent class (<em>EmbeddedDbTester</em>), you just don't need to initialize it in a @Before method because it is done automatically</li>\r\n</ul>\r\n<h2>Conclusion</h2>\r\n@Rules are certainly a great thing that can simplify the life of test writers and test framework authors. I'm not really happy with its API, which is little to invasive (the field must be public, the declared type - not just the actual runtime value - must implement TestRule =&gt; the API of my class visible to my users is littered with a JUnit-related method) but it is still a pretty good thing.\r\n<h2>Sidenote: About DbUnit Express</h2>\r\nIf you haven't heard about DbUnit Express before - it is a thin wrapper around DbUnit (unit testing of code interacting with a database) intended to make starting with DB testing as quick and as easy as possible by introducing\r\n<ol>\r\n\t<li>Convention over configuration - automatically loads data set file of name derived from the test name if it exists, ...</li>\r\n\t<li>Sensible defaults - comes pre-configured for an embedded Derby database</li>\r\n\t<li>Convenience methods - such as getDataSource() - extremely useful for testing code using Spring JDBC</li>\r\n\t<li>Utilities - RowComparator for easy verification of data in a select, DatabaseCreator for DB initialization from a DDL, replaceDatabase(dataSet), clearTable(name) , JUnit 4 @Rule automatically invoking onSetup(), ...</li>\r\n\t<li>Improved error reporting</li>\r\n\t<li>The configuration of DbUnit that proved to be most flexible and error-proof - fully qualified table names, XML data set,...</li>\r\n\t<li>Sample .ddl and data set .xml files</li>\r\n</ol>\r\n<div>For more information check <a href=\"https://sourceforge.net/apps/mediawiki/jeeutils/index.php?title=DbUnit_Express\">dbunit-express home page</a>.</div>",
  "excerpt": ""
 },
 {
  "title": "Correct your URL",
  "published": "2011-09-07 12:23:07",
  "postType": "post",
  "slug": "/2011/09/07/practical-intr%e2%80%a6and-java-proxy/",
  "status": "publish",
  "tags": [],
  "categories": [
   "Uncategorized"
  ],
  "content": "The page you want to access is<a title=\"Permanent link to Practical Introduction into Code Injection with AspectJ, Javassist, and Java Proxy\" href=\"../2011/09/07/practical-introduction-into-code-injection-with-aspectj-javassist-and-java-proxy/\" rel=\"bookmark\"> Practical Introduction into Code Injection with AspectJ, Javassist, and Java Proxy</a><br><br>Sorry for the wrong bit.ly link :-(",
  "excerpt": ""
 },
 {
  "title": "Principles for Creating Maintainable and Evolvable Tests",
  "published": "2011-11-21 10:52:29",
  "postType": "post",
  "slug": "/2011/11/21/principles-for-creating-maintainable-and-evolvable-tests/",
  "status": "publish",
  "tags": [
   "architecture",
   "opinion",
   "tdd",
   "Testing"
  ],
  "categories": [
   "Testing"
  ],
  "content": "Having [automated] unit/integration/functional/... tests is great but it is too easy for them to become a hindrance, making any change to the system painful and slow - up to the point where you throw them away. How to avoid this curse of rigid tests, too brittle, too intertwined, too coupled to the implementation details? Surely following the principles of clean code not only for production code but also for tests will help but is it enough? No, it is not. Based on a discussion on our recent course with Kent Beck, I think that the following three principles below are important to have decoupled, easy to evolve tests:\r\n<ol>\r\n\t<li>Tests tell a story</li>\r\n\t<li>True unit tests + decoupled higher-level integration tests (-&gt; Mike Cohn's <a href=\"http://blog.mountaingoatsoftware.com/the-forgotten-layer-of-the-test-automation-pyramid\">Layers of the Test Automation Pyramid</a>)</li>\r\n\t<li>More functional composition of the processing</li>\r\n</ol>\r\n<!--more-->\r\n(<em>Disclaimer: All good ideas here come from Kent Beck and my course-mates. All misconceptions are genuinely mine.</em>)\r\n<h2>1. Tests tell a story</h2>\r\nIf you think about your tests as telling a story - single test methods telling simple stories about small features, whole test classes about particular larger-scale features, the whole test suite about your software then you end up with better, more decoupled, and easier to understand tests. This implies that when somebody reads the test, s/he feels as if reading a story.<br><br>This actually corresponds nicely to what <a href=\"http://gojko.net/\">Gojko Adzic</a> is teaching about acceptance tests. i.e. that they should be a \"<a href=\"http://specificationbyexample.com/key_ideas.html\">living documentation</a>\" of the system for the use of the business users, and this is their by far greatest benefit (and not, as it is usually believed, that you have a set of regression tests or that you can show that the system works).<br><br>Why should you write your tests as stories?\r\n<ul>\r\n\t<li>It forces you to concentrate on telling what the code is supposed to do as opposed to how it should do it. Your tests will be therefore more decoupled from the implementation and thus more maintainable and more likely to discover a defect in the way how a requirement is implemented.</li>\r\n\t<li>The story-telling approach forces you to abstract from unimportant details, f. ex. by creating an abstraction layer between the test and the low-level details of what's being tested (the layer may consist of something as simple as a helper method or something more elaborate)</li>\r\n\t<li>The tests will be easier to understand. As we all know, code is read many more times than written so understandability is very important. If your tests are easy to read and grasp, they will serve as a very good documentation of the code under test. Future generations of programmers working on it will love you.</li>\r\n\t<li>If you find it difficult to write the test in a story-like manner then something is likely wrong with your API and you should change it.</li>\r\n</ul>\r\nHow should you write tests to read as stories?\r\n<ul>\r\n\t<li>Naming</li>\r\n<ul>\r\n\t<li>Not: <em>should_return_20_if_sk_or_ba</em> - this tells me nothing: what is 20? what is ba, sk? (For the curious: airlines, namely SAS and British Airways)</li>\r\n\t<li>Yes:<em> should_give_discount_for_preferred_airlines</em> - this tells me what and why is done</li>\r\n</ul>\r\n\t<li>Proper level of abstraction - As mentioned above, to get the true benefit out of your tests and make them ready to live long you need to keep them on the proper level of abstraction</li>\r\n<ul>\r\n\t<li>Move unimportant details away from the test, into helper methods, objects (such as an <a href=\"http://martinfowler.com/bliki/ObjectMother.html\">ObjectMother</a>) or setUp. Don't obscure the main logic of the test. (Of course, if you need extensive setup or if you have a lot of low-level code in your test, something is rather wrong with your test approach, the design of the tested code, or both. Fix it first.)</li>\r\n\t<li>For example some people claim that having a loop in a test is too low-level - if you need it then perhaps your API is insufficient, its users might need to loop too, so why not just provide a suitable method that would do it for you?</li>\r\n\t<li>By the way, nobody says that it is easy to write tests on the right level of abstraction. But it pays off.</li>\r\n\t<li>A (rather conceived) example (click to expand):\r\n<pre><code>\r\n// GOOD ABSTRACTION LEVEL:\r\nthis.employee.setSickFrom(date(2011,DECEMBER,1)).to(date(2011,DECEMBER,31));\r\nassertSalaryType(SalaryType.SICK, this.calculator.salaryFor(employee, DECEMBER));<br><br>// BAD ABSTRACTION LEVEL:\r\nCalendar start = Calendar.getInstance();\r\nstart.set(Calendar.YEAR, 2011);\r\nstart.set(Calendar.MONTH, DECEMBER - 1); // Januar = 0\r\nstart.set(Calendar.DAY_OF_MONTH, 1);\r\nCalendar end = Calendar.getInstance();\r\nstart.set(Calendar.YEAR, 2011);\r\nstart.set(Calendar.MONTH, DECEMBER - 1); // Januar = 0\r\nstart.set(Calendar.DAY_OF_MONTH, 31);\r\nthis.employee.setSickFrom(start).to(end);<br><br>Salary salary = this.calculator.salaryFor(employee, DECEMBER);<br><br>assertNotNull(salary);\r\nSalaryType salaryType = salary.getType();\r\nassertNotNull(salaryType);\r\nassertEquals(SalaryType.SICK, salaryType.getName());\r\n</code></pre></li>\r\n</ul>\r\n\t<li>Minimal coupling to implementation details - The more your test code resembles your implementation code the less useful it is. The whole point of tests is doing the same thing differently (and usually much more simply) then your implementation so that you are more likely to catch bugs in it. Copying &amp; pasting code from the implementation and adjusting it slightly is therefore a really bad thing to do. If you can't do things more simply (are sure you can't?!) try to do them at least differently.</li>\r\n\t<li>Mostly public API usage - To keep your tests as decoupled and maintainable as possible, not compromising the evolvability of your code, it seems reasonable to me to try to stick to the public API of the tested class as much as possible. If you want to check some low-level implementation details to be sure you've done them right, create another test case for it so that when the implementation changes, you can just throw it away while the test exercising the \"story\" implemented by the code will be able to live happily on. (See <a title=\"Never Mix Public and Private Unit Tests!\" href=\"../2011/10/20/never-mix-public-and-private-unit-tests/\">Never Mix Public and Private Unit Tests!</a>)</li>\r\n\t<li><a href=\"http://xunitpatterns.com/Testcase%20Class%20per%20Fixture.html\">TestCases per Fixture</a> (a separate test class for each of different setup needs) - I hope you already know that it is normal to have more test cases for one business class. Actually JUnit forces you to it e.g. by requiring the Parametrized test's data to be on the class level. If you group tests that require the same setup, you can move the setup code to the @Before method and thus keep the tests themselves much simpler and easier to read. Of course it is always little difficult to find the right balance between the number of test cases, fixtures, and test methods.</li>\r\n</ul>\r\n(Sidenote: Also the xUnit Patterns book states <a href=\"http://xunitpatterns.com/Goals%20of%20Test%20Automation.html#Tests%20as%20Documentation\">Tests as Documentation</a> as one of the main goals of testing.)\r\n<h2>2. True unit tests + decoupled higher-level integration tests</h2>\r\n(-&gt; Mike Cohn's <a href=\"http://blog.mountaingoatsoftware.com/the-forgotten-layer-of-the-test-automation-pyramid\">Layers of the Test Automation Pyramid</a>)<br><br>For discussing this JUnit perhaps isn't a good example - it is very special because it uses itself to test its behavior and the tests must fail even if there is a defect in the test framework - but still we can perhaps learn something from it. What surprised me a lot is that it has a high number of integration tests*, around 35%. The recipe for long-lived, evolvable tests seems to be to write:\r\n<ul>\r\n\t<li><strong>True unit tests</strong>, i.e. tests that only check one class and don't depend on its collaboration with other classes. Such a test is not affected by changes to those collaborations (that are covered by the integration tests) and if the tested class itself changes, the test is likely to either keep up with the change - or, if it is a large-scale change, you just throw it away (likely together with the class being tested) and write a new test for the new design. (I don't claim this is easier to implement and it also requires a particular way of coding and structuring the software [see #3 below] but it certainly seems to be a way to go.)</li>\r\n\t<li><strong>Integration tests</strong> that check the collaboration of multiple objects - not necessarily the whole application or a subsystem, just about any piece of definable functionality. Again, the integration test should be telling a story about what the module does - and this story itself is unlikely to change even if the way how the group of objects internally implement it evolves. It is thus crucial to test on the right level where you aren't bothered too much by concrete implementation details yet you aren't too far from the code you want to test.</li>\r\n<ul>\r\n\t<li>Kent mentioned a nice example of how they refactored the way JUnit 4.5 manages and executes individual phases of testing by replacing nested method calls with command objects (which made it possible to introduce @Rule) - thanks to the integration test being on the level \"I give some input to the execution subsystem and expect a particular output\", they still worked. If they were on a lower level and depended on the fact that there was a series of nested method calls, the refactoring would be much harder.</li>\r\n</ul>\r\n</ul>\r\n*) What is an integration tests? According to one of the possible definitions, unit test is a test where seeing the failure message you can immediately pinpoint the piece of code or even line where the problem originated. Contrary to that, if an integration test fails, you usually can't say why and have to dig into it or perhaps debug it a little.\r\n<h2>3. More functional composition of the processing (i.e. kill the mocks!)</h2>\r\nDo you need a mocking framework to write tests? Then you might be doing it in a suboptimal way. (Disclaimer: There surely are different yet equally good approaches to nearly anything :-).) When Kent was explaining the way he composes his programs he draw a picture similar to this one:<br><br><img class=\"aligncenter size-full wp-image-1382\" title=\"Kent - program structure\" src=\"https://lh3.googleusercontent.com/-x8NmkhlNKD4/TqAmDUHl7GI/AAAAAAAACL8/xIL5Tjt3Gp4/s261/integrators-and-workers.png\" alt=\"\" /><br><br>What is interesting about it? It is not the typical network of objects where one object does something and calls another one to *continue* with the processing or to do a part of it. It is composed of two types of objects: <em>workers</em> that receive an input and produce an output, and <em>integrators</em> that delegate the work to individual workers and pass it from one to another with minimal logic of their own. The workers are very functional and thus easy to test with true unit tests (and as said, if a different implementation is required, you just may throw the worker with its test away and create a new one) while the integrators should be as simple as possible (so the likelihood of a defect is smaller) and are covered by integration tests. (Everything fits nicely together, doesn't it?)<br><br>An example worker is JUnit's <a href=\"https://github.com/KentBeck/junit/blob/master/src/main/java/org/junit/runners/model/Statement.java\">Statement</a> (f.ex. <a href=\"https://github.com/KentBeck/junit/blob/master/src/main/java/org/junit/internal/runners/statements/FailOnTimeout.java\">FailOnTimeout</a>), which replaced a series of nested function calls used previously. The role of integrator is taken by a <a href=\"https://github.com/KentBeck/junit/blob/master/src/main/java/org/junit/runners/ParentRunner.java\">Runner</a>.\r\n<h2>Conclusion</h2>\r\nGiven that most of bigger business software systems live for quite a number of years, it's essential to write tests in such a way that they enhance and not limit the evolvability of the system. It is not easy but we must make efforts towards that.<br><br>To succeed we must structure our code and tests in a particular way and approach our test methods, test classes, and test suites as telling stories about <em>what</em> the code under test does.\r\n<h2>Related links</h2>\r\n<ul>\r\n\t<li>Uncle Bob: <a href=\"http://blog.objectmentor.com/articles/2009/10/28/manual-mocking-resisting-the-invasion-of-dots-and-parentheses\">Manual Mocking: Resisting the Invasion of Dots and Parentheses</a> - uncle Bob explains why he usually uses hand-coded stubs, talks about the difference between testing choreography and testing behavior, and when a mocking framework is really necessary</li>\r\n</ul>",
  "excerpt": ""
 },
 {
  "title": "Link: Advanced Usage of JUnit Theories, Multiple DataPoints, and ParameterSuppliers",
  "published": "2011-09-16 07:34:53",
  "postType": "post",
  "slug": "/2011/09/16/link-advanced-usage-of-junit-theories-multiple-datapoints-and-parametersuppliers/",
  "status": "publish",
  "tags": [
   "junit"
  ],
  "categories": [
   "Testing"
  ],
  "content": "It is surprising how difficult it is to find documentation for some JUnit features such as Theories. May be they haven't bothered to write it because it is still considered \"experimental\" (even though included in JUnit since 4.4). As usually we have to rely on <a href=\"http://blog.schauderhaft.de/\">Jens Schauder's blog</a> and I'd like to draw your attention to <a href=\"http://blog.schauderhaft.de/2010/02/07/junit-theories/\">his post describing advanced usage of JUnit Theories</a> including things like\r\n<ul>\r\n\t<li>multi-argument @Theory methods (each argument's value taken from a different set of data points thanks to their different data types),</li>\r\n\t<li>@TestedOn as an in-place values supplier, and</li>\r\n\t<li>use of org.junit.Assume.assumeThat,</li>\r\n\t<li>the use of parameter suppliers (create a marker interface annotated with @ParametersSuppliedBy(YourImplementation.class), create the implementation extending ParameterSupplier, and annotate your theory's argument with the interface)</li>\r\n</ul>\r\nThank you, Jens!",
  "excerpt": ""
 },
 {
  "title": "JUnit Tip: Verifying that an Exception with a Particular Message was Thrown",
  "published": "2011-09-16 19:20:47",
  "postType": "post",
  "slug": "/2011/09/16/junit-tip-verifying-that-an-exception-with-a-particular-message-was-thrown/",
  "status": "publish",
  "tags": [
   "junit"
  ],
  "categories": [
   "Testing"
  ],
  "content": "JUnit has a hidden treasure which makes it easy to do something we have long longed for - namely not only to verify that an exception of a particular type has been thrown but also that its message contains the expected message. The hidden pearl is the <a href=\"http://kentbeck.github.com/junit/javadoc/latest/index.html?org/junit/rules/ExpectedException.html\">@Rule ExpectedException</a> and its JavaDoc documents well how to use it (slightly modified):<br><br><!--more--><br><br><pre><code>\r\nimport org.junit.*;\r\nimport org.junit.rules.ExpectedException;<br><br>public static class HasExpectedException {\r\n        @Rule\r\n        public ExpectedException thrown= ExpectedException.none();<br><br>        @Test\r\n        public void throwsNothing() {\r\n            // no exception expected, none thrown: passes.\r\n        }<br><br>        @Test\r\n        public void throwsNullPointerExceptionWithMessage() {\r\n                thrown.expect(NullPointerException.class);\r\n                thrown.expectMessage(&quot;What happened here?&quot;);\r\n                thrown.expectMessage(allOf(containsString(&quot;What&quot;), containsString(&quot;here&quot;)));\r\n                throw new NullPointerException(&quot;What happened here?&quot;);\r\n        }\r\n }\r\n</code></pre><br><br>(As you might have noticed, it uses <a href=\"http://code.google.com/p/hamcrest/wiki/Tutorial\">Hamcrest matchers</a>; containsString isn't included directly in junit and thus you'd need junit-dep + hamcrest jars.)",
  "excerpt": ""
 },
 {
  "title": "Only a Masochist Would Write Unit Tests in Java. Be Smarter, Use Groovy (or Scala...).",
  "published": "2011-10-18 12:58:25",
  "postType": "post",
  "slug": "/2011/10/18/only-a-masochist-would-write-unit-tests-in-java-be-smarter-use-groovy-or-jruby-or-st-else-similar/",
  "status": "publish",
  "tags": [
   "groovy",
   "java",
   "opinion",
   "productivity",
   "Testing"
  ],
  "categories": [
   "Languages",
   "Testing"
  ],
  "content": "<img title=\"A soothing image of a kitten\" src=\"http://placekitten.com/g/200/300\" alt=\"\" width=\"200\" height=\"300\" /><br><br>I like writing unit tests but Java doesn't make it particularly easy. Especially if you need to create objects and object trees, transform objects for checking them etc. I miss a lot a conscise, powerful syntax, literals for regular expressions and collections, conscise, clojure-based methods for filtering and transforming collections, asserts providing more visibility into why they failed. But hey, who said I have to write tests in the same language as the production code?! I can use Groovy - with its syntax being <a href=\"http://groovy.codehaus.org/Differences+from+Java\">~ 100%</a> Java + like thousand % more, optional usage of static/dynamic typing, closures, hundreds of utility methods <a href=\"http://groovy.codehaus.org/groovy-jdk/\">added to the standard JDK classes</a> and so on. Groovy support for example in IntelliJ IDEA (autocompletion, refactoring ...) is very good so by using it you loose nothing and gain incredibly much. So I've decided that from now on I'll only use Groovy for unit tests. And so far my experience with it was overwhelmingly positive (though few things are little more complicated by the positives more than compensate for them). Read on to find out why you should try it too.<br><br>(<em>The arguments here focus on Groovy but I guess similar things could be said about JRuby, Scala etc. - with the exception of Java code compatibility, which you only get in Groovy.</em>)\r\n<h2>Few examples</h2>\r\nSome of the example below use some Groovy magic but don't be scared. You can write Groovy just as if it was Java and only learn and introduce its magic step by step as you need it.<br><br>Bean construction:<br><br><pre><code>\r\ndef testBean = new Customer(fname: &quot;Bob&quot;, sname: &quot;Newt&quot;, age: 42)\r\n// Java: c = new Customer(); c.setFname(&quot;Bob&quot;); c.setSname(&quot;Newt&quot;); c.setAge(42);\r\n</code></pre><br><br>(Of course this starts to pay of if either you don't want to create a constructor or if there are \"many\" properties and you need to set different subsets of them (constructor with 4+ arguments is hard to read).)<br><br>Reading a file:<br><br><pre><code>\r\nassert test.method() == new File(&quot;expected.txt&quot;).getText()\r\n// Java: buffered reader line by line ...; Note: == actually uses equals()\r\n</code></pre><br><br>Checking the content of a collection/map:<br><br><pre><code>\r\nassert customerFinder.findAll().collect {it.sname}.sort() == [&quot;Lizard&quot;,&quot;Newt&quot;]\r\n// Java: too long to show here (extract only surnames, sort them, compare ...)\r\nassert getCapitalsMap() == [&quot;UK&quot; : &quot;London&quot;, &quot;CR&quot; : &quot;Prague&quot;]\r\n</code></pre><br><br>Regular expressions:<br><br><pre><code>\r\nassert (&quot;dog1-and-dog2&quot; =~ /dog\\d/).getAt([0,1]) == [&quot;dog1&quot;, &quot;dog2&quot;]\r\n</code></pre>\r\n<ul>\r\n\t<li>Or more fail-safe regexp:\r\n<pre><code>\r\nassert (&quot;dog1-and-dog2&quot; =~ /dog\\d/).iterator().toSet() == [&quot;dog1&quot;, &quot;dog2&quot;].toSet()\r\n</code></pre></li>\r\n\t<li>With a match group:\r\n<pre><code>\r\nassert (&quot;dog11-and-dog22&quot; =~ /dog(\\d+)/).iterator().collect({it[1]}).toSet() == [&quot;11&quot;, &quot;22&quot;].toSet()\r\n</code></pre></li>\r\n</ul>\r\n<!--more-->\r\n<h2>What is Groovy?</h2>\r\n<a href=\"http://groovy.codehaus.org/Differences+from+Java\">Groovy</a> 1.8 is a mature scripting language for the JVM written as an extension of Java with optional dynamic typing, closures, and more. It's now developed by SpringSource, the company behind the Spring framework.<br><br>As mentioned, nearly all Java code is a valid Groovy code with basically one exception: To initialize an array you can't use { ... } (for that would be a closure), you must use [...] instead (notice that by default it actually creates a List, only when assigned to an array variable or casted to array will it produce an array). Make sure to check the few <a href=\"http://groovy.codehaus.org/Differences+from+Java\">common gotchas</a> before you dive into using Groovy.<br><br>You can experiment with Groovy online in the <a href=\"http://groovyconsole.appspot.com/\">GAE Groovy console</a>.\r\n<h2>Groovy features especially beneficial for testing</h2>\r\nGeneral\r\n<ul>\r\n\t<li>Dynamic typing at request =&gt; conscise, avoids code cluttered with casts</li>\r\n</ul>\r\n<a href=\"http://groovy.codehaus.org/groovy-jdk/java/util/Collection.html\">Collections</a>: Closure-based methods like every, each, find<br><br><a href=\"http://groovy.codehaus.org/groovy-jdk/java/io/File.html\">Files</a>: Read all the text with one call, withReader { .. } etc.<br><br>Testing/advanced:\r\n<ul>\r\n\t<li><em>assert</em>- you can use the Java keyword assert instead of JUnit methods, upon failure Groovy will provide you with pretty good info of what went wrong:\r\n<pre>Assertion failed: <br><br>assert config.getResolvers()) == [\"h:dataTable\" : resolver, \"my:dt2\" : null]\r\n       |      |                |                  |\r\n       |      |              false                |\r\n       |      |                                   MyResolver@731d2572\r\n       |      [h:dataTable:MyResolver@731d2572, my:dt2:MyResolver@731d2572]\r\n       LocalVariableConfiguration@7e859a68</pre>\r\n</li>\r\n\t<li>Here-docs: embed <a href=\"http://groovy.codehaus.org/Strings+and+GString\">multi-line strings</a> easily in a test (also supports replacing references like $variable with values)</li>\r\n\t<li><a href=\"http://groovy.codehaus.org/Groovy+way+to+implement+interfaces\">Implementing interfaces with a map</a> (map coercion)</li>\r\n\t<li><a href=\"http://groovy.codehaus.org/Developer+Testing+using+Maps+and+Expandos+instead+of+Mocks\">Use expandos to define dynamic beans </a>(similarly to JavaScript, you instantiate an <a href=\"http://groovy.codehaus.org/api/index.html\">Expando</a> and just add properties and closures as methods) - as described on the linked page, expandos and maps are usually enough to replace a mocking library</li>\r\n\t<li><a href=\"http://groovy.codehaus.org/Groovy+Mocks\">Build-in mocking</a></li>\r\n\t<li>With Groovy you can of course also use <a href=\"http://code.google.com/p/spock/\">Spock</a>, the excellent specification &amp; testing framework</li>\r\n</ul>\r\n<h2>Complications</h2>\r\n<ul>\r\n\t<li>Neither JUnitMax nor Infinitest (in IntelliJ) seem to support Groovy test cases</li>\r\n\t<li>You need a decent IDE such as IntelliJ IDEA</li>\r\n\t<li>If using Maven, you have to <a href=\"https://github.com/jakubholynet/static-jsfexpression-validator/blob/54802e77ac2225cf61664730e022ed261e73574c/pom.xml#L136\">explicitely configure the GMaven plugin</a> (esp. with a newer Groovy version)</li>\r\n\t<li>IntelliJ 10.5: Click &amp; alt+enter on a non-existing method to create it only works if the target type is a nested class within the test, not if it is a standalone Java class (so I just create my class there and when done TDDing I extract it into a top-level Java class)</li>\r\n</ul>\r\n<h2>Conclusion</h2>\r\nGroovy makes test writing much more productive and thus developers happy. I intend to use on all my open source projects and to try push it into our commercial projects too. You should give it a try too!\r\n<h3>Addendum</h3>\r\nI don't meen to say that you should start writing all your tests in Groovy (or Scala, JRuby, ..) right now and that whoever writes them in Java is a #!&amp;$ (insert a pejorative adjective of your choosing). If you are perfectly happy with Java, that's fine. If you don't like Groovy (Scala/JRuby/...) or have a negative experience with it, that's fine too. But if you feel after reading this that using Groovy/... might make you a more productive and happy developer then I humbly recommend that you try it and evaluate for yourself whether it is a positive change or not.<br><br>And yes, Kent Beck and Chuck Norris do write their tests in Java.<br><br>I apologize to all who feel irritated or offended by this post. That was not intended. Please eradicate it from your memory.\r\n<h3>Warning</h3>\r\nUnfortunately I have to say that despite all the benefits of Groovy I wouldn't recommand using it in Eclipse (3.7). The support there is very week, for example basic refactorings like creating a method/class used in the test but not really existing isn't supported. Contrary to that, IntelliJ is perfectly suitable for using Groovy. I haven't tried NetBeans.\r\n<h2>Additional Links</h2>\r\n<ul>\r\n\t<li><a href=\"http://www.docjar.com/docs/api/org/codehaus/groovy/runtime/DefaultGroovyMethods.html\">DefaultGroovyMethods</a>.java (<a href=\"http://grepcode.com/file/repo1.maven.org/maven2/org.codehaus.groovy/groovy-all/1.8.2/org/codehaus/groovy/runtime/DefaultGroovyMethods.java\">src</a>): defines the methods added to all objects</li>\r\n\t<li><a href=\"http://grepcode.com/file/repo1.maven.org/maven2/org.codehaus.groovy/groovy-all/1.8.2/org/codehaus/groovy/runtime/typehandling/DefaultTypeTransformation.java#DefaultTypeTransformation\">DefaultTypeTransformation</a>.java: methods used internally to convert between types and when using \"as aType\" - useful to know what <em>as</em> can convert</li>\r\n</ul>\r\n<div class=\"linkscent-iconblock\" style=\"float:none !important;border:0 solid #ff0000 !important;background:none repeat scroll center center transparent !important;width:auto !important;height:auto !important;display:block !important;overflow:visible !important;position:static !important;text-indent:0 !important;z-index:auto !important;max-width:none !important;min-width:0 !important;max-height:none !important;min-height:0 !important;left:auto !important;top:auto !important;bottom:auto !important;right:auto !important;line-height:16px !important;white-space:nowrap !important;margin:0!important;padding:0!important;\"><img class=\"linkscent-icon\" style=\"float:none !important;border:0 solid #ff0000 !important;width:16px !important;height:16px !important;display:none;overflow:visible !important;position:absolute !important;text-indent:0 !important;z-index:2147483635 !important;max-width:none !important;min-width:0 !important;max-height:none !important;min-height:0 !important;left:298px;top:123px;bottom:auto !important;right:auto !important;line-height:16px !important;white-space:nowrap !important;visibility:hidden;background:url('http://groovy.codehaus.org/favicon.ico') no-repeat scroll center center transparent !important;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" /><img class=\"linkscent-icon\" style=\"float:none !important;border:0 solid #ff0000 !important;background:none repeat scroll center center transparent;width:16px !important;height:16px !important;display:none;overflow:visible !important;position:absolute !important;text-indent:0 !important;z-index:2147483635 !important;max-width:none !important;min-width:0 !important;max-height:none !important;min-height:0 !important;left:316px;top:123px;bottom:auto !important;right:auto !important;line-height:16px !important;white-space:nowrap !important;visibility:hidden;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" /></div>",
  "excerpt": ""
 },
 {
  "title": "Inspect Your Webapp in a Live Environment Interactively with GroovyConsole",
  "published": "2011-09-27 19:10:44",
  "postType": "post",
  "slug": "/2011/09/27/inspect-your-webapp-in-a-live-environment-interactively-with-groovyconsole/",
  "status": "publish",
  "tags": [
   "groovy",
   "java",
   "productivity",
   "project",
   "troubleshooting"
  ],
  "categories": [
   "j2ee",
   "Languages",
   "Tools"
  ],
  "content": "Have you ever needed to check the state of your webapp's objects/Session/.. to find out why the hell something doesn't work or have you had to learn a weird 3rd party API that is only available on the server? Then you were doomed ... until the publication of GroovyConsole. <a href=\"http://sourceforge.net/apps/mediawiki/jeeutils/index.php?title=GroovyConsole_servlet_or_portlet\">JeeUtils GroovyConsole</a> provides a JSP page that let you execute any Groovy/Java code on the server side, with access to server-side objects like request/session etc.<br><br>Here is a screenshot of my recent troubleshooting session, where I needed to check the state of a session-scoped JSF Managed Bean:<br><br><!--more--><br><br><img class=\"alignnone\" style=\"border:1px solid black;\" title=\"GroovyConsole usage example\" src=\"https://lh5.googleusercontent.com/-mRxdoK2fHRg/ToIehv0gmWI/AAAAAAAACLA/y2jUa1j3LnQ/s800/GroovyConsole-1.0-1.jpg\" alt=\"\" width=\"800\" height=\"462\" /><br><br>(Notice that the screenshot uses heavily the beauties of Groovy though you could use the ordinary boring Java too :-).)<br><br>The application is self-explanatory (and pretty small) so just check it <a href=\"http://sourceforge.net/apps/mediawiki/jeeutils/index.php?title=GroovyConsole_servlet_or_portlet\">check it out</a> (and let me know what you think).<br><br>If you would prefer telnet access (and can have the port open) then you may be also interested in the <a href=\"http://groovy.codehaus.org/Embedding+a+Groovy+Console+in+a+Java+Server+Application\">Embedding Groovy article</a>.",
  "excerpt": ""
 },
 {
  "title": "Most interesting links of October",
  "published": "2011-10-31 21:59:13",
  "postType": "post",
  "slug": "/2011/10/31/most-interesting-links-of-october-2/",
  "status": "publish",
  "tags": [
   "clojure",
   "css",
   "facelets",
   "java",
   "javaEE",
   "JavaScript",
   "jsf",
   "lean",
   "monitoring",
   "ops",
   "spring"
  ],
  "categories": [
   "eclipse",
   "General",
   "j2ee",
   "Languages",
   "Testing",
   "Top links of month"
  ],
  "content": "<h2>Recommended Readings</h2>\r\n<ul>\r\n\t<li>Steve Yegge's <a href=\"http://steve-yegge.blogspot.com/2006/03/execution-in-kingdom-of-nouns.html\">Execution in the Kingdom of Nouns</a> - I guess you've already read this one but if not - it is a well-written and amusing post about why not having functions as first class citizens in Java causes developers to suffer. Highly recommended.</li>\r\n\t<li><a href=\"http://henk53.wordpress.com/2011/10/12/reply-to-comparing-java-web-frameworks/\">Reply to Comparing Java Web Frameworks</a> - a very nice and objective response to a recent blog summarizing a JavaOne presentation about the \"top 4\" web frameworks. The author argues that based on number of resources such as job trends, StackOverflow questions etc. (however data from each of them on its own is biased in a way) JSF is a very popular framework - and rightly so for even though JSF 1 sucked, JSF 2 is really good (and still improving). Interesting links too (such as <a href=\"http://jdevelopment.nl/jsf-22/\">What's new in JSF 2.2?</a>). Corresponds to my belief that GWT and JSF are some of the best frameworks available.</li>\r\n\t<li><a href=\"http://code.google.com/p/google-guice/wiki/UseNullable\">Using @Nullable</a> - use javax.annotation.Nullable with Guava's checkNotNull to fail fast when an unexpected null appeares in method arguments</li>\r\n\t<li><a href=\"http://www.slideshare.net/ertmanb/javaone-2011-migrating-spring-applications-to-java-ee-6\">JavaOne 2011: Migrating Spring Applications to Java EE 6</a> (slides) - nice (and visually attractive) comparison of JavaEE and Spring and proposal of a migration path. It's fun and worthy to see.</li>\r\n\t<li><a href=\"http://xunitpatterns.com/\">xUnitPatterns</a> - one of the elementary sources that anybody interested in testing should read through. Not only it explains all the basic concepts (<a href=\"http://xunitpatterns.com/Mock%20Object.html\">mocks</a>, <a href=\"http://xunitpatterns.com/Test%20Stub.html\">stubs</a>, <a href=\"http://xunitpatterns.com/Fake%20Object.html\">fakes</a>,...) but also many pitfalls to avoid (various <a href=\"http://xunitpatterns.com/Test%20Smells.html\">test smells</a> such as <a href=\"http://xunitpatterns.com/Fragile%20Test.html\">fragile tests</a> due to <em>Data Sensitivity</em>, <em>Behavior Sensitivity</em>, <em>Overspecified Software</em> [due to mocks] etc.), various strategies (such as for <a href=\"http://xunitpatterns.com/Fresh%20Fixture.html\">fixture setup</a>), and general <a href=\"http://xunitpatterns.com/Principles%20of%20Test%20Automation.html\">testing principles</a>. The materials on the site were turned into the book <a title=\"xUnit Test Patterns: Refactoring Test Code\" href=\"http://www.amazon.com/xUnit-Test-Patterns-Refactoring-Code/dp/0131495054/\">xUnit Test Patterns: Refactoring Test Code</a> (2007), which is more up-to-date and thus a better source.</li>\r\n\t<li>Eclipse tip: <a href=\"http://stackoverflow.com/questions/461255/things-possible-in-eclipse-that-arent-possible-in-intellij/462506#462506\">Automatically insert at correct position: Semicolon, Braces</a> - in \"while(|)\" type \"true {\" to get \"while(true) {|\" i.e. the '{' is moved to the end where it belongs, the same works for ';'</li>\r\n\t<li><a href=\"http://googletesting.blogspot.com/2011/10/google-test-analytics-now-in-open.html\">Google Test Analytics - Now in Open Source</a> - introduces Google's Attributes-Components-Capabilities (ACC) application intended to replace laborous and write&amp;forget test plans with something much more usable and quicker to set up, it's both a methodology for determining what needs to be tested and a tool for doing so and tracking the progress and high-risk areas (based not just on estimates but also actual data such as test coverage and bug count). The article is a good and brief introduction, you may also want to check a <a href=\"https://test-analytics.appspot.com/\">live hosted version</a> and a little more <a href=\"http://code.google.com/p/test-analytics/wiki/AccExplained\">detailed explanation</a> on the project's wiki.</li>\r\n\t<li><a href=\"http://www.ninthavenue.com.au/blog/c:foreach-vs-ui:repeat-in-facelets\">JSF and Facelets: build-time vs. render-time (component) tags</a> (2007) - avoid mixing them incorrectly</li>\r\n\t<li>StackOverflow: <a href=\"http://stackoverflow.com/questions/3623911/what-are-the-main-disadvantages-of-java-server-faces-2-0/3646940#3646940\">What are the main disadvantages of Java Server Faces 2.0?</a> Answer: The negative image of JSF comes from 1.x, JSF 2 is very good (and 2.2 is expected to be just perfect :-)). Nice summary and JSF history review.</li>\r\n\t<li>Ola Bini: <a href=\"http://olabini.com/blog/2011/10/javascript-in-the-small/\">JavaScript in the small</a> - best practices for projects using partly JavaScript - the module pattern (code in the body of an immediately executed function not to polute the global var namespace), handling module dependencies with st. like RequireJS, keeping JS out of HTML, functions generating functions for more readable code, use of many anonymous functions e.g. as a kind of named parameters, testing, open questions.</li>\r\n</ul>\r\n<h2>Talks</h2>\r\n<ul>\r\n\t<li>Kent Beck's JavaZone talk <a href=\"http://vimeo.com/28803277\">Software G Forces: The Effects of Acceleration</a> is absolutely worth the 1h time. Kent describes how the development process, practices and partly the whole organization have to change as you go from annual to monthly to weekly, daily, hourly deployments. What is a best practice for one of these speeds becomes an impediment for another one - so know where you are. You can get an older version of the <a href=\"http://www.iltam.org/files/G%20Forces.pdf\">slides</a> and there is also a <a href=\"http://www.shino.de/2010/11/04/software-g-forces-the-effects-of-acceleration/\">detailed summary</a> of the talk from another event.</li>\r\n\t<li>Rich Hickey: <a href=\"http://www.infoq.com/presentations/Simple-Made-Easy\">Simple Made Easy </a>- Rich, the author of Clojure, argues very well that we should primarily care for our tools, constructs and artifacts to be \"simple\", i.e. with minimal complexity, rather than \"easy\" i.e. not far from our current understanding and skill set. Simple means minimal interleaving - one concept, one task, one role, minimal mixing of who, what, how, when, where, why. While easy tools may make us start faster, only simplicity will make it possible to keep going fast because (growing) comlexity is the main cause of slowness.  And simplicity is a choice - we can create the same programs we do today with the tools of complexity with drastically simpler tools. Rich of course explains what, according to him, are complex tools and their simple(r) alternatives - see below. The start of the 1h talk is little slow but it is worth the time. I agree with him that we should much more thing about the simplicity/complexity of the things we use and create rather than easiness (think ORM).\r\nRead also <a href=\"http://blog.8thlight.com/uncle-bob/2011/10/20/Simple-Hickey.html\">Uncle Bob's affirmative reaction</a> (\"All too often we do what’s easy, at the expense of what’s simple. And so we make a mess. [...] doing what is simple as opposed to what is easy is one of the <em>defining</em> characteristics of a software craftsman.\").</li>\r\n</ul>\r\n<h3>Random Notes from Rich's Simple Made Easy Talk:</h3>\r\nThere are also <a href=\"https://github.com/AlexBaranosky/Strange-Loop-2011-Notes/blob/master/SImple%20Made%20Easy%20Notes.txt\">better notes</a> by Alex Baranosky and you may want to check a <a href=\"http://www.reddit.com/r/programming/comments/lirke/simple_made_easy_by_rich_hickey_video/\">follow-up discussion</a> with some Rich's answers.<br><br>The complex vs. simple toolkit (around 0:31):<br><br>COMPLEXITY                             SIMPLICITY\r\nState, objects                            Values\r\nMethods                                   Functions, namespaces\r\nvars                                          Managed refs\r\nInheritance, switch, matching  Polymorphism a la carte\r\nSyntax                                      Data\r\nImperative loops, fold              Set functions\r\nActors                                      Queues\r\nORM                                         Declarative data manipulation\r\nConditionals                             Rules\r\nInconsistency                            Consistency<br><br>What each of the complexity constructs mixes (complects) together<br><br>CONSTRUCT                        COMPLECTS (MIXES)\r\nState, objects - everything that touches it (for state complects time and value)\r\nMethods - function and state, namespaces (2 classes, same m. name)\r\nSyntax - Meaning, order\r\nInheritance - Types (ancestors, child)\r\nSwitch/matching - Multiple who/what pairs (1.decide who, 2.do what ?)\r\nvar(iable)s - Value, time\r\nImperative loops, fold - what/how (fold - order)\r\nActors - what/who\r\nORM - OMG :-)\r\nConditionals - Why, rest of program (rules what program does are intertw. with the structure and order of the program, distributed all over it)<br><br>HE SIMPLICITY TOOLKIT (around 0:44)\r\nCONSTRUCT            GET IT IVA...\r\nValues - Final, persistent collections\r\nFunctions - a.k.a. stateless methods\r\nNamespaces - Language support\r\nData - Maps, arrays, sets, XML, JSON etc.\r\nPolymorphism a la carte - Protocols, Haskell type classes\r\nManaged refs - Clojure/Haskell refs (compose time and value , not mix)\r\nSet functions - Libraries\r\nQueues - Libraries\r\nDeclarative data manipulation - SQL/LINQ/Datalog\r\nRules - Libraries, Prolog\r\nConsistency - Transactions, values<br><br>True abstraction isn't hiding complexity but <em>drawing things awa</em>y - along one of the dimensions of who, what, when, where, why [policy&amp;rules of the app.], how.\r\nAbstraction =&gt; there are things I don't need - and don't want - to know.\r\nWhy - do explore rules and declarative logic systems.\r\nWhen, where - when obj. A communicates with obj. B. =&gt; put a queue in between them so that A doesn't need to know where B is; you should use Qs extensively.\r\n<h2>Links to Keep</h2>\r\n<ul>\r\n\t<li><a href=\"http://webexpedition18.com/articles/useful-css-snippets/\">Incredibly Useful CSS Snippets</a> -  \"a list of CSS snippets that will help you minimize headaches, frustration and save your time while writing css\" - few float resets, targetting specific browsers &amp; browser hacks, cross-rowser transparency/min height/drop shadow, Google Font API, link styled by file type,</li>\r\n</ul>\r\nDevOps: Tools and libraries for system monitoring and (time series) data plotting\r\n<ul>\r\n\t<li><a href=\"http://www.hyperic.com/products/sigar\">Hyperic SIGAR API</a> - open-source library that unifies collection of system-related metrics such as memory, CPU load, processes, file system metrics across most common operating systems</li>\r\n\t<li><a href=\"http://code.google.com/p/rrd4j/\">rrd4j</a> - Java clone of the famous <a href=\"http://oss.oetiker.ch/rrdtool/\" rel=\"nofollow\">RRDTool</a>, which stores, aggregates and plots time-series data (RRD = round-robin database, i.e. keeps only a given number of samples and thus has a fixed size)</li>\r\n\t<li><a href=\"http://jrds.fr/\">JRDS</a> \"is performance collector, much like cacti or munins\", uses rrd4j. The documentation could be better and it seems to be just a one man project but it might be interesting to look at it.</li>\r\n</ul>\r\n<h2>Clojure Corner</h2>\r\n<ul>\r\n\t<li>Alex Miller: <a href=\"http://tech.puredanger.com/2011/10/20/real-world-clojure\">Real world Clojure</a> - a summary of experiences with using Clojure in enterprise data integration and analytics products at Revelytix, since early 2011 with a team of 5-10 devs. Some observations: Clojure code is 1-2 order of magnitude smaller than Java. It might take more time to learn than Java but not much. Clojure tooling is acceptable, Emacs is still the best. Debugging tools are unsurprisingly quite inferior to those for Java. Java profiling tools work but it may be hard to interpret the results. \"[..]  I’ve come to appreciate the data-centric approach to building software.\" Performance has been generally good so far.</li>\r\n\t<li>Article series <a href=\"http://corfield.org/blog/post.cfm/real-world-clojure-prelude\">Real World Clojure at World Singles</a> - the series focuses on various aspects of using Clojure and how it was used to solve particular problems at a large dating site that starting to migrate to it in 2010. Very interesting. F. ex. XML generation, multi-environment configuration, tooling (\"If Eclipse is your drug of choice, CCW [Counter ClockWise] will be a good way to work with Clojure.\", \"Clojure tooling is still pretty young [..]  - but given how much simpler Clojure is than most languages, you may not miss various features as much as you might expect!\")</li>\r\n\t<li><a href=\"http://stackoverflow.com/questions/2578837/comparing-clojure-books\">StackOverflow: Comparing Clojure books</a> - Programming Clojure, Clojure in Action, The Joy of Clojure, Practical Clojure - which one to pick? A pretty good comparison.</li>\r\n\t<li><a href=\"http://www.colourcoding.net/blog/archive/2011/10/25/clojure-is-a-get-stuff-done-language.aspx\">Clojure is a Get Stuff Done Language</a> - experience report - \"For all that people think of Clojure as a “hard” “propeller-head” language, it’s actually designed right from the start not for intellectual purity, but developer productivity.\"</li>\r\n</ul>",
  "excerpt": ""
 },
 {
  "title": "Note to Self: Running GroovyConsole with a Maven Project''s Classpath",
  "published": "2011-10-02 16:07:26",
  "postType": "post",
  "slug": "/2011/10/02/note-to-self-running-groovyconsole-with-a-maven-projects-classpath/",
  "status": "publish",
  "tags": [
   "groovy",
   "Maven",
   "productivity"
  ],
  "categories": [
   "Tools"
  ],
  "content": "It's pretty useful to have the ability to eperiment interactively with some API using the (desktop) <a href=\"http://groovy.codehaus.org/Groovy+Console\">Groovy Console</a>. If the API is in a Maven project, just add dependency on Groovy to your pom.xml:<br><br><pre><code>\r\n&lt;dependency&gt;\r\n    &lt;groupId&gt;org.codehaus.groovy&lt;/groupId&gt;\r\n    &lt;artifactId&gt;groovy-all&lt;/artifactId&gt;\r\n    &lt;version&gt;1.8.2&lt;/version&gt;\r\n&lt;/dependency&gt;\r\n</code></pre><br><br>And execute the console from the project's folder using the <a href=\"http://mojo.codehaus.org/exec-maven-plugin/java-mojo.html\">exec plugin</a>:<br><br><pre><code>\r\nmvn exec:java -Dexec.mainClass=&quot;groovy.ui.Console&quot;\r\n</code></pre><br><br>Enjoy.",
  "excerpt": ""
 },
 {
  "title": "Tools for Renaming the Package of a Dependency with Maven",
  "published": "2011-10-06 07:19:26",
  "postType": "post",
  "slug": "/2011/10/06/tools-for-renaming-the-package-of-a-dependency-with-maven/",
  "status": "publish",
  "tags": [
   "java",
   "Maven"
  ],
  "categories": [
   "Languages",
   "Tools"
  ],
  "content": "If you need to rename the Java package of a 3rd party library, e.g. to include it directly in your project while avoiding possible conflicts, you can use one of the following Maven plugins (and they may be more) in the package lifecycle phase:\r\n<ol>\r\n\t<li><a href=\"http://mvnplugins.fusesource.org/maven/1.14-SNAPSHOT/maven-uberize-plugin/index.html\">Uberize plugin</a> (latest - org.fusesource.mvnplugins:maven-uberize-plugin:1.20) - originally inspired by the Shade plugin, intended to overcome some of its limitations. Intended primarily to merge your code and dependencies into one jar.</li>\r\n\t<li><a href=\"http://maven.apache.org/plugins/maven-shade-plugin/\">Shade plugin</a></li>\r\n\t<li><a href=\"http://java.net/projects/package-rename-task\">package-rename-task</a>, Ant-based Maven plugin - I'm not sure whether this is further maintained</li>\r\n</ol>",
  "excerpt": ""
 },
 {
  "title": "Hacking A Maven Dependency with Javassist to Fix It",
  "published": "2011-10-19 15:16:06",
  "postType": "post",
  "slug": "/2011/10/19/hacking-a-maven-dependency-with-javassist-to-fix-it/",
  "status": "publish",
  "tags": [
   "AOP",
   "java",
   "Javassist",
   "Maven"
  ],
  "categories": [
   "Languages",
   "Tools"
  ],
  "content": "Have you ever wondered what to do when needing \"just a small change\" to a third-part library your project depended on? This post describes how to use Maven and Javassist to take a dependency of your project, instrument it to modify its behavior, re-pack it, and release it as an artifact with a different name (so that you me depend on my-customized-lib instead of on lib).<br><br>The process is as follows:\r\n<ol>\r\n\t<li>Phase process-sources - maven-dependency-plugin unpacks the dependency to classes/</li>\r\n\t<li>Phase compile (implicit) - compile the bytecode manipulation code</li>\r\n\t<li>Phase process-classes - exec-maven-plugin executes the compiled Javassist instrumenter to modify the unpacked classes</li>\r\n\t<li>Phase test - run tests on the instrumented code</li>\r\n\t<li>Phase package - let maven-jar re-package the instrumented classes, excluding the instrumenter itself</li>\r\n</ol>\r\n<!--more-->\r\n<h2>Why: The Case Introduction</h2>\r\nModifying binaries of third-party libraries is certainly an ugly thing but sometimes it's the most feasible way to satisfy a need. So it was with my <a title=\"Homepage of the build-time JSF EL expression validator\" href=\"https://github.com/jakubholynet/static-jsfexpression-validator\">JSF EL Validator</a> that reuses existing EL implementations with plugged-in custom variable and property resolvers (returning fake values of the expected types because real objects aren't available at the validation time). The problem was that the EL specification requires <a href=\"http://en.wikipedia.org/wiki/Short-circuit_evaluation\">short-circuit evaluation</a> of ?: branches and of /boolean expressions while to be able to validate the expressions I needed all parts of them to be evaluated. The only feasible solution proved to be the modification of the EL implementations to evaluate all children of a boolean/choice node.\r\n<h2>How: Javassist, Dependency and Exec Plugins</h2>\r\nI've used common Maven plugins to fetch and unpack the dependency, to execute the instrumentation code, and to pack the classes again and release them as an artifact with a different name. The instrumentation is implemented with a little of Java code leveraging Javassist to perform the actual modification on the unpacked class files.<br><br>The explanation will follow the Maven lifecycle phases the individual operations are bound to.\r\n<h3>0. Set-up a Project to Do the Instrumentation</h3>\r\nFirst we create a new project (or more likely a Maven module of the main project) to fetch, modify, pack, and release the dependency we need to tweak. The important thing in the project is only the POM that binds all the plugins and phases together and the Javassist code that performs the instrumentation.<br><br>An example is the <a href=\"https://github.com/jakubholynet/static-jsfexpression-validator/blob/77039388d6bcee43006594674d4ca8f5576fa982/jasper-el-customized-jsf12/pom.xml\">jasper-el-customized-jsf12</a>, which modifies org.apache.tomcat:jasper-el and releases it as jasper-el-customized-jsf12. Notice that I have added the jasper-el as an explicit dependency to the project - this is to make my IDE aware of it and to make it posssible for Maven to compile my instrumentation helper class (which accesses jasper-el classes). In theory it shouldn't be necessary as the classes will be made available in the process-sources phase but it would require some tweaking of the compiler's and IDE's classpaths though it would be a cleaner approach (for I would avoid having the dependency twice on the classpath: once explicitly as a .jar artifact and once as unpacked classes).\r\n<h3>1. Phase process-sources - maven-dependency-plugin unpacks the dependency</h3>\r\n<p>\r\nFirst we need to fetch and unpack the dependency so that Javassist can operate on it. The easiest thing is to unpack it into target/classes/ so that the tests and the JAR plugin have access to it without any configuration of their classpath.\r\n</p><p>\r\n(Notice that the instrumentation code could be compiled without dependening on the artifact being modified as the code to insert/modified can be represented just as String.)\r\n</p>\r\nThis is how to do it:<br><br><pre><code>\r\n&lt;plugin&gt;\r\n  &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;\r\n  &lt;artifactId&gt;maven-dependency-plugin&lt;/artifactId&gt;\r\n  &lt;version&gt;2.3&lt;/version&gt;\r\n  &lt;executions&gt;\r\n    &lt;execution&gt;\r\n      &lt;id&gt;unpack&lt;/id&gt;\r\n      &lt;goals&gt;\r\n        &lt;goal&gt;unpack&lt;/goal&gt;\r\n      &lt;/goals&gt;\r\n      &lt;configuration&gt;\r\n        &lt;artifactItems&gt;\r\n          &lt;artifactItem&gt;\r\n            &lt;groupId&gt;org.apache.tomcat&lt;/groupId&gt;\r\n            &lt;artifactId&gt;tomcat-jasper-el&lt;/artifactId&gt;\r\n            &lt;version&gt;${jasper.jsf20.version}&lt;/version&gt;\r\n          &lt;/artifactItem&gt;\r\n        &lt;/artifactItems&gt;\r\n        &lt;excludes&gt;META-INF/**&lt;/excludes&gt;\r\n        &lt;outputDirectory&gt;${project.build.outputDirectory}&lt;/outputDirectory&gt;\r\n        &lt;overWriteReleases&gt;true&lt;/overWriteReleases&gt;\r\n      &lt;/configuration&gt;\r\n    &lt;/execution&gt;\r\n  &lt;/executions&gt;\r\n&lt;/plugin&gt;\r\n</code></pre>\r\n<h3>2. Phase compile (implicit) - compile the bytecode manipulation code</h3>\r\nNo configuration necessary here, mvn compile will compile the Javassist instrumentation code as it would do with any other Java code.<br><br>First you of course need to write the instrumentation code. I've decided to use <a href=\"http://www.csg.is.titech.ac.jp/%7Echiba/javassist/\">Javassist</a> because it doesn't introduce any new runtime dependencies to the modified artifact. (Read my recent <a href=\"/2011/09/07/practical-introduction-into-code-injection-with-aspectj-javassist-and-java-proxy/#JavaZoneProposal-AOP-TheIndependentJavassist\">introduction into Javassist</a> if you feel the need.)<br><br>See <a href=\"https://github.com/jakubholynet/static-jsfexpression-validator/blob/77039388d6bcee43006594674d4ca8f5576fa982/jasper-el-customized-jsf12/src/main/java/net/jakubholy/jeeutils/jsfelcheck/jasperelcustomizer/instrumenter/JavassistTransformer.java\">JavassistTransformer.java</a> for details of the implementation, the code is rather simple and straightforward. Few commnets:\r\n<ul>\r\n\t<li>JavassistTransformer has a main() so it can be run by the exec plugin</li>\r\n\t<li>Javassist's ClassPool is instructed to search for the classes to instrument in the target/classes folder</li>\r\n\t<li>We tell Javassist what classes it should find and which of their methods it should modify (via insertBefore) and then we save the modified classes.</li>\r\n\t<li>I've minimized the code to inject in the transformer where it can only be represented as a string, and just insert a delegation of the processing to a helper class, <a href=\"https://github.com/jakubholynet/static-jsfexpression-validator/blob/77039388d6bcee43006594674d4ca8f5576fa982/jasper-el-customized-jsf12/src/main/java/net/jakubholy/jeeutils/jsfelcheck/jasperelcustomizer/GetValueFix.java\">GetValueFix.java</a>, which is a regular Java code using the dependency's classes and compiled by Javac and added to the modified jar.</li>\r\n</ul>\r\n<h3>3. Phase process-classes - exec-maven-plugin executes the compiled Javassist instrumenter to modify the unpacked classes</h3>\r\n<p>\r\nThe compiled instrumentation code has to be executed - that's why it has a main method - to actually modify the unpacked classes. That's easily achieved with the exec plugin:\r\n</p>\r\n<pre><code>\r\n&lt;plugin&gt;\r\n  &lt;groupId&gt;org.codehaus.mojo&lt;/groupId&gt;\r\n  &lt;artifactId&gt;exec-maven-plugin&lt;/artifactId&gt;\r\n  &lt;version&gt;1.2.1&lt;/version&gt;\r\n  &lt;executions&gt;\r\n    &lt;execution&gt;\r\n      &lt;goals&gt;\r\n        &lt;goal&gt;java&lt;/goal&gt;\r\n      &lt;/goals&gt;\r\n      &lt;phase&gt;process-classes&lt;/phase&gt;\r\n    &lt;/execution&gt;\r\n  &lt;/executions&gt;\r\n  &lt;configuration&gt;\r\n    &lt;mainClass&gt;net.jakubholy.jeeutils.jsfelcheck.jasperelcustomizer.instrumenter.JavassistTransformer&lt;/mainClass&gt;\r\n    &lt;arguments&gt;\r\n      &lt;argument&gt;${project.build.outputDirectory}&lt;/argument&gt;\r\n    &lt;/arguments&gt;\r\n    &lt;includePluginDependencies&gt;true&lt;/includePluginDependencies&gt;\r\n  &lt;/configuration&gt;\r\n  &lt;dependencies&gt;\r\n    &lt;dependency&gt;\r\n      &lt;groupId&gt;org.javassist&lt;/groupId&gt;\r\n      &lt;artifactId&gt;javassist&lt;/artifactId&gt;\r\n      &lt;version&gt;${javassist.version}&lt;/version&gt;\r\n    &lt;/dependency&gt;\r\n  &lt;/dependencies&gt;\r\n&lt;/plugin&gt;\r\n</code></pre><br><br>(I have to specify Javassist as an explicit dependency because its scope as a project dependency is \"provided\" and thus the exec plugin ignores it.)\r\n<h3>4. Phase test - run tests on the instrumented code</h3>\r\nYou wouldn't expect me not to test my code, right?<br><br>Testing doesn't require any special configuration as the instrumented classes to test are already in target/classes. If we wanted to have them somewhere else, we would just provide the surefire plugin's configuration with an additionalClasspathElements/additionalClasspathElement.<br><br>(You will notice that I have actually done that in the POM even though it is unnecessary given my direct usage of target/classes.)<br><br>BTW, if you wonder how the tests written in Groovy get compiled and executed, notice that I've <a href=\"https://github.com/jakubholynet/static-jsfexpression-validator/blob/master/pom.xml#L136\">configured that in the parent POM</a>. (Which is the only piece of configuration there with any impact on this module.)\r\n<h3>5. Phase package - let maven-jar re-package the instrumented classes</h3>\r\nAgain we could leave the JAR plugin with its default configuration as everything necessary is under target/classes but I prefer to specify the <a href=\"https://github.com/jakubholynet/static-jsfexpression-validator/blob/77039388d6bcee43006594674d4ca8f5576fa982/jasper-el-customized-jsf12/pom.xml#L127\">classesDirectory explicitly</a> and to exclude the instrumentation code (while including the GetValueFix helper).\r\n<h3>The POM</h3>\r\nYou may want to <a href=\"https://github.com/jakubholynet/static-jsfexpression-validator/blob/77039388d6bcee43006594674d4ca8f5576fa982/jasper-el-customized-jsf12/pom.xml\">check the complete pom.xml</a> at GitHub.\r\n<h2>Alternative: Renaming the Package</h2>\r\nIf you wanted to change the root package of the modified dependency you could do so with one of the <a href=\"/2011/10/06/tools-for-renaming-the-package-of-a-dependency-with-maven/\">package renamers for Maven</a>, f.ex. the <a href=\"http://mvnplugins.fusesource.org/maven/1.14-SNAPSHOT/maven-uberize-plugin/index.html\">Uberize plugin</a> but then you would need to hook into the processing it does to actually perform the instrumentation, e.g. by implementing a custom Uberize <a href=\"http://grepcode.com/file/repo1.maven.org/maven2/org.fusesource.mvnplugins/maven-uberize-plugin/1.19/org/fusesource/mvnplugins/uberize/Transformer.java?av=f\">Transformer</a> (which would likely need to be distributed as an independent artifcat of its own for the plugin to be able to use it).\r\n<h2>Summary</h2>\r\nI've shown an approach for configuring a set of Maven plugins to unpack, instrument, and re-pack a dependency and the code to perform the actual instrumentation using Javassist. The approach works but it certainly could be improved, for example I would prefer to unpack the classes of the dependency into a folder of their own rather than into target/classes and I'd also prefer not to need to specify the dependency explicitly in the dependencies section as this creates a duplication of its original classes (from the dependency's artifact jar) and modified (locally unpacked) classes on the classpath.",
  "excerpt": ""
 },
 {
  "title": "Never Mix Public and Private Unit Tests! (Decoupling Tests from Implementation Details)",
  "published": "2011-10-20 12:15:36",
  "postType": "post",
  "slug": "/2011/10/20/never-mix-public-and-private-unit-tests/",
  "status": "publish",
  "tags": [
   "opinion",
   "tdd",
   "Testing"
  ],
  "categories": [
   "General",
   "Testing"
  ],
  "content": "It seems to me that developers often do not really distinguish between the various types of unit tests they should be writing and thus mix things that should not be mixed, leading to difficult to maintain and hard to evolve test code. The dimension of unit test categorization I feel especially important here is the level of coupling to the unit under test and its internals. We should be constantly aware of what kind of test we are writing, what we are trying to achieve with the test, and thus which means are justifiable or, on the contrary, not suitable for that kind of test. In other words, we should always know whether we're writing a <em>Public Test</em> or a <em>Private Test</em> and never ever mix the two. Why not and what actually are these two kinds of tests? Read on! (And if you agree or disagree, don't hesitate to share your opinion.)\r\n<!--more-->\r\n<h2>Motivation</h2>\r\nWhen writing unit tests, we would like to have them as <em>focused</em> as possible so that they are easier to write (i.e. less context to set up, more direct verification), easier to understand (thanks to going directly to the point), and when then fail, it's easier to pinpoint the exact source of the failure. That means that we would like to test individual methods directly and without having to deal too much with other parts of the class. As methods usually depend on the state of their object we would often need to configure it, preferably in the simplest and most direct way possible, likely just setting the object's fields directly. The price we pay for this focus and effectiveness is tight coupling and thus more complicated refactoring.<br><br>At the same time we would like to keep our test as <em>independent</em> as possible from the actual implementation so that they are easier to maintain over a long period of time while the implementation keeps evolving w.r.t. changing business requirements.<br><br>How to deal with these two conflicting needs for focus and independence? I suggest that the answer is to use different types of unit tests for each of these concerns.\r\n<h2>Public Unit Test (unit = class)</h2>\r\nThe primarily intent of a Public Unit Test is to verify the contract between the class and the rest of the system. This contract expresses the <em>raison d'être</em> of the class, its purpose in the system. And the reason why a class exists together with its core responsibilities determined by it are very unlikely to change - and if they do then the best solution is to delete the class and create a new one, aligned with the new purpose, for no class can survive such a change to something so essential for its design.<br><br>A test that verifies these core responsibilities should be as decoupled as possible from their actual implementation so that the class can freely evolve within the bounds of its purpose and contract. The test should be a specification of what the class does without any interest in how it achieves it. Thus it can stay relevant throughout the whole life of the class while the internals of the implementation keep evolving.<br><br>It is essential to have these tests because they assure us that the system is still working as intended even as it undergoes refactorings and its functionality is extended and adjusted.<br><br>To implement a Public Unit Test we should use as much as possible only the public methods of the class because they represent its contract.<br><br>The disadvantage of Public Tests is that they may be too high-level (for they only access the public interface) and thus not suitable for test-driving the implementation. It's often much easier to test smaller units such as individual methods in isolation than a whole object. That's why we also need Private/Helper Unit Tests.<br><br>Public Unit Tests are also known as <a href=\"http://xunitpatterns.com/round%20trip%20test.html\">round trip tests</a> and they embody the testing principle <a href=\"http://xunitpatterns.com/Principles%20of%20Test%20Automation.html#Use%20the%20Front%20Door%20First\">Use the Front Door First</a>.<br><br>To make it feasible to implement such a decoupled and change-resistant test, multiple well-known principles should be followed, such as Separation of Concerns, publication of only the smallest reasonable interface (=&gt; fewer changes), data encapsulation (e.g. a parameter object is more resilient than a bunch of primitive parameters). It should also be mentioned that contrary to what I might seem to imply the test isn't completely static. Small, non-destructive changes to the contract that do not change its semantics (mostly changes to its representation's details, for example how we represent input parameters) and corresponding small changes to the test are acceptable, especially if it is something that an automated refactoring can do.<br><br>Example:<br><br><pre><code>\r\npublic class ArrayBasedStackTest {\r\n   ...\r\n   @Test public void pop_returns_pushed_in_reverse_order() {\r\n      stack.push(1);\r\n      stack.push(2);<br><br>      assertEquals(2, stack.pop());\r\n      assertEquals(1, stack.pop());\r\n   }\r\n}\r\n</code></pre><br><br>This is a typical public test - it uses only public methods to set up the state. When it fails we often cannot guess why, i.e. which of the three or four calls have not done what we expected and what exactly went wrong? On the other hand if we replace the internal array used to implement the stack with a linked list then it will have absolutely no impact on this test and it will be able to verify it equally well.\r\n<h2>Private (Helper) Unit Test (unit = method)</h2>\r\nThe primary purpose of a Private (or Helper) Unit Test is to verify small pieces of behavior of a class in isolation from the rest of the class to help the programmer gain confidence that her implementation is correct with respect to her intentions. Those pieces of code are usually not visible or really important to the outside users of the code, they are private details of the implementation - that's why I call the tests that verify them Private Tests. The main benefit of these tests is that they are tightly focused and thus easier to write and understand and thus also a very good fit for TDD.<br><br>The drawback of Private Unit Tests is that the need to isolate the piece of code being tested usually requires an intimate knowledge of the internals of the class and the pre-configuration and post-verification of its internal state. Thus they are very brittle and tend to break even for a moderate change of the implementation, even if the change is a refactoring that preservers the public contract. So if you need to do some non-trivial refactoring of the implementation then these tests not only fail to serve as the safety net that test should provide (failing even though the class still fulfills its contract) but also complicate the refactoring by requiring to be updated accordingly afterwards.<br><br>If you keep Public and Private Tests separated then you are free to keep the Private Tests only as long as their value outweighs their cost and to throw them away once they become too much of a burden. You can afford deleting them because you know that the contract of the class - which is the thing that really matters in the long run - is covered by the Public Tests. Depending on your situation, you may throw a Private Test away as soon as the functionality in question is developed (in which case they only serve you to drive the development [even Kent Beck <a href=\"http://pragprog.com/screencasts/v-kbtdd/test-driven-development\">does it sometimes - see episode 3</a>]) or you can keep it until the first larger refactoring that changes the internals of the class in a way the tightly coupled test can't survive.<br><br>If you are reluctant to delete tests then you should realize that tests are not only an asset but also a liability because they need to be created and maintained. And the economics of software development forces us to remove things whose long-term value is lower than their cost.<br><br>Example:<br><br><pre><code>\r\npublic class ArrayBasedStackPrivateTest {\r\n   ...\r\n   @Test public void test_growIfNecessary() {\r\n      ArrayBasedStack zeroSizedStack = new ArrayBasedStack(0);\r\n      // it has the package-private fields int[] content; int topIdx = 0<br><br>      int originalStackSize = zeroSizedStack.content.length;\r\n      assertEquals(0, originalStackSize);\r\n      assertEquals(0, zeroSizedStack.topIdx);<br><br>      zeroSizedStack.growIfNecessary();<br><br>      assertTrue(&quot;The stack hasn't grown; size: &quot; + originalStackSize\r\n            , zeroSizedStack.content.length &gt; originalStackSize);\r\n   }\r\n}\r\n</code></pre><br><br>This private test helps me to verify a \"private\" method of the stack without having to deal with its pop(). It doesn't need to set up any private state (as the constructor does it for me) but it uses its privileged access to check the \"private\" properties representing the state thus providing me with much better insight into a potential failure. (I've actually first written a public unit test but it failed for I was growing the stack by doubling its size - which doesn't really work with zero. Already writing assertions in this private test helped me to realize that.) The point with public vs. private unit test and access to internal state may be not so compelling in this simple case but you can certainly think of a real case from your experience where it would be more evident.\r\n<h2>Note on Terminology</h2>\r\n<em>Summary: contract &lt;=&gt; public, implementation details &lt;=&gt; private, unit &lt;=&gt; isolated\r\n</em><br><br>The terms \"public\" and \"private\" I use here reflect the conceptual distinction between the contract a class has with the rest of the system - which is thus its \"public\" API - and the details of its implementation, which are \"private\" to the class in sense of the good old OOP's encapsulation principle. They are not directly related to the keywords \"public\" and \"private\" as used in Java though the contract is usually represented by public methods while implementation details are often hidden in private methods (though to make them testable it's usually best to make them package-private unless you <a href=\"/2011/10/18/only-a-masochist-would-write-unit-tests-in-java-be-smarter-use-groovy-or-jruby-or-st-else-similar/\">write tests in Groovy</a>).<br><br>The term \"unit\" is used rather freely. According to a recent tweet by Kent Beck, you can recognize a unit test by the fact that if it fails then you know exactly what is the problem and which part of the code, perhaps even which line, to check. If a test fails and you can't tell why then it isn't a unit test. It follows that a lot of method-level tests are not really unit test in this strict sense and especially Public Tests tend to be actually low-level integration tests where the unit of integration is the class (and its non-public methods). The size of the \"unit\" being tested is another of the test categorization dimensions. In a less strict sense we could say that a test is a kind of unit test (of a particular level) if it checks the unit in isolation. In this isolation-based sense I've drawn an approximate equality between a Public Test and a class (for its purpose is to verify the contract of the class) and a Private Test and a method. A test method in a Public Test will usually call one or more public methods on its target object and occasionally on some other objects to verify its <a href=\"http://xunitpatterns.com/indirect%20output.html\">indirect (yet \"public\") outputs</a>. A test method in a Private Test will use \"private\" fields and setters to configure the target object, execute the non-public method under test, and check its output and perhaps some (public or non-public) fields/getters.\r\n<h2>Summary</h2>\r\nMy motivation for this article was my work on a system where the past developers lacked the distinction between private and public tests and mixed their code together thus negating completely the main benefit of Public Unit Tests, that is their resilience to changes in the tested class. Even correct refactorings had the potential to cause many tests to fail due to their overdependency on implementation details (so-called <a href=\"http://xunitpatterns.com/Fragile%20Test.html#Overcoupled%20Software\">overcoupling</a>).<br><br>That's why I wanted to make a clear distinction between resilient Public Tests that support software evolution and throw-away Private Tests that support developers in writing correct implementations.<br><br>The Public Test and Private Test are ideal opposite ends of a scale. In reality you will always be somewhere between the two - but you should be always aware where you're trying to be and make all the reasonable effort to get closer to it. If your Public Tests cannot be implemented without relying on implementation details, try to follow the OOP principle of encapsulating that what is likely to change so that when it changes, there will be only one place to update.<br><br>If you should remember only a single sentence from this article, it should be this: <em>You should primarily strive for having loosely coupled Public Tests verifying the core contracts of your classes to keep your system evolvable.</em><br><br><strong>Update</strong> 8/11: A recent <a href=\"http://java.dzone.com/articles/never-mix-public-and-private#comment-58177\">comment at DZone</a> shows that I haven't made myself clear enough. Therefore I'd like to stress that Public and Private Unit Tests are my own terms and have nothing to do with white box ~ unit and black box ~ integration testing. Both Private and Public U.T. test a single class in isolation - they only differ in how dependent they are on the inner organization of the class. Public U.T. check public methods only and are thus usually more coarse-grained, Private U.T. test non-public methods, usually as much in isolation as possible even if that requires knowing and modifying internal, private state of the object under test.\r\n<h2>Resources</h2>\r\n<ol>\r\n\t<li>Book <a title=\"xUnit Test Patterns: Refactoring Test Code\" href=\"http://www.amazon.com/xUnit-Test-Patterns-Refactoring-Code/dp/0131495054/\">xUnit Test Patterns: Refactoring Test Code</a> (2007)</li>\r\n</ol>",
  "excerpt": ""
 },
 {
  "title": "Spring: Make an Externally Created Object Available to Beans in applicationContext.xml",
  "published": "2011-10-11 09:54:19",
  "postType": "post",
  "slug": "/2011/10/11/spring-make-an-externally-created-object-available-to-beans-in-applicationcontext-xml/",
  "status": "publish",
  "tags": [
   "java",
   "spring"
  ],
  "categories": [
   "Languages"
  ],
  "content": "If your Spring beans need access to an object that is not created by Spring itself, you can \"inject\" it into the context by using a static parent context and registering the object with it. Beans can then reference it just as if it was defined in the application context file.\r\n<h2>Java: Configure ApplicationContext with an Injected Bean</h2>\r\n<pre><code>\r\nimport org.springframework.context.ApplicationContext;\r\nimport org.springframework.context.support.FileSystemXmlApplicationContext;\r\nimport org.springframework.context.support.GenericApplicationContext;\r\nimport org.springframework.context.support.StaticApplicationContext;<br><br>Object externalyDefinedBean = ...;\r\nGenericApplicationContext parentContext = new StaticApplicationContext();\r\nparentContext.getBeanFactory().registerSingleton(&quot;injectedBean&quot;, externalyDefinedBean);\r\nparentContext.refresh();   // seems to be required sometimes<br><br>ApplicationContext context = new FileSystemXmlApplicationContext(springConfigs, parentContext);\r\n</code></pre>\r\n<h2>Xml: Make Use of It</h2>\r\n<pre><code>\r\n&lt;bean id=&quot;springBean&quot; class=&quot;your.SpringBeanType&quot;&gt;\r\n   &lt;!-- Note: The injectedBean is defined outside of Spring config --&gt;\r\n   &lt;property name=&quot;someProperty&quot; ref=&quot;injectedBean&quot; /&gt;\r\n&lt;/bean&gt;\r\n</code></pre><br><br>Voila!",
  "excerpt": ""
 },
 {
  "title": "hasProperty, the Hidden Gem of Hamcrest (and assertThat)",
  "published": "2011-10-15 17:13:29",
  "postType": "post",
  "slug": "/2011/10/15/hasproperty-the-hidden-gem-of-hamcrest-and-assertthat/",
  "status": "publish",
  "tags": [
   "hamcrest",
   "java",
   "junit"
  ],
  "categories": [
   "Languages",
   "Testing"
  ],
  "content": "If you got used to JUnit 4's <code>assertThat</code> with various matchers (of course you will need junit-dep.jar and hamcrest.jar to get the full set instead of the small subset integrated in junit.jar), make sure you don't overlook the matcher hasProperty. It is very useful if you have non-trivial objects and cannot use some more flexible language like Groovy for your unit tests.<br><br>The advantage of <code>hasProperty</code> is that it allows you to check a particular property (or more properties with <code>allOf</code>) of an object while ignoring the others - pretty useful if the object has 20 properties and checking just one is enough for you. (Admittedly, an object with 20 properties is an abomination but hey, that's the real legacy word!)<br><br>Example - check that collection contains two Images with some file names:<br><br><pre><code>\r\nassertThat(&quot;Expected images&quot;, (Iterable&lt;Object&gt;) hotel.getImages()\r\n  , containsInAnyOrder(hasProperty(&quot;filename&quot;, is(&quot;radisson1.jpg&quot;))\r\n     , hasProperty(&quot;filename&quot;, is(&quot;radisson2.jpg&quot;))));\r\n</code></pre><br><br>The failure message in this case isn't as clear as I might wish but still this is the best solution I can think of.<br><br>Related:\r\n<ul>\r\n\t<li><a href=\"http://code.google.com/p/hamcrest/wiki/Tutorial\">An overview of Hamcrest matchers</a></li>\r\n\t<li>Another <a href=\"http://weblogs.java.net/blog/johnsmart/archive/2008/04/on_the_subtle_u.html\">blog about hasProperty</a> and all too common issues with generics in Hamcrest</li>\r\n\t<li><a href=\"https://github.com/alexruiz/fest-assert-2.x/wiki/Tips-and-tricks#wiki-extracted-properties-assertion\">Fest-Assert's extractProperty</a></li>\r\n</ul>",
  "excerpt": ""
 },
 {
  "title": "Aggregating Error Logs to Send a Warning Email When Too Many of Them - Log4j, Stat4j, SMTPAppender",
  "published": "2011-10-15 19:28:37",
  "postType": "post",
  "slug": "/2011/10/15/aggregating-error-logs-to-send-a-warning-email-when-too-many-of-them-log4j-stat4j-smtpappender/",
  "status": "publish",
  "tags": [
   "log4j",
   "logging",
   "monitoring",
   "ops"
  ],
  "categories": [
   "j2ee",
   "Tools"
  ],
  "content": "Our development team wanted to get notified as soon as something goes wrong in our production system, a critical Java web application serving thousands of customers daily. The idea was to let it send us an email when there are too many errors, indicating usually a problem with a database, an external web service, or something really bad with the application itself. In this post I want to present a simple solution we have implemented using a custom Log4J Appender based on Stats4j and an SMTPAppender (which is more difficult to configure and troubleshoot than you might expect) and in the following post I explore <a href=\"/2011/10/17/monitoring-java-webapp-with-hyperic-hq-send-email-when-too-many-errors-in-logs/\">how to achieve the same effect with the open-source Hyperic HQ</a> monitoring SW.<br><br><!--more-->\r\n<h2>The Challenge</h2>\r\nWe faced the following challenges with the logs:\r\n<ul>\r\n\t<li>It's unfortunately normal to have certain number of exceptions (customers select search criteria yielding no results, temporary, unimportant outages of external services etc.) and we certainly don't want to be spammed because of that. So the solution must have a configurable threshold and only send an alert when it is exceeded.</li>\r\n\t<li>The failure rate should be computed for a configurable period (long enough not to trigger an alert because of few-minutes outages yet short enough for the team to be informed ASAP when something serious happens).</li>\r\n\t<li>Once an alert is send, no further alerts should be send again for some time (ideally until the original problem is fixed), we don't want to be spammed because of a problem we already know about.</li>\r\n</ul>\r\n<h2>The Solution</h2>\r\nWe've based our solution on Lara D'Abreo's <a href=\"http://sourceforge.net/projects/stat4j/\">Stat4J</a>, which provides a custom Log4J appender that uses the logs to compute configurable measures and triggers alerts when they exceed their warning or critical thresholds. It is couple of years old, alpha-quality (regarding its generality and flexibility) open-source library, which is fortunately simple enough to be modified easily for one's needs.<br><br>So we have tweaked Stat4J to produce alerts when the number of alerts exceeds thresholds and keep quiet thereafter and combined that with a Log4J SMTPAppender that listens for the alerts and sends them via e-mail to the team.\r\n<h3>Stat4J Tweaking</h3>\r\nThe key components of Stat4J are the Stat4jAppender for Log4J itself, calculators (measures) that aggregate the individual logs (e.g. by counting them or extracting some number form them), statistics that define which logs to consider via regular expressions and how to process them by referencing a calculator, and finally alerts that log a warning when the value of a statistics exceeds its limits. You can learn more in an <a href=\"http://www.devx.com/java/Article/22110/0/page/3\">article that introduces Stat4J</a>.<br><br>We have implemented a custom measure calculator, <a href=\"https://github.com/jakubholynet/blog/blob/master/stat4j/src/net/sourceforge/stat4j/calculators/RunningRate.java\">RunningRate</a> (to count the number of failures in the last N minutes) and modified Stat4J as  follows:\r\n<ul>\r\n\t<li>We've <a href=\"https://github.com/jakubholynet/blog/blob/master/stat4j/src/net/sourceforge/stat4j/Alert.java#L124\">enhanced Alert</a> to support a new attribute, <em>quietperiod</em>, so that once triggered, subsequent alerts will be ignored for that duration (unless the previous alert was just a warning while the new one is a critical one)</li>\r\n\t<li>We've modified the appender to <a href=\"https://github.com/jakubholynet/blog/blob/master/stat4j/src/net/sourceforge/stat4j/log4j/Stat4jAppender.java#L53\">include the log's Throwable</a> together with the log message, which is then passed to the individual statistics calcualtors, so that we could filter more precisely what we want to count</li>\r\n\t<li>Finally we've modified Alert to <a href=\"https://github.com/jakubholynet/blog/blob/master/stat4j/src/net/sourceforge/stat4j/Alert.java#L92\">log alerts as errors</a> instead of warnings so that  the SMTPAppender wouldn't ignore them</li>\r\n</ul>\r\n<a href=\"https://github.com/jakubholynet/blog/tree/master/stat4j\">Get our modified Stat4j from GitHub</a> (sources or a <a href=\"https://github.com/jakubholynet/blog/downloads\">compiled jar</a>). Disclaimer: It is one day's hack and I'm not proud of the code.\r\n<h4>Stat4J Configuration</h4>\r\nTake the <a href=\"https://github.com/jakubholynet/blog/blob/master/stat4j/test/stat4j.properties\">example stat4j.properties</a> and put it on the classpath. It is already configured with the correct calculator, statistics, and alert. See this part:<br><br><pre><code>\r\n...\r\n### JAKUB HOLY - MY CONFIG\r\ncalculator.minuteRate.classname=net.sourceforge.stat4j.calculators.RunningRate\r\n# Period is in [ms] 1000 * 60 * 10 = 10 min:\r\ncalculator.minuteRate.period=600000<br><br>statistic.RunningErrorRate.description=Errors per 10 minutes\r\nstatistic.RunningErrorRate.calculator=minuteRate\r\n# Regular expression to match &quot;&lt;throwable.toString&gt; &lt;- &lt;original log message&gt;&quot;\r\nstatistic.RunningErrorRate.first.match=.*Exception.*<br><br># Error Rate\r\nalert.TooManyErrorsRecently.description=Too many errors in the log\r\nalert.TooManyErrorsRecently.statistic=RunningErrorRate\r\nalert.TooManyErrorsRecently.warn= &gt;=3\r\nalert.TooManyErrorsRecently.critical= &gt;=10\r\nalert.TooManyErrorsRecently.category=alerts\r\n# Ignore following warnings (or criticals, after the first critical) for the given amount of time:\r\n# 1000 * 60 * 100 = 100 min\r\nalert.TooManyErrorsRecently.quietperiod=6000000\r\n</code></pre><br><br>The important config params are\r\n<ul>\r\n\t<li><em>calculator.minuteRate.period</em> (in ms) - count errors over this period, reset the count at its end; a reasonable value may be 10 minutes</li>\r\n\t<li><em>alert.TooManyErrorsRecently.warn</em> and <em>.critical</em> - trigger the alert when so many errors in the period has been encountered; reasonable values depend on your application's normal error rate</li>\r\n\t<li><em>alert.TooManyErrorsRecently.quietperiod</em> (in ms) - don't send further alerts for this period not to spam in a persistent failure situation; the reasonable value depends on how quickly you usually fix problems, 1 hour would seem OK to me</li>\r\n\t<li>Notice that <em>statistic.RunningErrorRate.first.match</em> is a regular expression defining which logs to count; \".*\" would include any log, \"your\\.package\\..*Exception\" any exception in the package and so on, you can even specify logs to exclude using a <a href=\"http://download.oracle.com/javase/1,5.0/docs/api/java/util/regex/Pattern.html#special\">negative lookahead</a> (<a name=\"sum\"></a><tt>(?!</tt><em>X</em><tt>))</tt></li>\r\n</ul>\r\n<h3>Log4J Configuration</h3>\r\nNow we need to tell Log4J to use the Stat4j appender to count error occurences and to send alerts via email:<br><br><pre><code>\r\nlog4j.rootCategory=DEBUG, Console, FileAppender, Stat4jAppender\r\n...\r\n### Stat4jAppender &amp; EmailAlertsAppender ###\r\n# Collects statistics about logs and sends alerts when there\r\n# were too many failures in cooperation with the EmailAlertsAppender<br><br>## Stat4jAppender\r\nlog4j.appender.Stat4jAppender=net.sourceforge.stat4j.log4j.Stat4jAppender\r\nlog4j.appender.Stat4jAppender.Threshold=ERROR\r\n# For configuration see stat4j.properties<br><br>## EmailAlertsAppender\r\n# BEWARE: SMTPAppender ignores its Thresholds and only evers sends ERROR or higher messages\r\nlog4j.category.alerts=ERROR, EmailAlertsAppender\r\nlog4j.appender.EmailAlertsAppender=org.apache.log4j.net.SMTPAppender\r\nlog4j.appender.EmailAlertsAppender.To=dummy@example.com\r\n# BEWARE: The address below must have a valid domain or some receivers will reject it (e.g. GMail)\r\nlog4j.appender.EmailAlertsAppender.From=noreply-stat4j@google.no\r\nlog4j.appender.EmailAlertsAppender.SMTPHost=172.20.20.70\r\nlog4j.appender.EmailAlertsAppender.BufferSize=1\r\nlog4j.appender.EmailAlertsAppender.Subject=[Stat4j] Too many exceptions in log\r\nlog4j.appender.EmailAlertsAppender.layout=org.apache.log4j.PatternLayout\r\nlog4j.appender.EmailAlertsAppender.layout.ConversionPattern=%d{ISO8601} %-5p %X{clientIdentifier} %c %x - %m%n\r\n</code></pre><br><br>Comments\r\n<ul>\r\n\t<li>#8 Specify the Stat4J appender</li>\r\n\t<li>#9 Only send ERRORs to Stat4J, we are not interested in less serious exceptions</li>\r\n\t<li>#14 \"alerts\" is the log category used by Stat4jAppender to log alerts (the same you would create via Logger.getLogger(\"alerts\")); as mentioned, SMTPAppender will without respect to the configuration only process ERRORs and higher</li>\r\n</ul>\r\n<h4>Issues with the SMTPAppender</h4>\r\nIt is quite tricky to get the SMTPAppender working. Some pitfall:\r\n<ul>\r\n\t<li>SMTPAppender<em> ignores all logs that are not ERROR or higher without respect to how you set its threshold</em></li>\r\n\t<li>If you specify a non-existing From domain then some recipient's mail servers can just delete the email as spam (e.g. GMail)</li>\r\n\t<li>To send emails, you of course need mail.jar (and for older JVMs also activation.jar), here are <a href=\"http://haveacafe.wordpress.com/2008/09/26/113/\">instructions for Tomcat</a></li>\r\n</ul>\r\nAnd one $100 tip: to debug it, run your application in the debug mode and set a method breakpoint on javax.mail.Transport#send (you don't need the source code) and when there, set <em>this.session.debug</em> to true to get a very detailed log of the following SMTP communication in the server log.\r\n<h2>Sidenote</h2>\r\nThe fact that this article is based on Log4J doesn't mean I'd personally choose it, it just came with the project. I'd at least consider using the newer and shiny <a href=\"http://logback.qos.ch/\">Logback</a> instead :-).\r\n<h2>Conclusion</h2>\r\nStat4j + SMTPAppender are a very good base for a rather flexible do-it-yourself alerting system based on logs and e-mail. You can achieve the same thing out-out-the-box with Hyperic HQ plus much much more (provided that you get your admins to open two ports for it), which I will describe in the next blog post.\r\n<h2>Links</h2>\r\n<ul>\r\n\t<li>An alternative for preventing the SMTPAppender from spamming in persisten failure situations (aside of its built-in buffer size): <a href=\"https://github.com/reaktor/log4j-email-throttle\">log4j-email-throttle</a></li>\r\n\t<li><a href=\"http://www.mail-archive.com/log4j-user@logging.apache.org/msg12130.html\">EventConsolidatingAppender - announced via mailing list</a> in 2/2011 - \"the\r\npurpose of this appender is to consolidate multiple events that are received\r\nby a single logger within a specified number of seconds into a single event;\r\nthis single consolidated event is then forwarded to a 'downstream' appender\"</li>\r\n</ul>",
  "excerpt": ""
 },
 {
  "title": "Intro: Java Webapp Monitoring with Hyperic HQ + How to Alert on Too Many Errors in Logs",
  "published": "2011-10-17 15:06:41",
  "postType": "post",
  "slug": "/2011/10/17/monitoring-java-webapp-with-hyperic-hq-send-email-when-too-many-errors-in-logs/",
  "status": "publish",
  "tags": [
   "hyperic",
   "logging",
   "monitoring",
   "ops"
  ],
  "categories": [
   "j2ee",
   "Tools"
  ],
  "content": "This post describes how to set up the Java-based open source monitoring tool Hyperic HQ to monitor application server error logs and send a single warning e-mail when there are more of them than a threshold. In the previous post <a title=\"Permanent link to Aggregating Error Logs to Send a Warning Email When Too Many of Them – Log4j, Stat4j, SMTPAppender\" href=\"../2011/10/15/aggregating-error-logs-to-send-a-warning-email-when-too-many-of-them-log4j-stat4j-smtpappender/\" rel=\"bookmark\">Aggregating Error Logs to Send a Warning Email When Too Many of Them – Log4j, Stat4j, SMTPAppender</a> we've seen how to achieve that programatically while this solution is just about configuration. We will also see a little what else (a lot!) Hyperic can do for you and what the impressions after a short experimentation with it are.<!--more--><br><br>I'll be using Tomcat as the \"application server\" but it certainly works for other common ASs.\r\n<h2>Overview of Hyperic HQ</h2>\r\n<a href=\"http://www.springsource.com/landing/hyperic-open-source-download\">Hyperic HQ</a> 4.6 (and its commercial edition called VMware vFabric Hyperic) in points:\r\n<ul>\r\n\t<li>Developed by SpringSource/VMware</li>\r\n\t<li>Most likely the best available open-source monitoring SW (I believe it competes directly with Nagios but claims superiority in certain areas and I'd suppose it to be a better fit for the Java world as it itself is written in Java)</li>\r\n\t<li>Open-source, the enterprise version has some useful but non-substantial features like LDAP integration, dashboards personalized for roles, multi-action alerts (that would be useful but it is open-source and you can DIY) - see the <a href=\"http://www.springsource.com/products/systems-management/compare\">OSS x enteprise comparison</a></li>\r\n\t<li>You need to install Hyperic HQ monitoring server on one computer, a Hyperic agent on each machine to monitor and, if required, enable monitoring features in your SW (e.g. JMX in Tomcat)</li>\r\n\t<li>For agents and the server to communicate you must open a port on each machine (the enterp. version supports also unidirection communication initiated always by the agent)</li>\r\n\t<li>The server is a single package containing an embedded JBoss and PostgreSQL</li>\r\n\t<li>It has <a href=\"http://www.vmware.com/products/datacenter-virtualization/vfabric-hyperic/plugins.html\">monitoring (\"resource\") plugins</a> for many popular OSs, DBs, ASs, frameworks (Spring, JEE ...), HTTP servers etc. and integration with other technologies like JMX and softwares like Nagios and (enterpr. only) OpenNMS</li>\r\n</ul>\r\nHyperic HQ is very easy to install and the agent can detect many resources/services on its own and if the target SW needs some configuration to be monitorable then the Hyperic server will inform you about it and (at least in my case) provide instructions what to do.<br><br><a href=\"http://sourceforge.net/projects/hyperic-hq/files/\">Download the Hyperic HQ open-source</a> edition. (Notice that <em>Hyperic HQ</em> is used to refer to the open-source version while <em>vFabric Hyperic</em> refers to the enterprise edition.)\r\n<h3>Key Terms</h3>\r\nTo use Hyperic you need to know that a \"platform\" is a machine/OS, a \"server\" is a SW running there such as a DB or an AS, and \"service\" is st. monitorable running on the server such as the \"Apache Tomcat 6.0 Thread Pools\" service. Each of these levels has some metrics (CPU usage x JVM heap size x number active threads).\r\n<h3>Key UI Sections</h3>\r\n<img class=\"alignnone\" title=\"Hyperic HQ - Navigation tabs\" src=\"https://lh3.googleusercontent.com/-coEPG4NGrG4/Tp0uxELNdiI/AAAAAAAACLo/VOXs03lvrBc/s640/Hyperic_0-tabs.png\" alt=\"\" width=\"640\" height=\"254\" /><br><br>The start page/tab is <em>Dashboard</em>, where you can add \"portlets\" such as the Metric Viewer to get a quick overview of your systems. The next tab is <em>Resources</em>, where you can search for the monitored platforms/servers/services to show their detailed metrics, graphs etc., configure monitoring and alerts and so on. The <em>Analyze</em> tab provides an overview of events and alerts and <em>Administration</em> allows you e.g. to add users and to change what metrics are collected and shown by default (i.e. as indicators) for each resource type.<br><br>When you display a resource such as the Tomcat server, you've 4 additional tabs: <em>Monitor</em> (metrics, charts), <em>Inventory</em> (configuration and sub-resources), <em>Alerts</em> (see below), <em>Control</em> (define control actions on the resource such as restart), <em>Views</em> (Live Exec to execute OS monitoring commands; EE only??).\r\n<h3>Going Further</h3>\r\nYou may want to browse through the screenshots &amp; little text in four <em>New to Hyperic HQ</em> articles referenced at the end of this post to get a good overview of what the UI looks like and how it is used.\r\n<h2>Configuring Hyperic to Send Email When Too Many Errors in Logs</h2>\r\nWe will see how to install Hyperic, use it to monitor a local (or remote, it would be nearly the same) installation of Tomcat and how to alert us via e-mail when the number of errors in the Tomcat's logs exceeds a threshold.\r\n<h3>Installing Hyperic HQ 4.6 Server and Agent</h3>\r\n<ol>\r\n\t<li>Download the hyperic-hq-installer-* for your platform or hyperic-hq-installer-*-noJRE.zip, unpack it and run its <kbd>setup.sh/.bat</kbd>. Notice that it can be used to install either only the agent, only the server or both.</li>\r\n<ul>\r\n\t<li>Note: run <kbd>setup.sh -full</kbd> to get full set of options such as which DB to use (default = the embedded PostgreSQL, for production use it recommends a standalone Oracle or MySQL and supports also a standalone PostgreSQL)</li>\r\n</ul>\r\n\t<li>Follow the instructions - select to install both server and agent (unless you want to install the agent on another machine), provide the name of an existing directory (setup will create subdirs for server and agent) etc.</li>\r\n<ul>\r\n\t<li>By default the Hyperic Server web UI runs on the port 7080 (https on 7443)</li>\r\n\t<li>Afterwards you may check &lt;installer&gt;/installer/logs/hq-install.log[.verbose]</li>\r\n</ul>\r\n\t<li><a href=\"http://support.hyperic.com/display/DOC/Configure+and+Run+the+HQ+Agent\">Configure and run the agent</a> - execute <kbd>&lt;Hyperic installation root&gt;/agent-4.6/bin/hq-agent.sh start</kbd></li>\r\n<ul>\r\n\t<li>It will ask about the IP and http [and https] port of the monitoring server, the server admin credentials and the IP and port (default: 2144) the server should use to contact the agent</li>\r\n\t<li>You may check &lt;agent dir&gt;/log/agent.log to see the results of the autodiscovery of local services</li>\r\n</ul>\r\n\t<li>Start the server (if not done automatically): <kbd>&lt;Hyperic installation root&gt;/bin/hq-server.sh start</kbd></li>\r\n</ol>\r\n<h3>Enabling Monitoring of a Tomcat</h3>\r\nLog into your <a href=\"http://localhost:7080/\">Hyperic HQ</a>, the Dashboard will be displayed. If your agent started successfully then you should see its machine (f.ex. \"YourDomainName (MacOSX)\") in the Recently Added portlet or on the Resources tab under Platforms (if not then check the agent's log).<br><br>Click on the platform's name or go to Resources - Servers. You should see your Tomcat there provided that it was started, st. like \"YourDomainName Apache Tomcat 6.0\" (if not then check the agent's log). Most likely in the Availability column you will see a grey icon signifying that HQ isn't able to get monitoring data from it. If you click on its name you should be informed about the problem and provided with the instructions to enable <a href=\"http://tomcat.apache.org/tomcat-6.0-doc/monitoring.html#Enabling_JMX_Remote\">JMX monitoring on the Tomcat</a> (either put it all on one line removing the '\\' or make sure there is no space etc. following the backslash). Do it &amp; restart Tomcat. The grey icon should turn green.<br><br>(I guess Hyperic should be able monitor the logs w/o turning on JMX but haven't verified that.)\r\n<h3>Enable Tomcat Log Monitoring</h3>\r\nGo to Resources - Servers and click on your Tomcat, switch to the inventory tab and scroll down to the Configuration Properties and make sure you have there server.log_track.enable true and server.log_track.level Error, if not then click on Edit in the bottom-left corner and change it. (Notice that you can also specify a log pattern match and an alternative location of the log file.) You should have st. like:<br><br><img class=\"alignnone\" title=\"Hyperic HQ - View Server Inventory - Apache Tomcat 6.0\" src=\"https://lh3.googleusercontent.com/-eCR8hLROfU0/TpwpWvkAtOI/AAAAAAAACLQ/VD0Qa7a2ggE/s1145/Hyperic_1-View%252520Server%252520Inventory-Apache%252520Tomcat%2525206.0.png\" alt=\"\" width=\"1145\" height=\"258\" /><br><br>You may actually set a lower log level as it is also possible to specify wich severity to track in the alert.\r\n<h3>Setting Up an Alert</h3>\r\nWe will now tell Hyperic to produce a one-time alert when the number of errors in the log in the last 10 minutes exceeds 3. Alerts are shown in the UI and can be also send by email to any registered HQ user or just about any e-mail address.<br><br>Go to the Tomcat server resource (as above) and select the Alert sub-tab out of Monitor|Inventory|Alert|Control|View. Click on [Configure] and [New...] and fill it in as shown below:<br><br><img class=\"alignnone\" title=\"Hyperic HQ Alert configuration: Too many exceptions\" src=\"https://lh6.googleusercontent.com/-O45MdTzoGv8/TpwpWtVzsLI/AAAAAAAACLM/YhssG6arbP8/s1179/Hyperic_2-alert_config-too_many_exceptions.jpg\" alt=\"\" width=\"1179\" height=\"645\" /><br><br>At the bottom (not visible on the screenshot) you can click on <em>Notify Other Recipients</em> to add an e-mail address where to send the alerts.\r\n<h3>Fire the Alert</h3>\r\nMake your Tomcat log three exceptions and when coming back to the Hyperic UI or refreshing it you should see the alert in the masthead and also on the dashboard in the Recent Alerts portlet. If you configured the SMTP correctly and sat the alert to be send via e-mail then you should also get it into your mailbox.<br><br><img class=\"alignnone\" title=\"Hyperic HQ Dashboard with two alerts\" src=\"https://lh5.googleusercontent.com/-Ce8pszP9xOk/TpwpWsyiJ5I/AAAAAAAACLc/LMs4a-69D84/s800/Hyperic_3-Dashboard_with_alert.png\" alt=\"\" width=\"800\" height=\"174\" /><br><br>You can use the Recent Alerts portlet to mark an alert as fixed so that if the situation re-occures then a new alert will be generated (don't forget that we told HQ not to generate further alerts until fixed).\r\n<h2>Impressions from Hyperic HQ 4.6</h2>\r\nMy experience with Hyperic HQ is extremely short so I cannot provide a well-founded evaluation, just a bunch of impressions.<br><br>It is certainly very powerful regarding what it can monitor, pretty easy to set up, and moderately intuitive. The UI is little old-fashioned but ops/devs folks are used to such things and don't need everything to be like GMail or GitHub. The configurability of the dashboard is quite disappointing (metric views only in one column, cannot combine more metrics in one view, lot of wasted space etc.), especially compared to what I got used to in IBM's Rational Jazz. But it is possible to get the data via a webservice so you might be able to build your own display. It would be nice to have multi-conditional alerts and scriptable actions in the open source editions but it is free after all.<br><br>I miss the ability to define custom derived metrics (e.g. mean + std. deviation) or aggregations (e.g. weighted average). It actually seems to me that HQ has no concept of metric data aggregation. The only way around that is to get the raw data e.g. via the <a href=\"https://github.com/hyperic/hqapi/blob/master/hqapi1/src/main/java/org/hyperic/hq/hqapi1/MetricDataApi.java\">MetricDataApi</a> and agreggate it/derive metrics yourself.<br><br>To try out:\r\n<ul>\r\n\t<li>Switch between Show List View and Show Chart View on the Resources tab</li>\r\n\t<li>Define a custom group of related resources to make it easier to show them all at once etc. (Resources - new group and then Tools Menu - Add to group)</li>\r\n\t<li>Script Service: run a custom measurement script on a scheduled basis and save metrics in the Hyperic database along with plugin-reported metrics (Google it)</li>\r\n\t<li>By default, HQ collects a small subset of the available metrics. You can change that at Administration - Monitoring Defaults - click the resource's Edit metric templates, check the metrics you want and whether to show them by default (= indicators), enter a collection interval and the button next to it</li>\r\n\t<li>Quote: \"Even if developing Hyperic HQ plugins has an initial cost, we got familiar with it and developed many JMX Mbeans + associated Hyperic plugins\" - <a href=\"http://code.google.com/p/xebia-france/wiki/XebiaManagementExtras\">available at Google Code/Xebia</a></li>\r\n</ul>\r\n<h2>Conclusion</h2>\r\nHyperic HQ looks really good (as a tool, not the UI). Somewhere it may be difficult to get a port at the server and at the monitored machine open and you should absolutely use an external DB and be aware of its possible rapid growth if you collect lot of monitoring data and don't purge the older ones in some way. Its functionality is pretty good regarding both what can be monitored and what you can do with the data in the UI and if that is not enough then you have the webservice HQAPI and the full source code of HQ at your disposal. I'm certainly looking forward to trying it out on my next project.<br><br><em>If you have an experience with Hyperic HQ, please share it with us in the comments. Thanks!</em>\r\n<h2>Related</h2>\r\n<ul>\r\n\t<li><strong>Recommended</strong>: <a href=\"http://my.opera.com/ekoprabowo/blog/new-to-hyperic-hq-part-1\">New to Hyperic HQ: Part 1</a> (dashboard), <a href=\"http://my.opera.com/ekoprabowo/blog/2008/12/16/new-to-hyperic-hq-part-2\">Part 2</a> (resources), <a href=\"http://my.opera.com/ekoprabowo/blog/show.dml/2829801\">Part 3</a> (adding new platform/server), <a href=\"http://my.opera.com/ekoprabowo/blog/2008/12/18/new-to-hyperic-hq-part-4\">Part 4</a> (alerts) - lot of screenshots, only little of text, pretty useful for an overview and some common tasks</li>\r\n\t<li><strong>Recommended</strong>: <a href=\"http://www.hyperic.com/demo/tutorials/monitoring\">Demo - Monitoring in Hyperic HQ</a> (6 min video) - the 3 types of metrics, how to interpret them correctly. A good run-through the application.</li>\r\n\t<li>Hyperic resources</li>\r\n<ul>\r\n\t<li><a href=\"http://support.hyperic.com/display/hyperforge/Home\">HyperForge</a> - the home of Hyperic resource (i.e. monitoring) plugins</li>\r\n\t<li><a href=\"http://support.hyperic.com/display/DOCS46/vFabric+Hyperic+4.6\">Hyperic HQ/vFabric 4.6 documentation wiki</a>. The way they mark what is in the open-source and what in the EE version is beyond my comprehension (e.g. Alerts are in both while the advanced alert func. only in EE but can you <a href=\"http://support.hyperic.com/display/DOCS46/Alerts+and+Alert+Definitions\">see a difference?</a>). See also <a href=\"http://support.hyperic.com/display/EVO/Hyperic+Overview\">4.5's Hyperic HQ Overview</a> (or the less conscise version for <a href=\"http://support.hyperic.com/display/DOCS46/vFabric+Hyperic+Overview\">4.6</a>).</li>\r\n\t<li><a href=\"http://support.hyperic.com/display/DOCS46/About+vFabric+Hyperic+Web+Services+API\">Hyperic WebService API</a> (HQAPI) - get alerts, metric data, ... . <a href=\"https://github.com/hyperic/hqapi\">HQAPI at GitHub</a>.</li>\r\n</ul>\r\n\t<li>Articles etc.</li>\r\n<ul>\r\n\t<li><a href=\"http://www.youtube.com/watch?v=hJEd5ApAH-g\">YouTube: Understanding JMX Plugins in Hyperic HQ</a> (35 min) - intro, plugins arch., concepts, building JMX plugins</li>\r\n\t<li><a href=\"http://suniluiit.wordpress.com/2011/02/21/apache-cassandra-monitoring-through-hyperic-hq/\">Apache Cassandra monitoring through Hyperic HQ</a> (using a custom JMX plugin, HQ 4.4)</li>\r\n\t<li><a href=\"http://akanshajain.sys-con.com/node/1523569/mobile\">Monitoring webapps with Hyperic &amp; Hyperic web service API</a> (2008) - lot of HQAPI code</li>\r\n\t<li><a href=\"http://static.springsource.com/projects/tc-server/2.0/admin/html/ch03.html\">Configuring and Monitoring tc Runtime Instances Using Hyperic HQ</a></li>\r\n</ul>\r\n</ul>\r\n<h3>Related Tools</h3>\r\n<ul>\r\n\t<li><a href=\"http://newrelic.com/\">New Relic</a> - SaaS, has Java agent for Java 5+, supports multiple languages and PaaS providers, a Java and REST API in addition to that, drill down into slow transactions/DB operations. NewRelic Lite with very elementary monitoring is free, 14d trial for Pro. Nice UI, the drill-down is very valuable. Actively developed and extended (e.g. recently server monitoring). ThoughtWorks <a href=\"http://www.thoughtworks.com/articles/technology-radar-july-2011\">Technology Radar 7/2011</a> recommends it (they used it for RoR and .NET).</li>\r\n\t<li><a href=\"http://appdynamics.com/products-features-and-benefits.php\">AppDynamics</a> (see this article about <a href=\"http://www.appdynamics.com/blog/2011/11/01/just-how-useful-is-jmx-monitoring/\">A.D. in use</a>) - monitoring &amp; support for analysis via drill-down to the problematic areas. Pretty good if you have an application stack that it supports. SaaS or local deployment.</li>\r\n</ul>",
  "excerpt": ""
 },
 {
  "title": "Comparison of Eclipse 3.6 and IntelliJ IDEA 10.5: Pros and Cons",
  "published": "2011-10-18 13:04:06",
  "postType": "post",
  "slug": "/2011/10/18/comparison-of-eclipse-3-6-and-intellij-idea-10-5-pros-and-cons/",
  "status": "publish",
  "tags": [
   "intellij",
   "java"
  ],
  "categories": [
   "eclipse",
   "Languages",
   "Tools"
  ],
  "content": "After having worked with Eclipse for over 5 years I've came to use IntelliJ IDEA intensively on a J2EE project in three months and took this as an opportunity to compare the two. You can't really compare 5 years and 3 months but I still believe that it is long enough to get a pretty good overview of what a tool is like.<br><br><em>For the impatient:</em><br><br>IntelliJ is a very good tool, its killing feature for me is its excellent support for other languages such as Groovy (e.g. <a title=\"Blog: Only a Masochist Would Write Unit Tests in Java. Be Smarter, Use Groovy (or Scala…)\" href=\"/2011/10/18/only-a-masochist-would-write-unit-tests-in-java-be-smarter-use-groovy-or-jruby-or-st-else-similar/\">for unit tests</a>) and Clojure. Many details are more worked-out and with a higher usability then in Eclipse, f.ex. search &amp; replace with <a title=\"Search &amp; replace screenshot and docs\" href=\"http://blogs.jetbrains.com/idea/2011/04/in-place-replace-in-intellij-idea-105/\">match highlighting and replacement preview</a>. Its support for navigability and refactoring across multiple languages (Java, JSP, JSF, HQL, Spring config in my case) is also an absolutely great feature for productivity. And of course I have to add it credits for being a Czech product [<a href=\"http://en.wikipedia.org/wiki/JetBrains\">1</a>] (interestingly enough, NetBeans also comes from the Czech Republic [<a href=\"http://en.wikipedia.org/wiki/Netbeans#History_2\">2</a>]; it's a pity Eclipse hasn't this link too) :-).<br><br>My main issue with IntelliJ is its performance. First, running tests is slow because IntelliJ only does (re)compile the test/source when you hit the run button as opposed to Eclipse' incremental compilation. And that makes TDD very painful. (I tried to use the old Eclipse Mode plugin but it <a href=\"http://plugins.intellij.net/plugin/?id=3822\">has problems</a> with IntelliJ 9/10.) Second, sometimes the UI freezes* and you have to wait seconds or tens of seconds for it to respond again (even after disabling most plugins and some analysis). It doesn't happen too often but often enough to be noticed, to be annoying, and to interrupt the development flow.<br><br>*) Update: <a href=\"http://devnet.jetbrains.net/docs/DOC-197#comment-1092\">UI freezes may be a specific issue of Mac 64b 1.6 JDK</a><br><br>So I guess I'll use either Eclipse or IntelliJ with respect to the needs of the project at hand and hope for IntelliJ to resolve its performance issues (as NetBeans did).<!--more-->\r\n<h2>What's Cool in IntelliJ IDEA</h2>\r\nThe things I've stumbled upon and considered them noteworthy (there are certainly more of such goodies):\r\n<ul>\r\n\t<li>Great support for Groovy and Clojure (and others). I've used Groovy to write unit tests for my Java project and it worked pretty well (only click + Alt+Enter on a non-existing method to  create it didn't work unless the target class was a nested (static) class in the test itself)</li>\r\n\t<li>Out-of-the-box support for Spring*, namely you can click a bean class name in the applicationContext.xml to jump to it, deprecated classes are struck out, bean definitions are validated against available constructors and setters</li>\r\n\t<li>Refactoring\r\n<ul>\r\n\t<li><em>Move</em> can move more members/methods at once</li>\r\n\t<li><em>Move method</em> is aware of the current class' field of the target type so it is able to automatically insert fieldOfTargetType.movedMethod() - st- I miss a lot in Eclipse</li>\r\n\t<li><em>Rename</em> takes care also of JSF EL expressions in JSPs and other non-Java references (I suppose it is more clever than just a simple text search &amp; replace)</li>\r\n</ul>\r\n</li>\r\n\t<li>Completion proposals are displayed as you type (without pressing a hotkey - I love that) AND they include types that haven't been imported yet (@BeforeClass in a test...)</li>\r\n\t<li>(Auto)Completion proposals over multiple languages\r\n<ul>\r\n\t<li>CSS classes in JSPs (and in CSS/style it proposes e.g. color names)</li>\r\n</ul>\r\n</li>\r\n\t<li>Click-through in JSF EL expressions (well, at least sometimes)</li>\r\n\t<li>Usage search can find also method usages in JSPs, Spring config etc.</li>\r\n\t<li>Debugging\r\n<ul>\r\n\t<li>The Variables window automatically shows not only the local variables but also expressions based on them that are used in the code such as \"array_variable.length\"- a good time saver</li>\r\n</ul>\r\n</li>\r\n\t<li>JavaDoc: Closing tag completion - I've always missed that so much in Eclipse!</li>\r\n\t<li>When you generate a foreach loop (\"itco\" + tab) and change the source collection then it updates the element type automatically (in \"for (Type t: sourceColl)\")</li>\r\n\t<li>Really helpful RegExp integration in find &amp; replace in file - when typing, it shows both the first matched expression and what it will be replaced with</li>\r\n\t<li>General: Good at guessing resonable names for variables, ...</li>\r\n\t<li>Possibility to define a module for a subdirectory of the main module =&gt; you may have a project using Java 1.4 with tests in Java 5+. Works great with Maven multi-module projects too.</li>\r\n\t<li>The Project view displays directly Java types so you can distinguish a class from an interface at the first glance (Eclipse shows a file icon and you need to expand it first)</li>\r\n\t<li>The Java file structure view can show a \"property\" instead of a getter and a setter, making it shortet and easier to find what's really important</li>\r\n</ul>\r\n*) The Ultimate edition only (likely)<br><br>I'd recommend reading also the responses to the StackOverflow question <a href=\"http://stackoverflow.com/questions/239732/things-possible-in-intellij-that-arent-possible-in-eclipse\">Things possible in IntelliJ that aren't possible in Eclipse?</a> - among others they mention click-through anything, autocomplete taking into account more of the context (e.g. the name of the variable), the rename method refactoring updating also JSPs, Spring config, etc..<br><br>In general I'd say that IntelliJ has strong focus on usability and productivity, tries to understand what developers usually do and need and helps them with that and is pretty good at it. The authors claim it to be \"The Most Intelligent Java IDE\" and I think they do not exaggerate (or at least not too much :-)).\r\n<h2>Not So Cool</h2>\r\n(In no particular order.)\r\n<ul>\r\n\t<li>Eclipse only needs two hotkeys: Completion (^space) for class/property/templates/surround-with and Quick Fix (^1 - the <a href=\"/wiki/tools/eclipse/\">most powerful tool</a> in E.) for fixes such as imports, refactorings etc. In II you've several hotkeys for completion, one for live templates, one for fixes (intentions) ... - I've never managed to remember them all and to decide which one I should use in a particular situation</li>\r\n\t<li>No JavaDoc popup on mouse over (need ^J)</li>\r\n\t<li>The Live Template editor sucks, at least under Mac (can't type end-of-line, a curly bracket on Norwegian keyboard with Alt+Shift+8, backspace, ...). Fortunately you can select a code in an editor and Tools | Save as Live Template (though you should likely un-indent it first)</li>\r\n\t<li>No favorite static imports - for the first static method of a particular class I have to: 1) write the start of the method name; 2) press Ctrl+Alt+Space (Class name completion, don't ask me why this); 3) select the desired method such as CoreMatchers.allOf and press Alt+Enter as suggested in the pop-up's \"status bar\" -&gt; select Import statically. Since that on, all the static methods of the class will appear in the normal Ctrl+Space completion list (that's nice, though). In Eclipse I can add my belowed JUnit/Hamcrest/Mockito friends to favorite imports and have them always available.</li>\r\n\t<li>Slowness</li>\r\n<ul>\r\n\t<li>Slow testing - changed files are compiled just before a test is run while in Eclipse they have been compiled as soon as they were saved</li>\r\n\t<li>Sometimes II freezes for seconds/10s of seconds :'(\r\nUpdate: <a href=\"http://devnet.jetbrains.net/docs/DOC-197#comment-1092\">UI freezes may be a specific issue of Mac 64b 1.6 JDK</a></li>\r\n\t<li>Running analysis is SLOW (Checkstyle, ...) and can kill your IDE (and you too if you're of a weaker heart)</li>\r\n</ul>\r\n\t<li>The UI is little buggy, at least on Mac - dialogs not hidden when you click on another menu - not a big issue but annoying anyway</li>\r\n\t<li>Running webapp on Tomcat works great for some colleagues but not all  - useless logging without any details, the server doesn't start, no hints for how to solve, the Server -&gt; Output window contains confusing \"Disconnected from server\", Tomcat Log window contains only INFO logs (where are my debug logs?!), the file logs/catalina.out doesn't exist anymore, Tomcat failure visible in browser yet nothing in the logs ...</li>\r\n\t<li>JavaDoc - '#method' + ^space in Eclipse generates {@link #method} automatically, not so in II; even worse, class lookup doesn't work at all in II w/ot typing a @link first. I've found a <a href=\"http://michi.ist.inspirationslos.de/lang/en/2010/01/26/adding-javadoc-links-in-intellij-idea-with-live-templates/\">workaround via a live template</a> but I have to type its name and invoke it manually anyway.</li>\r\n\t<li>I miss Eclipse' auto-dissapearing views (just click anywhere in the editor and they'll disappear - though in II you can use Shift+Esc and if you un-pin a view then clicking in&amp;out of it will hide it) and the ability to maximize any view with double-click</li>\r\n\t<li>The number of plugins for IntelliJ is smaller than for Eclipse though all the main projects likely target it too</li>\r\n</ul>\r\nI could perhaps live with the small annoyances (or may be learn the proper way to do what I'm trying to achieve?) but the performance issues are hard to accept.\r\n<h2>Useful Resources</h2>\r\n<ul>\r\n\t<li><a href=\"http://www.jetbrains.com/idea/documentation/intentions.jsp\">II docs: Intentions</a></li>\r\n\t<li><a href=\"http://www.jetbrains.com/idea/features/code_assistance.html\">II docs: Code assistance</a> - overview of the different features for code completion etc.</li>\r\n\t<li>StackOverflow: <a href=\"http://stackoverflow.com/questions/239732/things-possible-in-intellij-that-arent-possible-in-eclipse\">Things possible in IntelliJ that aren't possible in Eclipse?</a></li>\r\n\t<li>StackOverflow: <a href=\"http://stackoverflow.com/questions/2524025/hidden-features-intellij-idea\">Hidden Features IntelliJ IDEA</a></li>\r\n\t<li>StackOverflow: <a href=\"//stackoverflow.com/questions/4387134/intellij-static-import-completion%20\">IntelliJ Static Import Completion</a></li>\r\n</ul>\r\n<h2>Conclusion</h2>\r\nRead the first 4 paragraphs again :-)\r\n<h2>The Software Compared</h2>\r\n<ul>\r\n\t<li>Eclipse 3.6 - I've worked with Eclipse since 3.0 or may be even before on many commercial projects</li>\r\n\t<li>IntelliJ IDEA Ultimate (the commercial, full-featured edition; II community is good enough unless you need special support for frameworks like JavaEE, Spring, and Hibernate - see the <a href=\"http://www.jetbrains.com/idea/features/editions_comparison_matrix.html\">editions comparison</a>)</li>\r\n</ul>",
  "excerpt": ""
 },
 {
  "title": "What Changes When You Deploy More Frequently and Why You Should Do It",
  "published": "2011-11-22 12:02:40",
  "postType": "post",
  "slug": "/2011/11/22/what-changes-when-you-deploy-more-frequently-and-why-you-should-do-it/",
  "status": "publish",
  "tags": [
   "agile",
   "continuous_deployment",
   "development",
   "DevOps",
   "opinion"
  ],
  "categories": [
   "General"
  ],
  "content": "This post is inspired by Kent Beck's excellent talk at JavaZone 2011 titled <a href=\"http://vimeo.com/28803277\">Software G Forces: The Effects of Acceleration</a> where he describes how the development process, practices and partly the whole organization change and/or have to change as you go from annual to monthly to weekly, daily, hourly deployments. I'd like to summarize some of the points he made and use that as a ground for arguing that more frequent deployments are (in general) better.<br><br>I'd highly recommend you to watch his presentation as I will only reproduce parts of it (and as they are out of their original context, they might well not represent exactly what Kent wanted to communicate).<br><br>Kent argues that as you deploy more and more frequently, many things have to change including the business side of the software. What is a best practice for one of these speeds becomes an impediment for another one. With more frequent deployments teams have to progress towards the following practices, while leaving some other practices behind:<br><br><!--more-->\r\n<ul>\r\n\t<li>Better, more automated testing: developer testing, automated acceptance testing (a.k.a. <a href=\"http://specificationbyexample.com/\">Specification by Example</a>). Notice that this implies that the software has to be designed for testability, which, I firmly believe, forces a better, more decoupled architecture (aside of the <a href=\"http://www.shino.de/2011/02/05/specification-by-example-the-big-win/\">other benefits of well-done SbE</a>).</li>\r\n\t<li>Merging of QA/testing team and operations team with the development team. There may still be a testing specialist and an operations specialist but they are one team with a shared responsibility and commitment and everyone does a little of everything.</li>\r\n\t<li>Improved feedback about production use and state of the application. (Which makes f.ex. data-driven, i.e. experimentation-based instead of guess-driven usability [UI] design possible.)</li>\r\n\t<li>Automated deployments including support for rollback (and I'd also assume it becomes necessary to implement <a href=\"http://cacm.acm.org/blogs/blog-cacm/51564-extreme-agility-at-facebook/fulltext\">gradual deployment</a> where functionality is first released to only a small subset of users and progressively enabled for more and more of them)</li>\r\n\t<li>Less up-front design and more empirical-based design refactoring and design evolution</li>\r\n\t<li>More suitable pricing model (per upgrade -&gt; subscription -&gt; per use ...)</li>\r\n</ul>\r\nAs a developer I find a couple of things associated with more frequent deployments very attractive. The key terms are <em>rapid feedback</em> and <em>high quality</em>. Both of them are also cornerstones of the lean development -  you cannot go fast without achieving an excellent quality (as Mary Poppendieck argues in her <a href=\"http://www.pearsonhighered.com/educator/product/Implementing-Lean-Software-Development-From-Concept-to-Cash/9780321437389.page\">book</a>) and feedback is much superior to guesswork in the complex world where we live and develop.<br><br>One of the positive changes is that the disconnection between developers and their application and its production life disappears. When programmers are isolated from the application by the QA and Ops teams they don't really care about how difficult it is to test or operate it. When they are one team, the communication becomes much better (=&gt; less wasted time) and the application will be much easier to test and operate (=&gt; yet less wasted time, less defects due to more effective testing and better defect detection). For me as a developer it is really a pain not to be a part of Ops and not to have a good insight into how my application is doing, how many people are using it and in which ways, how the latest new features have influenced this, and not to have a rapid defect detection and alerting (without them deployments become frightening ventures).<br><br>I very much agree with Kent that it is great to have daily+ deployments and rapid feedback from the production so that you can \"feel the software\" under your toes, meaning that whatever you decide now is going to effect users tomorrow. But it is not only about developers and feelings. As others have argued (just ask uncle Google about continuous delivery), more frequent deployments of small increments are much safer; good feedback makes it possible to detect and remove defects in virtually no time; it is cheaper (as I've reasoned above); and has many other benefits. Why then isn't everybody doing it? Well, radical changes aren't easy - and it isn't only the development that is transformed but the whole organization using the software. And it needs some effort to set up and some experience to do it correctly. So far continuous delivery is still a \"new\" paradigm and it will take time for the mainstream to understand and accept it.\r\n<h2>Me On (Design) Refactoring</h2>\r\nFrequent deployments make it possible to collect feedback and adjust the application correspondingly. Refactoring and <strong>design refactoring</strong> become an essential part of the process and replace the speculative design of today, that is designing for what you <em>think</em> - usually incorrectly - will be needed.<br><br>No matter how you make your design, the requirements will change and thus the design has to change too to prevent the software from turning into a growing pile of crap. Unfortunately too often people in the name of speed just cut corners and misuse and twist the old, insufficient design instead of reworking it, causing a lot of exponentially growing complexity and technical debt and thus a considerable loss.<br><br>Continuous, feedback-based design refactoring and evolution is the most reasonable and cost-effective approach to application design. Approach software development as continual improvement, as a <a href=\"http://www.stephenforte.net/PermaLink,guid,eb88ad5a-d7c1-48fd-8282-d2728e6464ad.aspx\">kaizen event</a>.\r\n<h2>Summary</h2>\r\nThe software development of the future will be an empirical process based on releasing often and adjusting based on the feedback. It requires higher process quality, removal of time wastes via efficient automation, removal of communication barriers between all stakeholders including testers and ops, and transformation of how the organization approaches software development, of its relations with customers, and of its business model. DevOps is a great model that can improve developer satisfaction and prevent a considerable waste.\r\n<h2>Related Posts</h2>\r\n<ul>\r\n\t<li>Greg Linden: <a href=\"http://cacm.acm.org/blogs/blog-cacm/40796-frequent-releases-change-software-engineering/fulltext\">Frequent Releases Change Software Engineering</a></li>\r\n\t<li>(Norwegian) O. C. Rynning: <a href=\"http://open.bekk.no/felles-ansvar-for-produksjon/\">Felles ansvar for produksjon!</a></li>\r\n\t<li>Aliastair Cockburn: <a href=\"http://alistair.cockburn.us/Trim+the+Tail\">Design as knowledge creation</a> - the value of early feedback; also: \"In most cases, the bigger the design that is done in the beginning, the more the unvalidated decisions produced, i.e. no “knowledge” is produced, only hypothesis, which is inventory.\"</li>\r\n\t<li>Regarding continuous system design refactoring - Aliastair Cockburn: <a href=\"http://alistair.cockburn.us/Incremental+Rearchitecture\">Incremental Rearchitecture</a> - \"Starting from a simple working architecture and applying Incremental Rearchitecture is a winning strategy for most, though not all systems\" (Also provides guidelines for How completely designed should the system architecture and infrastructure be during the early stages of the project?)</li>\r\n</ul>\r\n<div class=\"linkscent-iconblock\" style=\"float:none!important;border:0 solid #ff0000!important;background:none repeat scroll center center transparent!important;width:auto!important;height:auto!important;display:block!important;overflow:visible!important;position:static!important;text-indent:0!important;z-index:auto!important;max-width:none!important;min-width:0!important;max-height:none!important;min-height:0!important;left:auto!important;top:auto!important;bottom:auto!important;right:auto!important;line-height:16px!important;white-space:nowrap!important;margin:0!important;padding:0!important;\"><img class=\"linkscent-icon\" style=\"float:none!important;border:0 solid #ff0000!important;width:16px!important;height:16px!important;display:none;overflow:visible!important;position:absolute!important;text-indent:0!important;z-index:2147483635!important;max-width:none!important;min-width:0!important;max-height:none!important;min-height:0!important;left:580px;top:1199px;bottom:auto!important;right:auto!important;line-height:16px!important;white-space:nowrap!important;visibility:hidden;background:url('//interclue/content/cluecore/skins/default/linkscentExternal.png') no-repeat scroll center center transparent!important;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" /><img class=\"linkscent-icon\" style=\"float:none!important;border:0 solid #ff0000!important;background:none repeat scroll center center transparent;width:16px!important;height:16px!important;display:none;overflow:visible!important;position:absolute!important;text-indent:0!important;z-index:2147483635!important;max-width:none!important;min-width:0!important;max-height:none!important;min-height:0!important;left:598px;top:1199px;bottom:auto!important;right:auto!important;line-height:16px!important;white-space:nowrap!important;visibility:hidden;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" /></div>\r\n",
  "excerpt": ""
 },
 {
  "title": "JSF: Beware the Difference Between Build-Time and Render-Time Tags in Facelets",
  "published": "2011-10-28 10:55:28",
  "postType": "post",
  "slug": "/2011/10/28/jsf-beware-the-difference-between-build-time-and-render-time-tags-in-facelets/",
  "status": "publish",
  "tags": [
   "facelets",
   "java",
   "jsf",
   "pitfalls"
  ],
  "categories": [
   "j2ee",
   "Languages"
  ],
  "content": "This is to remind me that I should never ever forget the cruical difference between build-time-only tags (i.e. having tag handlers only) and render-time tags that have corresponding components. The problem is that their lifespan is different and thus mixing them can easily lead to nasty surprises. Build time tags are used to modify the <em>building</em> of a component tree and have no effect during its <em>rendering</em>, where only the components participate.<br><br>A typical mistake is the nesting of ui:include (build-time) inside ui:repeat (render-time) using the <var>var</var> that ui:repeat declares:<!--more--><br><br><pre><code>\r\n&lt;ui:repeat value=&quot;#{bean.books}&quot; var=&quot;book&quot;&gt;\r\n   &lt;ui:include src=&quot;#{book.type}-template.xhtml&quot; /&gt;\r\n&lt;/ui:repeat&gt;\r\n</code></pre><br><br>This won't work as intended because the <var>var</var> is only made available at the render time while ui:include is already evaluated at that point as it was invoked at the build time.<br><br>This is why combining JSTL and JSF isn't recommended in general. The complication with Facelets is that there is no clear distinct mark such as the namespace prefix that would distinguish build-time and render-time tags. In adition to JSTL also f.ex. f:actionListener, f:facet, ui:include, and any custom tag file are build-time while  e.g. f:selectItems, ui:repeat,h:inputText, and any custom UIComponent are render time. An addition to that it seems that f:converter and f:validator are yet another special case [3] (though more like build-time tags).<br><br><em>So make sure that you know which tags are build-time and which are render-time and when it is meaningful to mix them and when you should absolutely avoid it.</em><br><br>References (highly recommended to read through):\r\n<ol>\r\n\t<li>Andrew: <a href=\"http://drewdev.blogspot.com/2008/03/build-time-vs-render-time.html\">Build time vs. render time</a>  (2008) - mainly about JSP but the last section relates it to Facelets, which have the same problem with its tag handlers as JSP with its (non-JSF) tags</li>\r\n\t<li>BalusC: <a href=\"http://balusc.blogspot.com/2011/09/communication-in-jsf-20.html#ViewScopedFailsInTagHandlers\">Why @ViewScoped fails in tag handlers</a> (2011, JSF 2.0) - the author lists render-time alternatives for build-time tags where available</li>\r\n\t<li>Roger Keays: <a href=\"http://www.ninthavenue.com.au/blog/c:foreach-vs-ui:repeat-in-facelets\">c:forEach vs ui:repeat in Facelets</a>  (2007)</li>\r\n</ol>",
  "excerpt": ""
 },
 {
  "title": "Groovy: Creating an Interface Stub and Intercepting All Calls to It",
  "published": "2011-11-02 09:54:27",
  "postType": "post",
  "slug": "/2011/11/02/groovy-creating-interface-stub-and-intercepting-all-calls-to-it/",
  "status": "publish",
  "tags": [
   "groovy",
   "java",
   "Testing"
  ],
  "categories": [
   "Languages",
   "Testing"
  ],
  "content": "It's sometimes useful for unit testing to be able to create a simple no-op stub of an interface the class under test depends upon and to intercept all calls to the stub, for example to remember all the calls and parameters so that you can later verify that they've been invoked as expected. Often you'd use something like Mockito and its verify method but if you're writing <a title=\"Only a Masochist Would Write Unit Tests in Java. Be Smarter, Use Groovy (or Scala…).\" href=\"/2011/10/18/only-a-masochist-would-write-unit-tests-in-java-be-smarter-use-groovy-or-jruby-or-st-else-similar/\">unit tests in Groovy as I recommend</a> then there is a simpler and in a way a more powerful alternative.<!--more-->\r\n<h2>Solution 1 - When Calling the Stub From a Groovy Object</h2>\r\n<pre><code>\r\n@Before\r\npublic void setUp() {\r\n   this.collectedCalls = []\r\n   // The following works when a method on the listener is called from Groovy but not from Java:\r\n   this.listener = {} as PageNodeListener\r\n   listener.metaClass.invokeMethod = { name, args -&gt;\r\n      collectedCalls &lt;&lt; new Call(method: name, args: args) // Call is a simple structure class\r\n   }\r\n}<br><br>@Test\r\npublic void listener_stub_should_report_all_calls_to_it() throws Exception {\r\n   listener.fileEntered(&quot;fileName.dummy&quot;)\r\n   assert collectedCalls.find { it.equals(new Call(method: &quot;fileEntered&quot;, args: [&quot;fileName.dummy&quot;]))}\r\n}\r\n</code></pre><br><br>Notes:\r\n<ul>\r\n\t<li>5: <code>{} as PageNodeListener</code> uses Groovy's <a title=\"Groovy: Closure coercion\" href=\"http://groovy.codehaus.org/Groovy+way+to+implement+interfaces\">closure coercion</a> - basically it creates an implementation of the interface which uses the (empty) closure whenever any method is called (we could capture its arguments but not the method name via <code>{Object[] args -&gt; /*...*/} as PageNodeListener</code>)</li>\r\n\t<li>6-7: We then specify an interceptor method that should be invoked whenever any method is called on the instance</li>\r\n\t<li><a href=\"/2011/11/02/groovy-use-canonical-to-get-compiler-generated-equals-hashcode-and-tostring/\">Groovy makes it very easy to create beans like Call with equals, toString etc.</a></li>\r\n</ul>\r\nBeware that using a coerced closure as an interface implementation works only for methods that are either void or can return null (which is the return value of an empty closure, when invoked). Other methods will throw an NPE:<br><br><pre><code>\r\ndef list = {} as java.util.List\r\nlist.clear()    // OK, void\r\nlist.get(0)     // OK, returns null\r\nlist.isEmpty()  // NullPointerException at $Proxy4.isEmpty\r\n</code></pre><br><br>Alternatively, you may use <a href=\"http://docs.codehaus.org/display/GROOVY/Using+MockFor+and+StubFor\">Groovy's built-in mocking with MockFor and StubFor</a> (from the groovy.mock.interceptor package). The caller of the mock/stub must be in Groovy.\r\n<h2>Solution 2 - When Calling the Stub From a Java Object</h2>\r\nThe solution 1 is small and elegant but for me it hasn't worked when the stub was invoked by a Java object (a clarification of why that happened would be welcome). Fortunately Christoph Metzendorf proposed <a href=\"http://stackoverflow.com/questions/1765469/dynamically-implement-interface-in-groovy-using-invokemethod/1766824#1766824\">a solution at StackOverflow</a> (adjusted):<br><br><pre><code>\r\n@Before\r\npublic void setUp() {\r\n   this.collectedCalls = []\r\n   PageNodeListener listener = createListenerLoggingCallsInto(collectedCalls)\r\n   this.parser = new MyFaces21ValidatingFaceletsParser(TEST_WEBROOT, listener)\r\n}<br><br>def createListenerLoggingCallsInto(collectedCalls) {\r\n   def map = [:]<br><br>   PageNodeListener.class.methods.each() { method -&gt;\r\n      map.&quot;$method.name&quot; = { Object[] args -&gt;\r\n         collectedCalls &lt;&lt; new Call(method.name, args)\r\n      }\r\n   }<br><br>   return map.asType(PageNodeListener.class)\r\n}<br><br>@Test\r\npublic void should_notify_about_file_entered() throws Exception {\r\n   parser.validateExpressionsInView(toUrl(&quot;empty.xhtml&quot;), &quot;/empty.xhtml&quot;)\r\n   assert collectedCalls.find { it.equals(new Call(method: &quot;fileEntered&quot;, args: [&quot;/empty.xhtml&quot;]))}\r\n}\r\n</code></pre><br><br>Notes:\r\n<ul>\r\n\t<li>12-13: We create a map containing {method name} -&gt; {closure} for each of the interface's method</li>\r\n\t<li>17: The <a title=\"Groovy: Map coercion\" href=\"http://groovy.codehaus.org/Groovy+way+to+implement+interfaces\">map is then coerced to the interface</a> (the same as <code>someMap as PageNodeListener</code>). Notice that if it didn't contain an entry for a method then it would throw a NullPointerException if the method was invoked on the stub.</li>\r\n</ul>\r\nNotice that this version is more flexible than the Groovy-only one because we have full access to java.lang.reflect.<a title=\"class in java.lang.reflect\" href=\"http://download.oracle.com/javase/1,5.0/docs/api/java/lang/reflect/Method.html\" target=\"classFrame\">Method</a> when we create the map and thus can adjust the return value of the method closure w.r.t. what is expected. Thus it's possible to stub any interface, even if it has methods returning primitive types.\r\n<h2>Conclusion</h2>\r\nThis is a nice and simple way to stub an interface with methods that are void or return non-primitive values and collect all calls to the stub for a verification. If your requirements differ then you might be better of with a different type of <a href=\"http://docs.codehaus.org/display/GROOVY/Groovy+Mocks\">mocking in Groovy</a> or with a true mocking library.\r\n<h2>Additional Information</h2>\r\nGroovy version: 1.8.2, Java: 6.0.<br><br>See the full source code in the JSF EL Validator's <a href=\"https://github.com/jakubholynet/static-jsfexpression-validator/blob/5e89d97f6b5e98a197b1074dc1759fabb1048116/static-jsfexpression-validator-jsf20/src/test/java/org/apache/myfaces/view/facelets/compiler/NotifyingCompilationManagerTest.groovy\">NotifyingCompilationManagerTest.groovy</a>.\r\n<div class=\"linkscent-iconblock\" style=\"padding:0!important;margin:0!important;float:none !important;border:0 solid #ff0000 !important;background:none repeat scroll center center transparent !important;width:auto !important;height:auto !important;display:block !important;overflow:visible !important;position:static !important;text-indent:0 !important;z-index:auto !important;max-width:none !important;min-width:0 !important;max-height:none !important;min-height:0 !important;left:auto !important;top:auto !important;bottom:auto !important;right:auto !important;line-height:16px !important;white-space:nowrap !important;\"><img class=\"linkscent-icon\" style=\"padding:0!important;margin:0;float:none !important;border:0 solid #ff0000 !important;width:16px !important;height:16px !important;display:block;overflow:visible !important;position:absolute !important;text-indent:0 !important;z-index:2147483635 !important;max-width:none !important;min-width:0 !important;max-height:none !important;min-height:0 !important;left:484px;top:651px;bottom:auto !important;right:auto !important;line-height:16px !important;white-space:nowrap !important;visibility:visible;background:url('/favicon.ico') no-repeat scroll center center transparent !important;opacity:.5;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" /><img class=\"linkscent-icon\" style=\"padding:0!important;margin:0;float:none !important;border:0 solid #ff0000 !important;background:none repeat scroll center center transparent;width:16px !important;height:16px !important;display:none;overflow:visible !important;position:absolute !important;text-indent:0 !important;z-index:2147483635 !important;max-width:none !important;min-width:0 !important;max-height:none !important;min-height:0 !important;left:502px;top:651px;bottom:auto !important;right:auto !important;line-height:16px !important;white-space:nowrap !important;visibility:hidden;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" /></div>\r\n",
  "excerpt": ""
 },
 {
  "title": "Groovy: Use @Canonical to Get Compiler-generated Equals, HashCode and ToString",
  "published": "2011-11-02 10:18:34",
  "postType": "post",
  "slug": "/2011/11/02/groovy-use-canonical-to-get-compiler-generated-equals-hashcode-and-tostring/",
  "status": "publish",
  "tags": [
   "groovy",
   "java"
  ],
  "categories": [
   "General",
   "Languages"
  ],
  "content": "Groovy makes it extremely easy to create Java beans with getters, setters, equals, hashCode, and toString:<br><br><pre><code>\r\n@groovy.transform.Canonical\r\nclass Call {\r\n   def method\r\n   def args<br><br>   /* // custom impl. reusing the auto-generated one:\r\n   String toString() {\r\n      _toString().replaceFirst(&quot;^.*?Call&quot;, &quot;&quot;)\r\n   }*/\r\n}\r\n</code></pre><br><br>You can then do:<br><br><pre><code>\r\n// Auto-gen. constr. with positional arguments:\r\ndef call1 = new Call(&quot;someMethod&quot;, &quot;someArgs&quot;)\r\ndef call2 = new Call(method: &quot;someMethod&quot;, args: &quot;someArgs&quot;)\r\nassert call1.getMethod() == call1.method\r\nassert call2.equals(call1)\r\nassert ([call1, call2] as Set).size() == 1 // hashCode\r\n</code></pre><br><br>As you might have noticed, you may provide your own implementation of toString and reuse the auto-generated toString by calling <code>_toString()</code>.\r\n<h2>References</h2>\r\nJavaDoc for <a href=\"http://groovy.codehaus.org/api/groovy/transform/Canonical.html\">@Canonical</a>. You can also use separately any of: <a title=\"annotation in groovy.transform\" href=\"http://groovy.codehaus.org/api/groovy/transform/ToString.html\" target=\"classFrame\">@ToString</a>. <a title=\"annotation in groovy.transform\" href=\"http://groovy.codehaus.org/api/groovy/transform/EqualsAndHashCode.html\" target=\"classFrame\">@EqualsAndHashCode</a>, <a title=\"annotation in groovy.transform\" href=\"http://groovy.codehaus.org/api/groovy/transform/TupleConstructor.html\" target=\"classFrame\">@TupleConstructor</a>. And may be check also the <a href=\"http://groovy.codehaus.org/api/groovy/transform/package-frame.html\">other available AST annotations</a> such as Immutable and Synchronized and perhaps also <a href=\"http://groovy.codehaus.org/api/groovy/beans/package-frame.html\" target=\"packageFrame\">groovy.beans</a>'s Bindable and Vetoable annotations, if you need true Java Beans.",
  "excerpt": ""
 },
 {
  "title": "Most interesting links of November",
  "published": "2011-11-30 21:59:00",
  "postType": "post",
  "slug": "/2011/11/30/most-interesting-links-of-november-2/",
  "status": "publish",
  "tags": [
   "architecture",
   "clojure",
   "framework",
   "javaEE",
   "JavaScript",
   "jsf",
   "nosql",
   "performance",
   "scala",
   "security",
   "UI",
   "webapp"
  ],
  "categories": [
   "Databases",
   "General",
   "j2ee",
   "Top links of month"
  ],
  "content": "<h2>Recommended Readings</h2>\r\n<ul>\r\n\t<li><a href=\"http://www.poppendieck.com/reference.htm\">Recommended Reading by Poppendiecks</a> - an excellent selection, starting with Lean from Trenches, Management 3.0, Specification by Example, The Lean Startup etc.</li>\r\n\t<li>Eric Allman says that <a href=\"http://www.neophilic.com/b2evo/blogs/blog4.php/2011/09/02/programming-isnt-fun-any-more\">Programming Isn’t Fun Any More</a>  because problem solving has been replaced with learning, configuring, and integrating tons of libraries, frameworks, and tools and many people agree with that (as <a href=\"http://www.reddit.com/r/programming/comments/k42if/programming_isnt_fun_any_more/\">discussion on reddit</a> proves). In other words we tend to go for any benefit we can have without considering the costs and for \"easy\" solutions without considering the true enemy: complexity. Perhaps we should always listen to the Rich Hickey's <a href=\"http://www.infoq.com/presentations/Simple-Made-Easy\">Simple Made Easy</a> talk before we add a lib/tool/framework?</li>\r\n<ul>\r\n\t<li>Dean Wampler claims that <a href=\"http://blog.polyglotprogramming.com/2011/9/5/programming-can-be-fun-again\">functional programming can bring the joy back</a> - \"<em>[..] a functional language, Scala, Clojure, Haskell, etc. will greatly reduce the amount of code you create. That won’t solve the problem of trying to integrate with too many libraries, but you’ll be less tempted. I also believe those libraries will be less bulky, etc.</em>\"</li>\r\n\t<li>Few quotes from a <a href=\"http://reprog.wordpress.com/2010/03/04/whatever-happened-to-programming-redux-it-may-not-be-as-bad-as-all-that/\">related article</a> by M. Taylor: <em>To put it another way, libraries make excellent servants, but terrible masters.</em> | <em>[..] frameworks [..] do keep their promise of making things very quick and easy … so long as you do things in exactly the way the framework author intended</em> | On libraries: <em>[..] we all assume (I know I do) that “plug in solutions X1 and X3″ is going to be trivial. But it never is — it’s a tedious exercise in impedance-matching, requiring lots of time spent grubbing around in poorly-written manuals [..]</em> | On the effect of language choice: <em>[..] different languages, with their different expressive power and especially their different culture, yield very different experiences.</em></li>\r\n\t<li>To sum it up: Choose your tools and libraries wisely and always mind the global complexity. More usually means worse.</li>\r\n</ul>\r\n\t<li>Java Magazine - <a href=\"http://www.oraclejavamagazine-digital.com/javamagazine/20111112?sub_id=5AiqTIuomUOC#pg42\">Adam Bien: Stress Testing Java EE 6 Applications</a> (page 41+) - do developer stress testing! Using: JMeter, VisualVM to find out resource consumption and behavior in the application, VisualVM's Sampler profiling tool [cca 20% overhead], a webapp to extract metrics from GF (<a href=\"http://kenai.com/projects/javaee-patterns/sources/hg/show/StressTestMonitor?rev=238\">STM</a>)</li>\r\n\t<li>Java Magazine - <a href=\"http://www.oraclejavamagazine-digital.com/javamagazine/20111112?sub_id=5AiqTIuomUOC#pg51\">Polyglot Programming on the JVM</a> (page 50; excerpt from The Well-Grounded Java Developer) - why you should consider polyglot programming and how to decide whether to use it and what languages to pick, f.ex.: \"These [Java's] qualities make the language a great choice for implementing functionality in the stable layer [of the <a href=\"http://olabini.com/blog/2008/06/fractal-programming/\">polyglot programming pyramid</a>]. However, these same attributes become a burden in the middle and upper [lower, DSL, on the linked image] tiers of the pyramid; for example: Recompilation is laborious; Static typing can be inflexible and lead to long refactoring times; Deployment is a heavyweight process; Java's syntax is not a natural fit for producing DSLs.\" \"There is a wide range of natural use cases for *alternative languages*. [after identifying such a UC] You *now need to evaluate* whether using an alternative language is appropriate.\"</li>\r\n\t<li><a href=\"https://www.owasp.org/index.php/AppSensor_DetectionPoints\">Intrusion Detection for Web Apps - Detection Points</a> - If security is a concern of your web application then you should build intrusion detection into the application f.ex. leveraging the  <a href=\"http://www.owasp.org/index.php/Category:OWASP_AppSensor_Project\" rel=\"nofollow\">OWASP AppSensor</a> project. The key is to detect malicious/unexpected behavior and proactively do something such as locking the user out or alerting the admins. The page linked above lists some common suspicious behaviors such as the use of multiple usernames, unexpected HTTP command/method, additional/duplicated data in request. Worth checking out!</li>\r\n\t<li><a href=\"http://www.infoq.com/news/2011/11/yammer-scala\">Yammer Moving From Scala to Java</a>- Scala is a cool language but sometimes its cost is higher than the benefits. Snippets from the post: \"...the friction and complexity that\r\n<div id=\"LC20\">comes with using Scala instead of Java isn't offset by enough productivity benefit or reduction of maintenance burden ...\". \"Scala, as a language, has some profoundly interesting ideas in it. [...] But it's also a very complex language. The number of concepts I had to explain to new members of our team for even the simplest usage of a collection was surprising: implicit parameters, builder typeclasses, 'operator overloading', return type inference, etc. etc.\" (It's claimed that only library authors need to know some of that but if it's a part of library APIs, the users need to understand it too.) Notice that the author isn't saying \"Scala is bad\" but only that Scala isn't the best balance of their needs at this time, as Alex Miller put it<a href=\"http://tech.puredanger.com/2011/11/29/language-criticism/\">*</a>.<em>\r\nImportant note</em>: The text wasn't intended for publication and it is a private opinion of a Yammer developer, not the company itself. You should read <a href=\"http://eng.yammer.com/blog/2011/11/30/scala-at-yammer.html\">the official Yammer's position</a> where Coda puts it into the right context.</div></li>\r\n</ul>\r\n<h3>Refactoring</h3>\r\n<ul>\r\n\t<li><a href=\"http://java.dzone.com/articles/opportunistic-refactoring\">Opportunistic Refactoring</a> by Martin Fowler - refactor on the go - how &amp; why</li>\r\n\t<li>Michael Feathers: <a href=\"http://www.stickyminds.com/s.asp?F=S16679_COL_2\">Getting Empirical about Refactoring</a> - gather information that helps us understand the impact of our refactoring decisions using data from a SCM, namely File Churn (frequency of changes, i.e. commits) vs. Complexity - files with both high really need refactoring. Summary: \"<em>If we refactor as we make changes to our code, we end up working in progressively better code. Sometimes, however, it's nice to take a high-level view of a code base so that we can discover where the dragons are. I've been finding that this churn-vs.-complexity view helps me find good refactoring candidates and also gives me a good snapshot view of the design, commit, and refactoring styles of a team.</em>\"</li>\r\n</ul>\r\n<h3>UIs and Web Frameworks</h3>\r\n<ul>\r\n\t<li>Devoxx 2011 -<a href=\"http://prezi.com/dr3on1qcajzw/www-world-wide-wait-devoxx-edition/\"> WWW: World Wide Wait? A Performance Comparison of Java Web Frameworks</a> (slides) - the authors did extensive performance testing of some of the most popular web frameworks. Of course it's always hard to guess how general their results are, if/how they apply to one's particular situation, and if they aren't distorted in some way but it's worth for their approach alone (<a href=\"http://aws.amazon.com/what-is-aws/\">AWS</a> with its <a href=\"http://aws.amazon.com/cloudwatch/\">CloudWatch</a> monitoring, WebDriver, additional measurement of page load with <a href=\"http://www.softwareishard.com/blog/firebug/http-archive-specification/\">HAR</a> and a browser plugin). In their particular tests GWT scored best, followed by Spring MVC, with JSF and Wicket lagging far behind (especially the MyFaces implementation). Conclusion: A web framework may have strong impact on performance and scalability, if they are important for you then do test the performance early with as realistic code and load as possible.</li>\r\n\t<li><a href=\"http://nlabrot.blogspot.com/2011/01/jsf2-components-frameworks-datatable.html\">JSF2 - Benchmark datatable</a> by N. Labrot, 2/2011 - performance comparison of PrimeFaces 2.2.1, IceFaces 2.0, Richfaces 4.0.0M4 on a simple page with Ajax. I do not trust any benchmark that I don't fake myself :-) (for there are always too many factors that influence the conclusions to be drawn) but it's interesting anyway - and perhaps a good thing to do before you decide for a JSF component library.</li>\r\n\t<li><a href=\"http://alexmaccaw.co.uk/posts/async_ui\">Alex MacCaw: Asynchronous UIs - the future of web user interfaces</a> and the <a href=\"http://spinejs.com/\">Spine</a> framework - users in 2011 shouldn't anymore wait for pages to load and operations to complete, we should build asynchronous UIs where changes to the UI are performed immediately while a request to the server is sent in the background, similarly to sending e-mail in GMail, which returns at once displaying a non-intrusive \"Sending...\" notification. As a user I very much agree with Alex.</li>\r\n\t<li>Matt Raible's <a href=\"https://docs.google.com/a/iterate.no/document/pub?id=1X_XvpJd6TgEAMe4a6xxzJ38yzmthvrA6wD7zGy2Igog\">20 criteria for evaluating web frameworks</a>, 2010 (detailed description, here's a <a href=\"https://docs.google.com/a/iterate.no/document/pub?id=1jAGPWwlEcYikqOPg8faYgRV7cQNS_iCCoJ1VNc_99M4\">brief list</a>) - Matt's results are disputable and as he himself says you should always do your own evaluation and spikes but the criteria are pretty useful: Developer Productivity, Developer Perception, Learning Curve, Project Health, Developer Availability, Job Trends, Templating, Components, Ajax, Plugins or Add-Ons, Scalability, Testing, i18n and l10n, Validation, Multi-language Support (Groovy / Scala), Quality of Documentation/Tutorials, Books Published, REST Support (client and server), Mobile / iPhone Support, Degree of Risk.</li>\r\n</ul>\r\n<h3>NoSql</h3>\r\n<ul>\r\n\t<li><del>Don't use MongoDB</del> via <a href=\"http://twitter.com/#%21/nicolaiarocci/status/133242421277495297\">@nicolaiarocci</a> - a (fake?!) bad experience with MongoDB - <em>the text is not credible</em> (the author is anonymous, s/he doesn't explicitely state which version of MongoDB they used, the 10gen CTO can't find a matching client and any evidence for some of the issues mentioned) but it  gives context for the read-worthy <a href=\"http://news.ycombinator.com/item?id=3202081\">response from the 10gen CTO</a>, and a post that nicely explains <a title=\"Why the MongoDB hate?\" href=\"http://yourstartupsucks.com/post/12416816599/why-the-mongodb-hate?t=1320612601\">how to correctly design for MongoDB</a>. A comment about <a href=\"http://news.ycombinator.com/item?id=3203006\">MongoDB experience at Forsquare</a>: \"<em>Currently we have dozens of MongoDB instances across several different data clusters storing over a TB of data and handling 10s of thousands of requests per second (mostly reads but the write load is reasonably high as well).Have we run into problems with MongoDB along the way? Yes, of course we have. It is a new technology and problems happen.Have they been problematic enough to seriously threaten our data? No they have not.</em>\"</li>\r\n\t<li><a href=\"http://architects.dzone.com/articles/martin-fowler-polyglot\">Martin Fowler on Polyglot Persistence</a> - the are when will be choosing persistence solution with respect to our needs instead of mindlessly picking RDBMS is coming. Applications will combine multiple, specific solutions, f.ex. we could pick Redis (key-value) for caching, MongoDB (document DB) for product catalog, Neo4J (graph DB) for recommendations, RDBMS for financial data and reporting... (of course not all in one project!). Polyglot persistence will come at a cost (complexity, learning) - but it will come because the benefits are worth it - performance, data storage model and behavior more aligned with the business logic (NoSql databases ofer various models and tradeoffs and thus we can find a much better fit than with general-purpose RDBMs).</li>\r\n</ul>\r\n<h2>Talks &amp; Video</h2>\r\n<ul>\r\n\t<li>Adam Bien's JavaOne talk <a href=\"http://www.adam-bien.com/roller/abien/entry/java_ee_6_the_cool\">Java EE 6: The Cool Parts</a> (1h) - absolutely worth the time - a very practical fly through the cool features of Java EE (eventing, ..), most of the time is spent actually coding. Don't forget to check also the interesting discussion below the video (JEE and other frameworks, Java FX and JSF 2, ...).</li>\r\n\t<li>Jurgen Appelo's keynote <a href=\"http://vimeo.com/32227866\">How to Change the World</a> at Smidig 2011 is well done and highly useful. We all strive to change the world around us - as consultants we want to make our clients more agile, as team members we want to make our Scrum teams more self-organizing, as employees we want to help building knowledge-sharing and open culture, ... . However it isn't easy to influence or change people and culture and if we aren't aware of all the dimensions of a change (system, individuals, interactions, environment) and how to work along each of them, we are much less likely to succeed. The knowledge and experience that Jurgen shares with us can help us a lot in having an impact. You can also download the <a href=\"http://www.management30.com/change-management\">slides and change management questions</a>.</li>\r\n\t<li><a href=\"http://www.youtube.com/watch?feature=player_profilepage&amp;v=Atap3kaLguQ\">Project X: What is being a programmer like?</a> (5min) If ever again a non-geek asks you what you as a developer are doing, just show him this short and extremely funny video (created by my ex-employer - perhaps they estimated how much time and energy developers loose trying to explain it to normal people and decided to prevent this great waste :-))</li>\r\n\t<li>RSA Animate - <a href=\"http://www.youtube.com/watch?v=u6XAPnuFjJc\">Drive: The surprising truth about what motivates us</a> (10 min) - entertaining and enlightening; once we've enough money to cover our needs, it's autonomy (self-direction), mastery, and purpose what motivates us (money actually decrease our performance). Now this is a great evidence for lean/agile - for they're based on making people self-directing and encourage mastery (as in continous integration and top quality to enable steady pace). Autonomy enables engagement as does a higher purpose (\"make the world a better place\") - Steve Jobs with his visions was able to provide such a purpose. <a href=\"http://blogs.hbr.org/cs/2011/07/how_to_engage_the_front_line_i.html\">Atlassian's FedEx Days</a> are a good example of what engagement and benefits autonomy brings.</li>\r\n\t<li>Simon Sinek: <a href=\"http://www.ted.com/talks/simon_sinek_how_great_leaders_inspire_action.html\">How great leaders inspire action</a> (18 min, subtitles in 37 languages) - do you want to succeed, to change the world around you for the better, to start a new company? Then you must start by communicating \"why\" you do what you do, not \"what\" - like M. L. King, bro Wrights, and Apple. Very inspiring! (More in his <a href=\"http://amzn.com/1591846447\">Why</a> book.)</li>\r\n</ul>\r\n<h2>Links to Keep</h2>\r\n<ul>\r\n\t<li><a href=\"http://m.infoworld.com/d/html5/beyond-jquery-javascript-tools-the-html5-generation-178437\">Beyond jQuery: JavaScript tools for the HTML5 generation</a> - three dozen JavaScript libraries tuned for mobile devices, Canvas-based animation, HTML5 video, local databases, server interaction, charting, geolocation, and more</li>\r\n\t<li><a href=\"http://www.tomcatexpert.com/blog/2011/11/02/best-practices-securing-apache-tomcat-7\">Best Practices for Securing Apache Tomcat 7</a></li>\r\n</ul>\r\n<h2>Favorite Quotes</h2>\r\n<blockquote>\r\n<p style=\"text-align:left;\">Refactoring is like advertising: it doesn't cost, it pays.<em>\r\n- Mary &amp; Tom Poppendiecks, <a href=\"http://www.amazon.com/Implementing-Lean-Software-Development-Concept/dp/0321437381\">Implementing Lean Software Development</a>, p.166\r\n</em></p>\r\n</blockquote>\r\n<h2>Clojure Corner</h2>\r\n<ul>\r\n\t<li><a href=\"http://corfield.org/blog/post.cfm/real-world-clojure-email-status-tracking\">Real World Clojure - email status tracking</a> - using mulimethods to implement a state machine</li>\r\n\t<li><a href=\"https://github.com/relevance/clojure-conj/tree/master/2011-slides\">Slides from the Clojure/conj 2011</a> conference</li>\r\n\t<li><a href=\"http://tech.puredanger.com/2011/11/17/clojure-and-processing/\">Conway's Life in Clojure visualized via Processing</a></li>\r\n</ul>\r\n<div class=\"linkscent-iconblock\" style=\"float:none!important;border:0 solid #ff0000!important;background:none repeat scroll center center transparent!important;width:auto!important;height:auto!important;display:block!important;overflow:visible!important;position:static!important;text-indent:0!important;z-index:auto!important;max-width:none!important;min-width:0!important;max-height:none!important;min-height:0!important;left:auto!important;top:auto!important;bottom:auto!important;right:auto!important;line-height:16px!important;white-space:nowrap!important;margin:0!important;padding:0!important;\"><img class=\"linkscent-icon\" style=\"float:none!important;border:0 solid #ff0000!important;width:16px!important;height:16px!important;display:none;overflow:visible!important;position:absolute!important;text-indent:0!important;z-index:2147483635!important;max-width:none!important;min-width:0!important;max-height:none!important;min-height:0!important;left:433px;top:102px;bottom:auto!important;right:auto!important;line-height:16px!important;white-space:nowrap!important;visibility:hidden;background:url('//interclue/content/cluecore/skins/default/linkscentExternal.png') no-repeat scroll center center transparent!important;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" /><img class=\"linkscent-icon\" style=\"float:none!important;border:0 solid #ff0000!important;background:none repeat scroll center center transparent;width:16px!important;height:16px!important;display:none;overflow:visible!important;position:absolute!important;text-indent:0!important;z-index:2147483635!important;max-width:none!important;min-width:0!important;max-height:none!important;min-height:0!important;left:451px;top:102px;bottom:auto!important;right:auto!important;line-height:16px!important;white-space:nowrap!important;visibility:hidden;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" /></div>\r\n<div class=\"linkscent-iconblock\" style=\"float:none!important;border:0 solid #ff0000!important;background:none repeat scroll center center transparent!important;width:auto!important;height:auto!important;display:block!important;overflow:visible!important;position:static!important;text-indent:0!important;z-index:auto!important;max-width:none!important;min-width:0!important;max-height:none!important;min-height:0!important;left:auto!important;top:auto!important;bottom:auto!important;right:auto!important;line-height:16px!important;white-space:nowrap!important;margin:0!important;padding:0!important;\"><img class=\"linkscent-icon\" style=\"float:none!important;border:0 solid #ff0000!important;width:16px!important;height:16px!important;display:none;overflow:visible!important;position:absolute!important;text-indent:0!important;z-index:2147483635!important;max-width:none!important;min-width:0!important;max-height:none!important;min-height:0!important;left:517px;top:215px;bottom:auto!important;right:auto!important;line-height:16px!important;white-space:nowrap!important;visibility:hidden;background:url('//interclue/content/cluecore/skins/default/linkscentExternal.png') no-repeat scroll center center transparent!important;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" /><img class=\"linkscent-icon\" style=\"float:none!important;border:0 solid #ff0000!important;background:none repeat scroll center center transparent;width:16px!important;height:16px!important;display:none;overflow:visible!important;position:absolute!important;text-indent:0!important;z-index:2147483635!important;max-width:none!important;min-width:0!important;max-height:none!important;min-height:0!important;left:535px;top:215px;bottom:auto!important;right:auto!important;line-height:16px!important;white-space:nowrap!important;visibility:hidden;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" /></div>\r\n<div class=\"linkscent-iconblock\" style=\"float:none!important;border:0 solid #ff0000!important;background:none repeat scroll center center transparent!important;width:auto!important;height:auto!important;display:block!important;overflow:visible!important;position:static!important;text-indent:0!important;z-index:auto!important;max-width:none!important;min-width:0!important;max-height:none!important;min-height:0!important;left:auto!important;top:auto!important;bottom:auto!important;right:auto!important;line-height:16px!important;white-space:nowrap!important;margin:0!important;padding:0!important;\"><img class=\"linkscent-icon\" style=\"float:none!important;border:0 solid #ff0000!important;width:16px!important;height:16px!important;display:none;overflow:visible!important;position:absolute!important;text-indent:0!important;z-index:2147483635!important;max-width:none!important;min-width:0!important;max-height:none!important;min-height:0!important;left:289px;top:970px;bottom:auto!important;right:auto!important;line-height:16px!important;white-space:nowrap!important;visibility:hidden;background:url('http://www.management30.com/favicon.ico') no-repeat scroll center center transparent!important;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" /><img class=\"linkscent-icon\" style=\"float:none!important;border:0 solid #ff0000!important;background:none repeat scroll center center transparent;width:16px!important;height:16px!important;display:none;overflow:visible!important;position:absolute!important;text-indent:0!important;z-index:2147483635!important;max-width:none!important;min-width:0!important;max-height:none!important;min-height:0!important;left:307px;top:970px;bottom:auto!important;right:auto!important;line-height:16px!important;white-space:nowrap!important;visibility:hidden;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" /></div>\r\n<div class=\"linkscent-iconblock\" style=\"float:none!important;border:0 solid #ff0000!important;background:none repeat scroll center center transparent!important;width:auto!important;height:auto!important;display:block!important;overflow:visible!important;position:static!important;text-indent:0!important;z-index:auto!important;max-width:none!important;min-width:0!important;max-height:none!important;min-height:0!important;left:auto!important;top:auto!important;bottom:auto!important;right:auto!important;line-height:16px!important;white-space:nowrap!important;margin:0!important;padding:0!important;\"><img class=\"linkscent-icon\" style=\"float:none!important;border:0 solid #ff0000!important;width:16px!important;height:16px!important;display:none;overflow:visible!important;position:absolute!important;text-indent:0!important;z-index:2147483635!important;max-width:none!important;min-width:0!important;max-height:none!important;min-height:0!important;left:289px;top:969px;bottom:auto!important;right:auto!important;line-height:16px!important;white-space:nowrap!important;visibility:hidden;background:url('http://www.management30.com/favicon.ico') no-repeat scroll center center transparent!important;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" /><img class=\"linkscent-icon\" style=\"float:none!important;border:0 solid #ff0000!important;background:none repeat scroll center center transparent;width:16px!important;height:16px!important;display:none;overflow:visible!important;position:absolute!important;text-indent:0!important;z-index:2147483635!important;max-width:none!important;min-width:0!important;max-height:none!important;min-height:0!important;left:307px;top:969px;bottom:auto!important;right:auto!important;line-height:16px!important;white-space:nowrap!important;visibility:hidden;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" /><img class=\"linkscent-icon\" style=\"float:none!important;border:0 solid #ff0000!important;width:16px!important;height:16px!important;display:none;overflow:visible!important;position:absolute!important;text-indent:0!important;z-index:2147483635!important;max-width:none!important;min-width:0!important;max-height:none!important;min-height:0!important;left:306px;top:988px;bottom:auto!important;right:auto!important;line-height:16px!important;white-space:nowrap!important;visibility:hidden;background:url('http://s.ytimg.com/yt/favicon-vflZlzSbU.ico') no-repeat scroll center center transparent!important;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" /><img class=\"linkscent-icon\" style=\"float:none!important;border:0 solid #ff0000!important;background:url('//interclue/content/cluecore/skins/default/sprites.png') no-repeat scroll -48px -96px transparent;width:16px!important;height:16px!important;display:none;overflow:visible!important;position:absolute!important;text-indent:0!important;z-index:2147483635!important;max-width:none!important;min-width:0!important;max-height:none!important;min-height:0!important;left:324px;top:988px;bottom:auto!important;right:auto!important;line-height:16px!important;white-space:nowrap!important;visibility:hidden;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" width=\"16\" height=\"16\" /><img class=\"linkscent-icon\" style=\"float:none!important;border:0 solid #ff0000!important;background:none repeat scroll center center transparent;width:16px!important;height:16px!important;display:none;overflow:visible!important;position:absolute!important;text-indent:0!important;z-index:2147483635!important;max-width:none!important;min-width:0!important;max-height:none!important;min-height:0!important;left:342px;top:988px;bottom:auto!important;right:auto!important;line-height:16px!important;white-space:nowrap!important;visibility:hidden;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" /></div>\r\n<div class=\"linkscent-iconblock\" style=\"float:none!important;border:0 solid #ff0000!important;background:none repeat scroll center center transparent!important;width:auto!important;height:auto!important;display:block!important;overflow:visible!important;position:static!important;text-indent:0!important;z-index:auto!important;max-width:none!important;min-width:0!important;max-height:none!important;min-height:0!important;left:auto!important;top:auto!important;bottom:auto!important;right:auto!important;line-height:16px!important;white-space:nowrap!important;margin:0!important;padding:0!important;\"><img class=\"linkscent-icon\" style=\"float:none!important;border:0 solid #ff0000!important;width:16px!important;height:16px!important;display:block;overflow:visible!important;position:absolute!important;text-indent:0!important;z-index:2147483635!important;max-width:none!important;min-width:0!important;max-height:none!important;min-height:0!important;left:379px;top:1298px;bottom:auto!important;right:auto!important;line-height:16px!important;white-space:nowrap!important;visibility:visible;background:url('http://amazon.com/favicon.ico') no-repeat scroll center center transparent!important;opacity:0.388889;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" /><img class=\"linkscent-icon\" style=\"float:none!important;border:0 solid #ff0000!important;background:none repeat scroll center center transparent;width:16px!important;height:16px!important;display:none;overflow:visible!important;position:absolute!important;text-indent:0!important;z-index:2147483635!important;max-width:none!important;min-width:0!important;max-height:none!important;min-height:0!important;left:397px;top:1298px;bottom:auto!important;right:auto!important;line-height:16px!important;white-space:nowrap!important;visibility:hidden;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" /></div>\r\n<div class=\"linkscent-iconblock\" style=\"float:none!important;border:0 solid #ff0000!important;background:none repeat scroll center center transparent!important;width:auto!important;height:auto!important;display:block!important;overflow:visible!important;position:static!important;text-indent:0!important;z-index:auto!important;max-width:none!important;min-width:0!important;max-height:none!important;min-height:0!important;left:auto!important;top:auto!important;bottom:auto!important;right:auto!important;line-height:16px!important;white-space:nowrap!important;margin:0!important;padding:0!important;\"><img class=\"linkscent-icon\" style=\"float:none!important;border:0 solid #ff0000!important;width:16px!important;height:16px!important;display:none;overflow:visible!important;position:absolute!important;text-indent:0!important;z-index:2147483635!important;max-width:none!important;min-width:0!important;max-height:none!important;min-height:0!important;left:350px;top:140px;bottom:auto!important;right:auto!important;line-height:16px!important;white-space:nowrap!important;visibility:hidden;background:url('http://www.infoq.com/favicon.ico') no-repeat scroll center center transparent!important;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" /><img class=\"linkscent-icon\" style=\"float:none!important;border:0 solid #ff0000!important;background:none repeat scroll center center transparent;width:16px!important;height:16px!important;display:none;overflow:visible!important;position:absolute!important;text-indent:0!important;z-index:2147483635!important;max-width:none!important;min-width:0!important;max-height:none!important;min-height:0!important;left:368px;top:140px;bottom:auto!important;right:auto!important;line-height:16px!important;white-space:nowrap!important;visibility:hidden;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" /><img class=\"linkscent-icon\" style=\"float:none!important;border:0 solid #ff0000!important;width:16px!important;height:16px!important;display:none;overflow:visible!important;position:absolute!important;text-indent:0!important;z-index:2147483635!important;max-width:none!important;min-width:0!important;max-height:none!important;min-height:0!important;left:517px;top:159px;bottom:auto!important;right:auto!important;line-height:16px!important;white-space:nowrap!important;visibility:hidden;background:url('//interclue/content/cluecore/skins/default/linkscentExternal.png') no-repeat scroll center center transparent!important;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" /><img class=\"linkscent-icon\" style=\"float:none!important;border:0 solid #ff0000!important;background:none repeat scroll center center transparent;width:16px!important;height:16px!important;display:none;overflow:visible!important;position:absolute!important;text-indent:0!important;z-index:2147483635!important;max-width:none!important;min-width:0!important;max-height:none!important;min-height:0!important;left:535px;top:159px;bottom:auto!important;right:auto!important;line-height:16px!important;white-space:nowrap!important;visibility:hidden;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" /><img class=\"linkscent-icon\" style=\"float:none!important;border:0 solid #ff0000!important;width:16px!important;height:16px!important;display:none;overflow:visible!important;position:absolute!important;text-indent:0!important;z-index:2147483635!important;max-width:none!important;min-width:0!important;max-height:none!important;min-height:0!important;left:338px;top:880px;bottom:auto!important;right:auto!important;line-height:16px!important;white-space:nowrap!important;visibility:hidden;background:url('//interclue/content/cluecore/skins/default/linkscentExternal.png') no-repeat scroll center center transparent!important;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" /><img class=\"linkscent-icon\" style=\"float:none!important;border:0 solid #ff0000!important;background:url('//interclue/content/cluecore/skins/default/sprites.png') no-repeat scroll -32px -64px transparent;width:16px!important;height:16px!important;display:none;overflow:visible!important;position:absolute!important;text-indent:0!important;z-index:2147483635!important;max-width:none!important;min-width:0!important;max-height:none!important;min-height:0!important;left:356px;top:880px;bottom:auto!important;right:auto!important;line-height:16px!important;white-space:nowrap!important;visibility:hidden;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" width=\"16\" height=\"16\" /><img class=\"linkscent-icon\" style=\"float:none!important;border:0 solid #ff0000!important;background:none repeat scroll center center transparent;width:16px!important;height:16px!important;display:none;overflow:visible!important;position:absolute!important;text-indent:0!important;z-index:2147483635!important;max-width:none!important;min-width:0!important;max-height:none!important;min-height:0!important;left:374px;top:880px;bottom:auto!important;right:auto!important;line-height:16px!important;white-space:nowrap!important;visibility:hidden;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" /><img class=\"linkscent-icon\" style=\"float:none!important;border:0 solid #ff0000!important;width:16px!important;height:16px!important;display:none;overflow:visible!important;position:absolute!important;text-indent:0!important;z-index:2147483635!important;max-width:none!important;min-width:0!important;max-height:none!important;min-height:0!important;left:597px;top:801px;bottom:auto!important;right:auto!important;line-height:16px!important;white-space:nowrap!important;visibility:hidden;background:url('http://prezi.com/favicon.ico') no-repeat scroll center center transparent!important;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" /><img class=\"linkscent-icon\" style=\"float:none!important;border:0 solid #ff0000!important;background:none repeat scroll center center transparent;width:16px!important;height:16px!important;display:none;overflow:visible!important;position:absolute!important;text-indent:0!important;z-index:2147483635!important;max-width:none!important;min-width:0!important;max-height:none!important;min-height:0!important;left:615px;top:801px;bottom:auto!important;right:auto!important;line-height:16px!important;white-space:nowrap!important;visibility:hidden;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" /><img class=\"linkscent-icon\" style=\"float:none!important;border:0 solid #ff0000!important;width:16px!important;height:16px!important;display:none;overflow:visible!important;position:absolute!important;text-indent:0!important;z-index:2147483635!important;max-width:none!important;min-width:0!important;max-height:none!important;min-height:0!important;left:214px;top:500px;bottom:auto!important;right:auto!important;line-height:16px!important;white-space:nowrap!important;visibility:hidden;background:url('http://nlabrot.blogspot.com/favicon.ico') no-repeat scroll center center transparent!important;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" /><img class=\"linkscent-icon\" style=\"float:none!important;border:0 solid #ff0000!important;background:none repeat scroll center center transparent;width:16px!important;height:16px!important;display:none;overflow:visible!important;position:absolute!important;text-indent:0!important;z-index:2147483635!important;max-width:none!important;min-width:0!important;max-height:none!important;min-height:0!important;left:232px;top:500px;bottom:auto!important;right:auto!important;line-height:16px!important;white-space:nowrap!important;visibility:hidden;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" /><img class=\"linkscent-icon\" style=\"float:none!important;border:0 solid #ff0000!important;width:16px!important;height:16px!important;display:none;overflow:visible!important;position:absolute!important;text-indent:0!important;z-index:2147483635!important;max-width:none!important;min-width:0!important;max-height:none!important;min-height:0!important;left:437px;top:910px;bottom:auto!important;right:auto!important;line-height:16px!important;white-space:nowrap!important;visibility:hidden;background:url('//interclue/content/cluecore/skins/default/linkscentExternal.png') no-repeat scroll center center transparent!important;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" /><img class=\"linkscent-icon\" style=\"float:none!important;border:0 solid #ff0000!important;background:url('//interclue/content/cluecore/skins/default/sprites.png') no-repeat scroll -48px -96px transparent;width:16px!important;height:16px!important;display:none;overflow:visible!important;position:absolute!important;text-indent:0!important;z-index:2147483635!important;max-width:none!important;min-width:0!important;max-height:none!important;min-height:0!important;left:455px;top:910px;bottom:auto!important;right:auto!important;line-height:16px!important;white-space:nowrap!important;visibility:hidden;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" width=\"16\" height=\"16\" /><img class=\"linkscent-icon\" style=\"float:none!important;border:0 solid #ff0000!important;background:none repeat scroll center center transparent;width:16px!important;height:16px!important;display:none;overflow:visible!important;position:absolute!important;text-indent:0!important;z-index:2147483635!important;max-width:none!important;min-width:0!important;max-height:none!important;min-height:0!important;left:473px;top:910px;bottom:auto!important;right:auto!important;line-height:16px!important;white-space:nowrap!important;visibility:hidden;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" /><img class=\"linkscent-icon\" style=\"float:none!important;border:0 solid #ff0000!important;width:16px!important;height:16px!important;display:none;overflow:visible!important;position:absolute!important;text-indent:0!important;z-index:2147483635!important;max-width:none!important;min-width:0!important;max-height:none!important;min-height:0!important;left:772px;top:834px;bottom:auto!important;right:auto!important;line-height:16px!important;white-space:nowrap!important;visibility:hidden;background:url('http://amazon.com/favicon.ico') no-repeat scroll center center transparent!important;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" /><img class=\"linkscent-icon\" style=\"float:none!important;border:0 solid #ff0000!important;background:none repeat scroll center center transparent;width:16px!important;height:16px!important;display:none;overflow:visible!important;position:absolute!important;text-indent:0!important;z-index:2147483635!important;max-width:none!important;min-width:0!important;max-height:none!important;min-height:0!important;left:790px;top:834px;bottom:auto!important;right:auto!important;line-height:16px!important;white-space:nowrap!important;visibility:hidden;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" /><img class=\"linkscent-icon\" style=\"float:none!important;border:0 solid #ff0000!important;width:16px!important;height:16px!important;display:none;overflow:visible!important;position:absolute!important;text-indent:0!important;z-index:2147483635!important;max-width:none!important;min-width:0!important;max-height:none!important;min-height:0!important;left:202px;top:348px;bottom:auto!important;right:auto!important;line-height:16px!important;white-space:nowrap!important;visibility:hidden;background:url('http://java.dzone.com/favicon.ico') no-repeat scroll center center transparent!important;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" /><img class=\"linkscent-icon\" style=\"float:none!important;border:0 solid #ff0000!important;background:none repeat scroll center center transparent;width:16px!important;height:16px!important;display:none;overflow:visible!important;position:absolute!important;text-indent:0!important;z-index:2147483635!important;max-width:none!important;min-width:0!important;max-height:none!important;min-height:0!important;left:220px;top:348px;bottom:auto!important;right:auto!important;line-height:16px!important;white-space:nowrap!important;visibility:hidden;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" /></div>\r\n<div class=\"linkscent-iconblock\" style=\"float:none!important;border:0 solid #ff0000!important;background:none repeat scroll center center transparent!important;width:auto!important;height:auto!important;display:block!important;overflow:visible!important;position:static!important;text-indent:0!important;z-index:auto!important;max-width:none!important;min-width:0!important;max-height:none!important;min-height:0!important;left:auto!important;top:auto!important;bottom:auto!important;right:auto!important;line-height:16px!important;white-space:nowrap!important;margin:0!important;padding:0!important;\"><img class=\"linkscent-icon\" style=\"float:none!important;border:0 solid #ff0000!important;width:16px!important;height:16px!important;display:none;overflow:visible!important;position:absolute!important;text-indent:0!important;z-index:2147483635!important;max-width:none!important;min-width:0!important;max-height:none!important;min-height:0!important;left:270px;top:481px;bottom:auto!important;right:auto!important;line-height:16px!important;white-space:nowrap!important;visibility:hidden;background:url('http://architects.dzone.com/favicon.ico') no-repeat scroll center center transparent!important;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" /><img class=\"linkscent-icon\" style=\"float:none!important;border:0 solid #ff0000!important;background:none repeat scroll center center transparent;width:16px!important;height:16px!important;display:none;overflow:visible!important;position:absolute!important;text-indent:0!important;z-index:2147483635!important;max-width:none!important;min-width:0!important;max-height:none!important;min-height:0!important;left:288px;top:481px;bottom:auto!important;right:auto!important;line-height:16px!important;white-space:nowrap!important;visibility:hidden;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" /></div>\r\n<div class=\"linkscent-iconblock\" style=\"float:none!important;border:0 solid #ff0000!important;background:none repeat scroll center center transparent!important;width:auto!important;height:auto!important;display:block!important;overflow:visible!important;position:static!important;text-indent:0!important;z-index:auto!important;max-width:none!important;min-width:0!important;max-height:none!important;min-height:0!important;left:auto!important;top:auto!important;bottom:auto!important;right:auto!important;line-height:16px!important;white-space:nowrap!important;margin:0!important;padding:0!important;\"><img class=\"linkscent-icon\" style=\"float:none!important;border:0 solid #ff0000!important;width:16px!important;height:16px!important;display:none;overflow:visible!important;position:absolute!important;text-indent:0!important;z-index:2147483635!important;max-width:none!important;min-width:0!important;max-height:none!important;min-height:0!important;left:433px;top:595px;bottom:auto!important;right:auto!important;line-height:16px!important;white-space:nowrap!important;visibility:hidden;background:url('http://www.texterity.com/favicon.ico') no-repeat scroll center center transparent!important;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" /><img class=\"linkscent-icon\" style=\"float:none!important;border:0 solid #ff0000!important;background:url('//interclue/content/cluecore/skins/default/sprites.png') no-repeat scroll -32px -64px transparent;width:16px!important;height:16px!important;display:none;overflow:visible!important;position:absolute!important;text-indent:0!important;z-index:2147483635!important;max-width:none!important;min-width:0!important;max-height:none!important;min-height:0!important;left:451px;top:595px;bottom:auto!important;right:auto!important;line-height:16px!important;white-space:nowrap!important;visibility:hidden;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" width=\"16\" height=\"16\" /><img class=\"linkscent-icon\" style=\"float:none!important;border:0 solid #ff0000!important;background:url('//interclue/content/cluecore/skins/default/sprites.png') no-repeat scroll -48px -96px transparent;width:16px!important;height:16px!important;display:none;overflow:visible!important;position:absolute!important;text-indent:0!important;z-index:2147483635!important;max-width:none!important;min-width:0!important;max-height:none!important;min-height:0!important;left:469px;top:595px;bottom:auto!important;right:auto!important;line-height:16px!important;white-space:nowrap!important;visibility:hidden;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" width=\"16\" height=\"16\" /><img class=\"linkscent-icon\" style=\"float:none!important;border:0 solid #ff0000!important;background:none repeat scroll center center transparent;width:16px!important;height:16px!important;display:none;overflow:visible!important;position:absolute!important;text-indent:0!important;z-index:2147483635!important;max-width:none!important;min-width:0!important;max-height:none!important;min-height:0!important;left:487px;top:595px;bottom:auto!important;right:auto!important;line-height:16px!important;white-space:nowrap!important;visibility:hidden;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" /></div>\r\n<div class=\"linkscent-iconblock\" style=\"float:none!important;border:0 solid #ff0000!important;background:none repeat scroll center center transparent!important;width:auto!important;height:auto!important;display:block!important;overflow:visible!important;position:static!important;text-indent:0!important;z-index:auto!important;max-width:none!important;min-width:0!important;max-height:none!important;min-height:0!important;left:auto!important;top:auto!important;bottom:auto!important;right:auto!important;line-height:16px!important;white-space:nowrap!important;margin:0!important;padding:0!important;\"><img class=\"linkscent-icon\" style=\"float:none!important;border:0 solid #ff0000!important;width:16px!important;height:16px!important;display:none;overflow:visible!important;position:absolute!important;text-indent:0!important;z-index:2147483635!important;max-width:none!important;min-width:0!important;max-height:none!important;min-height:0!important;left:346px;top:652px;bottom:auto!important;right:auto!important;line-height:16px!important;white-space:nowrap!important;visibility:hidden;background:url('http://www.texterity.com/favicon.ico') no-repeat scroll center center transparent!important;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" /><img class=\"linkscent-icon\" style=\"float:none!important;border:0 solid #ff0000!important;background:url('//interclue/content/cluecore/skins/default/sprites.png') no-repeat scroll -32px -64px transparent;width:16px!important;height:16px!important;display:none;overflow:visible!important;position:absolute!important;text-indent:0!important;z-index:2147483635!important;max-width:none!important;min-width:0!important;max-height:none!important;min-height:0!important;left:364px;top:652px;bottom:auto!important;right:auto!important;line-height:16px!important;white-space:nowrap!important;visibility:hidden;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" width=\"16\" height=\"16\" /><img class=\"linkscent-icon\" style=\"float:none!important;border:0 solid #ff0000!important;background:url('//interclue/content/cluecore/skins/default/sprites.png') no-repeat scroll -48px -96px transparent;width:16px!important;height:16px!important;display:none;overflow:visible!important;position:absolute!important;text-indent:0!important;z-index:2147483635!important;max-width:none!important;min-width:0!important;max-height:none!important;min-height:0!important;left:382px;top:652px;bottom:auto!important;right:auto!important;line-height:16px!important;white-space:nowrap!important;visibility:hidden;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" width=\"16\" height=\"16\" /><img class=\"linkscent-icon\" style=\"float:none!important;border:0 solid #ff0000!important;background:none repeat scroll center center transparent;width:16px!important;height:16px!important;display:none;overflow:visible!important;position:absolute!important;text-indent:0!important;z-index:2147483635!important;max-width:none!important;min-width:0!important;max-height:none!important;min-height:0!important;left:400px;top:652px;bottom:auto!important;right:auto!important;line-height:16px!important;white-space:nowrap!important;visibility:hidden;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" /></div>\r\n<div class=\"linkscent-iconblock\" style=\"float:none!important;border:0 solid #ff0000!important;background:none repeat scroll center center transparent!important;width:auto!important;height:auto!important;display:block!important;overflow:visible!important;position:static!important;text-indent:0!important;z-index:auto!important;max-width:none!important;min-width:0!important;max-height:none!important;min-height:0!important;left:auto!important;top:auto!important;bottom:auto!important;right:auto!important;line-height:16px!important;white-space:nowrap!important;margin:0!important;padding:0!important;\"><img class=\"linkscent-icon\" style=\"float:none!important;border:0 solid #ff0000!important;width:16px!important;height:16px!important;display:block;overflow:visible!important;position:absolute!important;text-indent:0!important;z-index:2147483635!important;max-width:none!important;min-width:0!important;max-height:none!important;min-height:0!important;left:437px;top:1531px;bottom:auto!important;right:auto!important;line-height:16px!important;white-space:nowrap!important;visibility:visible;background:url('//interclue/content/cluecore/skins/default/linkscentExternal.png') no-repeat scroll center center transparent!important;opacity:1;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" /><img class=\"linkscent-icon\" style=\"float:none!important;border:0 solid #ff0000!important;background:none repeat scroll center center transparent;width:16px!important;height:16px!important;display:none;overflow:visible!important;position:absolute!important;text-indent:0!important;z-index:2147483635!important;max-width:none!important;min-width:0!important;max-height:none!important;min-height:0!important;left:455px;top:1531px;bottom:auto!important;right:auto!important;line-height:16px!important;white-space:nowrap!important;visibility:hidden;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" /></div>\r\n<div class=\"linkscent-iconblock\" style=\"float:none!important;border:0 solid #ff0000!important;background:none repeat scroll center center transparent!important;width:auto!important;height:auto!important;display:block!important;overflow:visible!important;position:static!important;text-indent:0!important;z-index:auto!important;max-width:none!important;min-width:0!important;max-height:none!important;min-height:0!important;left:auto!important;top:auto!important;bottom:auto!important;right:auto!important;line-height:16px!important;white-space:nowrap!important;margin:0!important;padding:0!important;\"><img class=\"linkscent-icon\" style=\"float:none!important;border:0 solid #ff0000!important;width:16px!important;height:16px!important;display:none;overflow:visible!important;position:absolute!important;text-indent:0!important;z-index:2147483635!important;max-width:none!important;min-width:0!important;max-height:none!important;min-height:0!important;left:461px;top:158px;bottom:auto!important;right:auto!important;line-height:16px!important;white-space:nowrap!important;visibility:hidden;background:url('http://www.infoq.com/favicon.ico') no-repeat scroll center center transparent!important;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" /><img class=\"linkscent-icon\" style=\"float:none!important;border:0 solid #ff0000!important;background:none repeat scroll center center transparent;width:16px!important;height:16px!important;display:none;overflow:visible!important;position:absolute!important;text-indent:0!important;z-index:2147483635!important;max-width:none!important;min-width:0!important;max-height:none!important;min-height:0!important;left:479px;top:158px;bottom:auto!important;right:auto!important;line-height:16px!important;white-space:nowrap!important;visibility:hidden;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" /><img class=\"linkscent-icon\" style=\"float:none!important;border:0 solid #ff0000!important;width:16px!important;height:16px!important;display:none;overflow:visible!important;position:absolute!important;text-indent:0!important;z-index:2147483635!important;max-width:none!important;min-width:0!important;max-height:none!important;min-height:0!important;left:214px;top:1227px;bottom:auto!important;right:auto!important;line-height:16px!important;white-space:nowrap!important;visibility:hidden;background:url('http://nlabrot.blogspot.com/favicon.ico') no-repeat scroll center center transparent!important;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" /><img class=\"linkscent-icon\" style=\"float:none!important;border:0 solid #ff0000!important;background:none repeat scroll center center transparent;width:16px!important;height:16px!important;display:none;overflow:visible!important;position:absolute!important;text-indent:0!important;z-index:2147483635!important;max-width:none!important;min-width:0!important;max-height:none!important;min-height:0!important;left:232px;top:1227px;bottom:auto!important;right:auto!important;line-height:16px!important;white-space:nowrap!important;visibility:hidden;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" /><img class=\"linkscent-icon\" style=\"float:none!important;border:0 solid #ff0000!important;width:16px!important;height:16px!important;display:none;overflow:visible!important;position:absolute!important;text-indent:0!important;z-index:2147483635!important;max-width:none!important;min-width:0!important;max-height:none!important;min-height:0!important;left:352px;top:691px;bottom:auto!important;right:auto!important;line-height:16px!important;white-space:nowrap!important;visibility:hidden;background:url('//www.owasp.org/favicon.ico') no-repeat scroll center center transparent!important;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" /><img class=\"linkscent-icon\" style=\"float:none!important;border:0 solid #ff0000!important;background:url('//interclue/content/cluecore/skins/default/sprites.png') no-repeat scroll -144px -96px transparent;width:16px!important;height:16px!important;display:none;overflow:visible!important;position:absolute!important;text-indent:0!important;z-index:2147483635!important;max-width:none!important;min-width:0!important;max-height:none!important;min-height:0!important;left:370px;top:691px;bottom:auto!important;right:auto!important;line-height:16px!important;white-space:nowrap!important;visibility:hidden;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" width=\"16\" height=\"16\" /><img class=\"linkscent-icon\" style=\"float:none!important;border:0 solid #ff0000!important;background:none repeat scroll center center transparent;width:16px!important;height:16px!important;display:none;overflow:visible!important;position:absolute!important;text-indent:0!important;z-index:2147483635!important;max-width:none!important;min-width:0!important;max-height:none!important;min-height:0!important;left:388px;top:691px;bottom:auto!important;right:auto!important;line-height:16px!important;white-space:nowrap!important;visibility:hidden;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" /></div>\r\n<div class=\"linkscent-iconblock\" style=\"float:none!important;border:0 solid #ff0000!important;background:none repeat scroll center center transparent!important;width:auto!important;height:auto!important;display:block!important;overflow:visible!important;position:static!important;text-indent:0!important;z-index:auto!important;max-width:none!important;min-width:0!important;max-height:none!important;min-height:0!important;left:auto!important;top:auto!important;bottom:auto!important;right:auto!important;line-height:16px!important;white-space:nowrap!important;margin:0!important;padding:0!important;\"><img class=\"linkscent-icon\" style=\"float:none!important;border:0 solid #ff0000!important;width:16px!important;height:16px!important;display:none;overflow:visible!important;position:absolute!important;text-indent:0!important;z-index:2147483635!important;max-width:none!important;min-width:0!important;max-height:none!important;min-height:0!important;left:433px;top:463px;bottom:auto!important;right:auto!important;line-height:16px!important;white-space:nowrap!important;visibility:hidden;background:url('//interclue/content/cluecore/skins/default/linkscentExternal.png') no-repeat scroll center center transparent!important;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" /><img class=\"linkscent-icon\" style=\"float:none!important;border:0 solid #ff0000!important;background:url('//interclue/content/cluecore/skins/default/sprites.png') no-repeat scroll -32px -64px transparent;width:16px!important;height:16px!important;display:none;overflow:visible!important;position:absolute!important;text-indent:0!important;z-index:2147483635!important;max-width:none!important;min-width:0!important;max-height:none!important;min-height:0!important;left:451px;top:463px;bottom:auto!important;right:auto!important;line-height:16px!important;white-space:nowrap!important;visibility:hidden;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" width=\"16\" height=\"16\" /><img class=\"linkscent-icon\" style=\"float:none!important;border:0 solid #ff0000!important;background:none repeat scroll center center transparent;width:16px!important;height:16px!important;display:none;overflow:visible!important;position:absolute!important;text-indent:0!important;z-index:2147483635!important;max-width:none!important;min-width:0!important;max-height:none!important;min-height:0!important;left:469px;top:463px;bottom:auto!important;right:auto!important;line-height:16px!important;white-space:nowrap!important;visibility:hidden;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" /><img class=\"linkscent-icon\" style=\"float:none!important;border:0 solid #ff0000!important;width:16px!important;height:16px!important;display:none;overflow:visible!important;position:absolute!important;text-indent:0!important;z-index:2147483635!important;max-width:none!important;min-width:0!important;max-height:none!important;min-height:0!important;left:531px;top:2448px;bottom:auto!important;right:auto!important;line-height:16px!important;white-space:nowrap!important;visibility:hidden;background:url('http://www.amazon.com/favicon.ico') no-repeat scroll center center transparent!important;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" /><img class=\"linkscent-icon\" style=\"float:none!important;border:0 solid #ff0000!important;background:url('//interclue/content/cluecore/skins/default/sprites.png') no-repeat scroll -48px -96px transparent;width:16px!important;height:16px!important;display:none;overflow:visible!important;position:absolute!important;text-indent:0!important;z-index:2147483635!important;max-width:none!important;min-width:0!important;max-height:none!important;min-height:0!important;left:549px;top:2448px;bottom:auto!important;right:auto!important;line-height:16px!important;white-space:nowrap!important;visibility:hidden;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" width=\"16\" height=\"16\" /><img class=\"linkscent-icon\" style=\"float:none!important;border:0 solid #ff0000!important;background:none repeat scroll center center transparent;width:16px!important;height:16px!important;display:none;overflow:visible!important;position:absolute!important;text-indent:0!important;z-index:2147483635!important;max-width:none!important;min-width:0!important;max-height:none!important;min-height:0!important;left:567px;top:2448px;bottom:auto!important;right:auto!important;line-height:16px!important;white-space:nowrap!important;visibility:hidden;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" /></div>\r\n<div class=\"linkscent-iconblock\" style=\"float:none!important;border:0 solid #ff0000!important;background:none repeat scroll center center transparent!important;width:auto!important;height:auto!important;display:block!important;overflow:visible!important;position:static!important;text-indent:0!important;z-index:auto!important;max-width:none!important;min-width:0!important;max-height:none!important;min-height:0!important;left:auto!important;top:auto!important;bottom:auto!important;right:auto!important;line-height:16px!important;white-space:nowrap!important;margin:0!important;padding:0!important;\"><img class=\"linkscent-icon\" style=\"float:none!important;border:0 solid #ff0000!important;width:16px!important;height:16px!important;display:none;overflow:visible!important;position:absolute!important;text-indent:0!important;z-index:2147483635!important;max-width:none!important;min-width:0!important;max-height:none!important;min-height:0!important;left:597px;top:1055px;bottom:auto!important;right:auto!important;line-height:16px!important;white-space:nowrap!important;visibility:hidden;background:url('http://prezi.com/favicon.ico') no-repeat scroll center center transparent!important;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" /><img class=\"linkscent-icon\" style=\"float:none!important;border:0 solid #ff0000!important;background:none repeat scroll center center transparent;width:16px!important;height:16px!important;display:none;overflow:visible!important;position:absolute!important;text-indent:0!important;z-index:2147483635!important;max-width:none!important;min-width:0!important;max-height:none!important;min-height:0!important;left:615px;top:1055px;bottom:auto!important;right:auto!important;line-height:16px!important;white-space:nowrap!important;visibility:hidden;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" /></div>\r\n<div class=\"linkscent-iconblock\" style=\"float:none!important;border:0 solid #ff0000!important;background:none repeat scroll center center transparent!important;width:auto!important;height:auto!important;display:block!important;overflow:visible!important;position:static!important;text-indent:0!important;z-index:auto!important;max-width:none!important;min-width:0!important;max-height:none!important;min-height:0!important;left:auto!important;top:auto!important;bottom:auto!important;right:auto!important;line-height:16px!important;white-space:nowrap!important;margin:0!important;padding:0!important;\"><img class=\"linkscent-icon\" style=\"float:none!important;border:0 solid #ff0000!important;width:16px!important;height:16px!important;display:none;overflow:visible!important;position:absolute!important;text-indent:0!important;z-index:2147483635!important;max-width:none!important;min-width:0!important;max-height:none!important;min-height:0!important;left:517px;top:215px;bottom:auto!important;right:auto!important;line-height:16px!important;white-space:nowrap!important;visibility:hidden;background:url('//interclue/content/cluecore/skins/default/linkscentExternal.png') no-repeat scroll center center transparent!important;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" /><img class=\"linkscent-icon\" style=\"float:none!important;border:0 solid #ff0000!important;background:none repeat scroll center center transparent;width:16px!important;height:16px!important;display:none;overflow:visible!important;position:absolute!important;text-indent:0!important;z-index:2147483635!important;max-width:none!important;min-width:0!important;max-height:none!important;min-height:0!important;left:535px;top:215px;bottom:auto!important;right:auto!important;line-height:16px!important;white-space:nowrap!important;visibility:hidden;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" /><img class=\"linkscent-icon\" style=\"float:none!important;border:0 solid #ff0000!important;width:16px!important;height:16px!important;display:none;overflow:visible!important;position:absolute!important;text-indent:0!important;z-index:2147483635!important;max-width:none!important;min-width:0!important;max-height:none!important;min-height:0!important;left:259px;top:938px;bottom:auto!important;right:auto!important;line-height:16px!important;white-space:nowrap!important;visibility:hidden;background:url('http://www.infoq.com/favicon.ico') no-repeat scroll center center transparent!important;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" /><img class=\"linkscent-icon\" style=\"float:none!important;border:0 solid #ff0000!important;background:none repeat scroll center center transparent;width:16px!important;height:16px!important;display:none;overflow:visible!important;position:absolute!important;text-indent:0!important;z-index:2147483635!important;max-width:none!important;min-width:0!important;max-height:none!important;min-height:0!important;left:277px;top:938px;bottom:auto!important;right:auto!important;line-height:16px!important;white-space:nowrap!important;visibility:hidden;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" /></div>",
  "excerpt": ""
 },
 {
  "title": "Book Review: Agile Project Management With Scrum",
  "published": "2011-11-07 20:19:05",
  "postType": "post",
  "slug": "/2011/11/07/book-review-agile-project-management-with-scrum/",
  "status": "publish",
  "tags": [
   "agile",
   "book",
   "review",
   "scrum"
  ],
  "categories": [
   "General"
  ],
  "content": "A review of and extract from <em><a href=\"http://amzn.com/073561993X\">Agile Project Management With Scrum</a></em> by Ken Schwaber, Microsoft Press 2003, ISBN 0-7356-1993-X.<br><br>The book is basically a set of case studies about Scrum that show how to implement the individual aspects of Scrum, what are the common pitfalls and how to avoid them, and help to understand its mantra of \"the art of the possible\" and how to adapt Scrum to various situations. It's very easy to read thanks to the case studies being brief and organized by topics (team, product owner, ...). I'd absolutely recommend it as a third book in this domain, after a general introduction into the lean thinking (<a href=\"http://amzn.com/0321437381\">Implementing Lean Software Development – From Concept to Cash</a> by M. &amp; T. Poppendieck is great for that) and an introduction into Scrum itself. Scrum is not just a set of practices, it requires an essential shift in thinking. Thus it is not enough to learn about the practices - you have to learn, understand, and accept the principles behind. This book will hopefully help you to refine your understanding of these principles.\r\n<h2>Extract</h2>\r\nThis extract contains the quotes and observations that I find the most interesting. It tries by no means to be objective or representative, a different person with a different experience and background would certainly pick different ones. Thus its value for others than myself is rather limited but it may perhaps serve as an inspiration to read the book. My all favourite quotes are in <span title=\"Well, strictly speaking they are inside &lt;em&gt; but you got what I mean :-)\"><em>italics</em><span>.<!--more-->\r\n<ul>\r\n\t<li>Scrum doesn’t ensure that the project will go as expected and yield exactly the predicted results, rather “Scrum controls the process of software development to guide work towards the most valuable outcome possible.” p2</li>\r\n</ul>\r\n<h3>3. The ScrumMaster</h3>\r\n<ul>\r\n\t<li>a Scrum master doesn’t control but facilitates, the team must be self-organizing and figure itself the best way to accomplish its goals</li>\r\n\t<li>this is important so that team members don’t miss “the deep personal commitment that emerges when people puzzle their way through their work on their own.” p 28</li>\r\n\t<li>“<em>The team’s ability to tackle its problems and solve them is the heart of Scrum and the basis of the Scrum team’s extraordinary productivity.</em>” p28</li>\r\n</ul>\r\n<h3>4. Bringing Order From Chaos</h3>\r\n<ul>\r\n\t<li>\"For Scrum to work the team has to deeply and viscerally understand collective commitment and self-organization<em>.\"</em> p48</li>\r\n\t<li>From a case study: “Until the team actually used Scrum to solve some of the problems it was facing, the team wouldn’t really grasp Scrum.” p52</li>\r\n</ul>\r\n<h3>6. Planning a Scrum Project</h3>\r\n<ul>\r\n\t<li>“The nature of complex problems is such that very small variations in any aspect of the problem can cause extreely large and unpredictable variations in how the problem manifests itself. So no matter how much time we spent improving the accuracy of our estimates, the estimates would still be wildly inaccurate.” p70</li>\r\n\t<li>\"the purpose of estimating is to get a handle on the size of each requirement, both in its own right and relative to the size of the other requirements. p70</li>\r\n</ul>\r\n<h3>7. Project Reporting - Keeping Everything Visible</h3>\r\n<ul>\r\n\t<li>Scrum doesn’t generate traditional project status reports, however most manager are satisfied with what it provides when they get used to it - the trick is to get over the first few Sprints. To help the managers to transition to Scrum, you may devise any number of ancillary reporting mechanisms to Scrum.</li>\r\n\t<li>“<em>But keep in mind that Scrum represents a major shift in thinking and acting, and many people don’t really understand Scrum until they have experienced it.</em>” p95</li>\r\n\t<li>it’s meaningless to say at the Daily Standup that you have been testing or fixing or whatever. “Without each team member clearly identifying what he or she was working on, the Daily Scrum was useless. No real commitments were being made and checked on. Nobody knew the areas of code their teammates were looking at, so they could not offer advice or help.” p96</li>\r\n\t<li>“[..] Scrum works only when everything is visible and everyone can inspect progress and recommend adaptations.” p98 (regarding the Daily Standup)</li>\r\n\t<li>“To manage itself, a team must have a plan and report against that plan. The details of the plan and the reporting must be specific enough to be meaningfull. The team has to be able to synchronize its work.” p99</li>\r\n\t<li>“The Sprint Backlog is the visible manifestation of the team fulfilling his responsability. ” [for planning its own work] p 99</li>\r\n</ul>\r\n<h3>8. The Team</h3>\r\nThe meaning of the Daily Scrum:\r\n<ul>\r\n\t<li>A stand-in ScrumMaster, George, felt that something was amiss during Daily Scrums. “After several days, he realized that <em>he heard hardly any requests for help or offers of help. There were no side comments that the had to contain to keep the meeting to 15 minutes. [..] George figured out why. As team members reported progress, they were looking at George instead of at other team members. They were [..] reporting to George</em>, who they saw as their project manager. Even though they have been told otherwise, the team members still felt that George was in charge and though that the Daily Scrum was a meeting at which they would report to him, and not a forum at which they’d synchronize with each other.” p104</li>\r\n\t<li>“A Team requires concrete experience with Scrum before it can truly understand how to manage itself and how to take the responsability and authority for planning and conducting its own activities.” p 105</li>\r\n</ul>\r\nIncrement of potentially shippable product functionality (and indirectly the definition of done):\r\n<ul>\r\n\t<li>“[..] I went over the concept of an increment of potentially shippable product functionality. Each Sprint, the Team commits to turning selected Product Backlog into such an increment. For the functionality to be potentially shippable, it has to be clean. [..] clean code not only has to be free from bugs, but must also adhere to coding standards, have been refactored to remove any duplication or ill-structured code, contain no clever programming tricks, and be easy to read and understand. Code has to be all of these things to be sustainable and maintainable. If code isn’t clean in all of these respects, developing functionality in future Sprints will take more and more time. The code will become more turgid, , unreadable, and difficult to debug.” p105 Only such, truly done, code can be presented to the Product Owner.</li>\r\n\t<li>On the importance of daily synchronization of team members: “Otherwise, team members might make incorrect assumptions about the completeness and adequacy of their work.” p106 (as the changes by others may negate or diminish the effects of their work)</li>\r\n\t<li>“Just as at the end of the Sprint, every day this code had to be clean - or else the inspection and adaptation mechanisms of Scrum wouldn’t work.” p106 (=&gt; check in, build, test daily) - for the team needs to know exactly where it is and where it isn’t</li>\r\n\t<li>“<em>Scrum, however, requires engineering excellence for its inspect and adapt practices to work.</em>” p107</li>\r\n\t<li>“Many business relationships are based on contracts and predictability that don’t tolerate the imprecision inherent in an estimate.” p111 (e.g. when promising the delivery of a functionality to a client)</li>\r\n\t<li>“Combine this imprecision [of communication from the customer to a fully developed system] with all of the other imprecise communication of expectations, with the imprecision and truculence of the technology being used, with the fact that people are doing the work, and any estimate of a release date becomes suspect.” p111</li>\r\n\t<li>=&gt; Thus an empirical process based on inspect &amp; adapt cycles is appropriate</li>\r\n\t<li>Teams tend to overcommit at the 1st spring, undercommit at the 2nd, but usually become quite accurate by the 3rd or 4th one</li>\r\n\t<li>“<em>The Product Owner and stakeholders are driving the development cycle by trading off functionality and time.</em>” p112</li>\r\n</ul>\r\n<h3>Appendix D: Fixed-Price, Fixed-Date Contracts</h3>\r\n<ul>\r\n\t<li>a mismatch between such contracts and Scrum: “<em>Scrum’s principle is ‘the art of the possible,’</em> not ’you give me what I paid for, when you said that you’d deliver it.” p147</li>\r\n\t<li>“[..] I realized that Scrum had no silver bullet - it had to go about addressing fixed-price, fixed-date contracts exactly the way any other process would [..]. There simply was no way around analyzing the customer’s requirements enough to understand the number and complexity of the architecture and design artifacts.” p147</li>\r\n\t<li>When using Scrum to bid on a f-p, f-d RFP, you’d parse the requirements into a (priority-ordered) backlog and communicate to the customer that the system wouldn’t be delivered all at once but incrementally, with early feedback, and the possibility to change some lower-priority items (e.g. due to changing business conditions) with minimum fuss, explaining that thus most likely ~80% of the expected value would be delivered when ~20% of the functionality is done - you could offer the possibility to finish the project prematurely, when enough business value had been derived (with some penalty, but less than the cost of unnecessary development)</li>\r\n\t<li>“Using Scrum in fixed-price, fixed-date situations presents an opportunity, but only if your audience knows how to listen and is willing to listen.” p149</li>\r\n</ul>\r\n<h3>Appendix E: Capability Maturity Model (CMM)</h3>\r\nFrom a discussion about CMM and Scrum:\r\n<ul>\r\n\t<li>“Even though Scrum took an empirical approach, someone employing its practices would satisfy all of the CMM level 2 KPAs [key practice areas] and many of the level 3 KPAs. The KPAs that weren’t satisfied at level 3 were those that addressed institutionalizing the practices. These KPAs were addressed in 2003 when the Scrum Methodology, the Certified Scrum Program, and Project Quickstart were made available as products.” p152</li>\r\n\t<li>F.ex. its empirical approach to requirements traceability through the end-of-sprint demonstration of the functionality developed “meets the requirements of the [requirements management] KPA without extensive documentation or overhead to the development process.” p153</li>\r\n</ul>",
  "excerpt": ""
 },
 {
  "title": "What Is CDI, How Does It Relate to @EJB And Spring?",
  "published": "2011-11-09 11:22:38",
  "postType": "post",
  "slug": "/2011/11/09/what-is-cdi-how-does-it-relate-to-ejb-and-spring/",
  "status": "publish",
  "tags": [
   "javaEE",
   "spring"
  ],
  "categories": [
   "j2ee"
  ],
  "content": "A brief overview of dependency injection in Java EE, the difference between @Resource/@EJB and @Inject, and how does that all relate to Spring - mostly in the form of links.<br><br><em>Context Dependency Injection</em> (CDI, <a href=\"http://jcp.org/en/jsr/detail?id=299\">JSR 299</a>) is a part of Java EE 6 Web Profile and itself builds on <em>Dependency Injection for Java</em> (<a href=\"http://jcp.org/en/jsr/detail?id=330\">JSR 330</a>), which introduces @Inject, @Named etc. While JSR 330 is for DI only and is implemented e.g. by Guice and Spring, CDI adds various EE stuff such as @RequestScoped, interceptors/decorators, producers, eventing and a base for integration with JSF, EJBs etc. Java EE components such as EJBs have been redefined to build on top of CDI (=&gt; @Stateless is now a CDI managed bean with additional services).<br><br>A key part of CDI aside of its DI capabilities is its awarness of bean contexts and the management of bean lifecycle and dependencies within those contexts (such as @RequestScoped or @ConversationScoped).<br><br>CDI is extensible - you can define new context scopes, drop-in interceptors and decorators, make other beans (e.g. from Spring) available for CDI,... .<br><br>Resources to check:<!--more-->\r\n<ul>\r\n\t<li><a href=\"http://www.oracle.com/technetwork/articles/java/cdi-javaee-bien-225152.html\">Contexts and Dependency Injection in Java EE 6</a> by Adam Bien - a very good explanation of the basics of CDI and how it differs from DI in Java EE 5 (hint: context awarness)</li>\r\n\t<li>Slideshow with a <a href=\"http://www.slideshare.net/Bozho/contexts-and-dependency-injection-for-the-javaee-platform\">good overview of CDI and all it offers</a></li>\r\n\t<li>About <a href=\"http://www.theserverside.com/tip/Dependency-Injection-in-Java-EE-6-Part-6\">CDI extensibility and SPIs</a> (e.g. Seam 3 is basically a set of portable CDI extensions)</li>\r\n\t<li>Guice and Spring do not implement CDI (3/2011) - and Spring <a href=\"//stackoverflow.com/questions/7238407/will-spring-support-cdi\">perhaps isn't motivated to do so</a> (it supports JSR 330, CDI would be too much work)</li>\r\n<ul>\r\n\t<li>Update: There seems to be an addon <a href=\"http://seamframework.org/Seam3/SpringModule\">Spring/CDI module</a> in development after all...</li>\r\n</ul>\r\n\t<li><a href=\"http://refcardz.dzone.com/refcardz/contexts-and-depencency\">DZone CDI Refcard</a> may be handy</li>\r\n\t<li><a href=\"http://niklasschlimm.blogspot.com/2011/06/cdi-10-vs-spring-31-feature-comparsion.html\">CDI 1.0 vs. Spring 3.1 feature comparsion: bean definition &amp; dependency injection</a>: \"in the area that I compared in this article [= DI], there is only little critical difference in the two technologies\" (though Spring more fine-tunable)</li>\r\n\t<li><a href=\"http://www.adam-bien.com/roller/abien/entry/java_ee_6_cdi_ejb\">Java EE 6 (CDI / EJB 3.1) XOR Spring Core Reloaded</a>: New projects should preferably start with pure Java EE including CDI and add Spring utilities such as JDBC/JMS when needed</li>\r\n\t<li><a href=\"http://www.slideshare.net/arungupta1/richwebex2010-cdi?src=related_normal&amp;rel=5664163\">Oracle: CDI in the Java EE 6 Ecosystem</a> - 62 pages slideshow, the stuff is explained more than in the previously mentioned slideshow</li>\r\n</ul>\r\nNote: CDI 1.1 (<a href=\"http://jcp.org/en/jsr/detail?id=346\">JSR 346</a>, Java EE 7) should have a standard way of bootstrapping it in non-EE environment (i.e. SE)",
  "excerpt": ""
 },
 {
  "title": "Tips And Resources For Creating DSLs in Groovy",
  "published": "2011-11-13 14:05:36",
  "postType": "post",
  "slug": "/2011/11/13/tips-and-resources-for-creating-dlss-in-groovy/",
  "status": "publish",
  "tags": [
   "dsl",
   "groovy",
   "java"
  ],
  "categories": [
   "General",
   "Languages"
  ],
  "content": "Paul King had a very good <a href=\"http://vimeo.com/28763158\">presentation</a> (last year's <a href=\"http://www.slideshare.net/paulk_asert/groovy-dsls-from-beginner-to-expert\">slides</a>) at JavaZone about why to use <a href=\"http://martinfowler.com/bliki/DomainSpecificLanguage.html\">Domain-Specific Languages</a> and how to create <a href=\"http://martinfowler.com/bliki/InternalDslStyle.html\">internal DSLs</a> in Groovy. I'd like to list here few tips that he has mentioned but before we get to that, why would you want to create a DSL? Martin Fowler answers that in his <a href=\"http://www.amazon.com/Domain-Specific-Languages-Addison-Wesley-Signature-Fowler/dp/0321712943\">Domain-Specific Languages book</a> (2010). Some of the reasons are to have a higher-level, more focused and conscise representation that also domain experts can read and perhaps even write. You  have certainly already used a DSL such as regular expressions, CSS, SQL, <a href=\"http://code.google.com/p/spock/\">Spock</a>'s BDD tests, build instructions in <a href=\"http://www.gradle.org/tutorial_using_tasks\">Gradle</a> - these are rather technical but sometimes DSLs are also created to be used by business users, f.ex. for anti-malaria drug resistance simulation. (Want <a href=\"http://www.warneronstine.com/2008/04/24/groovy-dsl-roundup/\">more DSLs in Groovy</a>?).<br><br>Paul mentions one important thing - you can always make your DSL better, i.e. more fail-proof (case insensitive, support plural endings, ...) and secure and more like a natural language but it all comes at a cost and you must evaluate when the cost overweights the benefit (beware the 80:20 rule).<br><br>Some of the Groovy DSL implementation tips:\r\n<!--more-->\r\n<ul>\r\n\t<li>Add methods to any object/class via metaprogramming: &lt;class|instance&gt;.metaclass.&lt;method name or getProperty&gt; = {MyType param -&gt; ... } - you can use 'delegate' to refer to the instance</li>\r\n<ul>\r\n\t<li>notice that <em>getProperty</em> is called for anything that isn't a method as in map['key'] == map.key - useful to implement e.g. 1.kg</li>\r\n\t<li>Call ExpandoMetaClass.enableGlobally() to propagate methods added to Number also to Integer etc.</li>\r\n</ul>\r\n\t<li>Use a GroovyShell and a custom Binding subclass overriding getVariable(String symbol) so as to return/create an object for unknown \"variables\" (ex.: \"newOrder\" -&gt; new Order(), creation of vars for symbols like \"h\", \"km\" etc. =&gt; 24.km/h)</li>\r\n\t<li>Operator overloading: methods of specific names are invoked for operators (/ -&gt; div, * -&gt; multiply etc.)</li>\r\n\t<li>Use a closure setting its delegate and configuring it the cosure's resolve strategy to delegate unknown methods further to the delegate</li>\r\n\t<li>Create a custom Closure subclass and use that for a closure instead of the default one</li>\r\n\t<li>Use Groovy's Categories (st. like a temporary mixin, activated via the use(category) { .. } form) to add localy methods to classes</li>\r\n\t<li>Use Groovy Builders for tree-like DSLs (builder &lt;-&gt; method calls that take a Closure as argument)</li>\r\n\t<li>Use map attributes to get st. resembling named atributes</li>\r\n\t<li>Use GroovyShell with a custom classloader and compilation phase something to prevent calls of other static and instance methods than allowed</li>\r\n</ul>\r\n<h2>Resources</h2>\r\n<ul>\r\n\t<li>Book <a href=\"https://www.packtpub.com/groovy-for-domain-specific-languages-dsl/book\">Groovy for Domain-Specific Languages</a> (a <a href=\"http://blogs.bytecode.com.au/glen/2010/08/18/book-review-groovy-for-domain-specific-languages.html\">review</a>) - I hope I'll get a chance to read this one</li>\r\n\t<li>M. Fowler's <a href=\"http://www.amazon.com/Domain-Specific-Languages-Addison-Wesley-Signature-Fowler/dp/0321712943\">Domain-Specific Languages</a> book</li>\r\n\t<li>Groovy<a href=\"http://groovy.codehaus.org/Writing+Domain-Specific+Languages\"> wiki: Writing Domain-Specific Languages</a></li>\r\n\t<li>DZone: <a href=\"http://groovy.dzone.com/news/domain-specific-language-unit-\">Unit-specific DSL using JScience</a>, using Groovy</li>\r\n\t<li>M. Fowler's <a href=\"http://martinfowler.com/dslCatalog/\">DSL Patterns Catalog</a></li>\r\n</ul>\r\nPS: The latest release of Groovy in Action should also contain a chapter on DSLs.",
  "excerpt": ""
 },
 {
  "title": "How to Fail With Drools or Any Other Tool/Framework/Library",
  "published": "2011-11-20 16:25:07",
  "postType": "post",
  "slug": "/2011/11/20/how-to-fail-with-drools-or-any-other-toolframeworklibrary/",
  "status": "publish",
  "tags": [
   "architecture",
   "opinion"
  ],
  "categories": [
   "General"
  ],
  "content": "What I like most at conferences are reports of someone's failure to do or implement something for they're the best sources of learning. And <a href=\"http://vimeo.com/28716168\">How to Fail with Drools (in Norwegian)</a> by C. Dannevig of Know IT at JavaZone 2011 is one of them. I'd like to summarize what they learned and extend it for introduction of a tool, framework, or library in general based on my own painful experiences.<br><br>They decided to switch to the <a href=\"http://www.jboss.org/drools\">Drools</a> rule management system (a.k.a. JBoss Rules) v.4 from their homegrown rules implementation to centralize all the rules code at one place, to get something simpler and easier to understand, and to improve the time to market by not requiring a redeploy when a rule is added. However Drools turned out to be more of a burden than help for the following reasons:<!--more-->\r\n<ul>\r\n\t<li>Too little time and resources were provided for learning Drools, which has a rather steep learning curve due to being based on declarative programming and rules matching (<a href=\"http://codeodor.com/index.cfm/2007/9/10/Rules-based-Programming-with-JBoss-RulesDrools/1600\">some background</a>), which is quite alien to the normal imperative/OO programmers.</li>\r\n\t<li>Drools' poor support for development and operations  - IDE only for Eclipse, difficult debugging, no stacktrace upon failure</li>\r\n\t<li>Their domain model was not well aligned with Drools and required lot of effort to make it usable by the rules</li>\r\n\t<li>The users were used to and satisfied with the current system and wanted to keep the parts facing them such as the rules management UI instead of Drools' own UI thus decreasing the value of the software (while increasing the overall complexity, we could add)</li>\r\n</ul>\r\nAt the end they've removed Drools and refactored their code to get all rules to one place, using only plain old Java - which works pretty well for them.\r\n<h2>Lessons Learned from Introducing Tools, Frameworks, and Libraries</h2>\r\nWhile the Know IT team encountered some issues specific to Drools, their experience has a lot in common with many other cases when a tool, a framework, or a library are introduced to solve some tasks and problems but turn out to be more of a problem themselves. What can we learn from these failures to deliver the expected benefits for the expected cost? (Actually such initiatives will be often labeled as a success even though the benefits are smaller and cost (often considerably) larger than planned.)<br><br>Always think twice - or three or four times - before introducing a [heavyweight] tool or framework. Especially if it requires a new and radically different way of thinking or working. Couldn't you solve it in a simpler way with plain old Java/Groovy/WhateverYouGot? Using an out of the box solution sounds very *easy* - especially at sales meetings - but it is in fact usually pretty *complex*. And as Rich Hickey recently so well <a title=\"Video: Simple Made Easy\" href=\"http://www.infoq.com/presentations/Simple-Made-Easy\">explained in his talk</a>, we should strive to minimize complexity instead of prioritizing the relative and misleading easiness (in the sense of \"easy to approach, to understand, to use\"). I'm certain that many of us have experienced how an \"I'll do it all for you, be happy and relax\" tool turns into a major obstacle and source of pain - at least I have experienced that with Websphere ESB 6.0. (It required heavy tooling that only few mastered, was in reality version 1.0 and a lot of the promised functionality had to be implemented manually anyway etc.)<br><br>We should never forget that introducing a new library, framework or tool has its cost, which we usually tend to underestimate. The cost has multiple dimensions:\r\n<ul>\r\n\t<li>Complexity - complexity is the single worst thing in IT projects, are you sure that increasing it will pay off? Complexity of infrastructure, of internal structure, ... .</li>\r\n\t<li>Competence - learning curve (which proved to be pretty high for Drools), how many people know it and availability of experts that can help in the case of troubles</li>\r\n\t<li>Development - does the tool somehow hinder development, testing or debugging, f.ex. by making it slower, more difficult, or by requiring special tooling (especially if it isn't available)? (Think of J2EE x Spring)</li>\r\n\t<li>Operations - what's the impact on observability of the application in production (high for Drools if it doesn't provide stack traces for failures), on troubleshooting, performance, deployment process, ...?</li>\r\n\t<li>Defects and limitations - every tool has them, even though seemingly mature (they had already version 4 of Drools); you usually run into limitations quite late, it's difficult if not impossible to discover them up front - and it's hard to estimate how flexible the authors have made it (it's especially bad if the solution is closed-source)</li>\r\n\t<li>Longevity - will the tool be around in 1, 5, 10 years? What about backwards compatibility, support for migration to higher versions? (The company I worked for decided to stop support for Websphere ESB in its infrastructure after one year and we had to migrate away from it - what wasted resources!)</li>\r\n\t<li>Dependencies - what dependencies does it have, don't they conflict with something else in the application or its environment? How it will be in 10 years?</li>\r\n</ul>\r\nAnd I'm sure I missed some dimensions. So be aware that the actual cost of using something is likely few times higher than your initial estimate.<br><br>Another lesson is that support for development is a key characteristics of any tool, framework, library. Any slowdown which it introduces must be multiplied at least by a 10<sup>6</sup> because all those slowdowns spread over the team and lifetime of the project will add up a lot. I experienced that too many times - a framework that required redeploy after every other changes, an application which required us to manually go through a wizard to the page we wanted to test, slow execution of tests by an IDE.<br><br>The last thing to bear in mind is that you should be aware whether a tool and the design behind it is well aligned with your business domain and processes (including the development process itself). If there are mismatches, you will need to pay for them - just think about OOP versus RDBMS (don't you know somebody who starts to shudder upon hearing \"ORM\"?).\r\n<h2>Conclusion</h2>\r\nBe aware that everything has its cost and make sure to account for it and beware our tendency to be overly optimistic when estimating both benefits and cost (perhaps hire a seasoned pessimist or appoint a devil's advocate). Always consider first using the tools you already have, however boring that might sound. I don't mean that we should never introduce new stuff - just want to make you more cautious about it. I've recently followed a few discussions on how \"enterprise\" applications get unnecessarily and to their own harm bloated with libraries and frameworks (e.g. <a href=\"http://www.neophilic.com/b2evo/blogs/blog4.php/2011/09/02/programming-isnt-fun-any-more\">Java isn't fun anymore</a> + <a href=\"http://www.reddit.com/r/programming/comments/k42if/programming_isnt_fun_any_more/\">comments</a>, <a href=\"http://vimeo.com/28760309\">@jhannes on SOA</a>) and I agree with them that we should be more careful and try to keep things simple. The tool cost dimensions above may hopefully help you to expose the less obvious constituents of the cost of new tools.<br><br>PS: I hope the IBM architect who once denied me to use XStream thus forcing me to parse a (simple) XML via the basic APIs is amused by this post. I was too young and unexperienced then. (Not implying I'm not that anymore :).)\r\n<div class=\"linkscent-iconblock\" style=\"float:none!important;border:0 solid #ff0000!important;background:none repeat scroll center center transparent!important;width:auto!important;height:auto!important;display:block!important;overflow:visible!important;position:static!important;text-indent:0!important;z-index:auto!important;max-width:none!important;min-width:0!important;max-height:none!important;min-height:0!important;left:auto!important;top:auto!important;bottom:auto!important;right:auto!important;line-height:16px!important;white-space:nowrap!important;margin:0!important;padding:0!important;\"><img class=\"linkscent-icon\" style=\"float:none!important;border:0 solid #ff0000!important;width:16px!important;height:16px!important;display:none;overflow:visible!important;position:absolute!important;text-indent:0!important;z-index:2147483635!important;max-width:none!important;min-width:0!important;max-height:none!important;min-height:0!important;left:854px;top:502px;bottom:auto!important;right:auto!important;line-height:16px!important;white-space:nowrap!important;visibility:hidden;background:url('http://www.infoq.com/favicon.ico') no-repeat scroll center center transparent!important;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" /><img class=\"linkscent-icon\" style=\"float:none!important;border:0 solid #ff0000!important;background:none repeat scroll center center transparent;width:16px!important;height:16px!important;display:none;overflow:visible!important;position:absolute!important;text-indent:0!important;z-index:2147483635!important;max-width:none!important;min-width:0!important;max-height:none!important;min-height:0!important;left:872px;top:502px;bottom:auto!important;right:auto!important;line-height:16px!important;white-space:nowrap!important;visibility:hidden;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" /></div>\r\n<div class=\"linkscent-iconblock\" style=\"float:none!important;border:0 solid #ff0000!important;background:none repeat scroll center center transparent!important;width:auto!important;height:auto!important;display:block!important;overflow:visible!important;position:static!important;text-indent:0!important;z-index:auto!important;max-width:none!important;min-width:0!important;max-height:none!important;min-height:0!important;left:auto!important;top:auto!important;bottom:auto!important;right:auto!important;line-height:16px!important;white-space:nowrap!important;margin:0!important;padding:0!important;\"><img class=\"linkscent-icon\" style=\"float:none!important;border:0 solid #ff0000!important;width:16px!important;height:16px!important;display:none;overflow:visible!important;position:absolute!important;text-indent:0!important;z-index:2147483635!important;max-width:none!important;min-width:0!important;max-height:none!important;min-height:0!important;left:331px;top:1334px;bottom:auto!important;right:auto!important;line-height:16px!important;white-space:nowrap!important;visibility:hidden;background:url('//interclue/content/cluecore/skins/default/linkscentExternal.png') no-repeat scroll center center transparent!important;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" /><img class=\"linkscent-icon\" style=\"float:none!important;border:0 solid #ff0000!important;background:none repeat scroll center center transparent;width:16px!important;height:16px!important;display:none;overflow:visible!important;position:absolute!important;text-indent:0!important;z-index:2147483635!important;max-width:none!important;min-width:0!important;max-height:none!important;min-height:0!important;left:349px;top:1334px;bottom:auto!important;right:auto!important;line-height:16px!important;white-space:nowrap!important;visibility:hidden;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" /><img class=\"linkscent-icon\" style=\"float:none!important;border:0 solid #ff0000!important;width:16px!important;height:16px!important;display:none;overflow:visible!important;position:absolute!important;text-indent:0!important;z-index:2147483635!important;max-width:none!important;min-width:0!important;max-height:none!important;min-height:0!important;left:522px;top:1353px;bottom:auto!important;right:auto!important;line-height:16px!important;white-space:nowrap!important;visibility:hidden;background:url('http://www.redditstatic.com/favicon.ico') no-repeat scroll center center transparent!important;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" /><img class=\"linkscent-icon\" style=\"float:none!important;border:0 solid #ff0000!important;background:none repeat scroll center center transparent;width:16px!important;height:16px!important;display:none;overflow:visible!important;position:absolute!important;text-indent:0!important;z-index:2147483635!important;max-width:none!important;min-width:0!important;max-height:none!important;min-height:0!important;left:540px;top:1353px;bottom:auto!important;right:auto!important;line-height:16px!important;white-space:nowrap!important;visibility:hidden;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" /><img class=\"linkscent-icon\" style=\"float:none!important;border:0 solid #ff0000!important;width:16px!important;height:16px!important;display:none;overflow:visible!important;position:absolute!important;text-indent:0!important;z-index:2147483635!important;max-width:none!important;min-width:0!important;max-height:none!important;min-height:0!important;left:779px;top:1251px;bottom:auto!important;right:auto!important;line-height:16px!important;white-space:nowrap!important;visibility:hidden;background:url('//interclue/content/cluecore/skins/default/linkscentExternal.png') no-repeat scroll center center transparent!important;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" /><img class=\"linkscent-icon\" style=\"float:none!important;border:0 solid #ff0000!important;background:none repeat scroll center center transparent;width:16px!important;height:16px!important;display:none;overflow:visible!important;position:absolute!important;text-indent:0!important;z-index:2147483635!important;max-width:none!important;min-width:0!important;max-height:none!important;min-height:0!important;left:797px;top:1251px;bottom:auto!important;right:auto!important;line-height:16px!important;white-space:nowrap!important;visibility:hidden;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" /></div>",
  "excerpt": ""
 },
 {
  "title": "Refactoring Spikes as a Learning Tool and How a Scheduled Git Reset Can Help",
  "published": "2011-11-21 12:35:25",
  "postType": "post",
  "slug": "/2011/11/21/refactoring-spikes-as-a-learning-tool-and-how-a-scheduled-git-reset-can-help/",
  "status": "publish",
  "tags": [
   "agile",
   "exercise",
   "learning",
   "legacy",
   "refactoring"
  ],
  "categories": [
   "General"
  ],
  "content": "To learn how complex your code base really is and how much effort a particular refactoring might require compared to the initial expectations, follow these steps:\r\n<ol>\r\n\t<li>Schedule <kbd>git reset --hard; git clean -fd</kbd> to run in 1 hour (e.g. via cron)</li>\r\n\t<li>Do the refactoring</li>\r\n\t<li>\"<em>WT*?! All my changes disappeared?!</em>\" - this experience indicates the end of the refactoring :-)</li>\r\n\t<li>Go for a walk or something and think about what you have learned about the code, its complexity, the refactoring</li>\r\n\t<li>Repeat regularly, f. ex. once every week or two - thus you'll improve your ability to direct the refactoring so that you learn as much as possible during the short time</li>\r\n</ol>\r\n<!--more-->The exercise has been recommended by Kent Beck, I've just added the scheduled reset because my discipline is not strong enough to resist the likely urge to continue \"just little further\" and to keep the code if it looks any good. (If I become absorbed in the refactoring so much that I'll forget to stop on time then I'll surely also forget about the reset and thus the tendency to just cancel it won't stand a chance.)<br><br>Notice that if you do any larger-scale refactoring, it might be pretty wise to apply the <a href=\"http://mikadomethod.wordpress.com/\">Mikado method</a> to help you keep track of where you are going and where you are while also keeping your buildable.<br><br>When I get to try this out I might write about my experiences here as well.",
  "excerpt": ""
 },
 {
  "title": "Where to Get Sample Java Webapps",
  "published": "2011-11-23 14:22:17",
  "postType": "post",
  "slug": "/2011/11/23/where-to-get-sample-java-webapps/",
  "status": "publish",
  "tags": [
   "demo",
   "java",
   "webapp"
  ],
  "categories": [
   "j2ee",
   "Languages"
  ],
  "content": "I was unsuccessfuly looking for some decent, neither too simple nor to complex Java web application for Iterate hackaton \"War of Web Frameworks\". I want to record the demo apps and options I've found in the case I'll need it ever again. Tips are welcome.<br><br><!--more-->\r\n<ul>\r\n\t<li><a href=\"http://downloads.jboss.org/hibernate/caveatemptor/\">Hibernate CaveatEmptor</a> - 2006, no UI, richer domain model (+- 15), auction site, created for the book Hibernate in Action, uses EJB3</li>\r\n\t<li><a href=\"http://wiki.eclipse.org/EclipseLink/Examples/Distributed\">EclipseLink Distributed Collatz Solver</a> - 2011, 6 entities, JPA 2.0, EJB 3.1, JSF 2.0, JAX-RS, intended to test distribution and JPA behavior under load, primitive UI, computation-intensive app (multiple SE clients + 1 EE server)</li>\r\n\t<li><a href=\"http://www.alfresco.org/\">Alfresco CMS</a> - stable, complex application with <a href=\"http://docs.alfresco.com/3.4/topic/com.alfresco.Enterprise_3_4_0.doc/concepts/ch-customize.html\">REST API</a> (CMIS compatible) based on its \"web scripts\"</li>\r\n\t<li><a href=\"http://netbeans.org/projects/samples/downloads/directory/Samples\">NetBeans Samples</a> including 1-entity <a href=\"http://netbeans.org/kb/samples/pet-catalog.html\">Pet Catalog</a> - usually too primitive (1-few classes, ..)</li>\r\n<ul>\r\n\t<li><a href=\"http://netbeans.org/kb/docs/javaee/ecommerce/intro.html\">NetBeans e-Commerce</a> (<a href=\"http://dot.netbeans.org:8080/AffableBean/\">demo</a>, <a href=\"http://netbeans.org/projects/samples/downloads/directory/Samples/JavaEE/ecommerce\">downloads</a>), recommended by Geertjan Wielenga - a JavaEE on-line grocery shop</li>\r\n</ul>\r\n\t<li><a href=\"https://src.springframework.org/svn/spring-samples/\">Spring samples (svn)</a> - including jpetstore (5 DAOs, Struts &amp; S. MVC UI), petcare, petclinic[-groovy], <a href=\"https://github.com/SpringSource/spring-mvc-showcase\">spring-mvc-showcase</a>; another example is <a href=\"https://github.com/SpringSource/greenhouse\">Spring Greenhouse</a> (a Spring reference app., \"App Catalog that allows Developers to develop new client apps for which users may establish Account-&gt;App connections\"), the functionality of the UI seems to be quite primitive</li>\r\n<ul>\r\n\t<li>PS: I had to <a href=\"https://github.com/jakubholynet/blog/commit/f37bb69478b50863078dc945d1ec4c5a378ab438\">fix JPetStore's pom.xml</a> to build it</li>\r\n</ul>\r\n\t<li>Demos of JSF component libraries (RchFaces, PrimeFaces, ...) - likely tightly coupled to JSF</li>\r\n\t<li><a href=\"http://java.net/projects/x-ray/\">A. Bien's x-ray</a> project - minimal UI, developed for the book \"Real World Night Hacks\"</li>\r\n\t<li><a href=\"http://pebble.sourceforge.net/\">Pebble Blog</a> - lot of files and servlets even though the use cases are quite simple (post blog, view posts, ..)</li>\r\n\t<li><a href=\"http://docs.oracle.com/cd/E19776-01/820-4867/ggrby/index.html\">Jersey Samples: Bookstore</a> (<a href=\"http://download.java.net/maven/2/com/sun/jersey/samples/jersey-samples/\">download links</a>) - a simple webapp built on JAX-RS (REST) and Jersey's implicit views in the form of simple JSPs. 4 resource classes. Highly resuable with other frameworks that support REST service layers.</li>\r\n</ul>\r\n<div class=\"linkscent-iconblock\" style=\"float:none !important;border:0 solid #ff0000 !important;background:none repeat scroll center center transparent !important;width:auto !important;height:auto !important;display:block !important;overflow:visible !important;position:static !important;text-indent:0 !important;z-index:auto !important;max-width:none !important;min-width:0 !important;max-height:none !important;min-height:0 !important;left:auto !important;top:auto !important;bottom:auto !important;right:auto !important;line-height:16px !important;white-space:nowrap !important;margin:0!important;padding:0!important;\"><img class=\"linkscent-icon\" style=\"float:none !important;border:0 solid #ff0000 !important;width:16px !important;height:16px !important;display:none;overflow:visible !important;position:absolute !important;text-indent:0 !important;z-index:2147483635 !important;max-width:none !important;min-width:0 !important;max-height:none !important;min-height:0 !important;left:405px;top:232px;bottom:auto !important;right:auto !important;line-height:16px !important;white-space:nowrap !important;visibility:hidden;background:url('//github.com/fluidicon.png') no-repeat scroll center center transparent !important;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" /><img class=\"linkscent-icon\" style=\"float:none !important;border:0 solid #ff0000 !important;background:url('//interclue/content/cluecore/skins/default/sprites.png') no-repeat scroll -144px -96px transparent;width:16px !important;height:16px !important;display:none;overflow:visible !important;position:absolute !important;text-indent:0 !important;z-index:2147483635 !important;max-width:none !important;min-width:0 !important;max-height:none !important;min-height:0 !important;left:423px;top:232px;bottom:auto !important;right:auto !important;line-height:16px !important;white-space:nowrap !important;visibility:hidden;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" width=\"16\" height=\"16\" /><img class=\"linkscent-icon\" style=\"float:none !important;border:0 solid #ff0000 !important;background:none repeat scroll center center transparent;width:16px !important;height:16px !important;display:none;overflow:visible !important;position:absolute !important;text-indent:0 !important;z-index:2147483635 !important;max-width:none !important;min-width:0 !important;max-height:none !important;min-height:0 !important;left:441px;top:232px;bottom:auto !important;right:auto !important;line-height:16px !important;white-space:nowrap !important;visibility:hidden;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" /><img class=\"linkscent-icon\" style=\"float:none !important;border:0 solid #ff0000 !important;width:16px !important;height:16px !important;display:none;overflow:visible !important;position:absolute !important;text-indent:0 !important;z-index:2147483635 !important;max-width:none !important;min-width:0 !important;max-height:none !important;min-height:0 !important;left:172px;top:213px;bottom:auto !important;right:auto !important;line-height:16px !important;white-space:nowrap !important;visibility:hidden;background:url('//interclue/content/cluecore/skins/default/linkscentExternal.png') no-repeat scroll center center transparent !important;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" /><img class=\"linkscent-icon\" style=\"float:none !important;border:0 solid #ff0000 !important;background:url('//interclue/content/cluecore/skins/default/sprites.png') no-repeat scroll -144px -96px transparent;width:16px !important;height:16px !important;display:none;overflow:visible !important;position:absolute !important;text-indent:0 !important;z-index:2147483635 !important;max-width:none !important;min-width:0 !important;max-height:none !important;min-height:0 !important;left:190px;top:213px;bottom:auto !important;right:auto !important;line-height:16px !important;white-space:nowrap !important;visibility:hidden;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" width=\"16\" height=\"16\" /><img class=\"linkscent-icon\" style=\"float:none !important;border:0 solid #ff0000 !important;background:none repeat scroll center center transparent;width:16px !important;height:16px !important;display:none;overflow:visible !important;position:absolute !important;text-indent:0 !important;z-index:2147483635 !important;max-width:none !important;min-width:0 !important;max-height:none !important;min-height:0 !important;left:208px;top:213px;bottom:auto !important;right:auto !important;line-height:16px !important;white-space:nowrap !important;visibility:hidden;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" /></div>\r\n<div class=\"linkscent-iconblock\" style=\"float:none !important;border:0 solid #ff0000 !important;background:none repeat scroll center center transparent !important;width:auto !important;height:auto !important;display:block !important;overflow:visible !important;position:static !important;text-indent:0 !important;z-index:auto !important;max-width:none !important;min-width:0 !important;max-height:none !important;min-height:0 !important;left:auto !important;top:auto !important;bottom:auto !important;right:auto !important;line-height:16px !important;white-space:nowrap !important;margin:0!important;padding:0!important;\"><img class=\"linkscent-icon\" style=\"float:none !important;border:0 solid #ff0000 !important;width:16px !important;height:16px !important;display:none;overflow:visible !important;position:absolute !important;text-indent:0 !important;z-index:2147483635 !important;max-width:none !important;min-width:0 !important;max-height:none !important;min-height:0 !important;left:331px;top:240px;bottom:auto !important;right:auto !important;line-height:16px !important;white-space:nowrap !important;visibility:hidden;background:url('http://netbeans.org/favicon.ico') no-repeat scroll center center transparent !important;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" /><img class=\"linkscent-icon\" style=\"float:none !important;border:0 solid #ff0000 !important;background:none repeat scroll center center transparent;width:16px !important;height:16px !important;display:none;overflow:visible !important;position:absolute !important;text-indent:0 !important;z-index:2147483635 !important;max-width:none !important;min-width:0 !important;max-height:none !important;min-height:0 !important;left:349px;top:240px;bottom:auto !important;right:auto !important;line-height:16px !important;white-space:nowrap !important;visibility:hidden;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" /><img class=\"linkscent-icon\" style=\"float:none !important;border:0 solid #ff0000 !important;width:16px !important;height:16px !important;display:none;overflow:visible !important;position:absolute !important;text-indent:0 !important;z-index:2147483635 !important;max-width:none !important;min-width:0 !important;max-height:none !important;min-height:0 !important;left:196px;top:107px;bottom:auto !important;right:auto !important;line-height:16px !important;white-space:nowrap !important;visibility:hidden;background:url('http://jboss.org/favicon.ico') no-repeat scroll center center transparent !important;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" /><img class=\"linkscent-icon\" style=\"float:none !important;border:0 solid #ff0000 !important;background:none repeat scroll center center transparent;width:16px !important;height:16px !important;display:none;overflow:visible !important;position:absolute !important;text-indent:0 !important;z-index:2147483635 !important;max-width:none !important;min-width:0 !important;max-height:none !important;min-height:0 !important;left:214px;top:107px;bottom:auto !important;right:auto !important;line-height:16px !important;white-space:nowrap !important;visibility:hidden;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" /><img class=\"linkscent-icon\" style=\"float:none !important;border:0 solid #ff0000 !important;width:16px !important;height:16px !important;display:none;overflow:visible !important;position:absolute !important;text-indent:0 !important;z-index:2147483635 !important;max-width:none !important;min-width:0 !important;max-height:none !important;min-height:0 !important;left:385px;top:202px;bottom:auto !important;right:auto !important;line-height:16px !important;white-space:nowrap !important;visibility:hidden;background:url('http://alfresco.com/favicon.ico') no-repeat scroll center center transparent !important;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" /><img class=\"linkscent-icon\" style=\"float:none !important;border:0 solid #ff0000 !important;background:none repeat scroll center center transparent;width:16px !important;height:16px !important;display:none;overflow:visible !important;position:absolute !important;text-indent:0 !important;z-index:2147483635 !important;max-width:none !important;min-width:0 !important;max-height:none !important;min-height:0 !important;left:403px;top:202px;bottom:auto !important;right:auto !important;line-height:16px !important;white-space:nowrap !important;visibility:hidden;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" /><img class=\"linkscent-icon\" style=\"float:none !important;border:0 solid #ff0000 !important;width:16px !important;height:16px !important;display:none;overflow:visible !important;position:absolute !important;text-indent:0 !important;z-index:2147483635 !important;max-width:none !important;min-width:0 !important;max-height:none !important;min-height:0 !important;left:285px;top:278px;bottom:auto !important;right:auto !important;line-height:16px !important;white-space:nowrap !important;visibility:hidden;background:url('http://github.com/favicon.ico') no-repeat scroll center center transparent !important;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" /><img class=\"linkscent-icon\" style=\"float:none !important;border:0 solid #ff0000 !important;background:url('//interclue/content/cluecore/skins/default/sprites.png') no-repeat scroll -144px -96px transparent;width:16px !important;height:16px !important;display:none;overflow:visible !important;position:absolute !important;text-indent:0 !important;z-index:2147483635 !important;max-width:none !important;min-width:0 !important;max-height:none !important;min-height:0 !important;left:303px;top:278px;bottom:auto !important;right:auto !important;line-height:16px !important;white-space:nowrap !important;visibility:hidden;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" width=\"16\" height=\"16\" /><img class=\"linkscent-icon\" style=\"float:none !important;border:0 solid #ff0000 !important;background:none repeat scroll center center transparent;width:16px !important;height:16px !important;display:none;overflow:visible !important;position:absolute !important;text-indent:0 !important;z-index:2147483635 !important;max-width:none !important;min-width:0 !important;max-height:none !important;min-height:0 !important;left:321px;top:278px;bottom:auto !important;right:auto !important;line-height:16px !important;white-space:nowrap !important;visibility:hidden;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" /><img class=\"linkscent-icon\" style=\"float:none !important;border:0 solid #ff0000 !important;width:16px !important;height:16px !important;display:none;overflow:visible !important;position:absolute !important;text-indent:0 !important;z-index:2147483635 !important;max-width:none !important;min-width:0 !important;max-height:none !important;min-height:0 !important;left:514px;top:297px;bottom:auto !important;right:auto !important;line-height:16px !important;white-space:nowrap !important;visibility:hidden;background:url('http://github.com/favicon.ico') no-repeat scroll center center transparent !important;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" /><img class=\"linkscent-icon\" style=\"float:none !important;border:0 solid #ff0000 !important;background:url('//interclue/content/cluecore/skins/default/sprites.png') no-repeat scroll -144px -96px transparent;width:16px !important;height:16px !important;display:none;overflow:visible !important;position:absolute !important;text-indent:0 !important;z-index:2147483635 !important;max-width:none !important;min-width:0 !important;max-height:none !important;min-height:0 !important;left:532px;top:297px;bottom:auto !important;right:auto !important;line-height:16px !important;white-space:nowrap !important;visibility:hidden;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" width=\"16\" height=\"16\" /><img class=\"linkscent-icon\" style=\"float:none !important;border:0 solid #ff0000 !important;background:none repeat scroll center center transparent;width:16px !important;height:16px !important;display:none;overflow:visible !important;position:absolute !important;text-indent:0 !important;z-index:2147483635 !important;max-width:none !important;min-width:0 !important;max-height:none !important;min-height:0 !important;left:550px;top:297px;bottom:auto !important;right:auto !important;line-height:16px !important;white-space:nowrap !important;visibility:hidden;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" /></div>\r\n<div class=\"linkscent-iconblock\" style=\"float:none !important;border:0 solid #ff0000 !important;background:none repeat scroll center center transparent !important;width:auto !important;height:auto !important;display:block !important;overflow:visible !important;position:static !important;text-indent:0 !important;z-index:auto !important;max-width:none !important;min-width:0 !important;max-height:none !important;min-height:0 !important;left:auto !important;top:auto !important;bottom:auto !important;right:auto !important;line-height:16px !important;white-space:nowrap !important;margin:0!important;padding:0!important;\"><img class=\"linkscent-icon\" style=\"float:none !important;border:0 solid #ff0000 !important;width:16px !important;height:16px !important;display:none;overflow:visible !important;position:absolute !important;text-indent:0 !important;z-index:2147483635 !important;max-width:none !important;min-width:0 !important;max-height:none !important;min-height:0 !important;left:385px;top:202px;bottom:auto !important;right:auto !important;line-height:16px !important;white-space:nowrap !important;visibility:hidden;background:url('http://alfresco.com/favicon.ico') no-repeat scroll center center transparent !important;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" /><img class=\"linkscent-icon\" style=\"float:none !important;border:0 solid #ff0000 !important;background:none repeat scroll center center transparent;width:16px !important;height:16px !important;display:none;overflow:visible !important;position:absolute !important;text-indent:0 !important;z-index:2147483635 !important;max-width:none !important;min-width:0 !important;max-height:none !important;min-height:0 !important;left:403px;top:202px;bottom:auto !important;right:auto !important;line-height:16px !important;white-space:nowrap !important;visibility:hidden;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" /><img class=\"linkscent-icon\" style=\"float:none !important;border:0 solid #ff0000 !important;width:16px !important;height:16px !important;display:none;overflow:visible !important;position:absolute !important;text-indent:0 !important;z-index:2147483635 !important;max-width:none !important;min-width:0 !important;max-height:none !important;min-height:0 !important;left:183px;top:544px;bottom:auto !important;right:auto !important;line-height:16px !important;white-space:nowrap !important;visibility:hidden;background:url('http://netbeans.org/favicon.ico') no-repeat scroll center center transparent !important;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" /><img class=\"linkscent-icon\" style=\"float:none !important;border:0 solid #ff0000 !important;background:none repeat scroll center center transparent;width:16px !important;height:16px !important;display:none;overflow:visible !important;position:absolute !important;text-indent:0 !important;z-index:2147483635 !important;max-width:none !important;min-width:0 !important;max-height:none !important;min-height:0 !important;left:201px;top:544px;bottom:auto !important;right:auto !important;line-height:16px !important;white-space:nowrap !important;visibility:hidden;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" /><img class=\"linkscent-icon\" style=\"float:none !important;border:0 solid #ff0000 !important;width:16px !important;height:16px !important;display:none;overflow:visible !important;position:absolute !important;text-indent:0 !important;z-index:2147483635 !important;max-width:none !important;min-width:0 !important;max-height:none !important;min-height:0 !important;left:223px;top:278px;bottom:auto !important;right:auto !important;line-height:16px !important;white-space:nowrap !important;visibility:hidden;background:url('http://netbeans.org/favicon.ico') no-repeat scroll center center transparent !important;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" /><img class=\"linkscent-icon\" style=\"float:none !important;border:0 solid #ff0000 !important;background:none repeat scroll center center transparent;width:16px !important;height:16px !important;display:none;overflow:visible !important;position:absolute !important;text-indent:0 !important;z-index:2147483635 !important;max-width:none !important;min-width:0 !important;max-height:none !important;min-height:0 !important;left:241px;top:278px;bottom:auto !important;right:auto !important;line-height:16px !important;white-space:nowrap !important;visibility:hidden;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" /><img class=\"linkscent-icon\" style=\"float:none !important;border:0 solid #ff0000 !important;width:16px !important;height:16px !important;display:none;overflow:visible !important;position:absolute !important;text-indent:0 !important;z-index:2147483635 !important;max-width:none !important;min-width:0 !important;max-height:none !important;min-height:0 !important;left:172px;top:297px;bottom:auto !important;right:auto !important;line-height:16px !important;white-space:nowrap !important;visibility:hidden;background:url('//interclue/content/cluecore/skins/default/linkscentExternal.png') no-repeat scroll center center transparent !important;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" /><img class=\"linkscent-icon\" style=\"float:none !important;border:0 solid #ff0000 !important;background:url('//interclue/content/cluecore/skins/default/sprites.png') no-repeat scroll -144px -96px transparent;width:16px !important;height:16px !important;display:none;overflow:visible !important;position:absolute !important;text-indent:0 !important;z-index:2147483635 !important;max-width:none !important;min-width:0 !important;max-height:none !important;min-height:0 !important;left:190px;top:297px;bottom:auto !important;right:auto !important;line-height:16px !important;white-space:nowrap !important;visibility:hidden;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" width=\"16\" height=\"16\" /><img class=\"linkscent-icon\" style=\"float:none !important;border:0 solid #ff0000 !important;background:none repeat scroll center center transparent;width:16px !important;height:16px !important;display:none;overflow:visible !important;position:absolute !important;text-indent:0 !important;z-index:2147483635 !important;max-width:none !important;min-width:0 !important;max-height:none !important;min-height:0 !important;left:208px;top:297px;bottom:auto !important;right:auto !important;line-height:16px !important;white-space:nowrap !important;visibility:hidden;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" /></div>\r\n",
  "excerpt": ""
 },
 {
  "title": "The 3 Most Important Things I''ve Learned This Year",
  "published": "2011-11-26 11:44:04",
  "postType": "post",
  "slug": "/2011/11/26/the-3-most-important-things-ive-learned-this-year/",
  "status": "publish",
  "tags": [
   "bestofyear"
  ],
  "categories": [
   "General"
  ],
  "content": "This is a technology blog but why do we actually use technology? We use it because we want to help people achieve something - and in the process of doing that we have to cooperate and communicate with many humans. The human factor is far more determining for our success than any kind of technology could ever be. Why do most project fail? Because of a bad technology? No - usually it's a failure of communication, leadership, process change. And this week I've learnt some very important things about this crucial human factor - and thus this post may well be the most valuable piece published here til now - or ever.<br><br>First, I've learned <a title=\"Jonah Lehrer: How We Decide\" href=\"http://fora.tv/2010/01/05/Jonah_Lehrer_How_We_Decide\">how we decide</a> (and a project - IT or other - is nothing but a bunch of hundreds, millions of decisions, both small and big). To deal with the incredibly complex world around us, human brain has many decision strategies ranging from a very rational decision making to \"gut feeling\" decisions based on our emotions and subconsciousness. Every of these strategies is perfectly suitable for some situations (for example relying on emotions and intuition is often the best thing, conversely to what we've been thought) - and leads to suboptimal results (read: terrible failures) in others. Thus the single most important factor that determines how successful we are is our ability of metacognition, i.e. being aware of how we think, and thus being able to select the most appropriate strategy for the situation at hand. (Which might not be as easy as it sounds and may require that we \"trick\" our mind somehow, i.e. by distracting it or forcing it into a certain decision mode.) Jonah Lehrer documents that on the \"Marshmallow experiment\" - the children who knew that they got to distract themselves somehow not to eat the marshmallow, which they've been given, not only managed to wait those 15 minutes for another one but were also much more successful in their later lives - presumably because their ability of metacognition helped them to make better decisions more often.<br><br><!--more-->Second, I've learned that <a href=\"http://www.ted.com/talks/simon_sinek_how_great_leaders_inspire_action.html\">the most important thing to succeed is to know (and communicate) why</a> - not just \"what\" we do or want to achieve, but \"why,\" what's our purpose, our goal. Because \"what\" talks just to our thin, rational neocortex - but that \"why\" strikes deep into the center that drives our motivation and behavior. Great leaders don't present plans, they inspire people with their cause - as did Martin Luther King with his \"<a href=\"http://www.americanrhetoric.com/speeches/mlkihaveadream.htm\">I have a dream</a>\" talk, brothers Wrights who were able to inspire themselves and their coworkers to achieve something a much better equipped team didn't, and Apple with its vision of great and friendly world that makes people stand in a queue for six hours to be the first to purchase their new product. You may not want to aspire to the same world-changing goals as they do but still, whatever you do, you should know that to attract people you have to know and communicate \"why.\" I'd certainly much rather work - likely even with sweat and blood - for a company that has a cause that resonates with me other than \"to make money\". (That may be also the reason why I don't like certain dominant company for I feel that their goal is to rule the world [of technology], to get it into and keep it in its iron embrace.)<br><br>Last, I've learned that <a title=\"RSA Animate - Drive: The surprising truth about what motivates us \" href=\"http://www.youtube.com/watch?v=u6XAPnuFjJc\">what motivates us isn't money, but purpose, mastery, autonomy</a> (not such a big surprise anyway, but it's nice to have it backed by actual research results). For a simple, physical task a financial reward increases performance - but for even a mildly cognitive task it decreases it. Thus to motivate employees, once the question of money is \"out of the table,\" i.e. once they've enough for what they need, you need something else. And it turns our that we are motivated by three desires -the desire for autonomy, for deciding ourselves our course of action, the desire to be better in what we do, to feel more competent, and - as mentioned already in the previous talk - by a purpose. (Frankly, who would be surprised that people prefer to do something meaningful, to participate on something bigger, on creating a better world of tomorrow?) This is a good guide both for attracting employees and choosing and employer - but it certainly applies in other dimensions of life too.\r\n<h2>Conclusion</h2>\r\nWe are human. We are not just rational machines, as the majority of the western science claimed in the last centuries. And that's a good thing. To be successful and happy we need to understand little more about ourselves and others to be able both to drive ourselves better and to communicate with others better. We should be more aware about how we think and decide and choose the right decision strategy without blindly preferring one (such as the rational one). When we want to appeal to other people to help us with our goal, we have to formulate and communicate our purpose, so that they can identify themselves with the purpose and help us with all their power. Finally, we should be aware of what motivates us and seek and foster such an environment where it flourishes. (One of the reasons why I prefer Scrum/lean that empowers the autonomy and responsibility of individuals over a tight, top-down controlled process.)<br><br>PS: The <a href=\"http://www.semco.com.br/en/content.asp?content=3&amp;contentID=567\">rules of the Semco group</a>, which a very non-standard company - open, cooperative, encouraging autonomy - is very inspiring.\r\n<div class=\"linkscent-iconblock\" style=\"float:none !important;border:0 solid #ff0000 !important;background:none repeat scroll center center transparent !important;width:auto !important;height:auto !important;display:block !important;overflow:visible !important;position:static !important;text-indent:0 !important;z-index:auto !important;max-width:none !important;min-width:0 !important;max-height:none !important;min-height:0 !important;left:auto !important;top:auto !important;bottom:auto !important;right:auto !important;line-height:16px !important;white-space:nowrap !important;margin:0!important;padding:0!important;\"><img class=\"linkscent-icon\" style=\"float:none !important;border:0 solid #ff0000 !important;width:16px !important;height:16px !important;display:none;overflow:visible !important;position:absolute !important;text-indent:0 !important;z-index:2147483635 !important;max-width:none !important;min-width:0 !important;max-height:none !important;min-height:0 !important;left:554px;top:302px;bottom:auto !important;right:auto !important;line-height:16px !important;white-space:nowrap !important;visibility:hidden;background:url('http://www.americanrhetoric.com/favicon.ico') no-repeat scroll center center transparent !important;opacity:0;margin:0;padding:0!important;\" alt=\"\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" /><img class=\"linkscent-icon\" style=\"float:none !important;border:0 solid #ff0000 !important;background:url('//interclue/content/cluecore/skins/default/sprites.png') no-repeat scroll -48px -96px transparent;width:16px !important;height:16px !important;display:none;overflow:visible !important;position:absolute !important;text-indent:0 !important;z-index:2147483635 !important;max-width:none !important;min-width:0 !important;max-height:none !important;min-height:0 !important;left:572px;top:302px;bottom:auto !important;right:auto !important;line-height:16px !important;white-space:nowrap !important;visibility:hidden;opacity:0;margin:0;padding:0!important;\" alt=\"\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" width=\"16\" height=\"16\" /><img class=\"linkscent-icon\" style=\"float:none !important;border:0 solid #ff0000 !important;background:none repeat scroll center center transparent;width:16px !important;height:16px !important;display:none;overflow:visible !important;position:absolute !important;text-indent:0 !important;z-index:2147483635 !important;max-width:none !important;min-width:0 !important;max-height:none !important;min-height:0 !important;left:590px;top:302px;bottom:auto !important;right:auto !important;line-height:16px !important;white-space:nowrap !important;visibility:hidden;opacity:0;margin:0;padding:0!important;\" alt=\"\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" /><img class=\"linkscent-icon\" style=\"float:none !important;border:0 solid #ff0000 !important;width:16px !important;height:16px !important;display:none;overflow:visible !important;position:absolute !important;text-indent:0 !important;z-index:2147483635 !important;max-width:none !important;min-width:0 !important;max-height:none !important;min-height:0 !important;left:496px;top:410px;bottom:auto !important;right:auto !important;line-height:16px !important;white-space:nowrap !important;visibility:hidden;background:url('http://www.youtube.com/favicon.ico') no-repeat scroll center center transparent !important;opacity:0;margin:0;padding:0!important;\" alt=\"\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" /><img class=\"linkscent-icon\" style=\"float:none !important;border:0 solid #ff0000 !important;background:url('//interclue/content/cluecore/skins/default/sprites.png') no-repeat scroll -48px -96px transparent;width:16px !important;height:16px !important;display:none;overflow:visible !important;position:absolute !important;text-indent:0 !important;z-index:2147483635 !important;max-width:none !important;min-width:0 !important;max-height:none !important;min-height:0 !important;left:514px;top:410px;bottom:auto !important;right:auto !important;line-height:16px !important;white-space:nowrap !important;visibility:hidden;opacity:0;margin:0;padding:0!important;\" alt=\"\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" width=\"16\" height=\"16\" /><img class=\"linkscent-icon\" style=\"float:none !important;border:0 solid #ff0000 !important;background:none repeat scroll center center transparent;width:16px !important;height:16px !important;display:none;overflow:visible !important;position:absolute !important;text-indent:0 !important;z-index:2147483635 !important;max-width:none !important;min-width:0 !important;max-height:none !important;min-height:0 !important;left:532px;top:410px;bottom:auto !important;right:auto !important;line-height:16px !important;white-space:nowrap !important;visibility:hidden;opacity:0;margin:0;padding:0!important;\" alt=\"\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" /></div>\r\n<div class=\"linkscent-iconblock\" style=\"float:none !important;border:0 solid #ff0000 !important;background:none repeat scroll center center transparent !important;width:auto !important;height:auto !important;display:block !important;overflow:visible !important;position:static !important;text-indent:0 !important;z-index:auto !important;max-width:none !important;min-width:0 !important;max-height:none !important;min-height:0 !important;left:auto !important;top:auto !important;bottom:auto !important;right:auto !important;line-height:16px !important;white-space:nowrap !important;margin:0!important;padding:0!important;\"><img class=\"linkscent-icon\" style=\"float:none !important;border:0 solid #ff0000 !important;width:16px !important;height:16px !important;display:none;overflow:visible !important;position:absolute !important;text-indent:0 !important;z-index:2147483635 !important;max-width:none !important;min-width:0 !important;max-height:none !important;min-height:0 !important;left:505px;top:708px;bottom:auto !important;right:auto !important;line-height:16px !important;white-space:nowrap !important;visibility:hidden;background:url('http://www.youtube.com/favicon.ico') no-repeat scroll center center transparent !important;opacity:0;margin:0;padding:0!important;\" alt=\"\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" /><img class=\"linkscent-icon\" style=\"float:none !important;border:0 solid #ff0000 !important;background:none repeat scroll center center transparent;width:16px !important;height:16px !important;display:none;overflow:visible !important;position:absolute !important;text-indent:0 !important;z-index:2147483635 !important;max-width:none !important;min-width:0 !important;max-height:none !important;min-height:0 !important;left:523px;top:708px;bottom:auto !important;right:auto !important;line-height:16px !important;white-space:nowrap !important;visibility:hidden;opacity:0;margin:0;padding:0!important;\" alt=\"\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" /></div>",
  "excerpt": ""
 },
 {
  "title": "Getting Started with Amazon Web Services and Fully Automated Resource Provisioning in 15 Minutes",
  "published": "2011-12-07 21:26:05",
  "postType": "post",
  "slug": "/2011/12/07/getting-started-with-amazon-web-services-and-fully-automated-resource-provisioning-in-15-minutes/",
  "status": "publish",
  "tags": [
   "automation",
   "aws",
   "cloud",
   "ec2",
   "ops"
  ],
  "categories": [
   "General",
   "Testing",
   "Tools"
  ],
  "content": "While waiting for a new project, I wanted to learn something useful. And because on many projects we need to assess and test the performance of the application being developed while only rarely there is enough hardware for generating a realistic load, I decided to learn more about provisioning virtual machines on demand in the Cloud, namely <a href=\"http://aws.amazon.com/\">Amazon Web Services</a> (AWS). I've learned a lot about the tools available to work with AWS and the automation of the setup of resources (machine instances, security groups, databases etc.) and automatic customization of virtual machine instances in the AWS cloud. I'd like to present a brief introduction into AWS and a succinct overview of the tools and automation options. If you are familiar with AWS/EC2 then you might want to jump over the introduction directly to the automation section.<br><br><!--more--><br><br><h2>Why AWS?</h2><br><br>Amazon is a leading provider of \"infrastructure as a service\" and is constantly adding new services to its offerings. AWS allow you to create virtual machines on demand, load balance them, connect them to a \"database as a service\" (with several advantages over a manually managed database) and various other services such as notifications, e-mail, and a queuing service. You get access to built-in monitoring and you can deploy applications to their \"platform as a service\" built on top of that while retaining control over those lower-level resources.<br><br>Follow the <a href=\"http://aws.typepad.com/aws/\">official AWS Blog</a> to be informed of new services, features etc.<br><br><h2>Getting started with AWS</h2><br><br>To <a href=\"https://www.amazon.com/ap/signin/177-1403391-6765917?_encoding=UTF8&amp;openid.assoc_handle=aws&amp;openid.return_to=https%3A%2F%2Faws-portal.amazon.com%2Fgp%2Faws%2Fdeveloper%2Fregistration%2Findex.html%2F177-1403391-6765917&amp;openid.mode=checkid_setup&amp;openid.ns=http%3A%2F%2Fspecs.openid.net%2Fauth%2F2.0&amp;openid.claimed_id=http%3A%2F%2Fspecs.openid.net%2Fauth%2F2.0%2Fidentifier_select&amp;openid.pape.max_auth_age=600&amp;siteState=awsMode%3A%3Aregistration%3A%3AheaderMessage%3A%3AAmazon%20Web%20Services%20Sign%20Up%3A%3A&amp;pageId=aws.ssop&amp;openid.pape.preferred_auth_policies=http%3A%2F%2Fschemas.openid.net%2Fpape%2Fpolicies%2F2007%2F06%2Fmulti-factor-physical&amp;marketplaceId=ATVPDKIKX0DER&amp;accountStatusPolicy=P1&amp;openid.ns.pape=http%3A%2F%2Fspecs.openid.net%2Fextensions%2Fpape%2F1.0&amp;openid.identity=http%3A%2F%2Fspecs.openid.net%2Fauth%2F2.0%2Fidentifier_select&amp;authCookies=1\">create an AWS account</a> you'll need a phone and a credit card (which will be charged if you use any of the paid services or exceed any of the free usage limits). Be careful during the sign-up process as the UI isn't exactly error-proof. It might take up to two hours before your account becomes fully functional.<br><br>The next thing to do is to browse through the <a href=\"aws.amazon.com/console/\">AWS Management Console</a>, which let you create and configure various services and resources, the most interesting being the Elastic Compute Cloud (EC2), where you can start new virtual machines. The management console is quite self-explanatory though not as user-friendly as I might wish. You might want to check these screenshots showing <a href=\"http://code.google.com/p/xebia-france/wiki/MonitoringOpenSourceJMeter\">how to create an EC2 instance</a> in the Management Console.<br><br><h3>Brief Overview</h3><br><br>The core rule of AWS is that you only pay for what you use, i.e. runtime hours of your instances and the traffic - see the <a href=\"http://calculator.s3.amazonaws.com/calc5.html\">AWS Simple Monthly Calculator</a>.<br><br>The most important resource is <strong>EC2</strong> as it allows you to create virtual machines, called \"instances.\" There are different <a href=\"http://aws.amazon.com/ec2/instance-types/\">types of instances</a> regarding their memory and computational power. By default they are transient and discarded (terminated) once you stop using them. You may also have an instance backed by the Elastic Block Storage (EBS) which enables you to stop and start the instance again with any state and changes preserved, Amazon charges $0.10/GB/month for that. You can also mount EBS storage as a volume to your instance if you need to persist only some data. There is no quick way to re-create a terminated instance, you have to go through the wizard again - that's where the command-line tools and automation become handy.<br><br>When setting up your EC2 instances, you'll likely also need to assign them into the same security group and configure what ports are open to whom in the security group (by default you cannot even SSH in).<br><br>If you want to learn all about EC2, go to the <a href=\"http://docs.amazonwebservices.com/AWSEC2/latest/UserGuide/\">Amazon EC2 User Guide</a>.<br><br>Aside of EC2 there are also many other interesting services such as the Elastic Beanstalk (PaaS, currently for Java webapps, using Tomcat), the distributed storage S3 etc. There are also some additional services such as the Amazon <a href=\"http://aws.amazon.com/cloudwatch/\">CloudWatch</a>, which is a (performance) monitoring tool for your AWS infrastructure. (Which can be complemented by <a href=\"http://newrelic.com/about/partners/amazon-web-services\">New Relic</a> monitoring for even more insight into the application.)<br><br><h2>Leveraging the Amazon Free Tier</h2><br><br>Amazon provides new customers with a <a href=\"http://aws.amazon.com/free/\">certain amount of resources for free</a> for one year, you only need to pay if you consume more than that. It includes for example a non-stop running micro EC2 instance backed by EBS (i.e. it is persistent, you can stop and start it again), 15 GB traffic, 10 GB of EBS storage, 5 GB of S3 storage, 10 CloudWatch metrics etc. It unfortunately doesn't include the Amazon-managed MySQL/Oracle database (<a href=\"http://aws.amazon.com/rds/\">RDS</a>) though they provided 1GB of space in the Amazon <a href=\"http://aws.amazon.com/simpledb/\">SimpleDB</a> (a NoSQL key-value store).<br><br>This means that you can have a constantly running EC2 Micro instance (613 MB memory) for free. You can use it as your base in the cloud, for example because the traffic between two EC2 instances is faster/cheaper and because it has full access to machines within the same security group.<br><br>The best choice is likely to base your instance on the <a href=\"http://aws.amazon.com/amazon-linux-ami/\">Amazon Linux AMI</a>, which is a variation of RedHat Linux optimized for AWS, equipped with most of the AWS API command-line tools and CloudInit for automated system setup (described later). I'd recommend you to browse through the <a href=\"http://ec2-downloads.s3.amazonaws.com/AmazonLinuxAMIUserGuide.pdf\">user guide</a> that describes what tools are available and how to use CloudInit.<br><br><h2>What about Automation?</h2><br><br>The AWS Management Console is great if you do something for the first time but the wizards are too time-consuming for repeated tasks. Especially if you need to set up more than a single instance - let's say a RDS database instance, an EC2 machine instance and the corresponding security groups or a number of identical instances. We will look into ways how to automate this.<br><br>Aside of setting up the infrastructure, you usually also need to customize the EC2 instances (at least by installing and starting the software you need them for). You can log into them via SSH but wouldn't it be great to be able to automate that, especially if you need multiple similar instances?<br><br>Notice that I'm now concerned only with automating the work of the AWS user. It is also possible to configure AWS to <a href=\"http://aws.amazon.com/autoscaling/\">automatically start new EC2 instances</a> when needed (e.g. when the load exceeds a limit) but that is a different story.<br><br>Overview:<br><br><ul>\n    <li>Infrastructure provisioning automation:</li>\n<ul>\n    <li>AWS API command-line tools (or AWS Java API or third-party tools/libraries)</li>\n    <li>AWS CloudFormation</li>\n</ul>\n    <li>Instance OS &amp; SW setup automation:</li>\n<ul>\n    <li>Canonical CloudInit (Ubuntu and Amazon Linux AMIs) - perhaps leveraging Puppet or Chef</li>\n    <li>Creating a customized AMI</li>\n</ul>\n</ul><br><br><h3>Automating Infrastructure Provisioning</h3><br><br>There are two prominent options for creating your EC2 instances and other resources without the AWS Management Console: AWS API command-line tools and AWS CloudFormation.<br><br><h4>AWS API command-line tools</h4><br><br>Amazon offers command-line tools for most of its services such as EC2 and RDS.<br><br><strong>EC2</strong>: Robert Sosinovski published very good instructions for <a href=\"http://www.robertsosinski.com/2008/01/26/starting-amazon-ec2-with-mac-os-x/\">starting with Amazon EC2 command-line tools</a> (which isn't specific to Mac OS X despite its title) back in 2008 but they are still valid so just follow them, there is no point in repeating them here (basically download, unpack, set environment variables, provide credentials). Alternatively, you can go to the <a href=\"aws.amazon.com/developertools/351\">download page</a> and follow the <a href=\"http://docs.amazonwebservices.com/AWSEC2/latest/UserGuide/index.html?SettingUp_CommandLine.html\">official instructions</a>. I'd recommend you to create a folder to include all the tools =&gt; $AWS_FOLDER/ec2/ etc. instead of ~/.ec2/.<br><br>If you want to use another AWS region than the default us-east-1 then you need to set also the environmental variable EC2_URL, see the list of <a href=\"http://docs.amazonwebservices.com/general/latest/gr/index.html?rande.html#ec2_region\">regional endpoints</a> or the command <em>ec2-describe-regions</em>. Ex. (my URL has ec2 in the middle contrary to the list of endpoints but evidently it works too):<br><br><pre><code>export EC2_URL=https://eu-west-1.ec2.amazonaws.com</code></pre><br><br><strong>Authentication setup for the other tools</strong>: While the documentation for the EC2 tools describes only authentication via the X.509 certificate (environmental variables EC2_PRIVATE_KEY, EC2_CERT), the other tools (at least RDS, CloudFormation) support uniform authentication via the environmental variable AWS_CREDENTIAL_FILE pointing to a file containing your AWS Access Key Id and Secret Key (which you can find in your <a href=\"aws.amazon.com/account\">AWS account</a> under Security Credentials - Access Keys), the configuration is described in the tools' readme files.<br><br><strong>RDS</strong>: Setup of the RDS command-line tools is quite similar to EC2, just <a title=\"RDS tools download page\" href=\"http://aws.amazon.com/developertools/2928\">download them</a> and add environmental variables as described in the included readme.txt.<br><br>As with EC2, you may want to change your default <a href=\"http://docs.amazonwebservices.com/general/latest/gr/index.html?rande.html#rds_region\">RDS region</a>:<br><br><pre><code>export RDS_URL=https://eu-west-1.rds.amazonaws.com</code></pre><br><br><h5>Examples from the Vaadin Test Setup</h5><br><br>My original plan was to try the performance testing described in <a href=\"https://vaadin.com/wiki/-/wiki/Main/Vaadin Scalability Testing with Amazon Web Services\">Vaadin Scalability Testing with Amazon Web Services</a>, which unfortunately proved to be impossible because the test application failed to run. During the process I've automated the individual setup steps, shown below. You may want to check the blog post to understand the context.<br><br>I didn't need to create a security group and allow access to it via the command-line as I've done it via the Management Console. You could open the SSH port as follows:<br><br><pre><code>ec2-authorize  -p 22</code></pre><br><br>Create two EC2 instances:<br><br><pre><code>ec2-run-instances ami-1a0f3d6e -t m1.large -k VaadinAS --instance-count 2 -z eu-west-1c -g quick-start-1</code></pre><br><br><ul>\n    <li>-k specifies the name of an existing key-pair (the Management Console offers you to create it the first time you create an instance) that will be associated with the instance to make ssh login without a password possible</li>\n    <li>-z specifies the availability zone (AZ) within the region (you can see the available ones when creating an instance in the Mgmt Console), it's likely better to have all resources in the same AZ</li>\n    <li>-g specifies an existing security group (again created in the Console); default is \"default\", I believe</li>\n</ul><br><br>The <em>ec2-run-instances</em> command also supports the --user-data or --user-data-file attribute to pass setup instructions to CloudInit, as described later on.<br><br>To log into instances you will need their public domain name/IP (printed when the command finishes) and user name, which depends on the AMI used (easiest: right-click on the instance in the Mgmt Console and select \"Connect\" to get a complete SSH connect command), and the key file (./VaadinAS.pem in my case). Thus I would log into my first instance as follows (provided that I've already opened port 22 in the security group):<br><br><pre><code>ssh -i VaadinAS.pem ubuntu@ec2-46-137-136-253.eu-west-1.compute.amazonaws.com</code></pre><br><br>Create a RDS instance using MySQL (it may take few minutes before its startup finishes):<br><br><pre><code>rds-create-db-instance quicktickets --allocated-storage 5 -c db.m1.large  -e MySQL5.1 -u quicktickets -p V3ryS3cr3t  -z eu-west-1c --backup-retention-period 0 --db-name quicktests</code></pre><br><br><ul>\n    <li>quicktickets will be the name of the instance</li>\n    <li>the max. size will be 5 GB (can be changed later)</li>\n    <li>-c - it will be based on the db.m1.large instance</li>\n    <li>-e - the DB type is MySQL, -u username quicktickets, -p password V3ryS3cr3t</li>\n    <li>-z eu-west-1c puts it into the same AZ as the EC2 instances</li>\n    <li>--backup-retention-period 0 - don't keep backups (default: 1 day)</li>\n    <li>--db-name quicktests - needed for connecting to it</li>\n</ul><br><br>Next I need to make the DB accessible from my EC2 instances (that are in the security group quick-start-1 ):<br><br><pre><code>rds-authorize-db-security-group-ingress default --ec2-security-group-name quick-start-1 --ec2-security-group-owner-id </code></pre><br><br><ul>\n    <li>You can find your AWS Account ID in your <a href=\"aws.amazon.com/account\">AWS account</a> under the Security Credentials</li>\n</ul><br><br>To find out the hostname of the instance execute <em>rds-describe-db-instance</em>, which will also tell you whether it is still launching or already running.<br><br>Now you can connect to the DB from an EC2 instance in the security group:<br><br><pre><code>mysql -h quicktickets.cpokd2djuazy.eu-west-1.rds.amazonaws.com -u quicktickets --password=V3ryS3cr3t quicktickets</code></pre><br><br><h4>AWS CloudFormation</h4><br><br><a href=\"http://aws.amazon.com/cloudformation/\">CloudFormation</a> is a new (2/2011) free service from Amazon that enables you to describe the resources you want and their dependencies in a text format and to use this \"template\" to instantiate them (\"to create a stack\") either via the AWS Management Console or via the <a href=\"http://aws.amazon.com/developertools/AWS-CloudFormation/2555753788650372\">CloudFormation Command Line Tools</a>. You can also share you template and use and combine templates created by others. The templates also support the UserData attribute that you can use to pass setup instructions to CloudInit, as described later on. Check out this screenshot-based post about <a href=\"http://bioteam.net/2011/02/amazon-cloudformation-first-look/\">setting up a CF stack via the Management Console</a>.<br><br>An example template file:<br><br><pre><code>\r\n{  &amp;quot;AWSTemplateFormatVersion&amp;quot;: &amp;quot;2010-09-09&amp;quot;,\r\n  &amp;quot;Description&amp;quot; : &amp;quot;One EC2 instance with a security group open for SSH&amp;quot;,<br><br>  &amp;quot;Parameters&amp;quot;: {\r\n    &amp;quot;KeyName&amp;quot;: {\r\n      &amp;quot;Description&amp;quot; : &amp;quot;Name of an existing EC2 KeyPair to enable SSH access&amp;quot;,\r\n      &amp;quot;Type&amp;quot;: &amp;quot;String&amp;quot;\r\n    },\r\n    &amp;quot;InstanceType&amp;quot;: {\r\n      &amp;quot;Default&amp;quot;: &amp;quot;m1.large&amp;quot;,  &amp;quot;Type&amp;quot;: &amp;quot;String&amp;quot;\r\n    }\r\n  },<br><br>  &amp;quot;Resources&amp;quot;: {<br><br>    &amp;quot;EC2SecurityGroup&amp;quot;: {\r\n      &amp;quot;Properties&amp;quot;: {\r\n        &amp;quot;SecurityGroupIngress&amp;quot;: [\r\n          {\r\n            &amp;quot;FromPort&amp;quot;: &amp;quot;22&amp;quot;,\r\n            &amp;quot;CidrIp&amp;quot;: &amp;quot;0.0.0.0/0&amp;quot;,\r\n            &amp;quot;ToPort&amp;quot;: &amp;quot;22&amp;quot;,\r\n            &amp;quot;IpProtocol&amp;quot;: &amp;quot;tcp&amp;quot;\r\n          }\r\n        ],\r\n        &amp;quot;GroupDescription&amp;quot;: &amp;quot;SSH access&amp;quot;\r\n      },\r\n      &amp;quot;Type&amp;quot;: &amp;quot;AWS::EC2::SecurityGroup&amp;quot;\r\n    },<br><br>    &amp;quot;Ec2Instance&amp;quot;: {\r\n      &amp;quot;Properties&amp;quot;: {\r\n        &amp;quot;SecurityGroups&amp;quot;: [{&amp;quot;Ref&amp;quot;: &amp;quot;EC2SecurityGroup&amp;quot;}],\r\n        &amp;quot;ImageId&amp;quot;: { &amp;quot;Fn::FindInMap&amp;quot;: [&amp;quot;AWSRegionArch2AMI&amp;quot;,\r\n            {&amp;quot;Ref&amp;quot;: &amp;quot;AWS::Region&amp;quot;}, &amp;quot;64&amp;quot;\r\n          ]\r\n        },\r\n        &amp;quot;UserData&amp;quot;: {\r\n          &amp;quot;Fn::Base64&amp;quot;: { &amp;quot;Fn::Join&amp;quot;: [&amp;quot;&amp;quot;, [\r\n              &amp;quot;#!/bin/bash -v\\n&amp;quot;,\r\n              &amp;quot;# you init bash script here...\\n&amp;quot;\r\n        ]]} },\r\n        &amp;quot;KeyName&amp;quot;: { &amp;quot;Ref&amp;quot;: &amp;quot;KeyName&amp;quot; },\r\n        &amp;quot;InstanceType&amp;quot;: { &amp;quot;Ref&amp;quot;: &amp;quot;InstanceType&amp;quot; }\r\n      },\r\n      &amp;quot;Type&amp;quot;: &amp;quot;AWS::EC2::Instance&amp;quot;\r\n    }\r\n  },<br><br>  &amp;quot;Mappings&amp;quot;: {\r\n    &amp;quot;AWSInstanceType2Arch&amp;quot; : {\r\n      &amp;quot;m1.large&amp;quot;    : { &amp;quot;Arch&amp;quot; : &amp;quot;64&amp;quot; }, &amp;quot;m1.xlarge&amp;quot;   : { &amp;quot;Arch&amp;quot; : &amp;quot;64&amp;quot; }, ...\r\n    }\r\n  },<br><br>  &amp;quot;Outputs&amp;quot; : {\r\n    &amp;quot;InstanceId&amp;quot; : {\r\n      &amp;quot;Description&amp;quot; : &amp;quot;InstanceId of the newly created EC2 instance&amp;quot;,\r\n      &amp;quot;Value&amp;quot; : { &amp;quot;Ref&amp;quot; : &amp;quot;Ec2Instance&amp;quot; }\r\n    },\r\n    &amp;quot;AZ&amp;quot; : {\r\n      &amp;quot;Description&amp;quot; : &amp;quot;Availability Zone of the newly created EC2 instance&amp;quot;,\r\n      &amp;quot;Value&amp;quot; : { &amp;quot;Fn::GetAtt&amp;quot; : [ &amp;quot;Ec2Instance&amp;quot;, &amp;quot;AvailabilityZone&amp;quot; ] }\r\n    },\r\n    &amp;quot;PublicIP&amp;quot; : {\r\n      &amp;quot;Description&amp;quot; : &amp;quot;Public IP address of the newly created EC2 instance&amp;quot;,\r\n      &amp;quot;Value&amp;quot; : { &amp;quot;Fn::GetAtt&amp;quot; : [ &amp;quot;Ec2Instance&amp;quot;, &amp;quot;PublicIp&amp;quot; ] }\r\n    }\r\n  }\r\n}\r\n</code></pre><br><br><ul>\n    <li>4: As you can see, you can define properties (with defaults) for which values may be supplied when a new stack is being created from the template</li>\n    <li>16, 31: Next it defines two resources: a security group and an EC2 instance (which uses some mappings because the names of AMIs differ based in region)</li>\n    <li>38: Setup instructions can be supplied to CloudInit via base64-encoded UserData</li>\n    <li>56: You can also define what information should be available via the DescribeStacks function (command line: cfn-describe-stacks)</li>\n</ul><br><br>CloudFormation let you define any resource (EC2 instances, RDS instances, load balancers, security groups, ...), their dependencies, and, via CloudInit, various boot-time actions such as SW installation. The templates are valid JSON documents.<br><br>Example: <a href=\"http://docs.amazonwebservices.com/FeaturedArticles/latest/index.html?cloudformation-waitcondition-article.html\">Using CloudFormation and Cloud-Init to install and start a RoR application</a> (featuring the WaitCondition) - it is not too long and describes the individual sections of the template file. You can also browse through the <a href=\"http://aws.amazon.com/cloudformation/aws-cloudformation-templates/\">public template files</a>, for example this: <a href=\"https://s3.amazonaws.com/cloudformation-templates-us-east-1/Drupal_Single_Instance_With_RDS.template\">Single EC2 Instance web server with Amazon RDS database instance</a>.<br><br>In June 2011 Amazon launched also <a href=\"https://forums.aws.amazon.com/ann.jspa?annID=1048\">CloudFormer</a>, a prototype tool that enables you to create CloudFormation templates from the existing AWS resources in your account.<br><br>If you still desire more information, read the <a href=\"docs.amazonwebservices.com/AWSCloudFormation/latest/UserGuide/\">CloudFormation User Guide</a>.<br><br><h5>Customizing an Instance with CloudFormation Metadata and Helper Scripts</h5><br><br>From <a href=\"https://s3.amazonaws.com/cloudformation-examples/BoostrappingApplicationsWithAWSCloudFormation.pdf\">Bootstrapping Applications via AWS CloudFormation</a>:<br><br><blockquote>AWS CloudFormation allows you to define the set of packages, files and operating system services through metadata in a template. In addition, it provides helper functions to\ninterpret the metadata and act on it, installing packages, creating files and starting or restarting services on the instance. The AWS CloudFormation scripts build on the basic CloudInit functionality and enable you to create a common, simple CloudInit startup script that is data-driven through metadata. You describe what needs to be installed on the host in metadata and AWS CloudFormation takes care of the how.</blockquote><br><br>See the document for instructions on how to use the metadata and <a href=\"http://aws.amazon.com/developertools/AWS-CloudFormation/4026240853893296\">helper scripts</a> such as <em>cfn-init</em>, which installs packages, downloads and unpacks archives, starts services, and creates files based on data in the metadata section. It also mentiones the integration of CloudFormation and Chef or Puppet, which is described in more detail in the whitepapers <a href=\"https://s3.amazonaws.com/cloudformation-examples/IntegratingAWSCloudFormationWithOpscodeChef.pdf\">Integrating AWS CloudFormation with Opscode Chef</a> and <a href=\"https://s3.amazonaws.com/cloudformation-examples/IntegratingAWSCloudFormationWithPuppet.pdf\">Integrating AWS CloudFormation with Puppet</a>. If you intended to use CloudFormation then you should absolutely read this 22 pages guide.<br><br>(Note: <em>cfn-init</em> supports downloading and unpacking packages, which can be used e.g. to fetch the latest source code of you application provided on-demand by GitHub.)<br><br>You can see an example of usage in this <a href=\"https://s3.amazonaws.com/cloudformation-templates-us-east-1/Drupal_Single_Instance_With_RDS.template\">template leveraging metadata &amp; helper scripts</a>.<br><br><h4>Other Alternatives</h4><br><br><ul>\n    <li>AWS Java API (the command-line tools use it, it's based on web service calls)</li>\n    <li>Third-party tools/libraries, e.g. the Ruby gem <a href=\"https://github.com/fog/fog\">Fog</a>.</li>\n    <li><a href=\"http://wiki.opscode.com/display/chef/Launch+Cloud+Instances+with+Knife\">Chef + Knife</a>, Puppet (I believe they provide their own wrappers for the AWS WS calls and leverage CloudInit)</li>\n</ul><br><br><h3>Automating EC2 Instance OS/SW Setup</h3><br><br>To customize the software inside EC2 instances and its configuration you can either create a customized AMI or use Canonical's CloudInit with AMIs that support it (Amazon Linux and Ubuntu and maybe others). If you use CloudFormation, you have also another possibility based on CloudInit, described in the C.F. section above.<br><br><h4>Canonical CloudInit and Instance User Data</h4><br><br>You can pass whatever text data to a new instance via the <a href=\"http://docs.amazonwebservices.com/AWSEC2/latest/UserGuide/index.html?instancedata-data-categories.html\">User Data</a> attribute (up to 16KB), the data is then available from within the instance at http://169.254.169.254/latest/user-data (you can also <a href=\"http://docs.amazonwebservices.com/AWSEC2/latest/UserGuide/index.html?AESDG-chapter-instancedata.html\">access various metadata</a> in a similar way). <a href=\"https://help.ubuntu.com/community/CloudInit\">CloudInit</a> is a Linux utility developed by Canonical, the company behind Ubuntu, that reads these data and processes any instructions embedded in them at boot time (approximately when rc.local runs). For example if it starts with #! then it is run as a shell script under root.<br><br>CloudInit accepts different types of instructions in user data, distinguished by the first line: a script (#!...), cloud config data i.e. packages to install etc. (#cloud-config), URLs of files to process (#include ...), #upstart-job to add something to /etc/init (run on each boot) and more. It can even handle gzip-compressed user data and multi-part data, combining several of the instruction types (see <a href=\"https://launchpad.net/cloud-utils\">cloud-utils</a> and the command <a href=\"http://www.makelinux.net/man/1/W/write-mime-multipart\">write-mime-multipart</a>).<br><br>The type <a href=\"http://ubuntu-smoser.blogspot.com/2010/03/introducing-cloud-inits-cloud-config.html\">#cloud-config</a> is quite useful as it is a simpler way to install packages and execute commands than a bash script. It contains YAML-formatted instructions, f.ex. \"runcmd\" to run a command-line tool, \"packages\" to install packages via the OS' package manager. Example: <a href=\"http://code.google.com/p/xebia-france/wiki/CloudInitConfigurationToAutomateInstallationOfJenkins\">Installing Jenkins CI with </a><a href=\"http://code.google.com/p/xebia-france/wiki/CloudInitConfigurationToAutomateInstallationOfJenkins\">#cloud-config</a>.<br><br>CloudInit isn't very well documented yet, you may ocassionaly need to <a href=\"http://code.launchpad.net/~cloud-init-dev/cloud-init/trunk\">read the Python source codes</a>. If something goes wrong, you can check the logs in the instance's /var/log/cloud-init.log.<br><br>Aside of the official documentation you might want to see Xebia's <a href=\"http://www.slideshare.net/XebiaFrance/cloudinit-introduction\">CloudInit introduction presentation</a> and read the section on CloudInit in the Amazon Linux AMI <a href=\"http://ec2-downloads.s3.amazonaws.com/AmazonLinuxAMIUserGuide.pdf\">user guide</a>.<br><br><h4>Creating a Customized Amazon Machine Image</h4><br><br>CloudInit installs and configures software at launch time and thus the instance takes longer to become fully available. If that is a problem then you may prefer to create your own customized <a href=\"http://aws.amazon.com/amis\">Amazon Machine Image</a> (AMI) with all the software already installed and configured. It's described e.g. in this brief <a href=\"http://docs.amazonwebservices.com/AWSEC2/2007-08-29/GettingStartedGuide/creating-an-image.html\">how to create a new AMI from an existing one</a> (2007) or in the <a href=\"http://docs.amazonwebservices.com/AWSEC2/latest/UserGuide/index.html?creating-an-ami.html\">official AMI customization docs</a> and you may also want to have a look at the <a href=\"http://aws.amazon.com/developertools/368\">EC2 AMI command line tools</a>. You'd then create new EC2 instances based on the customized AMI.<br><br><h2>Some Related Stuff</h2><br><br>If your EC2 instances need to communicate and use a technology that requires them to be on the same subnet then you can use Amazon <a href=\"http://aws.amazon.com/vpc/\">Virtual Private Cloud</a> (VPC; free) and even connect it to your data center via VPN ($0.05/h). This may be necessary for example for running <a href=\"http://jmeter.apache.org/usermanual/remote-test.html\">multiple JMeter instances</a>.<br><br>Regarding JMeter, Jörg Kalsbach has created an AMI that simplifies the creation of JMeter master-slaves farms (3/2010): <a href=\"http://aws.amazon.com/amis/2924\">JMeter In The Cloud - A cloud based load testing environment</a> (read the doc). (The trick is that the master instance starts the slave instances and thus knows their IPs. I guess that something similar could be done with CloudFormation, Auto Scale and user data/CloudInit.)<br><br><h2>Summary</h2><br><br>AWS is a dynamically developing platform with continually improving tooling and a growing offer of services. It's very easy to get started with using the web-based Management Console but it becomes soon more convenient to move to a more automated interface, such as the command-line tools or even CloudFormation for whole infrastructure stack setup. The support for customizing instances either by creating custom images or at launch time via CloudInit and/or CloudFormation's metadata and scripts is very good and people have already been combining it with their favorite DevOps tools Chef and Puppet.<br><br>I'd recommend you to start with AWS using the Management Console and then to switch to the command-line tools and CloudInit when you become comfortable with the concepts and usage. If you need to provision multiple resources repeatedly, you should use CloudFormation with its metadata and helper scripts (perhaps leveraging also Puppet/Chef).<br><br><p style=\"text-align:center;\"><em>Published originally at <a href=\"http://blog.iterate.no/2011/12/02/getting-started-with-amazon-web-services-and-fully-automated-resource-provisioning-in-15-minutes/\">blog.iterate.no</a>.</em></p>",
  "excerpt": ""
 },
 {
  "title": "Quiz: What''s the Best Test Method Name?",
  "published": "2011-12-13 20:36:08",
  "postType": "post",
  "slug": "/2011/12/13/quiz-whats-the-best-test-method-name/",
  "status": "publish",
  "tags": [
   "CleanCode",
   "java",
   "opinion"
  ],
  "categories": [
   "General",
   "Languages",
   "Testing"
  ],
  "content": "Which of the following names of test methods do you think to be the best?<br><br>[polldaddy poll=5757187]<br><br>(Notice that we could leave out \"payment_\" from the last name if it is clear from the context, i.e. from the fixture [a fancy name for test class] name.)<br><br>According to the holy book of <a href=\"http://www.amazon.fr/Clean-Code-Handbook-Software-Craftsmanship/dp/0132350882\">Clean Code</a>, the code should make visible the <em>intent</em> as much as possible. According to the testing guru Kent B., a test should be <em>telling a story</em> to its reader - a story about how the code should be used and function. According to these two and my own experiences from reading a lot of (test) core written by other people, the last one is absolutely the best. However you have the right to disagree and discuss :-)<br><br>PS: I firmly believe that calling a test method \"<em>test()</em>\" should be punishable.",
  "excerpt": ""
 },
 {
  "title": "Most interesting links of December",
  "published": "2011-12-31 21:59:03",
  "postType": "post",
  "slug": "/2011/12/31/most-interesting-links-of-december-2/",
  "status": "publish",
  "tags": [
   "BDD",
   "clojure",
   "cloud",
   "Maven",
   "performance",
   "SbE",
   "Testing"
  ],
  "categories": [
   "eclipse",
   "General",
   "Testing",
   "Top links of month"
  ],
  "content": "<h2>Recommended Readings</h2>\r\n<ul>\r\n\t<li><a href=\"http://techblog.netflix.com/2011/07/netflix-simian-army.html\">The Netflix Chaos Monkey</a> - how to test your preparedness for dealing with a system failure so that you won't experience nasty wakeup when something really fails in Sunday 3 am? Release a wild, armed monkey into your datacenter. Watch carefuly what happens as it randoly kills your instances. This is exactly what Netflix does with their with their cloud infrastructure - also a great inspiration for my recent project. Do you need to be always available? Than consider employing the chaos monkey - or a whole army of monkeys!\r\n(PS: There is also a post with a <a href=\"http://highscalability.com/blog/2010/12/28/netflix-continually-test-by-failing-servers-with-chaos-monke.html\">picture of the scary monky</a>.)</li>\r\n</ul>\r\n<h2>Links to Keep</h2>\r\n<ul>\r\n\t<li><a href=\"http://concordion.org/Technique.html\">BDD: Write specifications, not scripts</a> (from the Concordion site) - relatively brief yet very enriching practical description of how to do behavior-driven development a.k.a. Specification by Example right, the key point here being \"Write specifications, not scripts.\" It says why not (for scripts overspecify -&gt; are brittle, specs should be stable) and how to do it (decouple the stable spec and the volatile system via fixture code, expose minimal stuff to the spec, perhaps evolve a DSL between the fixture and the system). It also lists common \"smells\" of BDD done wrong. If it still isn't clear to you, read the <a href=\"http://concordion.org/ScriptingMakeover.html\">Script to Specification Makeover example</a> (or perhaps read it anyway). BTW, <a href=\"http://concordion.org/\">Concordion</a> is a new tool for doing BDD based on JUnit and HTML, which was created as a response to the weaknesses of Fit[Nesse], i.e. exactly the tendency to do scripting instead of specifications. It looks very promissing to me!</li>\r\n</ul>\r\n<h2>SW Utilities</h2>\r\n<ul>\r\n\t<li>(Linux/Mac) <a href=\"http://jakemccrary.com/blog/2011/07/25/utilities-i-like-autojump/\">Autojump - superfast navigation between favorite directories</a> in the command line (via Jake McCrary) - it keeps track of how much time you spend in each directory and when you execute <code>j &lt;substring of directory path/name&gt;</code>, it jumps into the most frequently used one matching the substring. It awesome! (You can also run <code>jumpstat</code> to see the statistics.)</li>\r\n\t<li>(Linux) <a href=\"http://jakemccrary.com/blog/2011/06/28/a-simple-way-of-testing-disconnect-logic/\">Tcpkill - service/network outage testing</a> (via Jake McCrary) - kill connections to or from a particular host, network, port, or combination of all - useful e.g. when you want to test that your software is resilient to the outage of a particular service or server - less brutal than actually killing the database etc. instances. We need to test that our application recoveres properly when one of our MongoDB nodes dies so this may be quite useful.</li>\r\n\t<li><a href=\"http://code.google.com/p/manik-hot-deploy/\">Manik Hot Deploy Plugin for Maven Projects</a> (v1.0.2 in 5/2011; older version <a href=\"http://marketplace.eclipse.org/content/manik-hot-deploy-plugin\">in the Marketplace</a>) - plugin that can do hot and incremental deployment to any app server (simply by copying to its hotdeploy directory or the directory of an installed webapp) whenever you run <em>mvn install</em> or automatically whenever sources change, multi-module support</li>\r\n</ul>\r\n<h2>Clojure Corner</h2>\r\n<ul>\r\n\t<li>Jake McCrary: <a href=\"http://jakemccrary.com/blog/2011/12/16/continuous-testing-with-clojure-and-expectations/?utm_source=twitterfeed&amp;utm_medium=twitter&amp;utm_campaign=Feed%3A+JakeMccrarysMusings+%28Jake+McCrary%27s+Musings%29\">Continuous Testing With Clojure and Expectations</a> - continuous test runner <em>lein-autoexpect</em> for Clojure tests written using the library <em>expectations</em> by Jay Field.</li>\r\n\t<li>Jake McCrary:<a href=\"http://jakemccrary.com/blog/2010/12/07/quickily-starting-a-powerful-clojure-repl/\"> Quickly Starting a Powerful Clojure REPL</a> - Clojure REPL only two steps away: 1) Run Emacs, 2) Execute M-x clojure-swank (no more need to open an existing Leinigen project) - the trick is to install the Leinigen plugin swank-clojure and use Jake's elisp function clojure-swank that automatically starts the swank-clojure server. (I had to hack the function for the clojure-swank output contained \"null\" instead of \"localhost\", likely due to incorrect DNS setup.)</li>\r\n</ul>\r\n<div class=\"linkscent-iconblock\" style=\"float:none!important;border:0 solid #ff0000!important;background:none repeat scroll center center transparent!important;width:auto!important;height:auto!important;display:block!important;overflow:visible!important;position:static!important;text-indent:0!important;z-index:auto!important;max-width:none!important;min-width:0!important;max-height:none!important;min-height:0!important;left:auto!important;top:auto!important;bottom:auto!important;right:auto!important;line-height:16px!important;white-space:nowrap!important;margin:0!important;padding:0!important;\"><img class=\"linkscent-icon\" style=\"float:none!important;border:0 solid #ff0000!important;width:16px!important;height:16px!important;display:none;overflow:visible!important;position:absolute!important;text-indent:0!important;z-index:2147483635!important;max-width:none!important;min-width:0!important;max-height:none!important;min-height:0!important;left:382px;top:121px;bottom:auto!important;right:auto!important;line-height:16px!important;white-space:nowrap!important;visibility:hidden;background:url('http://highscalability.com/favicon.png') no-repeat scroll center center transparent!important;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" /><img class=\"linkscent-icon\" style=\"float:none!important;border:0 solid #ff0000!important;background:none repeat scroll center center transparent;width:16px!important;height:16px!important;display:none;overflow:visible!important;position:absolute!important;text-indent:0!important;z-index:2147483635!important;max-width:none!important;min-width:0!important;max-height:none!important;min-height:0!important;left:400px;top:121px;bottom:auto!important;right:auto!important;line-height:16px!important;white-space:nowrap!important;visibility:hidden;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" /></div>\r\n<div class=\"linkscent-iconblock\" style=\"float:none!important;border:0 solid #ff0000!important;background:none repeat scroll center center transparent!important;width:auto!important;height:auto!important;display:block!important;overflow:visible!important;position:static!important;text-indent:0!important;z-index:auto!important;max-width:none!important;min-width:0!important;max-height:none!important;min-height:0!important;left:auto!important;top:auto!important;bottom:auto!important;right:auto!important;line-height:16px!important;white-space:nowrap!important;margin:0!important;padding:0!important;\"><img class=\"linkscent-icon\" style=\"float:none!important;border:0 solid #ff0000!important;width:16px!important;height:16px!important;display:none;overflow:visible!important;position:absolute!important;text-indent:0!important;z-index:2147483635!important;max-width:none!important;min-width:0!important;max-height:none!important;min-height:0!important;left:429px;top:562px;bottom:auto!important;right:auto!important;line-height:16px!important;white-space:nowrap!important;visibility:hidden;background:url('http://jakemccrary.com/favicon.ico') no-repeat scroll center center transparent!important;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" /><img class=\"linkscent-icon\" style=\"float:none!important;border:0 solid #ff0000!important;background:none repeat scroll center center transparent;width:16px!important;height:16px!important;display:none;overflow:visible!important;position:absolute!important;text-indent:0!important;z-index:2147483635!important;max-width:none!important;min-width:0!important;max-height:none!important;min-height:0!important;left:447px;top:562px;bottom:auto!important;right:auto!important;line-height:16px!important;white-space:nowrap!important;visibility:hidden;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" /></div>\r\n<div class=\"linkscent-iconblock\" style=\"float:none!important;border:0 solid #ff0000!important;background:none repeat scroll center center transparent!important;width:auto!important;height:auto!important;display:block!important;overflow:visible!important;position:static!important;text-indent:0!important;z-index:auto!important;max-width:none!important;min-width:0!important;max-height:none!important;min-height:0!important;left:auto!important;top:auto!important;bottom:auto!important;right:auto!important;line-height:16px!important;white-space:nowrap!important;margin:0!important;padding:0!important;\"><img class=\"linkscent-icon\" style=\"float:none!important;border:0 solid #ff0000!important;width:16px!important;height:16px!important;display:none;overflow:visible!important;position:absolute!important;text-indent:0!important;z-index:2147483635!important;max-width:none!important;min-width:0!important;max-height:none!important;min-height:0!important;left:464px;top:343px;bottom:auto!important;right:auto!important;line-height:16px!important;white-space:nowrap!important;visibility:hidden;opacity:0;background:url('http://concordion.org/favicon.ico') no-repeat scroll center center transparent!important;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" /><img class=\"linkscent-icon\" style=\"float:none!important;border:0 solid #ff0000!important;background:none repeat scroll center center transparent;width:16px!important;height:16px!important;display:none;overflow:visible!important;position:absolute!important;text-indent:0!important;z-index:2147483635!important;max-width:none!important;min-width:0!important;max-height:none!important;min-height:0!important;left:482px;top:343px;bottom:auto!important;right:auto!important;line-height:16px!important;white-space:nowrap!important;visibility:hidden;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" /><img class=\"linkscent-icon\" style=\"float:none!important;border:0 solid #ff0000!important;width:16px!important;height:16px!important;display:none;overflow:visible!important;position:absolute!important;text-indent:0!important;z-index:2147483635!important;max-width:none!important;min-width:0!important;max-height:none!important;min-height:0!important;left:429px;top:713px;bottom:auto!important;right:auto!important;line-height:16px!important;white-space:nowrap!important;visibility:hidden;background:url('http://jakemccrary.com/favicon.ico') no-repeat scroll center center transparent!important;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" /><img class=\"linkscent-icon\" style=\"float:none!important;border:0 solid #ff0000!important;background:none repeat scroll center center transparent;width:16px!important;height:16px!important;display:none;overflow:visible!important;position:absolute!important;text-indent:0!important;z-index:2147483635!important;max-width:none!important;min-width:0!important;max-height:none!important;min-height:0!important;left:447px;top:713px;bottom:auto!important;right:auto!important;line-height:16px!important;white-space:nowrap!important;visibility:hidden;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" /><img class=\"linkscent-icon\" style=\"float:none!important;border:0 solid #ff0000!important;width:16px!important;height:16px!important;display:none;overflow:visible!important;position:absolute!important;text-indent:0!important;z-index:2147483635!important;max-width:none!important;min-width:0!important;max-height:none!important;min-height:0!important;left:309px;top:643px;bottom:auto!important;right:auto!important;line-height:16px!important;white-space:nowrap!important;visibility:hidden;background:url('http://code.google.com/favicon.ico') no-repeat scroll center center transparent!important;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" /><img class=\"linkscent-icon\" style=\"float:none!important;border:0 solid #ff0000!important;background:url('//interclue/content/cluecore/skins/default/sprites.png') no-repeat scroll -8px 0 transparent;width:16px!important;height:16px!important;display:none;overflow:visible!important;position:absolute!important;text-indent:0!important;z-index:2147483635!important;max-width:none!important;min-width:0!important;max-height:none!important;min-height:0!important;left:327px;top:643px;bottom:auto!important;right:auto!important;line-height:16px!important;white-space:nowrap!important;visibility:hidden;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" width=\"16\" height=\"16\" /><img class=\"linkscent-icon\" style=\"float:none!important;border:0 solid #ff0000!important;background:url('//interclue/content/cluecore/skins/default/sprites.png') no-repeat scroll -48px -96px transparent;width:16px!important;height:16px!important;display:none;overflow:visible!important;position:absolute!important;text-indent:0!important;z-index:2147483635!important;max-width:none!important;min-width:0!important;max-height:none!important;min-height:0!important;left:345px;top:643px;bottom:auto!important;right:auto!important;line-height:16px!important;white-space:nowrap!important;visibility:hidden;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" width=\"16\" height=\"16\" /><img class=\"linkscent-icon\" style=\"float:none!important;border:0 solid #ff0000!important;background:none repeat scroll center center transparent;width:16px!important;height:16px!important;display:none;overflow:visible!important;position:absolute!important;text-indent:0!important;z-index:2147483635!important;max-width:none!important;min-width:0!important;max-height:none!important;min-height:0!important;left:363px;top:643px;bottom:auto!important;right:auto!important;line-height:16px!important;white-space:nowrap!important;visibility:hidden;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" /><img class=\"linkscent-icon\" style=\"float:none!important;border:0 solid #ff0000!important;width:16px!important;height:16px!important;display:none;overflow:visible!important;position:absolute!important;text-indent:0!important;z-index:2147483635!important;max-width:none!important;min-width:0!important;max-height:none!important;min-height:0!important;left:601px;top:643px;bottom:auto!important;right:auto!important;line-height:16px!important;white-space:nowrap!important;visibility:hidden;background:url('http://eclipse.org/favicon.ico') no-repeat scroll center center transparent!important;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" /><img class=\"linkscent-icon\" style=\"float:none!important;border:0 solid #ff0000!important;background:url('//interclue/content/cluecore/skins/default/sprites.png') no-repeat scroll -48px -96px transparent;width:16px!important;height:16px!important;display:none;overflow:visible!important;position:absolute!important;text-indent:0!important;z-index:2147483635!important;max-width:none!important;min-width:0!important;max-height:none!important;min-height:0!important;left:619px;top:643px;bottom:auto!important;right:auto!important;line-height:16px!important;white-space:nowrap!important;visibility:hidden;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" width=\"16\" height=\"16\" /><img class=\"linkscent-icon\" style=\"float:none!important;border:0 solid #ff0000!important;background:none repeat scroll center center transparent;width:16px!important;height:16px!important;display:none;overflow:visible!important;position:absolute!important;text-indent:0!important;z-index:2147483635!important;max-width:none!important;min-width:0!important;max-height:none!important;min-height:0!important;left:637px;top:643px;bottom:auto!important;right:auto!important;line-height:16px!important;white-space:nowrap!important;visibility:hidden;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" /><img class=\"linkscent-icon\" style=\"float:none!important;border:0 solid #ff0000!important;width:16px!important;height:16px!important;display:none;overflow:visible!important;position:absolute!important;text-indent:0!important;z-index:2147483635!important;max-width:none!important;min-width:0!important;max-height:none!important;min-height:0!important;left:476px;top:470px;bottom:auto!important;right:auto!important;line-height:16px!important;white-space:nowrap!important;visibility:hidden;background:url('http://jakemccrary.com/favicon.ico') no-repeat scroll center center transparent!important;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" /><img class=\"linkscent-icon\" style=\"float:none!important;border:0 solid #ff0000!important;background:none repeat scroll center center transparent;width:16px!important;height:16px!important;display:none;overflow:visible!important;position:absolute!important;text-indent:0!important;z-index:2147483635!important;max-width:none!important;min-width:0!important;max-height:none!important;min-height:0!important;left:494px;top:470px;bottom:auto!important;right:auto!important;line-height:16px!important;white-space:nowrap!important;visibility:hidden;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" /></div>\r\n",
  "excerpt": ""
 },
 {
  "title": "AWK: Extract Logs for the Given Date(s) from a Log File",
  "published": "2011-12-18 11:43:52",
  "postType": "post",
  "slug": "/2011/12/18/awk-extract-logs-for-a-given-dates-from-a-log-file/",
  "status": "publish",
  "tags": [
   "analysis",
   "linux",
   "logging"
  ],
  "categories": [
   "General",
   "Tools"
  ],
  "content": "If your log file has entries like these:<br><br><pre><code>\r\n2011-12-10T22:00:27.996+0000 [http-8080-1] INFO  my.package.MyClass Hello, I'm alive!\r\n2011-12-11T17:05:46.811+0000 [http-8080-15] ERROR my.package.MyClass  - Error caught in DispatcherServlet\r\n        at my.package.MyServiceClass(MyServiceClass.java:36)\r\n...\r\n2011-12-11T17:06:10.120+0000 [http-8080-14] DEBUG my.package.MyClass Whoo, that has been a long day!\r\n</code></pre><br><br>Then you can use the following bash script snippet to extract logs only for a particular day or consecutive days, including everything - even lines not starting with the date such as stacktraces - between the first log of the date up to the first log of a subsequent date (default: yesterday):<br><br><pre><code>\r\nLOGFILE_ORIG=&quot;$0&quot;; LOGFILE=&quot;${LOGFILE_ORIG}.subset&quot;\r\nif [ -z &quot;$LOGDAY&quot; ]; then LOGDAY=$(date +%F -d &quot;-1 days&quot;); fi\r\nif [ -z &quot;$AFTERLOGDAY&quot; ]; then AFTERLOGDAY=$(date +%F -d &quot;$LOGDAY +1 days&quot;); fi\r\necho &quot;Extracting logs in the range (&gt;= $LOGDAY &amp;&amp; &lt; $AFTERLOGDAY) into $LOGFILE ...&quot; awk &quot;/^$LOGDAY/,/^$AFTERLOGDAY/ {if(!/^$AFTERLOGDAY/) print}&quot; $LOGFILE_ORIG &gt; $LOGFILE\r\n</code></pre><br><br>This <code>date</code> format works on Linux. Date is very flexible and can provide dates in any format, not only yyyy-mm-dd. You may also want to read more about <a href=\"http://www.catonmat.net/blog/ten-awk-tips-tricks-and-pitfalls/#awk_ranges\">Awk ranges</a> and other tips.<br><br>You would run it in one of the following ways:<br><br><pre><code>\r\n$ ./analysis.sh /path/to/logfile.log\r\n$ LOGDAY=2011-12-12 AFTERLOGDAY=2011-12-17 ./analysis.sh /path/to/logfile.log\r\n</code></pre>",
  "excerpt": ""
 },
 {
  "title": "Annual  Blogging Report 2011",
  "published": "2012-01-01 18:44:01",
  "postType": "post",
  "slug": "/2012/01/01/annual-blogging-report-2011/",
  "status": "publish",
  "tags": [],
  "categories": [
   "Uncategorized"
  ],
  "content": "The WordPress.com stats helper monkeys prepared a 2011 annual report for this blog.<br><br><a href=\"/2011/annual-report/\"><img src=\"http://www.wordpress.com/wp-content/mu-plugins/annual-reports/img/emailteaser.jpg\" alt=\"\" width=\"100%\" /></a><br><br>Here's an excerpt:\r\n<blockquote>Madison Square Garden can seat 20,000 people for a concert. This blog was viewed about <strong>62 000</strong> times in 2011. If it were a concert at Madison Square Garden, it would take about 3 sold-out performances for that many people to see it.</blockquote>\r\n<a href=\"/2011/annual-report/\">Click here to see the complete report.</a>",
  "excerpt": ""
 },
 {
  "title": "uCertify",
  "published": "2012-01-09 19:11:07",
  "postType": "post",
  "slug": "/2012/01/09/ucertify/",
  "status": "publish",
  "tags": [],
  "categories": [
   "Uncategorized"
  ],
  "content": "Some guy from <a href=\"http://www.ucertify.com/\">uCertify</a>, which offers preparation kits for various programming exams in Java and other areas, asked me to review their PrepKit service. I hadn't really the time to do so but I'm sure it's awsome,  and it even work on Macs. So if you want to prepare for an exam, you might consider them.<br><br>I'm very thankful for them for teaching me to never promise anything I'm not really commited to do.",
  "excerpt": ""
 },
 {
  "title": "Key Lessons from the Specification by Example Course, Day 1",
  "published": "2012-01-09 21:37:05",
  "postType": "post",
  "slug": "/2012/01/09/key-lessons-from-the-specification-by-example-course-day-1/",
  "status": "publish",
  "tags": [
   "development",
   "methodology",
   "SbE"
  ],
  "categories": [
   "General",
   "Testing"
  ],
  "content": "I'm taking part in a course of <a href=\"http://www.specificationbyexample.com/\">Specification by Example</a>, lead by <a href=\"http://gojko.net/\">Gojko Adzic</a>. Here I want to summarize the key things I've learned in the first day of this entertaining and fruitful course thanks to both Gojko and my co-participants.<br><br>If you haven't heard about Specification by Example (SbE) before (really?!), then you need know that its main concern is ensuring that you build the right thing (complimentary to building the thing right), which is achieved by specifying functionality collaboratively with business users, testers, and developers, clarifying and nailing them with key examples, and finally, where it is worth the effort, automating checks of those examples to get not only automated acceptance tests but, more importantly, a \"living documentation\" of what the system does that never gets out of date. Best to <a href=\"http://www.specificationbyexample.com/key_ideas.html\">read the key ideas</a> described by Gojko himself or the <a href=\"http://en.wikipedia.org/wiki/Specification_by_example\">SbE Wikipedia page</a>.<!--more--><br><br>The course is a well-balanced mixture of theory, war stories, and practical and fun exercises so there is a lot of opportunities to learn (and basically no opportunity to sleep, as sad as it may be for somebody). Here are the key things I personally have learned today (in the temporal order):\r\n<ol>\r\n\t<li><em>Simplify the domain and examples by extracting individual concepts - when multiple concepts or concerns are mixed together, the specification and tests are too complex and numerous.</em>\r\nSpecifying collaboratively and involving many different people helps to spot those concepts that often are not very obvious.</li>\r\n\t<li><em>When under time press, don't rush to implementation without communicating sufficiently to build a shared understanding first. And, for God's sake, involve the customer!</em>\r\nWhen time is limited, we must first of all agree on what and how to build. Everybody has different expectations so if we don't communicate, everybody will do what s/he believes is needed, resulting in lot of diverging efforts and thus waste.</li>\r\n\t<li><em>Find the time to define a clear sprint goal and objectives.</em>\r\nThey are necessary to direct us to where we are going and to tell us how far we've got. In each team, the answers to \"how far you think you are?\" varied between 30% and 80% with few honest \"I've no idea\".</li>\r\n\t<li><em>Simplify the domain and examples by choosing representations that fit the domain well. It should as simple as possible - but not simpler.</em>\r\nFor example in the domain of Black Jack, it's unwise to represent the total value of player's cards as an integer because 21 composed of three cards and 21 composed of two cards (= black jack) are quite different, also, for any value over 21, we only need to know that it's over the limit. Using just an integer makes the tests hard to understand and leads to unnecessarily many of them. On the other hand, a number is still a much better representation than a list of the individual cards, which contains a lot of unnecessary information (3+7 is no different from 7+3 or 2+8 or 2+2+6).</li>\r\n\t<li><em>Build a shared understanding of the domain, benefiting from the participation of different people to discover special and unclear cases.</em>\r\nSuccessful teams manage to build a shared understanding of the business domain and scope and thus avoid the risk of building something else than expected. It's very surprising how different opinions people may have about even such a simple thing like the number of points in a five-pointed star, considering their understanding to be the obvious one (10 and 5 being the most frequent, with 11 from a vector-based graphic designer and some more weird ones). Thus talking together is really essential. Everybody brings something to the table - business users their domain knowledge, developers the knowledge of possibilities and limitations of the technical solution, testers their expertise in \"breaking\" the system. The more people (to a certain limit) the better.</li>\r\n\t<li> <em>Discover implicit (and often rather different) assumptions by constructing examples for a specification together.</em></li>\r\n\t<li><em>Technique: Set-based design for example representation</em>: Split participants into groups and let each work separately on creating the examples for 10-15 min, then compare the representations they've chosen for the examples and key concepts, merge them into the best possible one. (We had three teams, each represented examples differently, at least two had important ideas that made it into the final representation, better than any of the original ones.)</li>\r\n\t<li><em>If you seem to need too many examples for a specification then you either don't understand the domain well, or are mixing multiple concepts, or have chosen unsuitable representations, or any combination of these.</em></li>\r\n\t<li><em>A user story is a suggestion for a solution, and usually a suboptimal one (for done by an amateur). Always make the business objective clear first.</em>\r\nWar story: The business requested their Bluetooth appliance to be extended with video streaming, which would be extremely technically difficult. It turned out that it's perfectly OK to deliver the video clips up front on a memory card and only play them from it on demand. Months of work saved.</li>\r\n\t<li><em>Specification by Example (collaborative specification, emphasis on the business domain) lead to aligning the business, software and test models. Thus a small change in the business model requires only a small change in tests and the software.</em>\r\nThe maintenance nightmare of unaligned acceptance tests and application, where a small change on the business side may require weeks of work, is gone. Of course this requires a lot of attention to creating the models aligned and keeping them so. See the Domain-Driven Design movement for more info.</li>\r\n\t<li><em>Decide the layer (UI, service, ...) where to test your application and the isolation of the tested module from the environment based on the risk covered and the effort to do so.</em>\r\nThe more right your tests are on the scale an isolated test - an end-to-end test the more risk they cover and the more expensive is it to develop and maintain them (and slow to run). For the same reasons it's rarely worth to test the application via the UI, as opposed to going directly to the service or other layer. Decide where to be based on the risk covered/involved and the (long-term) cost.</li>\r\n\t<li><em>SbE has *nothing* to do with integration tests.</em>\r\nIt may test the system end-to-end but doesn't need to. And it only tests a few key examples for each specification, not all possible values.</li>\r\n\t<li><em>The key benefit of the full SbE is that you gain \"living documentation\".</em>\r\n(Not really a new thing for me but worth repeating. Regression tests usually catch ~ 25% bugs and thus aren't worth the effort. The shared understanding and living docs are, though.)</li>\r\n</ol>\r\nThe tool to achieve many of the above is the <em>Specification Workshop</em> (or an alternative thereof), where business users, testers, and developers (notice the plurals) collaboratively specify functionality and derive key examples for the specifications, thus discovering hidden complexity and extracting individual (separately testable) concepts. War story: Once the business user/analyst said about a requirement that it is so simple that it doesn't need to be discussed. The team persisted and after half an hour all three business people were shouting on each other, unable to reach an agreement. The moral: If it's simple, always give it the 5min for examples. (And yes, there was a happy ending, some 2 weeks later.)<br><br>FYI: I should blog about the days 2 and 3 in a couple of days.",
  "excerpt": ""
 },
 {
  "title": "How to Create Maintainable Acceptance Tests",
  "published": "2012-01-18 20:08:40",
  "postType": "post",
  "slug": "/2012/01/18/how-to-create-maintainable-acceptance-tests/",
  "status": "publish",
  "tags": [
   "maintainability",
   "opinion",
   "SbE",
   "Testing"
  ],
  "categories": [
   "Testing"
  ],
  "content": "This post summarizes what I've learned from various sources about making acceptance or black-box tests maintainable. This topic is of great interest to me because I believe in the benefits that acceptance tests can bring (such as <a href=\"http://specificationbyexample.com/key_ideas.html\">living documentation</a>) but I'm also very much aware that it is all too easy to create an unmaintainable monster whose weight eventually crushes you. So the question is how to navigate the minefield to get to the golden apple?<br><br>The key elements that contribute to the maintainability of acceptance tests are:<br><br><ol>\n    <li><strong>Aligned business, software, and test models</strong> =&gt; small change in business requires only a similarly small change in the software and a small change in tests (Gojko Adzic explains that very well in his JavaZone 2012 talk <a href=\"http://vimeo.com/28722624\">Long-term value of acceptance tests</a>)\n<ul>\n    <li>The key to gaining the alignment is to use business language in all the three models from the very start, building them around business concepts and relationships</li>\n</ul>\n</li>\n    <li><strong>Testing under the surface level</strong>, if possible\n<ul>\n    <li>Prefer to test your application via the service layer or at worst the servlet layer; only test on the UI level if you really have to and only as little as possible for UI is much more brittle (and also difficult to test)</li>\n    <li>The more you want to test the more you have to pay for it in the terms of maintenance effort. Usually you decide so that you cover the part(s) of the application where the most risk is - the best thing is to do cost-benefit evaluation.</li>\n</ul>\n</li>\n    <li><strong>Isolating tests from implementation</strong> by <a href=\"http://concordion.org/Technique.html\">layers of test abstraction</a>\n<ul>\n    <li>Top layer: Acceptance tests should only describe \"what\" is tested and never \"how\" to test it. You must avoid <a href=\"http://concordion.org/ScriptingMakeover.html\">writing scripts instead of specifications</a>.</li>\n    <li>Layer 2: Instrumentation - right below the acceptance test is an instrumentation layer, which extracts input/output data from the test and defines how to perform the test via a high-level API, provided by the next level (we could say a test DSL) such as \"logInUser(X); openAccountPage();\"</li>\n    <li>Layer 3: High-level test DSL: This layer contains all the implementation details and exposes to the higher layer high-level primitives that it can use to compose the tests without depending on implementation details (ex.: logInUser may use HtmlUnit to load a page, fill a form, post it). See the PageObject example below.</li>\n</ul>\n</li>\n</ol><br><br>(And of course many, if not all, of the <a href=\"/2011/11/21/principles-for-creating-maintainable-and-evolvable-tests/\">rules for creating maintainable unit tests</a> apply as well.)<br><br><!--more--><br><br><h2>Maintainability vs. easy of writing</h2><br><br>As <a href=\"http://www.javacodegeeks.com/2015/01/challenging-myself-with-copliens-why-most-unit-testing-is-waste.html/comment-page-1/#comment-47413\">James Coplien points out</a>, it might be better to focus on making it easy to write a test quickly rather than on maintainability - f.ex. by making it easy to get the system into the state where you can access/test a feature and adding hooks that enable you to observe the state of the system (and thus simplify verification of results). You can f.ex. also break a system into a set of smaller systems. &lt;=&gt; does the architecture support the right kind granularity and level of product increment changes?<br><br><h2>What others have to say</h2><br><br>On the three layers of test isolation:<br><br><blockquote>\n<ol>\n    <li>Business rule or functionality level: what is this test demonstrating or exercising. Ideally illustrated with realistic key examples. For example: Free delivery is offered to customers who order two or more books, illustrated with an example of a customer who orders one book and doesn't get free delivery and an example of a customer who orders two books and gets free delivery.</li>\n    <li>User interface workflow level: what does a user have to do to exercise the functionality through the UI, on a higher activity level. For example, put the specified number of books in a shopping cart, enter address details, verify that delivery options include or not include free delivery as expected.</li>\n    <li>Technical activity level: what are the technical steps required to exercise the functionality. For example, open the shop homepage, log in with testuser and testpassword go to the /book page, click on the first image with the book CSS class, wait for page to load, click on the ‘Buy now’ link and so on.</li>\n</ol>\n(<em>The Secret Ninja Cucumber Scrolls, page 109 - 110</em>)</blockquote><br><br>On isolating tests from implementation in Selenium web UI tests by <a href=\"http://code.google.com/p/selenium/wiki/PageObjects\">modelling pages with PageObjects</a>, exposing services (e.g. \"hasUnreadEmail\", \"loginExpctingFailure\") and hiding the low-level implementation details:<br><br><blockquote><a href=\"http://code.google.com/p/selenium/wiki/PageObjects\">PageObjects</a> can be thought of as facing in two directions simultaneously.  Facing towards the developer of a test, they represent the <strong>services</strong> offered by a particular page. Facing away from the developer, they should be the only thing that has a deep knowledge of the structure of the HTML of a page (or part of a page)</blockquote><br><br>The <a href=\"http://thoughtworks.fileburst.com/assets/thoughtworks-tech-radar-march-2012-us-color.pdf\">ThoughtWorks Technology Radar 3/2012</a> promotes <em>testing at the appropriate level</em> (marked as suitable for adoption) while having <em>test recorders</em> \"on hold\" with this comments:<br><br><blockquote>[...], has encouraged widespread use of acceptance testing at the browser level. This unfortunately encouraged doing the bulk of testing where the cost to run the tests is the greatest. Instead, we should <strong>test at the appropriate level</strong>, as close to the code as possible, so that tests can be run with maximum efficiency. Browser-level tests should be the icing on the cake, supported by acceptance and unit tests executed at appropriate layers.<br><br><strong>Test recorders</strong> seem invaluable as they provide a quick way to capture navigation through an application. However, we strongly advise against their regular use, as it tends to result in brittle tests which break with small changes to the UI. The test code they produce tends to be relatively poor and riddled with unnecessary duplication. Most importantly, test recorders tend to cut channels of communication between the test automation and development teams. When faced with an application that is difficult to test through the user interface, the solution is to have a critical conversation between the teams to build a more testable UI.</blockquote><br><br>On aligned business, software and test models:<br><br><blockquote>The principle of symmetric change\nThe best software is the one where the technical software model is aligned with the relevant business domain model. This ensures that one small change in the business domain (new requirements or changes to existing features) results in one small change in software. The same is true for the other artefacts produced for software — tests and documentation. When the tests are aligned with the business domain model, one small change in business will result in one small change in tests, making the tests easy to maintain.\nTests described at a low level technical detail, in the language of technical UI interactions, are everything but aligned with a business model. If anything, they are aligned with the current design and layout of user interfaces. A small change in business requirements can have a huge impact on such tests, requiring hours of updates to tests after just a few minutes of changes to the code.<br><br>(<em>The Secret Ninja Cucumber Scrolls, page 111</em>)</blockquote><br><br><h2>Resources</h2><br><br>This post is very much based on the following resources:<br><br><ol>\n    <li><a href=\"http://cuke4ninja.com/download.html\">The Secret Ninja Cucumber Scrolls</a> (free pdf) by David de Florinier and Gojko Adzic, 2011-03-16</li>\n    <li><a href=\"http://concordion.org/\">http://concordion.org/</a> by David Peterson</li>\n    <li><a href=\"http://specificationbyexample.com/\">Specification by example</a>, Gojko Adzic, 2011, Manning, ISBN 978-1617290084</li>\n    <li><a href=\"http://vimeo.com/28722624\">Long-term value of acceptance tests</a>, Gojko Adzic, a talk at JavaZone 2012</li>\n</ol><br><br><p style=\"text-align:center;\"><em>You might enjoy also other <a href=\"/tag/opinion/\">posts on effective development</a>.</em></p><br><br><div class=\"linkscent-iconblock\" style=\"float:none !important;border:0 solid #ff0000 !important;background:none repeat scroll center center transparent !important;width:auto !important;height:auto !important;display:block !important;overflow:visible !important;position:static !important;text-indent:0 !important;z-index:auto !important;max-width:none !important;min-width:0 !important;max-height:none !important;min-height:0 !important;left:auto !important;top:auto !important;bottom:auto !important;right:auto !important;line-height:16px !important;white-space:nowrap !important;margin:0!important;padding:0!important;\"><img class=\"linkscent-icon\" style=\"float:none !important;border:0 solid #ff0000 !important;width:16px !important;height:16px !important;display:none;overflow:visible !important;position:absolute !important;text-indent:0 !important;z-index:2147483635 !important;max-width:none !important;min-width:0 !important;max-height:none !important;min-height:0 !important;left:406px;top:231px;bottom:auto !important;right:auto !important;line-height:16px !important;white-space:nowrap !important;visibility:hidden;background:url('http://concordion.org/favicon.ico') no-repeat scroll center center transparent !important;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" /><img class=\"linkscent-icon\" style=\"float:none !important;border:0 solid #ff0000 !important;background:none repeat scroll center center transparent;width:16px !important;height:16px !important;display:none;overflow:visible !important;position:absolute !important;text-indent:0 !important;z-index:2147483635 !important;max-width:none !important;min-width:0 !important;max-height:none !important;min-height:0 !important;left:424px;top:231px;bottom:auto !important;right:auto !important;line-height:16px !important;white-space:nowrap !important;visibility:hidden;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" /><img class=\"linkscent-icon\" style=\"float:none !important;border:0 solid #ff0000 !important;width:16px !important;height:16px !important;display:none;overflow:visible !important;position:absolute !important;text-indent:0 !important;z-index:2147483635 !important;max-width:none !important;min-width:0 !important;max-height:none !important;min-height:0 !important;left:251px;top:778px;bottom:auto !important;right:auto !important;line-height:16px !important;white-space:nowrap !important;visibility:hidden;background:url('http://cuke4ninja.com/favicon.ico') no-repeat scroll center center transparent !important;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" /><img class=\"linkscent-icon\" style=\"float:none !important;border:0 solid #ff0000 !important;background:url('//interclue/content/cluecore/skins/default/sprites.png') no-repeat scroll -48px -96px transparent;width:16px !important;height:16px !important;display:none;overflow:visible !important;position:absolute !important;text-indent:0 !important;z-index:2147483635 !important;max-width:none !important;min-width:0 !important;max-height:none !important;min-height:0 !important;left:269px;top:778px;bottom:auto !important;right:auto !important;line-height:16px !important;white-space:nowrap !important;visibility:hidden;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" width=\"16\" height=\"16\" /><img class=\"linkscent-icon\" style=\"float:none !important;border:0 solid #ff0000 !important;background:none repeat scroll center center transparent;width:16px !important;height:16px !important;display:none;overflow:visible !important;position:absolute !important;text-indent:0 !important;z-index:2147483635 !important;max-width:none !important;min-width:0 !important;max-height:none !important;min-height:0 !important;left:287px;top:778px;bottom:auto !important;right:auto !important;line-height:16px !important;white-space:nowrap !important;visibility:hidden;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" /></div><br><br><div class=\"linkscent-iconblock\" style=\"float:none !important;border:0 solid #ff0000 !important;background:none repeat scroll center center transparent !important;width:auto !important;height:auto !important;display:block !important;overflow:visible !important;position:static !important;text-indent:0 !important;z-index:auto !important;max-width:none !important;min-width:0 !important;max-height:none !important;min-height:0 !important;left:auto !important;top:auto !important;bottom:auto !important;right:auto !important;line-height:16px !important;white-space:nowrap !important;margin:0!important;padding:0!important;\"><img class=\"linkscent-icon\" style=\"float:none !important;border:0 solid #ff0000 !important;width:16px !important;height:16px !important;display:none;overflow:visible !important;position:absolute !important;text-indent:0 !important;z-index:2147483635 !important;max-width:none !important;min-width:0 !important;max-height:none !important;min-height:0 !important;left:170px;top:321px;bottom:auto !important;right:auto !important;line-height:16px !important;white-space:nowrap !important;visibility:hidden;background:url('http://concordion.org/favicon.ico') no-repeat scroll center center transparent !important;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" /><img class=\"linkscent-icon\" style=\"float:none !important;border:0 solid #ff0000 !important;background:none repeat scroll center center transparent;width:16px !important;height:16px !important;display:none;overflow:visible !important;position:absolute !important;text-indent:0 !important;z-index:2147483635 !important;max-width:none !important;min-width:0 !important;max-height:none !important;min-height:0 !important;left:188px;top:321px;bottom:auto !important;right:auto !important;line-height:16px !important;white-space:nowrap !important;visibility:hidden;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" /><img class=\"linkscent-icon\" style=\"float:none !important;border:0 solid #ff0000 !important;width:16px !important;height:16px !important;display:none;overflow:visible !important;position:absolute !important;text-indent:0 !important;z-index:2147483635 !important;max-width:none !important;min-width:0 !important;max-height:none !important;min-height:0 !important;left:568px;top:29px;bottom:auto !important;right:auto !important;line-height:16px !important;white-space:nowrap !important;visibility:hidden;background:url('//interclue/content/cluecore/skins/default/linkscentExternal.png') no-repeat scroll center center transparent !important;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" /><img class=\"linkscent-icon\" style=\"float:none !important;border:0 solid #ff0000 !important;background:none repeat scroll center center transparent;width:16px !important;height:16px !important;display:none;overflow:visible !important;position:absolute !important;text-indent:0 !important;z-index:2147483635 !important;max-width:none !important;min-width:0 !important;max-height:none !important;min-height:0 !important;left:586px;top:29px;bottom:auto !important;right:auto !important;line-height:16px !important;white-space:nowrap !important;visibility:hidden;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" /></div><br><br><div class=\"linkscent-iconblock\" style=\"float:none !important;border:0 solid #ff0000 !important;background:none repeat scroll center center transparent !important;width:auto !important;height:auto !important;display:block !important;overflow:visible !important;position:static !important;text-indent:0 !important;z-index:auto !important;max-width:none !important;min-width:0 !important;max-height:none !important;min-height:0 !important;left:auto !important;top:auto !important;bottom:auto !important;right:auto !important;line-height:16px !important;white-space:nowrap !important;margin:0!important;padding:0!important;\"><img class=\"linkscent-icon\" style=\"float:none !important;border:0 solid #ff0000 !important;width:16px !important;height:16px !important;display:none;overflow:visible !important;position:absolute !important;text-indent:0 !important;z-index:2147483635 !important;max-width:none !important;min-width:0 !important;max-height:none !important;min-height:0 !important;left:185px;top:1185px;bottom:auto !important;right:auto !important;line-height:16px !important;white-space:nowrap !important;visibility:hidden;background:url('http://concordion.org/favicon.ico') no-repeat scroll center center transparent !important;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" /><img class=\"linkscent-icon\" style=\"float:none !important;border:0 solid #ff0000 !important;background:none repeat scroll center center transparent;width:16px !important;height:16px !important;display:none;overflow:visible !important;position:absolute !important;text-indent:0 !important;z-index:2147483635 !important;max-width:none !important;min-width:0 !important;max-height:none !important;min-height:0 !important;left:203px;top:1185px;bottom:auto !important;right:auto !important;line-height:16px !important;white-space:nowrap !important;visibility:hidden;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" /><img class=\"linkscent-icon\" style=\"float:none !important;border:0 solid #ff0000 !important;width:16px !important;height:16px !important;display:none;overflow:visible !important;position:absolute !important;text-indent:0 !important;z-index:2147483635 !important;max-width:none !important;min-width:0 !important;max-height:none !important;min-height:0 !important;left:257px;top:1223px;bottom:auto !important;right:auto !important;line-height:16px !important;white-space:nowrap !important;visibility:hidden;background:url('http://vimeo.com/favicon.ico') no-repeat scroll center center transparent !important;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" /><img class=\"linkscent-icon\" style=\"float:none !important;border:0 solid #ff0000 !important;background:none repeat scroll center center transparent;width:16px !important;height:16px !important;display:none;overflow:visible !important;position:absolute !important;text-indent:0 !important;z-index:2147483635 !important;max-width:none !important;min-width:0 !important;max-height:none !important;min-height:0 !important;left:275px;top:1223px;bottom:auto !important;right:auto !important;line-height:16px !important;white-space:nowrap !important;visibility:hidden;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" /></div>",
  "excerpt": ""
 },
 {
  "title": "Visualize Maven Project Dependencies with dependency:tree and Dot Diagram Output",
  "published": "2012-01-13 13:06:57",
  "postType": "post",
  "slug": "/2012/01/13/visualize-maven-project-dependencies-with-dependencytree-and-dot-diagram-output/",
  "status": "publish",
  "tags": [
   "Maven"
  ],
  "categories": [
   "Tools"
  ],
  "content": "The <a href=\"http://maven.apache.org/plugins/maven-dependency-plugin/tree-mojo.html\">dependency:tree</a> goal of the Maven plugin <em>dependency</em> supports various graphical outputs from the version 2.4 up. This is how you would create a diagram showing all dependencies in the com.example group in the <a href=\"http://en.wikipedia.org/wiki/DOT_language\">dot format</a>:<br><br><pre><code>mvn dependency:tree -Dincludes=com.example -DappendOutput=true -DoutputType=dot -DoutputFile=/path/to/output.gv</code></pre><br><br>(The output is just a text file with the extension Graphviz gv.)<br><br>To actually produce an image from the dot file you can use one of <a href=\"http://www.graphviz.org/Resources.php\">dot renderers</a>, f.ex. this <a href=\"http://ashitani.jp/gv/\">online dot renderer</a> (paste into the right text box, press enter).<br><br>You could also <a href=\"http://www.summa-tech.com/blog/2011/04/12/a-visual-maven-dependency-tree-view/\">generate the output f.ex. in the graphml format &amp; visualize it in Eclipse</a>.<br><br>Note: Thanks to the reader Not Relevant for pointing out the right extension and a typo.\r\n<div class=\"linkscent-iconblock\" style=\"float:none!important;border:0 solid #ff0000!important;background:none repeat scroll center center transparent!important;width:auto!important;height:auto!important;display:block!important;overflow:visible!important;position:static!important;text-indent:0!important;z-index:auto!important;max-width:none!important;min-width:0!important;max-height:none!important;min-height:0!important;left:auto!important;top:auto!important;bottom:auto!important;right:auto!important;line-height:16px!important;white-space:nowrap!important;margin:0!important;padding:0!important;\"><img class=\"linkscent-icon\" style=\"float:none!important;border:0 solid #ff0000!important;width:16px!important;height:16px!important;display:none;overflow:visible!important;position:absolute!important;text-indent:0!important;z-index:2147483635!important;max-width:none!important;min-width:0!important;max-height:none!important;min-height:0!important;left:503px;top:193px;bottom:auto!important;right:auto!important;line-height:16px!important;white-space:nowrap!important;visibility:hidden;opacity:0;background:url('http://www.summa-tech.com/favicon.ico') no-repeat scroll center center transparent!important;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" /><img class=\"linkscent-icon\" style=\"float:none!important;border:0 solid #ff0000!important;background:none repeat scroll center center transparent;width:16px!important;height:16px!important;display:none;overflow:visible!important;position:absolute!important;text-indent:0!important;z-index:2147483635!important;max-width:none!important;min-width:0!important;max-height:none!important;min-height:0!important;left:521px;top:193px;bottom:auto!important;right:auto!important;line-height:16px!important;white-space:nowrap!important;visibility:hidden;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" /><img class=\"linkscent-icon\" style=\"float:none!important;border:0 solid #ff0000!important;width:16px!important;height:16px!important;display:none;overflow:visible!important;position:absolute!important;text-indent:0!important;z-index:2147483635!important;max-width:none!important;min-width:0!important;max-height:none!important;min-height:0!important;left:446px;top:129px;bottom:auto!important;right:auto!important;line-height:16px!important;white-space:nowrap!important;visibility:hidden;background:url('http://www.graphviz.org/favicon.ico') no-repeat scroll center center transparent!important;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" /><img class=\"linkscent-icon\" style=\"float:none!important;border:0 solid #ff0000!important;background:none repeat scroll center center transparent;width:16px!important;height:16px!important;display:none;overflow:visible!important;position:absolute!important;text-indent:0!important;z-index:2147483635!important;max-width:none!important;min-width:0!important;max-height:none!important;min-height:0!important;left:464px;top:129px;bottom:auto!important;right:auto!important;line-height:16px!important;white-space:nowrap!important;visibility:hidden;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" /></div>",
  "excerpt": ""
 },
 {
  "title": "Note To Self: What to Do When a Vagrant Machine Stops Working (Destroy or Up Failing)",
  "published": "2012-03-24 13:46:50",
  "postType": "post",
  "slug": "/2012/03/24/note-to-self-how-to-solve-vagrant-destroy-failing-with-error-in-api-call-in-ffi-rb/",
  "status": "publish",
  "tags": [
   "DevOps",
   "error",
   "troubleshooting",
   "vagrant"
  ],
  "categories": [
   "Tools"
  ],
  "content": "Sometimes \"<em>vagrant destroy</em>\" fails with an exception from the depths of the virtualbox Ruby gem or vagrant up freezes for a long time only to fail with SSH connection failure message. Here are some tips how to solve such problems.<br><br>See also my <a title=\"Vagrant Notes\" href=\"/wiki/tools/vagrant-notes/\">Vagrant Notes</a>.<br><br><!--more-->\r\n<h2>Vagrant Destroy Failing with \"Error in API call\" in ffi.rb</h2>\r\nSometimes \"<em>vagrant destroy</em>\" fails with an exception from the depths of the virtualbox Ruby gem. A solution might be to use the command-line VirtualBox tool VBoxManage to forcibly stop the machine.\r\n<h3>Symptomps</h3>\r\n1. \"vagrant destroy\" fails with an exception like this one:<br><br><pre><code>\r\n$ vagrant destroy\r\n[default] Destroying VM and associated drives...\r\n/Library/Ruby/Gems/1.8/gems/virtualbox-0.9.2/lib/virtualbox/com/implementer/ffi.rb:106:in `call_and_check': Error in API call to unregister: 2159738887 (VirtualBox::Exceptions::InvalidObjectStateException)\r\n\tfrom /Library/Ruby/Gems/1.8/gems/virtualbox-0.9.2/lib/virtualbox/com/implementer/ffi.rb:80:in `call_vtbl_function'\r\n\tfrom /Library/Ruby/Gems/1.8/gems/virtualbox-0.9.2/lib/virtualbox/com/implementer/ffi.rb:61:in `call_function'\r\n\tfrom /Library/Ruby/Gems/1.8/gems/virtualbox-0.9.2/lib/virtualbox/com/abstract_interface.rb:145:in `call_function'\r\n\tfrom /Library/Ruby/Gems/1.8/gems/virtualbox-0.9.2/lib/virtualbox/com/abstract_interface.rb:62:in `unregister'\r\n\tfrom /Library/Ruby/Gems/1.8/gems/virtualbox-0.9.2/lib/virtualbox/vm.rb:578:in `destroy'\r\n\tfrom ...\r\n</code></pre><br><br>2. VirtualBox GUI lists the vagrant_&lt;number&gt; machine as running<br><br>3. You can actually see the VirtualBox process started by Vagrant:<br><br><pre><code>\r\n$ ps aux | grep -i vagr\r\nme ... /Applications/VirtualBox.app/Contents/MacOS/VBoxHeadless --comment vagrant_1326716120 --startvm 026abe1a-b9\r\n</code></pre>\r\n<h3>Solution</h3>\r\nList all the VirtualBox VMs:<br><br><pre><code>$ VBoxManage list vms</code></pre><br><br>(This will also list internal hex IDs of the machines; you can find the id of the current machine in the .vagrant file in the directory where your ran vagrant from.)<br><br>Power off the Vagrant VM:<br><br><pre><code>\r\n$ VBoxManage controlvm vagrant_1326716120 poweroff\r\n# Or: 'cat .vagrant' =&gt; {&quot;active&quot;:{&quot;default&quot;:&quot;a683f28a-4bdc-4739-b7ae-8ae21013dbd5&quot;}}\r\n# VBoxManage controlvm a683f28a-4bdc-4739-b7ae-8ae21013dbd5 poweroff\r\n</code></pre><br><br>Run vagrant destroy again:<br><br><pre><code>\r\n$ vagrant destroy\r\n[default] Destroying VM and associated drives...\r\n</code></pre><br><br>(If it doesn't help, try to remove the VM manually via VBoxManage unregistervm as described in the references.)\r\n<h3>References</h3>\r\n<ul>\r\n\t<li><a href=\"https://forums.virtualbox.org/viewtopic.php?f=7&amp;t=39967\">VirtualBox forum: What to do with a locked VM</a></li>\r\n\t<li><a href=\"http://rockpenguin.wordpress.com/2008/03/16/removing-a-virtual-machine-from-virtualbox/\">Manual removal of a VM from VirtualBox</a> (2008)</li>\r\n</ul>\r\n<h2>Vagrant up/halt/ssh Timeouts with \"Failed to connect to VM via SSH\"</h2>\r\nThe error might look like this:<br><br><pre><code>\r\n[default] Failed to connect to VM!\r\nFailed to connect to VM via SSH. Please verify the VM successfully booted\r\nby looking at the VirtualBox GUI.\r\n</code></pre><br><br>This likely indicate some problem during booting the machine, often a network setup issue. It might be either a random thing or it might be caused by a <em>mismatch between your VirtualBox version and the installed guest additions</em>. The mismatch would be indicated by this being printed during vagrant up:<br><br><pre><code>\r\n[default] Importing base box 'lucid32'...\r\n[default] The guest additions on this VM do not match the install version of\r\nVirtualBox! This may cause things such as forwarded ports, shared\r\nfolders, and more to not work properly. If any of those things fail on\r\nthis machine, please update the guest additions and repackage the\r\nbox.<br><br>Guest Additions Version: 4.1.0\r\nVirtualBox Version: 4.1.6\r\n</code></pre><br><br>If the wrong version of guest addition is your case then the best solution is either to use<a href=\"https://github.com/dotless-de/vagrant-vbguest\"> vagrant-vbguest</a> to automatically upgrade guest additions or to install the correct version and <a href=\"vagrantup.com/docs/base_boxes.html#package_and_distribute\">repackage the box</a>, storing it at some location accessible to all who need it. Alternatively use another base box compatible with your VB version, for example from <a href=\"http://vagrantbox.es/\">Vagrantbox.es</a> (though it still might be a good idea to copy it to a place you've control over).<br><br>If you believe that the problem is just <em>temporary</em>, you can try to resolve it by following this:\r\n<ol>\r\n\t<li>Power off the machine via VBoxManage, as shown above</li>\r\n\t<li>Tell Vagrant to start the machine in the GUI instead of the headless mode by adding \"<em>config.vm.boot_mode = :gui</em>\" to your Vagrant file</li>\r\n\t<li>Run <em>vagrant up</em> and use the VirtualBox UI that should automatically open to log into the virtual machine (user vagrant, psw vagrant) and check its network, SSH status, system logs</li>\r\n</ol>\r\n<h3>Installing Virtual Box Guess Additions</h3>\r\nUpdate: You may try the Vagrant plugin <a href=\"https://github.com/dotless-de/vagrant-vbguest\">vagrant-vbguest that can install/update VB Guest Additions automatically</a> for you.<br><br>The installation is described in the <a href=\"http://www.virtualbox.org/manual/ch04.html#idp5800672\">Virtual Box documentation</a> and also, little differently, in <a href=\"http://vagrantup.com/docs/base_boxes.html#install_virtualbox_guest_additions\">Vagrant documentation - Install VirtualBox Guest Additions</a> (no dkms, installs headers).\r\n<ol>\r\n\t<li><code>sudo apt-get update; sudo apt-get install linux-headers-$(uname -r) build-essential</code> (Virtual Box docs use dkms but I believe that it is only useful if you plan upgrading the guest additions regularly)</li>\r\n\t<li><a href=\"http://www.virtualbox.org/manual/ch04.html#mountingadditionsiso\">Mount the VBoxGuestAdditions.iso</a> as a CDrom (OS X: /Applications/VirtualBox.app/Contents/MacOS/VBoxGuestAdditions.iso; in Finder right-click on VirtualBox.app and select View package contents; than drag&amp;drop it to the open file dialog of the virtual drive)</li>\r\n\t<li>Mount it: <code>sudo mount /dev/cdrom /cdrom</code></li>\r\n\t<li>Install the additions: <code>cd /cdrom; sudo sh ./VBoxLinuxAdditions.run</code>\r\n(This will likely end with \"<em>Installing the Windows System drivers …fail! (Could not find the X.Org or Xfree86 Window Sytem.)</em>\" but that's OK since we're running a headless system.)</li>\r\n\t<li>Run <code>sudo apt-get clean</code>  to remove unnecessary files, you may also want to remove some of the packages installed above.</li>\r\n</ol>\r\n<h3>References</h3>\r\n<ul>\r\n\t<li><a href=\"http://superuser.com/questions/342473/vagrant-ssh-fails-with-virtualbox\">Vagrant ssh fails with VirtualBox</a> - also check the two vagrant issues mentioned there,  <a href=\"https://github.com/mitchellh/vagrant/issues/391\" rel=\"nofollow\">#391</a> and <a href=\"https://github.com/mitchellh/vagrant/issues/455\" rel=\"nofollow\">#455</a>.</li>\r\n</ul>\r\n<div class=\"linkscent-iconblock\" style=\"padding:0!important;margin:0!important;float:none!important;border:0 solid #ff0000!important;background:none repeat scroll center center transparent!important;height:auto!important;display:block!important;overflow:visible!important;position:static!important;text-indent:0!important;max-width:none!important;min-width:0!important;max-height:none!important;min-height:0!important;left:auto!important;top:auto!important;bottom:auto!important;right:auto!important;line-height:16px!important;white-space:nowrap!important;\"><img class=\"linkscent-icon\" style=\"padding:0!important;margin:0;float:none!important;border:0 solid #ff0000!important;height:16px!important;display:none;overflow:visible!important;position:absolute!important;text-indent:0!important;max-width:none!important;min-width:0!important;max-height:none!important;min-height:0!important;left:367px;top:1828px;bottom:auto!important;right:auto!important;line-height:16px!important;white-space:nowrap!important;visibility:hidden;background:url('http://www.virtualbox.org/favicon.ico') no-repeat scroll center center transparent!important;opacity:0;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" /><img class=\"linkscent-icon\" style=\"padding:0!important;margin:0;float:none!important;border:0 solid #ff0000!important;background:url('//interclue/content/cluecore/skins/default/sprites.png') no-repeat scroll -32px -64px transparent;height:16px!important;display:none;overflow:visible!important;position:absolute!important;text-indent:0!important;max-width:none!important;min-width:0!important;max-height:none!important;min-height:0!important;left:385px;top:1828px;bottom:auto!important;right:auto!important;line-height:16px!important;white-space:nowrap!important;visibility:hidden;opacity:0;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" width=\"16\" height=\"16\" /><img class=\"linkscent-icon\" style=\"padding:0!important;margin:0;float:none!important;border:0 solid #ff0000!important;background:none repeat scroll center center transparent;height:16px!important;display:none;overflow:visible!important;position:absolute!important;text-indent:0!important;max-width:none!important;min-width:0!important;max-height:none!important;min-height:0!important;left:403px;top:1828px;bottom:auto!important;right:auto!important;line-height:16px!important;white-space:nowrap!important;visibility:hidden;opacity:0;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" /></div>",
  "excerpt": ""
 },
 {
  "title": "Most interesting links of January ''12",
  "published": "2012-01-31 21:59:47",
  "postType": "post",
  "slug": "/2012/01/31/most-interesting-links-of-january-2/",
  "status": "publish",
  "tags": [
   "book",
   "clojure",
   "DevOps",
   "java",
   "lean",
   "legacy",
   "logging",
   "performance",
   "quality",
   "refactoring",
   "Testing"
  ],
  "categories": [
   "General",
   "Languages",
   "Testing",
   "Tools",
   "Top links of month"
  ],
  "content": "<h2>Recommended Readings</h2>\r\n<ul>\r\n\t<li>Jeff Sutherland: <a href=\"http://scrum.jeffsutherland.com/2011/12/powerful-strategy-for-defect-prevention.html\">Powerful Strategy for Defect Prevention: Improve the Quality of Your Product</a> - \"A classic paper from IBM shows how they systematically reduced defects by analyzing root cause. The cost of implementing this practice is less than the cost of fixing defects that you will have if you do not implement it so it should always be implemented.\" - categorize defects by type, severity, component, when introduced; 80% of them will originate in 20% of the code; apply prioritized automated testing (solve always the largest problem first). \"In three months, one of our venture companies cut a 4-6 week deployment cycle to 2 weeks with only 120 tests.\"</li>\r\n\t<li>Ebook draft: <a href=\"http://www.agical.com/mikmeth/mikadomethod.pdf\">Beheading the Software Beast - Relentless restructurings with The Mikado Method</a> (foreword by T. Poppendieck) - the book introduces the <a href=\"http://mikadomethod.wordpress.com/2009/12/09/introduction-to-the-mikado-method/\">Mikado Method</a> for organized, always-staying-green (large-scale) refactorings, especially useful for legacy systems, shows it on a real-world example (30 pages!), discusses various application restructuring techniques, provides practical guidelines for dealing with different sizes of refactorings and teams, discusses in depth technical debt and more. To sum it up in three words: Check it out!</li>\r\n\t<li><a href=\"http://www.jayonsoftware.com/home/2012/1/9/daily-routine-of-a-4-hour-programmer.html\">Daily Routine of a 4 Hour Programmer</a> (well, it's actually about 4h of focused programming + some hours of the rest) - a very interesting reading with some inspiring ideas. We should all find some time to follow up the field, to reflect on our day and learn from it (<a href=\"http://en.wikipedia.org/wiki/Kaizen\">kaizen</a>)</li>\r\n\t<li><a href=\"http://blog.jonasbandi.net/2010/02/agile-testing-quadrants.html\">The Agile Testing Quadrants</a> - understanding the different types of tests, their purpose and relation by slicing them by the axis \"business facing x technology facing\" and the axis \"supporting the team x critiquing the product\" =&gt; unit tests x functional tests x exploratory testing x performance testing (and other). It helps to understand what should be automated, what needs to be manual and helps not to forget all the dimensions of testing.</li>\r\n\t<li>Adam Bien: <a href=\"http://www.adam-bien.com/roller/abien/entry/can_stateful_java_ee_6\">Can stateful Java EE apps scale?</a> - What does \"stateless\" really mean? \"Stateless only means, that the entire state is stored in the database and has to synchronized on every request.\" \"I start the development of non-trivial (&gt;CRUD) applications with Gateway / PDOs [JH: stateful EJBs exposing JPA entities] and measure the performance and memory consumption continuously.\" Some general tips: Don't split your web server and servlet container, don't use session replication.</li>\r\n\t<li>Brian Tarbox: <a href=\"http://pragprog.com/magazines/2011-12/justintime-logging\">Just-In-Time Logging</a> - How to remove 90% of worthless logs while still getting detailed logs for cases that matters - the solution is to (1) only add logs for a particular \"transaction\" with the system into a runtime structure and (2) flush it to the log only if the transaction fails or st. else significant happens with it. The blog also proposes a possible implementation in detail.</li>\r\n\t<li><a href=\"http://www.dzone.com/links/r/dzones_top_10_nosql_articles_of_2011.html\">DZone's Top 10 NoSQL Articles of 2011</a></li>\r\n\t<li><a href=\"http://www.dzone.com/links/r/dzones_top_5_devops_articles_of_2011.html\">DZone's Top 5 DevOps Articles of 2011</a></li>\r\n\t<li><a href=\"http://java.dzone.com/articles/test-driven-infrastructure\">Test Driven Infrastructure with Vagrant, Puppet and Guard</a> - this is interesting for me for I'm using Vagrant and Puppet on my project to create and share development environments or their parts and applying test-first approach to it seems interesting as do also the tools, <a href=\"https://github.com/rodjek/rspec-puppet\">rspec-puppet</a>, <a href=\"https://github.com/nistude/cucumber-puppet\">cucumber-puppet</a> and <a href=\"https://github.com/guard/guard\">Guard</a> (events triggered by file changes) and referenced articels.</li>\r\n\t<li><a href=\"http://onlysoftware.wordpress.com/2012/01/01/51-sonar-plugins-you-must-not-miss-2012-version/\">5+1 Sonar Plugins you must not miss (2012 version)</a> - Timeline Plugin (with Google Visualization Annotated TimeLine), Useless Code Plugin, SIG Maintainability Model Plugin (metrics Analysability, Changeability, Stability, Testability), Quality Index Plugin (1-number health indicator), Technical Debt Plugin</li>\r\n</ul>\r\n<h2>Links to Keep</h2>\r\n<ul>\r\n\t<li>Niklas Schlimm: <a href=\"http://www.javacodegeeks.com/2012/01/java-ee-6-vs-spring-framework.html?m=1\">Java EE 6 vs. Spring Framework: A technology decision making process</a> - key factors to consider when deciding between Java EE and Spring (or a mixed application of both) - value of standards, independence/flexibility, production-readiness, downwards compatibility ...</li>\r\n</ul>\r\n<h2>Clojure Corner</h2>\r\n<ul>\r\n\t<li><a href=\"http://clojurescriptone.com/\">ClojureScript One Guide</a> - \"ClojureScript One shows you how to use ClojureScript to build single-page, single-language applications in a productive, effective and fun way.\"</li>\r\n\t<li><a href=\"http://martinsprogrammingblog.blogspot.com/2011/12/asynchronous-workflows-in-clojure.html\">Asynchronous workflows in Clojure</a> - true asynchronous (non-blocking) network access in Clojure with Netty/the Lamina project.</li>\r\n\t<li><a href=\"http://stuartsierra.com/2012/01/03/clojure-2011-year-in-review\">Clojure 2011 Year in Review</a> - a list with important events in the Clojure sphere with links to details - C. 1.3.0, ClojureScript, logic programming with core.logic, clojure-contrib restructuring, birth of 4Clojure and Avout.</li>\r\n\t<li><a href=\"http://www.clojureatlas.com/\">Clojure Atlas</a> - interesting project (alpha version) presenting Clojure documentation in the form of interactive graph of related concepts and functions; it's far from perfection but I like the concept and consider paying those ~ $25 for the 1.3.0 version when its out (however, the <a href=\"http://www.clojureatlas.com/org.clojure:clojure:1.2.0?guest=t\">demo is free</a> and it might become open-sourced in 2012)</li>\r\n</ul>\r\n<div class=\"linkscent-iconblock\" style=\"float:none !important;border:0 solid #ff0000 !important;background:none repeat scroll center center transparent !important;width:auto !important;height:auto !important;display:block !important;overflow:visible !important;position:static !important;text-indent:0 !important;z-index:auto !important;max-width:none !important;min-width:0 !important;max-height:none !important;min-height:0 !important;left:auto !important;top:auto !important;bottom:auto !important;right:auto !important;line-height:16px !important;white-space:nowrap !important;margin:0!important;padding:0!important;\"><img class=\"linkscent-icon\" style=\"float:none !important;border:0 solid #ff0000 !important;width:16px !important;height:16px !important;display:none;overflow:visible !important;position:absolute !important;text-indent:0 !important;z-index:2147483635 !important;max-width:none !important;min-width:0 !important;max-height:none !important;min-height:0 !important;left:296px;top:731px;bottom:auto !important;right:auto !important;line-height:16px !important;white-space:nowrap !important;visibility:hidden;background:url('//interclue/content/cluecore/skins/default/linkscentExternal.png') no-repeat scroll center center transparent !important;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" /><img class=\"linkscent-icon\" style=\"float:none !important;border:0 solid #ff0000 !important;background:none repeat scroll center center transparent;width:16px !important;height:16px !important;display:none;overflow:visible !important;position:absolute !important;text-indent:0 !important;z-index:2147483635 !important;max-width:none !important;min-width:0 !important;max-height:none !important;min-height:0 !important;left:314px;top:731px;bottom:auto !important;right:auto !important;line-height:16px !important;white-space:nowrap !important;visibility:hidden;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" /></div>\r\n<div class=\"linkscent-iconblock\" style=\"float:none !important;border:0 solid #ff0000 !important;background:none repeat scroll center center transparent !important;width:auto !important;height:auto !important;display:block !important;overflow:visible !important;position:static !important;text-indent:0 !important;z-index:auto !important;max-width:none !important;min-width:0 !important;max-height:none !important;min-height:0 !important;left:auto !important;top:auto !important;bottom:auto !important;right:auto !important;line-height:16px !important;white-space:nowrap !important;margin:0!important;padding:0!important;\"><img class=\"linkscent-icon\" style=\"float:none !important;border:0 solid #ff0000 !important;width:16px !important;height:16px !important;display:none;overflow:visible !important;position:absolute !important;text-indent:0 !important;z-index:2147483635 !important;max-width:none !important;min-width:0 !important;max-height:none !important;min-height:0 !important;left:277px;top:443px;bottom:auto !important;right:auto !important;line-height:16px !important;white-space:nowrap !important;visibility:hidden;background:url('http://www.dzone.com/favicon.ico') no-repeat scroll center center transparent !important;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" /><img class=\"linkscent-icon\" style=\"float:none !important;border:0 solid #ff0000 !important;background:none repeat scroll center center transparent;width:16px !important;height:16px !important;display:none;overflow:visible !important;position:absolute !important;text-indent:0 !important;z-index:2147483635 !important;max-width:none !important;min-width:0 !important;max-height:none !important;min-height:0 !important;left:295px;top:443px;bottom:auto !important;right:auto !important;line-height:16px !important;white-space:nowrap !important;visibility:hidden;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/linkscentError.png\" alt=\"\" /><img class=\"linkscent-icon\" style=\"float:none !important;border:0 solid #ff0000 !important;width:16px !important;height:16px !important;display:none;overflow:visible !important;position:absolute !important;text-indent:0 !important;z-index:2147483635 !important;max-width:none !important;min-width:0 !important;max-height:none !important;min-height:0 !important;left:481px;top:519px;bottom:auto !important;right:auto !important;line-height:16px !important;white-space:nowrap !important;visibility:hidden;background:url('//interclue/content/cluecore/skins/default/linkscentExternal.png') no-repeat scroll center center transparent !important;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" /><img class=\"linkscent-icon\" style=\"float:none !important;border:0 solid #ff0000 !important;background:url('//interclue/content/cluecore/skins/default/sprites.png') no-repeat scroll -144px -96px transparent;width:16px !important;height:16px !important;display:none;overflow:visible !important;position:absolute !important;text-indent:0 !important;z-index:2147483635 !important;max-width:none !important;min-width:0 !important;max-height:none !important;min-height:0 !important;left:499px;top:519px;bottom:auto !important;right:auto !important;line-height:16px !important;white-space:nowrap !important;visibility:hidden;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" width=\"16\" height=\"16\" /><img class=\"linkscent-icon\" style=\"float:none !important;border:0 solid #ff0000 !important;background:none repeat scroll center center transparent;width:16px !important;height:16px !important;display:none;overflow:visible !important;position:absolute !important;text-indent:0 !important;z-index:2147483635 !important;max-width:none !important;min-width:0 !important;max-height:none !important;min-height:0 !important;left:517px;top:519px;bottom:auto !important;right:auto !important;line-height:16px !important;white-space:nowrap !important;visibility:hidden;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" /><img class=\"linkscent-icon\" style=\"float:none !important;border:0 solid #ff0000 !important;width:16px !important;height:16px !important;display:none;overflow:visible !important;position:absolute !important;text-indent:0 !important;z-index:2147483635 !important;max-width:none !important;min-width:0 !important;max-height:none !important;min-height:0 !important;left:192px;top:806px;bottom:auto !important;right:auto !important;line-height:16px !important;white-space:nowrap !important;visibility:hidden;background:url('http://clojurescriptone.com/favicon.ico') no-repeat scroll center center transparent !important;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" /><img class=\"linkscent-icon\" style=\"float:none !important;border:0 solid #ff0000 !important;background:none repeat scroll center center transparent;width:16px !important;height:16px !important;display:none;overflow:visible !important;position:absolute !important;text-indent:0 !important;z-index:2147483635 !important;max-width:none !important;min-width:0 !important;max-height:none !important;min-height:0 !important;left:210px;top:806px;bottom:auto !important;right:auto !important;line-height:16px !important;white-space:nowrap !important;visibility:hidden;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" /><img class=\"linkscent-icon\" style=\"float:none !important;border:0 solid #ff0000 !important;width:16px !important;height:16px !important;display:none;overflow:visible !important;position:absolute !important;text-indent:0 !important;z-index:2147483635 !important;max-width:none !important;min-width:0 !important;max-height:none !important;min-height:0 !important;left:591px;top:557px;bottom:auto !important;right:auto !important;line-height:16px !important;white-space:nowrap !important;visibility:hidden;opacity:0;background:url('http://scrum.jeffsutherland.com/favicon.ico') no-repeat scroll center center transparent !important;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" /><img class=\"linkscent-icon\" style=\"float:none !important;border:0 solid #ff0000 !important;background:none repeat scroll center center transparent;width:16px !important;height:16px !important;display:none;overflow:visible !important;position:absolute !important;text-indent:0 !important;z-index:2147483635 !important;max-width:none !important;min-width:0 !important;max-height:none !important;min-height:0 !important;left:609px;top:557px;bottom:auto !important;right:auto !important;line-height:16px !important;white-space:nowrap !important;visibility:hidden;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" /></div>\r\n<div class=\"linkscent-iconblock\" style=\"float:none !important;border:0 solid #ff0000 !important;background:none repeat scroll center center transparent !important;width:auto !important;height:auto !important;display:block !important;overflow:visible !important;position:static !important;text-indent:0 !important;z-index:auto !important;max-width:none !important;min-width:0 !important;max-height:none !important;min-height:0 !important;left:auto !important;top:auto !important;bottom:auto !important;right:auto !important;line-height:16px !important;white-space:nowrap !important;margin:0!important;padding:0!important;\"><img class=\"linkscent-icon\" style=\"float:none !important;border:0 solid #ff0000 !important;width:16px !important;height:16px !important;display:none;overflow:visible !important;position:absolute !important;text-indent:0 !important;z-index:2147483635 !important;max-width:none !important;min-width:0 !important;max-height:none !important;min-height:0 !important;left:561px;top:780px;bottom:auto !important;right:auto !important;line-height:16px !important;white-space:nowrap !important;visibility:hidden;background:url('http://www.javacodegeeks.com/favicon.ico') no-repeat scroll center center transparent !important;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" /><img class=\"linkscent-icon\" style=\"float:none !important;border:0 solid #ff0000 !important;background:none repeat scroll center center transparent;width:16px !important;height:16px !important;display:none;overflow:visible !important;position:absolute !important;text-indent:0 !important;z-index:2147483635 !important;max-width:none !important;min-width:0 !important;max-height:none !important;min-height:0 !important;left:579px;top:780px;bottom:auto !important;right:auto !important;line-height:16px !important;white-space:nowrap !important;visibility:hidden;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" /></div>\r\n<div class=\"linkscent-iconblock\" style=\"float:none !important;border:0 solid #ff0000 !important;background:none repeat scroll center center transparent !important;width:auto !important;height:auto !important;display:block !important;overflow:visible !important;position:static !important;text-indent:0 !important;z-index:auto !important;max-width:none !important;min-width:0 !important;max-height:none !important;min-height:0 !important;left:auto !important;top:auto !important;bottom:auto !important;right:auto !important;line-height:16px !important;white-space:nowrap !important;margin:0!important;padding:0!important;\"><img class=\"linkscent-icon\" style=\"float:none !important;border:0 solid #ff0000 !important;width:16px !important;height:16px !important;display:none;overflow:visible !important;position:absolute !important;text-indent:0 !important;z-index:2147483635 !important;max-width:none !important;min-width:0 !important;max-height:none !important;min-height:0 !important;left:600px;top:63px;bottom:auto !important;right:auto !important;line-height:16px !important;white-space:nowrap !important;visibility:hidden;background:url('//interclue/content/cluecore/skins/default/linkscentExternal.png') no-repeat scroll center center transparent !important;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" /><img class=\"linkscent-icon\" style=\"float:none !important;border:0 solid #ff0000 !important;background:url('//interclue/content/cluecore/skins/default/sprites.png') no-repeat scroll -64px -96px transparent;width:16px !important;height:16px !important;display:none;overflow:visible !important;position:absolute !important;text-indent:0 !important;z-index:2147483635 !important;max-width:none !important;min-width:0 !important;max-height:none !important;min-height:0 !important;left:618px;top:63px;bottom:auto !important;right:auto !important;line-height:16px !important;white-space:nowrap !important;visibility:hidden;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" width=\"16\" height=\"16\" /><img class=\"linkscent-icon\" style=\"float:none !important;border:0 solid #ff0000 !important;background:none repeat scroll center center transparent;width:16px !important;height:16px !important;display:none;overflow:visible !important;position:absolute !important;text-indent:0 !important;z-index:2147483635 !important;max-width:none !important;min-width:0 !important;max-height:none !important;min-height:0 !important;left:636px;top:63px;bottom:auto !important;right:auto !important;line-height:16px !important;white-space:nowrap !important;visibility:hidden;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" /></div>\r\n",
  "excerpt": ""
 },
 {
  "title": "Troubleshooting Jersey REST Server and Client",
  "published": "2012-01-31 15:37:27",
  "postType": "post",
  "slug": "/2012/01/31/troubleshooting-jersey-rest-server-and-client/",
  "status": "publish",
  "tags": [
   "java",
   "JAX-RS",
   "REST"
  ],
  "categories": [
   "Languages"
  ],
  "content": "The logging in Jersey, the reference JAX-RS implementation, is little sub-optimal. For example if it cannot find a method producing the expected MIME type then it will return \"Unsupported mime type\" to the client but won't log anything (which mime type was requested, which mime types are actually available, ...).  Debugging it isn't exactly easy either, so what to do?<br><br>Well, I don't know the ultimate solution but want to share few tips.<br><br><!--more-->\r\n<h2>Enable Tracing of Request Matching</h2>\r\nJersey since version 1.1.5 <a href=\"http://blogs.oracle.com/sandoz/entry/tracing_in_jersey\">supports request matching tracing</a>, provided somehow detailed information about the matching process in the response headers.<br><br>To enable it for the Jersey Test framework you'd do something like this in your test class:<br><br><pre><code>\r\npublic class MyJerseyTest extends JerseyTest {<br><br>    public MyJerseyTest() {\r\n        super(new WebAppDescriptor\r\n                .Builder(&quot;my.package.with.jaxrs.resources&quot;)\r\n                .contextPath(&quot;myCtxPath&quot;)\r\n                .servletPath(&quot;/myServletPath&quot;)\r\n                .initParam(&quot;com.sun.jersey.config.feature.Trace&quot;, &quot;true&quot;)\r\n                .build());\r\n    }<br><br>    // Your test methods here ...; you can get the trace headers via ClientResponse#getHeaders()\r\n}\r\n</code></pre><br><br>To enable it for the server itself (though might be not such a good idea to enable this in production), you would set it in web.xml:\r\n<pre>&lt;web-app  ...&gt;\r\n    &lt;servlet&gt;\r\n        &lt;servlet-name&gt;Jersey REST Service for value codes&lt;/servlet-name&gt;\r\n        &lt;servlet-class&gt;com.sun.jersey.spi.container.servlet.ServletContainer&lt;/servlet-class&gt;\r\n        ...\r\n        &lt;init-param&gt;\r\n            &lt;param-name&gt;com.sun.jersey.config.feature.Trace&lt;/param-name&gt;\r\n            &lt;param-value&gt;true&lt;/param-value&gt;\r\n        &lt;/init-param&gt;<br><br>    &lt;/servlet&gt;\r\n...\r\n&lt;/web-app&gt;</pre>\r\nThe headers, which you can obtain via e.g. <kbd>curl -i</kbd> or via <code>ClientResponse#getHeaders()</code>, might look like this:<br><br><pre><code>\r\n{X-Jersey-Trace-008=[mapped exception to response: javax.ws.rs.WebApplicationException@56f9659d -&gt; 415 (Unsupported Media Type)],\r\nX-Jersey-Trace-002=[accept right hand path java.util.regex.Matcher[pattern=/myResource/([-0-9a-zA-Z_]+)(/.*)? region=0,17 lastmatch=/myResource/23/mySubresources]: &quot;/myResource/23/mySubresources&quot; -&gt; &quot;/myResource/23&quot; : &quot;/mySubresources&quot;],\r\nX-Jersey-Trace-003=[accept resource: &quot;myResource/23&quot; -&gt; @Path(&quot;/myResource/{item: [-0-9a-zA-Z_]+}&quot;) com.example.MyExampleResource@41babddb],\r\nX-Jersey-Trace-000=[accept root resource classes: &quot;/myResource/23/mySubresources&quot;],\r\nX-Jersey-Trace-001=[match path &quot;/myResource/23/mySubresources&quot; -&gt; &quot;/application\\.wadl(/.*)?&quot;, &quot;/myResource/([-0-9a-zA-Z_]+)(/.*)?&quot;, &quot;/myResource(/.*)?&quot;, &quot;/mySubresources/([-0-9a-zA-Z_]+)(/.*)?&quot;],\r\nX-Jersey-Trace-006=[accept sub-resource methods: &quot;myResource/23&quot; : &quot;/mySubresources&quot;, GET -&gt; com.example.MyExampleResource@41babddb],\r\nX-Jersey-Trace-007=[accept termination (matching failure): &quot;/mySubresources&quot;],\r\nX-Jersey-Trace-004=[match path &quot;/mySubresources&quot; -&gt; &quot;/mySubresources(/)?&quot;, &quot;&quot;],\r\nX-Jersey-Trace-005=[accept right hand path java.util.regex.Matcher[pattern=/mySubresources(/)? region=0,6 lastmatch=/mySubresources]: &quot;/mySubresources&quot; -&gt; &quot;/mySubresources&quot; : &quot;&quot;]\r\n, Transfer-Encoding=[chunked], Date=[Tue, 31 Jan 2012 14:48:26 GMT], server=[grizzly/2.1.2], Content-Type=[text/html; charset=iso-8859-1]}\r\n</code></pre><br><br>provided that you have the class <code>com.example.MyExampleResource</code> annotated with <code>@Path(\"/myResource/{item: [-0-9a-zA-Z_]+}\")</code> and a method annotated with <code>@GET @Path(\"mySubresources\")</code> (and the class field <code>@PathParam(\"item\") Long item</code>).<br><br>As you can see, there is still no info regarding accepted/supported MIME types.\r\n<h2>Get Detailed Logging Into a File</h2>\r\nJersey uses Java logging, which is know for being difficult to configure. Here is a dirty trick to get detailed Jersey logs into a file:<br><br><pre><code>\r\npublic class MyJerseyTest extends JerseyTest {<br><br>    @BeforeClass public static void setupJerseyLog() throws Exception {\r\n        Handler fh = new ConsoleHandler(); // FileHandler(&quot;/tmp/jersey_test.log&quot;);\r\n        Logger.getLogger(&quot;&quot;).addHandler(fh);\r\n        Logger.getLogger(&quot;com.sun.jersey&quot;).setLevel(Level.FINEST);\r\n    }<br><br>    // Your test methods here ...\r\n}\r\n</code></pre><br><br>Notice that even thoug the log level is ALL, the logs still might be quite useless to troubleshoot some problems (such s the unsupported MIME type).\r\n<h2>Configure Request/Response Logging Filters</h2>\r\nJersey provides a <a href=\"http://stackoverflow.com/a/2362106\">LoggingFilter that can be used to log request/response entities and it can be installed both into the server and the client</a>. The com.sun.jersey.api.container.filter.LoggingFilter may be installed into the server via init-params, the com.sun.jersey.api.client.filter.LoggingFilter may be installed into the client via client.addFilter. JerseTest automatically installs the LoggingFilter into the client it uses if the system property \"enableLogging\" is set (to whatever- this must happen before JersyTest's constuctor).<br><br>Client:<br><br><pre><code>\r\n// Alternatively, call this before the JersetTest constructor: System.setProperty(&quot;enableLogging&quot;, &quot;true&quot;);\r\nWebResource resource = resource();\r\nresource.addFilter(new com.sun.jersey.api.client.filter.LoggingFilter());\r\nClientResponse response = resource.path(..)...get(..);\r\n</code></pre><br><br>Server:<br><br><pre><code>\r\npublic MyJerseyIT() {\r\nsuper(new WebAppDescriptor.Builder()\r\n... // set paths, packages etc.\r\n.initParam(&quot;com.sun.jersey.spi.container.ContainerRequestFilters&quot;, &quot;com.sun.jersey.api.container.filter.LoggingFilter&quot;)\r\n.build());\r\n}\r\n</code></pre>\r\n<h2>Tips &amp; Tricks</h2>\r\n<h3>Beware: Remember to Call setUp!</h3>\r\nIf you write a JUnit 4 test, make sure that you by mistake don't override <em>setUp</em> without calling <em>super.setUp</em>. <em>JerseyTest</em> is JUnit 3 test and needs its setUp to be called to function properly. If your Grizzly container stops soon after being started and you're thus getting ConnectException: Connection refused, make sure that the method is called.\r\n<h3>Sample AbstractJerseyTest Class with Best Practies</h3>\r\nSee my <a href=\"https://github.com/jakubholynet/blog/blob/master/snippets/AbstractJerseyTest.java\">AbstractJerseyTest.java at GitHub</a> - server setup, logging, tracing, response status check etc.",
  "excerpt": ""
 },
 {
  "title": "Most interesting links of February ''12",
  "published": "2012-02-29 21:59:16",
  "postType": "post",
  "slug": "/2012/02/29/most-interesting-links-of-february-12/",
  "status": "publish",
  "tags": [
   "agile",
   "AOP",
   "clojure",
   "http",
   "java",
   "Jersey",
   "nosql",
   "performance",
   "REST",
   "scala",
   "ssh",
   "Testing"
  ],
  "categories": [
   "General",
   "j2ee",
   "Languages",
   "Testing",
   "Tools",
   "Top links of month"
  ],
  "content": "<h2>Recommended Readings</h2>\r\n<ul>\r\n\t<li>List of <a href=\"http://twitter.github.com/\">open source projects at Twitter</a> including e.g. their <a href=\"https://github.com/twitter/scala_school\">scala_school</a> - Lessons in the Fundamentals of Scala and <a href=\"https://github.com/twitter/effectivescala\">effectivescala</a> - Twitter's Effective Scala Guide</li>\r\n\t<li>M. Fowler &amp; P. Sadalage: <a href=\"http://martinfowler.com/articles/nosql-intro.pdf\">Introduction into NoSQL and Polyglot Persistence</a> (pdf, 11 slides) - what RDBMS offer and why it sometimes isn't enough, what the different NoSQL incarnations offer, how and on which projects to mix and match them</li>\r\n\t<li><a href=\"http://www.exampler.com/blog/2012/02/04/two-phase-release-planning/\">Two phase release planning</a> - the best way to plan something somehow reliably is to just start doing it, i.e. just start the project with the objective of answering \"Can this team produce a respectable implementation of that system by that date?\" in as short time as possible (i.e. few weeks). Then: \"Phase 2: At this point, there’s a commitment: a respectable product will be released on a particular date. Now those paying for the product have to accept a brute fact: they will not know, until close to that date, just what that product will look like (its feature list). What they do know is that it will be the best product this development team can produce by that date.\" Final words: \"My success selling this approach has been mixed. People really like the feeling of certainty, even if it’s based on nothing more than a grand collective pretending.\"</li>\r\n\t<li><a href=\"http://highscalability.com/blog/2012/2/13/tumblr-architecture-15-billion-page-views-a-month-and-harder.html\">Tumblr Architecture - 15 Billion Page Views A Month And Harder To Scale Than Twitter</a> - what SW (Scala, Finagle, heavily partitioned MySQL, ...) and HW they use, the architecture (Firehose - event bus, cell design), lessons learned (incl. \"MySQL (plus sharding) scales, apps don't.\"</li>\r\n\t<li><a href=\"http://blog.jayfields.com/2011/01/compatible-opinions-on-software.html\">Jay Fields' Thoughts: Compatible Opinions on Software</a> - about teams and opinion conflicts - there are some areas where no opinion is really right (e.g. powerful language vs. powerful IDE) yet people may have very strong feeling about them. Be aware of what your opinions are and how strong they are - and compose teams so that they include more less people with compatible (not same!) opinions - because if you team people with strong opposing opinions, they'll loose lot of productivity. Quotes: \"I also believe that you can have two technically excellent people who have vastly different opinions on the most effective way to deliver software.\" \"I suggest that you do your best to avoid working with someone who has both an opposing view and is as inflexible as you are on the subject. The more central the subject is to the project, the more likely it is that productivity will be lost.\"</li>\r\n\t<li><a href=\"http://blog.jayfields.com/2012/01/lessons-learned-while-introducing-new.html\">Jay Fields' Thoughts: Lessons Learned while Introducing a New Programming Language</a> (namely Clojure) - introducing a new language and winning the hearts of (sufficient subset of) the people is difficult and requires lot of extra effort. This is both an experience report and a pretty good guide for doing it.</li>\r\n\t<li><a href=\"http://blog.jayfields.com/2011/08/life-after-pair-programming.html\">Jay Fields' Thoughts: Life After Pair Programming</a> - a proponent of pair-programming comes to the conclusion that in some contexts pairing may not be beneficial, i.e. the <a href=\"http://pragprog.com/magazines/2011-07/pair-programming-benefits\">benefits of pair-programming</a> don't overweight the costs (for a small team, small software, ...)</li>\r\n\t<li>The <a href=\"http://lusislog.blogspot.com/2011/06/why-monitoring-sucks.html\">Why Monitoring Sucks (and what we're doing about it) - the #monitoringsucks initiative</a>- what tools there are, why they suck, what to do, new tools, what metrics to collect, blogs, ...\r\n<ul>\r\n\t<li>Related: <a href=\"http://java.dzone.com/articles/getting-started-sensu\">Getting started with the Sensu monitoring framework</a></li>\r\n</ul>\r\n</li>\r\n\t<li><a href=\"http://www.infoq.com/news/2012/01/byteman-2-bytecode-manipulation\">JBoss Byteman 2.0.0: Bytecode Manipulation, Testing, Fault Injection, Logging</a> - a Java agent which helps testing, tracing, and monitoring code, code is injected based on simple scripts (rules) in the event-condition-action form (the conditions may use counters, timers etc.). Contrary to AOP, there is no need to create classes or compile code. \"Byteman is also simpler to use and easier to change, especially for testing and ad hoc logging purposes.\" \"Byteman was invented primarily to support automation of tests for multi-threaded and multi-JVM Java applications using a technique called fault injection.\" It was used e.g. to orchestrate the timing of activities performed by independent threads, for monitoring and statistics gathering, for <a href=\"https://community.jboss.org/wiki/FaultInjectionTestingWithByteman#top\">application testing via fault injection</a>. Contains a JUnit4 Runner for easily instrumenting the code under test, it can automatically load a rule before a test and unload it afterwards:\r\n<pre>@Test\r\n@BMRule(name=\"throw IOException at 1st call\",\r\ntargetClass = \"TextLineProcessor\",\r\ntargetMethod = \"processPipeline\",\r\naction = \"throw new java.io.IOException()\")\r\npublic void testErrorInPipeline() throws Exception { ... }</pre>\r\n</li>\r\n\t<li><a href=\"http://code-recommenders.blogspot.com/2011/12/how-should-code-search-work.html\">How should code search work?</a> - a thought-provoking article about how much better code completion could be if it profited more from patterns of usage in existing source codes - and how to achieve that. Intermediate results available in the <a href=\"www.eclipse.org/recommenders/documentation/\">Code Recommenders</a> Eclipse plugin.</li>\r\n</ul>\r\nREST\r\n<ul>\r\n\t<li><a href=\"http://codahale.com/what-makes-jersey-interesting-parameter-classes/\">What Makes Jersey Interesting: Parameter Classes</a> (by Coda Hale, 5/2009) - brief yet rich and very practical introduction into Jersey (the reference implementation of JAX-RS. i.e. REST, for Java) including error handling, parameter classes (automatic wrapping of primitive values). The following article, <a href=\"http://codahale.com/what-makes-jersey-interesting-injection-providers/\">What Makes Jersey Interesting: Injection Providers</a>, might be of interest too.</li>\r\n\t<li><a href=\"http://www.infoq.com/articles/webber-rest-workflow\">How to GET a Cup of Coffee</a>, 10/2008 - good introduction into creating applications based on REST, explained on an example of building REST workflow for the ordering process in Starbucks - a \"self-describing state machine\". The advantage of this article is that it presents the whole REST workflow with GET, OPTIONS, POST, PUT and \"advanced\" features such as the use of If-Unmodified-Since/If-Match, Precondition Failed, Conflict. The workflow steps are connected via the Location header and a custom &lt;next&gt; link tag with rel and uri. Other keywords: etag, microformats, HATEOS (-&gt; derive the next resource to access from the links in the previous one), Atom and AtomPub, caching (web trades latency for scaleability; if 1+s latency isn't acceptable than web isn't the right platform), URI templates (-&gt; more coupling than links in responses), evolution (-&gt; links from responses, new transitions), idempotency. \"The Web is a robust framework for integrating systems at local, enterprise, and Internet scale.\"</li>\r\n</ul>\r\n<h2>Links to Keep</h2>\r\n<h2>Tools, Libraries etc.</h2>\r\n<ul>\r\n\t<li><a href=\"http://clusterssh.sourceforge.net/\">ClusterSSH</a> - whatever commands you execute in the master SSH session are also execute in the slave sessions - useful if you often need to execute the same thing on multiple machines (requires Perl); to install on Mac: \"brew install csshx\"</li>\r\n\t<li><a href=\"http://html5boilerplate.com/\">HTML5 Boilerplate</a> (H5BP) - customizable initial HTML5 project template for a website; <a href=\"http://www.quora.com/Is-Bootstrap-a-complement-OR-an-alternative-to-HTML5-Boilerplate-or-viceversa\">can be combined e.g. with Bootstrap</a>, the HTML/JS/CSS toolkit (there is even a <a href=\"https://gist.github.com/1422879\">script to set them both up</a>). Includes server configs for optimal performance, \"delivers best practices, standard elements\".</li>\r\n\t<li><a href=\"http://vanillajava.blogspot.com/2012/02/high-performance-libraries-in-java.html\">High performance libraries in Java</a> - disruptor, Java Chronicle (ultra-fast in-memory db), Colt Matrix library (scientific computations), Javolution (RT Java), Trove collections for primitives, MG4J (free full-text search engine for large document collections), some serialization &amp; other banchmarks links.</li>\r\n\t<li><a href=\"http://twitter.github.com/finagle/\">Twitter Finagle</a> - \"library to implement asynchronous Remote Procedure Call (RPC) clients and servers. Finagle is flexible enough to support a variety of RPC styles, including request-response, streaming, and pipelining; for example, HTTP pipelining and Redis pipelining. It also makes it easy to work with stateful RPC styles; for example, RPCs that require authentication and those that support transactions.\" Supports also failover/retry, service discovery, multiple protocol (e.g. http, thrift). Build on Netty, Java NIO. See the <a href=\"https://github.com/twitter/finagle/blob/master/README.md#Finagle%20Overview\">overview</a> and <a href=\"https://github.com/twitter/finagle/blob/master/README.md#Architecture\">architecture</a>.</li>\r\n\t<li><a href=\"http://www.eclipse.org/recommenders/\">Eclipse Code Recommenders</a> - interesting plugin in incubation that tries to bring more more intelligent completion based more on context and the wisdom of the crowds (i.e. patterns of usage in existing source codes) to Eclipse</li>\r\n</ul>\r\n<h2>Clojure Corner</h2>\r\n<ul>\r\n\t<li><a href=\"http://clojure.com/blog/2012/02/17/clojure-governance.html\">Clojure/huh? - Clojure's Governance and How It Got That Way</a> - an interesting description how the development of Clojure and inclusion of new libraries is managed. \"Rich is extremely conservative about adding features to the language, and he has impressed this view on Clojure/core for the purpose of screening tickets.\" E.g. it took two years to get support for named arguments - but the result is a much better and cleaner way of doing it.</li>\r\n\t<li><a href=\"http://www.clojure.net/tags.html#monads-ref\">Clojure Monads Series</a> - comprehensive explanations of monads starting with <a href=\"http://www.clojure.net/2012/02/02/Monads-in-Clojure\">Monads In Clojure</a></li>\r\n</ul>\r\n<h2>Quotes</h2>\r\n<p style=\"text-align:left;\">A language that doesn't affect the way you think about programming, is not worth knowing- <em></em></p>\r\n<p style=\"text-align:right;\"><em> </em>- Alan Perlis</p>\r\n<p style=\"text-align:left;\">Lisp is worth learning for the profound enlightenment experience you will have when you finally get it; that experience will make you a better programmer for the rest of your days, even if you never actually use Lisp itself a lot.</p>\r\n<p style=\"text-align:right;\" dir=\"ltr\">Eric S. Raymond, \"How to Become a Hacker\"</p><br><br><div class=\"linkscent-iconblock\" style=\"float:none !important;border:0 solid #ff0000 !important;background:none repeat scroll center center transparent !important;width:auto !important;height:auto !important;display:block !important;overflow:visible !important;position:static !important;text-indent:0 !important;z-index:auto !important;max-width:none !important;min-width:0 !important;max-height:none !important;min-height:0 !important;left:auto !important;top:auto !important;bottom:auto !important;right:auto !important;line-height:16px !important;white-space:nowrap !important;margin:0!important;padding:0!important;\"><img class=\"linkscent-icon\" style=\"float:none !important;border:0 solid #ff0000 !important;width:16px !important;height:16px !important;display:none;overflow:visible !important;position:absolute !important;text-indent:0 !important;z-index:2147483635 !important;max-width:none !important;min-width:0 !important;max-height:none !important;min-height:0 !important;left:485px;top:557px;bottom:auto !important;right:auto !important;line-height:16px !important;white-space:nowrap !important;visibility:hidden;background:url('http://martinfowler.com/favicon.ico') no-repeat scroll center center transparent !important;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" /><img class=\"linkscent-icon\" style=\"float:none !important;border:0 solid #ff0000 !important;background:url('//interclue/content/cluecore/skins/default/sprites.png') no-repeat scroll -64px -96px transparent;width:16px !important;height:16px !important;display:none;overflow:visible !important;position:absolute !important;text-indent:0 !important;z-index:2147483635 !important;max-width:none !important;min-width:0 !important;max-height:none !important;min-height:0 !important;left:503px;top:557px;bottom:auto !important;right:auto !important;line-height:16px !important;white-space:nowrap !important;visibility:hidden;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" width=\"16\" height=\"16\" /><img class=\"linkscent-icon\" style=\"float:none !important;border:0 solid #ff0000 !important;background:none repeat scroll center center transparent;width:16px !important;height:16px !important;display:none;overflow:visible !important;position:absolute !important;text-indent:0 !important;z-index:2147483635 !important;max-width:none !important;min-width:0 !important;max-height:none !important;min-height:0 !important;left:521px;top:557px;bottom:auto !important;right:auto !important;line-height:16px !important;white-space:nowrap !important;visibility:hidden;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" /><img class=\"linkscent-icon\" style=\"float:none !important;border:0 solid #ff0000 !important;width:16px !important;height:16px !important;display:none;overflow:visible !important;position:absolute !important;text-indent:0 !important;z-index:2147483635 !important;max-width:none !important;min-width:0 !important;max-height:none !important;min-height:0 !important;left:582px;top:595px;bottom:auto !important;right:auto !important;line-height:16px !important;white-space:nowrap !important;visibility:hidden;background:url('http://lusislog.blogspot.com/favicon.ico') no-repeat scroll center center transparent !important;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" /><img class=\"linkscent-icon\" style=\"float:none !important;border:0 solid #ff0000 !important;background:url('//interclue/content/cluecore/skins/default/sprites.png') no-repeat scroll -48px -96px transparent;width:16px !important;height:16px !important;display:none;overflow:visible !important;position:absolute !important;text-indent:0 !important;z-index:2147483635 !important;max-width:none !important;min-width:0 !important;max-height:none !important;min-height:0 !important;left:600px;top:595px;bottom:auto !important;right:auto !important;line-height:16px !important;white-space:nowrap !important;visibility:hidden;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" width=\"16\" height=\"16\" /><img class=\"linkscent-icon\" style=\"float:none !important;border:0 solid #ff0000 !important;background:none repeat scroll center center transparent;width:16px !important;height:16px !important;display:none;overflow:visible !important;position:absolute !important;text-indent:0 !important;z-index:2147483635 !important;max-width:none !important;min-width:0 !important;max-height:none !important;min-height:0 !important;left:618px;top:595px;bottom:auto !important;right:auto !important;line-height:16px !important;white-space:nowrap !important;visibility:hidden;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" /></div>\r\n<div class=\"linkscent-iconblock\" style=\"float:none !important;border:0 solid #ff0000 !important;background:none repeat scroll center center transparent !important;width:auto !important;height:auto !important;display:block !important;overflow:visible !important;position:static !important;text-indent:0 !important;z-index:auto !important;max-width:none !important;min-width:0 !important;max-height:none !important;min-height:0 !important;left:auto !important;top:auto !important;bottom:auto !important;right:auto !important;line-height:16px !important;white-space:nowrap !important;margin:0!important;padding:0!important;\"><img class=\"linkscent-icon\" style=\"float:none !important;border:0 solid #ff0000 !important;width:16px !important;height:16px !important;display:none;overflow:visible !important;position:absolute !important;text-indent:0 !important;z-index:2147483635 !important;max-width:none !important;min-width:0 !important;max-height:none !important;min-height:0 !important;left:252px;top:1417px;bottom:auto !important;right:auto !important;line-height:16px !important;white-space:nowrap !important;visibility:hidden;background:url('http://vanillajava.blogspot.com/favicon.ico') no-repeat scroll center center transparent !important;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" /><img class=\"linkscent-icon\" style=\"float:none !important;border:0 solid #ff0000 !important;background:none repeat scroll center center transparent;width:16px !important;height:16px !important;display:none;overflow:visible !important;position:absolute !important;text-indent:0 !important;z-index:2147483635 !important;max-width:none !important;min-width:0 !important;max-height:none !important;min-height:0 !important;left:270px;top:1417px;bottom:auto !important;right:auto !important;line-height:16px !important;white-space:nowrap !important;visibility:hidden;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" /><img class=\"linkscent-icon\" style=\"float:none !important;border:0 solid #ff0000 !important;width:16px !important;height:16px !important;display:none;overflow:visible !important;position:absolute !important;text-indent:0 !important;z-index:2147483635 !important;max-width:none !important;min-width:0 !important;max-height:none !important;min-height:0 !important;left:495px;top:1549px;bottom:auto !important;right:auto !important;line-height:16px !important;white-space:nowrap !important;visibility:hidden;background:url('http://github.com/favicon.ico') no-repeat scroll center center transparent !important;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" /><img class=\"linkscent-icon\" style=\"float:none !important;border:0 solid #ff0000 !important;background:url('//interclue/content/cluecore/skins/default/sprites.png') no-repeat scroll -32px -64px transparent;width:16px !important;height:16px !important;display:none;overflow:visible !important;position:absolute !important;text-indent:0 !important;z-index:2147483635 !important;max-width:none !important;min-width:0 !important;max-height:none !important;min-height:0 !important;left:513px;top:1549px;bottom:auto !important;right:auto !important;line-height:16px !important;white-space:nowrap !important;visibility:hidden;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" width=\"16\" height=\"16\" /><img class=\"linkscent-icon\" style=\"float:none !important;border:0 solid #ff0000 !important;background:url('//interclue/content/cluecore/skins/default/sprites.png') no-repeat scroll -144px -96px transparent;width:16px !important;height:16px !important;display:none;overflow:visible !important;position:absolute !important;text-indent:0 !important;z-index:2147483635 !important;max-width:none !important;min-width:0 !important;max-height:none !important;min-height:0 !important;left:531px;top:1549px;bottom:auto !important;right:auto !important;line-height:16px !important;white-space:nowrap !important;visibility:hidden;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" width=\"16\" height=\"16\" /><img class=\"linkscent-icon\" style=\"float:none !important;border:0 solid #ff0000 !important;background:none repeat scroll center center transparent;width:16px !important;height:16px !important;display:none;overflow:visible !important;position:absolute !important;text-indent:0 !important;z-index:2147483635 !important;max-width:none !important;min-width:0 !important;max-height:none !important;min-height:0 !important;left:549px;top:1549px;bottom:auto !important;right:auto !important;line-height:16px !important;white-space:nowrap !important;visibility:hidden;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" /></div>",
  "excerpt": ""
 },
 {
  "title": "Separating Integration and Unit Tests with Maven, Sonar, Failsafe, and JaCoCo",
  "published": "2012-02-05 11:43:25",
  "postType": "post",
  "slug": "/2012/02/05/separating-integration-and-unit-tests-with-maven-sonar-failsafe-and-jacoco/",
  "status": "publish",
  "tags": [
   "java",
   "Maven",
   "Sonar",
   "Testing"
  ],
  "categories": [
   "Languages",
   "Testing",
   "Tools"
  ],
  "content": "<strong>Goal</strong>: Execute the slow integration tests separately from unit tests and show as much information about them as possible in Sonar.<br><br>The first part - executing IT and UT separately - is achieved by using the <a href=\"http://maven.apache.org/plugins/maven-failsafe-plugin/\" rel=\"nofollow\">maven-failsafe-plugin</a> and by naming the integration tests *IT (so that the unit test running surefire-maven-plugin will ignore them while failsafe will execute them in the <em>integration-test</em> phase and collect results in the <em>verify </em>phase).<br><br>The second part - showing information about integration tests in Sonar - is little more tricky. Metrics of integration tests will not be included in the Test coverage + Unit tests success widget. You can add Integration test coverage (IT coverage) widget if you enable JaCoCo but there is no alternative for the test success metrics. But don't despair, read on!<br><br>Important notice: The integration of Sonar, JaCoCo and Failsafe evolves quite quickly so this information may easily get outdated with the next releases of Sonar<br><br><strong>Versions</strong>: Sonar 2.12, Maven 3.0.3<br><br><!--more-->\r\n<h3 id=\"Sonar-PrerequisityHowSonarWorks\">Prerequisity: How Sonar Works</h3>\r\nIt's important to understand how Sonar works and how it is integrated into the build process. Briefly:\r\n<ul>\r\n\t<li>Sonar is run <em>after</em> the project is built (and thus various artifacts are already generated): either as a post- action in Jenkins or after executing mvn install manually</li>\r\n\t<li>Sonar comes bundled with various integrated quality analysis plugins such as PMD, Checkstyle, Findbugs (depending on the quality profile chosen). You do not need to add them manually to your POM (but you can, if you need to configure them). However if you need something it doesn't do yet such as collecting coverage for integration tests, you have to do it manually.</li>\r\n\t<li>Sonar may either reuse existing reports (checkstyle, ...) or generate its own.</li>\r\n\t<li>F.ex. if you choose JaCoCo as the default code coverage provider, Sonar will automatically rerun unit tests with JaCoCo enabled to collect the coverage metrics. You can see the file target/sonar/sonar-pom.xml that it generates to see what it does.</li>\r\n</ul>\r\n<h3 id=\"Sonar-SonarITTestSuccess\">Fooling Sonar to Display IT Test Success</h3>\r\nExecuting unit tests via Surefire and integration tests via Failsafe results in not beeing able to see when integration tests fail. (Because this is shown by the Unit test success widget, which doesn't support Failsafe.) However it's possible to fool Sonar to show test success for both unit and integration tests together by instructing Failsafe to store its test reports to the same directory as Surefire instead of the default failsafe-reports, and that's what we do:<br><br><pre><code>\r\n&lt;!-- pom.xml, the build/plugins section --&gt;\r\n&lt;plugin&gt;\r\n    &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;\r\n    &lt;artifactId&gt;maven-failsafe-plugin&lt;/artifactId&gt;\r\n    &lt;configuration&gt;\r\n        &lt;reportsDirectory&gt;${project.build.directory}/surefire-reports&lt;/reportsDirectory&gt;\r\n    &lt;/configuration&gt;\r\n&lt;/plugin&gt;\r\n</code></pre>\r\n<h3 id=\"Sonar-SonarITCodeCoverage\">How to display IT Code Coverage in Sonar</h3>\r\nSonar 2.12 currently isn't able to compute test coverage for integration tests automatically and thus we have to do it manually. Summary:\r\n<ol>\r\n\t<li>Add Failsafe to your Maven configuration as shown above.</li>\r\n\t<li>Add JaCoCo to Maven and combine it with Failsafe to produce the coverage report when integration tests are run</li>\r\n\t<li>Instruct Sonar to execute the verify phase and pass the path to the integration test report to it</li>\r\n</ol>\r\n<h4>1. Add Failsafe to your Maven configuration as shown above</h4>\r\nSee the pom.xml fragment under \"Fooling Sonar to Display IT Test Success\" above.\r\n<h4>2. Add JaCoCo to Maven and combine it with Failsafe to produce the coverage report when integration tests are run</h4>\r\nAs Sonar 2.12 doesn't automatically reconfigure Failsafe to collect code coverage, we have to instruct Failsafe manually to load the JaCoCo java agent that will collect and store the coverage report (to target/jacoco.exec by default):<br><br><pre><code>\r\n&lt;!-- pom.xml fragment: --&gt;\r\n&lt;build&gt;\r\n ...\r\n     &lt;!-- Run integration tests (*IT) --&gt;\r\n    &lt;plugin&gt;\r\n        &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;\r\n        &lt;artifactId&gt;maven-failsafe-plugin&lt;/artifactId&gt;\r\n        &lt;configuration&gt;\r\n            &lt;reportsDirectory&gt;${project.build.directory}/surefire-reports&lt;/reportsDirectory&gt;\r\n            &lt;argLine&gt;${jacoco.agent.argLine}&lt;/argLine&gt;\r\n        &lt;/configuration&gt;\r\n    &lt;/plugin&gt;\r\n    &lt;!--\r\n        Compute integration test coverage for Sonar\r\n        BEWARE: Sonar doesn't run the verify phase, it has to be forced by setting -Dsonar.phase=verify\r\n    --&gt;\r\n    &lt;plugin&gt;\r\n        &lt;groupId&gt;org.jacoco&lt;/groupId&gt;\r\n        &lt;artifactId&gt;jacoco-maven-plugin&lt;/artifactId&gt;\r\n        &lt;configuration&gt;\r\n            &lt;propertyName&gt;jacoco.agent.argLine&lt;/propertyName&gt; &lt;!-- default: argLine --&gt;\r\n            &lt;includes&gt;\r\n                &lt;include&gt;com/comoyo/**&lt;/include&gt;\r\n            &lt;/includes&gt;\r\n            &lt;destFile&gt;${project.build.directory}/jacoco-integration.exec&lt;/destFile&gt; &lt;!-- agent --&gt;\r\n            &lt;dataFile&gt;${project.build.directory}/jacoco-integration.exec&lt;/dataFile&gt; &lt;!-- report --&gt;\r\n        &lt;/configuration&gt;\r\n        &lt;executions&gt;\r\n            &lt;execution&gt;\r\n                &lt;id&gt;agent&lt;/id&gt;\r\n                &lt;goals&gt;&lt;goal&gt;prepare-agent&lt;/goal&gt;&lt;/goals&gt;\r\n            &lt;/execution&gt;\r\n        &lt;/executions&gt;\r\n    &lt;/plugin&gt;\r\n&lt;/build&gt;\r\n</code></pre><br><br>The key lines are 10 (argLine) and 28 (prepare-agent before verify - the default phase, if unspecified, is <em>init</em>).\r\n<h4>3. Instruct Sonar to execute the verify phase and pass the path to the integration test report to it</h4>\r\n<em>Important: If you use Sonar prior to 2.12 then you must install the Sonar JaCoCo plugin manually.</em><br><br>Whether running Sonar from Jenkins or locally we have to make sure that the verify phase is run and pass to Sonar the path to the generated JaCoCo integration test coverage report. This is best done in Sonar in the JaCoCo plugin configuration (on the project level?) but you could also do it manually by passing it to maven via \"-Dsonar.jacoco.itReportPath=target/jacoco-integration.exec\" or by setting the property in pom.xml under project/properties.<br><br><strong>Jenkins Sonar plugin</strong> does not require any special <a href=\"http://docs.codehaus.org/display/SONAR/Activate+Sonar+on+Jenkins+job\" rel=\"nofollow\">configuration</a> if path to the report is set inside Sonar's JaCoCo plugin.<br><br><strong>Command line</strong> (the <a href=\"http://docs.codehaus.org/display/SONAR/Analyse+with+Maven\" rel=\"nofollow\">recommended</a> way; the first line runs among others the phase verify and thus generates the report):\r\n<pre>payment$ mvn clean install -Dtest=false -DfailIfNoTests=false\r\npayment$ mvn <a href=\"http://sonarsonar/\" rel=\"nofollow\">sonar:sonar</a></pre>\r\nWe could actually invoke Maven with a single line, though that isn't recommended because it would run tests multiple times:\r\n<pre>payment$ mvn -Dsonar.phase=verify <a href=\"http://sonarsonar/\" rel=\"nofollow\">sonar:sonar</a></pre>\r\n<div>NOTE: If you set JaCoCo as the default code coverage provider in Sonar than it will produce coverage for unit tests overriding the integration test coverage from the verify phase. Solutions: 1) Don't enable JaCoCo, 2) Configure JaCoCo to use a different file for integration tests (which we do)</div>\r\nSome logs of interest from running mvn sonar:sonar:\r\n<pre>...\r\nJaCoCo agent (version 0.5.3.201107060350) extracted: /var/folders/k0/2842tm752zv1dh4q77_gmgdr0000gn/T/jacocoagent2548420105762793132.jar\r\nJVM options: -<a rel=\"nofollow\">javaagent:/var/folders/k0/2842tm752zv1dh4q77_gmgdr0000gn/T/jacocoagent2548420105762793132.jar=destfile=target/jacoco.exec,excludes=*_javassist_*</a>\r\nInitializer FindbugsMavenInitializer...\r\nInitializer FindbugsMavenInitializer done: 4 ms\r\nExecute maven plugin maven-surefire-plugin...\r\nExecute org.apache.maven.plugins:maven-surefire-plugin:2.8.1:test...\r\n...\r\nExecute maven plugin maven-surefire-plugin done: 9856 ms\r\nInitializer JacocoMavenInitializer...\r\n..\r\nSensor SquidSensor done: 2207 ms\r\nSensor JaCoCoSensor...\r\nAnalysing /myproject/target/jacoco.exec\r\nSensor JaCoCoSensor done: 559 ms\r\nSensor JaCoCoItSensor...\r\nAnalysing /myproject/target/jacoco-integration.exec\r\nSensor JaCoCoItSensor done: 89 ms\r\nSensor SurefireSensor...</pre>\r\n<ul>\r\n\t<li>Notice that I've JaCoCo set as my code coverage provider in Sonar and Sonar does use its own copy of it  (the line JaCoCo agent .. extracted), which it uses in the test phase</li>\r\n\t<li>Notice that Sonar runs surefire:test automatically (with instrumentation) to collect code coverage</li>\r\n\t<li>Notice that JaCoCo processed both *.exec files (the first generated by Sonar for unit tests, the other generated by Maven in verify prior to calling Sonar)</li>\r\n</ul>\r\n<h4 id=\"Sonar-Caveats\">Tip: Compute the total code coverage of unit + integration tests</h4>\r\nUnit and integration test coverage are computed separately; to see the total code coverage we would need to merge the two (notice we can't just sum them as both kinds of tests can cover some of the same lines). It would be possible by using JaCoCo both to compute unit test coverage (supported out of the box) and integration test coverage into different files and using its Ant task to merge the two coverage files, passing the resulting file as the IT test coverage file to Sonar (for we cannot get a 3rd widget to display this summed coverage). However I haven't tried it.\r\n<h4 id=\"Sonar-NoteonTestingJaCoCoFailsafeandMavenIntegration\">Note on Testing JaCoCo, Failsafe and Maven Integration</h4>\r\nIf Sonar doesn't show the IT coverage widget though it is on the dashboard (click on Configure widgets while logged in) or shows 0% though it should be higher, you may check the data that JaCoCo is generating by producing HTML report from them. There is both an Ant task for that, which didn't work for me, and Maven goal. This is how you instruct JaCoCo to generate the report when \"mvn site\" is run - notice the lines 13, 14 (remember that you must run \"mvn verify\" first to generate the binary coverage report):<br><br><pre><code>\r\n&lt;!-- pom.xml build/plugins fragment --&gt;\r\n&lt;plugin&gt;\r\n    &lt;groupId&gt;org.jacoco&lt;/groupId&gt;\r\n    &lt;artifactId&gt;jacoco-maven-plugin&lt;/artifactId&gt;\r\n    &lt;executions&gt;\r\n        &lt;execution&gt;\r\n            &lt;id&gt;agent&lt;/id&gt;\r\n            &lt;phase&gt;pre-integration-test&lt;/phase&gt;\r\n            &lt;goals&gt;&lt;goal&gt;prepare-agent&lt;/goal&gt;&lt;/goals&gt;\r\n        &lt;/execution&gt;\r\n        &lt;execution&gt;\r\n            &lt;id&gt;report&lt;/id&gt;\r\n            &lt;phase&gt;site&lt;/phase&gt;\r\n            &lt;goals&gt;&lt;goal&gt;report&lt;/goal&gt;&lt;/goals&gt;\r\n        &lt;/execution&gt;\r\n    &lt;/executions&gt;\r\n&lt;/plugin&gt;\r\n</code></pre>\r\n<h3 id=\"Sonar-References\">References</h3>\r\nJaCoCo Maven plugin has minimal <a href=\"http://www.eclemma.org/jacoco/trunk/doc/maven.html\">documentation</a> but you can get useful info via:\r\n<pre>mvn <a href=\"http://helpdescribe/\" rel=\"nofollow\">help:describe</a> -Dplugin=org.<a href=\"http://jacocojacoco-maven-plugin/\" rel=\"nofollow\">jacoco:jacoco-maven-plugin</a> -Ddetail</pre>\r\nSonar: <a href=\"http://www.sonarsource.org/measure-code-coverage-by-integration-tests-with-sonar/\" rel=\"nofollow\">Measure Code Coverage by Integration Tests with Sonar</a> (9/2010) - doesn't use the JaCoCo Maven plugin and thus has to configure the argLine manually<br><br><h3 id=\"pom\">The Complete POM</h3>\r\n<a href=\"https://github.com/jakubholynet/blog/blob/master/snippets/split_integration_tst_and_coverage-pom.xml\">See the complete POM at GitHub</a>.",
  "excerpt": ""
 },
 {
  "title": "Using Java Compiler Tree API to Extract Generics Types",
  "published": "2012-02-06 22:52:31",
  "postType": "post",
  "slug": "/2012/02/07/using-java-compiler-tree-api-to-extract-generics-types/",
  "status": "publish",
  "tags": [
   "compiler",
   "generics",
   "java",
   "JDK"
  ],
  "categories": [
   "Languages"
  ],
  "content": "I was looking for some way to extract information about types of elements in Java collections/maps using generics (List&lt;String&gt;, Map&lt;String, MyBean&gt;) so that the users of the <a href=\"https://github.com/jakubholynet/static-jsfexpression-validator\">Static JSF Expression Validator</a> wouldn't need to declare the type of the elements manually. One possible way to get this information is to process the source codes with the Sun Compiler Tree API, available since JDK 6.<br><br>It might be best to go and check the resulting 263 lines of <a id=\"552f4bec297f7ef876e29e9bd519fbaf4639b81c\" href=\"https://github.com/jakubholynet/blog/blob/master/miniprojects/generics-detector/CollectionGenericsTypeExctractor.java\">CollectionGenericsTypeExctractor.java</a> now. The code is little ugly, largely due to the API being ugly.<br><br><!--more--><br><br>Overview\r\n<ol>\r\n\t<li>JavaCompiler (Compiler API) is used to compile the source codes that should be searched for generics</li>\r\n\t<li>A custom annotation provider (Java Annotation API) is used during the compilation to process the sources</li>\r\n\t<li>The processor only delegates to a custom TreePathScanner (Sun Compiler Tree API) whose <em>visitMethod</em> extracts all the information from the MethodTree, using some dark magic to get fully qualified type names of the class and return type</li>\r\n</ol>\r\nLimitations\r\n<ol>\r\n\t<li>The Compiler must be able to resolve all dependencies (imports) to be able to process the files</li>\r\n\t<li>It only works with Sun JDK and its tools.jar must be on the class path (the Compiler and Annotation APIs are a part of Java specification but the Compiler Tree API is not and is thus vendor-specific)</li>\r\n\t<li>The code currently doesn't handle getters inside nested/inner classes (it would need to check that it is such a class and replace the last . with $ in the name)</li>\r\n</ol>\r\nYou'd better check the <a id=\"552f4bec297f7ef876e29e9bd519fbaf4639b81c\" href=\"https://github.com/jakubholynet/blog/blob/master/miniprojects/generics-detector/CollectionGenericsTypeExctractor.java\">complete (short) code</a> at GitHub but if it's too far for you :-), here is the crucial piece:<br><br><pre><code>\r\n@Override\r\npublic Object visitMethod(MethodTree methodTree, Trees trees) {\r\n\tString typeNameQualified = getEnclosingClassNameIfAvailable(trees);<br><br>\t// Skip or bad stuff happens (case: inside anonymous inner class)\r\n\tif (typeNameQualified == null) {\r\n\t\treturn super.visitMethod(methodTree, trees);\r\n\t}<br><br>\tTree returnType = methodTree.getReturnType();   // null for void method\r\n\tif (getter(methodTree) &amp;&amp; returnType instanceof ParameterizedTypeTree) {\r\n\t\tassert Tree.Kind.PARAMETERIZED_TYPE == returnType.getKind();\r\n\t\tParameterizedTypeTree parametrizedReturnType = (ParameterizedTypeTree) returnType;<br><br>\t\tTypeCategory category = detectTypeCategory(parametrizedReturnType);\r\n\t\tif (category.isCollectionOrMap()) {\r\n\t\t\tTree valueTypeArgument = parametrizedReturnType.getTypeArguments().get(category.getValueTypeArgumentIdx());\r\n\t\t\tfinal String qualifiedGenericTypeName = getQualifiedType(valueTypeArgument);<br><br>\t\t\tString methodJsfName = getMethodJsfName(methodTree);\r\n\t\t\tSystem.out.println(&quot;FOUND &quot; + typeNameQualified + &quot;.&quot; + methodJsfName + &quot;.*=&quot; + qualifiedGenericTypeName);\r\n\t\t\t// Unqualified name: ((IdentifierTree) valueTypeArgument).getName().toString();\r\n\t\t}\r\n\t}\r\n\treturn super.visitMethod(methodTree, trees);\r\n}\r\n</code></pre><br><br>Most of the code has been copied from the article <a href=\"http://today.java.net/pub/a/today/2008/04/10/source-code-analysis-using-java-6-compiler-apis.html\">Source Code Analysis Using Java 6 APIs</a> by Seema Richard (4/2008).\r\n<h2>Conclusion</h2>\r\nIt's possible to use the Java Compiler Tree API to get the desired information but it is not exactly easy because the API os overly complex and undocumented. It would likely be better to use some decent open-source Java parser.",
  "excerpt": ""
 },
 {
  "title": "Release 0.9.9 of Static JSF EL Expression Validator with Annotated Beans Autodetection",
  "published": "2012-02-13 14:10:44",
  "postType": "post",
  "slug": "/2012/02/13/release-0-9-8-of-static-jsf-el-expression-validator-with-annotated-beans-autodetection/",
  "status": "publish",
  "tags": [
   "java",
   "jsf",
   "open_source",
   "project"
  ],
  "categories": [
   "j2ee",
   "Languages",
   "Tools"
  ],
  "content": "I've released version 0.9.9 of <a href=\"https://github.com/jakubholynet/static-jsfexpression-validator\">Static JSF EL Expression Validator</a> (tool to check that EL expressions in JSF pages use only existing beans and properties), available for <a href=\"http://repo1.maven.org/maven2/net/jakubholy/jeeutils/jsfelcheck/\">download from Maven Central</a>. The main addition since the last version is the ability to detect managed beans based on annotations instead of reading them from faces-confix.xml or Spring config, thanks to the cool <a href=\"http://code.google.com/p/reflections/\">Reflections lib</a>, and support for ui:repeat.<br><br><!--more-->\r\n<h3>Version 0.9.9</h3>\r\n<ul>\r\n\t<li>Support for ui:repeat</li>\r\n</ul>\r\n<h3>Version 0.9.8</h3>\r\n<ul>\r\n\t<li>Support for detecting managed beans based on annotations (analyzer.withManagedBeansAndVariablesConfiguration(fromClassesInPackages(..)..))</li>\r\n\t<li>The directory passed to analyzer.validateElExpressions must the root of your web application; alternatively you can pass in two directories - the webapp root and the directory containing the pages to analyze</li>\r\n</ul>\r\n<div class=\"linkscent-iconblock\" style=\"float:none !important;border:0 solid #ff0000 !important;background:none repeat scroll center center transparent !important;width:auto !important;height:auto !important;display:block !important;overflow:visible !important;position:static !important;text-indent:0 !important;z-index:auto !important;max-width:none !important;min-width:0 !important;max-height:none !important;min-height:0 !important;left:auto !important;top:auto !important;bottom:auto !important;right:auto !important;line-height:16px !important;white-space:nowrap !important;margin:0!important;padding:0!important;\"><img class=\"linkscent-icon\" style=\"float:none !important;border:0 solid #ff0000 !important;width:16px !important;height:16px !important;display:none;overflow:visible !important;position:absolute !important;text-indent:0 !important;z-index:2147483635 !important;max-width:none !important;min-width:0 !important;max-height:none !important;min-height:0 !important;left:440px;top:29px;bottom:auto !important;right:auto !important;line-height:16px !important;white-space:nowrap !important;visibility:hidden;background:url('//interclue/content/cluecore/skins/default/linkscentExternal.png') no-repeat scroll center center transparent !important;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" /><img class=\"linkscent-icon\" style=\"float:none !important;border:0 solid #ff0000 !important;background:none repeat scroll center center transparent;width:16px !important;height:16px !important;display:block;overflow:visible !important;position:absolute !important;text-indent:0 !important;z-index:2147483635 !important;max-width:none !important;min-width:0 !important;max-height:none !important;min-height:0 !important;left:458px;top:29px;bottom:auto !important;right:auto !important;line-height:16px !important;white-space:nowrap !important;visibility:hidden;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/linkscentError.png\" alt=\"\" /></div>\r\n<div class=\"linkscent-iconblock\" style=\"float:none !important;border:0 solid #ff0000 !important;background:none repeat scroll center center transparent !important;width:auto !important;height:auto !important;display:block !important;overflow:visible !important;position:static !important;text-indent:0 !important;z-index:auto !important;max-width:none !important;min-width:0 !important;max-height:none !important;min-height:0 !important;left:auto !important;top:auto !important;bottom:auto !important;right:auto !important;line-height:16px !important;white-space:nowrap !important;margin:0!important;padding:0!important;\"><img class=\"linkscent-icon\" style=\"float:none !important;border:0 solid #ff0000 !important;width:16px !important;height:16px !important;display:none;overflow:visible !important;position:absolute !important;text-indent:0 !important;z-index:2147483635 !important;max-width:none !important;min-width:0 !important;max-height:none !important;min-height:0 !important;left:379px;top:10px;bottom:auto !important;right:auto !important;line-height:16px !important;white-space:nowrap !important;visibility:hidden;background:url('http://github.com/favicon.ico') no-repeat scroll center center transparent !important;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" /><img class=\"linkscent-icon\" style=\"float:none !important;border:0 solid #ff0000 !important;background:url('//interclue/content/cluecore/skins/default/sprites.png') no-repeat scroll -144px -96px transparent;width:16px !important;height:16px !important;display:none;overflow:visible !important;position:absolute !important;text-indent:0 !important;z-index:2147483635 !important;max-width:none !important;min-width:0 !important;max-height:none !important;min-height:0 !important;left:397px;top:10px;bottom:auto !important;right:auto !important;line-height:16px !important;white-space:nowrap !important;visibility:hidden;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" width=\"16\" height=\"16\" /><img class=\"linkscent-icon\" style=\"float:none !important;border:0 solid #ff0000 !important;background:none repeat scroll center center transparent;width:16px !important;height:16px !important;display:none;overflow:visible !important;position:absolute !important;text-indent:0 !important;z-index:2147483635 !important;max-width:none !important;min-width:0 !important;max-height:none !important;min-height:0 !important;left:415px;top:10px;bottom:auto !important;right:auto !important;line-height:16px !important;white-space:nowrap !important;visibility:hidden;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" /><img class=\"linkscent-icon\" style=\"float:none !important;border:0 solid #ff0000 !important;width:16px !important;height:16px !important;display:none;overflow:visible !important;position:absolute !important;text-indent:0 !important;z-index:2147483635 !important;max-width:none !important;min-width:0 !important;max-height:none !important;min-height:0 !important;left:392px;top:29px;bottom:auto !important;right:auto !important;line-height:16px !important;white-space:nowrap !important;visibility:hidden;background:url('//interclue/content/cluecore/skins/default/linkscentExternal.png') no-repeat scroll center center transparent !important;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" /><img class=\"linkscent-icon\" style=\"float:none !important;border:0 solid #ff0000 !important;background:none repeat scroll center center transparent;width:16px !important;height:16px !important;display:none;overflow:visible !important;position:absolute !important;text-indent:0 !important;z-index:2147483635 !important;max-width:none !important;min-width:0 !important;max-height:none !important;min-height:0 !important;left:410px;top:29px;bottom:auto !important;right:auto !important;line-height:16px !important;white-space:nowrap !important;visibility:hidden;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" /></div>\r\n",
  "excerpt": ""
 },
 {
  "title": "Profiling Tomcat Webapp with VisualVM and NetBeans - Pitfalls",
  "published": "2012-02-25 15:07:37",
  "postType": "post",
  "slug": "/2012/02/25/profiling-tomcat-webapp-with-visualvm-and-netbeans-pitfalls/",
  "status": "publish",
  "tags": [
   "java",
   "performance",
   "profiling"
  ],
  "categories": [
   "Languages",
   "Tools"
  ],
  "content": "Profiling a webapp running on Tomcat with VisualVM or NetBeans wasn't as easy as expected, so this is a brief record of what to avoid to succeed.<br><br>Environment: Mac OS X, Java JDK 1.6.0_29, Netbeans 7.1, VisualVM 1.3.3 (installed separately), Tomcat 6.\r\n<h2>The Pitfalls:</h2>\r\nVisualVM\r\n<ul>\r\n\t<li>VisualVM Sampler and Profiler: <strong>To be able to drill down to the slow methods you need to take a snapshot before you stop the sampling/profiling</strong> (there is a [Snapshot] button above the Hot Spots list). This is not very intuitive and the interface doesn't communicate it.</li>\r\n\t<li>VisualVM Profiler: Excludes Thread.sleep() &amp; Object.wait() time (as opposed to the NetBeans profiler where you can choose to include/exclude them) =&gt; if you method is spending lot of time waiting for a lock, you won't discover it</li>\r\n\t<li>You might need to allow unsafe, passwordless JMX connections in your Tomcat config, see Resources</li>\r\n</ul>\r\nNetBeans Profiler\r\n<ul>\r\n\t<li>While VisualVM was able to dynamically connect to my Tomcat, NetBeans wasn't able to do it and hasn't provided any notification about the failure. The only visible manifestation was that it wasn't showing and collecting any data. Solution: Use the \"Direct\" attach invocation, i.e. starting the target java application with the NetBeans profiling agentlib.</li>\r\n</ul>\r\n<h2>Tools Overview</h2>\r\n<h3>VisualVM</h3>\r\nExtremely useful tool, included in JDK since 6.0 (command line: jvisualvm) or on the <a href=\"http://visualvm.java.net/\">VisualVM page</a>.\r\n<ul>\r\n\t<li>Automatically discovers local Java processes and can connect to them (if they run Java 6+)</li>\r\n\t<li>Monitoring - threads, heap, permgen, CPU, classes</li>\r\n\t<li>Sampler - low-overhead profiling tool (takes thread snapshot at regular intervals and compares their stack traces to find out where most time is spent)</li>\r\n\t<li>Plugins, such as MBeans, Tracers</li>\r\n\t<li>Profiler - a simpler version of NetBeans profiler (<a href=\"https://blogs.oracle.com/nbprofiler/entry/profiling_with_visualvm_part_2\">comparison here</a>); it can dynamically attach to running (Java 6+) processes and instrument classes on-the-fly. The not very visible checkbox <em>Settings</em> in the right-top corner can be used to set the classes to start profiling from (syntax: my.package.** to include subpackages or my.package.* or my.pkg.MyClass) and the packages not to / only to profile (syntax differs here: my.package.* to include subpackages or my.package. or my.pkg.).</li>\r\n</ul>\r\n<h2>Resources</h2>\r\n<ul>\r\n\t<li>Experience :-)</li>\r\n\t<li><a href=\"https://blogs.oracle.com/nbprofiler/entry/profiling_with_visualvm_part_1\">Profiling With VisualVM, Part 1</a> (6/2008) and <a href=\"https://blogs.oracle.com/nbprofiler/entry/profiling_with_visualvm_part_2\">Part 2</a>, including comparison with the full NB profiler</li>\r\n\t<li><a href=\"http://mballantyne.blogspot.com/2011/05/profiling-tomcat-with-visualvm-on-mac.html\">Profiling Tomcat with VisualVM on Mac OS X</a> - including JMX setup in Tomcat</li>\r\n</ul>\r\n<div class=\"linkscent-iconblock\" style=\"float:none !important;border:0 solid #ff0000 !important;background:none repeat scroll center center transparent !important;width:auto !important;height:auto !important;display:block !important;overflow:visible !important;position:static !important;text-indent:0 !important;z-index:auto !important;max-width:none !important;min-width:0 !important;max-height:none !important;min-height:0 !important;left:auto !important;top:auto !important;bottom:auto !important;right:auto !important;line-height:16px !important;white-space:nowrap !important;margin:0!important;padding:0!important;\"><img class=\"linkscent-icon\" style=\"float:none !important;border:0 solid #ff0000 !important;width:16px !important;height:16px !important;display:none;overflow:visible !important;position:absolute !important;text-indent:0 !important;z-index:2147483635 !important;max-width:none !important;min-width:0 !important;max-height:none !important;min-height:0 !important;left:589px;top:445px;bottom:auto !important;right:auto !important;line-height:16px !important;white-space:nowrap !important;visibility:hidden;background:url('http://visualvm.java.net/favicon.ico') no-repeat scroll center center transparent !important;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" /><img class=\"linkscent-icon\" style=\"float:none !important;border:0 solid #ff0000 !important;background:none repeat scroll center center transparent;width:16px !important;height:16px !important;display:none;overflow:visible !important;position:absolute !important;text-indent:0 !important;z-index:2147483635 !important;max-width:none !important;min-width:0 !important;max-height:none !important;min-height:0 !important;left:607px;top:445px;bottom:auto !important;right:auto !important;line-height:16px !important;white-space:nowrap !important;visibility:hidden;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" /></div>\r\n",
  "excerpt": ""
 },
 {
  "title": "Cool Tools: Fault Injection into Unit Tests with JBoss Byteman - Easier Testing of Error Handling",
  "published": "2012-02-25 18:22:50",
  "postType": "post",
  "slug": "/2012/02/25/cool-tools-fault-injection-into-unit-tests-with-jboss-byteman-easier-testing-of-error-handling/",
  "status": "publish",
  "tags": [
   "AOP",
   "concurrency"
  ],
  "categories": [
   "Testing",
   "Tools"
  ],
  "content": "How do you test error handling in your application? Do you? Is it at all possible to simulate SocketTimeoutException, SQLException? Normally the answer would be that it isn't possible or very difficult, requiring a complicated setup. Not anymore - with <a href=\"http://www.jboss.org/byteman\">JBoss Byteman</a> you can easily inject whatever code - e.g. throw new SocketTimeoutException() - in any place - e.g. Socket.connect. The code is injected before your test runs and unloaded when it finishes. Here is an example:<br><br><pre><code>\r\n@RunWith(BMUnitRunner.class)\r\npublic class BytemanJUnitTests {\r\n@Test(expected=MyServiceUnavailableException.class)\r\n   @BMRule(name=&quot;throw timeout at 1st call&quot;,\r\n   targetClass = &quot;Socket&quot;,\r\n   targetMethod = &quot;connect&quot;,\r\n   action = &quot;throw new java.io.IOException()&quot;)\r\n   public void testErrorInPipeline() throws Exception {\r\n      // Invokes internally Socket.connect(..):\r\n      new MyHttpClient(&quot;http://example.com/data&quot;).read();\r\n   }\r\n}\r\n</code></pre><br><br><!--more-->\r\nWhat's even more cool, the Byteman rules also support various conditions such as count downs or rendezvous - a special object that can be used to synchonize and order independent thread, e.g. to ensure that thread A executes method a before thread B executes method b - which makes it possible to <strong>test different orders of execution and concurrency issues</strong> that they might cause.<br><br>Fault injection in JUnit tests and the use of conditions such as rendezvous is well explained in the official tutorial <a href=\"https://community.jboss.org/wiki/FaultInjectionTestingWithByteman\">Fault Injection Testing With Byteman</a>.<br><br>In general, JBoss Byteman 2.0.0 is a Bytecode Manipulation, Testing, Fault Injection, Logging and generally aspect-oriented programming tool. More exactly it is a Java agent which helps testing, tracing, and monitoring code. Additional code is injected (instrumentation) based on simple scripts (rules) in the event-condition-action form (the conditions may use counters, timers etc.). Contrary to standard AOP, there is no need to create classes or compile code. \"Byteman is also simpler to use and easier to change, especially for testing and ad hoc logging purposes.\" \"Byteman was invented primarily to support automation of tests for multi-threaded and multi-JVM Java applications using a technique called fault injection.\"<br><br>Yyou can <a href=\"http://www.jboss.org/byteman/downloads\">download Byteman</a> from the project site or get it from the <a href=\"http://repository.jboss.org/nexus/content/groups/public\">JBoss Maven repository</a> (let's hope they'll release into Maven Central too.)<br><br><a href=\"https://github.com/jakubholynet/presentations/tree/master/UnitTestingSwissKnife/ExampleByteman\">Get a complete example project</a> from my JavaZone 2012 talk at GitHub.<br><br><strong>Update</strong>: Brett L. Schuchert argues very well in <a href=\"http://martinfowler.com/articles/modernMockingTools.html\">Modern Mocking Tools and Black Magic - An example of power corrupting</a> why using such black magic (<a href=\"http://code.google.com/p/jmockit/\">JMockIt</a> in his case) should be avoided as only treating the symtomps in favor of actually fixing the code.",
  "excerpt": ""
 },
 {
  "title": "Link: Benchmark and Scaling of Amazon RDS (MySQL)",
  "published": "2012-03-01 08:34:37",
  "postType": "post",
  "slug": "/2012/03/01/link-benchmark-and-scaling-of-amazon-rds-mysql/",
  "status": "publish",
  "tags": [
   "aws",
   "performance",
   "rds"
  ],
  "categories": [
   "General"
  ],
  "content": "Performance and scaling of the Amazon-managed MySQL, Relational Data Store (RDS):<br><br><a href=\"https://forums.aws.amazon.com/thread.jspa?messageID=203052\" rel=\"nofollow\">Scaling options</a>:\r\n<ul>\r\n\t<li><strong>Horizontal scaling</strong>\r\n<ul>\r\n\t<li><strong>Sharding</strong> (distribute data [tables or rows] among multiple RDS instances; <a href=\"http://highscalability.com/blog/2012/2/13/tumblr-architecture-15-billion-page-views-a-month-and-harder.html\">Tumblr uses sharded MySQL and it worked well for them</a>) - there is no explicit support so the applications have to handle it themselves, i.e. know which table/rows to read from which instance</li>\r\n\t<li><strong>Read-replicas</strong>: RDS supports set up of read-only replicas using MySQL's own replication; the replicas are evidently only usable for reading and may contain little stale data</li>\r\n</ul>\r\n</li>\r\n\t<li><strong>Vertical scaling</strong> (stronger EC2 instances) - there are interesting <a href=\"http://highscalability.com/blog/2011/6/21/running-tpc-c-on-mysqlrds.html\" rel=\"nofollow\">results from a benchmark of RDS with various instances/DB sizes</a> (6/2011, <a href=\"http://www.cloudcommons.com/learn/-/asset_publisher/bY1m/content/id/79371/\" rel=\"nofollow\">complete report</a>); key observations:\r\n<ul>\r\n\t<li>\"With hardly any dependency on the database size, MySQL <strong>reaches its optimal throughput at around 64 concurrent users</strong>. Anything above that causes throughput degradation.\"</li>\r\n\t<li>\"Throughput is improving as machines get stronger. However, there is a sweet-spot, a point where adding hardware doesn’t help performance. The sweet spot is around the XL machine, which reaches a<strong> [max] throughput of around 7000 tpm</strong>.\" (transactions per minute =&gt; ~ 110 tx/sec)</li>\r\n</ul>\r\n</li>\r\n</ul>\r\nDisclaimer: No banchmark proves anything generally applicable, it's always necessary to run one's own production load and measure that to see how in reality a DB performs for one's actual needs.\r\n<h2>Notes</h2>\r\n<ul>\r\n\t<li>The number of concurrent connections is by default derived from the memory, namely 150 for a small 1.5GB instance and 650 for a large 7.5GB instance. According to one expert it's completely OK to set it to 1000 connections without regard to memory; MySQL should handle it.</li>\r\n</ul>\r\n<div class=\"linkscent-iconblock\" style=\"float:none!important;border:0 solid #ff0000!important;background:none repeat scroll center center transparent!important;width:auto!important;height:auto!important;display:block!important;overflow:visible!important;position:static!important;text-indent:0!important;z-index:auto!important;max-width:none!important;min-width:0!important;max-height:none!important;min-height:0!important;left:auto!important;top:auto!important;bottom:auto!important;right:auto!important;line-height:16px!important;white-space:nowrap!important;margin:0!important;padding:0!important;\"><img class=\"linkscent-icon\" style=\"float:none!important;border:0 solid #ff0000!important;width:16px!important;height:16px!important;display:none;overflow:visible!important;position:absolute!important;text-indent:0!important;z-index:2147483635!important;max-width:none!important;min-width:0!important;max-height:none!important;min-height:0!important;left:160px;top:207px;bottom:auto!important;right:auto!important;line-height:16px!important;white-space:nowrap!important;visibility:hidden;background:url('http://highscalability.com/favicon.ico') no-repeat scroll center center transparent!important;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" /><img class=\"linkscent-icon\" style=\"float:none!important;border:0 solid #ff0000!important;background:none repeat scroll center center transparent;width:16px!important;height:16px!important;display:none;overflow:visible!important;position:absolute!important;text-indent:0!important;z-index:2147483635!important;max-width:none!important;min-width:0!important;max-height:none!important;min-height:0!important;left:178px;top:207px;bottom:auto!important;right:auto!important;line-height:16px!important;white-space:nowrap!important;visibility:hidden;opacity:0;margin:0;padding:0!important;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" /></div>\r\n",
  "excerpt": ""
 },
 {
  "title": "Kent Beck: Best Practices for Software Design with Low Feature Latency and High Throughput",
  "published": "2012-03-11 22:48:12",
  "postType": "post",
  "slug": "/2012/03/12/kent-beck-best-practices-for-software-design-with-low-feature-latency-and-high-throughput/",
  "status": "publish",
  "tags": [
   "agile",
   "design",
   "software"
  ],
  "categories": [
   "General"
  ],
  "content": "I was fortunate to attend Kent Beck's lecture summarizing his experiences and thoughts regarding efficient software design. Traditionally there have been two schools of thought about design: <em>Predictive design</em>, trying to design everything upfront (and making lot of wrong decisions) and <em>reactive design</em>, where any design is only done if it is absolutely necessary for implementing a feature (thus developing often on top of an insufficient design). Kent tried hard to discover such a design method that really delivers on the promises of both while avoiding their failures. This method is based on evolving design frequently in small, safe steps and focusing on learning while following some key best practices. It doesn't really matter what scope of design we are are speaking about, the method and principles are the same whether you're redesigning a class or a complex system.<br><br><!--more-->\r\n<h3>What is a good design?</h3>\r\nSome of the key factors are low coupling and high coherence, introduced in the book Structured Design similarly to this:\r\n<ul>\r\n\t<li>Two elements are coupled if whenever the first element (method, class, system) is changed then also the other element has to be changed.</li>\r\n\t<li>Cohesion is the ration of coupling of internal elements, i.e. an element is cohesive if all its internal elements belong together and are strongly related. We cannot avoid coupling but we can try to isolate coupled elements into a single unit (perhaps exposing a simpler interface to the surroundings) rather than having them distributed all over the system because this co-location makes changes easier.</li>\r\n</ul>\r\n<strong>Coupling</strong> Regarding coupling we can distinguish a *potential coupling*, i.e. a coupling that actually isn't a problem for that particular system because the coupled elements in reality never change (though, of course, that could change in the future), and a *realized coupling*, where the coupled elements indeed change and have to be kept in synchronization. It's of course the realized couplings that we need to limit. (It should be noticed that in any complex system all the elements are potentially coupled to all the others - f.ex. adding yet another server to your farm may overload one particular switch, leading to failures and timeouts in a remote parts of the system. There is no way to discover these couplings upfront.)<br><br>So a good design should be easy to change. Some of the other criteria are easy to understand, supporting the requirements at hand etc. Now when we have some idea of what a good design is, let's go back to the design methods.\r\n<h3>Predictive Design</h3>\r\nThe predictive design promises <em>high througput</em> - you design all that will be needed at once, without a costly trial-and-failure process. However we only rarely really know all that is necessary, the reality is always (much) more complex than envisioned, and thus we end up with an unsuitable, suboptimal design. The start of a project is actually the worst time to make decisions because we won't ever know less about the software than at this point (JH: remember the lean principle of the \"last responsible moment\" for making decisions, after the most knowledge has been gathered but before it's too late).\r\n<h3>Reactive Design</h3>\r\nThe reactive design promises <em>low latency</em> - instead of wasting days trying in vain to make the perfect design, you just start implementing features right away and adjust and clean the design reactively, when you cannot proceed without changing it. However the low latency is a lie because, as we continue building the software on top of an insufficient design, the development gets slower and slower (the yeasterday's sins make today's sins harder to commit).\r\n<h3>Achieving High Throughput and Low Latency</h3>\r\nHow to achieve both a relatively high throughput and low latency, for real? How to avoid both the cost of making a design decision too late (and thus developing on top of an unsuitable system) and the cost of making the decision too early and being forced to change it later? According to Kent, the best available solution is to <em><strong>design the software incrementally and adjust the design very frequently, applying the following principles</strong></em>:\r\n<ol>\r\n\t<li>Make changes in <strong>Small, Safe Steps</strong>. A safe change doesn't break anything, so it either has to be an automated refactoring (where the IDE guarantees its safety) or you must be pretty sure that it is safe and the affected code should preferably be also covered by a solid and fast test suite. (JH: It must be fast to enable frequent changes.) The safety of changes is the key enabler for the high throughput - you always know where you are, your software is always working, you can always go forth - or back or just stop there.</li>\r\n\t<li>There are only <strong>4 kinds of these design changes</strong>that we make and thus for approaches:\r\n<ol>\r\n\t<li>A simple design change that is safe in itself - then you <strong>just make it</strong> (e.g. pushing a method to a parent class).</li>\r\n\t<li>We know what we want to change but it is complicated - <strong>use <a href=\"/wiki/development/parallel-design-parallel-change/\">parallel design</a></strong>, i.e. develop the new design while still keeping the old design, having them both side by side for a while. Then, when feeling sure, just switch over to the new design and only after it proves itself, remove the old design. It might seem as a lot of unnecessary work but it is safe and it is constant safety that makes true speed possible. (JH: Which reminds me of the lean realization that local optimization - e.g. making a change quickly - often leads to the whole being suboptimal.)</li>\r\n\t<li>If you don't know what design you need then simplify - <strong>try something simple</strong>, ignoring most of the know complexities, with the goal of exploring the domain. You want to learn as much as possible from the change. For example if you should implement a linear algebra system, try first just adding two numbers. Try - observe - learn.</li>\r\n\t<li><strong>Use stepping stones</strong>: If you don't know in which direction your design should evolve or you just cannot get to where you want to be from where you are easily but there is something, which would help you to solve the problem if you had it (a tool, a library, a high-level API, DSL, ...) then create this \"stepping stone\" first. F.ex. I don't know how to help my uncle, a veggetable farmer, to plan the optimal trip through the local markets, but if I had a way to represent these markets, their profitability, and routes between them in the computer, it would certainly help me to think about the problem further.</li>\r\n</ol>\r\n</li>\r\n</ol>\r\nWith this approach the evolution of the software design becomes an integral part of your development process and with the frequent and safe steps it might look like you are flying when developing.<br><br>JH: You might notice that one of the underlying key ideas is that software development is a learning process, where we learn both about the domain, its intricacies, and the pros and cons of possible solutions. The learning is based on experience and thus it is necessary that we can quickly try and test various ideas and get quick feedback on them, throwing them away or continuing developing them afterwards. To avoid the failure of the reactive design, i.e. sticking to a bad design decision for too long, make smaller stepping stones and try to get feedback and real, hard data as soon as possible and act based on them.<br><br>BTW, Kent calls this method \"<a href=\"https://www.google.com/search?q=responsive+design+kent+beck\">responsive design</a>,\" if you want to find out more about it. You may want to check out first of all this <a href=\"http://www.infoq.com/presentations/responsive-design\">Kent's presentation</a> and perhaps also these <a href=\"http://www.slideshare.net/stonemankim/responsive-design-one-day\">detailed slides</a> and a blog <a href=\"http://www.carlopescio.com/2010/07/on-kent-becks-responsive-design.html\">post by Carlo Pescio with many valuable links</a>.\r\n<h2>Related</h2>\r\n<ul>\r\n\t<li>Kent's talk on  <a title=\"Responsive Design\" href=\"http://www.infoq.com/presentations/responsive-design\">Responsive Design</a> (<a href=\"http://www.slideshare.net/deimos/kent-beck-effective-design\">slides</a>).</li>\r\n\t<li><a href=\"http://matteo.vaccari.name/blog/archives/777\">About Kent Beck’s Stepping Stone strategy</a> by Matteo Vaccari - the two types of them, examples (I feel though that the idea of the simplification strategy could be slightly broader)</li>\r\n\t<li>Kent's post on <a href=\"http://www.threeriversinstitute.org/blog/?p=104\">Coupling and Cohesion</a> and their cost and too small x too large elements and potential x effective coupling</li>\r\n</ul>\r\n<p style=\"text-align:right;\"><em>Reposted from <a href=\"http://blog.iterate.no/2012/03/12/kent-beck-best-practices-for-software-design-with-low-feature-latency-and-high-throughput/\">blog.iterate.no</a>.</em></p>",
  "excerpt": ""
 },
 {
  "title": "Most interesting links of Mars ''12",
  "published": "2012-03-31 21:59:57",
  "postType": "post",
  "slug": "/2012/03/31/most-interesting-links-of-mars-12/",
  "status": "publish",
  "tags": [
   "agile",
   "cloud",
   "design",
   "management",
   "Testing",
   "trends"
  ],
  "categories": [
   "General",
   "Testing",
   "Top links of month"
  ],
  "content": "<h2>Recommended Readings</h2>\r\n<ul>\r\n\t<li><a href=\"http://thoughtworks.fileburst.com/assets/thoughtworks-tech-radar-march-2012-us-color.pdf\">ThoughtWorks Technology Radar 3/2012</a> - including apps with embedded servlet containers (assess), health check pages for webapp monitoring, <a href=\"/2012/01/18/how-to-create-maintainable-acceptance-tests/\">testing at the appropriate level</a> (adopt), JavaScript micro-framewors (trial, see <a href=\"http://Microjs.com/\">Microjs.com</a>), Gradle over Maven (e.g. thanks to flexibility), <a href=\"http://opensocial.org/\">OpenSocial</a> for data &amp; content sharing between (enterprise) apps (assess), Clojure (before in asses) and CoffeeScript on trial (Scala very close to adopt), JavaScript as a 1st class language (adopt), single-threaded servers with aync I/O (Node.js, <a href=\"https://github.com/webbit/webbit\">Webbit</a> for Java [http/websocket], ...; assess).</li>\r\n\t<li>Jez Humble: <a href=\"http://www.informit.com/articles/article.aspx?p=1833567\">Four Principles of Low-Risk Software Releases</a> - how to make your releases safer by making them incremental (versioned artifacts instead of overwritting, expand &amp; contract DB scripts, versioned APIs, releasing to a subset of customers first), separating software deployment from releasing it so that end-users can use it (=&gt; you can do smoke tests, canary releasing, dark launching [feature in place but not visible to users, already doing something]; includes feature toggles [toggle on only for somebody, switch off new buggy feature, ...]), delivering features in smaller batches (=&gt; more frequently, smaller risk of any individual release thanks to less stuff and easier roll-back/forward), and optimizing for resiliance (=&gt; ability to provision a running production system to a known good state in predictable time - crucial when stuff fails).</li>\r\n\t<li><a href=\"http://blog.incubaid.com/2012/03/28/the-game-of-distributed-systems-programming-which-level-are-you/\">The Game of Distributed Systems Programming. Which Level Are You?</a> (via Kent Beck) - we start with a naive approach to distributed systems, treating them as just a little different local systems, then (painfully) come to understand the <a href=\"http://en.wikipedia.org/wiki/Fallacies_of_Distributed_Computing\">fallacies of distributed programming</a> and start to program explicitely for the distributed environment leveraging asynchronous messaging and (often functional) languages with good support for concurrency and distribution. We suffer by random, subtle, non-deterministic defects and try to separate and restrict non-determinism by becoming purely functional ... . Much recommended to anybody dealing with distributed systems (i.e. everybody, nowadays). The discussion is worth reading as well.</li>\r\n\t<li><a href=\"http://rgordon.co.uk/blog/2012/03/05/shapes-dont-draw/#.T2oidI2SwnE.dzone\">Shapes Don’t Draw</a> - thought-provoking criticism of inappropriate use of OOP, which leads to bad and inflexible code. Simplification is OK as long as the domain is equally simple - but in the real world shapes do not draw themselves. (And Trades don't decide their price and certainly shouldn't reference services and a database.)</li>\r\n\t<li><a href=\"http://www.grisha.ru/cmm/cimm.htm\">Capability Im-Maturity Model</a> (via Markus Krüger) - everybody knows CMMI, but it’s useful to know also the negative directions an organization can develop in. Defined by Capt. Tom Schorsch in 1996, building on Anthony Finkelstein's paper <a href=\"http://www.cs.ucl.ac.uk/staff/A.Finkelstein/papers/immaturity.pdf\">A Software Process Immaturity Model</a>.</li>\r\n\t<li>Cynefin: <a href=\"http://hbr.org/2007/11/a-leaders-framework-for-decision-making/ar/1\">A Leader’s Framework for Decision Making</a> - an introduction into the <a href=\"http://en.wikipedia.org/wiki/Cynefin\">Cynefin cognitive framework</a> - the key point is that we encounter 5 types of contexts differing by the predictability of effects and each of them requires a different management style, using the wrong one is a recipe for a disaster. Quote:\r\n<blockquote>The framework sorts the issues facing leaders into five contexts defined by the nature of the relationship between cause and effect. Four of these—simple, complicated, complex, and chaotic—require leaders to diagnose situations and to act in contextually appropriate ways. The fifth—disorder—applies when it is unclear which of the other four contexts is predominant.</blockquote>\r\n</li>\r\n\t<li><a href=\"http://scrummaster.no/?p=571\">Et spørsmål om kompleksitet</a> (Norwegian). Key ideas mixed with my own: Command &amp; control management in the traditional Ford way works very well - but only in stable domains with clear cause-and-effect relationships (i.e. the Simple context of Cynefin). But many tasks today have lot of uncertanity and complexity and deal with creating new, never before seen things. We try to lead projects as if they were automobile factories while often they are more like research - and researchers cannot plan when they will make a breakthrough. Most of the new development of IT systems falls into the Complex context of Cynefin - there is lot of uncertanity, no clear answers, we cannot forsee problems, and have to base our progress on empirical experience and leverage <a href=\"http://en.wikipedia.org/wiki/Emergence\">emergence</a> (emergent design, ..).</li>\r\n\t<li><a href=\"http://blogs.captechconsulting.com/blog/chris-wash/the-economics-developer-testing\">The Economics of Developer Testing</a> - a very interesting reflection on the cost and value of testing and what is enough tests. Tests cost to develop and maintain (and different tests cost differently, the more complex the more expensive). Not having tests costs too - usually quite a lot. To find the right ballance between tests and code and different types of tests we must be aware of their cost and benefits, both short &amp; long term. Worth reading, good links. (Note: We often tend to underestimate the cost of not having good tests. Much more then you might think.)</li>\r\n</ul>\r\n<h2>Links to Keep</h2>\r\n<ul>\r\n\t<li><a href=\"http://www.lukew.com/ff/entry.asp?1514\">Proved Patterns for Creating Responsive Web UIs</a> (adapting to the user device size - PC, mobile, ..): Mostly Fluid (fluid grids, down-scaling images,decreasing margins and eventually stacking columns below each other on smaller screens), Column Drop, Layout Shifter (diff. layout for large/medium/small screens), ... .</li>\r\n\t<li><a href=\"http://h30565.www3.hp.com/t5/Feature-Articles/16-Linux-Server-Monitoring-Commands-You-Really-Need-To-Know/ba-p/1936\">16 Linux Server Monitoring Commands You Really Need To Know</a> - some elementary such as top, iostat, and netstat and some more dashboard-like such as <a href=\"http://nmon.sourceforge.net/pmwiki.php\" rel=\"nofollow\" target=\"_blank\">nmon</a> (Nigel's Monitor) and the stats collecting <a href=\"http://www.thegeekstuff.com/2011/03/sar-exampl\" rel=\"nofollow\" target=\"_blank\">sar</a>.</li>\r\n</ul>\r\n<h2>Quotes</h2>\r\nKent Beck answering a <a href=\"http://stackoverflow.com/a/153565\">question about how much testing to do</a> (highlighted by me):\r\n<blockquote><strong>I get paid for code that works, not for tests, so my philosophy is to test as little as possible to reach a given level of confidence</strong> (I suspect <strong>this level of confidence is high compared to industry standards</strong>, but that could just be hubris). If I don't typically make a kind of mistake (like setting the wrong variables in a constructor), I don't test for it. I do tend to make sense of test errors, so I'm extra careful when I have logic with complicated conditionals. When coding on a team, I modify my strategy to carefully test code that we, collectively, tend to get wrong.<br><br>Different people will have different testing strategies based on this philosophy, but that seems reasonable to me given the immature state of understanding of how tests can best fit into the inner loop of coding. Ten or twenty years from now we'll likely have a more universal theory of which tests to write, which tests not to write, and how to tell the difference. In the meantime, experimentation seems in order.</blockquote>\r\n",
  "excerpt": ""
 },
 {
  "title": "Exposing Functionality Over HTTP with Groovy and Ultra-Lightweight HTTP Servers",
  "published": "2012-04-04 12:43:15",
  "postType": "post",
  "slug": "/2012/04/04/exposing-functionality-over-http-with-groovy-and-ultra-lightweight-http-servers/",
  "status": "publish",
  "tags": [
   "groovy",
   "java",
   "REST",
   "webapp"
  ],
  "categories": [
   "j2ee",
   "Languages"
  ],
  "content": "I needed a quick and simple way to enable some users to query a table and figured out that the easiest solution was to use an embedded, ligthweight HTTP server so that the users could type a URL in their browser and get the results. The question was, of course, which server is best for it. I'd like to summarize here the options I've discovered - including Gretty, Jetty, Restlet, Jersey and others - and their pros &amp; cons together with complete examples for most of them. I've on purpose avoided various frameworks that might support this easily such as Grails because it didn't feel really lightweight and I needed only a very simple, temporary application.<br><br>I used Groovy for its high productivity, especially regarding JDBC - with GSQL I needed only two lines to get the data from a DB in a user-friendly format.<br><br>My ideal solution would make it possible to start the server with support for HTTPS and authorization and declare handlers for URLs programatically, in a single file (Groovy script), in just few lines of code. (Very similar to the Gretty solution below + the security stuff.)<br><br><!--more-->\r\n<h2>Side Notes</h2>\r\n<h3>Note on Grape</h3>\r\n<a href=\"http://groovy.codehaus.org/Grape\">Grape</a>, the Groovy packaging engine, makes it possible to download dependencies at runtime via @Grab annotations. If you run your groovy script f.ex. via &lt;your groovy 1.8 installation&gt;/bin/groovy then it will just work because Groovy is distributed together with Ivy, which is required for Grape to work. (If using IntelliJ then add ivy.jar manually to the project's classpath and then invoke intention action (Mac: Alt+Enter) on the @Grab annotation to download it and add it to the classpath.)\r\n \r\n<h3>Note on HTTPS/SSL Configuration</h3>\r\nTo enable HTTPS, you will need to create a keystore with a key pair, which is <a href=\"http://docs.codehaus.org/display/JETTY/How+to+configure+SSL#HowtoconfigureSSL-step1\">well described in the documentation of Jetty</a> (step 1a).<br><br>For the impatient:\r\n<ul>\r\n\t<li>Run<pre><code>keytool -keystore $HOME/.keystore -alias myGroovyServer -genkey -keyalg RSA</code></pre></li>\r\n\t<li>When asked \"What is your first and last name?\", provide the hostname where the service will be running, e.g. \"localhost\" or \"myserver.example.com\"</li>\r\n\t<li>Specify the same password for the keystore and the generated key (e.g. \"myKeystorePsw\")</li>\r\n\t<li>When running the server, supply the (absolute) path to the generated file <var>.keystore</var> (in a server-specific way) and set the system property <var>javax.net.ssl.keyStorePassword</var> to the password</li>\r\n</ul>\r\n<h2>1. Simple HTTP Request and Response Solutions</h2>\r\n<h3>Attempt 1: Gretty</h3>\r\n<a href=\"https://github.com/groovypp/gretty\">Gretty</a> is a Groovy wrapper for Netty, the asynchronous web server, and is written in Groovy++. (<a href=\"http://groovy.dzone.com/articles/groovy-action\">Intro article for Gretty</a>.)<br><br><strong>Pros</strong>: Well integrated with Groovy, simple to get started with, supports serving static resources and more, Netty is cool.<br><br><strong>Cons</strong>: Undocumented, the project seems to be dormant, no clear way to add user authorization and HTTPS.<br><br>The code:<br><br><pre><code>\r\n@GrabConfig(systemClassLoader=true)\r\n@GrabResolver(name='gretty', root='http://groovypp.artifactoryonline.com/groovypp/libs-releases-local')\r\n@Grapes([\r\n    @Grab('org.mbte.groovypp:gretty:0.4.279'),\r\n    @Grab('mysql:mysql-connector-java:5.1.16')])<br><br>import org.mbte.gretty.httpserver.*\r\nimport groovy.sql.Sql<br><br>class Main {<br><br>    final def db = [url: 'jdbc:mysql://localhost:3306/user', user: 'dbUser', psw: 'dbPsw' ]<br><br>    def run() {\r\n        startServer()\r\n    }<br><br>    def getUser(def code) {\r\n        println &quot;Connecting to the DB to check '$code'...&quot;\r\n        def sql = Sql.newInstance( db.url, db.user, db.psw)\r\n        return sql.firstRow(&quot;select * from users where code = $code&quot;) ?: &quot;No such code found&quot;\r\n    }<br><br>    def startServer() {\r\n        GrettyServer server = []\r\n        server.groovy = [\r\n                localAddress: new InetSocketAddress(6789), // no host =&gt; all\r\n                defaultHandler: {\r\n                    response.redirect &quot;/&quot;\r\n                },\r\n                &quot;/:code&quot;: {\r\n                    get {\r\n                        def user = getUser(it.code)\r\n                        response.text = &quot;The code '${it.code}' refers to $user\\n&quot;\r\n                        // =&gt; st. like: &quot;The code 'abc' refers to [id:123, name:me@somewhere.no, code:abc]&quot;\r\n                    }\r\n                }\r\n        ]\r\n        server.start()\r\n        println &quot;Groovy server is ready to serve&quot;\r\n    }\r\n}<br><br>new Main().run()\r\n</code></pre><br><br><h3>Jetty</h3>\r\n<strong>Pros</strong>: Mature, powerful, often used in the embedded form, supports <a href=\"http://docs.codehaus.org/display/JETTY/How+to+configure+SSL\">HTTPS</a> and <a href=\"http://docs.codehaus.org/display/JETTY/How+to+Configure+Security+with+Embedded+Jetty\">authorization (also programatically)</a>.<br><br><strong>Pitfall</strong>: You cannot use org.eclipse.jetty:jetty-server because Grape.grab will fail to download the dependency <var>org.eclipse.jetty.orbit:javax.servlet</var> <a href=\"https://jira.codehaus.org/browse/JETTY-1493\">due to Ivy getting confused</a> by packaging vs. extension. Use <var>org.eclipse.jetty.<strong>aggregate</strong>:jetty-server</var> instead (the <a href=\"http://wiki.eclipse.org/Jetty/Reference/Dependencies#Aggregate_JARs\">Jetty aggregate packages</a> merge multiple smaller JARs).<br><br><h4>Example: Jetty with Security</h4> <br><br>(based on the articles about <a href=\"http://wiki.eclipse.org/Jetty/Tutorial/Embedding_Jetty\">Embedding Jetty</a> (including SSL) for programatic configuration and handling requests via a custom handler or servlet (very well written indeed) and <a href=\"http://docs.codehaus.org/display/JETTY/How+to+Configure+Security+with+Embedded+Jetty#HowtoConfigureSecuritywithEmbeddedJetty-Programmaticsecurityconstraintsnowebxml\">How to Configure Security with Embedded Jetty</a> for programatic configuration of authentication and authorization)<br><br><pre><code>\r\nimport groovy.sql.Sql\r\nimport javax.servlet.*\r\nimport javax.servlet.http.*\r\nimport org.eclipse.jetty.server.*\r\nimport org.eclipse.jetty.server.ssl.SslSelectChannelConnector\r\nimport org.eclipse.jetty.servlet.*\r\nimport org.eclipse.jetty.security.*\r\nimport org.eclipse.jetty.util.security.*<br><br>@GrabConfig(systemClassLoader = true)\r\n@Grapes([\r\n    @Grab('org.eclipse.jetty.aggregate:jetty-server:8.1.2.v20120308'),\r\n    @Grab('org.eclipse.jetty.aggregate:jetty-servlet:8.1.2.v20120308'),\r\n    @Grab(group='javax.servlet', module='javax.servlet-api', version='3.0.1'),\r\n    @Grab('mysql:mysql-connector-java:5.1.16')])\r\nclass Main extends HttpServlet {<br><br>    final def db = [url: 'jdbc:mysql://localhost:3306/user', user: 'dbUser', psw: 'dbPsw' ]<br><br>    protected void doGet(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException {\r\n        final String code = request.pathInfo.substring(1); // skip leading '/'\r\n        response.setContentType(&quot;text/plain&quot;);<br><br>        try {\r\n            def user = getUser(code)\r\n            response.setStatus(HttpServletResponse.SC_OK);\r\n            response.getWriter().println(&quot;Usage of the code '${code}': $user\\n&quot;)\r\n        } catch (Exception e) {\r\n            response.setStatus(HttpServletResponse.SC_INTERNAL_SERVER_ERROR)\r\n            response.getWriter().println(&quot;Connection to the database failed. This may be due to temporary &quot; +\r\n                    &quot;connection problems or due to misconfiguration. Try later.&quot;)\r\n        }\r\n    }<br><br>    def getUser(def code) {\r\n        println &quot;Connecting to the DB to check '$code'...&quot;\r\n        def sql = Sql.newInstance( db.url, db.user, db.psw)\r\n        return sql.firstRow(&quot;select * from users where code = $code&quot;) ?: &quot;No such code found&quot;\r\n    }<br><br>    public static startServer() {\r\n        Server server = new Server();\r\n        server.setHandler(createServletHandlerWithAuthentication(\r\n                &quot;/&quot;, new Main(), createAuthenticationConstraint()))\r\n        server.setConnectors((Connector[])[createSslConnector()])\r\n        server.start();\r\n        server.join();\r\n    }<br><br>    /** Wrap the servlet in the servlet handler and configure it to run at the given URL, setting its security handler. */\r\n    private static createServletHandlerWithAuthentication(String contextPath, Servlet servlet, SecurityHandler securityHandler) {\r\n        final String pathSpec = &quot;/*&quot;\r\n        ServletContextHandler servletHandler = new ServletContextHandler(ServletContextHandler.NO_SESSIONS)\r\n        servletHandler.setContextPath(contextPath)\r\n        servletHandler.setSecurityHandler(securityHandler)\r\n        servletHandler.addServlet(new ServletHolder(servlet), pathSpec)\r\n        return servletHandler\r\n    }<br><br>    /** Create HTTPS connector running at port 6789 and using key pair from the hard-coded keystore. */\r\n    private static Connector createSslConnector() {\r\n        SslSelectChannelConnector ssl_connector = new SslSelectChannelConnector()\r\n        ssl_connector.setPort(6789)<br><br>        def cf = ssl_connector.getSslContextFactory()\r\n        cf.setKeyStore(System.getProperty(&quot;user.home&quot;) + &quot;/.keystore&quot;)\r\n        cf.setKeyStorePassword(&quot;myKeystorePsw&quot;)\r\n        cf.setKeyManagerPassword(&quot;myKeystorePsw&quot;)<br><br>        return ssl_connector\r\n    }<br><br>    /** Create a security handler requiring authentication with username/password. */\r\n    private static SecurityHandler createAuthenticationConstraint() {\r\n        Constraint constraint = new Constraint();\r\n        constraint.setName(Constraint.__BASIC_AUTH);\r\n        constraint.setRoles((String[])[&quot;user&quot;]);\r\n        constraint.setAuthenticate(true);<br><br>        ConstraintMapping cm = new ConstraintMapping();\r\n        cm.setConstraint(constraint);\r\n        cm.setPathSpec(&quot;/*&quot;); // auth. required for any URL<br><br>        def loginSrv = new HashLoginService()\r\n        loginSrv.putUser(&quot;myLogin&quot;, new Password(&quot;myPassword&quot;), (String[])[&quot;user&quot;])\r\n        loginSrv.setName(&quot;My App Realm&quot;)<br><br>        SecurityHandler sh = new ConstraintSecurityHandler()\r\n        sh.setLoginService(loginSrv)\r\n        sh.setConstraintMappings((ConstraintMapping[])[cm]);<br><br>        return sh\r\n    }\r\n}<br><br>Main.startServer()\r\n</code></pre><br><br>Additional resources:\r\n<ul>\r\n\t<li>Post: <a href=\"http://mrhaki.blogspot.com/2009/10/groovy-goodness-groovlets-as.html\">Embedded Groovy executing Groovlets</a> (Groovy scripts with access to request/response and support for generating HTML)</li>\r\n\t<li>Post: A <a href=\"http://www.joergm.com/2009/12/scripting-magic-with-groovy-grape-and-jetty/\">Groovy+Jetty blog featuring support for command-line arguments, @Grab</a>, and serving of static resources</li>\r\n\t<li>Post: <a href=\"http://actionsresults.com/blog/2009/10/24/embedded-jetty-ssl-https/\">Enabling HTTPS for an Embedded Jetty</a></li>\r\n</ul>\r\n<h3>Winstone</h3>\r\n<a href=\"http://winstone.sourceforge.net/\">Winstone</a> is a 200KB servlet container <a href=\"http://search.maven.org/#search|ga|1|winstone\">available via Maven</a>, last release 2008. It seems to be focused on serving WARs.\r\n<h3>Sun Java 6 HttpServer</h3>\r\n<a href=\"https://blogs.oracle.com/michaelmcm/entry/http_server_api_in_java\">Sun JRE 6+ contains a ligthweight, programmatically controled HTTP server</a>, supporting also HTTPS. <a href=\"http://alistairisrael.wordpress.com/2009/09/02/functional-http-testing-with-sun-java-6-httpserver/\">Example code</a>.\r\n<h2>2. REST-based Solutions</h2><br><br><h3>Jersey JAX-RS</h3>\r\nJersey, the reference implementation of JAX-RS (aka REST), can run on an embedded test server such as Grizzly, GlassFish, or Jetty.<br><br><strong>Pros</strong>: The reference implementation of JAX-RS, i.e. standard.<br><br><strong>Cons</strong>: <a href=\"/2012/01/31/troubleshooting-jersey-rest-server-and-client/\">Troubleshooting Jersey</a> isn't as easy as I'd like it to be. The documentation should be better (compare to Jetty's), this is really a weak point (try to find anything about securing Jersey with an embedded Grizzly).<br><br><h4>Example: Jersey with embedded Grizzly, without security</h4><br><br>(If interested in security and authentication, check out the sample project <a href=\"https://maven.java.net/content/repositories/releases/com/sun/jersey/samples/https-clientserver-grizzly/1.12/https-clientserver-grizzly-1.12-project.zip\">https-clientserver-grizzly</a>. It seems little to complex to me.)<br><br><pre><code>\r\nimport groovy.sql.Sql<br><br>import javax.ws.rs.*\r\nimport javax.ws.rs.core.*\r\nimport com.sun.jersey.api.core.*\r\nimport com.sun.jersey.api.container.grizzly2.GrizzlyServerFactory\r\nimport org.glassfish.grizzly.http.server.HttpServer<br><br>@GrabConfig(systemClassLoader = true)\r\n@GrabResolver(name = 'gretty', root = 'http://groovypp.artifactoryonline.com/groovypp/libs-releases-local')\r\n@Grapes([\r\n    @Grab('com.sun.jersey:jersey-server:1.12'),\r\n    @Grab('com.sun.jersey:jersey-core:1.12'),\r\n    @Grab(group='com.sun.jersey', module='jersey-grizzly2', version='1.12'),\r\n    @Grab(group='javax.ws.rs', module='jsr311-api', version='1.1.1'),\r\n    @Grab('mysql:mysql-connector-java:5.1.16')])<br><br>@Path(&quot;/{code}&quot;)\r\nclass Main {<br><br>    final def db = [url: 'jdbc:mysql://localhost:3306/user', user: 'dbUser', psw: 'dbPsw' ]<br><br>    @GET @Produces(&quot;text/plain&quot;)\r\n    public Response getUserByCode(@PathParam('code') String code) {\r\n        try {\r\n            def user = getUser(code)\r\n            return Response.ok().entity(&quot;Usage of the code '${code}': $user\\n&quot;.toString()).build();\r\n        } catch (Exception e) {\r\n            Response.serverError().entity(&quot;Connection to the database failed. This may be due to temporary &quot; +\r\n                    &quot;connection problems or due to misconfiguration. Try later. Cause: $e&quot;.toString()).build();\r\n        }\r\n    }<br><br>    def getUser(def code) {\r\n        println &quot;Connecting to the DB to check '$code'...&quot;\r\n        def sql = Sql.newInstance( db.url, db.user, db.psw)\r\n        return sql.firstRow(&quot;select * from users where code = $code&quot;) ?: &quot;No such code found&quot;\r\n    }<br><br>    public static startServer() {\r\n        ResourceConfig resources = new ClassNamesResourceConfig(Main)\r\n        def uri = UriBuilder.fromUri(&quot;http://localhost/&quot;).port(6789).build();\r\n        HttpServer httpServer = GrizzlyServerFactory.createHttpServer(uri, resources);\r\n        println(&quot;Jersey app started with WADL available at ${uri}application.wadl&quot;)\r\n        System.in.read();\r\n        httpServer.stop();\r\n    }\r\n}<br><br>Main.startServer()\r\n</code></pre><br><br>\r\n<h3>RESTEasy with an Embedded TJWS (Tiny Java Web Server and Servlet Container)</h3>\r\nTJWS is trully miniature, 100KB footprint, runs also on Android, about 5 times smaller than the competitors <a href=\"http://www.gefionsoftware.com/\" target=\"_blank\">LWS</a> and <a href=\"http://jetty.mortbay.org/jetty/index.html\" target=\"_blank\">Jetty</a>.<br><br>From the RESTEasy documentation:<br><br><pre><code>\r\n@Path(&quot;&quot;)\r\npublic class MyResource {<br><br>   @GET public String get() { return &quot;hello world&quot;; }<br><br>   public static void main(String[] args) throws Exception  {\r\n      TJWSEmbeddedJaxrsServer tjws = new TJWSEmbeddedJaxrsServer();\r\n      tjws.setPort(8081);\r\n      tjws.getRegistry().addPerRequestResource(MyResource.class);\r\n      tjws.start();\r\n   }\r\n}\r\n</code></pre><br><br><a href=\"http://tjws.sourceforge.net/#security\">TJWS itself supports SSL</a>, I'm not sure about the JBoss TJWS plugin for RESTEasy (which is the only version of tjws availabe in Maven). It <a href=\"http://tjws.sourceforge.net/#embedded\">can be also embedded</a> but isn't available via Maven and I don't know if it supports mapping of requests to code (instead of WARs and JSPs).\r\n<h3>Restlet with an Embedded Server</h3>\r\nSee the article <a href=\"http://blog.arc90.com/2008/06/04/building-restful-web-apps-with-groovy-and-restlet-part-1-up-and-running/\">Building RESTful Web Apps with Groovy and Restlet, Part 1: Up and Running</a> (2008). As Restlet is available in Maven, we could just @Grab the dependencies.<br><br>What is even more interesting is the <a href=\"http://docs.codehaus.org/display/GROOVY/GroovyRestlet\">GroovyRestlet module that let you configure authorization and request handling programatically</a>, with only few lines. (You can <a href=\"http://www.restlet.org/documentation/1.1/tutorial#part11\">do this also in Java</a>, with some more LoC.)<br><br>Doc for the release 2.1: <a href=\"http://wiki.restlet.org/docs_2.1/13-restlet/27-restlet/46-restlet.html\">How to implement authorization and HTTPS</a>, <a href=\"http://wiki.restlet.org/docs_2.1/13-restlet/21-restlet/318-restlet/319-restlet.html\">the simplest possible REST server</a> in ~ 6 lines of Java.<br><br>(Notice that Restlet comes with a simple HTTP server but can also use Jetty or Grizzly.)<br><br><strong>Pros</strong>: RESt (though non-standard), good integration with Groovy (though it might be outdated)<br><br><strong>Cons</strong>: As of 4/2012 Restlet is only in its private Maven repository though they're <a href=\"https://github.com/restlet/restlet-framework-java/issues/481\">going to be in Maven Central</a> too, JAX-RS support <a href=\"http://wiki.restlet.org/docs_2.1/13-restlet/28-restlet/57-restlet.html\">isn't fully implemented</a> yet (Restlet 2.1-RC3). The documentation could be better (more comprehensive, more interlinked, more varied examples). To use HTTPS you must choose some other server than the internal one.\r\n<h4>Example: Restlet + SimpleFramework Server + HTTPS and Authentication (w/o Groovy integration)</h4>\r\n<pre><code>\r\nimport groovy.sql.Sql\r\nimport org.restlet.*\r\nimport org.restlet.data.*\r\nimport org.restlet.resource.*\r\nimport org.restlet.security.*<br><br>@GrabConfig(systemClassLoader = true)\r\n@GrabResolver(name = 'gretty', root = 'http://groovypp.artifactoryonline.com/groovypp/libs-releases-local')\r\n@GrabResolver(name = 'restlet', root = 'http://maven.restlet.org')\r\n@Grapes([\r\n   @Grab('org.restlet.jse:org.restlet:2.1-RC3'),\r\n   @Grab('org.restlet.jse:org.restlet.ext.simple:2.1-RC3'),\r\n   @Grab('mysql:mysql-connector-java:5.1.16')])\r\nclass Main extends ServerResource {<br><br>    final def db = [url: 'jdbc:mysql://localhost:3306/user', user: 'dbUser', psw: 'dbPsw' ]<br><br>    @Get public String getUser() {\r\n        def code = getRequestAttributes().get(&quot;code&quot;)\r\n        def user = getUser(code)\r\n        return &quot;Usage of the code '${code}': $user\\n&quot;\r\n    }<br><br>    def getUser(def code) {<br><br>        println &quot;Connecting to the DB to check '$code'...&quot;\r\n        def sql = Sql.newInstance( db.url, db.user, db.psw)\r\n        return sql.firstRow(&quot;select * from users where code = $code&quot;) ?: &quot;No such code found&quot;\r\n    }<br><br>    public static startServer() {\r\n        Component component = new Component();\r\n        def userResourceFinder = component.getDefaultHost().createFinder(Main.class);\r\n        component.getDefaultHost().attach(&quot;/{code}&quot;\r\n                , wrapResourceInAuthenticationCheck(component.getContext(), userResourceFinder));\r\n        configureHttpsServer(component, 6789)\r\n        component.start()\r\n    }<br><br>    /**\r\n     * Add a Guard (a filter) that asks the user for username/password and checks it against a map.\r\n     */\r\n    private static Restlet wrapResourceInAuthenticationCheck(Context context, Restlet resource) {\r\n        MapVerifier verifier = new MapVerifier();\r\n        verifier.getLocalSecrets().put(&quot;myLogin&quot;, &quot;myPassword&quot;.toCharArray());<br><br>        ChallengeAuthenticator guard = new ChallengeAuthenticator(context.createChildContext(), ChallengeScheme.HTTP_BASIC, &quot;My App&quot;);\r\n        guard.setVerifier(verifier);\r\n        guard.setNext(resource);<br><br>        return guard;\r\n    }<br><br>    /**\r\n     * Create the server, instruct it to use a SslContextFactory, and configure the factory with\r\n     * our keystore and password. I guess that which server to use is determined by Restlet based on which\r\n     * package (*.ext.simple.*, *.ext.jetty.* etc.) is available.\r\n     */\r\n    private static void configureHttpsServer(Component component, int port) {\r\n        def secureServer = component.getServers().add(Protocol.HTTPS, port);<br><br>        // See http://www.restlet.org/documentation/2.1/jse/ext/org/restlet/ext/ssl/DefaultSslContextFactory.html\r\n        // for params such as keystore path and password\r\n        System.setProperty(&quot;javax.net.ssl.keyStorePassword&quot;, &quot;myKeystorePsw&quot;) // used for keystorePassword &amp; keyPassword\r\n        def confg = secureServer.getContext().getParameters()\r\n        confg.add(&quot;sslContextFactory&quot;, &quot;org.restlet.ext.ssl.DefaultSslContextFactory&quot;)\r\n        // Beware: keystorePath shall default to ${user.home}/.keystore but doesn't seem to do so =&gt; set it explicitly\r\n        confg.add(&quot;keystorePath&quot;, &quot;${System.getProperty('user.home')}/.keystore&quot;)\r\n    }\r\n}<br><br>Main.startServer()\r\n</code></pre><br><br><h2>Conclusion</h2>\r\nI'd perhaps use either Jetty if REST isn't needed and Jersey+Jetty otherwise (I'd certainly pick Jetty over Grizzly as the documentation is much better). Restlet might be interesting too provided that the Groovy integration works and if you don't mind using a non-standard REST implementation.<br><br>Looking at the length of the code samples it might have been better to try Grails or st. similar after all :-)",
  "excerpt": ""
 },
 {
  "title": "Groovy Grape: Troubleshooting Failed Download",
  "published": "2012-04-02 20:36:42",
  "postType": "post",
  "slug": "/2012/04/02/groovy-grape-troubleshooting-failed-download/",
  "status": "publish",
  "tags": [
   "groovy",
   "java"
  ],
  "categories": [
   "General",
   "Languages"
  ],
  "content": "If you use the Grape's <a href=\"http://groovy.codehaus.org/Grape\">@Grab</a> annotation to get dependencies for your Groovy scripts at runtime and their retrieval fails with the exception \"General error during conversion: Error grabbing Grapes -- [unresolved dependency: ...not found]\" and a useless stack trace then you migth want to know that you can configure Ivy to log all the details of what is going on (what it is trying to download, where from, ...), for example in the interactive <em>groovysh</em> shell:<br><br><pre><code>\r\ngroovy:000&gt; org.apache.ivy.util.Message.setDefaultLogger(new org.apache.ivy.util.DefaultMessageLogger(org.apache.ivy.util.Message.MSG_DEBUG))\r\ngroovy:000&gt; groovy.grape.Grape.grab(autoDownload: true, group: 'org.eclipse.jetty.orbit', module: 'javax.servlet', version: '3.0.0.v201112011016')\r\n...\r\nWARN: ==== ibiblio: tried\r\nWARN:   http://repo1.maven.org/maven2/org/eclipse/jetty/orbit/javax.servlet/3.0.0.v201112011016/javax.servlet-3.0.0.v201112011016.orbi\r\n...\r\n</code></pre><br><br>You can likely also increase the log level by setting the system property <em>ivy.message.logger.level</em> to 4 (debug, see the Ivy <a href=\"http://grepcode.com/file/repository.springsource.com/org.apache.ant/com.springsource.org.apache.ivy/2.1.0/org/apache/ivy/util/Message.java\">Message</a> class.)<br><br>(<del>For the list of arguments that grab supports see <a href=\"https://github.com/groovy/groovy-core/blob/GROOVY_1_8_X/src/main/groovy/grape/GrapeIvy.groovy\">GrapeIvy</a>, namely the method <em>createGrabRecord</em> [btw, <a href=\"http://jira.codehaus.org/browse/GROOVY-5395\">ext and type are ignored</a> unless you also set classifier]</del> <em>this has been fixed</em>)",
  "excerpt": ""
 },
 {
  "title": "Most interesting links of April ''12",
  "published": "2012-04-30 21:59:23",
  "postType": "post",
  "slug": "/2012/04/30/most-interesting-links-of-april-12/",
  "status": "publish",
  "tags": [
   "agile",
   "bigdata",
   "nosql",
   "Testing"
  ],
  "categories": [
   "Databases",
   "General",
   "Testing",
   "Tools",
   "Top links of month"
  ],
  "content": "<h2>Recommended Readings</h2>\r\n<ul>\r\n\t<li>V. Duarte: <a href=\"http://softwaredevelopmenttoday.blogspot.com/2012/01/story-points-considered-harmful-or-why.html\">Story Points Considered Harmful - Or why the future of estimation is really in our past...</a> (<a href=\"http://www.youtube.com/watch?v=2PyZu1qHy_o\">also as 1h video</a>) - thoughtful and data-backed claim that there is a much cheaper way for estimating work throughput than estimating each story in story points (SP) and that is simply counting the stories. Even though their sizes differ, over (not that much) longer periods, where it really matters, these differences will even out. The author argues that estimating in number of stories provides the same reliability and benefits as SP and is much easier. (Keep in mind that estimation is just an attempt at predicting the future and humans are proved to be terrible at doing that; why to pretend that we can do it?) I'd recommand this to anybody doing Scrum and similar.</li>\r\n\t<li>M. Fowler: <a href=\"http://martinfowler.com/bliki/TestCoverage.html\">Test Coverage</a> - it's obvious that increasing test coverage for the sake of test coverage it's a nonsense but some people still need to be reminded of it :-). Fowler explains what the real benefit of test coverage measurements is and how to use it for good instead of for evil.</li>\r\n\t<li>Brian Marick: <a href=\"http://www.exampler.com/testing-com/writings/coverage.pdf\">How to Misuse Code Coverage</a> (pdf) - cited a lot by Fowler in his article, this is really a good paper. Marick has participated in the development of several code coverage tools and understands well their limitations. One of the key points is that code coverage tools can discover only one class of test weakness (not testing some paths through your code) but cannot discover that you are missing some code you should have (e.g. when you check only for two of three possible return values). Thus the code coverage metric tells you \"this code isn't well tested, are you sure you don't to look more into it\"? It's crucial not to write tests so as to increase the code coverage; look at the code and improve the test without any regard for coverage. You may thus decrease the likeliness of both the class of problems.</li>\r\n\t<li><a href=\"http://blog.engineering.kiip.me/post/20988881092/a-year-with-mongodb\">A Year with MongoDB</a> - Kiip has found out that Mongo isn't the best choice for them (having 240GB, 500+ operations/s, 85M docs and their specific usage of the store) and migrated to the combination of Riak (key-value store) and PostgreSQL. Some of the issues they hit are slow counts and limit/offset queries due to using non-counting B-trees for indexing, memory management that could be more intelligent and tuned for the use to make sure the data needed is indeed in RAM, no built-in support for compressing key names (their size adds up as they're repeated in each document; you've to compress them [user -&gt; u etc.] in the client if you want to), limited concurrency due to process-wide write lock (which becomes a problem if the write's aren't short enough w.r.t. number of ops/s, e.g. because data isn't in RAM and/or the query is complicated), safe settings (waiting for a write to finish, ...) off by default, offline-only table compaction (w/o it the disk usage grows unbounded). The lessons learnt for me: Know your storage, its weaknesses and intended way of usage, and make sure it matches your needs.</li>\r\n\t<li>Rudolf Winestock: <a href=\"http://www.winestockwebdesign.com/Essays/Lisp_Curse.html\">The Lisp Curse</a> - Lisp's expressive power is actually a cause of its lack of momentum because it's so easy to implement anything that people have no need to join forces and thus there are many half-baked (\"works-for-me\") solutions for anything - but no complete, generally accepted one. An interesting essay. \"Lisp is so powerful that problems which are technical issues in other programming languages are social issues in Lisp.\"</li>\r\n\t<li><a href=\"http://www.cubrid.org/blog/dev-platform/understanding-jdbc-internals-and-timeout-configuration/\">Understanding JDBC Internals &amp; Timeout Configuration</a> - the article itself could have been written better but it conveys the important information that configuring timeouts for JDBC isn't trivial because they need to be set correctly at different levels and without a socket timeout set in a driver-specific way it can hang forever if the DB cannot be reached due to network/system failure</li>\r\n\t<li><a href=\"http://architects.dzone.com/news/circle-through-your-google\">Circos: An Amazing Tool for Visualizing Big Data</a> - this article is interesting primarily for its combination of Google Analytics API, Neo4J and an unusual data visualization with circular graphs</li>\r\n</ul>\r\n<h2>Tools</h2>\r\n<ul>\r\n\t<li><a href=\"http://blog.julienviet.com/2012/04/23/crash-1_0-released/\">CRaSH: Extensible shell for the JVM</a> (<a href=\"http://vietj.github.com/crash/#doc\">docs</a>) - a shell that you can embedd into a web server as a WAR, run standalone or attach to a running JVM, connect to it via SSH or Telnet, and use it to execute commands against the JVM. Some commands: configure loggers, control threads, monitor the system (mem, threads, ..), connect/issue queries via JDBC. More commands can be written in Groovy. There is a whole set of commands for working with JCR. Pluggable authentication.</li>\r\n</ul>\r\n<h2>Clojure Corner</h2>\r\n<ul>\r\n\t<li><a href=\"https://github.com/clojure/clojure/blob/master/changes.md\">Clojure 1.4 Released - What's new?</a> - support for custom reader literals =&gt; literals for instants and uuid, aligned dot property access with ClojureScript, added mapv, filterv, reduce-kv</li>\r\n\t<li><a href=\"http://blog.japila.pl/2012/04/clojure-easier-sleinlein2-pomegranate-is-there-already/\">Running REPL simplified with lein2</a> (lein2 repl) - no more need for rlwrap, completion</li>\r\n</ul>\r\n<div class=\"linkscent-iconblock\" style=\"padding:0!important;margin:0!important;float:none!important;border:0 solid #ff0000!important;background:none repeat scroll center center transparent!important;width:auto!important;height:auto!important;display:block!important;overflow:visible!important;position:static!important;text-indent:0!important;z-index:auto!important;max-width:none!important;min-width:0!important;max-height:none!important;min-height:0!important;left:auto!important;top:auto!important;bottom:auto!important;right:auto!important;line-height:16px!important;white-space:nowrap!important;\"><img class=\"linkscent-icon\" style=\"padding:0!important;margin:0;float:none!important;border:0 solid #ff0000!important;width:16px!important;height:16px!important;display:none;overflow:visible!important;position:absolute!important;text-indent:0!important;z-index:2147483635!important;max-width:none!important;min-width:0!important;max-height:none!important;min-height:0!important;left:86px;top:64px;bottom:auto!important;right:auto!important;line-height:16px!important;white-space:nowrap!important;visibility:hidden;background:url('http://www.blogger.com/favicon.ico') no-repeat scroll center center transparent!important;opacity:0;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" /><img class=\"linkscent-icon\" style=\"padding:0!important;margin:0;float:none!important;border:0 solid #ff0000!important;background:url('//interclue/content/cluecore/skins/default/sprites.png') no-repeat scroll -48px -96px transparent;width:16px!important;height:16px!important;display:none;overflow:visible!important;position:absolute!important;text-indent:0!important;z-index:2147483635!important;max-width:none!important;min-width:0!important;max-height:none!important;min-height:0!important;left:104px;top:64px;bottom:auto!important;right:auto!important;line-height:16px!important;white-space:nowrap!important;visibility:hidden;opacity:0;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" width=\"16\" height=\"16\" /><img class=\"linkscent-icon\" style=\"padding:0!important;margin:0;float:none!important;border:0 solid #ff0000!important;background:none repeat scroll center center transparent;width:16px!important;height:16px!important;display:none;overflow:visible!important;position:absolute!important;text-indent:0!important;z-index:2147483635!important;max-width:none!important;min-width:0!important;max-height:none!important;min-height:0!important;left:122px;top:64px;bottom:auto!important;right:auto!important;line-height:16px!important;white-space:nowrap!important;visibility:hidden;opacity:0;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" /><img class=\"linkscent-icon\" style=\"padding:0!important;margin:0;float:none!important;border:0 solid #ff0000!important;width:16px!important;height:16px!important;display:none;overflow:visible!important;position:absolute!important;text-indent:0!important;z-index:2147483635!important;max-width:none!important;min-width:0!important;max-height:none!important;min-height:0!important;left:308px;top:140px;bottom:auto!important;right:auto!important;line-height:16px!important;white-space:nowrap!important;visibility:hidden;background:url('//interclue/content/cluecore/skins/default/linkscentExternal.png') no-repeat scroll center center transparent!important;opacity:0;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" /><img class=\"linkscent-icon\" style=\"padding:0!important;margin:0;float:none!important;border:0 solid #ff0000!important;background:url('//interclue/content/cluecore/skins/default/sprites.png') no-repeat scroll -64px -96px transparent;width:16px!important;height:16px!important;display:none;overflow:visible!important;position:absolute!important;text-indent:0!important;z-index:2147483635!important;max-width:none!important;min-width:0!important;max-height:none!important;min-height:0!important;left:326px;top:140px;bottom:auto!important;right:auto!important;line-height:16px!important;white-space:nowrap!important;visibility:hidden;opacity:0;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" width=\"16\" height=\"16\" /><img class=\"linkscent-icon\" style=\"padding:0!important;margin:0;float:none!important;border:0 solid #ff0000!important;background:none repeat scroll center center transparent;width:16px!important;height:16px!important;display:none;overflow:visible!important;position:absolute!important;text-indent:0!important;z-index:2147483635!important;max-width:none!important;min-width:0!important;max-height:none!important;min-height:0!important;left:344px;top:140px;bottom:auto!important;right:auto!important;line-height:16px!important;white-space:nowrap!important;visibility:hidden;opacity:0;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" /><img class=\"linkscent-icon\" style=\"padding:0!important;margin:0;float:none!important;border:0 solid #ff0000!important;width:16px!important;height:16px!important;display:none;overflow:visible!important;position:absolute!important;text-indent:0!important;z-index:2147483635!important;max-width:none!important;min-width:0!important;max-height:none!important;min-height:0!important;left:197px;top:159px;bottom:auto!important;right:auto!important;line-height:16px!important;white-space:nowrap!important;visibility:hidden;background:url('http://martinfowler.com/favicon.ico') no-repeat scroll center center transparent!important;opacity:0;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" /><img class=\"linkscent-icon\" style=\"padding:0!important;margin:0;float:none!important;border:0 solid #ff0000!important;background:none repeat scroll center center transparent;width:16px!important;height:16px!important;display:none;overflow:visible!important;position:absolute!important;text-indent:0!important;z-index:2147483635!important;max-width:none!important;min-width:0!important;max-height:none!important;min-height:0!important;left:215px;top:159px;bottom:auto!important;right:auto!important;line-height:16px!important;white-space:nowrap!important;visibility:hidden;opacity:0;\" src=\"//interclue/content/cluecore/skins/default/pixel.gif\" alt=\"\" /></div>",
  "excerpt": ""
 },
 {
  "title": "Creating On-Demand Clusters in EC2 with Puppet",
  "published": "2012-05-05 13:21:09",
  "postType": "post",
  "slug": "/2012/05/05/creating-on-demand-clusters-in-ec2-with-puppet/",
  "status": "publish",
  "tags": [
   "aws",
   "cloud",
   "DevOps",
   "ec2"
  ],
  "categories": [
   "General",
   "Tools"
  ],
  "content": "For a recent project I needed to be able to start on-demand clusters of machines in Amazon EC2. We needed each instance in a cluster to allow SSH and sudo access for all team members and to install and configure the software appropriate for that cluster (\"database\" node or \"testclient\" node).<br><br>You can see the results of my effort using EC2 command-line tools, Puppet etc. at <a href=\"https://github.com/iterate/codecamp2012/tree/puppet\">the project's Puppet GitHub repository</a>, the setup is described in detail in its <a href=\"https://github.com/iterate/codecamp2012/blob/puppet/README.md\">README</a>.<br><br>(Tips for improvements are welcome. And not, <a href=\"http://web.mit.edu/star/cluster/\">Star Cluster</a> isn't what we needed.)",
  "excerpt": ""
 },
 {
  "title": "Bad Code: Too Many Object Conversions Between Application Layers And How to Avoid Them",
  "published": "2012-05-12 11:25:30",
  "postType": "post",
  "slug": "/2012/05/12/bad-code-too-many-object-conversions-between-application-layers-and-how-to-avoid-them/",
  "status": "publish",
  "tags": [
   "badcode",
   "CleanCode",
   "design",
   "java",
   "opinion"
  ],
  "categories": [
   "General",
   "Languages"
  ],
  "content": "Have you ever worked with an application where you had to copy data from one object to another and another and so on before you actually could do something with it? Have you ever written code to convert data from XML to a DTO to a Business Object to a JDBC Statement? Again and again for each of the different data types being processed? Then you have encountered an all too common antipattern of many \"enterprise\" (read \"overdesigned\") applications, which we could call The Endless Mapping Death March. Let's look at an application suffering from this antipattern and how to rewrite it in a much nicer, leaner and easier to maintain form.<br><br>The application, The World of Thrilling Fashion (or WTF for short) collects and stores information about newly designed dresses and makes it available via a REST API. Every poor dress has to go through the following conversions before reaching a devoted fashion fan:<br><br><ol>\n    <li>Parsing from XML into a XML-specific XDress object</li>\n    <li>Processing and conversion to an application-specific Dress object</li>\n    <li>Conversion to a MongoDB's DBObject so that it can be stored in the DB (as JSON)</li>\n    <li>Conversion from the DBObject back to the Dress object</li>\n    <li>Conversion from Dress to a JSON string</li>\n</ol><br><br>Uff, that's lot of work! Each of the conversions is coded manually and if we want to extend WTF to provide information also about trendy shoes, we will need to code all of them again. (Plus couple of methods in our MongoDAO, such as getAllShoes and storeShoes.) But we can do much better than that!<br><br><!--more--><br><br><h2>Eliminating the Manual Conversions</h2><br><br>It's time-consuming, error-prone and annoying to code all the conversions while you actually want to use your time to build business logic and not some boilerplate code. We can eliminate the manual work in two ways:<br><br><ol>\n    <li>Generalize the conversions so that they only need to be written once (likely leveraging existing conversion libraries)</li>\n    <li>Eliminate them, e.g. use the same data format through the complete processing chain</li>\n</ol><br><br>To be fair, I have to admit that the manual approach also has some advantages: you have full (fool? :-)) power over the form of the objects and can fit them perfectly for the processing required, you don't need to introduce huge and buggy libraries, and you earn more money, if paid by LOC.<br><br>However the disadvantages named above nearly always overweight the advantages, especially if you reuse suitable, mature, high-quality libraries that allow you to customize the processing to any detail on an on-need basis.<br><br>One question remains: how do we represent the data? We have two possibilities:<br><br><ol>\n    <li>With generic data structures, i.e. maps. This is common in dynamic functional languages such as Clojure and it is extremely easy and comfortable.\n<ul>\n    <li>Pros: Less work, very flexible, generic operations can be applied easily (map, filter, etc.)</li>\n</ul>\n</li>\n    <li>With objects specific for each data type, i.e. POJOs such as DressVariant, Shoes\n<ul>\n    <li>Pros: Type safety, the compiler helps to ensure that your code is correct, it might be easier to understand</li>\n    <li>Cons: You have to write and maintain a class for each possible data element being processed</li>\n</ul>\n</li>\n</ol><br><br><h2>Sidenote: The Business Domain</h2><br><br>You might skip this section and only come back later if you want to understand the reasoning behind the design.<br><br>WTF has to do some processing of the dress elements that it retrieves, mainly because multiple elements may represent the same dress only with slight variations such as color. WTF thus stores such a group of related elements as a list of DressVariant items inside a parent Dress object, generates a unique ID for the Dress and stores the IDs of the input elements in an attributed named \"externalIds\". Therefore N input elements becomes M Dress elements with 1+ DressVariants, M &lt;= N.<br><br>WTF also has to do some other processing on its WTF XML input such as detecting which images are real and which are just fake placeholders but we won't discuss that.<br><br><h2>Implementing the Static-Typed Generic Processing</h2><br><br>I've decided to keep having a class per data type not to diverge too much from the current implementation. How do we now make the manual conversions generic and reusable?<br><br>Let's first see how I would like to construct the processing pipeline:<br><br><pre><code>\r\nfetchFrom(&amp;quot;http://wtf.example.com/atom/dresses.xml&amp;quot;)\r\n   .parseNodesAt(&amp;quot;/feed/dress&amp;quot;)\r\n   .transform(DressVariant.class, new DressDeduplicatingTransformer()); // Transformer\r\n   .transform(new PojoToDboTransformer()); // Transformer\r\n   .store(new MongoDAO());\r\n// + we'll use DBObject.toMap() + PojoToJson mapper when serving the data via REST\r\n</code></pre><br><br>So we fetch XML from a URL, send it to a parser to extract some nodes that are automatically converted to DressVariant objects, next we use a transformer that merges multiple DressVariants into a single, unified Dress object, and finally we convert the resulting POJO into a Mongo DBObject before storing it into the DB. What do we use for the conversions?<br><br><ol>\n    <li>XML -&gt; DressVariant: Use <a href=\"http://docs.oracle.com/javase/6/docs/api/javax/xml/bind/Unmarshaller.html\">JAXB</a> to convert Nodes to our POJO annotated with @XmlRootElement. Notice that you can customize the conversion that JAXB performs very much, if the need be. Thus you only need to create a simple POJO and add one annotation.</li>\n    <li>DressVariant -&gt; Dress: We will check the MongoDB and either send further an existing Dress or a new Dress object with this DressVariant added (this will result in multiple updates if the dress really has multiple formats in the input feed, but that isn't a problem for us). This conversion is type-specific, i.e. for each data type we have to code its own transformation. That is good because for example Shoes don't need any such deduplicating processing/converting.</li>\n    <li>Dress -&gt; DBObject: We will use the Jackson Mongo Mapper, and extension of the first-class JSON mapping library, that adds support for Mongo DB. It will also performs some special data sanitization required by Mongo, such as replacing '.' in map keys with '-'.</li>\n    <li>DBObject -&gt; MongoDB: We will have one generic method, <code>storeDocument(String collectionName, DBObject doc)</code>, where the collection name is derived from the original object (e.g. DressVariant -&gt; \"dressVariants\"). The doc's attribute id is expected to be its unique identificator (and thus we will either update or insert based on its [missing] value).</li>\n    <li>MongoDB -&gt; DBObject: Again a generic method, <code>list(String collectionName)</code></li>\n    <li>DBObject -&gt; Map: The DBObject does that itself</li>\n    <li>Map -&gt; JSON: We will use the <a href=\"http://jersey.java.net/nonav/documentation/latest/json.html#json.pojo.approach.section\">PojoMapping</a> feature of the Jersey REST library to automatically convert the Map produced by our methods to JSON when sending it to the clients.</li>\n    <li>JSON -&gt; clients: We will have one GenericCollectionResource with a list method mapped to the URL /list/{collectionName}\". It will load the collection from Mongo as described and return a List, automatically converted to JSON by Jersey.</li>\n</ol><br><br>Result: Aside of custom data-type-specific transformations, instead of 1 POJO, 4 hand-coded converters, and 2+2 methods <em>for each data type</em> we now need only 1 POJO per data type plus one generic converter, 4 generic methods and one or two libraries. Less coding, less code, less defects, more productivity, more fun.<br><br>Notice that thanks to our choice of libraries, if the default conversion schemas turn out not to be sufficient for us, we can tweak them as much as we want - though we most certainly don't want to go that way. It's better to sacrifice some flexibility and more fit data formats than doing too many tweaks, struggling with the mapping libraries instead of leveraging them. A wise man chooses his battles.<br><br><h2>Sample Code</h2><br><br>Sample code demonstrating automatic, generic mappings XML -&gt; Java -&gt; Mongo -&gt; REST with JSON is <a href=\"https://github.com/jakubholynet/blog/tree/master/miniprojects/generic-pojo-mappers\">available at GitHub -</a> generic-pojo-mappers.<br><br><h2>Summary and Conclusion</h2><br><br>Many applications force developers to convert data between a number of objects, which is very unproductive and error-prone. A better approach is to avoid the conversions and use the same object throughout the whole processing as much as possible, doing conversions only when really necessary. These conversions are better written in a generic and reusable way than hand-coded for each data type and it often pays off to use an existing, mature mapping library for that (though you must make sure your intended use is aligned with its philosophy and design).<br><br>Using the same object throughout the processing causes it to be less fitted for the individual processing stages but it makes them much easier and faster to write and maintain. We lose some performance due to using reflection but that is negligible with respect to the I/O (retrieving a file over HTTP, sending data to a DB) and XML parsing.<br><br>In the example of the World of Thrilling Fashion, we have cut the amount of manual coding and methods considerably and the result is a smaller, cleaner, and more flexible code (w.r.t. adding new data types).<br><br><h3>Criticism</h3><br><br><em>But I really need to use objects fine-tuned for each layer of processing!</em><br><br>Your choice, if you really need it, do it - but be aware of how much you pay for it.<br><br><a href=\"/2011/11/20/how-to-fail-with-drools-or-any-other-toolframeworklibrary/\"><em>Libraries are evil!</em></a><br><br>Well, yes. Sometimes it's better to hand-code things but not always. Make sure that you don't use a library in a way different than intended because then you might lose more time fighting it than being productive.<br><br><em>You are an idiot!</em><br><br>Yes, <a href=\"http://java.dzone.com/articles/only-masochist-would-write#comments\">many people think so</a>. Thank you for reading.<br><br><em>Do you say that I'm an idiot if I wrote code like that?</em><br><br>Not at all, you might have good reasons to do so. Or you might not know the alternatives. Or you just haven't such a strong dislike of writing mindless code as I do. That's OK.<br><br><h2>Related</h2><br><br>The rich <a href=\"http://www.adam-bien.com/roller/abien/entry/can_stateful_java_ee_6\">Persistent Domain Object + slim Gateway</a> patterns by Adam Bien also make it possible to use the same object (a JPA entity) throughout all the application (web UI - DB) in the name of increased productivity.<br><br>M. Fowler's <a href=\"http://martinfowler.com/bliki/EmbeddedDocument.html\">EmbeddedDocument</a> is a pattern for working with JSON flowing in/out of our services (REST &lt;-&gt; JSON-friendly DB) without unnecessary conversions but with good encapsulation; naive approach: json -&gt; object graph -&gt; (processing) -&gt; json; \"In many of these situtiations a better way to proceed is to keep the data in a JSONish form, but still wrap it with objects to coordinate manipulation.\" - use a lib to parse the JSON into a generic structure (e.g. a structure of lists, and maps/dicts) and store in a field of an object defining methods that encapsulate it - f.ex. for an Order we could have a method returning the customer and another computing the cost, accessing the underlying generic structure. The user of the wrapper object doesn't need to know/care about the underlying structure.<br><br><blockquote>The sweet spot for an embedded document is when you're providing the document in the same form that you get it from the data store, but still want to do some manipulation of that data. [..] The order object needs only a constructor and a method to return its JSON representaiton. On the other hand as you do more work on the data - more server side logic, transforming into different representations - then it's worth considering whether it's easier to turn the data into an object graph.<br><br><em>You might enjoy also other <a href=\"/tag/opinion/\">posts on effective development</a>.</em></blockquote>",
  "excerpt": ""
 },
 {
  "title": "Most interesting links of May ''12",
  "published": "2012-05-31 21:59:26",
  "postType": "post",
  "slug": "/2012/05/31/most-interesting-links-of-may-12/",
  "status": "publish",
  "tags": [
   "agile",
   "clojure",
   "concurrency",
   "design",
   "html5",
   "leanstartup",
   "ORM",
   "scrum",
   "smtp",
   "trends"
  ],
  "categories": [
   "Databases",
   "General",
   "Testing",
   "Tools",
   "Top links of month"
  ],
  "content": "This was a rich month, bringing some hope for ORM, providing a peep-hole into the bright and awesome future with in-browser video and other cool web-stuff presented at WebRebels 2012 and IDEs providing immediate feedback and visualisation. There were valuable articles about simplicity and quality in software and good talks about the lean startup (i.e. enabling innovation) and other topics.\r\n<h2>Recommended Readings</h2>\r\n<ul>\r\n\t<li>M.Fowler: <a href=\"http://martinfowler.com/bliki/OrmHate.html\">ORM Hate - Why ORM is actually a good solution</a> - a very valuable article where Fowler opposes the popular trend of criticising Object-Relational Mappers such as Hibernate. Yes, using an ORM is difficult and a leaky abstraction - but that's because the problem of mapping from a rich in-memory object model to a relational store is inherently difficult (and you need to do it with or w/o an ORM tool) and because those last 10-20% of DB access require human intelligence. If you can avoid the need for ORM by using the relational model also in memory or by using a NoSQL database with a data model that fits your in-memory model then it's great to do so but often you can't and then using ORM is the best solution. You certainly don't want to code your own \"lightweight\" ORM.</li>\r\n\t<li>Alan Quayle on <a href=\"http://www.alanquayle.com/blog/2012/05/what-webrtc-means-to-telecoms.html\">WebRTC, the HTML5 standard for in-browser video/text communication - intro &amp; status</a> - this is an exciting technology coming to our browsers. Some quotes: <em>\"WebRTC enables applications such as voice calls, video chat, file sharing, messaging, white-boarding, gaming, human computer interaction, etc. without any client or plug-in download to run from a browser using simple HTML and JavaScript APIs.  Real time communications becomes pervasive on the internet. … Essentially any browser becomes a SIP end point, a telephone, an 'open' Skype client, an end point for any real-time communication and control. … Likely by the end of this year we'll see Chrome and Firefox running WebRTC.</em>\"</li>\r\n\t<li><a href=\"http://www.cs.kent.ac.uk/projects/ofa/jcsp/explain.html\">Communicating Sequential Processes: Theory for reasoning about concurrent, interacting processes</a> - an inspirational reading about a much better way to do concurrency than Java threads; \"... [CSP] is a language for describing patterns of interaction between concurrent objects. It is supported by an elegant, mathematical theory, a set of proof tools, and an extensive literature.\" The beauty is that thanks to the theory behind, you can actually reason about the interactions and verify their correctness, contrary to the feared mess of Java threads. <a href=\"http://en.wikipedia.org/wiki/Communicating_sequential_processes#Comparison_with_the_Actor_Model\">CSP is broadly similar to the popular Actors model</a> and is implemented in Occam while it also influenced Erlang's concurrency model and Go. The library <a href=\"http://www.cs.kent.ac.uk/projects/ofa/jcsp/\">JSCP</a> brings it to Java. I guess we're better of using Actors due to their popularity and maturity though the mathematical backing of CSP with the potential of formal proofs of correctness is indeed attractive. Any of the two is better than using threads directly because:\r\n<blockquote>The monitor-threads model provided by Java, whilst easy to understand, proves very difficult to apply safely in any system above a modest level of complexity. One problem is that monitor methods are tightly interdependent, so that their semantics compose in non-trivial ways [...]</blockquote>\r\n</li>\r\n\t<li><a href=\"http://clojure.com/blog/2012/05/08/reducers-a-library-and-model-for-collection-processing.html\">Rich Hickey introduces the Reducers library: simplicity in practice</a> - a beautiful example of simplifying something by taking appart all the unrelated but mingled concerns and focus only on those really needed. Whether you're interested in Clojure or not, you should read the beginning of the post where Hickey explains how the current collection functions based on <em>first</em> (returns 1st element) and <em>rest</em> (returns the remaining ones) mix too many things (ordering, output representation, etc.) and how this \"new super-generalized and minimal abstraction for collections\" avoids that and thus provides e.g. for doing things in parallel and composing transformation without producing intermediate collections. Beautiful! (PS: I've blogged about more examples of <a title=\"Beautiful Code: Simplicity Yields Power\" href=\"/2012/05/09/beautiful-code-simplicity-yields-power/\">pursuing simplicity &amp; gaining power</a>.)</li>\r\n\t<li><a href=\"http://martinfowler.com/bliki/CannotMeasureProductivity.html\">M. Fowler: Cannot Measure Productivity</a> - a thoughful discussion of why the productivity of programmers is hard/impossible to measure (i.e. you should concentrate on measuring other, more useful metrics) \"[..] false measures only make things worse.\"</li>\r\n\t<li><a href=\"http://gojko.net/2012/05/08/redefining-software-quality/\">Gojko Adzic: Redefining software quality</a> - an obligatory read that introduces a holistic view of SW quality and the quality pyramid. The key idea is that there are multiple, vertically organized facets of quality and once a more basic facet is saturated, you should move and and concentrate on the next facet and level of quality. The quality pyramid: Deployable &amp; functionally OK &gt; Performant &amp; secure &gt; Usable &gt; Useful &gt; Successful. Once a particular level is satisfied, it is wasteful to put more effort into it and you'll bring much more value to the customer by focusing on the next higher level. Gojko: \"Yet from what I see most software teams invest, build and test only at the lowest two levels, gold-plating things without a way to explain why that is bad.\"</li>\r\n\t<li><a href=\"http://arlobelshee.com/post/is-pair-programming-for-me\">Is Pair Programming for Me?</a> - the author, who claims to have taught pair programming to 200+500 people, points out that pair programming is a skill that must be (consciously) learned, or actually a number of inter-personal skills. He also describes the cycle people go through when learning it, including a temporary downswing in productivity and negative view of pairing (therefore people should do it at least for 3-4 weeks to overcome the problems and gain the benefits).</li>\r\n</ul>\r\n<h3>Videos</h3>\r\n<ul>\r\n\t<li><a href=\"http://vimeo.com/36579366\">Bret Victor: Inventing on Principle</a> (55 min, see at least the first 5 min) - very inspiring! Victor firmly believes that \"creators need an immediate connection to what they create\" and demonstrates how this can be achieve when coding image rendering, a game, an algorithm, when designing a circuit. After watching it for few minutes you will think: How could we have been working with such crappy tools without realizing how limited they are? Fortunately people started to apply the idea of an immediate connection between code and the result, f.ex. in <a href=\"http://www.chris-granger.com/2012/04/12/light-table---a-new-ide-concept/\">LightTable</a> and <a href=\"http://bike.sh/\">Bikeshed</a>'s IDE. On the other hand, there is an evidence that <a href=\"http://alarmingdevelopment.org/?p=680\">this may be too hard</a> with the current programming languages.</li>\r\n\t<li><a href=\"http://www.youtube.com/watch?feature=player_embedded&amp;v=zGXAVw3vF9A\">Eric Ries: Evangelizing for the Lean Startup</a> - entertaining and enriching introduction into an approach for bringing innovation to life - f.ex. in startups - withou failing unnecessary, demonstrated on the example of the author's failed and successful startup. Many innovators fail because they don't realize that their key challenge is that they don't now neither the problem (who are our customers and what they need) nor the solution (the product to satisfy the need) and thus what they need to do is to experiment and learn in the shortest cycles possible. If you wander what the buzz about lean startup is or how to build innovations, this is the ultimite source you should watch. The video has 1h but the first 20-30 min will give you a sufficient overview. The key points summarized by the Iterate lean guru <a href=\"https://twitter.com/#!/hauge2\">Anders Haugeto</a>:\r\ndd\r\n<blockquote>- There is only one way to measure progress: Progress == The amount of things you have learned from your real customers\r\n- Hence, you need to work a continuous loop to build, measure and learn as fast as possible. Typical iterations, like sprints, are too long, hence inefficient\r\n- Until you have an established product, even recognized engineering practices like TDD, sprints, refactoring, and all the XP-stuff are less important than this feedback cycle\r\n- Even the perfect agile method is nothing, if you're using it to build the wrong product: How can you know you are heading in the right direction?</blockquote>\r\n</li>\r\n\t<li><a href=\"https://vimeo.com/channels/wr2012\">WebRebels 2012 conference talks</a> - I'd especially recommend the awakening talk by Zed Shaw pointing out that we're building amazing things - but on top of crapy technologies without realizing anymore that the technologies are crappy and could/should be much better. Erlend Oftedal's talk about webapp security was an (scary) eye-opener for me. If you're considering offline webapps with HTML5's webapp cache and/or local storage then you must listen to Jake Archibald's painful story of various pitfalls hidden there. Christian Johansen's Pure, functional JavaScript is a pleasure to listen to. Check out the <a href=\"http://webrebels.org/#schedule\">program</a>.</li>\r\n</ul>\r\n<h2>Links to Keep</h2>\r\n<ul>\r\n\t<li>E. King: <a href=\"http://www.scrumalliance.org/articles/417-maximizing-the-value-of-your-standup-\">Maximizing the Value of Your Stand-up</a> - interesting techniques to try out at your stand-ups - Speed Scrum, Pass-the-Conch Scrum (passing a token randomly to define the order), Time-Box Scrum, Challenge Scrum (the team may ask 1 question each presenter), Impediments-Only Scrum, Award Scrum (reward for best articulation of his/her information), Business Value-Focused Scrum, No-Board Scrum, Whiteboard Scrum, Buddy Scrum (report for sb. else)</li>\r\n</ul>\r\n<h2>Useful Tools</h2>\r\n<ul>\r\n\t<li><a href=\"http://puppet-lint.com/\">puppet-lint</a> - check code style of your Puppet files</li>\r\n\t<li><a href=\"https://github.com/guard/guard#readme\">Guard</a> - cross-platform tool that can watch for file changes and execute actions (\"guards\") when a file is changed, useful e.g. to execute tests/style checks only on the files being modified. Includes <a href=\"https://github.com/guard/guard/wiki/List-of-available-Guards\">support for many testing/checking tools</a> and multiple notification means such as Growl.</li>\r\n\t<li><a href=\"http://java.net/projects/threadlogic\">ThreadLogic</a> - Thread dump analyzer that understands common patterns found in application servers and enabling the definition of custom patterns. Supports Sun, IBM, and JRockit.</li>\r\n\t<li><a href=\"http://quintanasoft.com/dumbster/\">Dumbster</a> - mock SMTP server for unit testing (start in @Before, get sent messages in the test, stop afterwards)</li>\r\n</ul>\r\n<h2>Quotes</h2>\r\nKai Thomas Gilb, in a talk proposal for JavaZone 2012:\r\n<blockquote>Accurate estimation is impossible for complex technical projects, but keeping to agreed budgets, and deadlines is achievable by using feedback and change.</blockquote>\r\n<h2>Clojure Corner</h2>\r\n<ul>\r\n\t<li><a href=\"http://stackoverflow.com/questions/2186709/are-there-any-good-clojure-benchmarks\">StackOverflow: Clojure Performance Benchmarks</a> - links to various discussions and benchmarks (beware that older results and facts are likely to be outdated). And of course you must keep in mind that 1) benchmark only measure what they measure, e.g. the outcomes cannot be generalized and that 2) benchmark results aren't relevant for your problem unless you're doing exactly the kind of operations being benchmarked (e.g. who cares that X is 100 ms slower if your code spends 1s waiting for a XML file download?) (Craig Andera had a pretty good <a href=\"http://blip.tv/clojure/craig-andera-performance-in-the-wild-5970188\">experience report from webapp performance testing</a> including what (not) to do)</li>\r\n\t<li>A good <a href=\"http://cataclysmicmutation.com/2012/05/euroclojure-wrapup/\">wrapup of the EuroClojure conference</a> by Deon Garrett. Such a pity I missed it!</li>\r\n\t<li><a href=\"https://github.com/ctford/goldberg\">Goldberg (at GitHub)</a> - Johann Sebastian Bach's Goldberg Variations in <a href=\"http://overtone.github.com/\">Overtone</a> by @ctford; using Overtone and Clojure to build up mathematical and functional definitions of canons. Deon Garrett: \"Go right now and download the code from Chris’ talk. If you don’t know Clojure, use this as an excuse to learn it – it’s that good.\"</li>\r\n</ul>\r\n<a href=\"http://www.codequarterly.com/2011/rich-hickey/\">Rich Hickey interviewed by M. Fogus</a>:\r\n<blockquote>Reducing incidental complexity is a primary focus of Clojure, and you could dig into how it does that in every area.<br><br>...<br><br>In particular, the use of objects to represent simple informational data is almost criminal in its generation of per-piece-of-information micro-languages, i.e. the class methods, versus far more powerful, declarative, and generic methods like relational algebra. Inventing a class with its own interface to hold a piece of information is like inventing a new language to write every short story. This is anti-reuse, and, I think, results in an explosion of code in typical OO applications.</blockquote>",
  "excerpt": ""
 },
 {
  "title": "Beautiful Code: Simplicity Yields Power",
  "published": "2012-05-09 19:14:32",
  "postType": "post",
  "slug": "/2012/05/09/beautiful-code-simplicity-yields-power/",
  "status": "publish",
  "tags": [
   "clojure",
   "design",
   "opinion"
  ],
  "categories": [
   "General"
  ],
  "content": "<div id=\"main-content\">\n<div><br><br>In <a href=\"http://www.infoq.com/presentations/Simple-Made-Easy\" rel=\"nofollow\">Simple Made Easy</a> argues Rich Hickey that mixing orthogonal concerns introduces unnecessary complexity and that we should keep them separate. This mixing sometimes occurs on such a basic level that we believe that there is no other way to do it, an example being the interleaving of polymorphism and hierarchical namespacing represented by OO class hierarchies. Taking those \"complected\" concerns apart and dealing with them separately yields cleaner, simpler solutions and sometimes also more powerful ones because you are free to combine them as you need and not as the author decided.<br><br><!--more--><br><br>A practical example of this simplification by separation of complected concerns is the new Reducers library of collection transforming functions for Clojure. It's very interesting to <a href=\"http://clojure.com/blog/2012/05/08/reducers-a-library-and-model-for-collection-processing.html\" rel=\"nofollow\">read its story</a>, no matter whether you're interested in Clojure or not. The old implementation of collection functions such as map, filter and reduce implies a lot: for example the order of processing (sequential), its mechanims (recursion), the representation of the result. On the contrary, this \"new super-generalized and minimal abstraction for collections\" has only a single requirement for something to be regarded as a collection: \"a collection is some set of things that, when given a function to apply to its contents, can do so and give you the result.\" By not prescribing any unrelated mechanism it opens door to a more flexible and powerful implementation, f.ex. making it possible to process collections in parallel and to compose multiple transformer functions without producing intermediate collections. Elegant and powerful.<br><br>Another example of simplicity that brings power is the story of <a href=\"http://clojure.com/blog/2012/02/17/clojure-governance.html\" rel=\"nofollow\">adding support for named parameters to Clojure</a>. Instead of introducing a new construct to the language, Rich took two years to come up with a more elegant and powerful solution that is a natural extension of an existing language feature. He looked at destructuring, i.e. the ability to automatically bind the content of a collection to individual variables (f.ex. specifying a function parameter as \"[fname lname]\" and calling it with the vector [\"Gandalf\" \"Grey\"] would bind the local variable fname to \"Gandalf\"), and extended it to support maps so that you can automatically bind the value of a key to a local variable. It fits naturally in and is usable and useful in many other contexts than just function calls.<br><br>The conclusion is that striving for simplicity and eliminating orthogonal concerns leads to better and occassionally (often?) more powerful solutions.<br><br><em>(Note: This post doesn't expect its readers to know anything about Clojure and thus I opted to use terms and formulations understandable to everybody, even though not completely technically correct.)</em>\n<p style=\"text-align:center;\"><em>You might enjoy also other <a href=\"/tag/opinion/\">posts on effective development</a>.</em></p><br><br></div>\n</div>",
  "excerpt": ""
 },
 {
  "title": "Most interesting links of June ''12",
  "published": "2012-06-30 21:59:58",
  "postType": "post",
  "slug": "/2012/06/30/most-interesting-links-of-june-12/",
  "status": "publish",
  "tags": [
   "agile",
   "clojure",
   "design",
   "DevOps",
   "groovy",
   "inspiration",
   "lean",
   "leanstartup",
   "performance",
   "puppet",
   "python"
  ],
  "categories": [
   "General",
   "Testing",
   "Tools",
   "Top links of month"
  ],
  "content": "<h2>Recommended Readings</h2>\r\nDevelopment\r\n<ul>\r\n\t<li><a href=\"http://www.ibm.com/developerworks/java/library/j-eaed19/index.html\">Neal Ford: Evolutionary architecture and emergent design: Emergent design in the wild</a> - discusses why not to do Big Design Up Front and how to recognize the \"last responsible moment\". Quote: \"<em>It's puzzling that so many organizations continue to use BDUF in the face of so many failures and underachieving projects.</em>\"</li>\r\n\t<li><a href=\"http://gojko.net/2012/05/31/how-to-solve-not-enough-time/\">Gojko Adzic: How To Solve “Not Enough Time”</a> - everybody in IT complains about too much work. The solution acording to Gojko? Kill software already made that isn’t needed (ex.: deleted 70% functionality that wasn't used; remember that maintenance costs grow ~ exponentially with size/complexity). Kill software in making that won’t be needed (know the value -  <a href=\"http://gojko.net/effect-map\">effect maps</a>). Kill software that was not successful (if you measure the value of SW, you know whether its existence is worth it). Well written and inspiring. I'm looking forward to killing some SW :-)</li>\r\n\t<li>Coding Horror: <a href=\"http://www.codinghorror.com/blog/2006/10/the-last-responsible-moment.html\">Postponing decisions to the last responsible moment</a> - a brief and pretty good explanation of this key lean principle together with its connection to YAGNI (and some <a href=\"http://alistair.cockburn.us/Last+Responsible+Moment+reconsidered\">criticism of LRM</a> by A. Cockburn - I agree with the postscript 2)</li>\r\n</ul>\r\nSpecial\r\n<ul>\r\n\t<li><a href=\"http://www.buildtheenterprise.org/\">Build The (USS) Enterprise</a> - A fascinating site by an engineer who dares to think big yet manages to stay rooted in reality. A huge inspiration for us all! We tend to think too small. Having a great, inspiring goal is what moves us forward. And people are known to have achieve seemingly impossible things nobody else believed in (how many believed Columbus could reach India by by sailing the opposite direcetion? and even though he actually hasn't, the impacts of his discovery were tremendous)</li>\r\n\t<li><a href=\"http://www.nirandfar.com/2012/04/hooking-users-in-3-steps.html\">Hooking Users In 3 Steps: An Intro to Habit Testing</a> - to be successful with a new web product in this age of distraction, you need your users to build the habit of using the app regularly (think of Twitter, Facebook, newspaper); this post describes how to find your habitual users, understand them, and optimize the application to turn more occassional users into habitual ones (identify habitual users - learn how they use the app &amp; learn what turns random users into \"devotees\" - optimize the \"habit path\")</li>\r\n\t<li><a href=\"http://puppetlabs.com/blog/git-workflow-and-puppet-environments/\">Puppet: Serve configuration from a particular Git branch on demand</a> (original: Git Workflow and Puppet Environments) - at Comoyo we use Puppet to configure all our environments and developers need to test their changes before pushing them to the live environment, preferably without interference from other devs. This post by Adrien of PuppetLabs describes how to enable each developer to have her private branch(es) and have Pupet Master serve the config from the branch on demand, using little puppet environments and hooks magic. (Notice that if using Puppet to serve files then you'll <a href=\"http://docs.puppetlabs.com/guides/environment.html#caveats\">need to have them inside a module</a>, which <a href=\"http://docs.puppetlabs.com/puppet/2.7/reference/modules_fundamentals.html\">is a good practice</a> anyway.)</li>\r\n</ul>\r\nOther\r\n<ul>\r\n\t<li><a href=\"http://refcardz.dzone.com/refcardz/jetty\">DZone reference card for Jetty</a> (DZone login required) - useful, brief overview over Jetty XML and programatic configuration, especially useful is the overview of handlers, use of servlets and webapps, SSL support, websockets</li>\r\n\t<li><a href=\"http://www.infoq.com/articles/new-groovy-20\">What’s new in Groovy 2.0?</a> - static type checking, Java 7</li>\r\n\t<li><a href=\"http://shootout.alioth.debian.org/u64q/benchmark.php?test=all&amp;lang=python3&amp;lang2=java\">Speed, memory and LOC of Python 3 vs. Java 7</a> [fixed link] (the computer language benchmark game) - Python tends to take more time (though not terribly more) but is quite economical with memory and visibly more productive (3* less lines of code). <a href=\"http://shootout.alioth.debian.org/u64q/benchmark.php?test=all&amp;lang=yarv&amp;lang2=java\">Ruby</a> is similar but way slower. <a href=\"http://shootout.alioth.debian.org/u64q/benchmark.php?test=all&amp;lang=scala&amp;lang2=java\">Scala</a> is little slower and more memory hunrgy but also more productive. Of course performance is rarely the key factor for picking a language on often it doesn't matter that much.</li>\r\n</ul>\r\n<h2>Favourite Quotes</h2>\r\n<blockquote>\r\n<p style=\"text-align:left;\">Goodhart's Law: once a metric becomes a target, it loses its meaning as a measure.</p>\r\n<p style=\"text-align:right;\"><a href=\"http://www.facebook.com/WordFriday/posts/320731068014857\">by WordFriday</a></p>\r\n</blockquote>\r\n<h2>Clojure Corner</h2>\r\n<ul>\r\n\t<li><a href=\"http://www.infoq.com/presentations/What-Sucks-about-Clojure-and-Why-You-ll-Love-It-Anyway\">What Sucks about Clojure...and Why You'll Love It Anyway</a> - 40 min talk by Clojure Programming author Chas Emerick. Some of the negative points: Namespaces - complex (use x refer etc.; no package.* import, ...), no forward references; Dynamic scope (with-foo ...) has subtle, complex behavior and hard to see =&gt; avoid when you can; Using STM (effectively) is hard even though it looks easy, it's overused, think of it rather as in-memory db with superior integr. with Clojure (ex.: what is the right ref granularity? whole word map? small particle?), nondeterministic (which tx will fail/suceed? - can't reason) =&gt; strange error under high load/mix of operations; JVM: long startup time, ...; Macros look easy but are hard (don't compose nicely with the rest); Function composition - hard to find failure root cause.</li>\r\n\t<li><a href=\"http://martinsprogrammingblog.blogspot.no/2012/02/why-is-clojure-so-slow.html\">Why is Clojure so slow?</a> (2/2012) - an interesting comparison of Clojure and other languages (C, F#, Groovy etc.) and an analysis of its slow start-up time (metadata and docstring building) and slower performance. (Interestingly, ClojureScript runs it 9* faster.) According to the author, it's slower partly due to the imutable data structures (nothing new here, we knew we have to offer some performance for the increased safety and robustness). Conclusion: \"Clojure is a beautiful, powerful and very useful language, but [...] not great for small script-y programs.\" Also, the usefulness of the benchmark is limited if you aren't writing games. Plans for <a href=\"http://blip.tv/clojure/rich-hickey-keynote-5970064\">making Clojure leaner and faster</a> are under way.</li>\r\n\t<li><a href=\"http://clojure.com/blog/2012/02/03/functional-relational-programming-with-cascalog.html\">Stuart Sierra: Functional Relational Programming with Cascalog</a> - a brief introduction into Cascalog with a valuable background info about Hadoop, MapReduce, relational programming in Clojure. Good links, especially the paper <a title=\"Out of the Tar Pit, 2006 paper by Ben Mosely and Peter Marks [PDF]\" href=\"http://web.mac.com/ben_moseley/frp/paper-v1_01.pdf\">Out of the Tar Pit</a> looks interesting.</li>\r\n</ul>",
  "excerpt": ""
 },
 {
  "title": "Serving Files with Puppet Standalone in Vagrant From the puppet:// URIs",
  "published": "2012-06-14 09:40:10",
  "postType": "post",
  "slug": "/2012/06/14/serving-files-with-puppet-standalone-in-vagrant-from-the-puppet-uris/",
  "status": "publish",
  "tags": [
   "DevOps",
   "puppet",
   "vagrant"
  ],
  "categories": [
   "Tools"
  ],
  "content": "If you use Puppet in the client-server mode to configure your production environment then you might want to be able to copy &amp; paste from the prod configuration into the <a href=\"http://vagrantup.com/v1/docs/provisioners/puppet.html\">Vagrant's standalone puppet</a>'s configuration to test stuff. One of the key features necessary for that is enabling file serving via \"source =&gt; 'puppet:///path/to/file'\". In the client-server mode the files are served by the server, in the standalone mode you can configure puppet to read from a local (likely shared) folder. We will see how to do this.<br><br><!--more--><br><br>Credits: This post is based heavily on Akumria's answer at <a href=\"http://stackoverflow.com/a/10463734\">StackOverflow: how to source a file in puppet manifest from module</a>.\r\n<h2>Enabling Puppet Standalone in Vagrant to Resolve puppet:///...</h2>\r\nQuick overview:\r\n<ol>\r\n\t<li>Make the directory with the files to be served available to the Vagrant VM</li>\r\n\t<li>Create fileserver.conf to inform Puppet about the directory</li>\r\n\t<li>Tell puppet about the fileserver.conf</li>\r\n\t<li>Use it</li>\r\n</ol>\r\n<h3>1. Make the directory with the files to be served available to the Vagrant VM</h3>\r\nFor example as a shared folder:<br><br><pre><code>\r\n# Snippet of &lt;vagrant directory&gt;/Vagrantfile\r\nconfig.vm.share_folder &quot;PuppetFiles&quot;, &quot;/etc/puppet/files&quot;, &quot;./puppet-files-symlink&quot;\r\n</code></pre><br><br>(In my case this is actually a symlink to the actual folder in our puppet git repository. Beware that <a href=\"https://github.com/mitchellh/vagrant/issues/713\">symlinks inside shared folders often don't work</a> and thus it's better to use the symlink as a standalone shared folder root.)<br><br>Notice you don't need to declare a shared folder\r\n<h3>2. Create fileserver.conf to inform Puppet about the directory</h3>\r\nYou need to tell to Puppet that the source\"puppet:///files/\" should be served from /etc/puppet/files/:<br><br><pre><code>\r\n# &lt;vagrant directory&gt;/fileserver.conf\r\n[files]\r\n  path /etc/puppet/files\r\n  allow *\r\n</code></pre>\r\n<h3>3. Tell puppet about the fileserver.conf</h3>\r\nPuppet needs to know that it should read the fileserver.conf file:<br><br><pre><code>\r\n# Snippet of &lt;vagrant directory&gt;/Vagrantfile\r\nconfig.vm.provision :puppet,\r\n  :options =&gt; [&quot;--fileserverconfig=/vagrant/fileserver.conf&quot;],\r\n  :facter =&gt; { &quot;fqdn&quot; =&gt; &quot;vagrant.vagrantup.com&quot; } do |puppet|\r\n     ...\r\nend\r\n</code></pre>\r\n<h3>4. Use it</h3>\r\n<pre><code>\r\nvagrant_dir$ echo &quot;dummy content&quot; &gt; ./puppet-files-symlink/example-file.txt\r\n</code></pre><br><br>&nbsp;<br><br><pre><code>\r\n # Snippet of &lt;vagrant directory&gt;/manifests/&lt;my manifest&gt;.pp\r\n ...\r\nfile{'/tmp/example-file.txt':\r\n  ensure =&gt; file,\r\n  source =&gt; 'puppet:///files/example-file.txt',\r\n}\r\n...\r\n</code></pre>\r\n<h2>Caveats</h2>\r\n<h3>URLs with server name (puppet://puppet/) don't work</h3>\r\nURLs like <code>puppet://puppet/files/path/to/file</code> don't work, you must use <code>puppet:///files/path/to/file</code> instead (empty, i.e. implicit, server name =&gt; three slashes).<br><br>The reason is, I believe, that if you state the server name explicitely then Puppet will try to find the server and get the files from there (that might be a desirable behavior if you run Puppet Master locally or elsewhere; in that case just add the server name to <code>/etc/hosts</code> in the Vagrant VM or make sure the DNS server used can resolve it). On the other hand, if you leave the server name out and rely on the implicit value then Puppet in the standalone mode will consult its fileserver.conf and behave accordingly. (Notice that in the server-client mode the implicit server name equals the puppet master, i.e. puppet:/// works perfectly well there.)<br><br>If you use <code>puppet://puppet/files/...</code> then you'll get an error like this:\r\n<pre>err: /Stage[main]/My_example_class/File[fetch_cdn_logs.py]: Could not evaluate: \r\ngetaddrinfo: Name or service not known Could not retrieve file metadata for puppet://puppet/files/analytics/fetch_cdn_logs.py: \r\ngetaddrinfo: Name or service not known at /tmp/vagrant-puppet/manifests/analytics_dev.pp:283</pre>\r\n<h2>Environment</h2>\r\nPuppet: 2.7.14, Vagrant:1.0.2",
  "excerpt": ""
 },
 {
  "title": "Creating Custom Login Modules In JBoss AS 7 (and Earlier)",
  "published": "2012-06-21 19:15:22",
  "postType": "post",
  "slug": "/2012/06/21/creating-custom-login-modules-in-jboss-as-7-and-earlier/",
  "status": "publish",
  "tags": [
   "java",
   "jboss",
   "security",
   "webapp"
  ],
  "categories": [
   "j2ee",
   "Languages",
   "Tools"
  ],
  "content": "JBoss AS 7 is neat but the documentation is still quite lacking (and error messages not as useful as they could be). This post summarizes how you can create your own JavaEE-compliant login module for authenticating users of your webapp deployed on JBoss AS. A working elementary username-password module provided.<br><br><!--more-->\r\n<h2>Why to use Java EE standard authentication?</h2>\r\n<h3>Java EE security primer</h3>\r\nA part of the Java EE specification is security for web and EE applications, which makes it possible both to specify declarative constraints in your web.xml (such as \"role X is required to access resources at URLs \"/protected/*\") and to control it programatically, i.e. verifying that the user has a particular role (see <a href=\"http://docs.oracle.com/javaee/1.4/api/javax/servlet/http/HttpServletRequest.html#isUserInRole%28java.lang.String%29\">HttpServletRequest.isUserInRole</a>).<br><br>It works as follows:\r\n<ol>\r\n\t<li>You declare in your web.xml:\r\n<ol>\r\n\t<li>Login configuration - primarily whether to use browser prompt (basic) or a custom login form and a name for the login realm\r\n<ul>\r\n\t<li>The custom form uses \"magic\" values for the post action and the fields, starting with j_, which are intercepted and processed by the server</li>\r\n</ul>\r\n</li>\r\n\t<li>The roles used in your application (typically you'd something like \"user\" and perhaps \"admin\")</li>\r\n\t<li>What roles are required for accessing particular URL patterns (default: none)</li>\r\n\t<li>Whether HTTPS is required for some parts of the application</li>\r\n</ol>\r\n</li>\r\n\t<li>You tell your application server how to authenticate users for that login realm, usually by associating its name with one of the available login modules in the configuration (the modules ranging from simple file-based user list to LDAP and Kerberos support). Only rarely do you need to create your own login module, the topic of this post.</li>\r\n</ol>\r\nIf this is new for you than I strongly recommend reading <a href=\"http://docs.oracle.com/javaee/5/tutorial/doc/bncbx.html\">The Java EE 5 Tutorial - Examples: Securing Web Applications</a> (Form-Based Authentication with a JSP Page incl. security constraint specification, Basic Authentication with JAX-WS, Securing an Enterprise Bean, Using the isCallerInRole and getCallerPrincipal Methods).\r\n<h3>Why to bother?</h3>\r\n<ul>\r\n\t<li>Declarative security is nicely decoupled from the business code</li>\r\n\t<li>It's easy to propagate security information between a webapp and for example EJBs (where you can protect a complete bean or a particular method declaratively via xml or via annotations such as <a href=\"http://docs.oracle.com/javaee/5/tutorial/doc/bnbzj.html#bnbzk\">@RolesAllowed</a>)</li>\r\n\t<li>It's easy to switch to a different authentication mechanism such as LDAP and it's more likely that SSO will be supported</li>\r\n</ul>\r\n<h2>Custom login module implementation options</h2>\r\nIf one of the <a href=\"https://community.jboss.org/wiki/JBossAS7SecurityDomainModel#Security_Domains\">login modules (a.k.a. security domains) provided out of the box</a> with JBoss, such as UsersRoles, Ldap, Database, Certificate, isn't sufficient for you then you can adjust one of them or implement your own. You can:\r\n<ol>\r\n\t<li>Extend one of the concrete modules, overriding one or some of its methods to ajdust to your needs - see f.ex. how to <a href=\"https://community.jboss.org/wiki/CreatingACustomLoginModule\">override the DatabaseServerLoginModule to specify your own encryption</a> of the stored passwords. This should be your primary choice, of possible.</li>\r\n\t<li>Subclass UsernamePasswordLoginModule</li>\r\n\t<li>Implement javax.security.auth.spi.LoginModule if you need maximal flexibility and portability (this is a part of Java EE, namely <a href=\"http://docs.oracle.com/javase/1.4.2/docs/guide/security/jaas/JAASLMDevGuide.html\">JAAS</a>, and is quite complex)</li>\r\n</ol>\r\nJBoss EAP 5 <a href=\"http://docs.redhat.com/docs/en-US/JBoss_Enterprise_Application_Platform/5/html/Security_Guide/sect-Custom_Modules.html\">Security Guide Ch. 12.2. Custom Modules</a> has an excellent description of the basic modules (AbstractServerLoginModule, UsernamePasswordLoginModule) and how to proceed when subclassing them or any other standard module, including description of the key methods to implement/override. You must read it. (The guide is still perfectly applicable to JBoss AS 7 in this regard.) The custom <a href=\"http://docs.redhat.com/docs/en-US/JBoss_Enterprise_Application_Platform/5/html/Security_Guide/sect-Custom_LoginModule_Example.html\">JndiUserAndPass module example</a>, extending UsernamePasswordLoginModule, is also worth reading - it uses module options and JNDI lookup.\r\n<h3>Example: Custom UsernamePasswordLoginModule subclass</h3>\r\nSee the <a href=\"https://github.com/jakubholynet/blog/blob/master/miniprojects/jboss-custom-login/src/main/java/custom/MySimpleUsernamePasswordLoginModule.java\">source code of MySimpleUsernamePasswordLoginModule</a> that extends JBoss' <em>UsernamePasswordLoginModule</em>.<br><br>The abstract <a href=\"http://www.docjar.com/html/api/org/jboss/security/auth/spi/UsernamePasswordLoginModule.java.html\">UsernamePasswordLoginModule</a> (<a href=\"http://www.docjar.com/src/api/org/jboss/security/auth/spi/UsernamePasswordLoginModule.java\">source code</a>) works by comparing the password provided by the user for equality with the password returned from the method getUsersPassword, implemented by a subclass. You can use the method getUsername to obtain the user name of the user attempting login.\r\n<h4>Implement abstract methods</h4>\r\n<h5>getUsersPassword()</h5>\r\nImplement getUsersPassword() to lookup the user's password wherever you have it. If you do not store passwords in plain text then read how to customize the behavior via other methods below\r\n<h5>getRoleSets()</h5>\r\nImplement getRoleSets() (from <a href=\"http://www.docjar.com/html/api/org/jboss/security/auth/spi/AbstractServerLoginModule.java.html\">AbstractServerLoginModule)</a> to return at least one group named \"Roles\" and containing 0+ roles assigned to the user, see the implementation in <a href=\"https://github.com/jakubholynet/blog/blob/master/miniprojects/jboss-custom-login/src/main/java/custom/MySimpleUsernamePasswordLoginModule.java\">the source code for this post</a>. Usually you'd lookup the roles for the user somewhere (instead of returning hardcoded \"user_role\" role).\r\n<h4>Optionally extend initialize(..) to get access to module options etc.</h4>\r\nUsually you will also want to extend <em>initialize(Subject subject, CallbackHandler callbackHandler, Map sharedState, Map options)</em> (called for each authentication attempt),\r\n<ul>\r\n\t<li>To get values of properties declared via the &lt;module-option ..&gt; element in the security-domain configuration - <a href=\"http://docs.redhat.com/docs/en-US/JBoss_Enterprise_Application_Platform/5/html/Security_Guide/sect-Custom_LoginModule_Example.html\">see JBoss 5 custom module example</a></li>\r\n\t<li>To do other initialization, such as looking up a data source via JNDI - see the <a href=\"http://www.docjar.com/html/api/org/jboss/security/auth/spi/DatabaseServerLoginModule.java.html\">DatabaseServerLoginModule</a></li>\r\n</ul>\r\n<h4>Optionally override other methods to customize the behavior</h4>\r\nIf you do not store passwords in plain text (a wise choice!) and your hashing method isn't supported out of the box then you can override <em>createPasswordHash(String username, String password,  String digestOption)</em> to hash/encrypt the user-supplied password before comparison with the stored password.<br><br>Alternatively you could override <em>validatePassword(String inputPassword, String expectedPassword)</em> to do whatever conversion on the password before comparison or even do a different type of comparison than equality.\r\n<h2>Custom login module deployment options</h2>\r\nIn JBoss AS you can\r\n<ol>\r\n\t<li>Deploy your login module class in a JAR as a standalone module, independently of the webapp, under <em>&lt;JBoss AS 7&gt;/modules/</em>, together with a module.xml - described at <a href=\"https://community.jboss.org/wiki/JBossAS7SecurityCustomLoginModules\">JBossAS7SecurityCustomLoginModules</a></li>\r\n\t<li>Deploy your login module class as a part of your webapp (no module.xml required)\r\n<ol>\r\n\t<li> In a JAR inside WEB-INF/lib/</li>\r\n\t<li>Directly under WEB-INF/classes</li>\r\n</ol>\r\n</li>\r\n</ol>\r\nIn each case you have to declare a corresponding security-domain it inside JBoss configuration (standalone/configuration/standalone.xml or domain/configuration/domain.xml):<br><br><pre><code>\r\n&lt;security-domain name=&quot;form-auth&quot; cache-type=&quot;default&quot;&gt;\r\n  &lt;authentication&gt;\r\n    &lt;login-module code=&quot;custom.MySimpleUsernamePasswordLoginModule&quot; flag=&quot;required&quot;&gt;\r\n      &lt;!--module-option name=&quot;exampleProperty&quot; value=&quot;exampleValue&quot;/--&gt;\r\n    &lt;/login-module&gt;\r\n  &lt;/authentication&gt;\r\n&lt;/security-domain&gt;\r\n</code></pre><br><br>The <em>code</em> attribute should contain the fully qualified name of your login module class and the security-domain's <em>name</em> must match the declaration in jboss-web.xml:<br><br><pre><code>\r\n&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;\r\n&lt;jboss-web&gt;\r\n  &lt;security-domain&gt;form-auth&lt;/security-domain&gt;\r\n  &lt;disable-audit&gt;true&lt;/disable-audit&gt;\r\n&lt;/jboss-web&gt;\r\n</code></pre>\r\n<h2>The code</h2>\r\n<a href=\"https://github.com/jakubholynet/blog/tree/master/miniprojects/jboss-custom-login\">Download the webapp jboss-custom-login</a> containing the custom login module <a id=\"dbc2bb6d6dfd6a92fb06631e16bc9fc0c17b8816\" href=\"https://github.com/jakubholynet/blog/blob/master/miniprojects/jboss-custom-login/src/main/java/custom/MySimpleUsernamePasswordLoginModule.java\">MySimpleUsernamePasswordLoginModule</a>, follow the deployment instructions in the <a href=\"https://github.com/jakubholynet/blog/blob/master/miniprojects/jboss-custom-login/README.md\">README</a>.",
  "excerpt": ""
 },
 {
  "title": "How to Set JVM Memory for Clojure REPL in Emacs (clojure-jack-in, clojure-swank)",
  "published": "2012-06-30 17:57:50",
  "postType": "post",
  "slug": "/2012/06/30/how-to-set-jvm-memory-for-clojure-repl-in-emacs-clojure-jack-in-clojure-swank/",
  "status": "publish",
  "tags": [
   "clojure",
   "emacs"
  ],
  "categories": [
   "Tools"
  ],
  "content": "How to increase heap size for Clojure REPL started from Emacs, either standalone or as a part of a project.\r\n<h2>1. Clojure REPL Started for a Lein Project</h2>\r\nIf you have a Leiningen 2.0 project and start Clojure REPL for it in Emacs via <code>M-x clojure-jack-in</code> then you can set JVM arguments such as heap size in the <code>project.clj</code>:<br><br><pre><code>\r\n(defproject cascalog-comoyo &quot;0.1.0-SNAPSHOT&quot;\r\n; ...\r\n:jvm-opts [&quot;-Xmx768M&quot;])\r\n</code></pre>\r\n<h2>2. Clojure REPL Started Outside of Lein</h2>\r\nIf you use <a href=\"http://jakemccrary.com/blog/2010/12/07/quickily-starting-a-powerful-clojure-repl/\">Jake McCrary's clojure-swank</a> operation to start Clojure REPL in Emacs without having a Leiningen project then you can set JVM options by adding them to the shell-command call in clojure-swank's definition:<br><br><pre><code>\r\n...\r\n(shell-command &quot;JAVA_OPTS='-Xmx768M' ~/.lein/bin/swank-clojure &amp;&quot; buffer))\r\n...\r\n</code></pre>",
  "excerpt": ""
 },
 {
  "title": "Testing Zabbix Trigger Expressions",
  "published": "2012-07-02 09:18:33",
  "postType": "post",
  "slug": "/2012/07/02/testing-zabbix-trigger-expressions/",
  "status": "publish",
  "tags": [
   "monitoring",
   "ops",
   "zabbix"
  ],
  "categories": [
   "Testing",
   "Tools"
  ],
  "content": "When defining a Zabbix (1.8.2) trigger e.g. to inform you that there are errors in a log file, how do you verify that it is correct? As somebody recommended in a forum, you can use a <a href=\"http://www.zabbix.com/documentation/1.8/manual/config/items#calculated_items\">Calculated Item</a> with a similar expression (the syntax is little different from triggers). Contrary to triggers, the value of a calculated item is easy to see and the historical values are stored so you can check how it evolved. If your trigger expression is complex the you can create multiple calculated items, one for each subexpression.<br><br><!--more-->\r\n<h2>Example</h2>\r\nIf we have a log item that sends us data whenever the text \"ERROR\" appears in a log line and the corresponding trigger expected to fire if we have got any data from the item in the last 600 sec (nodata() returns 1 if there indeed was no data):<br><br><pre><code>{hive.example.com:log[&quot;/tmp/ada/hive.log&quot;,&quot;ERROR&quot;,,20].nodata(600)}=0</code></pre><br><br>Then we could test it with a calculated item with the expression<br><br><pre><code>nodata(&quot;hive.example.com:log[\\&quot;/tmp/ada/hive.log\\&quot;,\\&quot;ERROR\\&quot;,,20]&quot;, 600)</code></pre><br><br>(Notice that the function comes first, taking the host:item as its 0th parameter and that this is enclosed with \"\", escaping any nested \" with \\.)<br><br>The value of the calculated item will be re-checked every &lt;update interval&gt; (independent on whether the source item changed or not) and stored, in this case it will either thave the value of 0 or 1. We can also construct more complex expressions with &amp;, + etc. similarly to trigger expressions.",
  "excerpt": ""
 },
 {
  "title": "Notify on Errors in a Log File with Zabbix 1.8",
  "published": "2012-07-03 15:37:33",
  "postType": "post",
  "slug": "/2012/07/03/notify-on-errors-in-a-log-file-with-zabbix-1-8/",
  "status": "publish",
  "tags": [
   "monitoring",
   "ops",
   "zabbix"
  ],
  "categories": [
   "Tools"
  ],
  "content": "Situation: You want to get notified when a log entry marked ERROR appears in a log file. You want the corresponding trigger to reset back to the OK state if there are no more errors for 10 minutes. (This post assumes certain familiarity with Zabbix UI.)<br><br><!--more-->\r\n<h2>Solution</h2>\r\n<h3>Create log item sending error log lines</h3>\r\nCreate a new item with\r\n<ul>\r\n\t<li>Type: Zabbix agent (active)\r\n<ul>\r\n\t<li>It must be \"Zabbix agent (active)\" because it isn't pulled by the server in regular intervals but pushed by the agent whenever there is a new (matching) log line.</li>\r\n</ul>\r\n</li>\r\n\t<li>Key: log[\"/tmp/ada/hive.log\",\"ERROR\",,20]\r\n<ul>\r\n\t<li>You could also use logrt if you have rotating logs (zabbix would only read the latest or all, as you want)</li>\r\n\t<li>Here we specify that we only want to send lines that contain the regular expression ERROR, we could also have a more complex pattern such as \"(ERRORS|WARNINGS)\". We assume that there are many uninteresting log lines and don't want to send those unnecessarily over the network.</li>\r\n</ul>\r\n</li>\r\n\t<li>Type of information: Log</li>\r\n\t<li>Log time format: Optional, a pattern matching date+time info at the beginning of each line, f.ex. \"yyyy-MM-dd hh:mm:ss\" (you could use also any other character, f.ex. 'x', as a placeholder for timestamp-unrelated data preceeding the timestamp)</li>\r\n</ul>\r\n<h4>Troubleshooting:</h4>\r\nIf your item isn't receiving any data even though there are error entries in the log then enable detailed logging in Zabbix to verify that the agent and server haven't a problem. (If they do then the status of the item will be changed to \"Not supported\" by Zabbix.)<br><br>To enable logging, make sure there is DebugLevel=5 and LogFile=/var/log/zabbix-agent/zabbix_agentd.log (without a leading #)  in /etc/zabbix/zabbix_agentd.conf.<br><br>One possible cause of problem is if Hostname in /etc/zabbix/zabbix_agentd.conf and in the Zabbix UI differ, f.ex. if one of them is fully qualified and the other isn't.<br><br>If everything is OK then you should see a log like this:<br><br><pre><code>\r\n14187:20120626:085459.706 refresh_active_checks('10.2.0.83',10051)\r\n ...\r\n 14187:20120626:085459.869 Got [{\r\n        &quot;response&quot;:&quot;success&quot;,\r\n        &quot;data&quot;:[\r\n                {\r\n                        &quot;key&quot;:&quot;log[\\&quot;\\/tmp\\/ada\\/hive.log\\&quot;,\\&quot;ERROR\\&quot;,,20]&quot;,\r\n                        &quot;delay&quot;:&quot;30&quot;,\r\n                        &quot;lastlogsize&quot;:&quot;127180&quot;,\r\n                        &quot;mtime&quot;:&quot;0&quot;}]}]\r\n 14187:20120626:085459.869 In parse_list_of_checks()\r\n 14187:20120626:085459.869 In disable_all_metrics()\r\n 14187:20120626:085459.869 In add_check('log[&quot;/tmp/ada/hive.log&quot;,&quot;ERROR&quot;,,20]', 30, 127180, 0)\r\n...<br><br> 14187:20120626:085530.156 In process_active_checks('10.2.0.83',10051)\r\n 14187:20120626:085530.156 In process_log() filename:'/tmp/ada/hive.log' lastlogsize:186157\r\n</code></pre>\r\n<h3>Create a trigger that fires if it receives any data from the item</h3>\r\nThe item only has data if there are any error logs. Therefore the trigger needs fire if it receives any data and get off if there hasn't been any new (error) data in a period, such as 600 sec. We would therefore create a trigger using the nodata(period) function that returns 1 if there indeed has been no new data in the period:\r\n<ul>\r\n\t<li>Expression: {myserver.example.com:log[\"/tmp/ada/hive.log\",\"ERROR\",,20].nodata(600)}=0</li>\r\n</ul>\r\n<h3>Create an action to send an e-mail</h3>\r\nThis is described well enough <a href=\"http://www.zabbix.com/documentation/pt/1.8/manual/config/actions\">in Zabbix documentation</a>. Basically you'd create an action with the condition Trigger = &lt;the name of the trigger created above&gt;. (And perhaps with \"and Trigger value = PROBLEM\".) You might also want to <a href=\"http://www.zabbix.com/documentation/1.8/manual/escalations_and_repeated_notifications\">set up escalation</a> to get reminder emails - perhaps after a growing delay - if the problem persists, i.e. if there is an error every 10 min or more often.\r\n<h2>Key points</h2>\r\n<ul>\r\n\t<li>Make sure to use Zabbix agent (active)</li>\r\n\t<li>If you aren't getting any data, enable and check the log. Make sure hostname in agent config and server match.</li>\r\n\t<li>Data are only sent when there is an error =&gt; use nodata(aPeriod) to automatically reset the trigger (if this is what you want)</li>\r\n</ul>",
  "excerpt": ""
 },
 {
  "title": "Book Review: Implementation Patterns",
  "published": "2012-07-05 08:33:38",
  "postType": "post",
  "slug": "/2012/07/05/book-review-implementation-patterns/",
  "status": "publish",
  "tags": [
   "book",
   "CleanCode",
   "design",
   "review"
  ],
  "categories": [
   "General"
  ],
  "content": "<em><a href=\"http://www.amazon.com/Implementation-Patterns-Kent-Beck/dp/0321413091/\">Implementation Patterns</a>, Kent Beck, 2007, ISBN 0321413091.</em>\r\n<div><br><br>Summary: Should you read the book? Yes, the chapter on principles and values is trully enlightening. The book in general contains pearls of wisdom hidden in the mud of \"I know that already, man.\" I would thus recommend <em>skimming through</em> the book and reading only the pieces matching your level and needs.<br><br>The book seems to be targeted a lot at Java beginners (especially the chapter on collections), going into otherwise unnecessary details, yet there are many valuable advises of which some can only be appreciated by somebody with multiple years of professional programming experience. It thus seems to me that the book isn't a perfect match for anybody but everybody will find there many useful ideas. It would best be split in two.<br><br>An experienced developer will already know many of the patterns though it's perhaps useful to see them named and described explicitly and listed next to each - it helps to be aware and clearer of what you do and why you do it.<br><br></div>\r\n<div>I'd absolutely recommend everybody to read the chapter A Theory of Programming, explaining Kent's style of programming and the underlying key <a href=\"http://blog.iterate.no/2012/06/20/programming-like-kent-beck/\">values of communication, simplicity and flexibility</a> as well as the more concrete principles (local consequence, minimize repetition, logic and data together, symmetry, declarative expression, co-locating data and logic having the same rate of change). Also in the rest of the book there are valuable ideas that it would be a pity to miss. I list below some of those that I found particularly interesting.</div>\r\n<div></div>\r\n<div><!--more--></div>\r\n<div>\r\n<h2>Selected Quotes etc.</h2>\r\n<ul>\r\n\t<li>On the cost of software, maintenance, big up-front designs, communication: \"[..] the cost of software maintenance is much higher than the cost of initial development. [..] Maintenance is expensive because understanding existing code is time-consuming and error-prone.\" p.19\r\n<ul>\r\n\t<li>\"One strategy for reducing overall cost is to invest more in initial development in hope of reducing or eliminating the need for maintenance. Such efforts have generally failed to reduce overall costs. When code needs to change in unanticipated ways, no amount of forethought can perfectly prepare the code for change. The premature attempts to make the code general enough to meet future needs often interfere with the unanticipated changes that turn out to be necessary.\" p.19 The future is uncertain and money we've now are generally more valuable than those we might save in the future.</li>\r\n\t<li>\"My strategy for reducing overall costs is to ask all programmers to address the cost of understanding code during the maintenance phase by focusing on communicating, programmer-to-programmer.\" p.20</li>\r\n\t<li>\"[..] the implementation patterns are focused on ways to gain immediate benefit while setting up clean code for ease of future development.\"</li>\r\n</ul>\r\n</li>\r\n\t<li>Flexibility (and simplicity): \"Making workable decisions today and maintaining the flexibility to change your mind in the future is a key to good software development.\" p.45</li>\r\n\t<li>Aesthetics and programming: \"Sometimes I feel silly introducing methods 'just' to satisfy an 'aesthetic' urge like symmetry. Aesthetics go deeper than that. [..] Once you have cultivated your sense of aesthetics of code, the aesthetic impression you receive of your code is valuable feedback about the quality of the code.\" p.68</li>\r\n\t<li>Why revealing intent and hiding implementation is important: \"The distinction between intention and implementation [..] It is what allows you to understand a computation first in essence and later, if necessary, in detail.\" p.69\r\n(=&gt; the \"explaining message\" pattern: send first a message (call method) named after the problem you're solving which in turn sends a message named after how it's solved)</li>\r\n\t<li>\"Compose methods based on facts, not speculation. Get your code working, then decide how it should be structured.\" p.78 - you learn only during the implementation what pieces you need and how the best fit them together\r\n<ul>\r\n\t<li>Similarly: \"Try moving the logic and seeing if it reads more clearly. Sometimes these moves violate your preconception about which object is responsible for what part of a computation. Believing and acting on the evidence of your eyes generally improves the design.\" p.94</li>\r\n</ul>\r\n</li>\r\n\t<li>Method naming: \"Why was this method invoked and not some other? [..] The calling method should be telling a story. Name methods so they help tell the story.\" p.79</li>\r\n\t<li>Final methods (and classes): Use only when overriding the method would lead to serious consequences. \"I don't use final myself, and I have occasionally been frustrated when encountering final methods when I had legitimate reason to override a method.\" p.81 (JH: Final might often prevent testing or complicate it unnecessarily.)</li>\r\n\t<li>\"Following the principle of putting logic and data together, the need for public- or package-visible getting methods is a clue that logic should be elsewhere.\" (though there are some exceptions) p.95</li>\r\n\t<li>Setters: The name should be written from the client code's perspective, w.r.t. what it wants to achieve, not how =&gt; .centered() is better than setJustification(CENTERED).</li>\r\n\t<li>About safe copies (return new List(instanceList)): Use only rarely, when really needed, not as a part of the core semantics. \"Immutable objects and composed methods provide simpler, more communicative interfaces that are less prone to error.\" p.98</li>\r\n\t<li>\"Learning how to use patterns needs to be followed by learning when to use them and when to leave them in the bag.\" p.131</li>\r\n</ul>\r\n<h2>Other Highlights</h2>\r\n<ul>\r\n\t<li>Design: when to use an interface (-: can't add methods) and when to use an abstract class (-: more coupled, single inheritance). Use \"versioned interface\" (f.ex. \"interface MyServiceEnhanced extends MyService\") when you need to add a method to an interface but cannot force existing clients to update</li>\r\n\t<li>Design patterns for expressing clearly what is similar and what is different</li>\r\n\t<li>Guard Clause: Don't mix exceptional flows with the main logic flow, i.e. have simple checks like \"if (param1 == null) throw new IllegalArgumentExc.(..);\" at the beginning instead of (nested?!) if-else. (JH: I even prefer to drop {..} here since guard statements are and always should be one-liners and are thus easier to spot and read.)</li>\r\n\t<li>The chapter about evolving frameworks was also quite interesting</li>\r\n\t<li>Simple Superclass Name (p.23): Important classes should have one-word names. Find rich metaphors to make even the short names expressive enough. Strike balance between brevity and expressiveness in class names.</li>\r\n</ul>\r\n</div>",
  "excerpt": ""
 },
 {
  "title": "Most interesting links of July ''12",
  "published": "2012-07-31 21:59:19",
  "postType": "post",
  "slug": "/2012/07/31/most-interesting-links-of-july-12/",
  "status": "publish",
  "tags": [
   "agile",
   "design"
  ],
  "categories": [
   "General",
   "Tools",
   "Top links of month"
  ],
  "content": "A brief one due to (thanks to?) holiday and an accompanying surprising lack of enthusiasm for the technical stuff.\r\n<h2>Recommended Readings</h2>\r\n<ul>\r\n\t<li><a href=\"http://blog.borud.no/2010/11/microdesign-and-red-flags.html\">Microdesign and red flags</a> - why using an \"else\" or returning a boolean as a success indicator should rise a red flag and make you think what you're trying to achieve and whether there aren't better options (often there are - using guard conditions instead of else and throwing an exception or returning a detailed status object instead of a boolean)</li>\r\n\t<li><a href=\"http://www.ibm.com/developerworks/java/library/j-eaed19/index.html\">Evolutionary architecture and emergent design: Emergent design in the wild</a> - the final article in Neal Ford's highly interesting<a href=\"http://www.ibm.com/developerworks/views/java/libraryview.jsp?search_by=evolutionary+architecture+emergent+design:\"> series on emergent design</a>, discussing how to recognize the \"last responsible moment,\" the problems with big up-front designs due to \"unknown unknowns\" etc., highly recommended</li>\r\n</ul>\r\n<h2>Useful Tools</h2>\r\n<ul>\r\n\t<li><a href=\"https://github.com/capistrano/capistrano/\">Capistrano</a> - Ruby ops tool usable to execute shell commands on multiple servers via SSH (originally intended for deployment of RoR apps). Cap shell enables execution of commands on all/selected servers interactively.\r\nQuick start: gem install capistrano; echo \"role :all, srv1.example.com, srv2,example.com\" &gt; Capfile; cap invoke COMMAND=\"hostname\" SUDO=1; cap shell\r\nAlternatives: ClusterSSH, Fabric.</li>\r\n</ul>",
  "excerpt": ""
 },
 {
  "title": "How to Add MapRed-Only Node to Hadoop",
  "published": "2012-08-08 13:10:24",
  "postType": "post",
  "slug": "/2012/08/08/how-to-add-mapred-only-node-to-hadoop/",
  "status": "publish",
  "tags": [
   "bigdata",
   "hadoop",
   "ops"
  ],
  "categories": [
   "General",
   "Tools"
  ],
  "content": "I was surprised not to be able to google an answer to this so I want to record my findings here. To add (a.k.a. commision) a node to Hadoop cluster that should be used only for map-reduce tasks and not for storing data, you have multiple options:\r\n<ol>\r\n\t<li>Do not start the datanode service on the node</li>\r\n\t<li>If you've configured Hadoop to allow only nodes on its whitelist files to connect to it then add it to the file pointed to by the <a href=\"http://hadoop.apache.org/common/docs/r1.0.1/mapred-default.html#mapred.hosts\">property mapred.hosts</a> but not to the file in <a href=\"hadoop.apache.org/common/docs/r1.0.1/hdfs-default.html#dfs.hosts\">dfs.hosts</a>.</li>\r\n\t<li>Otherwise add the node to the DFS' blacklist, i.e. file pointed to by the property <a href=\"http://hadoop.apache.org/common/docs/r1.0.1/hdfs-default.html#dfs.hosts.exclude\">dfs.hosts.exclude</a> and execute <code>hadoop dfsadmin -refreshNodes</code> on the namenode to apply it.</li>\r\n</ol>\r\n<!--more--><br><br>#3 is what I did as we weren't using #2.<br><br>When the datanode and tasktracker services start on the new node, they will try to register with the namenode and jobtracker. If the node is on the DFS exclude list then its datanode will not be allowed to connect and consequently won't be used to store data while map-reduce tasks will be allowed to run on it.<br><br>You can set (previously unset) property dfs.hosts.exclude in hdfs-site.xml without restarting the namenode service, it will pick it up anyway (likely when running -refreshNodes). Notice that it should contain path to a file on the local filesystem at the namenode server.",
  "excerpt": ""
 },
 {
  "title": "Zabbix: Fixing Active Checks to Work With Zabbix Proxy",
  "published": "2012-08-08 15:32:23",
  "postType": "post",
  "slug": "/2012/08/08/zabbix-fixing-active-checks-to-work-with-zabbix-proxy/",
  "status": "publish",
  "tags": [
   "monitoring",
   "ops",
   "zabbix"
  ],
  "categories": [
   "General",
   "Tools"
  ],
  "content": "We've recently changed our Zabbix 1.8.1 setup to include Zabbix Proxy, which broke all our active checks (f.ex. monitoring of log files). The solution seems to be having the proxy first, before the Zabbix Server, in the Zabbix Agent's config parameter <em>Server</em>, i.e. \"Server=&lt;proxy ip&gt;,&lt;server ip&gt;\".<br><br><!--more--><br><br>After the introduction of the proxy, retrieval of active checks by the agent started to fail:<br><br><pre><code>\r\n2977:20120803:142521.844 zabbix_agentd started. Zabbix 1.8.1 (revision 9702).\r\n...\r\n2984:20120803:142521.850 zabbix_agentd active check started [10.1.0.83:10051]\r\n2984:20120803:142522.028 No active checks on server: host [myserver.example.com] not found\r\n</code></pre><br><br>\r\nI know that this happens if the name of the host in the Zabbix Server UI differs from the <em>Hostname</em> in /etc/zabbix/zabbix_agentd.conf (myserver.example.com in this case) and indeed there was a difference - the name was shown as \"my-zabbix-proxy.example.com:myserver.example.com\" (my-zabbix-proxy.example.com is the hostname of the new Zabbix Proxy).<br><br>However it wasn't possible to change the name, when clicking on it (Configuration -&gt; Hosts -&gt; find the host -&gt; click its name) to edit it, the proxy prefix there isn't editable. I tried to change <em>Hostname</em> in zabbix_agentd.conf to  \"my-zabbix-proxy.example.com:myserver.example.com\" but to no avail.<br><br>Finally I tried to switch the order of the server and proxy IPs in the Server param so that the proxy is first and thus the agent retrieves its active checks from the proxy instead of from the server, which fixed the problem.<br><br>From /var/log/zabbix-agent/zabbix_agentd.log after the change (and DebugLevel=4 as the default level of 3 only showed \"active check started [10.2.0.150:10051]\" followed by \"collector started\" but no details of the checks):<br><br><pre><code>\r\n25382:20120808:145557.663 refresh_active_checks('10.2.0.150',10051)\r\n25382:20120808:145557.664 Sending [{\r\n  &quot;request&quot;:&quot;active checks&quot;,\r\n  &quot;host&quot;:&quot;myserver.example.com&quot;}]\r\n25382:20120808:145557.664 Before read\r\n25382:20120808:145557.669 Got [{\r\n  &quot;response&quot;:&quot;success&quot;,\r\n  &quot;data&quot;:[\r\n    {\r\n      &quot;key&quot;:&quot;log[\\&quot;\\/tmp\\/ada\\/hive.log\\&quot;,\\&quot;ERROR\\&quot;,,20]&quot;,\r\n      &quot;delay&quot;:&quot;30&quot;,\r\n      &quot;lastlogsize&quot;:&quot;284542&quot;,\r\n      &quot;mtime&quot;:&quot;0&quot;}]}]\r\n</code></pre>",
  "excerpt": ""
 },
 {
  "title": "You''re Writing the Wrong Software - You Never Know What Users Want Until You Ask Them",
  "published": "2012-08-12 19:04:22",
  "postType": "post",
  "slug": "/2012/08/12/youre-writing-the-wrong-software-you-never-know-what-users-want-until-you-ask-them/",
  "status": "publish",
  "tags": [
   "leanstartup",
   "methodology"
  ],
  "categories": [
   "General"
  ],
  "content": "Too often companies and IT departments believe that they know what software they should create. However users often need and want something different than you believe, even if you're a domain expert yourself. My colleague and dear friend Ivar had exactly this experience when designing a meal planning tool for his girlfriend and himself. He knew everything perfectly - the previous tool they've used (a paper on the fridge), the problem domain, the users. Yet the first prototype tested did not at all match the ideas of what he thought was needed.<br><br><!--more--><br><br>If the best possible expert isn't able to predict user needs even in such a simple domain, how can we, in our real-world and large-scale projects? Thus - unless you are in Henry Ford's shoes - you have to experiment and learn what the real need and value is based on actual users. The <a href=\"http://theleanstartup.com/principles\">Lean Startup methodology</a> provides many useful ideas and tools for making your assumptions explicit and verifying them as quickly and as cheaply as possible (f.ex. the <a href=\"http://www.ashmaurya.com/2012/02/why-lean-canvas/\">lean canvas</a>) so that when you finish your product, it will likely be something pretty different from what you conceived but it will be needed, liked and used.<br><br>Don't be mislead by the name lean startup - the methodology is equally valuable for established companies that need to innovate (which is, in IT, basically everybody).<br><br>Recommended books: <a href=\"http://www.amazon.com/The-Lean-Startup-Entrepreneurs-Continuous/dp/0307887898\">Lean Startup</a>, <a href=\"http://www.amazon.com/Running-Lean-Iterate-Works-Series/dp/1449305172\">Running Lean</a>.",
  "excerpt": ""
 },
 {
  "title": "Minimalistic Practical Introduction to Puppet (Not Only) For Vagrant Users",
  "published": "2012-08-13 09:36:35",
  "postType": "post",
  "slug": "/2012/08/13/minimalistic-practical-introduction-to-puppet-for-vagrant-users/",
  "status": "publish",
  "tags": [
   "DevOps",
   "introduction",
   "puppet"
  ],
  "categories": [
   "General",
   "Tools"
  ],
  "content": "I couldn't find any good, brief, practical introduction into Puppet that gives you basic working knowledge in minimal time, so here it is. You will learn how to do the elementary things with Puppet - install packages, copy files, start services, execute commands. I won't go into Puppet installation, nodes, etc. as this introduction focuses on the users of <a href=\"http://vagrantup.com/\">Vagrant</a>, which comes with Puppet pre-installed and working in the serverless configuration.<br><br><!--more-->\r\n<h2>What is Puppet?</h2>\r\nPuppet is a <em>provisioner</em> - a cross-OS software that sets up operating systems by installing and configuring software etc., based on some form of instructions. Here as an example of such instructions - a <em>manifest</em> - for Puppet:<br><br><pre><code>\r\n# my_sample_manifest.pp\r\nclass my_development_env {\r\n  package {'vim': ensure =&gt; 'present' }\r\n}<br><br># Apply it\r\ninclude my_development_env\r\n</code></pre><br><br>Running it with\r\n<pre>puppet apply --verbose --debug my_sample_manifest.pp</pre>\r\nwould install vim on the system.<br><br>Notice that while Puppet can be run only once, it is generally intended to be run repeatedly to fetch and apply the latest configuration (usually from some source code management system such as Git). Therefore all its operations must be idempotent - they can be performed safely multiple times.\r\n<h2>The Puppet Configuration File a.k.a. Manifest</h2>\r\nPuppet manifests are written in a Ruby-like syntax and are composed of the declaration of <em>\"resources\"</em> (packages, files, etc.), grouped optionally into one or more <em>classes</em> (i.e. templates that can be applied to a system). Each concrete resource has a title (e.g. 'vim') followed by a colon and comma-separated pairs of property =&gt; value. You may have multiple resources of the same type (e.g. package) as long as they have different titles.<br><br>The property values are most often strings, enclosed by 'single quotes' or alternatively with \"double quotes\" if you want variables within them replaced with their values. (A variable starts with the dollar sign.)<br><br>Instead of a name or a value you can also use an array of titles/values, enclosed with [  ].<br><br>(Note: It is a common practice to leave a trailing comma behind the last property =&gt; value pair.)<br><br>You can group resources within classes (<em>class my_class_name { ... }</em>) and then apply the class with either include (<em>include my_class_name</em>) or with the more complex class (<em>class { 'my_class_name': }</em>). You can also include a class in another class like this.\r\n<h2>Doing Things With Puppet</h2>\r\n<h3>Installing Software With Package</h3>\r\nThe most used way to install software packages is with this simple usage of <a href=\"http://docs.puppetlabs.com/references/latest/type.html#package\">package</a>:<br><br><pre><code>\r\npackage {['vim', 'apache2']: ensure =&gt; 'present' }\r\n</code></pre><br><br>Puppet supports various package providers and by default picks the system one (such as apt at Ubuntu or rpm at RedHat). You can explicitly state another supported package provider such as Ruby's gem or Python's pip.<br><br>You can also request a particular version of the package (if supported) with ensure =&gt; '&lt;version&gt;' or to the latest one with ensure =&gt; 'latest' (this will also reinstall it whenever a new version is released and Puppet runs). In the case of ensure =&gt; 'present' (also called 'installed'): if the package already is installed then nothing happens otherwise the latest version is installed.\r\n<h3>Copying and creating Files With File</h3>\r\nCreate a file with content specified in-line:<br><br><pre><code>\r\nfile {'/etc/myfile.example':\r\n  ensure =&gt; 'file',\r\n  content =&gt; &quot;line1\\nline2\\n&quot;,\r\n}\r\n</code></pre><br><br>Copy a directory including its content, set ownership etc.:<br><br><pre><code>\r\nfile {'/etc/apache2':\r\n  ensure  =&gt; 'directory',\r\n  source  =&gt; '/vagrant/files/etc/apache2',\r\n  recurse =&gt; 'remote',\r\n  owner   =&gt; 'root',\r\n  group   =&gt; 'root',\r\n  mode    =&gt; '0755',\r\n}\r\n</code></pre><br><br>This requires that the directory /vagrant/files/etc/apache2 exists. (Vagrant automatically shares the directory with the Vagrantfile as /vagrant in the VM so this actually copies files from the host machine.With the master-agent setup of Puppet you can also get files remotely, from the master, using the puppet:// protocol in the source.)<br><br>You can also create files based on ERB <a href=\"http://docs.puppetlabs.com/guides/templating.html\">templates</a> (with source =&gt; template('relative/path/to/it')) but we won't discuss that here.<br><br>You can also create symlinks (with ensure =&gt; link, target =&gt; 'path/to/it') and do other stuff, reader more in the <a href=\"http://docs.puppetlabs.com/references/latest/type.html#file\">file resource documentation</a>.\r\n<h3>(Re)Starting Daemons with Service</h3>\r\nWhen you've installed the necessary packages and copied their configuration files, you'll likely want to start the software, which is done with <a href=\"http://docs.puppetlabs.com/references/latest/type.html#service\">service</a>:<br><br><pre><code>\r\nservice { 'apache2':·\r\n  ensure =&gt; running,·\r\n  require =&gt; Package['apache2'],\r\n}\r\n</code></pre><br><br>(We will talk about require later; it makes sure that we don't try to start Apache before it's installed.)<br><br>On Linux, Puppet makes sure that the service is registered with the system to be started after OS restart and starts it. Puppet reuses the OS' support for services, such as the service startup scripts in /etc/init.d/ (where service = script's name) or Ubuntu's upstart.<br><br>You can also declare your own start/stop/status commands with the properties of the same names, f.ex. start =&gt; '/bin/myapp start'.\r\n<h3>When Everything Fails: Executing Commands</h3>\r\nYou can also execute any shell command with <a href=\"http://docs.puppetlabs.com/references/latest/type.html#exec\">exec</a>:<br><br><pre><code>\r\nexec { 'install hive':\r\n  command =&gt; 'wget http://apache.uib.no/hive/hive-0.8.1/hive-0.8.1-bin.tar.gz -O - | tar -xzC /tmp',\r\n  creates =&gt; '/tmp/hive-0.8.1-bin',\r\n  path =&gt; '/bin:/usr/bin',\r\n  user =&gt; 'root',\r\n}\r\n</code></pre><br><br>Programs must have fully qualified paths or you must specify where to look for them with <em>path</em>.<br><br>It is critical that all such commands can be run multiple times without harm, i.e., they are idempotent. To achieve that you can instruct Puppet to skip the command if a file exists with <em>creates</em> =&gt; ... or if a command succeeds or fails with <em>unless</em>/<em>onlyif</em>.<br><br>You can also run a command in reaction to a change to a dependent object by combining <em>refreshonly</em> and <em>subscribe</em>.\r\n<h3>Other Things to Do</h3>\r\nYou can create users and groups, register authorized ssh keys, define cron entries, mount disks and much more - check out <a href=\"http://docs.puppetlabs.com/references/latest/type.html\">Puppet Type Reference</a>.\r\n<h3>Enforcing Execution Order With Require, Before, Notify etc.</h3>\r\nPuppet processes the resources specified in a random order, not in the order of specification. So if you need a particular order - such as installing a package first, copying config files second, starting a service third - then you must tell Puppet about these dependencies. There are multiple ways to express dependencies and several types of dependencies:\r\n<ul>\r\n\t<li>Before and require - simple execution order dependency</li>\r\n\t<li>Notify and subscribe - an enhanced version of before/require which also notifies the dependent resource whenever the resource it depends on changes, used with refreshable resources such as services; typically used between a service and its configuration file (Puppet will refresh it by restarting it)</li>\r\n</ul>\r\nEx.:<br><br><pre><code>\r\nservice { 'apache2':\r\n  ensure =&gt; running,\r\n  subscribe =&gt; File['/etc/apache2'],\r\n  require =&gt; [ Package['apache2'], File['some/other/file'] ],\r\n}\r\n</code></pre><br><br>Notice that contrary to resource <em>declaration</em> the resource <em>reference</em> has the resource name uppercased and the resource title is within [].<br><br>Puppet is clever enough to derive the \"require\" dependency between some resource that it manages such as a file and its parent folder or an exec and its user - this is well documented for each resource in the <a href=\"docs.puppetlabs.com/references/latest/type.html\">Puppet Type Reference</a> in the paragraphs titled \"Autorequires:\".<br><br>You can also express dependencies between individual classes by defining <a href=\"http://www.personal.psu.edu/ryc108/blogs/puppetmaster/2010/10/automating-shibboleth-idp-builds-using-stages.html\">stages</a>, assigning selected classes to them, and declaring the ordering of the stages using before &amp; require. Hopefully you won't need that.\r\n<h2>Bonus Advanced Topic: Using Puppet Modules</h2>\r\nModules are self-contained pieces of Puppet configuration (manifests, templates, files) that you can easily include in your configuration by placing them into Puppet's manifest directory. Puppet automatically find them and makes their classes available to you for use in your manifest(s). You can download modules from the <a href=\"http://forge.puppetlabs.com/\">Puppet Forge</a>.<br><br><a href=\"http://forge.puppetlabs.com/puppetlabs/mysql\">See the examples on the puppetlabs/mysql module page</a> about how such a module would be used in your manifest.<br><br>With Vagrant you would instruct Vagrant to provide modules from a particular directory available to Puppet with<br><br><pre><code>\r\nconfig.vm.provision :puppet,\r\n  :module_path =&gt; &quot;my_modules&quot; do |puppet|\r\n        puppet.manifest_file = &quot;my_manifest.pp&quot;\r\nend\r\n</code></pre><br><br>(in this case you'd need manifest/ next to your Vagrantfile) and then in your Puppet manifest you could have <em>class { 'mysql': }</em> etc.\r\n<h2>Where to Go Next?</h2>\r\nThere are some things I haven't covered that you're likely to encounter such as <a href=\"http://docs.puppetlabs.com/learning/variables.html\">variables and conditionals</a>, built-in <a href=\"http://docs.puppetlabs.com/references/latest/function.html\">functions</a> such as template(..), <a href=\"http://docs.puppetlabs.com/guides/parameterized_classes.html\">parametrized classes</a>, class inheritance. I have also skipped all master-agent related things such as nodes and facts. It's perhaps best to learn them when you encounter them.<br><br>In each case you should have a look at the <a href=\"http://docs.puppetlabs.com/references/latest/type.html\">Puppet Type Reference</a> and if you have plenty of time, you can start reading the <a href=\"http://docs.puppetlabs.com/guides/language_guide.html\">Language Guide</a>. In the on-line <a href=\"http://www.puppetcookbook.com/\">Puppet CookBook</a> you can find many useful snippets. You may also want to download the <a href=\"http://docs.puppetlabs.com/learning/#get-equipped\">Learning Puppet VM</a> to experiment with Puppet (or just <a href=\"https://github.com/jakubholynet/presentations/tree/master/CommitOnDayOneThanksToVagrantAndPuppet\">try Vagrant</a>).",
  "excerpt": ""
 },
 {
  "title": "Most interesting links of August ''12",
  "published": "2012-08-31 21:59:46",
  "postType": "post",
  "slug": "/2012/08/31/most-interesting-links-of-august-12/",
  "status": "publish",
  "tags": [
   "agile",
   "BI",
   "http",
   "human",
   "network",
   "proxy"
  ],
  "categories": [
   "General",
   "Tools",
   "Top links of month"
  ],
  "content": "<h2>Recommended Readings</h2>\r\n<ul>\r\n\t<li><a href=\"http://www.mountaingoatsoftware.com/articles/how-to-fail-with-agile\">How To Fail With Agile:Twenty Tips to Help You Avoid Success</a> - a great overview of ways people may make agile projects and initiatives fail - use them to either avoid the failure or to make it certain, according to your attitude towards agile</li>\r\n\t<li><a href=\"http://vim-adventures.com/\">vim-adventures.com</a>: Learning Vim keys in an entertaining way by playing an on-line 2D game. A brilliant idea!</li>\r\n\t<li><a href=\"http://architects.dzone.com/articles/search-better-big-data\">The Search for a Better BIG Data Analytics Pipeline</a> - how to use big data and analytics on it in a company. Big data = lot of data, simple processing; deep analysis = representative, small sample of data (no need for all), advanced techniques. Big data can provide input for analysis.</li>\r\n</ul>\r\n<h2>Links to Keep</h2>\r\n<ul>\r\n\t<li>Pat Kua's <a href=\"http://www.thekua.com/atwork/category/onboarding-strategies/\">Onboarding Strategies series</a> - tips for getting new people onto your team as a tech lead and making them productive quickly. He also wrote the InfoQ article <a href=\"http://www.infoq.com/articles/pat-kua-onboarding-new\">A Leaner Start: Reducing Team Setup Times</a> based on the series. Some posts: Catalogue of patterns applied, Airing .. about feedback meetings, Pair programming, Preparation e-mail, Domain driven design and readable code, Tech huddles (what-we-learned session every 2nd day), Transparent technical debt, Visible architecture, Big vision business problem.</li>\r\n</ul>\r\n<h2>Useful Tools</h2>\r\n<ul>\r\n\t<li><a href=\"https://www.owasp.org/index.php/OWASP_Hatkit_Proxy_Project\">OWASP Hatkit Proxy</a>: TCP/HTTP proxy intended for developers that can intercept and modify requests and store parsed communication into MongoDB for later exploration. You can define what (not) to store/intercept with white- (black-)lists. Syntax highlighting, Swing UI etc.</li>\r\n\t<li><a href=\"http://queue.acm.org/detail.cfm?id=1483108&amp;CFID=1014150&amp;CFTOKEN=54279563\">Using Doxygen to understand a code base</a> - Doxygen can generate a full cross reference of source code, class diagram, caller and call graphs for many languages including Java, PHP, C.</li>\r\n</ul>\r\n<h2>Interesting Quotes</h2>\r\n<blockquote>Our standards by default exclude comments where possible replaced by representing as much intent as possible in the code itself. We focus on what it does and why. I’ve found “What” tends to be best represented by production code, whilst “Why” is better explained in tests because you can better represent different contexts there.\r\n- <em>Pat Kua: <a href=\"http://www.thekua.com/atwork/category/onboarding-strategies/\">Onboarding strategy: Domain driven design and readable code</a></em></blockquote>",
  "excerpt": ""
 },
 {
  "title": "Recommended Book: Real World Java EE Night Hacks by Adam Bien",
  "published": "2012-08-13 19:19:14",
  "postType": "post",
  "slug": "/2012/08/13/recommended-book-real-world-java-ee-night-hacks-by-adam-bien/",
  "status": "publish",
  "tags": [
   "book",
   "development",
   "java",
   "javaEE",
   "review"
  ],
  "categories": [
   "General",
   "j2ee",
   "Languages"
  ],
  "content": "<em>Real World Java EE Night Hacks - Dissecting the Business Tier, Adam Bien, 2011, ISBN 9780557078325.</em><br><br>I highly recommend this very thin and down-to-the-earth-practical book to everybody interested in back-end Java (a basic knowledge of servlets, Java ORM, and REST might be useful). The book evolves around a small but realistic project (<a href=\"http://java.net/projects/x-ray/\">X-Ray</a>), which we follow from the inception through couple of iterations til the end. Bien shows us how lean Java EE can be, how to profit from the functionality that it offers, and how these pieces of functionality fit together to deliver something useful. He actually introduces a complete Java EE development environment including continuous integration (CI), code quality analysis, functional and stress testing.<br><br>Some of the things that I appreciate most in the book is that we can follow author's decision process with respect to implementation options (such as SOAP vs. REST vs. Hessian etc., a REST library vs. sockets, or when (not) to use asynchronous processing) and that we can see the evolution of the design from an initial  version that failed through cycles of growing and refactoring and eventually introducing new technologies and patterns (events, configuration over convention) to support new and increased requirements.<!--more--><br><br>One of the most interesting parts for me was the chapter about stress testing (using jMeter) and mainly the fact that it is introduced as a common part of a development process right from the start, which is how it should be bad sadly usually isn't. There are some good tips about what to measure and how to do it regularly.<br><br>I'd be also glad to see more often the full CI pipeline, where build and unit tests are followed by integration tests, deployment to a freshly created server, functional tests, and the computation of Sonar metrics.<br><br>Other highlights: Leveraging Scala's productivity for writing unit tests with ScalaTest (while the application itself is in pure Java), using async/threads for reliability, occasionally writing low-level but simple stuff oneself rather than adding a heavy-weight dependency (f.ex. a simple socket-based REST client), a pragmatic discussion of availability, robustness, and consistency w.r.t. caching, a discussion of the importance of timeouts for robustness (to avoid dead/live-locks).<br><br>The only thing I'd change is the Fitnesse functional test which is too low-level, too script-ish for my taste (though it works perfectly for the Bien's needs). I'd prefer something like\r\n<table border=\"1px\">\r\n<tbody>\r\n<tr>\r\n<th>URLs accessed</th>\r\n<th>Total hits</th>\r\n<th>Today hits</th>\r\n</tr>\r\n<tr>\r\n<td></td>\r\n<td>0</td>\r\n<td>0</td>\r\n</tr>\r\n<tr>\r\n<td>/entry/post_one\r\n/entry/post_two</td>\r\n<td>1</td>\r\n<td>1</td>\r\n</tr>\r\n<tr>\r\n<td>/entry/post_one\r\n/entry/post_two\r\n/entry/post_three</td>\r\n<td>3</td>\r\n<td>3</td>\r\n</tr>\r\n</tbody>\r\n</table>\r\nA. Bien is clearly a very experienced and pragmatic developer, knowledgeable of Java [EE] - somebody <a href=\"http://www.adam-bien.com/roller/abien/\">worth following</a>.\r\n<blockquote>\"High availability and extreme consistency are overrated in the real world. Clients prescribe 24/7 availability for noncritical software without even thinking about the consequences.\" p.66<br><br>\"It is very typical to find aplication, JVM, and even operating system bugs during stress testing. The earlier in the software lifecycle such bugs appear, the easier is it to fix them.\" p.152</blockquote>\r\nCheck out the <a href=\"http://press.adam-bien.com/real-world-java-ee-night-hacks-dissecting-the-business-tier.htm\">book's home page</a> where you can find more details of the content and links for obtaining both the printed and electronic version (<a href=\"http://www.amazon.co.uk/Real-World-Night-Hacks-Dissecting-Business/dp/B004Z20A3G/ref=sr_1_1?ie=UTF8&amp;s=digital-text&amp;qid=1304622022&amp;sr=8-1\">kindle</a> / <a href=\"http://www.lulu.com/product/ebook/real-world-java-ee-night-hacks-dissecting-the-business-tier/15592362\">epub</a>).<br><br>You may also want to watch Bien's free <a href=\"https://event.on24.com/eventRegistration/EventLobbyServlet?target=registration.jsp&amp;eventid=490456&amp;sessionid=1&amp;key=70E912638F2A7DC107C3903E9B9E3924&amp;partnerref=WLS_Dev_7_JavaFB_07242012&amp;sourcepage=register\">screencast about lightweight and modern Java EE (6)</a> architectures full of live coding.",
  "excerpt": ""
 },
 {
  "title": "Tip: How to Easily Customize PMD Rules in Eclipse",
  "published": "2012-08-21 08:55:46",
  "postType": "post",
  "slug": "/2012/08/21/tips-how-to-easily-customize-pmd-rules-in-eclipse/",
  "status": "publish",
  "tags": [
   "pmd"
  ],
  "categories": [
   "eclipse",
   "Tools"
  ],
  "content": "The default PMD rules are little too strict for me (especially when starting on a legacy project) so I need to adjust them, usually by decreasing priority to warning. It's however quite difficult to find the rule responsible for an error message unless you know how to do it. The answer is the PMD Violations Overview view, which lists the rule names (such as \"ConstructorCallsOverridableMethod\", as opposed to the error message such as \"Overridable method 'addSummaryPeriod' called during object construction\").<br><br><!--more--><br><br>Therefore:\r\n<ol>\r\n\t<li>Window - Show View - Other... - PMD - Violations Overview</li>\r\n\t<li>In the top-right corner of the Violations Overview view, select e.g. only the priority 1 and 2 warnings by clicking the colored circles representing the other priorities.</li>\r\n\t<li>Expand the list down to the rule name level to find the rules you want to change</li>\r\n\t<li>Eclipse configuration: PMD - Rules Configuration - click on \"Rule name\" column to sort the rules by name, find the rule</li>\r\n</ol>\r\nEclipse 3.7, PMD plugin 3.2.6.",
  "excerpt": ""
 },
 {
  "title": "Help, My Code Isn''t Testable! Do I Need to Fix the Design?",
  "published": "2012-09-09 13:11:59",
  "postType": "post",
  "slug": "/2012/09/09/help-my-code-isnt-testable-do-i-need-to-fix-the-design/",
  "status": "publish",
  "tags": [
   "CleanCode",
   "design",
   "legacy",
   "testability"
  ],
  "categories": [
   "Testing"
  ],
  "content": "Our code is often untestable because there is no easy way to \"sense<sup>1</sup>\" the results in a good way and because the code depends on external data/functionality without making it possible to replace or modify these during a test (it's missing a seam<sup>2</sup>, i.e. a place where the <em>behavior</em> of the code can be changed without modifying the code itself). In such cases the best thing to do is to fix the design to make the code testable instead of trying to write a brittle and slow integration test. Let's see an example of such code and how to fix it.<br><br><!--more-->\r\n<h2>Example Spaghetti Design</h2>\r\nThe following code is a REST-like service that fetches a list of files from the Amazon's Simple Storage Service (S3) and displays them as a list of links to the contents of the files:<br><br>\n\nhttps://gist.github.com/3683899\n\n\r\n<h3>Why is the code difficult to test?</h3>\r\n<ol>\r\n\t<li>There is no seam that would enable us to bypass the external dependency on S3 and thus we cannot influence what data is passed to the method and cannot test it easily with different values. Moreover we depend on network connection and correct state in the S3 service to be able to run the code.</li>\r\n\t<li>It's difficult to sense the result of the method because it mixes the data with their presentation. It would be much easier to have direct access to the data to verify that directories are excluded and that the expected file names are displayed. Moreover the core logic is much less likely to change than the HTML presentation but changing the presentation will break our tests even though the logic won't change.</li>\r\n</ol>\r\n<h3>What can we do to improve it?</h3>\r\nWe first test the code as-is to be sure that our refactoring doesn't break anything (the test will be brittle and ugly but it is just temporary), refactor it to break the external dependency and split the data and presentation, and finally re-write the tests.<br><br>We start by writing a simple test:<br><br>\n\nhttps://gist.github.com/3684047\n\n\r\n<h2>Refactoring the Design</h2>\r\nThis is the refactored design, where I have decoupled the code from S3 by introducing a Facade/Adapter and split the data processing and rendering:<br><br>https://gist.github.com/3684066<br><br>In practice I'd consider using the built-in conversion capabilities of Jersey (with a custom <a href=\"http://jersey.java.net/nonav/apidocs/latest/jersey/javax/ws/rs/ext/MessageBodyWriter.html\">MessageBodyWriter</a> for HTML) and returning <code>List&lt;S3File&gt;</code> from <code>listS3Files</code>.<br><br>This is what the test looks like now:<br><br>https://gist.github.com/3684150<br><br>Next I'd implement an integration test for the REST service but still using the FakeS3Facade to verify that the service works and is reachable at the expected URL and that the link to a file content works as well. I would also write an integration test for the real S3 client (through S3FilesResource but without running it on a server) that would be executed only on-demand to verify that our S3 credentials are correct and that we can reach S3. (I don't want to execute it regularly as depending on an external service is slow and brittle.)<br><br><em>Disclaimer: The service above isn't a good example of proper REST usage and I have taken couple of shortucts that do not represent good code for the sake of brevity.</em><br><br>----<br><br><sup>1</sup>) Introduced by Michael Feathers in <a href=\"http://www.amazon.com/Working-Effectively-Legacy-Michael-Feathers/dp/0131177052\">Working Effectively with Legacy Code</a>, page 20-21\r\n<sup>2</sup>) ibid, page 31",
  "excerpt": ""
 },
 {
  "title": "(Unit) Testing Swiss Knife: All the Tools You Wanted to Know",
  "published": "2012-09-09 13:27:27",
  "postType": "post",
  "slug": "/2012/09/09/unit-testing-swiss-knife-all-the-tools-you-wanted-to-know/",
  "status": "publish",
  "tags": [
   "java",
   "JavaZone",
   "junit"
  ],
  "categories": [
   "Languages",
   "Testing",
   "Tools"
  ],
  "content": "I love testing. And I like productivity. There are many tools and libraries that make writing tests easier, more convenient, more fun. I would like to introduce here those that I found the most useful during the years, from selected advanced features of JUnit to assertion libraries, powerful behavior/fault injection, testing of database-related code, and finally to boosting your testing productivity hundredfold with Groovy.<br><br>This post accompanies <a href=\"http://javazone.no/incogito10/events/JavaZone%202012/sessions#2e8d5563-5a8f-4cda-9881-ef41c5509d48\">my JavaZone 2012 lightning talk</a> and goes more in depth and introduces additional tools and tips.<br><br><!--more-->\r\n<h2>Table of Content</h2>\r\n<ol>\r\n\t<li><a href=\"#junit\">Advanced JUnit 4: Useful to Know</a>\r\n<ol>\r\n\t<li><a href=\"#junit-rules\">Removing Duplication And Simplyfing Tests With @Rule</a></li>\r\n\t<li><a href=\"#junit-parametrized\">@RunWith(Parametrized): Re-Run Tests With Different Data</a></li>\r\n\t<li><a href=\"#junit-runners\">The Almighty Custom Runners</a></li>\r\n\t<li><a href=\"#junit-assume\">Conditionally Ignore Tests With Assume</a></li>\r\n\t<li><a href=\"#junit-theories\">Theories (Experimental!)</a></li>\r\n</ol>\r\n</li>\r\n\t<li><a href=\"#dbunit_express\">Testing DAOs with DbUnit Express</a></li>\r\n\t<li><a href=\"#matchers\">Readable Tests with Matchers</a></li>\r\n\t<li><a href=\"#groovy\">Attaining Eternal Bliss with Groovy</a></li>\r\n\t<li><a href=\"#byteman\">Fault Injection with JBoss Byteman</a></li>\r\n\t<li><a href=\"#other\">Other Stuff to Know</a>\r\n<ol>\r\n\t<li><a href=\"#arquillian\">Java EE Integration Testing With JBoss Arquillian</a></li>\r\n\t<li><a href=\"#infinitest\">Continuous Integration In Your IDE With Infinitest</a></li>\r\n</ol>\r\n</li>\r\n\t<li><a href=\"#code\">The Code</a></li>\r\n</ol>\r\n<h2 id=\"junit\">Advanced JUnit 4: Useful to Know</h2>\r\n<h3 id=\"junit-rules\">Removing Duplication And Simplyfing Tests With @Rule</h3>\r\nRules have been introduced to JUnit around version 4.8. Simply said, rules can perform actions before and after each test or the whole test case, similarly to your @Before[Class] and @After[Class] methods but even before/after them. To use a rule you would assign it a <em>public</em> field of your test class. Example:<br><br><pre><code>\r\npublic class ExampleTest {\r\n   @Rule public ExpectedException thrown = ExpectedException.none(); // *must* be public<br><br>   @Test\r\n   public void throwsNullPointerExceptionWithMessage() {\r\n      thrown.expect(NullPointerException.class); // same as @Test(expected=...)\r\n      thrown.expectMessage(&quot;cool failure&quot;);      // check message substring\r\n      throw new NullPointerException(&quot;My cool failure message&quot;);\r\n  }\r\n}\r\n</code></pre><br><br>You can use <a href=\"http://kentbeck.github.com/junit/javadoc/latest/org/junit/Rule.html\">@Rule</a> with a public instance field for rules that should act before/after each test method and <a href=\"http://kentbeck.github.com/junit/javadoc/latest/org/junit/ClassRule.html\">@ClassRule</a> with a public static field for rules that should act before/after the whole test case.<br><br>You can use the <a href=\"http://kentbeck.github.com/junit/javadoc/latest/org/junit/rules/TestRule.html\">existing rule implementations</a> to simplify your tests. Some of the most useful rules are (click on the name for JavaDoc with examples):\r\n<ul>\r\n\t<li><a title=\"class in org.junit.rules\" href=\"http://kentbeck.github.com/junit/javadoc/latest/org/junit/rules/ExpectedException.html\"><code>ExpectedException</code></a>: check that an exception has been thrown and that the message is as expected\r\n<ul>\r\n\t<li>See my post <a href=\"/2011/09/16/junit-tip-verifying-that-an-exception-with-a-particular-message-was-thrown/\">JUnit Tip: Verifying that an Exception with a Particular Message was Thrown</a> for more details</li>\r\n</ul>\r\n</li>\r\n\t<li><a title=\"class in org.junit.rules\" href=\"http://kentbeck.github.com/junit/javadoc/latest/org/junit/rules/TemporaryFolder.html\"><code>TemporaryFolder</code></a>: create fresh files/folders before test and delete them after test</li>\r\n</ul>\r\nIf you are repeating the same set-up and tear-down code in multiple test cases then you should consider creating your own rule implementation (usually by extending <a href=\"http://kentbeck.github.com/junit/javadoc/latest/org/junit/rules/ExternalResource.html\">ExternalResource</a>) and pushing the set-up/tear-down code there. Let's how introducing a rule simplified tests of the DbUnit Express users.<br><br>Before introducing @Rule, every DbUnit Express test required the declaration of a db tester and it initialization in setUp:<br><br><pre><code>\r\npublic class SimpleNonExtendingEmbeddedDbJUnit4Test {<br><br>    private final EmbeddedDbTester testDb = new EmbeddedDbTester();<br><br>    @Before\r\n    public void setUp() throws Exception {\r\n       testDb.onSetup();\r\n   }\r\n// ...\r\n</code></pre><br><br>Introducing <a href=\"https://github.com/jakubholynet/dbunit-express/blob/master/src/main/java/net/jakubholy/dbunitexpress/EmbeddedDbTesterRule.java\">EmbeddedDbTesterRule</a> simplified that to one annotated line:<br><br><pre><code>\r\npublic class EmbeddedDbTesterRuleTest {<br><br>    @Rule\r\n    public final EmbeddedDbTesterRule embeddedDb = new EmbeddedDbTesterRule();\r\n// ...\r\n</code></pre><br><br>(The EmbeddedDbTesterRule is more complicated than usual because I wanted it to extend the original class, EmbeddedDbTester, and thus couldn't extend ExternalResource.)<br><br>See also <a href=\"/2011/09/04/dry-use-junit-rule-instead-of-repeating-setupbefore-in-each-test/\">DRY: Use JUnit @Rule Instead of Repeating Setup/@Before in Each Test</a>.\r\n<h3 id=\"junit-parametrized\">@RunWith(Parametrized): Re-Run Tests With Different Data</h3>\r\nOccasionally we need to execute the same test method(s) repeatedly for different data. The typical solution is to copy, paste and adjust (brrr, a certain path to hell) or to use iteration:<br><br><pre><code>\r\n@Test public void acceptAllValidEmails() {\r\n   String emails = {&quot;word@example.com&quot;, &quot;under_score@a.b.cz&quot;, &quot;d.ot@here.org&quot;};\r\n   for (String email: emails) {\r\n      assertTrue(&quot;Should accept &quot; + email, this.filter.accept(email));\r\n   }\r\n}\r\n</code></pre><br><br>The Parametrized runner provides a different way by creating a new instance of the test class for each data set with the data passed to its constructor and available to all test methods, the data itself provided by a static method:<br><br><pre><code>\r\n@RunWith(value = Parameterized.class)\r\npublic class FilterTest {<br><br>   private String email;\r\n   private Filter filter = ...;<br><br>   public FilterTest(String email) { this.email = email; } // parametrized constructor<br><br>   @Parameters // the 1st element of each array will be assigned to the 1st constructor parameter etc.\r\n   public static Collection&lt;Object[]&gt; data() {\r\n     return Arrays.asList(new String[][]  { {&quot;word@example.com&quot;}, {&quot;under_score@a.b.cz&quot;}, {&quot;d.ot@here.org&quot;}});\r\n   }<br><br>   @Test public void acceptAllValidEmails() {\r\n      assertTrue(&quot;Should accept &quot; + this.email, this.filter.accept(this.email));\r\n   }\r\n}\r\n</code></pre><br><br>The downside is that it requires quite lot of typing and thus it pays off only sometimes. A limitation is that you cannot apply a set of values to a single test method, which stems from the design of JUnit which expects you to create a different TestCase for each individual fixture, i.e. test data/context (which isn't a bad idea but sometimes it is just too costly to do).\r\n<h4>Alternatives:</h4>\r\n<ul>\r\n\t<li>Use the <a href=\"http://twip.sourceforge.net/howto.html\">TwiP runner</a> (available separately) that adds support for parameters to test methods and supplies values from a provided set or randomly from the whole space</li>\r\n\t<li>Use the <a href=\"http://code.google.com/p/junitparams/\">JUnitParamsRunner</a> (available separately) that permits more flexible specification of data and to do it on per-method basis</li>\r\n\t<li>Use <a href=\"http://dimitrisli.wordpress.com/2011/02/24/testng-showcase-parameterized-testing/\">TestNG</a> :-)</li>\r\n\t<li>Use JUnit Theories, see below</li>\r\n</ul>\r\n<h3 id=\"junit-runners\">The Almighty Custom Runners</h3>\r\nYou have certainly used an alternative JUnit runner (activated by the @RunWith(&lt;runner class&gt;) annotation), such as Parametrized, MockitoJUnitRunner, or SpringJUnit4ClassRunner. But have you ever considered writing your own?<br><br>Runner is the most powerful and flexible part of the JUnit architecture, it can decide how the test class is instantiated and initialized, what methods are executed and how and in what order etc. You can therefore use it for some neat tricks.<br><br>For example <a href=\"http://johannesbrodwall.com/\">Johannes Brodwall</a> of Steria wrote a custom runner that switches between using a fast in-memory database and the true stand-alone database based on whether the tests run on a developer's machine or on the continuous integration server.<br><br>You'd typically extend the default runner <a href=\"http://kentbeck.github.com/junit/javadoc/latest/org/junit/runners/BlockJUnit4ClassRunner.html\">BlockJUnit4ClassRunner</a> (<a href=\"http://jarvana.com/jarvana/view/junit/junit/4.10/junit-4.10-sources.jar!/org/junit/runners/BlockJUnit4ClassRunner.java?format=ok\">source</a>), as e.g. Mockito and Spring do.\r\n<h3 id=\"junit-assume\">Conditionally Ignore Tests With Assume</h3>\r\nIt's useful to be able to @Ignore tests based on a condition, for example to disable database integration tests in environments where the database isn't available. You can use the <a href=\"http://kentbeck.github.com/junit/javadoc/latest/org/junit/Assume.html\"><code>org.junit.Assume</code></a> class for that - if you call any of its <code>assume*</code> methods in a test method and it evaluates to false than the test will be treated is if it were marked with @Ignore. You can ignore all tests by doing this in a @Before method.<br><br>Example: Ignore DB tests if a particular system property is set:<br><br><pre><code>\r\n@Before public void ignoreTestsIfDbTestsDisabled() {\r\n   assumeThat(System.getProperties().containsKey(&quot;tests.db.disable&quot;), is(false));\r\n}\r\n</code></pre><br><br>(Assume is also often used together with Theories to define what values are legal for a particular theory.)\r\n<h3 id=\"junit-theories\">Theories (Experimental!)</h3>\r\nTheories are parametrized test methods that are executed for each possible combination of values of their parameters. The values are defined as fields annotated with @DataPoint or provided by a method annotated with @DataPoints. You use @RunWith(Theories.class) and annotate each test method with @Theory instead of @Test.<br><br>Jens Schauder wrote an <a href=\"http://blog.schauderhaft.de/2010/01/31/new-feature-of-junit-theories/\">example test where each test method (theory) is executed for all possible 2-element combinations of three string values</a>. Jacob Childress uses <a href=\"https://blogs.oracle.com/jacobc/entry/junit_theories\">theories as an alternative to Parametrized by using only a single parameter</a> (thus there are no combinations) and a @DataPoints method. Adam Hepner has written <a href=\"http://programmers.stackexchange.com/questions/63016/parameterized-tests-when-and-why-do-you-use-them/63135#63135\">brief instructions</a> for two parameter method and assume at StackOverflow.<br><br>Contrary to Parametrized, the Theories runner doesn't supply fixed sets of parameters to the test methods but generates all combinations of the available values and runs the tests for each of them, making it easier to test many more cases.<br><br>Notice that you can exclude some combinations/values by using assume (discussed above).\r\n<h2 id=\"dbunit_express\">Testing DAOs with DbUnit Express</h2>\r\n<a href=\"https://github.com/jakubholynet/dbunit-express\">DbUnit Express</a> is a thin wrapper around <a href=\"http://www.dbunit.org/\">DbUnit</a> (unit testing of code interacting with a database) intended to make starting with DB testing as quick and as easy as possible by introducing convention over configuration, by using an embedded Derby database out of the box (though you can change that), and by providing various utilities for initializing, using, and checking the content of the test database.<br><br>The main feature of DbUnit [Express] is the ability to ensure a clean, defined state of the database before each test by removing and inserting data based on (optionally test class-specific) data set files (XML, csv, Excel, ...). In addition to that it provides access to the database via a Connection or DataSource and utilities for checking the data. The goal of DbUnit Express is to help you to get your first complete DB test ready in 10 minutes in a form that can be easily distributed to other developers (in-memory DB automatically initialized from a provided .ddl file).<br><br>Example:<br><br><pre><code>\r\npublic class ExampleJUnit4WithRuleTest {<br><br>\t/**\r\n\t * Initialize the test and instruct it to use a custom data set file instead of the default dbunit-test_data_set.xml.\r\n\t * The set up of the test DB will be executed automaticaly thanks to the magic of @Rule.\r\n\t */\r\n    @Rule\r\n    public EmbeddedDbTesterRule testDb = new EmbeddedDbTesterRule(&quot;EmbeddedDbTesterRuleTest-data.xml&quot;);<br><br>    @Test\r\n    public void should_contain_data_supplied_by_dbunit() throws Exception {\r\n    \t// 1. TODO: Invoke the database-using class that you want to test, passing to it the test database\r\n    \t// via testDb.getDataSource() or testDb.getSqlConnection()\r\n    \t// ex.: new MyUserDao(testDb.getDataSource()).save(new User(&quot;Jakub&quot;, &quot;Holy&quot;));<br><br>    \t// 2. Verify the results ...\r\n    \t// Here we use a checker to check the content of the my_test_table loaded from the EmbeddedDbTesterRuleTest-data.xml\r\n        testDb.createCheckerForSelect(&quot;select some_text from my_test_schema.my_test_table&quot;)\r\n                .withErrorMessage(&quot;No data found =&gt; onSetup wasn't executed as expected&quot;)\r\n                .assertRowCount(1)\r\n                .assertNext(&quot;EmbeddedDbTesterRuleTest data&quot;); // the 1st row\r\n    }\r\n}\r\n</code></pre><br><br>Read more information about set up, usage, and benefits on the <a href=\"https://github.com/jakubholynet/dbunit-express\">DbUnit Express documentation page</a>.<br><br><strong>Related:</strong>\r\n<ul>\r\n\t<li><a href=\"http://static.springsource.org/spring/docs/3.1.x/spring-framework-reference/html/jdbc.html#jdbc-embedded-database-support\">Spring's Embedded database support</a> - automatically create and load an embedded DB (Derby, H2, HSQL).</li>\r\n</ul>\r\n<h2 id=\"matchers\">Readable Tests with Matchers</h2>\r\nTests are much better if they clearly express what they test. However JUnit itself doesn't make it possible (perhaps by design?) to express more complex conditions such as checking the content of a list or particular atributes of entities within a list. You can make your tests much more conscise and easier to understand by using matcher libraries such as <a href=\"https://github.com/alexruiz/fest-assert-2.x/wiki\">FEST-Assert</a> (currently at version 2 milestone 7) or <a href=\"http://hamcrest.org/JavaHamcrest/\">Hamcrest</a>. As a bonus, you will get much more descriptive and clear error messages.<br><br><pre><code>\r\n// JUnit\r\nassertNotNull(list);\r\nassertEquals(6, list.size());\r\nassertTrue(list.contains(sam));\r\nassertTrue(list.contains(frodo));\r\n</code></pre><br><br>&nbsp;<br><br><pre><code>\r\n// FEST-Assert\r\nassertThat(list)\r\n .hasSize(6)\r\n .contains(frodo, sam);\r\n</code></pre><br><br>&nbsp;<br><br><pre><code>\r\n// Hamcrest\r\nassertThat(list.size(), is(6));\r\nassertThat(list, hasItems(frodo, sam));\r\n</code></pre><br><br>Personally I prefer FEST-Assert because it has a nice fluent API that is intuitive to use and easy to discover via autocompletion in IDE. Hamcrest is older and suffers from issues with generics - earlier or later you run into a case where you have to add same strange casts or convert a generic list to List and then cast it to List&lt;SomethingElse&gt; to get Hamcrest working. It even sometimes happens that the code works with Maven but fails with Eclipse or vice versa.<br><br><a href=\"http://weblogs.java.net/blog/johnsmart/archive/2008/04/on_the_subtle_u.html\">Hamcrest &amp; generics hell</a> by J.F. Smart and <a href=\"http://stackoverflow.com/search?q=hamcrest+generics\">at StackOverflow</a> (e.g. explicit <a href=\"http://stackoverflow.com/questions/9707531/hamcrest-generics-hell-2-iterablewithsize-gives-errror-is-not-applicable-for\">cast to collection element type</a>).<br><br>Learn some <a href=\"https://github.com/alexruiz/fest-assert-2.x/wiki/Tips-and-tricks\">great tips and tricks for Fest-Assert</a> such as <a href=\"https://github.com/alexruiz/fest-assert-2.x/wiki/Tips-and-tricks#wiki-extracted-properties-assertion\">extracting a particular property</a> from beans in a collection or <a href=\"https://github.com/alexruiz/fest-assert-2.x/wiki/Tips-and-tricks#wiki-filters\">retaining only objects matching</a> a condition.\r\n<h2 id=\"groovy\">Attaining Eternal Bliss with Groovy</h2>\r\nThe happiest moment in my testing life was when I realized that I can use one language - typically Java - for the production code and another, much more productive one for tests - Groovy.<br><br>Why to use Groovy?\r\n<ul>\r\n\t<li>It's syntax is 99.9% of Java + 1000% more =&gt; you can copy &amp; paste to Groovy (and back), you can learn the productive features of Groovy gradually</li>\r\n\t<li>Powerful, concise, productive</li>\r\n\t<li>It has literals for lists, maps, regular expressions etc.</li>\r\n\t<li>Groovy adds many extremely useful and poweful methods to JDK classes that skyrocket your productivity:\r\n<ul>\r\n\t<li><a href=\"http://groovy.codehaus.org/groovy-jdk/java/util/Collection.html\">Collections</a>: filter, map, ...</li>\r\n\t<li><a href=\"http://groovy.codehaus.org/groovy-jdk/java/io/File.html\">File</a>: getText(), ...</li>\r\n</ul>\r\n</li>\r\n\t<li>A single powerful assert (\"assert &lt;expressions&gt;\") providing very clear failure messages about all parts of the expression involved. With Groovy you generally don't need to learn and use a matcher library</li>\r\n\t<li>Closures now &amp; here :-)</li>\r\n\t<li>Multi-line strings and strings with variable replacement (\"text $replacedWithVariableValue text\")</li>\r\n\t<li>Useful libraries such as <a href=\"http://code.google.com/p/spock/\">Spock</a></li>\r\n</ul>\r\nRead more about how Groovy can make you much more productive and happy at <a href=\"/2011/10/18/only-a-masochist-would-write-unit-tests-in-java-be-smarter-use-groovy-or-jruby-or-st-else-similar/\">Only a Masochist Would Write Unit Tests in Java. Be Smarter, Use Groovy (or Scala…)</a>.<br><br><strong>Alternatives</strong>: <a href=\"http://www.scalatest.org/\">ScalaTest</a> if you know Scala - it also integrates very well with JUnit and production code in Java\r\n<h2 id=\"byteman\">Fault Injection with JBoss Byteman</h2>\r\nByteman is pure magic. It can change behavior of any method on the call stack executed during a test. And you don't need to have access to the object owning the method. The <a href=\"/2011/09/07/practical-introduction-into-code-injection-with-aspectj-javassist-and-java-proxy/\">behavior is injected</a> into the target method before a test and removed when it finishes (contrary to most other <abbr title=\"Aspect-Oriented Programming\">AOP</abbr> tools that change code at load time and leave it so).<br><br>There are two primary uses of Byteman:\r\n<ol>\r\n\t<li>Testing of failure handling by \"injecting\" failures, usually in the form of throwing an exception such as SocketTimeoutException or FileNotFoundException, into methods somewhere down the call stack</li>\r\n\t<li>Testing of legacy code - Byteman enables you to shortcut/replace dependencies that would otherwise prevent you from testing a class (e.g. a web service client instantiated internally in the class)</li>\r\n</ol>\r\nEx.:<br><br><pre><code>\r\n@RunWith(BMUnitRunner.class)\r\npublic class MyMainTest {<br><br>\t@Test(expected = IllegalStateException.class)\r\n\t@BMRule(name=&quot;throw IllegalStateException from the helper class&quot;,\r\n\t\t\ttargetClass = &quot;MainsHelper&quot;,\r\n\t\t\ttargetMethod = &quot;sayHello&quot;,\r\n\t\t\taction = &quot;throw new java.lang.IllegalStateException(\\&quot;Exception injected by Byteman\\&quot;)&quot;)\r\n\tpublic void testSayHello() {\r\n\t\tnew MyMain().sayHello();\r\n\t\tfail(&quot;sayHello should have failed due to Byteman injecting an exception into sayHello&quot;);\r\n\t}\r\n}\r\n</code></pre><br><br>Read more at <a href=\"/2012/02/25/cool-tools-fault-injection-into-unit-tests-with-jboss-byteman-easier-testing-of-error-handling/\">Cool Tools: Fault Injection into Unit Tests with JBoss Byteman – Easier Testing of Error Handling</a> and get the <a href=\"https://github.com/jakubholynet/presentations/tree/master/UnitTestingSwissKnife/ExampleByteman\">complete ExampleByteman project from GitHub</a>.<br><br>Beware that with great power comes also great responsibility. You should only use Byteman as the last resort since such tests are harder to understand and more brittle.<br><br><strong>Alternative</strong>: <a href=\"http://code.google.com/p/jmockit/\">JMockit</a> (might be easier to use since you only write code as Java code and not as text as in the case of Byteman)<br><br><strong>Update</strong>: Brett L. Schuchert argues very well in <a href=\"http://martinfowler.com/articles/modernMockingTools.html\">Modern Mocking Tools and Black Magic - An example of power corrupting</a> why using such black magic (<a href=\"http://code.google.com/p/jmockit/\">JMockit</a> in his case) should be avoided as only treating the symtomps in favor of actually fixing the code.\r\n<h2 id=\"other\">Other Stuff to Know</h2>\r\n<h3 id=\"arquillian\">Java EE Integration Testing With JBoss Arquillian</h3>\r\nJava EE in the version 5/6 incarnations has become a lean yet powerful platform worth considering. If you go this way and delegate cross-cutting concerns to the container (in the form of interceptors, dependency injection, eventing etc.) then you will also need to verify that these container-managed pieces are assembled correctly and work as expected.<br><br><a href=\"http://www.jboss.org/arquillian.html\">JBoss Arquillian</a> is the best tool for this job - it let you define what classes and resources to include in a test and runs it on an embedded server (Glassfish, JBoss, ...). If you use Java EE then you absolutely should have a look at Arquillian.\r\n<h3 id=\"infinitest\">Continuous Integration In Your IDE With Infinitest</h3>\r\n<a href=\"http://infinitest.github.com/\">Infinitest</a> (<a href=\"http://infinitest.github.com/user_guide.html\">User Guide</a>) is my absolutely favorite Eclipse/IntelliJ plugin. It provides you with immediate feedback whenever you change your production or test code by running the tests affected by the change and reporting their failures directly in the source code as markers.<br><br>If you have to run your tests manually then you will tend to run them less often, after larger changes. With Infinitest you learn about a failure that you introduced soon after having done so, making it much easier to understand what's wrong and to fix it.<br><br>Infinitest can be easily configured to skip some tests (typically slow/integration tests) and set JVM arguments for the tests and supports both JUnit and TestNG. It isn't completely perfect but it does a great job anyway. Highly recommended.\r\n<h3>And Even More...</h3>\r\n<a href=\"/wiki/development/testing/\">See my wiki page on Testing for even more tools and libraries</a>.\r\n<h2 id=\"code\">The Code</h2>\r\nThe code is available in my <a href=\"https://github.com/jakubholynet/presentations/tree/master/UnitTestingSwissKnife/\">UnitTestingSwissKnife GitHub repository</a>.<br><br>PS: Feedback is welcomed.",
  "excerpt": ""
 },
 {
  "title": "Most interesting links of September ''12",
  "published": "2012-09-30 21:59:22",
  "postType": "post",
  "slug": "/2012/09/30/most-interesting-links-of-september-12/",
  "status": "publish",
  "tags": [
   "agile",
   "clojure",
   "fp",
   "groovy",
   "haskell",
   "nosql",
   "spring",
   "tdd",
   "xp"
  ],
  "categories": [
   "General",
   "Testing",
   "Top links of month"
  ],
  "content": "<h2>Recommended Readings</h2>\r\n<ul>\r\n\t<li>Johannes Brodwall: <a href=\"http://johannesbrodwall.com/2010/11/10/this-dependency-injection-madness-must-end/\">This dependency injection madness must end!</a> - it's very valuable to hear well-founded arguments against any popular belief and Dependency Injection is one of these. \"I have started disliking the consequence of this strategy very much: All coupling in my system becomes implicit and harder to understand. I have instead reverted to using design patterns like the Singleton pattern, but with a slight twist.\"</li>\r\n\t<li><a href=\"http://online.wsj.com/article/SB10000872396390443855804577599993053055030.html\">Computer Programmers Learn Tough Lesson in Sharing - WSJ.com</a> - A balanced presentation of pair-programming including both benefits and issues. A key point: It is a skill that must be learned (to respect the other one, give her space, be aware of how your behavior is perceived by her, ...).</li>\r\n\t<li><a href=\"https://m.facebook.com/note.php?note_id=472392329460303\">Kent Beck: Functional TDD: A Clash of Cultures</a> - TDD has been developed for object-oriented languages and applying it to a functional language with strong type brings interesting challenges. Also a good summary of the benefits of TDD: double checking of the logic (by the implementation and the, preferably quite different, test), solution decomposition (focus on part of the problem, once solve be sure it stays solved),  automatic checking of correctness, outside in design (API first, implementation after that). Plus the pleasant experience of the continuous cycle of tension (failing test) - relief (green).</li>\r\n\t<li><a href=\"http://pragprog.com/magazines/2012-09/thinking-functionally-with-haskell\">Paul Callaghan: Thinking Functionally with Haskell: Types? Tests? We Need a New Word</a> - Powerful type systems eliminate possibility of defects thus venturing into the domain of testing - what can they offer and where the new border and symbiosis between types and tests will be?</li>\r\n\t<li><a href=\"http://pragprog.com/magazines/2012-07/tales-from-the-ops-side\">Tales from the Ops Side: Black Friday</a> - an interesting and exciting view into the life of operations engineers one day when all went wrong. Key learnings: Many interdependant components are difficult to reason about; good monitoring and communication are crucial. The post refers to an interesting concept of <a href=\"http://roc.cs.berkeley.edu/\">Recovery-Oriented Computing</a>, i.e. failures are inevitable and their prediction is nearly impossible thus we must focus on making the systems able to survive failures (e.g. vi damage containment, automatic fault detection, component-level restartability).</li>\r\n\t<li><a href=\"infoworld.com/d/application-development/groovy-the-roadmap-the-popular-jvm-language-202990\">Groovy: The road map for the popular JVM language</a> - why was Groovy created (as Java companion focused on productivity), key changes in Groovy 2.0 (more suport for static typing, Java 7, modularity with speed as a side-effect) and in the future Groovy 3.0 (invokedynamic everywhere, more Groovy written in itself).</li>\r\n\t<li><a href=\"http://martinfowler.com/articles/nosqlKeyPoints.html\">Martin Fowler: Key Points from NoSQL Distilled</a> - an overview of why NoSQL, data models, distribution models, consistency, map-reduce, polyglot persistence, criteries for choosing a database.</li>\r\n\t<li><a href=\"http://architects.dzone.com/articles/you%E2%80%99re-top-developer\">You’re a Top Developer!</a> - a surprising hypothesis that \"90% of all developers never read a programming blog, never have any side projects to learn something new, and never spend any time or effort outside work hours to improve\". However I haven't seen any data to back that up (the author only quotes  <a href=\"http://www.amazon.com/gp/product/0932633439/ref=as_li_qf_sp_asin_il_tl?ie=UTF8&amp;camp=1789&amp;creative=9325&amp;creativeASIN=0932633439&amp;linkCode=as2&amp;tag=passforcodi-20\" target=\"_blank\">Peopleware</a>) and the author doesn't propose any explanation for the fact. I'd really like to know if it is true and why it is so.</li>\r\n</ul>\r\nBusiness &amp; Agile\r\n<ul>\r\n\t<li><a href=\"http://www.fastcompany.com/3001275/experimentation-new-planning\">Experimentation Is The New Planning</a> - \"You have no idea what’s going to happen to your industry. That’s why you build your organization into an engine of possibility.\" We need \"to  continually develop options and explore possibilities\" to survive in the ever-changing conditions. Successful strategies emerge from the many ongoing experiments. However, \"For emergent strategy to be successful, there must be enough autonomy, freedom, and slack in the system for people and resources to connect in a peer-to-peer way\".</li>\r\n\t<li><a href=\"http://erik.doernenburg.com/2012/09/buy-vs-build-shift-part-1/\">The Buy-vs-Build Shift (part 1)</a> - Buy to reduce risk of failure (however true agile development - with frequent deliveries and feedback-driven direction - may be cheaper and more importantly can tailor the product to the actual needs) and to avoid inefficiecy of development (but it doesn't need to be so with agile). \"[..] in projects with long cycle times (years) there is a tendency for the business to be somewhat speculative and request all functionality that they can think of [..] With prioritised iterative delivery the business can halt a project when all features that are actually needed have been completed. [..] it does reduce the amount of features that are implemented, and based on my experience, quite substantially so.\" Today's development with e.g. TDD, powerful IDEs supporting automated refactoring, powerful development/production machine, the all-knowing Internet may be much more efficient.</li>\r\n\t<li><a href=\"http://www.economist.com/node/21559618\">European entrepreneurs - Les misérables</a> - A good analysis of why it is much more difficult to be an entrepreneur in Europe than in USA (the strong negative impact of a business failure, lack of local investors, cost of firing people) and the decline of European entrepreneurship since 19th century/WW1.</li>\r\n\t<li><a href=\"http://www.gao.gov/products/GAO-12-681\">U.S. Government Accountability Office: Effective Practices and Federal Challenges in Applying Agile Methods</a> - US government considers agile effective; description of the useful practices and of challenges</li>\r\n</ul>\r\n<h2>Tools</h2>\r\n<ul>\r\n\t<li><a href=\"http://code.google.com/p/googlecl/\">Command line tools for the Google Data APIs</a> - create calendar tasks with reminders, list [today's] task; edit a doc in a local editor (vim, ...), get/upload docs; send photos to Picasa, ... .</li>\r\n</ul>\r\n<h2>Clojure Corner</h2>\r\n<ul>\r\n\t<li><a href=\"http://www.unexpected-vortices.com/clojure/10-minute-emacs-for-clojure.html\">10-minute Emacs for Clojure</a> - getting started with Emacs for Clojure - install &amp; config &amp; basic usage for Emacs newbies (though no REPL integration yet)</li>\r\n\t<li><a href=\"http://ktuman.blogspot.no/2012/09/first-month-runa-inc-clojure-shop-in.html\">Keep IT Simply Simple: First month @Runa Inc. - Clojure shop in Silicon Valley</a> - brief post about using Clojure in the wild. Some points: TDD works splendidly; frameworks are not necessary; Clojure can be really fast (&lt;= type hinting, memoziation, performant data structures + occasional Java code)</li>\r\n\t<li><a href=\"http://blackstag.com/blog.posting?id=5\">Blackstag: Why Clojure?</a> The author describes the set of reasons that have led him to Clojure - and those that actually made him stick with it. \"[..] what I like the most about Clojure is that it brings together the best of what many languages have to offer while not forcing it all upon me and, in doing so, has provided a good balance between power and flexibility.\" \"With Clojure I accomplish more and have found a greater sense of happiness with the work I am doing.\"</li>\r\n</ul>",
  "excerpt": ""
 },
 {
  "title": "Programming Like Kent Beck",
  "published": "2012-09-12 08:38:11",
  "postType": "post",
  "slug": "/2012/09/12/programming-like-kent-beck/",
  "status": "publish",
  "tags": [
   "best practices",
   "CleanCode",
   "craftsmanship",
   "java",
   "kent beck",
   "opinion",
   "tdd"
  ],
  "categories": [
   "General",
   "Languages",
   "Testing"
  ],
  "content": "<em>Republished from <a href=\"http://blog.iterate.no/2012/06/20/programming-like-kent-beck/\">blog.iterate.no</a> with the permission of my co-authors Stig Bergestad and Krzysztof Grodzicki.</em><br><br>Three of us, namely Stig, Krzysztof, and Jakub, have had the pleasure of spending a week with Kent Beck during Iterate Code Camp 2012, working together on a project and learning programming best practices. We would like to share the valuable lessons that we have learnt and that made us better programmers (or so we would like to think at least).<br><br><!--more--><br><br><h2>Values Underlying the Programming Style</h2><br><br>Most of the things that we have learnt stem from three basic values: communication, simplicity, and flexibility (in the order of importance). We will introduce them briefly here, you can find a more detailed description in Kent's book <a href=\"http://www.amazon.com/Implementation-Patterns-Kent-Beck/dp/0321413091/\">Implementation Patterns</a>, along with few fundamental practices such as the application of symmetry.<br><br><h3>Communication</h3><br><br>Programs are read much more often than written and therefore should communicate clearly their intent. Code is primarily means of communication. (For a typical enterprise system, a lot of code will be modified by many programmers over 5 - 15 years and they'll all need to understand it.)<br><br><h3>Simplicity</h3><br><br>Eliminate excess complexity. Apply simplicity at all levels. Simplicity helps communication by making programs easier to understand. Communication helps simplicity by making it easier to see what is excess complexity.<br><br><h3>Flexibility</h3><br><br>\"Making workable decisions today and maintaining the flexibility to change your mind in the future is a key to good software development.\" -- Implementation Patterns, Kent Beck<br><br>Programs should be flexible in the ways they change, they should make common changes easy or at least easier. Complexity can often arise from excess flexibility, but if that flexibility is not needed then it is waste. The best kind of flexibility comes from simplicity coupled with extensive tests. Trying to create flexibility through design phases or the likes usually ends up with this kind of \"complex flexibility\". Most of the time you do not have enough information to make a proper design decision about where your program will need to change, so the lean mantra of <a href=\"http://www.codinghorror.com/blog/2006/10/the-last-responsible-moment.html\">postponing your decisions til the last responsible moment</a> is a valid and useful approach. That is when you have the best grounds for any decision.<br><br><h3>Summary</h3><br><br>Write code that communicates well what and why is done so that your co-workers and future maintainers can take it over without too much cost. (Yet you have to assume some level of skill and knowledge in you audience.) You cannot foresee the future so keep your code simple and sufficiently flexible so that it can evolve.<br><br><h2>Key Learnings</h2><br><br><h3>1. You Ain't Gonna Need It!</h3><br><br><blockquote>What is today's demo? What test to start with?</blockquote><br><br>Before we arrived, we settled on a topic that we thought would be fun and challenging. We settled on trying our hands at prototyping a highly scalable, distributed database. We expected upon arrival to spend few hours discussing approaches to how we should actually implement this. After all, there are lot of things to consider: replication strategies, consistent hashing, cluster membership auto-discovery, and conflict resolution, to name a few. If you have just 5 days, you need to plan how to implement it in the simplest possible way. What to do. What to skip. Right? Wrong. Instead of any planning, Kent just asked us what would be the demo we would like to show at the end of the day. And his next question was what test to write.<br><br>It turned out to be a very smart approach because we actually implemented only a very small subset of the possible functionality, deciding daily what to do next based on our experiences with the problem so far. Any discussion from the beginning longer than 10 minutes would be 90% wasted time. This doesn't mean that planning is bad (though <a href=\"http://livebyquotes.com/2012/in-preparing-for-battle-i-have-always-found-that-plans-are-useless-but-planning-is-indispensable-gen-dwight-eisenhower/\">the resulting plans are usually useless</a>), it only means that we usually do much more of it than we actually need. Getting real feedback and basing our decisions on that, on real data, is much more practical and valuable than any speculations.<br><br>Therefore prefer on-going planning based on feedback and experience to extensive up-front planning. Ask yourself: What am I going to present at the next demo/meeting/day? What test to write to reflect that and thus guide my development effort?<br><br><h3>2. Write High-Level Tests to Guide the Development</h3><br><br>The goal of our second day was replication, demonstrated by writing to one instance, killing it, and reading the (replicated) data from the second instance. We started by writing a <a href=\"https://github.com/iterate/codecamp2012/blob/369bfddad85ecb26322d64ee0d7db7bc5c129b5e/src/test/java/no/iterate/graft/GraftReplicationTest.java\">corresponding test</a>, which follows these steps closely, nearly literally:<br><br><pre><code>\r\nList&amp;lt;Graft&amp;gt; grafts = Graft.getTwoGrafts();\r\nGraft first = grafts.get(0);\r\nGraft second = grafts.get(1);<br><br>first.createNode().put(&amp;quot;key&amp;quot;, &amp;quot;value&amp;quot;)\r\nfirst.kill();<br><br>assertNotNull(second.getNodeByProperty(&amp;quot;key&amp;quot;, &amp;quot;value&amp;quot;));\r\n</code></pre><br><br>(The API of course evolved later into something more general.)<br><br>Now the interesting thing is that this is not a unit test. It is basically an integration test, or to use a less technical term, a story test exercising a rather high-level feature. A feature of interest to the customer. While a unit tests tells me \"this <em>class</em> is working as intended,\" a story test tells me \"this <em>feature</em> works as intended\".<br><br>I used to think about TDD at the unit/class level but this is TDD at a much higher level. It has some interesting properties:<br><br><ul>\n    <li>It helps measure real progress of the project because it exercises something that is actually meaningful to the customer (if you permit me to use this \"customer\" in a little blurry fashion)</li>\n    <li>It helps keep you focused on delivering business functionality (by being on its level)</li>\n    <li>It's likely to stay mostly unchanged and live much longer than unit tests or actually most of the code base because it is on such a conceptual level</li>\n</ul><br><br>Now, according to the <a href=\"http://www.ibm.com/developerworks/java/library/j-aopwork11/TestingPyramid.jpg\">testing pyramid</a>, there are of course fewer story tests than there are unit tests, and story tests do not test all possible cases. Does it mean that you need to do all these story tests and then do them again only in smaller unit tests? No, that is not the point. Getting back to the principle of flexibility and the way things change, create additional unit tests only when you need them. For example when you encounter some case where the first story test did not actually \"capture the whole\" properly, or when you discover a really important corner case, or when you want to focus on implementing a part of the overall solution. Speculating about failure points can be just as wasteful as speculating about design.<br><br><h3>3. Best Practices for [Unit] Testing</h3><br><br><h4>Write Tests From the End</h4><br><br>We normally start a test with an idea of what we want to verify, but we may be not completely sure how to arrive there. Therefore it is good practice to express what we do know, the desired end-result, first. We do this in the form of an assertion and only then shift our focus to figuring how to get there. That's how we started the test of replication in Graft, shown above.<br><br>This is an application of the key principle of focus.<br><br><h4>Write Implementation in Tests, Refactor Later</h4><br><br>You know the functionality you want and so you start writing the test for it. Instead of thinking about how it should be organized (what classes to create, where to put them, whether to use a factory class or a factory method), why not initially write the code directly in the test method? You can always factor out the code later. This way you can focus on what's really important - describing the desired functionality with a test - instead of being distracted by secondary considerations. Additionally, by postponing the decision about the internal organization of the implementation, you will have more knowledge when actually deciding it and you will likely end up with a better solution.<br><br>Key principles: Focus, avoiding premature decision-making.<br><br><h4>Bottom-up Design</h4><br><br>Avoids:<br><br><ul>\n    <li>assuming too much, too early</li>\n    <li>locking yourself into a specific design and premature design</li>\n    <li>restricting yourself (you will usually end up with the design you first intended)</li>\n</ul><br><br>Start by implementing small parts of functionality. Then combine them to form more complex behavior. Don't get distracted by dependencies, write simple stubs for them that you will replace later with real implementations. Using this technique you are not bound to design decisions taken at the beginning as in the 'top-down' approach. It requires a little bit of intuition and some experience, but combined with TDD it helps to make better design and implementation.<br><br>We found this technique quite useful as we didn't know the final solution at the beginning. When developing Graft, we haven't designed the whole application up-front. We picked a use case on the first day, implemented it, and continued by choosing and implementing other use cases each day.<br><br><h4>Act &amp; Assert at the Same Level of Abstraction</h4><br><br>Our Graft DB has a telnet-like interface for receiving commands from users. Consider the following two (simplified) variations of the <a href=\"https://github.com/iterate/codecamp2012/blob/2889f05057c4d339b6065a7e81f1d95de3456017/src/test/java/no/iterate/geekolympics/remote/CommandProcessorTest.java#L22\">addComment test</a>:<br><br><pre><code>\r\n// Test 1\r\nGraft db = ...; this.subject = new CommandProcessor(db);\r\nsubject.process(&amp;quot;addComment eventId my_comment&amp;quot;);<br><br>assertThat(subject.process(&amp;quot;getComments eventId&amp;quot;)).isEqualTo(&amp;quot;my_comment&amp;quot;);\r\n</code></pre><br><br><pre><code>\r\n // Test 2 (same setUp)\r\nsubject.process(&amp;quot;addComment eventId my_comment&amp;quot;);<br><br>assertThat(db.getComments(&amp;quot;eventId&amp;quot;)).containsOnly(&amp;quot;my_comment&amp;quot;);\r\n</code></pre><br><br>The first test, while testing the addComment command, uses another command - getComments - to check the resulting state. It uses only a single API entry point - <em>subject</em> - during the whole test. The second test accesses directly the underlying database instance and its API to get the same data, i.e. aside of <em>subject</em> it uses also the underlying <em>db</em>.<br><br>Thus the first test is not truly \"unit\" test as it depends on the correctness of another method of the tested class. The second test is much more focused and potentially simpler to write as it accesses directly the target data structure and thus performs the checks right at the source.<br><br>We would argue that tests like the first one, which perform all operations at the same level, namely the level of the public API of the object under test, are better. \"Better\" here means easier to understand and, more importantly, much more stable and maintainable because they are not coupled to the internal implementation of the functionality being tested. The price of increased complexity of these unit-integration tests (due to relying on multiple methods in each test) is absolutely worth the gain.<br><br>Tests similar to the second one are none the less more common, either accessing directly the underlying layers (an object, property, database, ...) or using mocks to gain the possibility of direct verification of side-effects. These techniques often lead to coupled and hard to maintain tests and should be limited to the \"private unit tests,\" as described and argued in <a href=\"/2011/10/20/never-mix-public-and-private-unit-tests/\">Never Mix Public and Private Unit Tests!</a><br><br><h3>4. Focus!</h3><br><br><ul>\n    <li>Put tasks that pop up on a Later list instead of doing them at once</li>\n    <li>Focus on fixing the test first - however ugly and simple (and refactor later)</li>\n    <li>Focus on the current needs - no premature abstraction</li>\n</ul><br><br>One thing that really caught our attention is Kent's focus on what he is doing at any moment. Being focused means concentrating on finishing that one thing you're currently doing without getting distracted by other concerns, however important or simple to fix. (Side note: Never say never.) When having a failing test, focus on making it pass quickly, no matter how ugly the (temporary) solution is or that it \"cuts corners.\" If you notice along the way something else that needs to be done - giving a method a better name, removing a dead code, fixing an unrelated bug - don't do it, put it on a task list and do it later. Otherwise you risk losing your attention and the current context. Do one thing at a time. When making a test pass, focus just on that, and leave concerns such as good code til the subsequent refactoring (which should follow shortly). (This reminds me of the <a href=\"http://mikadomethod.wordpress.com/2009/12/09/introduction-to-the-mikado-method/\">Mikado method</a> for large-scale refactorings, whose main purpose is also to keep focus and not getting lost in many sidetracks.)<br><br>A related practice is to focus on the current needs when implementing a feature, without speculatively designing for tomorrow's needs (possibly literally tomorrow). Focus on what is needed right now, to finish the current task, and make the solution simple so that it will be easy to refactor and extend for both known and unforseen future needs. As Kent argues in Implementation Patterns (and others elsewhere), we're very bad at speculative design, i.e. the future needs are usually quite different from what we expected and therefore it's better to create solutions that are simple and with that also flexible. You of course need to pay some attention to the future needs but far less than we tend to do. Admit to yourself that you cannot predict the future. Even if you know what else is going to be required, how can you know that no new requirements that would change or delay that (up til infinity) will appear?<br><br><h2>Some other stuff we learned</h2><br><br><h3>Parallel Design</h3><br><br><p dir=\"ltr\">Parallel design means that when changing a design, you keep the old design as long as possible while gradually adding the new one and then you gradually switching to the new design. This applies both at large and also (surprisingly) small scale. Though it's costly - you have to figure out how to have them both run and it requires more effort to have them both - it often pays off because it's safer and it enables resumable refactoring, discussed below.</p><br><br><p dir=\"ltr\">An example of a high-level parallel design is the replacement of a RDBMS with a NoSQL database. You'd start by implementing the code for writing into the new DB, then you would use it and write both to the old and the new one, then you would start also reading from the new one (perhaps comparing the results to the old code to verify their correctness) while still using the old DB's data. Next you would start actually using the NoSQL DB's data, while still writing to/reading from the old DB (so that you could easily switch back). Only when the new DB proves itself would you gradually remove the old DB.</p><br><br><p dir=\"ltr\">An example of a micro-level parallel design is the replacement of method parameters (message etc.) with the object they come from (an Edge), as <a href=\"https://github.com/iterate/codecamp2012/commit/cc04f0bb60d8260456049790793d462ce8810ef2#diff-1\">we did for notifyComment</a>:</p><br><br><pre><code>\r\n- public void notifyComment(String message, String eventName, String user) {\r\n-    notifications.add(user + &amp;quot;: commented on &amp;quot; + eventName + &amp;quot; &amp;quot; + message);\r\n---\r\n+ public void notifyComment(Edge target) {\r\n+    notifications.add(target.getTo().getId() + &amp;quot;: commented on &amp;quot; + target.getFrom().getId() + &amp;quot; &amp;quot; + target.get(&amp;quot;comment&amp;quot;));\r\n</code></pre><br><br><p dir=\"ltr\">The steps were:</p><br><br><ol>\n    <li>Adding the Edge as another parameter (Refactor - Change Method Signature)</li>\n    <li>Replacing one by one usages of the original parameters with properties of the target Edge (Infinitest running tests automatically after each change to verify we're still good)</li>\n    <li>Finally removing all the original parameters (Refactor - Change Method Signature)</li>\n</ol><br><br>The good thing is that your code always works and you can commit or stop at any time.<br><br><h3>Resumable Refactoring</h3><br><br>If you apply the practices described below when performing a larger-scale refactoring then your code will always be buildable and you will be able to stop in the middle of the refactoring and continue (or not) at any later time.<br><br>The practices are parallel design and going forward in <a href=\"/2012/03/12/kent-beck-best-practices-for-software-design-with-low-feature-latency-and-high-throughput/\">small, safe steps</a> i.e. steps that provably do not break anything. In essence it's about keeping the oversight and control, at each step you know exactly what you did which broke the test and this way you can not only quickly put the application back in a working state, but also quickly hone in on what exactly caused the problem.<br><br>(The Mikado method mentioned above is a great guide for refactoring systems where every change reveals a number of other changes required to make it possible. Of course the ultimate resource for refactoring legacy systems is Michael Feathers's <a href=\"http://www.amazon.com/Working-Effectively-Legacy-Michael-Feathers/dp/0131177052/\">Working Effectively with Legacy Code</a>).<br><br><h3>Refactor on Green, at Will</h3><br><br><p dir=\"ltr\">The dogmatic TDD practitioners claim that you cannot change the behavior of production code unless some test forces you to do so. Thus it might be refreshing to hear that Kent doesn't hesitate to <a href=\"http://cleancoder.posterous.com/the-transformation-priority-premise\">generalize the code</a> (e.g. by replacing fakes with a real implementation) even though there are no tests that require the generalization to pass.</p><br><br><p dir=\"ltr\">On the other hand it doesn't mean that forcing a generalization by tests is a bad thing or that you should not do it. This is basically a question of the economics of software development, of balancing the cost (of writing and maintaining tests) with the benefits (defect and regression prevention). It's a question of the risk involved and of your confidence in your coding skills. Kent has rightfully much more confidence in his coding skills (and much more experience with it) than many of us. Our confidence is quite low based on past experiences and therefore we'll probably go on enforcing generalizations with tests.</p><br><br><p dir=\"ltr\">We'd close this topic by quoting Kent speaking about <a href=\"http://stackoverflow.com/a/153565\">how much testing to do</a>:</p><br><br><blockquote>I get paid for code that works, not for tests, so my philosophy is to test as little as possible to reach a given level of confidence (I suspect this level of confidence is high compared to industry standards, but that could just be hubris). If I don’t typically make a kind of mistake (like setting the wrong variables in a constructor), I don’t test for it. I do tend to make sense of test errors, so I’m extra careful when I have logic with complicated conditionals. When coding on a team, I modify my strategy to carefully test code that we, collectively, tend to get wrong.<br><br>Different people will have different testing strategies based on this philosophy, but that seems reasonable to me given the immature state of understanding of how tests can best fit into the inner loop of coding. Ten or twenty years from now we’ll likely have a more universal theory of which tests to write, which tests not to write, and how to tell the difference. In the meantime, experimentation seems in order.</blockquote><br><br><h3>Symmetry in the Code</h3><br><br>Symmetry is an abstract concept, more specific than the values of communication, simplicity, and flexibility, but still rather general. In Implementation Patterns Kent refers to symmetry as a programming principle.<br><br>Code with symmetries is easier to grasp than code that is asymmetric. It's easier to read and understand. So what, more specifically, is symmetric code? To quote Kent again:<br><br><blockquote>Symmetry in code is where the same idea is expressed the same way everywhere it appears in the code.</blockquote><br><br>Imagine a code where the some idea, like \"getting the last updated document from the DB,\" is implemented several times. The code is asymmetric if the method names differ, if they do things in different order, if there are some important differences between them. When you ask yourself \"what does this method do\" and you arrive at pretty much the same answer for all methods in spite of all the differences, then you have some violation of symmetry. An example of symmetry in code is keeping the abstraction level consistent within a code block, like a method. if the block is a mix of low level assignments and method calls, you may want to see if you can abstract away the assignments with a method. The astute reader have probably noticed that consistency is a large part of symmetry: being consistent with abstraction levels, consistent with method naming, and so on. But symmetry is more abstract in that it deals more with ideas, not rules (such as the rule that class and method names should be in camel-case).<br><br><h3>And What Do you Know, Even Some More ...</h3><br><br><ul>\n    <li><strong>Manage your energy</strong> - be aware of your energy and stop before becoming tired. Don't forget to take breaks. A rested developer is multiple times more productive than a tired one. (J.B. Rainsberger in <a href=\"http://www.youtube.com/watch?v=7HecgbghFTk\">The Economics of Software Design</a> shares the story of working so intensively that he became exhausted and totally unproductive).</li>\n    <li><strong>Pair-programming is a <a href=\"http://arlobelshee.com/post/is-pair-programming-for-me\">skill one must consciously learn</a></strong> (and it may be more challenging for some personality types, which shall to be respected)</li>\n    <li><strong>Prefer IDE's refactorings to manual changes</strong> - f.ex. none of us had ever before used the \"inline\" refactoring while Kent uses it all the time. Once you master the refactorings, they'll become much more efficient than changing things manually and, more importantly, they avoid the small but non-zero probability of breaking something (remember that Murphy guy who said - what can break will break)</li>\n</ul><br><br><h2>Code</h2><br><br>You can find code for Iterate Code Camp 2012 on GitHub - <a title=\"Github codecamp2012\" href=\"https://bit.ly/codecamp2012\">bit.ly/codecamp2012</a><br><br><h2>Conclusion</h2><br><br>We hope that you, our dear reader, find some of these ideas interesting and have got inspired to try them in your daily practice, as we did.<br><br><h2>Related Resources</h2><br><br><ul>\n    <li>Jakub's blog post <a href=\"/2011/11/21/principles-for-creating-maintainable-and-evolvable-tests/\">Principles for Creating Maintainable and Evolvable Tests</a> summarizes some complementary principles for writing tests that he learnt from Kent</li>\n    <li>Rich Hickey: <a href=\"http://www.infoq.com/presentations/Simple-Made-Easy\">Simple Made Easy</a> - a great talk that explains the crucial difference between \"simple\" (vs. complex) and \"easy\" and how our languages and tools aren't as simple as they should be, often because they try to be easy</li>\n</ul><br><br><p style=\"text-align:center;\"><em>- Krzysztof, Stig, and Jakub, June 2012 -</em></p><br><br><p style=\"text-align:center;\"><em>You might enjoy also other <a href=\"/tag/opinion/\">posts on effective development</a></em></p>",
  "excerpt": ""
 },
 {
  "title": "The Best Code I Have Ever Written Is The Code I Never Wrote",
  "published": "2012-09-14 09:50:24",
  "postType": "post",
  "slug": "/2012/09/14/the-best-code-i-have-ever-written-is-the-code-i-never-wrote/",
  "status": "publish",
  "tags": [
   "development",
   "opinion"
  ],
  "categories": [
   "General"
  ],
  "content": "The best code I have ever written is the code I never wrote. It works exactly as intended. There are no bugs, ever. It doesn't increase complexity of the application. Other people don't need to struggle to understand it. It gets never outdated.<br><br>Therefore don't write code unless you really have to.<br><br><p style=\"text-align:center;\"><em>You might enjoy also other <a href=\"/tag/opinion/\">posts on effective development</a>.</em></p>",
  "excerpt": ""
 },
 {
  "title": "Books Our Developers Should Read",
  "published": "2013-03-12 10:39:15",
  "postType": "post",
  "slug": "/2013/03/12/books-our-developers-should-read/",
  "status": "publish",
  "tags": [
   "book",
   "learning"
  ],
  "categories": [
   "General"
  ],
  "content": "<em>Republished from <a href=\"http://blog.iterate.no/2012/08/19/books-everybody-should-read/\">blog.iterate.no</a> with the permission of my co-author, Morten Berg, and later updated.</em><br><br>There are a few books that every developer in Iterate should read because they express what we believe in and are extremely valuable in themselves. The books chosen are generally and broadly useful and not tied to some too limited domain (contrary to e.g. Effective Java).  The list is kept as short as possible, about 4-5 books, and is revised regularly.<br><br>Why particularly these books, why lean and agile? Our people are primarily responsible for crafting solutions for our clients, for making sure that they use the customers' limited resources efficiently to produce the maximal business value possible. However, according to our experience, it is never truly known upfront where that value lies. Software development is therefore inherently a learning and exploration process. A process that needs to be continually adjusted based on empirical feedback from the reality and on shifting conditions. This is what lean is about: eliminating waste, maximizing value by maximizing learning, making sure that the right product is built. We value software craftmanship and building things right - but building the right things is crucial.<br><br>Here are the books and why we believe they are so important.<br><br><!--more-->\r\n<h2 id=\"CoreBooksEverybodyShouldRead-1. ImplementingLeanSoftwareDevelopment:FromConcepttoCash\">1. Implementing Lean Software Development: From Concept to Cash</h2>\r\n<em>Mary and Tom Poppendieck, 2006<em><em> (<a href=\"http://www.amazon.com/Implementing-Lean-Software-Development-Concept/dp/0321437381/\" rel=\"nofollow\">amazon</a>)</em></em>\r\n</em><br><br>Thin yet extremely rich book that is a perfect introduction into the lean thinking and its many sides. It's unbelievable how much valuable insights can fit into this book. It not only conveys why the lean approach is the only feasible one, but also how to implement it in practice.<br><br><strong>Keywords</strong>: Eliminating waste, last responsible moment, sustainable cadence, build quality in<br><br>Tips: It's highly recommended to read <a href=\"http://itrevolution.com/books/phoenix-project-devops-book/\" rel=\"nofollow\">The Phoenix Project: A Novel About IT, DevOps, and Helping Your Business Win</a> befor/after Poppendiecks; it's a brief, exciting novel following the story of a company in crisis and its new Ops boss that brings it from chaos to incredible effectivity through the application of lean principles. You won't be able to put it down.\r\n<h2 id=\"CoreBooksEverybodyShouldRead-2.RunningLean:IteratefromPlanAtoaPlanThatWorks\">2. Running Lean: Iterate from Plan A to a Plan That Works</h2>\r\n<em>Ash Maurya, 2012</em><em> (<a href=\"http://www.amazon.com/Running-Lean-Iterate-Plan-Works/dp/1449305172/\" rel=\"nofollow\">amazon</a>)</em><br><br>Iterate believes that the Lean Startup methodology is the right way to foster innovation both in new and existing companies. And innovation is that what drives us forward and helps us survive in the ever more competitive market. Provided that you already have an idea of what lean startup is, then this book is the right one for you. Contrary to Eric Ries' \"The Lean Startup\", this book is very practical and introduces many ways how to do hypothesis testing in practice etc.<br><br><strong>Keywords</strong>: User centric, measuring, interviewing, eliminate waste by not creating what's not worth creating, unknown solution\r\n<h2 id=\"CoreBooksEverybodyShouldRead-3.CleanCode:AHandbookofAgileSoftwareCraftsmanship\">3. Clean Code: A Handbook of Agile Software Craftsmanship</h2>\r\n<em>Robert C. Martin (Uncle Bob), 2008<em> (<a href=\"http://www.amazon.com/Clean-Code-Handbook-Software-Craftsmanship/dp/0132350882/\" rel=\"nofollow\">amazon</a>)</em></em><br><br>The very essential book for every self-respecting software professional providing insights into what is good code and how to write it. It will change the way you code for the better. Everybody has heard that methods and classes should be small, do one thing, have self-explanatory names, be implemented in test-first fashion etc. This book explains all of it and explains why.<br><br><strong>Keywords</strong>: Single responsibility principle, TDD, YAGNI, DRY\r\n<h2 id=\"CoreBooksEverybodyShouldRead-4.WorkingEffectivelywithLegacyCode\">4. Working Effectively with Legacy Code</h2>\r\n<em>Michael Feathers, 2004</em><em> (<a href=\"http://www.amazon.com/Working-Effectively-Legacy-Michael-Feathers/dp/0131177052/\" rel=\"nofollow\">amazon</a>)</em><br><br>The bible of anybody working with legacy code (i.e. most code). Even some green field projects happen to create legacy code from the start and thus can benefit from it. But even non-legacy development would benefit from the refactoring and (emergent) design insights. The key topics of this book are refactoring and testing. Getting to know a complex code base, making it better, changing it safely. Though little older, it is still equally valuable. It introduces many methods, techniques, and approaches that every developer should have in his/her arsenal. Taster of the chapters: I Don't Understand the Code well Enough to Change It, My Application Has No Structure, This Class Is Too Big and I Don't Want It to Get Any Bigger.<br><br>It perhaps isn't necessary to read it cover-to-cover but it's important to be familiar with what is there so that when you are in a situation where you'd benefit from its wisdom, you know it is there and where to find it.<br><br><strong>Keywords</strong>: Technical debt, refactoring, testing, mocks/fakes, breaking dependencies, scratch refactoring, effect analysis, emergent design.\r\n<h2 id=\"CoreBooksEverybodyShouldRead-5.AgileinaNutshell(originaltitleAgileProductOwnershipinaNutshell)\">5. Agile in a Nutshell (original title Agile Product Ownership in a Nutshell)</h2>\r\n<em>Henrik Kniberg, 2012</em>\r\n<blockquote>Wow, that was 15 minutes well spent. It's like compressing all important knowledge into one sketch. - Pål</blockquote>\r\n<a href=\"http://youtu.be/502ILHjX9EE\" rel=\"nofollow\">This 15 min video</a> is the best explanation of the key aspects of the agile development process ever, and with a wonderful animation. It touches most of the main points in agile; not just the practices but the reasons why they are there. It visualizes the big picture, placing the individual aspects into the context. It is Scrum and Product Owner-centric but still very valuable in a broader context. We recommend to watch it after becoming familiar with lean/agile (f.ex. by reading From Concept to Cash) as it is a great summary and a self-test of understanding agile.<br><br>It discusses among other things building the right thing vs. building it right vs. building it fast, technical debt, focus on value instead of features, saying no to requests, the estimation conversation.\r\n<h2>Closing Comments</h2>\r\nDo you also have such a list in your company? Would you care to share it?\r\n<h2>Update</h2>\r\nSome of the other books that the readers highly valued were <a href=\"http://www.amazon.com/Code-Complete-Practical-Handbook-Construction/dp/0735619670\">Code Complete: A Practical Handbook of Software Construction</a> and <a href=\"http://www.amazon.com/The-Pragmatic-Programmer-Journeyman-Master/dp/020161622X\">The Pragmatic Programmer: From Journeyman to Master</a>. We will evaluate whether to add any of them or replace a book from the list.",
  "excerpt": ""
 },
 {
  "title": "VisualVM: Monitoring Remote JVM Over SSH (JMX Or Not)",
  "published": "2012-09-21 16:35:43",
  "postType": "post",
  "slug": "/2012/09/21/visualvm-monitoring-remote-jvm-over-ssh-jmx-or-not/",
  "status": "publish",
  "tags": [
   "java",
   "jmx",
   "monitoring",
   "ops"
  ],
  "categories": [
   "General",
   "Languages",
   "Tools"
  ],
  "content": "<em>(Disclaimer: Based on personal experience and little research, the information might be incomplete.)</em><br><br>VisualVM is a great tool for monitoring JVM (5.0+) regarding memory usage, threads, GC, MBeans etc. Let's see how to use it over SSH to monitor (or even profile, using its sampler) a remote JVM either with JMX or without it.<br><br>This post is based on Sun JVM 1.6 running on Ubuntu 10 and VisualVM 1.3.3.<br><br><!--more-->\r\n<h2>1. Communication: JStatD vs. JMX</h2>\r\nThere are two modes of communication between VisualVM and the JVM: Either over the <a href=\"http://en.wikipedia.org/wiki/JMX\">Java Management Extensions</a> (JMX) protocol or over <a href=\"http://docs.oracle.com/javase/1.5.0/docs/tooldocs/share/jstatd.html\">jstatd</a>.\r\n<h3>jstatd</h3>\r\njstatd is a daemon that is distributed with JDK. You start it from the command line (it's likely necessary to run it as the user running the target JVM or as root) on the target machine and VisualVM will contact it to fetch information about the remote JVMs.\r\n<ul>\r\n\t<li>Advantages: Can connect to a running JVM, no need to start it with special parameters</li>\r\n\t<li>Disadvantages: Much more limited monitoring capabilities (f.ex. no CPU usage monitoring, not possible to run the Sampler and/or take thread dumps).</li>\r\n</ul>\r\nEx.:<br><br><pre><code>\r\nbash&gt; cat jstatd.all.policy\r\ngrant codebase &quot;file:${java.home}/../lib/tools.jar&quot; {\r\npermission java.security.AllPermission;\r\n}\r\nbash&gt; sudo /path/to/JDK/bin/jstatd -J-Djava.security.policy=jstatd.all.policy\r\n# You can specify port with -p number and get more info with -J-Djava.rmi.server.logCalls=true\r\n</code></pre><br><br>Note: Replace \"${java.home}/../lib/tools.jar\" with the absolute \"/path/to/jdk/lib/tools.jar\" if you have only copied but not installed the JDK.<br><br>If you get the failure<br><br><pre><code>\r\nCould not create remote object\r\naccess denied (java.util.PropertyPermission java.rmi.server.ignoreSubClasses write)\r\njava.security.AccessControlException: access denied (java.util.PropertyPermission java.rmi.server.ignoreSubClasses write)\r\nat java.security.AccessControlContext.checkPermission(AccessControlContext.java:374)\r\n</code></pre><br><br>then jstatd likely hasn't been started with the right java.security.policy file (try to provide fully qualified path to it).<br><br><a href=\"http://docs.oracle.com/javase/6/docs/technotes/guides/visualvm/applications_remote.html\">More info about VisualVM and jstatd</a> from Oracle.\r\n<h3>JMX</h3>\r\n<ul>\r\n\t<li>Advantages: Using JMX will give you the full power of VisualVM.</li>\r\n\t<li>Disadvantages: Need to start the JVM with some system properties.</li>\r\n</ul>\r\nYou will generally want to use something like the following properties when starting the target JVM (though you could also enable SSL and/or require username and password):<br><br><pre><code><br><br>yourJavaCommand... -Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.port=1098<br><br></code></pre><br><br>See <a href=\"http://docs.oracle.com/javase/6/docs/technotes/guides/visualvm/jmx_connections.html\">Remote JMX Connections</a>.\r\n<h2>2. Security: SSH</h2>\r\nThe easiest way to connect to the remote JMX or jstatd over ssh is to use a <a href=\"http://en.wikipedia.org/wiki/SOCKS\">SOCKS proxy</a>, which standard ssh clients can set up.\r\n<h3>2.1 Set Up the SSH Tunnel With SOCKS</h3>\r\n<pre><code>ssh -v -D 9696 my_server.example.com</code></pre>\r\n<h3>2.2 Configure VisualVM to Use the Proxy</h3>\r\nTools-&gt;Options-&gt;Network - Manual Proxy Settings - check it and configure SOCKS Proxy at localhost and port 9696\r\n<h3>2.3 Connect VisualVM to the Target</h3>\r\nFile -&gt; Add Remote Host... - type the IP or hostname of the remote machine\r\n<h4>JStatD Connection</h4>\r\nYou should see logs both in the ssh window (thanks to its \"-v\", f.ex. \"<em>debug1: Connection to port 9696 forwarding to socks port 0 requested.</em>\" and \"<em>debug1: channel 3: free: direct-tcpip: listening port 9696 for 10.2.47.71 port 1099, connect from 127.0.0.1 port 61262, nchannels 6</em>\") and in the console where you started jstatd (many, f.ex. \"<em>FINER: RMI TCP Connection(23)-10.2.47.71: ...</em>\")<br><br>Wait few minutes after having added the remote host, you should then see the JVMs running there.<br><br>Available stats: JVM arguments, Monitor: Heap, classes, threads monitoring (but not CPU). Sampler and MBeans require JMX.\r\n<h4>JMX</h4>\r\nRight-click on the remote host you have added and select Add JMX Connection ..., type the JMX port you have chosen.<br><br>You should see similar logs as with jstatd.<br><br>Available stats: Also CPU usage, system properties, detailed Threads report with access to stack traces, CPU sampling (memory sampling not supported).\r\n<h2>Note: Sampler vs. Profiler</h2>\r\nThe VisualVM's Sampler excludes time spent in Object.wait and Thread.sleep (f.ex. waiting on I/O). Use the <a href=\"http://profiler.netbeans.org/\">NetBeans Profiler</a> to profile or sample a remote application if you want to have more control or want the possibility to include Object.wait and Thread.sleep time. It requires its Remote Pack (a java agent, i.e. a JAR file) to be in the target JVM (NetBeans' Attach Wizard can generate the remote pack for you in step 4, Manual integration, and show you the options to pass to the target JVM to use it).<br><br>You can <a href=\"http://kirk.blog-city.com/profiling_on_the_cloud_with_netbeans.htm\">run the profiler over SSH by forwarding its default port</a> (5140) and attaching to the forwarded port at localhost.<br><br>(NetBeans version 7.1.1.)",
  "excerpt": ""
 },
 {
  "title": "Enabling JMX Monitoring for Hadoop And Hive",
  "published": "2012-09-21 17:02:24",
  "postType": "post",
  "slug": "/2012/09/21/enabling-jmx-monitoring-for-hadoop-and-hive/",
  "status": "publish",
  "tags": [
   "bigdata",
   "hadoop",
   "hive",
   "monitoring",
   "ops"
  ],
  "categories": [
   "Tools"
  ],
  "content": "Hadoop's NameNode and JobTracker expose interesting metrics and statistics over the JMX. Hive seems not to expose anything intersting but it still might be useful to monitor its JVM or do simpler profiling/sampling on it. Let's see how to enable JMX and how to access it securely, over SSH.<br><br><!--more--><br><br>Background: We run NameNode, JobTracker and Hive on the same server. Monitoring og TaskTrackers and DataNodes isn't that interesting but still might be useful to have.\r\n<h2>Configuration</h2>\r\n<h3>/etc/hadoop/hadoop-env.sh</h3>\r\n<pre><code>\r\ndiff --git a/etc/hadoop/hadoop-env.sh b/etc/hadoop/hadoop-env.sh\r\nindex 69a13b1..e8ca596 100644\r\n--- a/etc/hadoop/hadoop-env.sh\r\n+++ b/etc/hadoop/hadoop-env.sh\r\n@@ -14,7 +14,8 @@ export HADOOP_CONF_DIR=${HADOOP_CONF_DIR:-&quot;/etc/hadoop&quot;}\r\n #export HADOOP_NAMENODE_INIT_HEAPSIZE=&quot;&quot;<br><br> # Extra Java runtime options. Empty by default.\r\n-export HADOOP_OPTS=&quot;-Djava.net.preferIPv4Stack=true $HADOOP_CLIENT_OPTS&quot;\r\n+# Added $HIVE_OPTS that is set by hive-env.sh when starting hiveserver\r\n+export HADOOP_OPTS=&quot;-Djava.net.preferIPv4Stack=true $HADOOP_CLIENT_OPTS $HIVE_OPTS&quot;<br><br> # Command specific options appended to HADOOP_OPTS when specified\r\n export HADOOP_NAMENODE_OPTS=&quot;-Dhadoop.security.logger=INFO,DRFAS -Dhdfs.audit.logger=INFO,DRFAAUDIT $HADOOP_NAMENODE_OPTS&quot;\r\n@@ -43,3 +44,16 @@ export HADOOP_SECURE_DN_PID_DIR=/var/run/hadoop<br><br> # A string representing this instance of hadoop. $USER by default.\r\n export HADOOP_IDENT_STRING=$USER\r\n+\r\n+### JMX settings\r\n+export JMX_OPTS=&quot; -Dcom.sun.management.jmxremote.authenticate=false \\\r\n+    -Dcom.sun.management.jmxremote.ssl=false \\\r\n+    -Dcom.sun.management.jmxremote.port&quot;\r\n+#    -Dcom.sun.management.jmxremote.password.file=$HADOOP_HOME/conf/jmxremote.password \\\r\n+#    -Dcom.sun.management.jmxremote.access.file=$HADOOP_HOME/conf/jmxremote.access&quot;\r\n+export HADOOP_NAMENODE_OPTS=&quot;$JMX_OPTS=8006 $HADOOP_NAMENODE_OPTS&quot;\r\n+export HADOOP_SECONDARYNAMENODE_OPTS=&quot;$HADOOP_SECONDARYNAMENODE_OPTS&quot;\r\n+export HADOOP_DATANODE_OPTS=&quot;$JMX_OPTS=8006 $HADOOP_DATANODE_OPTS&quot;\r\n+export HADOOP_BALANCER_OPTS=&quot;$HADOOP_BALANCER_OPTS&quot;\r\n+export HADOOP_JOBTRACKER_OPTS=&quot;$JMX_OPTS=8007 $HADOOP_JOBTRACKER_OPTS&quot;\r\n+export HADOOP_TASKTRACKER_OPTS=&quot;$JMX_OPTS=8007 $HADOOP_TASKTRACKER_OPTS&quot;\r\n</code></pre><br><br>The JMX setting is used for Hadoop's daemons while the HIVE_OPTS was added for Hive.\r\n<h3>&lt;hive home&gt;/conf/hive-env.sh</h3>\r\nEnable JMX when running the Hive thrift server (we don't want it when running the command-line client etc. since it's pointless and we wouldn't need to make sure that each of them has a unique port):<br><br><pre><code>\r\nif [ &quot;$SERVICE&quot; = &quot;hiveserver&quot; ]; then\r\n  JMX_OPTS=&quot;-Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.port=8008&quot;\r\n  export HIVE_OPTS=&quot;$HIVE_OPTS $JMX_OPTS&quot;\r\nfi\r\n</code></pre>\r\n<h3>Pitfalls</h3>\r\nWhen you start Hive server via <em>hive --service hiveserver</em> then it actually executes \"<em>hadoop jar ...</em>\" so to be able to pass options from hive-env.sh to the JVM we had to add $HIVE_OPTS in hadoop-env.sh. (I haven't found a cleaner way to do it.)\r\n<h2>Effects</h2>\r\nWhen we now start Hive or any of the Hadoop daemons, they will expose their metrics at their respective ports (NameNode - 8006, JobTracker - 8007, Hive - 8008).<br><br>(If you are running DataNode and/or TaskTracker on the same machine then you'll need to change their ports to be unique.)\r\n<h2>Secure Connection Over SSH</h2>\r\nRead the post <a title=\"VisualVM: Monitoring Remote JVM Over SSH (JMX Or Not)\" href=\"/2012/09/21/visualvm-monitoring-remote-jvm-over-ssh-jmx-or-not/\">VisualVM: Monitoring Remote JVM Over SSH (JMX Or Not)</a> to find out how to connect securely to the JMX ports over ssh, f.ex. with VisualVM (spolier: ssh -D 9696 hostname; use proxy at localhost:9696).\r\n<h2>Note: Accessing the Metrics Via The Hadoop JMX JSON Servlet</h2>\r\nYou can get the metrics also without JMX, through the NameNode/JobTracker's web interface (<a href=\"http://hadoop.apache.org/docs/r1.0.1/api/index.html\">JMXJsonServlet</a>; at least in Hadoop 1.0.1):<br><br><pre><code>curl -i http://localhost:50070/jmx</code></pre><br><br>Which will return lot of information about both Hadoop and the JVM as JSON:<br><br><pre><code>\r\n...\r\n{\r\n    &quot;name&quot; : &quot;Hadoop:service=NameNode,name=NameNodeInfo&quot;,\r\n    &quot;modelerType&quot; : &quot;org.apache.hadoop.hdfs.server.namenode.FSNamesystem&quot;,\r\n    &quot;Used&quot; : 1648071774208,\r\n    &quot;UpgradeFinalized&quot; : true,\r\n    &quot;Free&quot; : 613441536,\r\n    &quot;Safemode&quot; : &quot;&quot;,\r\n    &quot;NonDfsUsedSpace&quot; : 92258828288,\r\n    &quot;PercentUsed&quot; : 94.665405,\r\n    &quot;PercentRemaining&quot; : 0.035236143,\r\n    &quot;TotalBlocks&quot; : 35009,\r\n    &quot;TotalFiles&quot; : 98441,\r\n    &quot;LiveNodes&quot; : &quot;{\\&quot;staging-data01.example.com\\&quot;:{\\&quot;usedSpace\\&quot;:399837089792,\\&quot;lastContact\\&quot;:0},\\&quot;staging-data02.example.com\\&quot;:{\\&quot;usedSpace\\&quot;:148883341312,\\&quot;lastContact\\&quot;:0}}&quot;,\r\n    &quot;DeadNodes&quot; : &quot;{}&quot;,\r\n    &quot;DecomNodes&quot; : &quot;{}&quot;,\r\n    &quot;Threads&quot; : 35,\r\n    &quot;HostName&quot; : &quot;staging-name.example.com&quot;,\r\n    &quot;Version&quot; : &quot;1.0.1, r1243785&quot;,\r\n    &quot;Total&quot; : 1740944044032\r\n  },\r\n...\r\n</code></pre><br><br>You can fetch only a particular key with the <var>qry</var> parameter:<br><br><pre><code>curl -i http://localhost:50070/jmx?qry=Hadoop:service=NameNode,name=NameNodeInfo</code></pre><br><br>An the expectable response:<br><br><pre><code>\r\nHTTP/1.1 200 OK\r\nContent-Type: application/json; charset=utf8\r\nContent-Length: 1417\r\nServer: Jetty(6.1.26)<br><br>{\r\n  &quot;beans&quot; : [ {\r\n    &quot;name&quot; : &quot;Hadoop:service=NameNode,name=NameNodeInfo&quot;,\r\n    &quot;modelerType&quot; : &quot;org.apache.hadoop.hdfs.server.namenode.FSNamesystem&quot;,\r\n    ...\r\n  } ]\r\n</code></pre><br><br>The examples above use NameNode's port 50070. Change it to JobTracker's 50030 to get information about Map-Reduce.<br><br>Some keys of interest:\r\n<ul>\r\n\t<li>NameNode\r\n<ul>\r\n\t<li>Hadoop:service=NameNode,name=RpcActivityForPort8020\r\n<ul>\r\n\t<li>RpcQueueTime_avg_time, RpcProcessingTime_avg_time - is the latency increasing?</li>\r\n</ul>\r\n</li>\r\n\t<li>Hadoop:service=NameNode,name=FSNamesystemState\r\n<ul>\r\n\t<li>CapacityTotal, CapacityUsed, CapacityRemaining, TotalLoad, UnderReplicatedBlocks, FSState</li>\r\n</ul>\r\n</li>\r\n\t<li>Hadoop:service=NameNode,name=FSNamesystemMetrics\r\n<ul>\r\n\t<li>CorruptBlocks, MissingBlocks (not sure it is for the whole FS, though)</li>\r\n</ul>\r\n</li>\r\n\t<li>Hadoop:service=NameNode,name=NameNodeInfo\r\n<ul>\r\n\t<li>LiveNodes (incl. usedSpace), DeadNodes, DecomNodes, PercentRemaining / PercentUsed</li>\r\n</ul>\r\n</li>\r\n</ul>\r\n</li>\r\n\t<li>JobTracker\r\n<ul>\r\n\t<li>Hadoop:service=JobTracker,name=RpcActivityForPort8021 - as for NameNode</li>\r\n\t<li>Hadoop:service=JobTracker,name=JobTrackerMetrics\r\n<ul>\r\n\t<li>jobs_submitted, jobs_completed, jobs_failed, jobs_killed, jobs_running</li>\r\n</ul>\r\n</li>\r\n</ul>\r\n</li>\r\n</ul>",
  "excerpt": ""
 },
 {
  "title": "Using Java as Native Linux Apps - Calling C, Daemonization, Packaging, CLI (Brian McCallister)",
  "published": "2012-09-25 19:24:17",
  "postType": "post",
  "slug": "/2012/09/25/using-java-as-native-linux-apps-calling-c-daemonization-packaging-cli-brian-mccallister/",
  "status": "publish",
  "tags": [
   "daemon",
   "deployment",
   "java",
   "linux",
   "native",
   "ops"
  ],
  "categories": [
   "Languages"
  ],
  "content": "This is a summary of the excellent JavaZone 2012 talk <a href=\"https://vimeo.com/49478286\">Going Native (vimeo)</a> by <a href=\"http://skife.org/\">Brian McCallister</a>. Content: Using native libraries in Java and packaging them with Java apps, daemonization, trully executable JARs, powerful CLI, creating manpages, packaging natively as deb/rpm.<br><br><h2>1. Using Native Libs in Java</h2>\r\n<h3>Calling Native Libs</h3>\r\nCalling native libraries such as C ones was hard and ugly with JNI but is very simple and nice with <a href=\"https://github.com/twall/jna\">JNA</a> (GPL) and <a href=\"https://github.com/jnr/jffi\">JNR</a> (Apache/LGPL)\r\n<!--more--><br><br>JNR and JNA use the functions <a href=\"http://tldp.org/HOWTO/Program-Library-HOWTO/dl-libraries.html\">dlopen, dlsym</a> to dynamically load a shared library and symbols (i.e. functions) in it.<br><br>The JNA code belows shows how to load the library MagickWand (/usr/lib/libMagickWand.so) and call some methods mapped to native functions on it, e.g. MagickWandGenesis.<br><br><pre><code>\r\n// 1. The interfaceto use a dynamically loaded native lib:\r\nimport jnr.ffi.Pointer;\r\npublic interface MagickWand {\r\n  public void MagickWandGenesis();\r\n  /* MagickWand* */ Pointer NewMagickWand();\r\n  int MagickReadImage(Pointer wand, String path);\r\n}\r\n// 2. Using it:\r\nint MagickFalse = 0;\r\nfinal MagickWand w =\r\nLibrary.loadLibrary(&quot;MagickWand&quot;, MagickWand.class);\r\nw.MagickWandGenesis();\r\nPointer magick_wand = w.NewMagickWand();\r\nint rs = w.MagickReadImage(magick_wand, &quot;bunny.jpg&quot;);\r\nif (rs == MagickFalse) {\r\n   fail(&quot;bad exit code&quot;);\r\n}\r\n</code></pre><br><br>See <a href=\"https://github.com/twall/jna/blob/master/www/GettingStarted.md\">Getting Started with JNA</a> for more examples, this time based on JNA.<br><br><h3>Packaging Native Libs with Your Java App</h3>\r\nOk, so we can call a native library but how we get to it? One way to ensure the native lib is on the target system is to package it with your java application. <a href=\"http://fusesource.com/forge/sites/hawtjni/\">Hawt-JNI</a> is a library and Maven plugin that (among others) makes it possible to build a native library, attach it to you application and load it at runtime.<br><br><a href=\"https://github.com/fusesource/leveldbjni/blob/master/leveldbjni/src/main/java/org/fusesource/leveldbjni/internal/NativeDB.java\">Leveldbjni uses JNI to access the native leveldb</a> library and Hawt-JNI to generate JNI code from annotations (instead of using the more user-friendly JNA or JNR) and to include it inside its JAR and to access it.<br><br>The auto-loading of the packaged native library is done by the Hawt-JNI call<br><br><pre><code>\r\nprivate static final Library LIBRARY = new Library(&quot;simple&quot;, Simple.class);\r\nstatic {\r\n  LIBRARY.load();\r\n}\r\n</code></pre><br><br>- it does the same thing as <code>System.loadLibrary(\"simple\")</code> but also extracts the library from the JAR and loads if from there (<a href=\"http://hawtjni.fusesource.org/documentation/developer-guide.html#getting-started\">copied from the doc</a>).<br><br>You might want to check out <a href=\"http://github.com/chirino/hawtjni/tree/master/hawtjni-example/\">the example Hawt-JNI maven project</a> and perhaps alos <a href=\"http://hawtjni.fusesource.org/documentation/developer-guide.html#adding-to-maven-build\">How to Add HawtJNI to an Existing Maven Build</a>. Notice you don't need to use Hawt to build you library, you can use is as well to only package it in (goal package-jar) and to load it.<br><br>This is how a maven library with baked-in native libs looks like:<br><br><pre><code>\r\n$ unzip -l leveldbjni-all-1.2.jar | grep libleveldbjni\r\n655754 02-27-12 12:44 META-INF/native/linux32/libleveldbjni.so\r\n707423 02-27-12 12:44 META-INF/native/linux64/libleveldbjni.so\r\n446052 02-27-12 12:44 META-INF/native/osx/libleveldbjni.jnilib\r\n</code></pre>\r\n<h2>2. Daemonization</h2>\r\nDaemonization of Java apps wasn't easy. You'd often use <a href=\"http://commons.apache.org/daemon/\">commons-daemon</a> or create a wrapper script leveraging e.g. Ubuntu's start-stop-daemon. Daemonization is difficult because you need to do lot of stuff that is difficult from the JVM: fork, setsid so you parent doesn't own you, dup to protect your files, fork again, …. Fork in Java is risky (you'd miss all system threads such as gc; risk of incosistencies), the rest can be faked via posix - but you can basically use posix_spawn instead (via jnr-ffi). Read on!\r\n<h3>Gressil: The Daemonization Library (~25min in the talk)</h3>\r\n<a href=\"http://github.com/brianm/gressil\">Gressil</a> is a Java library created by Brian for simple and nice daemonization of Java apps (it basically spawns a new JVM via jnr-ffi, handles pid file, stdin/stderr/out etc.)<br><br><pre><code>\r\npublic static void main(String[] args) throws IOException\r\n{\r\n  new Daemon().withMainArgs(args)\r\n              .withPidFile(new File(&quot;/tmp/chatty.pid&quot;))\r\n              .withStdout(new File(&quot;/tmp/chatty.out&quot;))\r\n              .withExtraMainArgs(&quot;hello&quot;, &quot;world,&quot;)\r\n              .withExtraJvmArgs(remoteDebugOnPort(5005))\r\n              .daemonize();\r\n  ...\r\n}\r\n</code></pre><br><br>Isn't that cool?\r\n<h2>3. Using Java As a Proper Linux Program (27min)</h2>\r\nJAR is just a ZIP file and zip allows for arbitrary crap at the beginning (until a magic number) =&gt; you can prepend e.g. a shell script to expand the jar (beware: you need the empty line after the exec otherwise jar gets confused):<br><br><pre><code><br><br>$ head -4 ./target/dwarf # this is actually a .jar\r\n#!/bin/sh<br><br>exec java -jar &quot;$0&quot; &quot;$@&quot;<br><br>$<br><br></code></pre><br><br>You can use Brian's <a href=\"https://github.com/brianm/really-executable-jars-maven-plugin\">Maven plugin really-executable-jars</a> to create such an executable JAR for you.<br><br>End result:<br><br><pre><code>\r\n  # Instead of executing this:\r\n$ java -jar ./dwarf.jar --waffles=yes\r\n  # You can execute this:\r\n$ dwarf --waffles=yes\r\n</code></pre><br><br>Check out Brian's project Dwarf (link at the bottom of this post) for a practical example using the Maven plugin.\r\n<h2>4. Better CLI With Airline (~31 min)</h2>\r\n<a href=\"http://github.com/airlift/airline\">Airline</a> is a Java library for creating better command-line interfaces. It has also support for commands (such as git's git add, git log) that are implemented by individual classes. It even generates bash autocompletion.<br><br><pre><code>\r\npublic static void main(String[] args)\r\n{\r\n  CliBuilder builder = Cli.buildCli(&quot;git&quot;, Runnable.class)\r\n          .withDescription(&quot;the stupid content tracker&quot;)\r\n          .withDefaultCommand(Help.class)\r\n          .withCommands(Help.class, Add.class);\r\n  builder.withGroup(&quot;remote&quot;)\r\n         .withDescription(&quot;Manage set of tracked repositories&quot;)\r\n         .withDefaultCommand(RemoteShow.class)\r\n         .withCommands(RemoteShow.class, RemoteAdd.class);\r\n  Cli gitParser = builder.build();\r\n  gitParser.parse(args).run();\r\n}<br><br>// And the add command implementation:\r\n@Command(name=&quot;add&quot;, description=&quot;Add file contents to the index&quot;)\r\npublic static class Add implements Runnable\r\n{\r\n  @Option(type=OptionType.GLOBAL, name=&quot;-v&quot;, description=&quot;Verbose mode&quot;)\r\n  public boolean verbose;<br><br>  @Arguments(description = &quot;Patterns of files to be added&quot;)\r\n  public List patterns;<br><br>  @Option(name=&quot;-i&quot;, description=&quot;Add modified contents interactively.&quot;)\r\n  public boolean interactive;<br><br>  public void run()\r\n  {\r\n    System.out.println(getClass().getSimpleName());\r\n  }\r\n}\r\n</code></pre><br><br>And the use of it:<br><br><pre><code>\r\n$ git help\r\nusage: git [-v] &lt;command&gt; []\r\nThe most commonly used git commands are:\r\n    add       Add file contents to the index\r\n    help      Display help information\r\n    remote    Manage set of tracked repositories\r\nSee 'git help &lt;command&gt;' for more information on a specific command.\r\n</code></pre>\r\n<h2>5. Creating Manpages</h2>\r\nThe Man pages native format is terrible but fortunately you can use <a href=\"http://daringfireball.net/projects/markdown/\">Markdown</a> and the command-line utility <a href=\"http://rtomayko.github.com/ronn\">ronn</a> to turn it into a manpage. (It basically turns md into html and then via some black magic incantantions into grof.)\r\n<h2>6. Packaging (37min)</h2>\r\nYou have an executable, a man page, perhaps some scripts and now you want to install them on the target system. The best way is to use its native package manager.\r\n<ul>\r\n\t<li> .deb: mvn plugin <a href=\"http://github.com/tcurdt/jdeb\">jdeb</a> (deb ~ tar)</li>\r\n\t<li>.rpm: mvn plugin <a href=\"http://mojo.codehouse.org/rpm-maven-plugin\">rpm-maven-plugin</a>, needs locally installed <a href=\"http://www.rpm.org/max-rpm-snapshot/rpmbuild.8.html\">rpmbuild</a></li>\r\n\t<li>mac: a mess, use e.g. homebrew manually</li>\r\n</ul>\r\n<h2>Example Project: Dwarf</h2>\r\nBrian used many of this techniques in his open source <a href=\"https://github.com/brianm/dwarf/\">project Dwarf</a> so check it out. <a href=\"https://github.com/brianm/dwarf/blob/master/pom.xml\">It uses f.ex</a> jdeb, manpage generation from Markdown via ronn (manually), executable jar.<br><br>That's all, folks! Go and watch the <a href=\"https://vimeo.com/49478286\">Going Native video</a>!\r\n<h2>Related</h2>\r\nBrian's posts\r\n<ul>\r\n\t<li><a href=\"http://skife.org/java/2012/01/24/java_daemonization_with_gressil.html\">Java Daemonization with posix_spawn(2)</a>, also introducing Gressil</li>\r\n\t<li><a href=\"http://skife.org/java/2012/01/10/posix_from_java.html\">POSIX from Java</a> - proper access to POSIX and libc system calls,  <a href=\"https://github.com/jnr/jnr-posix\">jnr-posix</a></li>\r\n\t<li><a href=\"http://skife.org/java/unix/2011/06/20/really_executable_jars.html\">Making Really Executable Jars</a></li>\r\n</ul>\r\n<em>Acknowledgement: Thanks to Brian for providing his slides and granting the permission to use the examples from them.</em>",
  "excerpt": ""
 },
 {
  "title": "Infographic: Why Should All Learn Little Code",
  "published": "2012-09-24 08:39:41",
  "postType": "post",
  "slug": "/2012/09/24/infographic-why-should-all-learn-little-code/",
  "status": "publish",
  "tags": [
   "learning"
  ],
  "categories": [
   "General"
  ],
  "content": "<a href=\"http://www.onlinecollege.org/Program-or-Be-Programmed\">\r\n<img src=\"https://s3.amazonaws.com/infographics/Rise-of-Coding-Finall.jpg\" alt=\"Programming Infographic (by OnlineCollege.org)\" width=\"500\" border=\"0\" />\r\n</a><br><br><em>By <a href=\"http://www.onlinecollege.org/Program-or-Be-Programmed\">OnlineCollege.org</a></em><br><br>BTW, <a href=\"http://www.codecademy.com/\">Codecademy</a> is really fun.",
  "excerpt": ""
 },
 {
  "title": "Note: Loading Tab-Separated Data In Cascalog",
  "published": "2012-10-09 13:41:40",
  "postType": "post",
  "slug": "/2012/10/09/note-loading-tab-separated-data-in-cascalog/",
  "status": "publish",
  "tags": [
   "bigdata",
   "cascalog",
   "clojure",
   "java"
  ],
  "categories": [
   "General",
   "Languages",
   "Tools"
  ],
  "content": "To load all fields from a tab-separated text file in <a href=\"https://github.com/nathanmarz/cascalog/\">Cascalog</a> we need to use the generic hfs-tap and specify the \"scheme\" (notice that loading all fields and expecting tab as the separator is the default behavior of <a href=\"http://docs.cascading.org/cascading/2.0/javadoc/cascading/scheme/hadoop/TextDelimited.html\">TextDelimited</a>):<br><br><pre><code>\r\n (hfs-tap\r\n   (cascading.scheme.hadoop.TextDelimited.)\r\n   &quot;hdfs:///user/hive/warehouse/playerevents/epoch_week=2196/output_aewa-analytics-ada_1334697041_1.log&quot;)\r\n</code></pre><br><br>With a custom separator and fields:<br><br><pre><code>\r\n (hfs-tap\r\n   (cascading.scheme.hadoop.TextDelimited. (cascalog.workflow/fields [&quot;?f1&quot; &quot;?f2&quot;]) &quot;\\t&quot;) ; or cascading.tuple.Fields/ALL inst. of (fields ...)\r\n   &quot;hdfs:///user/hive/warehouse/playerevents/epoch_week=2196/output_aewa-analytics-ada_1334697041_1.log&quot;)\r\n</code></pre><br><br><a href=\"http://docs.cascading.org/cascading/2.0/userguide/html/ch03s06.html\">Hadoop doesn't manage to load data files from nested sub-directories</a> (for example from a Hive partitioned table). To load them, you need to use a \"glob pattern\" to turn the standard Hfs tap into a <a href=\"http://docs.cascading.org/cascading/2.0/javadoc/cascading/tap/hadoop/GlobHfs.html\">GlobHfs</a> tap. This is how we would match all the subdirectories (Hadoop will then handle loading the files in them):<br><br><pre><code>\r\n (hfs-tap\r\n   (cascading.scheme.hadoop.TextDelimited.)\r\n   &quot;hdfs:///user/hive/warehouse/playerevents/&quot;\r\n   :source-pattern &quot;epoch_week=*/&quot;)\r\n</code></pre><br><br>Enjoy.",
  "excerpt": ""
 },
 {
  "title": "My Scala vs. Clojure Impression In Pictures",
  "published": "2012-10-13 12:21:50",
  "postType": "post",
  "slug": "/2012/10/13/my-scala-vs-clojure-impression-in-pictures/",
  "status": "publish",
  "tags": [
   "clojure",
   "java",
   "opinion",
   "scala"
  ],
  "categories": [
   "General",
   "Languages"
  ],
  "content": "<table border=\"0\">\n<tbody>\n<tr>\n<td>\n<div style=\"background-image:url('/images/2012/10/church-gothic.jpg');background-position:0 -110px;height:333px;width:333px;\" title=\"Church of Saint-Pierre, Aulnay, France\"></div>\n<p style=\"text-align:right;\"><small>(By <a href=\"http://www.flickr.com/photos/art_roman_p/\">kristobalite</a>)</small></p>\n<em>Clojure</em>:\nClean\nStructured\nFocused</td>\n<td>\n<div style=\"background-image:url('/images/2012/10/chruch-baroque.jpg');background-position:-60px 0;height:333px;width:333px;\" title=\"Cathedral of Granada, Spain\"></div>\n<p style=\"text-align:right;\"><small>(By <a href=\"http://www.flickr.com/photos/taudiophile/\">agiamba</a>)</small></p>\n<em>Scala</em>:\nAdorned\nOverflowing\nMagnificent</td>\n</tr>\n</tbody>\n</table><br><br>Clojure has a zen-like quality to it. There is extreme focus on <a href=\"/2012/05/09/beautiful-code-simplicity-yields-power/\">simplicity</a>, on defining few elementary orthogonal concepts that can be combined in powerful ways. For example it <a href=\"http://clojure.com/blog/2012/02/17/clojure-governance.html\">took 3 years</a> for Clojure to get named parameters - but the result, destructuring, is something much richer and more applicable, that fits the language perfectly and has become a core part of idiomatic Clojure.<br><br>Scala feels as if trying to empower the programmer in any possible way, throwing in shortcuts, syntactic sugar, and plenty of methods so that anything can be done with the minimal amount of code. It is overwhelming.<br><br><em>Disclaimer: I have only a few weeks of experience with Scala and are in no position to judge it. This is just an impression I have gained so far and nothing more. I'm sure it is a great language.</em>",
  "excerpt": ""
 },
 {
  "title": "Puppet Troubleshooting: Compiling Catalog, Locating a Cached Catalog",
  "published": "2012-10-17 07:34:17",
  "postType": "post",
  "slug": "/2012/10/17/puppet-where-to-find-the-cached-catalog-on-client/",
  "status": "publish",
  "tags": [
   "DevOps",
   "puppet"
  ],
  "categories": [
   "Tools"
  ],
  "content": "Few troubleshooting tips for Puppet.\r\n<h2>Where to Find the Cached Catalog On Client</h2>\r\nPuppet Agent caches its compiled (text/Ruby) catalog under its $vardir, for example Puppet 0.25.x stores it into <code>/var/lib/puppet/client_yaml/catalog/&lt;hostname&gt;.yaml</code>. It might be useful when troubleshooting.\r\n<h2>Compiling Catalog Manually</h2>\r\nYou can compile the catalog for a particular node manually on the Puppet Master. Ex.:<br><br><pre><code>puppetmasterd --compile mynode.example.com &gt; mynode_catalog</code></pre><br><br>The compilation uses locally cached facts, typically in <code>/var/lib/puppet/yaml/facts/&lt;hostname&gt;.yaml</code> .<br><br>You can try the catalog manually on the node (though retrieving files via puppet://puppet/... will fail). You will first need delete the leading lines with messages/warnings from the compilation process, if any (such as \"[warning] ...\"):<br><br><pre><code>puppet --noop --apply mynode_catalog</code></pre>",
  "excerpt": ""
 },
 {
  "title": "Tool Tip: Byob - Screen With Text UI",
  "published": "2012-10-17 12:21:21",
  "postType": "post",
  "slug": "/2012/10/17/tool-tip-byob-screen-with-text-ui/",
  "status": "publish",
  "tags": [
   "linux"
  ],
  "categories": [
   "Tools"
  ],
  "content": "<a href=\"http://www.rackaid.com/resources/linux-screen-tutorial-and-how-to/\" rel=\"nofollow\">Screen</a> (<a href=\"http://linux.die.net/man/1/screen\" rel=\"nofollow\">man</a>) is very useful for running terminal sessions on remote computers that enable the user to disconnect and re-connect. <a href=\"http://en.wikipedia.org/wiki/Byobu_%28software%29\">Byobu</a> (<a href=\"http://manpages.ubuntu.com/manpages/oneiric/en/man1/byobu.1.html\">man</a>), formerly also called screen-profiles, is a wrapper script for screen that adds status lines with useful info to screen and provides text UI for configuring it (byobu-config).<br><br>Screen allows you to have multiple \"windows\" (terminal sessions) opened at the same time and jump between them (C-a n). You can also display multiple windows if you split your screen.<br><br>Few screen/byobu tips (C-a means Contol-a):\r\n<ul>\r\n\t<li>Configuration\r\n<ul>\r\n\t<li>Increase scroll history via \"screen -h &lt;num lines&gt;\" or \"defscrollback &lt;num lines&gt;\" in ~/.screenrc</li>\r\n</ul>\r\n</li>\r\n\t<li>Detach from screen: C-a d</li>\r\n\t<li>Re-attach to screen: screen -rd</li>\r\n\t<li>Split vertically: C-a |\r\n<ul>\r\n\t<li>Jump to the new split (or back): C-a tab</li>\r\n\t<li>Create new window in the split (=&gt; shell): C-a c</li>\r\n\t<li>Remove all splits but the current one: C-a Q</li>\r\n</ul>\r\n</li>\r\n\t<li>Next window: C-a n</li>\r\n\t<li>Pass \"C-a\" to the terminal running under screen: \"C-a a\"</li>\r\n\t<li>Help \"C-a ?\"</li>\r\n\t<li>Byobu: disable the Fn keys and only use the traditional screen commands: run byobu-config and select to use only them\r\n<ul>\r\n\t<li>To access Bybou menu (config) type, instead of F9, C-a @</li>\r\n</ul>\r\n</li>\r\n</ul>",
  "excerpt": ""
 },
 {
  "title": "Most interesting links of October ''12",
  "published": "2012-10-31 21:59:21",
  "postType": "post",
  "slug": "/2012/10/31/most-interesting-links-of-october-12/",
  "status": "publish",
  "tags": [
   "bash",
   "clojure",
   "java",
   "legacy",
   "productivity",
   "quality",
   "scala"
  ],
  "categories": [
   "General",
   "Languages",
   "Testing",
   "Tools",
   "Top links of month"
  ],
  "content": "<h2>Recommended Readings</h2>\r\n<ul>\r\n\t<li><a href=\"http://automagical.rationalmind.net/2010/08/17/some-lesser-known-truths-about-programming/\">David Veksler: Some lesser-known truths about programming</a> - things newcomers into the field of IT don't know and don't expect, true and an interesting read. Not backed by good data but anyway. F.ex.: \"[..] a programmer spends about 10-20% of his time writing code [..] much of the other 90% thinking, researching, and experimenting\". \"A good programmer is ten times more productive than an average programmer. A great programmer is 20-100 times more productive than the average [..]\" \"Bad programmers write code which lacks conceptual integrity, non-redundancy, hierarchy, and patterns, and so is very difficult to refactor.\" \"Continuous change leads to software rot, which erodes the conceptual integrity of the original design.\" \"A <a href=\"http://www.softwaremag.com/focus-areas/application-development/product-coverage/standish-project-success-rates-improved-over-10-years/\">2004 study found that</a> most software projects (51%) will fail in a critical aspect, and 15% will fail totally.\"</li>\r\n\t<li>Brett L. Schuchert: <a href=\"http://martinfowler.com/articles/modernMockingTools.html\">Modern Mocking Tools and Black Magic - An example of power corrupting</a> - interesting for two reasons: a good analysis of a poorly written piece of code and discussion of the code injection black magic (<a href=\"http://code.google.com/p/jmockit/\">JMockIt</a>) vs. actually breaking dependencies to enable tests.  The author presents a typical example of low-quality method (mixing multiple concerns, mixing different levels of abstractions, untestable due to a hardcoded use of an external call) and discusses ways to improve it and to make it testable. Recommended to read.</li>\r\n\t<li><a href=\"http://pragprog.com/magazines/2012-10/its-not-about-the-unit-tests\">It’s Not About the Unit Tests - Learning from iOS Developers</a>: iOS developers don't do much testing yet they manage to produce high quality. How is that possible? The key isn't testing itself, but caring for the code. (Of course, iOS is little special: small apps, no legacy, a powerful platform that does lot for the apps, very visual apps.) \"It’s not about the practices. It’s about the spirit and intent behind them, and how they are applied.\" (M. Fowler had a similar observation about a team that used mock-based testing exclusively and thus lacked integration tests yet all worked. [I've lost the link to the post and would be grateful for it])</li>\r\n\t<li><a href=\"http://www.javacodegeeks.com/2012/10/java-code-quality-tools-overview.html\">Java Code Quality Tools – Overview</a> - brief descriptions of 44 quality-related tools including some interesting tools and Eclipse plugins I didn't know or knew but forgot. F.ex. analysis of dependencies with <a href=\"http://www.jboss.org/tattletale\">JBoss Tattletale</a> or <a href=\"http://www.kirkk.com/main/Main/JarAnalyzer\">JarAnalyzer</a>, <a href=\"http://clirr.sourceforge.net/\">Clirr</a> to check libraries for source and binary backwards compatibility, <a href=\"http://jdiff.sourceforge.net/\">JDiff</a> generates JavaDoc-based report of removed/added/changed in an API. <a href=\"http://spoon.gforge.inria.fr/\">Spoon</a> - read and check or transform Java code. <a href=\"http://babelfish.arc.nasa.gov/trac/jpf\">Java PathFinder</a> (NASA) - special JVM capable of checking all execution path to discover concurrency defects etc.</li>\r\n</ul>\r\n<h2>Tools</h2>\r\n<ul>\r\n\t<li><a href=\"http://www.linuxjournal.com/article/10585?page=0,0\">DirB, Directory Bookmarks for Bash</a> (<a href=\"http://www.dirb.info/\">home</a>) - moving efficiently among favourite directories (<code>s &lt;name&gt;</code> to create a bookmark for pwd, <code>g &lt;bookmark | relative/abs dir path&gt;</code> to enter a dir (=&gt; works both for bookmarks and as a replacement for cd); also support for relative path bookmarks &amp; more; <code>sl</code> lists bookmakrs in the last used order) (You might also want to check out <a href=\"http://jakemccrary.com/blog/2011/07/25/utilities-i-like-autojump/\">Autojump</a>, <a href=\"/2011/12/31/most-interesting-links-of-december-2/\">described in Dec 11</a>; <a href=\"http://www.huyng.com/projects/bashmarks/\">bashmarks</a> is another similar project. Another similar project is rupa's <a href=\"https://github.com/rupa/z\">z</a> and <a href=\"https://github.com/rupa/j2\">j2</a> and the fish clone <a href=\"https://github.com/sjl/z-fish\">z-fish</a>)</li>\r\n</ul>\r\n<h2>Clojure Corner</h2>\r\n<ul>\r\n\t<li> Jon Pither: <a href=\"http://www.pitheringabout.com/?p=693\">Clojure at a Bank – Moving from Java</a> -  the justification (productivity, dynamism, FP a better match for the domain) and process behind moving from Java to Clojure with a monolithic 1M LOC Spring/Hibernate app. (Random quotes: \"I had used some dynamical languages before and it was quite obvious that we were essentially forcing lots of schema and type definition on to a problem domain that just didn’t want or need it.\" \"[..] it [dependency injection] just looks redundant in retrospect now that I’m working 95% with FP code.\") There is also a EuroClojure <a href=\"http://vimeo.com/45130708\">talk about their experiences</a> one year later (35 min).</li>\r\n\t<li><a href=\"http://blog.getprismatic.com/blog/2012/10/1/prismatics-graph-at-strange-loop.html\">Prismatic's \"Graph\" at Strange Loop</a> - an interesting desing problem, its solution, and a resulting OSS library. The problem: How to break a large function into independently usable small ones that might depend on each other without ever needing to recompute a value once the function producing is called. The solution: Graph - \"Graph is a <em>simple</em>, <em>declarative</em> abstraction to express compositional structure.\" (Enabling explicit declaration of data dependencies and pluging in different implementations.)</li>\r\n\t<li>The Oblong: Blog about 2/3 D <a href=\"http://oblong-code.blogspot.no/\">game programming in Clojure</a>, starting from scratch (w/o an engine); interesting experiences</li>\r\n\t<li><a href=\"http://clojurefun.wordpress.com/2012/09/03/ironclad-steam-legions-clojure-game-development-battle-report/\">Ironclad: Steam Legions – Clojure game development battle report</a> (the game <a href=\"https://github.com/mikera/ironclad\">on Github</a>)</li>\r\n\t<li><a href=\"http://variadic.me/posts/2012-03-29-building-wishlisted.html\">Building the Wishlisted.org webapp in Clojure</a> - experiences from learning Clojure for real by building a webapp in Noir</li>\r\n\t<li><a href=\"http://blog.markwatson.com/2012/10/clojure-vs-scala-smackdown.html\">Clojure vs. Scala smackdown</a> (\"Just kidding with the title of this post :-)\") - a short post with interesting discussion. Dmitri Sotnikov's opinion resonates with me: \"I found that for me Clojure wins on simplicity and consistency. While it looks more alien initially, once you learn the basics, you just reuse the same patterns everywhere.\" Some more comments: \"One major concern was maintainability, since it's fairly easy to write very dense code. This turned out to not be a problem in practice. Because Clojure code is written as a tree, refactoring it is very easy.\" REPL seems to be a big win (applies to Scala too). Scala's type system might get tedious and learning its quirks takes time but there is lot of potential and both have they strong sides.</li>\r\n\t<li><a href=\"http://www.colourcoding.net/blog/archive/2012/10/15/code-fatigue.aspx\">Code Fatigue</a> - discussion of the advantages of learning, using, and combining the (many) standard Clojure functions instead of a \"basic solution\" using recursion etc. The argument is in favor of higher-level code with less complexity in the form of branching, recursion, nested expressions etc. and thus less mental fatigue.</li>\r\n</ul>\r\n<h2>Favorite Quotes</h2>\r\n<blockquote>A classic test only cares about the final state - not how that state was derived. Mockist tests are thus <em>more coupled to the implementation</em> [emphasis mine] of a method. Changing the nature of calls to collaborators usually cause a mockist test to break.<br><br><em>- Martin Fowler in his classical <a href=\"http://martinfowler.com/articles/mocksArentStubs.html\">Mocks Aren't Stubs</a></em></blockquote>\r\nI'm afraid of code. When I see a big pile of code, I get scared ;-). Some classes and method make me cry. I had troubles explaining why I prefer short pieces of code keeping the same level of abstraction, cohesive and loosely coupled. The following quote captures the essence - improved communication.\r\n<blockquote>One way to improve communication is to reduce the need for it and the same can be said for code. [...] Since we tend to read code more than write it, anything we can do to reduce the need to read code is time well invested in the life of a project.<br><br>- Brett L. Schuchert in <a href=\"http://martinfowler.com/articles/modernMockingTools.html\">Modern Mocking Tools and Black Magic - An example of power corrupting</a> justifying extraction of code into another class or method</blockquote>",
  "excerpt": ""
 },
 {
  "title": "Tip: Import Leiningen Project to IntelliJ (With Dependencies)",
  "published": "2012-10-26 22:18:43",
  "postType": "post",
  "slug": "/2012/10/27/tip-import-leiningen-project-to-intellij-with-dependencies/",
  "status": "publish",
  "tags": [
   "clojure",
   "intellij",
   "lein"
  ],
  "categories": [
   "Tools"
  ],
  "content": "To import a <a href=\"http://leiningen.org/\">Leiningen</a>-based project into IntelliJ with the Clojure plugin, the best way seems to be:\r\n<ol>\r\n\t<li>Run <code>lein pom</code> to generate a Maven <code>pom.xml</code> from <code>project.clj</code></li>\r\n\t<li>Import the project as a Maven project (File - New Project... - Import project from external model - Maven - browse to the directory - ...)</li>\r\n</ol>\r\nVersions: Leiningen 2.0.0-preveiw10, IntelliJ 11. You don't need the Leiningen plugin for IntelliJ (it seems to be useful only for running the leiningen tasks, which you can well do from the command line).<br><br>If you change the dependencies, regenerate the pom.<br><br>(Notice that Leiningen 1 did download all the dependencies into ./lib/ when executing <code>lein deps</code> but that doesn't work anymore in Leiningen 2.)",
  "excerpt": ""
 },
 {
  "title": "Do You Know Why You Are Testing?! (On The Principles Underlying TDD)",
  "published": "2012-10-27 10:53:35",
  "postType": "post",
  "slug": "/2012/10/27/the-principles-underlying-test-driven-development-or-why-you-should-tdd/",
  "status": "publish",
  "tags": [
   "kent beck",
   "opinion",
   "tdd"
  ],
  "categories": [
   "Testing"
  ],
  "content": "Kent Beck in his recent post <a href=\"https://m.facebook.com/note.php?note_id=472392329460303\">Functional TDD: A Clash of Cultures</a> summarizes well the key principles and benefits that underlie test-driven development. I think it is really worthwhile becoming aware of and thinking over these foundation stones of TDD (and testing in general). Knowing them enables you to apply TDD in the most effective way with respect to a particular context to gain the maximum of these benefits. People that do not really understand the value of their tests and TDD tend to write hard to maintain tests of limited (and occasionally even negative) value. Are you one of them?<br><br><!--more--><br><br>According to Kent, the principles are:<br><br><ul>\n    <li>Double checking. \"If I think through a problem two different ways and arrive at the same answer, it's much more likely the right answer than if I only think one way. I need to keep some form of double checking.\" - the production code being one way and the test - simpler and preferably quite different from that code - being the other one.</li>\n    <li>Solution decomposition. \"I need to be able to work on a part of a problem at a time without having to hold the whole thing in my head at once. Having solved part of a problem I need proof that it is and remains solved.\" Failing high-level tests remind you of what yet needs to be implemented and help you focus on those areas. Tests enable you to freely refactor and improve an originally primitive implementation of a component without needing to think of the rest as they set boundaries within which you know you can move without breaking anything else. The tests are automated and thus you always know that that what they assert still holds.</li>\n    <li>Automatic verification. \"I need the computer to check whether results are correct. Green should mean, as closely as I can approximate, 'Ready to serve nearly a billion users.'\" (Automatic verification also provides a safety net for refactoring and future evolution of the code.)</li>\n    <li>Outside in. \"The program's externally visible behavior is more important than its internal structure (leaky abstractions notwithstanding). I want to start my search for a solution from the outside most of the time.\" With TDD you focus first on defining the outside-facing API of your classes and only after that you go on evolving the internal implementation.</li>\n</ul><br><br>Kent also mentions, and I must agree, that the continuous cycle of tension (failing test) – relief (green) provides for a good pace and pleasant feeling during development.<br><br>There are also other important benefits of testing. My two favourite ones are:<br><br><ul>\n    <li>Documentation. Tests document how the class is to be used and often also why it is as it is, something that is usually not possible to communicate in the code itself.</li>\n    <li>Design. TDD doesn't actually help you to create better designs; instead it makes a bad design painful and thus pushes towards a better one, one that is more cohesive and loosely coupled.</li>\n</ul><br><br>Update: I've noticed that I forgot one, for me personally very important aspect of TDD: it is fun. It is not just tension and relief, it is a continuous cycle of rewarding challenges, a cycle of contests between me-tester and me-developer, trying to find out how to test the thing in the simples way and how to fool the test or make it pass in the simples way.<br><br>The key message here is that you should know the value of what you are doing and adjust your practice with respect to the context to get the value. Following TDD or testing slavishly without understanding its value is very likely to lead to bad tests that cause more pain then benefit.<br><br>(<em>If you like this post then you might also like <a href=\"/2011/11/21/principles-for-creating-maintainable-and-evolvable-tests/\">Principles for Creating Maintainable and Evolvable Tests</a>, <a href=\"/2011/10/20/never-mix-public-and-private-unit-tests/\" rel=\"next\">Never Mix Public and Private Unit Tests! (Decoupling Tests from Implementation Details)</a> and <a href=\"/wiki/development/clean-test-design/\">Clean Test Design</a>. And you might enjoy also other <a href=\"/tag/opinion/\">posts on effective development</a>.</em>)",
  "excerpt": ""
 },
 {
  "title": "Most interesting links of November ''12",
  "published": "2012-11-30 21:59:48",
  "postType": "post",
  "slug": "/2012/11/30/most-interesting-links-of-november-12/",
  "status": "publish",
  "tags": [
   "clojure",
   "github",
   "java",
   "logging",
   "scala"
  ],
  "categories": [
   "General",
   "Languages",
   "Top links of month"
  ],
  "content": "<h2>Recommended Readings</h2>\r\n<ul>\r\n\t<li>James Roper: <a href=\"http://jazzy.id.au/default/2012/11/02/scaling_scala_vs_java.html\">Scaling Scala vs Java</a> (recommended by M. Odersky) - writing scalable apps in Scala is much easier then Java because idiomatic Scala uses immutable structures and lends itself naturally to asynchronous processing while doing these things in Java is possible but very unnatural and laborious. \"It [Scala] is biased towards scaling, it encourages practices that help you scale.\"</li>\r\n\t<li><a href=\"http://today.java.net/article/2006/04/04/exception-handling-antipatterns#logging\">Exception Handling Antipatterns</a> (2006, still valuable) - Log and Throw, Throwing Exception (instead of a suitable subclass), Throwing the Kitchen Sink (declaring many exceptions in method signature), Catching Exception (instead of a particular subclass), Destructive Wrapping (not including the exception as cause), Log and Return Null, Catch and Ignore (swallowing the exception), Throw from Within Finally, Multi-Line Log Messages (via repeated log calls instead of \\n), Ignoring InterruptedException (instead of breaking the loop etc.), Relying on getCause().</li>\r\n\t<li>The GitHub way: <a href=\"http://tomayko.com/writings/adopt-an-open-source-process-constraints\">Your team should work like an open source project</a> - a provocative article about the development process in GitHub that strongly prefers asynchronous and on-line communication over face-to-face meetings and communication, which, according to the author, leads to increased productivity. That is quite the opposite of what is usually practiced. I can think of situation where direct interaction is invaluable but, on the other hand, I could certainly live with less meetings. (<a href=\"http://news.ycombinator.com/item?id=4805635\">Comments on Hacker News</a>)</li>\r\n</ul>\r\n<h2>Clojure Corner</h2>\r\n<ul>\r\n\t<li>Chas Emerick's screencast <a href=\"http://cemerick.com/2012/05/02/starting-clojure/\">Starting Clojure</a> is a great example of Clojure development and interactive Clojure web development without restarts, with live code changes and direct access to the running app via REPL. It makes also a good job of introducing the Eclipse Clojure plugin Counterclockwise and the popular web framework Compojure with the template engine Enlive and HTTP abstraction Ring. Highly recommended! (I would however recommend to already know a little about the language.)</li>\r\n\t<li><a href=\"http://cemerick.com/2012/08/06/results-of-the-2012-state-of-clojure-survey/\">Results of the 2012 State of Clojure survey</a> (and, for comparison, <a href=\"http://cemerick.com/2010/06/07/results-from-the-state-of-clojure-summer-2010-survey/\">2010 results</a>) - some interesting facts are what people use Clojure for (math / data analysis 35%, web development 70%), 60% people evaluating ClojureScript, answers to \"What have been the biggest wins for you in using Clojure?\", the fact that ~ 20% use Eclipse, around 60% Emacs, only 10% IntelliJ, 23% vim. Also interesting is \"What has been most frustrating for you in your use of Clojure\" (with 30% mentions of documentation, being now improved by <a href=\"http://clojure-doc.org/\">clojure-doc.org</a>, 23% \"future stuffing concerns\")</li>\r\n</ul>\r\n<h2>Favorite Quotes</h2>\r\n<blockquote>You can reach a point with Lisp where, between the conceptual simplicity, the large libraries, and the customization of macros, you are able to write only code that matters.<br><br><em>- Rich Hickey <a href=\"http://www.codequarterly.com/2011/rich-hickey/\">in an interview</a>\r\n</em></blockquote>\r\n<blockquote>Lisp was a piece of theory that unexpectedly got turned into a programming language.<br><br><em>- Paul Graham in <a href=\"http://www.paulgraham.com/icad.html\">Revenge of the Nerds</a>\r\n</em></blockquote>",
  "excerpt": ""
 },
 {
  "title": "Most interesting links of December ''12",
  "published": "2012-12-31 21:59:26",
  "postType": "post",
  "slug": "/2012/12/31/most-interesting-links-of-december-12/",
  "status": "publish",
  "tags": [
   "aws",
   "bigdata",
   "clojure",
   "cloud",
   "development",
   "java",
   "kent beck",
   "methodology",
   "outsourcing",
   "scala",
   "scaling",
   "webapp",
   "xp"
  ],
  "categories": [
   "General",
   "Languages",
   "Tools",
   "Top links of month"
  ],
  "content": "<h2>Recommended Readings</h2>\r\nSoftware development\r\n<ul>\r\n\t<li>Kent Beck: <a href=\"https://www.facebook.com/notes/kent-beck/when-worse-is-better-incrementally-escaping-local-maxima/498576730175196\">When Worse Is Better: Incrementally Escaping Local Maxima</a> - Kent reintroduces his Sprinting Centipede strategy (\"reduce the cost of each change as much as possible so as to enable small changes to be chained together nearly continuously\" =&gt; \"From the outside it is clear that big changes are happening, even though from the inside it's clear that no individual change is large or risky.\") and advices how to deal with situations where improvements have reached a local maxima by making the design temporarily intentionally worse (f.ex. by inlining all the ugly methods or writing to both the old and the new data store); strongly recommended\r\n<ul>\r\n\t<li>Related: <a href=\"https://m.facebook.com/note.php?note_id=501948919837977\">Efficient Incremental Change</a> - transmute risk into time by doing small, safe steps, then optimize your ability to make these steps quickly and thus being able to achieve large changes</li>\r\n</ul>\r\n</li>\r\n\t<li><a href=\"http://www.sintef.no/home/Press-Room/Research-News/Bad-business-outsourcing-to-India/\">Researchers: It is not profitable to outsource development</a> - the Scandinavian research organisation SINTEF ICT has studied the effects of outsourcing and discovered that often it is more expensive than in-country development due to hidden costs caused by worse communication and cultural differences (f.ex. Indians tend not to ask questions and work based on their, often incomplete, understanding) and very high people turn-over; even after the true cost is discovered, companies irrationally stay there. However it is possible to succeed, in some cases.</li>\r\n\t<li>Bjørn Borud: <a href=\"http://blog.borud.no/2012/11/tractor-pulling-and-software-engineering.html\">Tractor pulling and software engineering</a> - very valuable and pragmatic advices on producing good software (i.e. avoiding accumulating so much crap that the software just stops progressing). Don't think only about the happy path. Simplify. Write for other developers, i.e. avoid too \"smart\" solutions, test &amp; document, dp actually think about design and its implication w.r.t performance etc. Awake the scientist in you: \"Do things because you know they work, not because it happens to be the hip thing to do.\"\r\n(Note: I see the good intention behind \"design for the weakest programmer you can think of\" but plase don't take it too far! Software should be primarily <a href=\"http://www.infoq.com/presentations/Simple-Made-Easy\">simple, not necessarily easy</a>.</li>\r\n\t<li><a href=\"http://blog.iterate.no/2012/10/01/know-your-feedback-loop-why-and-how-to-optimize-it/\">Know your feedback loop – why and how to optimize it</a> - to succeed, we need to learn faster; the only way to do that is to optimize our feedback loops, i.e. shorten the path our assumptions travel before they are (in)validated, whether about our code, business functionality, or the whole project idea. Conscise, valuable.</li>\r\n\t<li><a href=\"https://www.braintreepayments.com/braintrust/code-quality-is-the-least-important-reason-to-pair-program\">Code quality is the least important reason to pair program</a> - the author argues, based on his experience, other benefits of pair programming are more important than code quality: \"[..]  the most important reasons why we pair: it contributes to an amazing company culture, it’s the best way to bring new developers up to speed, and it provides a great way to share knowledge across the development team.\"</li>\r\n\t<li><a href=\"http://agile.dzone.com/articles/you-can%E2%80%99t-refactor-your-way\">You Can’t Refactor Your Way Out of Every Problem</a> - refactoring can’t help you if the design is fundamentally wrong, you need to rewrite it; know when it can or cannot help and act accordingly (related to how much design is needed upfront since some design decision cannot be reverted/improved upon)</li>\r\n</ul>\r\nLanguages\r\n<ul>\r\n\t<li><a href=\"http://youtu.be/hcY8cYfAEwU\">Josh Bloch: Java - the good, bad and ugly parts</a> (video, 15 min); summary: right design decisions (VM, GC, threads, dynamic linking, OOP, static typing, exceptions, ...), some bad details (signed byte, lossy long-&gt; double, == doesn't cal .equals, ability to call overriden methods from constructors, ...); Mr. Bloch has also given a longer talk examining the evolution of Java from 1.0 to 1.7 in<a href=\"http://www.devoxx.com/display/DV11/The+Evolution+of+Java++Past,+Present,+and+Future\"> The Evolution of Java: Past, Present, and Future</a>.</li>\r\n\t<li><a href=\"http://yz.mit.edu/wp/true-scala-complexity/\">True Scala complexity</a> - a thoughtful criticism of the complexity of Scala, based on code samples; \"[it is true that] Scala is a language with a smaller number of orthogonal features than found in many other languages. [...] However, the problem is that each feature has substantial depth, intersecting in numerous ways that are riddled with nuances, <a href=\"http://issues.scala-lang.org/browse/SI-2712\" rel=\"nofollow\">limitations</a>, exceptions and rules to remember. It doesn’t take long to bump into these edges, of which there are many.\"; however, its possible to avoid many of the problems mentioned by resorting to less smart, more clumsy and verbose Java-like code; also, the author still likes Scala.</li>\r\n\t<li><a href=\"http://www.infoq.com/articles/scala-java-myths-facts\">Scala or Java? Exploring myths and facts</a> (3/2012) - a balanced view of Scala's strengths and weaknesses; \"[..] the same features that makes Scala expressive can also lead to performance problems and complexity. This article details where this balance needs to be considered.\" Topics: productivity, complexity, concurrency support, language extensibility, Java interoperability, quality of tooling, speed, backward compatibility. Plenty of useful links.</li>\r\n</ul>\r\nBig data &amp; Cloud:\r\n<ul>\r\n\t<li>Dean Wampler's slides from <a href=\"http://techmeshconf.com/dl/techmesh-london-2012/slides/DeanWampler_BeyondMapReduce.pdf\">Beyond Map Reduce</a> - 1) Hadoop Map Reduce is the EJB 2 of big data but there are better APIs such as Cascading with Scala/Clojure wrappers; there are also \"alternative\" solutions like Spark and Storm; 2) functional/relational programming with simple data structures (lists, sets, maps etc.) is much more suitable for big data than OOP (for we do mostly stateless data transformations)</li>\r\n\t<li><a href=\"http://bigdatanoob.blogspot.jp/2012/11/hbase-vs-cassandra.html\">Apache HBase vs Apache Cassandra</a> - comparison sheet - if you want to decide between the two</li>\r\n\t<li><a href=\"http://architects.dzone.com/articles/optimizing-mongodb-aws\">Optimizing MongoDB on AWS</a> - 20 min talk about the current state of the art. Simplicity: Mongo AMIs by 10gen, Cloudformation template etc. Stability &amp; perf.: new storage options - EBS with provisioned IOPS volumes (high I/O) + EBS Optimized Instances (dedicated throughput to EBS), High IO instances (hi1.4xlarge - SSD)); comparison of throughput (number of operations, MBs) of these storages; tips for filesystem config. Scalability: scale horizontally and vertically, shrink as needed.</li>\r\n\t<li><a href=\"http://blog.empathybox.com/post/19574936361/getting-real-about-distributed-system-reliability\">Getting Real About Distributed System Reliability</a> by Jay Kreps, the author of the Voldemort DB: distributed software is NOT somehow innately reliable; a common mistake is to consider only probability of independent failures but failures typically are dependent (e.g. network problems affect the whole data center, not a single machine); the theoretical reliability \"[..] is an upper bound on reliability but one that you could never, never approach in practice\"; \"For example Google has <a href=\"http://research.google.com/pubs/archive/36737.pdf\">a fantastic paper</a> that gives empirical numbers on system failures in Bigtable and GFS and reports empirical data on groups of failures that show rates several orders of magnitude higher than the independence assumption would predict. This is what one of the best system and operations teams in the world can get: your numbers may be far worse.\" The new systems are far less mature (=&gt; mor bugs, worse monitoring, less experience) and thus less reliable (it takes a decade for a FS to become mature, likely similar here). Distributed systems are of course more complex to configure and operate. \"I have come around to the view that the real core difficulty of these systems is operations, not architecture or design.\" Some nice examples of failures.</li>\r\n</ul>\r\nOther\r\n<ul>\r\n\t<li><a href=\"http://www.smashingmagazine.com/2012/12/22/talks-to-help-you-become-a-better-front-end-engineer-in-2013/\">Talks To Help You Become A Better Front-End Engineer In 2013</a> (tl;dr) - topics such as mobile web development, modern web devel. workflow, current/upcoming featrues of CSS3, ECMAScript 6, CSS preprocessors (LESS etc.), how to write maintainable JS, modular CSS, responsive design, JS debugging, offline webapps, CSS profiling and speed tracer, JS testing</li>\r\n\t<li><a href=\"http://www.kitchensoap.com/2012/10/25/on-being-a-senior-engineer/\">On Being A Senior Engineer</a> - valuable insights into what makes an engineer \"senior\" (i.e. mature; from the field of web operations but applies to IT in general): mature engineers seek out constructive criticism of their designs, understand the non-technical areas of how they are perceived (=&gt; assertive, nice to work with etc.), understand that not all of their projects are filled with rockstar-on-stage work, anticipate the impact of their code (on resource usage, others' ability to understand &amp; extend it etc.), lift the skills and expertise of those around them, make their trade-offs explicit when making decisions, do not practice \"Cover Your Ass Engineering,\" are able to view the project from another person’s (stakeholder's) perspective, are aware of cognitive biases (such as the <a title=\"Planning Fallacy\" href=\"http://en.wikipedia.org/wiki/Planning_fallacy\" target=\"_blank\">Planning Fallacy</a>), practice <a href=\"http://blog.stephenwyattbush.com/2012/04/07/dad-and-the-ten-commandments-of-egoless-programming\">egoless programming</a>, know the importance of (sometimes irrational) feelings people have.</li>\r\n</ul>\r\n<h2>Clojure Corner</h2>\r\n<ul>\r\n\t<li><a href=\"https://vimeo.com/53223938#at=0\">Polymorphism in Clojure</a> - Tim Ewald's 1h live coding talk at Øredev conference introducing mechanisms for polymorphism (and Java interoperability) in Clojure and explaining well the different use cases for them. Included: why records, protocols &amp; polymorphism with them (shapes, area =&gt; open, not explicit switch) (also good for Java interop.: interfaces), reify, multimethods.</li>\r\n\t<li><a href=\"http://www.infoq.com/presentations/Thinking-in-Data\">Stuart Sierra: Thinking in Data</a> (1h talk) - Sierra introduces data-oriented programming, i.e. programming with generic, immutable data structures (such as maps), pure functions, and isolated side-effects. Some other points: Records are an optimization, only for perforamnce (rarely) or polymorphism (ot often); the case for composable functions;  testing using simulations (generative testing) etc.; visualization of state &amp; process</li>\r\n</ul>\r\n<h2>Tools &amp; Libs</h2>\r\n<ul>\r\n\t<li><a href=\"https://github.com/Netflix/Hystrix/wiki\">Netflix' Hysterix</a>: library to make distributed systems more resilitent by preventing a single slow/failing dependency from causing resource (thread etc.) exhaustion etc. by wrapping external calls in a separate thread with clear timeouts and support for fallbacks, with good monitoring etc. Read \"Problem Definition\" on the page to understand the problem it tries to solve.</li>\r\n</ul>\r\n<h2>Favorite Quotes</h2>\r\n<blockquote>if you build something that is fundamentally broken it isn't really interesting that you followed the plan or you followed some methodology -- the thing you built is fundamentally broken.<br><br>- <a href=\"http://blog.borud.no/\">Bjørn Borud</a>, Chief Architect at Comoyo.no, in an email 12/2012</blockquote>\r\n<blockquote>The root of the Toyota Way is to be dissatisfied with the status quo; you have to ask constantly, \"Why are we doing this?\"<br><br>- Katsuaki Watanabe, Tyota President 2005 - 2009 (from the talk <a href=\"http://agile2009.agilealliance.org/files/session_pdfs/Deliberate%20Practice_2.pdf\">Deliberate Practice</a>)</blockquote>",
  "excerpt": ""
 },
 {
  "title": "What Is Clean Code? - In Quotes",
  "published": "2012-12-15 17:32:01",
  "postType": "post",
  "slug": "/2012/12/15/what-is-clean-code-quotes/",
  "status": "publish",
  "tags": [
   "CleanCode",
   "craftsmanship"
  ],
  "categories": [
   "General"
  ],
  "content": "What is actually good, clean code? Why does it matter?<br><br>Marry Poppendieck has, in her excellent talk <a href=\"http://www.infoq.com/presentations/poppendieck-deliberate-practice-in-software-development\">Deliberate Practice in Software Development</a> (<a href=\"http://agile2009.agilealliance.org/files/session_pdfs/Deliberate%20Practice_2.pdf\">slides</a>), quoted a couple of leading figures of our industry on what is clean code.<br><br>(<strong>Emphasis</strong> is mine.)<br><br>Bjarne Stroustrup, inventor of C++:\r\n<blockquote>I like my code to be elegant and efficient. The logic should be <strong>straightforward</strong> and make it hard for bugs to hide, the dependencies minimal to ease maintenance, <strong>error handling complete according to an articulated strategy</strong>, and performance close to optimal so as not to tempt people to make the code messy with unprincipled optimizations. Clean code <strong>does one thing</strong> well.</blockquote>\r\nGrady Booch, author of Object-Oriented Analysis and Design with Applications:\r\n<blockquote>Clean code is simple and direct. Clean code reads like well-written prose. Clean code never obscures the <strong>designers’ intent</strong> but rather is full of crisp abstractions and straightforward lines of control.</blockquote>\r\n“Big” Dave Thomas, founder of OTI and godfather of the Eclipse strategy:\r\n<blockquote>Clean code <strong>can be read, and enhanced by a developer other than its original author</strong>. It has unit and acceptance tests. It has meaningful names. It provides <strong>one way rather than many</strong> ways for doing one thing. It has <strong>minimal</strong> dependencies, which are explicitly defined, and provides a clear and minimal API. Code should be literate since, depending on the language, not all necessary information can be expressed clearly in code alone.</blockquote>\r\nMichael Feathers, author of Working Effectively with Legacy Code:\r\n<blockquote>I could list all of the qualities that I notice in clean code, but there is one overarching quality that leads to all of them. <strong>Clean code always looks like it was written by someone who cares.</strong> There is <strong>nothing obvious that you can do to make it better</strong>. All of those things were thought about by the code’s author, and if you try to imagine improvements, you are led back to where you are, sitting in appreciation of the code someone left for you—code written by someone who cared deeply about the craft.</blockquote>\r\nWard Cunningham, inventor of Wiki and Fit, co-inventor of Extreme Programming. The force behind Design Patterns. Smalltalk and OO thought leader. The godfather of all those who care about code.\r\n<blockquote>You know you are working with clean code when each routine you read turns out to be <strong>pretty much what you expected</strong>. You can call it beautiful code when the code also makes it look like the language was made for the problem.</blockquote>\r\n<h2>Summary</h2>\r\nClean code is\r\n<ul>\r\n\t<li>Easily accessible to others (straightforward, clear intent, good abstractions, no surprises, good names) - this is absolutely the most mentioned point</li>\r\n\t<li>Is made for the real-world, i.e. has a clear error-handling strategy (my current project has been burnt a lot by the lack of this so my emphasis is little subjective :-))</li>\r\n\t<li>The author clearly cares for the software and other developers (which implies both readability and maintainability)</li>\r\n\t<li>Is minimal (does one thing, has minimal dependencies)</li>\r\n\t<li>Is good at what it does</li>\r\n</ul>",
  "excerpt": ""
 },
 {
  "title": "Blogging Stats of 2012",
  "published": "2013-01-01 14:27:07",
  "postType": "post",
  "slug": "/2013/01/01/blogging-stats-of-2012/",
  "status": "publish",
  "tags": [],
  "categories": [
   "General"
  ],
  "content": "The WordPress.com stats helper monkeys prepared a 2012 annual report for this blog.<br><br><a href=\"/2012/annual-report/\"><img alt=\"\" src=\"http://www.wordpress.com/wp-content/mu-plugins/annual-reports/img/2012-emailteaser.png\" width=\"100%\" /></a><br><br>A summary:\r\n<blockquote>19,000 people fit into the new Barclays Center to see Jay-Z perform. This blog was viewed about <strong>130 000</strong> times in 2012. If it were a concert at the Barclays Center, it would take about 7 sold-out performances for that many people to see it.</blockquote>\r\n<a href=\"/2012/annual-report/\">Click here to see the complete report.</a>",
  "excerpt": ""
 },
 {
  "title": "My 2012 in Review",
  "published": "2013-01-04 20:42:33",
  "postType": "post",
  "slug": "/2013/01/04/my-2012-in-review/",
  "status": "publish",
  "tags": [],
  "categories": [
   "General",
   "Top links of month"
  ],
  "content": "With year 2012 over it is perhaps time to look back and see what interesting has happend, what I have done, written, learned, what articles I have enjoyed most etc.<br><br>This has been my second year in Norway and I am still very much enjoying it, there is a very active developer community organizing great conferences such as <a href=\"http://jz12.java.no/\">JavaZone</a> (followed by an amazing trip to the nature a.k.a. <a href=\"http://timberglund.com/blog/2012/09/30/survivorzone-documentary/\">SurvivalZone</a>) and <a href=\"http://smidig2012.no/\">Smidig</a> (Agile) where I have also <a href=\"https://vimeo.com/album/2147674\">presented</a>, Scala-focused <a href=\"http://flatmap.no/\">flatMap</a>, many <a href=\"http://www.meetup.com/explore/?offset=0&amp;psize=32&amp;currentpage=1&amp;allMeetups=true&amp;categories=&amp;keywords=oslo&amp;radius=5&amp;userFreeform=Oslo%2C+Norway&amp;mcId=z1030352&amp;mcName=Oslo%2C+Norway&amp;sort=default\">meetups</a> etc.\r\n<h2>Events &amp; side jobs</h2>\r\nThanks to <a href=\"https://www.iterate.no/\">my company</a> I had the opportunity to do some real consulting work, namely helping with a technical audit of an R&amp;D department and co-organizing a TDD and refactoring workshop for the customer, and I have learned a lot from both of these.<br><br>The most exciting event was a week long educational stay with Ken Beck that has resulted in the most popular blog post ever of my company and myself, <a href=\"http://blog.iterate.no/2012/06/20/programming-like-kent-beck/\">Programming Like Kent Beck</a>. Another exciting event was the workshop <a href=\"http://www.programutvikling.no/kurskalenderoversikt.aspx?mid_1=1352&amp;mid=1535&amp;id=871059\">BDD - Specification by Example</a> by <a href=\"http://gojko.net/\">Gojko Adzic</a>, simply the best workshop/course I have ever attended, with plenty of valuable content about how <a href=\"http://specificationbyexample.com/key_ideas.html\">to build the right software</a>. I also very much enjoyed preparing and presenting an <a href=\"https://github.com/iterate/iterate-clojure-workshop12#readme\">introductory workshop into Clojure</a> with my friends and collegues Lars and Ivar.<br><br><!--more-->\r\n<h2>Work</h2>\r\nI have worked the whole year with a partner company that aims at creating innovative internet solutions such as on-line entertainment and communication services. I have learned a lot about the cloud, the Amazon Web Services platform, <a href=\"http://puppetlabs.com/\">Puppet</a> and DevOps, <a href=\"http://vagrantup.com/\">Vagrant</a>, big data scale warehousing using Hadoop and Hive, NoSQL databases such as MongoDB, REST, and running distributed services. I have wasted too much time trying to get <a href=\"http://www.zabbix.com/\">Zabbix</a> to monitor what I want (despite of its shortcomings and lack of friendliness towards troubleshooting, it is sadly still one of the best monitoring tools, I have been told). I have done too little pair-programming and I have spent too much time in Java, bash, and Zabbix instead of learning more about modern web UI development and using more productive languages such as Clojure, Groovy, and Scala (though I have managed to sneak two of them in).<br><br>The work is great. I miss only three things - pair programming, Clojure, and opportunities to learn from smart and skilled people. Regarding the last point, I have smart and skilled co-workers - only the opportunities to learn from them are way too limited (partly due to the first point, lack of pairing).\r\n<h2>Learning</h2>\r\nI have started to focus on functional programming in general and Clojure and partially Scala in particular. I believe there is a lot we can learn from this paradigm and higher-order functions and immutability have really nice benefits. I hope to continue exploring when these laguages might be a better choice then Java in 2013 with my collegues in the Iterate Functional Programming Group.<br><br>Some books I have read and appreciated:\r\n<ul>\r\n\t<li>Adam Bien's <a title=\"Permanent link to Recommended Book: Real World Java EE Night Hacks by Adam Bien\" href=\"/2012/08/13/recommended-book-real-world-java-ee-night-hacks-by-adam-bien/\" rel=\"bookmark\">Real World Java EE Night Hacks</a></li>\r\n\t<li>Gojko Adzic' <a href=\"http://specificationbyexample.com/\">Specification by Example: How successful teams deliver the right software</a></li>\r\n\t<li>Michael Feathers' <a href=\"http://www.amazon.com/Working-Effectively-Legacy-Michael-Feathers/dp/0131177052/\">Working Effectively with Legacy Code</a></li>\r\n\t<li>Kent Beck's <a title=\"Permanent link to Book Review: Implementation Patterns\" href=\"/2012/07/05/book-review-implementation-patterns/\" rel=\"bookmark\">Implementation Patterns</a></li>\r\n\t<li><a href=\"http://www.amazon.com/Summary-Lean-Startup-Eric-ebook/dp/B006RINUII/\">Summary: The Lean Startup</a> by Eric Ries and <a href=\"http://www.amazon.com/Running-Lean-Iterate-Works-Series/dp/1449305172/\"> Running Lean</a> by Ash Maurya (we believe that innovation is crucial for companies that want to succeed)</li>\r\n</ul>\r\n<h2>Blogging</h2>\r\nI have thought a lot about <a href=\"/wiki/development/testing/\">testing</a>, <a href=\"/2011/11/21/principles-for-creating-maintainable-and-evolvable-tests/\">maintainable test</a>, <a href=\"/code-quality/\">code quality</a>, legacy code and software development and evolution and my opinions are slowly crystalizing, partly here under the <a href=\"/tag/opinion/\">opinions tag</a>.<br><br>I have published 57 blog posts, multiple of them about topics such as  <a href=\"/tag/cleancode/\" rel=\"tag\">CleanCode</a>, <a href=\"/tag/craftsmanship/\" rel=\"tag\">craftsmanship</a>, <a title=\"View all posts in Testing\" href=\"/category/testing-2/\" rel=\"category tag\">Testing</a>,  <a href=\"/tag/devops/\" rel=\"tag\">DevOps</a> and <a href=\"/tag/ops/\" rel=\"tag\">ops</a>, <a href=\"/tag/puppet/\" rel=\"tag\">puppet</a>, <a href=\"/tag/clojure/\" rel=\"tag\">clojure</a>,  <a href=\"/tag/bigdata/\" rel=\"tag\">bigdata</a>, <a href=\"/tag/book/\" rel=\"tag\">book</a>, <a href=\"/tag/design/\" rel=\"tag\">design</a>.<br><br>My blog posts of this year that I personally appreciate most are these:\r\n<ul>\r\n\t<li><a title=\"Permanent link to Programming Like Kent Beck\" href=\"/2012/09/12/programming-like-kent-beck/\" rel=\"bookmark\">Programming Like Kent Beck</a></li>\r\n\t<li><a title=\"Permanent link to Do You Know Why You Are Testing?! (On The Principles Underlying TDD)\" href=\"/2012/10/27/the-principles-underlying-test-driven-development-or-why-you-should-tdd/\" rel=\"bookmark\">Do You Know Why You Are Testing?! (On The Principles Underlying TDD)</a></li>\r\n\t<li><a title=\"Permanent link to How to Create Maintainable Acceptance Tests\" href=\"/2012/01/18/how-to-create-maintainable-acceptance-tests/\" rel=\"bookmark\">How to Create Maintainable Acceptance Tests</a></li>\r\n\t<li><a title=\"Permanent link to What Is Clean Code? – In Quotes\" href=\"/2012/12/15/what-is-clean-code-quotes/\" rel=\"bookmark\">What Is Clean Code? – In Quotes</a></li>\r\n\t<li><a title=\"Permanent link to (Unit) Testing Swiss Knife: All the Tools You Wanted to Know\" href=\"/2012/09/09/unit-testing-swiss-knife-all-the-tools-you-wanted-to-know/\" rel=\"bookmark\">(Unit) Testing Swiss Knife: All the Tools You Wanted to Know</a></li>\r\n\t<li><a title=\"Permanent link to Bad Code: Too Many Object Conversions Between Application Layers And How to Avoid Them\" href=\"/2012/05/12/bad-code-too-many-object-conversions-between-application-layers-and-how-to-avoid-them/\" rel=\"bookmark\">Bad Code: Too Many Object Conversions Between Application Layers And How to Avoid Them</a></li>\r\n\t<li><a title=\"Permanent link to Kent Beck: Best Practices for Software Design with Low Feature Latency and High Throughput\" href=\"/2012/03/12/kent-beck-best-practices-for-software-design-with-low-feature-latency-and-high-throughput/\" rel=\"bookmark\">Kent Beck: Best Practices for Software Design with Low Feature Latency and High Throughput</a></li>\r\n\t<li><a title=\"Permanent link to Using Java as Native Linux Apps – Calling C, Daemonization, Packaging, CLI (Brian McCallister)\" href=\"/2012/09/25/using-java-as-native-linux-apps-calling-c-daemonization-packaging-cli-brian-mccallister/\" rel=\"bookmark\">Using Java as Native Linux Apps – Calling C, Daemonization, Packaging, CLI (Brian McCallister)</a></li>\r\n\t<li><a title=\"Permanent link to Minimalistic Practical Introduction to Puppet (Not Only) For Vagrant Users\" href=\"/2012/08/13/minimalistic-practical-introduction-to-puppet-for-vagrant-users/\" rel=\"bookmark\">Minimalistic Practical Introduction to Puppet (Not Only) For Vagrant Users</a></li>\r\n\t<li><a title=\"Permanent link to Beautiful Code: Simplicity Yields Power\" href=\"/2012/05/09/beautiful-code-simplicity-yields-power/\" rel=\"bookmark\">Beautiful Code: Simplicity Yields Power</a></li>\r\n\t<li><a title=\"Permanent link to Key Lessons from the Specification by Example Course, Day 1\" href=\"/2012/01/09/key-lessons-from-the-specification-by-example-course-day-1/\" rel=\"bookmark\">Key Lessons from the Specification by Example Course, Day 1</a></li>\r\n</ul>\r\nAnother blog post that I really like and that I haven't written but have motivated it, is Iterate's <a href=\"http://blog.iterate.no/2012/08/19/books-everybody-should-read/\">Books Our Developers Should Read</a> presenting the 4 books we believe are crucial for all our developers/consultants.\r\n<h2>Great articles</h2>\r\nSome of the best articles I have read and talks I have seen in 2013, in the reverse chronological order:\r\n<ul>\r\n\t<li><a href=\"http://blog.empathybox.com/post/19574936361/getting-real-about-distributed-system-reliability\">Getting Real About Distributed System Reliability</a> by Jay Kreps, the author of the Voldemort DB</li>\r\n\t<li><a href=\"http://www.kitchensoap.com/2012/10/25/on-being-a-senior-engineer/\">On Being A Senior Engineer</a> – valuable insights into what makes an engineer “senior”</li>\r\n\t<li>Jon Pither: <a href=\"http://www.pitheringabout.com/?p=693\">Clojure at a Bank – Moving from Java</a> -  the justification (productivity, dynamism, FP a better match for the domain) and process behind moving from Java to Clojure with a monolithic 1M LOC Spring/Hibernate app.</li>\r\n\t<li>Tom Gilb's excellent JavaZone talk <a href=\"https://vimeo.com/49381225\">Managing Agile Processes, with a Stakeholder Value point of view: 10 Revised Agile Principles</a>, claiming that development should always start from understanding the business need and delivering business value each iteration, all of that backed by metrics - all of that backed by many years of successful projects done this wat</li>\r\n\t<li>M.Fowler: <a href=\"http://martinfowler.com/bliki/OrmHate.html\">ORM Hate – Why ORM is actually a good solution</a> – a very valuable article where Fowler opposes the popular trend of criticising Object-Relational Mappers such as Hibernate.</li>\r\n\t<li><a href=\"http://gojko.net/2012/05/08/redefining-software-quality/\">Gojko Adzic: Redefining software quality</a> – an obligatory read that introduces a holistic view of SW quality and the quality pyramid</li>\r\n\t<li><a href=\"http://vimeo.com/36579366\">Bret Victor: Inventing on Principle</a> (55 min, see at least the first 5 min) – very inspiring! Victor firmly believes that “creators need an immediate connection to what they create” and demonstrates how this can be achieved</li>\r\n\t<li><a href=\"http://blog.incubaid.com/2012/03/28/the-game-of-distributed-systems-programming-which-level-are-you/\">The Game of Distributed Systems Programming. Which Level Are You?</a></li>\r\n\t<li><a href=\"http://rgordon.co.uk/blog/2012/03/05/shapes-dont-draw/#.T2oidI2SwnE.dzone\">Shapes Don’t Draw</a> – thought-provoking criticism of inappropriate use of OOP, which leads to bad and inflexible code</li>\r\n\t<li><a href=\"http://blog.jayfields.com/2011/01/compatible-opinions-on-software.html\">Jay Fields’ Thoughts: Compatible Opinions on Software</a> – about teams and opinion conflicts – there are some areas where no opinion is really right yet people may have very strong feeling about them.</li>\r\n</ul>\r\n<h2>Tools</h2>\r\nI have begun to use <a href=\"http://en.wikipedia.org/wiki/GNU_Screen\">screen</a> (via the wrapper <a href=\"http://en.wikipedia.org/wiki/Byobu_(software)\">byobu</a>) for long-running sessions on servers, switched to IntelliJ 12 for Java development, begun to re-learn Emacs for the sake of Clojure. I have also adopted <a href=\"http://code.google.com/p/csshx/\">Cluster SSH</a> for multi-server ops tasks, started to experiment with the <a href=\"http://fishshell.com/\">fish shell</a> (with <a href=\"//github.com/zmalltalker/fish-nuggets.git\">addons</a>) instead of bash or the growingly popular zsh",
  "excerpt": ""
 },
 {
  "title": "Fast Code To Production Cycle Matters: For Pleasure, Productivity, Profit",
  "published": "2013-01-04 23:24:13",
  "postType": "post",
  "slug": "/2013/01/05/fast-code-to-production-cycle-matters-for-pleasure-engagement-profit/",
  "status": "publish",
  "tags": [
   "agile",
   "development",
   "opinion"
  ],
  "categories": [
   "General"
  ],
  "content": "I spent one afternoon adding a much needed feature to our application. Now I have been waiting for several days for various people to review and approve it. And I have just realized how tiring it is and how much energy it takes from me.<br><br>To create something and get it out into production at once (plus minus) is fun and really motivates me to do and try stuff, it is a great feeling to see it immediately affecting the users and processes. And a quick feedback (from the users and the behavior of the application) - while still being engaged for the thing and having all the context in my mind - makes it easy and fun to fix and improve it, leading to a better result faster. Waiting, on the other hand, is exhausting and depressing. I usually start working on something else, forget the context, lose the interest (it is not easy to be fired up for two things at the same time) etc.<br><br>Therefore, if you care for happy developers and better products, make sure that your time from code to production is as short as possible. Look at your process, eliminate all delays, make it smooth.<br><br>PS: I am not saying that code reviews are bad. They are great. They just shouldn't be a source of delay. For example if you can pair-program then you get an instant code review.<br><br><p style=\"text-align:center;\"><em>You might enjoy also other <a href=\"/tag/opinion/\">posts on effective development</a>.</em></p>",
  "excerpt": ""
 },
 {
  "title": "Most interesting links of January ''13",
  "published": "2013-01-31 21:59:10",
  "postType": "post",
  "slug": "/2013/01/31/most-interesting-links-of-january-13/",
  "status": "publish",
  "tags": [
   "bigdata",
   "clojure",
   "cloud",
   "fun",
   "human",
   "java",
   "performance",
   "SbE",
   "scala",
   "security",
   "tdd",
   "Testing"
  ],
  "categories": [
   "General",
   "Languages",
   "Testing",
   "Tools",
   "Top links of month"
  ],
  "content": "<h2>Recommended Readings</h2>\r\nVarious\r\n<ul>\r\n\t<li>Dustin Marx: <a href=\"http://www.javacodegeeks.com/2013/01/significant-software-development-developments-of-2012.html\">Significant Software Development Developments of 2012</a> - Groovy 2.0 with static typing, rise of Git[Hub], NoSQL, mobile development (iOS etc.), Scala and Typesafe stack 2.0, big data, HTML5, security (Java issues etc.), cloud, DevOps.</li>\r\n\t<li><a href=\"http://www.javacodegeeks.com/2012/11/20-kick-ass-programming-quotes.html\">20 Kick-ass programming quotes</a> - including Bill Gates' \"Measuring programming progress by lines of code is like measuring aircraft building progress by weight.\",  B.W. Kernighan's \"Debugging is twice as hard as writing the code in the first place. Therefore, if you write the code as cleverly as possible, you are, by definition, not smart enough to debug it.\", Martin Golding's \"Always code as if the guy who ends up maintaining your code will be a violent psychopath who knows where you live.\" (my favorite)</li>\r\n\t<li><a href=\"http://blogs.hbr.org/2013/01/how-to-have-a-year-that-matter/\">How to Have a Year that Matters</a> (via <a href=\"https://twitter.com/gbrindusa\">@gbrindusa</a>) - do you want to just survive and collect possessions or do you want to make a difference? Some questions everybody should pose to him/herself.</li>\r\n\t<li><a href=\"https://docs.google.com/a/iterate.no/document/d/1dc1xxO8UMFaGLOwgkykYdghGWm_2Gn0iCrxFsympqcE/mobilebasic?pli=1&amp;hl=en_US\">Expression Language Injection</a> - security defect in applications using JSP EL that can sometimes leads to double evaluation of the expressions and thus makes it possible to execute data supplied by the user in request parameters etc. as expressions, affects e.g. unpatched Spring 2.x and 3.</li>\r\n</ul>\r\nLanguages etc.\r\n<ul>\r\n\t<li><a href=\"http://news.ycombinator.com/item?id=5008127\">HN discussion about Scala 2.10</a> - compilation speed and whether it matters, comparison of the speed and type system with Haskell and OCaml, problems with incremental compilation (dependency cycles, fragile base class), some speed up tips such as factoring out subprojects, the pros and cons of implicits etc.</li>\r\n\t<li>Blog <a href=\"http://mechanical-sympathy.blogspot.no/\">Mechanical Sympathy</a> - interesting posts and performance tests regarding \"writing software which works in harmony with the underlying hardware to gain great performance\" such as <a href=\"http://mechanical-sympathy.blogspot.no/2012/08/memory-access-patterns-are-important.html\">Memory Access Patterns Are Important</a> and <a href=\"http://mechanical-sympathy.blogspot.no/2012/10/compact-off-heap-structurestuples-in.html\">Compact Off-Heap Structures/Tuples In Java</a>.</li>\r\n\t<li>Neal Ford: <a href=\"http://www.ibm.com/developerworks/java/library/j-ft20/index.html\">Functional thinking: Why functional programming is on the rise</a> - Why you should care about functional programming, even if you don't plan to change languages any time soon - N. Ford explains the advantages of FP and why FP concepts are spreading into other languages (higher abstractions enabling focus on the results over steps and ceding control to the language, more reusability on a finer level (higher-order functions etc.), few generic data structures with many operations -&gt; better composability, \"new\" and different tool such as lazy collections, shaping the language towards the problem instead of vice versa, aligning with trends such as immutability)</li>\r\n\t<li>Neal Ford: <a href=\"http://www.ibm.com/developerworks/java/library/j-jn1/index.html\">Java.next: The Java.next languages Leveraging Groovy, Scala, and Clojure in an increasingly polyglot world</a> - a comparison of these languages with focus on what they are [not] suitable for, exploration of their paradigms (static vs. dynamic typing, imperative vs. functional)</li>\r\n</ul>\r\nSW development\r\n<ul>\r\n\t<li><a href=\"http://server.dzone.com/articles/how-completely-fail-bdd\">How to Completely Fail at BDD</a> - a story of an enthusiastic developer who tried to make everyone's life better by introducing automated BDD tests and failed due to differences in culture (and inability to change thinking from the traditional testing), a surprising lack of interest in the tool and learning how to write good tests: \"Culturally, my current team just isn’t ready or interested in something like this.\" Morale: It is hard to <a href=\"http://www.amazon.com/Switch-Change-Things-When-Hard/dp/0385528752/\">change people</a>, good ideas are not enough.</li>\r\n\t<li><a href=\"http://michaelfeathers.typepad.com/michael_feathers_blog/2013/01/refactoring-is-sloppy.html\">M. Feathers: Refactoring is Sloppy</a> - refactoring is often prioritized out of regular development and refactoring sprints/stories aren't popular due to past failures etc. An counter-intuitive way to get refactoring in is to imagine, during planning, what the code would need to be like to make it easy to implement a story. Then create a task for making it so before the story itself and assign it to somebody else then the story (to force a degree of scrutiny and communication). \"Like anything else in process, this is medicine.  It's not meant to be 'the way that people do things for all time' [..]\" - i.e. intended for use when you can't fit refactoring in otherwise. It may also make the cost of the current bad code more visible. Read also the commits (f.ex. the mikado method case).</li>\r\n\t<li><a href=\"http://cyber-dojo.com/\">Cyber-dojo</a>: A great way to practice TDD together. Compare your read-green cycle and development over time with other teams. Purposefully minimalistic editor, a number of prepared tdd tasks.</li>\r\n\t<li><a href=\"http://java.dzone.com/articles/dark-side-craftsmanship\">On the Dark Side of \"Craftsmanship\"</a> - an interesting and provoking article. Some developers, the software labouers, want to get work done and go home, they haven't the motivation and energy to continualy spend time improving themselves. There is nothing wrong with that and we shouldn't disparge them because of that. We shouldn't divide people into craftsmen and the bad ones. A summary of and response to the varied reactions follows up in <a href=\"http://agile.dzone.com/articles/more-craftsmanship\">More on \"Craftsmanship\"</a>. The author is right that we can't expect everybody to spend nights improving her/his programming skills. Still they should not produce code of poor quality (with few exceptions) since maintaining such code costs a lot. There should be time for enough quality in a 9-5 day and people should be provided with enough guidance and education to be able to write decent code. (Though I'm not sure how feasible it is, how much effort it takes to become an acceptable developer.) Does the increased cost of writing (an learning to write) good code overweight the cost of working with bad code? That is an eternal discussion.</li>\r\n</ul>\r\nCloud, web, big data etc.\r\n<ul>\r\n\t<li><a href=\"http://mcfunley.com/whom-the-gods-would-destroy-they-first-give-real-time-analytics\">Whom the Gods Would Destroy, They First Give Real-time Analytics</a> (via <a href=\"http://leonomics.com/\">Leon</a>) - a very reasonable argument against real-time analytics: yes, we want real-time operational metrics but \"analytics\" only makes sense on a sensible amount of data (for the sake of statistical significance etc.) RT analytics could easily provide misguided results.\r\n<a href=\"http://www.infoq.com/articles/cap-twelve-years-later-how-the-rules-have-changed\">CAP Twelve Years Later: How the \"Rules\" Have Changed</a> (tl;dr, via <a href=\"https://twitter.com/_dagi\">@_dagi</a>) - an in-depth discussion of the CAP theorem and the simplification (2 out of 3) that it makes; there are many more nuances. By Eric Brewer, a professor of computer science at the University of California, Berkeley, and vice president of infrastructure at Google.</li>\r\n\t<li><a href=\"http://roca-style.org/\">ROCA: Resource-oriented Client Architecture</a> - \"A collection of simple recommendations for decent Web application frontends.\" Server-side: true REST, no session state, working back/refresh etc. Client: semantic HTML independent of layout, progressive enhancement (usable with older browsers), usable without JS (all logic on the server) etc. Certainly not suitable for all types of apps but worthwile to consider the principles and compare them with your needs.</li>\r\n</ul>\r\n<h2>Clojure Corner</h2>\r\n<ul>\r\n\t<li><a href=\"http://martinsprogrammingblog.blogspot.no/2012/05/distributed-actors-in-clojure.html\">Distributed Actors in Clojure</a> (5/2012) - a discussion of options for Akka-like stuff in Clojure. Akka is great but \"<a href=\"http://blog.darevay.com/2011/06/clojure-and-akka-a-match-made-in/\">interfacing to Akka from Clojure is not nice</a>, and certainly not idiomatic\". Though there have been some new Akka-Clojure libs since that (<a href=\"https://github.com/jasongustafson/akka-clojure\">akka-clojure</a>, <a href=\"https://github.com/gaverhae/okku\">okku</a>).</li>\r\n</ul>\r\n<h2>Tools</h2>\r\n<ul>\r\n\t<li><a href=\"http://vaurien.readthedocs.org/en/1.5/\">Vaurien, the Chaos TCP Proxy</a> (via <a href=\"http://twitter.com/bsvingen\">@bsvingen</a>) - an extensible proxy that you can control from your tests to simulate network failure or problems such as delays on 20% of the requests; great for testing how an application behaves when facing failures or difficulties with its dependencies. It supports the protocols tcp, http, redis, memcache.</li>\r\n\t<li><a href=\"https://github.com/wvanbergen/request-log-analyzer#readme\">Wvanbergen's request-log-analyzer</a> for Apache, MySQL, PostgreSQL, Rails and more (via Zarko) - generates a performance report from a supported access log to point out requests that might need optimizing</li>\r\n\t<li><a href=\"http://teohm.github.com/blog/2012/03/22/working-effectively-with-iterm2/\">Working Effectively With iTerm2</a> (Mac) - good tips in the body and comments</li>\r\n</ul>\r\n<h2>Favorite Quotes</h2>\r\nA very good (though not very scientific) definition of project success applicable for distinguishing truly agile from process-driven projects:\r\n<blockquote>[..] a project is successful if:\r\n<ul>\r\n\t<li>Something was delivered and put to use</li>\r\n\t<li>The project members, sponsors and users are basically happy with the outcome of the project</li>\r\n</ul>\r\n<em>- Johannes Brodwall in <a href=\"http://www.programutvikling.no/userfiles/brosjyre.pdf\">\"How do we become Agile?\" and why it doesn't matter</a>, inspired by Alistair Cockburn\r\n</em></blockquote>\r\n(Notice there isn't a single word about being \"on time and budget\".)",
  "excerpt": ""
 },
 {
  "title": "Bash Magic: List Hive Table Sizes in GB",
  "published": "2013-01-08 09:03:49",
  "postType": "post",
  "slug": "/2013/01/08/bash-magic-list-hive-table-sizes-in-gb/",
  "status": "publish",
  "tags": [
   "DevOps",
   "hadoop"
  ],
  "categories": [
   "Tools"
  ],
  "content": "To list the sizes of Hive tables in Hadoop in GBs:\r\n<pre><code>\r\nsudo -u hdfs hadoop fs -du /user/hive/warehouse/ | awk '/^[0-9]+/ { print int($1/(1024**3)) &quot; [GB]\\t&quot; $2 }'\r\n</code></pre><br><br>Result:\r\n<pre>\r\n448 [GB] hdfs://aewb-analytics-staging-name.example.com:8020/user/hive/warehouse/mybigtable\r\n8 [GB]\thdfs://aewb-analytics-staging-name.example.com:8020/user/hive/warehouse/anotherone\r\n0 [GB]\thdfs://aewb-analytics-staging-name.example.com:8020/user/hive/warehouse/tinyone\r\n</pre>",
  "excerpt": ""
 },
 {
  "title": "Bash: Parse Options And Non-Options With Getopts",
  "published": "2013-01-09 12:24:32",
  "postType": "post",
  "slug": "/2013/01/09/bash-parse-options-and-non-options-with-getopts/",
  "status": "publish",
  "tags": [
   "bash"
  ],
  "categories": [
   "General"
  ],
  "content": "Parsing script or function options and non-option arguments is easy in Bash with <code>getopts</code> but there are some catches, such as the need to reset OPTIND. We will se how to do it using <code>getopts</code>, <code>shift</code>, and <code>case</code>.<br><br>The code below will parse the function arguments and remove them so that $1 will refer to the first non-option argument (i.e. not starting with -). You would invoke it f.ex. as  <code>latest_recur -x Hello -a '*.txt'</code>.<br><br><pre><code>\r\n# Find the latest files under the current dir, recursively; options:\r\n# -a list all, not only 30 latest\r\n#  - pattern passed to find's -name; ex.: &quot;*.log.processed&quot;\r\nfunction latest_recur {\r\n   local show_all=\r\n   OPTIND=1\r\n   while getopts &quot;ax:&quot; opt; do\r\n      case $opt in\r\n         a) show_all=yes ;;\r\n         x) echo &quot;You said: $OPTARG&quot; ;;\r\n         \\?) echo &quot;Invalid option: -$OPTARG&quot; &gt;&amp;2; return 1;;\r\n     esac\r\n   done\r\n   shift $((OPTIND-1))<br><br>   if [ -z &quot;$1&quot; ]; then NAME_ARG=&quot;&quot;; else NAME_ARG=&quot;-name $1&quot;; fi\r\n   find -type f $NAME_ARG | xargs --no-run-if-empty stat --format '%Y :%y %n' | sort -nr | if [ -z &quot;$show_all&quot; ]; then head -n 30 -; else cat -; fi\r\n}\r\n</code></pre>\r\n<ul>\r\n\t<li>#5, #9 the variable used to store the flag must be defined/reset first</li>\r\n\t<li><strong>#6</strong> OPTIND is a global variable pointing to the next argument that getopts should parse; you <strong>must reset it manually</strong> (otherwise the next call to the function will ignore its arguments)</li>\r\n\t<li>#7 getopts parses one by one all the supported options (a, x here) and stores them into $opt;</li>\r\n\t<li>#10, #11 the value passed to the option (Hello, *.txt) is stored into the variable OPTARG</li>\r\n\t<li><strong>#14</strong> we must manually shift away the processed option arguments so that the first non-option argument ('*.txt') will become argument number 1 as you can see at #16; OPTIND is set by getopts</li>\r\n</ul>\r\n<code>Getopts</code> can do quite a lot. It supports short options with or without arguments such as \"-lht\", \"-l -h -t\", \"-l -I '*.swp'\". It can also report/ignore unknown arguments etc., see <a href=\"http://linux.about.com/library/cmd/blcmdl1_getopts.htm\">its brief documentation</a> and this <a href=\"http://wiki.bash-hackers.org/howto/getopts_tutorial\">small getopts tutorial</a>. Briefly said, getopts takes opstring and varname; opstring is a list of letters optionally followed by ':' to indicate that that flag requires a value; varname is the name of the variable to store the flag name into. If you put : in front of the opstring (\":ax:\") then it will not complain about unknown options or missing arguments for options that require them.",
  "excerpt": ""
 },
 {
  "title": "The Sprinting Centipede Strategy: How to Improve Software Without Breaking It",
  "published": "2013-01-14 20:29:23",
  "postType": "post",
  "slug": "/2013/01/14/the-sprinting-centipede-strategy-how-to-improve-software-without-breaking-it/",
  "status": "publish",
  "tags": [
   "best practices",
   "design",
   "opinion",
   "refactoring"
  ],
  "categories": [
   "General",
   "SW development"
  ],
  "content": "<em>Re-published from <a href=\"http://blog.iterate.no/2013/01/14/the-sprinting-centipede-strategy-how-to-improve-software-without-breaking-it/\">blog.iterate.no</a></em>.<br><br>Our code has been broken for weeks. Compiler errors, failing tests, incorrect behavior plagued our team. Why? Because we have been struck by a Blind Frog Leap. By doing multiple concurrent changes to a key component in the hope of improving it, we have leaped far away from its ugly but stable and working state into the marshes of brokenness. Our best intentions have brought havoc upon us, something expected to be a few man-days work has paralized us for over a month until the changes were finally reverted (for the time being).<br><br>Lessons learned: Avoid Frog Leaps. Follow instead Kent Beck's strategy of <a href=\"https://www.facebook.com/notes/kent-beck/when-worse-is-better-incrementally-escaping-local-maxima/498576730175196\" rel=\"nofollow\">Sprinting Centipede</a> - proceed in small, safe steps, that don't break the code. Deploy it to production often, preferably daily, to force yourself to really small and really safe changes. Do not change multiple unrelated things at the same time. Don't assume that you know how the code works. Don't assume that your intended change is a simple one. Test thoroughly (and don't trust your test suite overly). Let the computer give you feedback and hard facts about your changes - by running tests, by executing the code, by running the code in production.<br><br><!--more--><br><br>What happened? We have batch jobs whose configuration properties may be set via (1) command-line arguments or (2) job-specific or (3) shared entries in a file. The jobs used to access it via the static call <code>Configuration.get(\"my.property\")</code>. Since a global, automatically loaded configuration makes it impossible to unit-test the jobs with different configurations, we wanted to replace the singleton with instances of configuration passed around.<br><br>I will describe briefly our failed refactoring, propose a better way to do it, and discuss how to evolve and refactor software without such failures.<br><br><h2 id=\"Blogdraft:TheSprintingCentipedeStrategy:HowtoImproveSoftwareWithoutBreakingIt-Thepathtomarshes\">The path to marshes</h2><br><br>We have tried to produce this:<br><br><img src=\"https://lh4.googleusercontent.com/-CFlEKPGyNps/UO22cf5haMI/AAAAAAAACn8/RjIAKRYblN4/s640/refact_fail1.png\" alt=\"\" width=\"640\" height=\"169\" /><br><br><em>Fig.1: A large failed refactoring</em><br><br>We have started by replacing the static <code>Configuration</code> with three instantiable classes, each having only a single responsability (<a href=\"http://en.wikipedia.org/wiki/Single_responsibility_principle\" rel=\"nofollow\">SRP</a>). Then we have modified each job to accept/create the one it needed. We have also renamed some command-line arguments and properties to something more understandable and made various small improvements. Finally, we have replaced the (mis)use of the configuration system for storing information about where the jobs have finished their work the last time (\"bookmarks\") with something better. As a side-effect, there were also some other changes, for example the default configuration was no more loaded from a location on the classpath but from a relative file system path and the command-line arguments were processed little differently. All but one tests were passing and all looked well. It has been more complicated (a change required other changes, the original design was too simplistic, etc.) and thus took longer than expected but we have finally managed it.<br><br>However when we have tried to run the application, it didn't work. It couldn't find its configuration file (for it hasn't been looked up on the classpath anymore), some properties that used to respect job-specific values didn't do so anymore and we have unknowingly introduced some inconsistencies and defects. It has proven to be too difficult to find out how the individual configuration properties interacted and ensuring that all the sources of configuration - command-line arguments, shared and job-specific properties - were respected in the right order and at all places where necessary. Our attempts at fixing it took long and were futile. (Fixing broken legacy codebase which you haven't understood in the first place is never easy.)<br><br>Even if we managed to fix all the problems, another one would have remained. The changes weren't backwards compatible. To be able to deploy them to the production, we would need to stop everything, update (correctly) all the configuration and our cron jobs. A potential for many mistakes.<br><br><h2 id=\"Blogdraft:TheSprintingCentipedeStrategy:HowtoImproveSoftwareWithoutBreakingIt-Abetterway?\">A better way?</h2><br><br>Does it mean that improving software is too risky to pay off? No if we are more careful, proceed in small, safe, verified steps and minimize or avoid disruptive changes. Let's see how we could have proceeded if we followed these principles.<br><br><img class=\"alignnone\" src=\"https://lh5.googleusercontent.com/-RqHyh6yfALo/UO22eRfugFI/AAAAAAAACoE/bt5G_H2TZdk/s288/refact1_configinst.png\" alt=\"\" width=\"288\" height=\"208\" /><br><br><em>Fig.2: Introduce a configuration instance</em><br><br>As the first step (see Fig. 2), we could have left nearly everything as it was, only introduce a temporary <code>ConfigurationInstance</code><sup>1</sup> class with the same API (to make drop-in replacement easier) as <code>Configuration</code> but non-static and modify <code>Configuration</code> to forward all calls to its own (singleton) instance<sup>2</sup> of <code>ConfigurationInstance</code>. A small, easy, safe change. We could then modify our jobs, one by one, to use a <code>ConfigurationInstance</code> obtained via <code>Configuration.getInstance()</code> by default and also alternatively accept an instance of it upon creation. (Notice that anytime during this process we could - and should - deploy to production.)<br><br>The code would look like this:<br><br><pre><code>\r\nclass Configuration {\r\n   private static ConfigurationInstance instance = new ConfigurationInstance();\r\n   public static ConfigurationInstance getInstance() { return instance; }\r\n   public static void setTestInstance(ConfigurationInstance config) { instance = config; } // for tests only\r\n   public static String get(String property) { instance.get(property); }\r\n}\r\nclass ConfigurationInstance {\r\n   ...\r\n   public String get(String property) { /** some code ... */ }\r\n}\r\nclass MyUpdatedJob {\r\n   private ConfigurationInstance config;\r\n   /** The new constructor */\r\n   MyUpdatedJob(ConfigurationInstance config) { this.config = config; }\r\n   /** @deprecated The old constructor kept for now for backwards-compatibility */\r\n   MyUpdatedJob() { this.config = Configuration.getInstance(); }\r\n   doTheJob() { ... config.get(&amp;quot;my.property.xy&amp;quot;) ... }\r\n}\r\nclass OldNotUpdatedJob {\r\n   doTheJob() { ... Configuration.get(&amp;quot;my.property.xy&amp;quot;) /* not updated yet, not testable */ ... }\r\n}\r\n</code></pre><br><br>Once this is finished for all jobs, we could change the instantiation of jobs to pass in the <code>ConfigurationInstance</code>. Next we could remove all the remaining references to <code>Configuration</code>, delete it, and perhaps rename <code>ConfigurationInstance</code> to <code>Configuration</code>. We could regularly deploy to our test/staging environment and eventually to production to make sure that everything still works (which it should for the changes are minimal).<br><br>Next, as a separate and independent change, we could factor out and change the storage of \"bookmarks.\" Other improvements - such as renaming configuration properties - should also be done later and independently. (Not surprisingly the more changes you do, the higher risk of something being wrong.)<br><br>We could/should also introduce code for automatic migration from the old configuration to the new one - for example to read bookmarks in the old format if the new doesn't exist and store them in the new one. For properties we could add code that checks for both the old and the new name (and warns if the old one is still used). Thus deploying the changes would not require us to synchronize with configuration and execution changes.<br><br><hr /><br><br><sup>1</sup>) Notice that Java doesn't allow us to have both static and non-static method of the same name so we would need either to create instance methods in Configuration with different names or, as we did, create another class. We want to keep the same names to make migration from the static to the instance configuration a matter of a simple and safe search and replace (\"<code>Configuration.</code>\" with \"<code>configuration.</code>\" after having added the field <code>configuration</code> to the target class.) \"ConfigurationInstance\" is admittedly an ugly name but easy and safe to change later.<br><br><sup>2</sup>) A variation of the <a href=\"http://my.safaribooksonline.com/book/software-engineering-and-development/0131177052/dependency-breaking-techniques/ch25lev1sec11#X2ludGVybmFsX0J2ZGVwRmxhc2hSZWFkZXI/eG1saWQ9MDEzMTE3NzA1Mi8yNTU=\" rel=\"nofollow\">Introduce Instance Delegator</a> refactoring described in Michael Feathers' seminal book <a href=\"http://www.amazon.com/Working-Effectively-Legacy-Michael-Feathers/dp/0131177052/\" rel=\"nofollow\">Working Effectively with Legacy Code</a><br><br><h2 id=\"Blogdraft:TheSprintingCentipedeStrategy:HowtoImproveSoftwareWithoutBreakingIt-Principlesofsafesoftwareevolution\">Principles of safe software evolution</h2><br><br>Changing legacy - poorly structured, poorly tested - code is risky but necessary for the prevention of its further deteroriation and for making it better and thus decreasing its maintenance cost. It is well possible to minimize the risk - if we are cautious and proceed in small, safe steps while verifying the changes regularly (by testing and deploying to staging/production).<br><br><strong>What is a small and a safe change?</strong> It depends. But a good rule of thumb might be that it is such a change that (1) everybody else can daily merge in and that (2) can be then deployed to staging (and, f.ex. a day later, to production). If it should be possible to merge it in every day then it must be relatively small and non-destructive. If it should be deployed daily then it must be safe and backwards-compatible (or automatically migrating old data). If your change is larger or riskier than that, then it is too large/risky.<br><br><strong>Cost &amp; benefits of safety</strong>: It isn't easy or \"cheap\" to change software in a safe way. It requires us to think hard, to ocassionally make it uglier for a while, to spend resources on maintaining (temporary) backwards-compatibility. It seems to be much more efficient to change the code without catering for such safety - but only until you hit unexpected problems and spend days trying to fix stuff, knee deep in the shit (i.e. broken codebase being constantly changed by your teammates). It is similar to TDD - it is slower but pays off thanks to the time you do not waste debugging and troubleshooting production issues. (Showing the time you <em>do not</em> loose to your team or management is unfortunately challenging.)<br><br><strong>Sprinting Centipede - series of tiny changes</strong>: To make a change in small and safe steps, we often need to break it down and continually evolve the code towards the target design through a series of small changes, each one in a limited area of the codebase and along a single axis, changing a single thing only. The smaller and safer the changes, the faster we can perform and verify them and thus change quite a lot over time - this is what Kent Beck calls the Sprinting Centipede strategy.<br><br><a href=\"/wiki/development/parallel-design-parallel-change/\"><strong>Parallel Design</strong></a>: Sometimes a change cannot be really broken down, such as replacing a data storage with another one. In such a case we can apply for example the Parallel Design technique, i.e. evolving the new code, while still keeping the old code around. We can, for instance, first write only the code to store data in the new database; then start also reading from it while also reading from the old database, verifying the results are same and returning the old one; then we can start returning the new results (still keeping the old code around to be able to switch back); finally we can phase out the old code and storage.<br><br><strong>Prerequisities</strong>: It is of course possible to follow the Sprinting Centipede strategy only if you can build, test, and deploy and get warned about possible problems quickly. The longer the test and deployment (and thus feedback) cycle the longer steps you must make otherwise you will spend most of the time waiting.<br><br><h2 id=\"Blogdraft:TheSprintingCentipedeStrategy:HowtoImproveSoftwareWithoutBreakingIt-FAQ\">FAQ</h2><br><br><h3 id=\"Blogdraft:TheSprintingCentipedeStrategy:HowtoImproveSoftwareWithoutBreakingIt-HowcanIdeploytoproductionachangeIamnotcompletelysureiscorrect?\">How can I deploy to production a change I am not completely sure is correct?</h3><br><br>Code, especially legacy code, can rarely be tested really thoroughly and thus we have never complete certainity of its correctness. But we cannot give up improving the code for otherwise it will be only getting worse. Fear and stagnation isn't a solution - improvement of the codebase and the process is. We must carefuly consider the risk and test accordingly. The smaller the change and the better your monitoring and ability to roll back or fix quickly, the less impact will a possible defect have. (And if there is a chance for a defect, there will be one, earlier or later.)<br><br><h2 id=\"Blogdraft:TheSprintingCentipedeStrategy:HowtoImproveSoftwareWithoutBreakingIt-Conclusion\">Conclusion</h2><br><br>It might seem slow to follow the Sprinting Cantipede strategy of software evolution, i.e. proceeding in small, safe, largely non-disruptive, incremental steps while merging regularly with the main development branch and verifying the changes often by running tests and deploying to the production environment. But our experience has shown that a Blind Frog Leap - a hope-driven large change or batch of changes - may actually be much slower and ocassionally infeasible due to unexpected but always present complications and defects and consequential delays, diverging branches etc. And I believe that this happens quite often. Therefore do change only one thing at a time, preferably so that the change can be deployed without requiring other (configuration etc.) changes, collect feedback, make sure that you can stop the refactoring at any time while gaining as much value as possible from it (instead of investing a lot of effort into a large change and risking that it will be abandoned completely). What is your experience?<br><br>It is noteworthy that a similar problem happens too often on the level of projects. People try to produce too much at once instead of doing something minimal, deploying, and continuing the development based on feedback rather than believes.<br><br><h2 id=\"Blogdraft:TheSprintingCentipedeStrategy:HowtoImproveSoftwareWithoutBreakingIt-References\">References</h2><br><br><ul>\n    <li><a href=\"http://www.infoq.com/presentations/The-Limited-Red-Society\" rel=\"nofollow\">The Limited Red Society</a> (a good <a href=\"http://www.markhneedham.com/blog/2010/07/05/the-limited-red-society-joshua-kerievsky/\" rel=\"nofollow\">summary here</a>) - Joshua Kerievsky discusses the need to reduce “red” periods of time while developing software (also introduces Parallel Change, which I refer to as Parallel Design above)</li>\n    <li>A summary of Kent Beck's talk about<a href=\"/2012/03/12/kent-beck-best-practices-for-software-design-with-low-feature-latency-and-high-throughput/\" rel=\"nofollow\"> Best Practices for Software Design with Low Feature Latency and High Throughput</a></li>\n    <li><a href=\"http://www.agical.com/mikmeth/mikadomethod.pdf\" rel=\"nofollow\">The Mikado Method book</a> (online) has a nice description of a typical failed refactoring in the section \"The mikado method - a product of failure\" (1.2 in the current version)</li>\n</ul><br><br><h2 id=\"Blogdraft:TheSprintingCentipedeStrategy:HowtoImproveSoftwareWithoutBreakingIt-Acknowledgement\">Acknowledgement</h2><br><br>I'd like to thank to my colleagues Anders, Morten, and Jeanine for their help and feedback. Sorry Anders, I couldn't make it shorter. You know, every word is a child of mine :-).<br><br><p style=\"text-align:center;\"><em>You might enjoy also other <a href=\"/tag/opinion/\">posts on effective development</a>.</em></p>",
  "excerpt": ""
 },
 {
  "title": "Most interesting links of February ''13",
  "published": "2013-02-28 21:59:38",
  "postType": "post",
  "slug": "/2013/02/28/most-interesting-links-of-february-13/",
  "status": "publish",
  "tags": [
   "CleanCode",
   "clojure",
   "design"
  ],
  "categories": [
   "General",
   "Tools",
   "Top links of month"
  ],
  "content": "<h2>Recommended Readings</h2>\r\n<ul>\r\n\t<li><a href=\"http://comoyo.github.com/blog/2013/02/06/the-inverse-of-ioc-is-control/\">Øyvind Bakksjø: The inverse of IoC is Control</a> - a well-founded criticism of the (over)use of inversion-of-control containers such as Spring and Guice. Bakksjø isn't against dependency injection in general but he prefers to do it manually, instead of magically, in a main method, using Java instead of an obscure DSL/XML. The dependencies are typically known at compile time so why postpone assembling (and defect discovery) to runtime? Why hide how parts fit together into the non-transparent magic of IoC? He has many good points though I believe there are cases when some automation of the wiring process is valuable (think of scope-dependant beans, diff. deps in diff. environments etc.) Comment by B. Borud: \"<span style=\"color:#000000;\">Explicit wiring you can read from start to finish beats vague declarative shit that you <i>may</i> be able to figure out if you pay close attention.</span>\" Check out also the <a href=\"http://news.ycombinator.com/item?id=5181597\">comments at HN</a>.</li>\r\n\t<li>J. B. Rainsberger: <a href=\"http://blog.thecodewhisperer.com/2013/01/29/consequences-of-dependency-inversion-principle/\">Demystifying the Dependency Inversion Principle</a> - a very good explanation of the value of dependency injection in the terms of general good code principles (promoting abstractions and postponing determination of details to the latest moment/client)</li>\r\n\t<li><a href=\"http://www.codinghorror.com/blog/2008/07/coding-without-comments.html\">CodingHorror: Coding Without Comments</a> (2008) - a very good explanation if how to treat comments (similar what Clean Code says): write code so that it is self-explanatory (using good method and variable names), if necessary, add comments that explain why (while the code shows what/how).</li>\r\n\t<li><a href=\"http://agile.dzone.com/articles/frustrations-and-aspirations-0\">Frustrations and Aspirations of a Software Craftsman</a> - what makes us happy or unhappy on a project? (I could add some too.) Bad: bureaucracy, old/unfit technology, lack of autonomy and credibility, uninteresting domain, demotivated people, blaming and highly competitive environment, arrogant and unskilled people, ... =&gt; it is mostly about people. Good: projects where there is passion, craftsmanship, friendship and trust.</li>\r\n\t<li><a href=\"http://webtide.intalio.com/2013/01/jetty-9-goes-fast-with-mechanical-sympathy/\">Jetty-9 goes fast with Mechanical Sympathy</a> - interesting how the run-time behavior might differ from what we would expect and how knowing the hardware can improve performance. Here:  <a href=\"http://en.wikipedia.org/wiki/False_sharing\">false sharing</a> of a blocking queue's head/tail pointers and locks (close =&gt; same CPU cache row =&gt; updating one invalidates the other), using trie backed directly by IO buffers for faster String lookups etc. Result (all microbenchmark disclaimers): jetty-9 out performs jetty-8 by 30% faster and 50% less YG garbage.</li>\r\n</ul>\r\nCzech\r\n<ul>\r\n\t<li><a href=\"http://blog.kolman.cz/2013/02/jak-spravne-pojmenovat-test.html?m=1\">Daniel Kolman: Jak správně pojmenovat test</a> - a good description of different approaches to name and organize tests w.r.t. the experience of the developer - starting with \"testWorks1\" through one method-one test with \"testMyMethodName\" through a more thoughtful naming scheme such as Roy Osherove's <a href=\"http://osherove.com/blog/2005/4/3/naming-standards-for-unit-tests.html\">UnitOfWork_StateUnderTest_ExpectedBehavior</a> (e.g. ndexOf_containsSearchedString_returnsCorrectIndex) to tests as a living documentation: tests represent a list of features of the class, each name is a sentence having the class under test as its subject (e.g. [list] holdsItemsInTheOrderTheyWereAdded). Advantages of the latter: readability, documentation, it forces us to think what actually is still the responsability of the class and what isn't. \"<em>Stačí názvům testů věnovat dostatečnou pozornost a ony vám samy napoví, kdy už toho třída dělá moc a měli byste se zamyslet, jak kód lépe rozdělit.\"</em></li>\r\n</ul>\r\nNon-IT\r\n<ul>\r\n\t<li><a href=\"http://www.inc.com/suzanne-lucas/why-you-should-work-with-someone-you-hate.html\">Why You Should Work With Someone You Hate</a> - working with people we like and do not have conflicts with is nice but we are likely to have similar views and ideas and miss the broader picture. Working with somebody that drives you crazy while being able to respect each other is very valuable because it opens you to different views and forces you to really defend yours. Recommended!</li>\r\n\t<li><a href=\"https://www.facebook.com/note.php?note_id=536820369684165\">Kent Beck: Focusing Talks: Three Questions</a> - some good advices for performing technical talks and avoiding putting too much into the talk. Ask 1) Who is the audience? - be as specific and narrow as possible to be able to tune and cut the content; \"Better to reach one person than zero.\" 2) What is my one startling sentence? - one that makes the audience take notice; \"Picking one sentence, I encourage focus and empathy in myself. Now I have one person's attention. What do I say?\" 3) What would I like the audience to do? \"'To what purpose?' helps me discard interesting-but-tangential points, to, as Peter Jackson put it, move the ring.\" \"The more clear and uncompromising I can be with the three questions, though, the easier all the rest of it becomes.\" \"Talk about less. And less. Less than that.\"</li>\r\n</ul>\r\n<h2>Clojure Corner</h2>\r\n<ul>\r\n\t<li><a href=\"http://www.learningclojure.com/2013/02/clojures-reader-is-unsafe.html\">Clojure's Reader is Unsafe (for untrusted strings)</a> - don't use read-string to read untrusted strings - even if you set *read-eval* to false, it can still be persuaded to execute arbitrary code (hopefully fixed in Clojure 1.5). The right, save way is to use clojure.tools.reader.edn/read-string.</li>\r\n</ul>\r\n<h2>Tools</h2>\r\n<ul>\r\n\t<li><a href=\"http://android.stackexchange.com/questions/594/clock-to-use-when-giving-presentations\">Android: Clock to use when giving presentations</a> - presentation countdown apps for Android</li>\r\n\t<li><a href=\"https://github.com/Netflix/SimianArmy\">Netflix open-sourced its Chaos Monkey and the whole SymianArmy </a></li>\r\n</ul>",
  "excerpt": ""
 },
 {
  "title": "JDBC: What resources you have to close and when?",
  "published": "2013-02-18 08:54:35",
  "postType": "post",
  "slug": "/2013/02/18/jdbc-what-resources-you-have-to-close-and-when/",
  "status": "publish",
  "tags": [
   "best practices",
   "java",
   "jdbc"
  ],
  "categories": [
   "Languages"
  ],
  "content": "I was never sure what resources in JDBC must be explicitely closed and wasn't able to find it anywhere explained. Finally my good colleague, Magne Mære, has explained it to me:\r\n<blockquote>In JDBC there are several kinds of resources that ideally should be closed after use.  Even though every Statement and PreparedStatement is specified to be implicitly closed when the Connection object is closed, you can't be guaranteed when (or if) this happens, especially if it's used with connection pooling. You should explicitly close your Statement and PreparedStatement objects to be sure. ResultSet objects might also be an issue, but as they are guaranteed to be closed when the corresponding Statement/PreparedStatement object is closed, you can usually disregard it.</blockquote>\r\nSummary: Always close PreparedStatement/Statement and Connection. (Of course, with Java 7+ you'd use the try-with-resources idiom to make it happen automatically.)<br><br>PS: I believe that the close() method on pooled connections doesn't actually close them but just returns them to the pool.<br><br>A request to my dear users: References to any good resources would be appreciate.",
  "excerpt": ""
 },
 {
  "title": "Most interesting links of Mars ''13",
  "published": "2013-03-31 21:59:58",
  "postType": "post",
  "slug": "/2013/03/31/most-interesting-links-of-mars-13/",
  "status": "publish",
  "tags": [
   "agile",
   "aws",
   "book",
   "CleanCode",
   "clojure",
   "cloud",
   "design",
   "development",
   "DevOps",
   "estimation",
   "html5",
   "human",
   "leanstartup",
   "learning",
   "methodology",
   "presentation",
   "python"
  ],
  "categories": [
   "General",
   "SW development",
   "Tools",
   "Top links of month"
  ],
  "content": "<h2>Recommended Readings</h2>\r\nA lot of stuff this month since I have finally got time to review some older articles. Quite a few articles by Fowler. Few really great (yet short) talks on agile &amp; SW development.<br><br>Top\r\n<ul>\r\n\t<li><a href=\"http://youtu.be/502ILHjX9EE\">Agile in a Nutshell</a> (originally Agile Product Ownership in a Nutshell) by Henrik Kniberg - the best explanation of the agile development process ever, in just 15 minutes and with wonderful animation; every developer should see this. Some highlights: the most important task of product owner is to say NO so that backlog doesn't grow infinitely; at start, the estimates of size and value will suck and that's OK because the value is in the conversation, not in the numbers (that are anyway just relative); the goal is to maximize outcome (value), not output (# features). Compromises between short-term vs. long-term goals, knowledge vs. customer value building etc. Build the right thing (PO) x build it right (devs) x build it fast (SM). Technical debt x sustainable pace. As I said - you MUST see it.</li>\r\n\t<li><a href=\"http://youtu.be/8kotnF6hfd8?t=45m\">Martin Fowler: The Value of Software Design</a> (talk, 22 min, from 0:45:00 til 1:07; Feb 2013) - a balanced argument for the value of good software design and internal code quality based on paying off by enabling us to keep our development speed. Discusses the <a href=\"http://martinfowler.com/bliki/DesignStaminaHypothesis.html\">DesignStaminaHypothesis</a> (bad design =&gt; rapid decline of development speed), <a href=\"http://martinfowler.com/bliki/TechnicalDebt.html\">TechnicalDebt</a>, <a href=\"http://martinfowler.com/bliki/TechnicalDebtQuadrant.html\">TechnicalDebtQuadrant</a> (Prudent x Reckless, Deliberate x Inadvertent), <a href=\"http://martinfowler.com/bliki/TradableQualityHypothesis.html\">TradableQualityHypothesis</a>. According to the experience of Fowler and others, the good design payoff point \"it's weeks, not months.\"</li>\r\n\t<li><a href=\"http://www.moserware.com/2008/03/what-does-it-take-to-become-grandmaster.html\">What Does It Take To Become A Grandmaster Developer?</a> - great post about cognition and learning, valuable references, quotes from an interesting study of good vs. mediocre developers. We have mental capacity for ~7 chunks of information =&gt; great performers recognize patterns and see and understand thus higher-level chunks and have many \"chunks\" (patterns encountered previously) readily available. You need deliberate effort to learn more chunks - especially initially but you must always try to get out of your comfort zone to grow. Experienced collegues can help a lot in acending the learning curve.</li>\r\n</ul>\r\nAgile, organization, innovation, project management\r\n<ul>\r\n\t<li><a href=\"http://agile.dzone.com/articles/how-prioritize-user-story-map\">How to Prioritize a User Story Map</a> - we all know that we should prioritize features by their value, risk, and lack of knowledge and that we should slice the features thin so that they fit into short iteration and can be deployed soon to produce feedback, right? Here we see a nice example of what happens if not done so and how to do feature slicing better.</li>\r\n\t<li><a href=\"http://flowchainsensei.wordpress.com/rightshifting/\">Bob Marshall: Rightshifting</a> - according to the author, 80% of knowledge work organizations are very ineffective, wasting resources on non-value-adding activites; only few are effective, even fewer highly effective. Rightshifting is the attempt at shiting them to the right, towards higher effectiveness. Links to a few videos explaining it more. Related: Steve McConnell's <a href=\"http://www.stevemcconnell.com/psd/13-businesscase.htm\">Business Case for Better Software Practices</a>, referring to a study by <a href=\"http://www.sei.cmu.edu/\">SEI</a>; \"The actual distribution of software effectiveness is asymmetric. Most organizations perform much closer to the worst practice than to the best.\" - the best performing 10 times better then the worst/average (productivity, speed, defects, value)</li>\r\n\t<li><a href=\"http://continuousdelivery.com/2013/01/on-antifragility-in-systems-and-organizational-architecture/\">On Antifragility in Systems and Organizational Architecture</a> - introduces the concept of antifragility, based on Nassim Taleb's book <a href=\"http://www.amazon.com/dp/1400067820?tag=contindelive-20\">Antifragile</a> that compares fragile, robust, and antifragile systems and organizational structures (which is also applicable to SW systems); robust = resists change (unless too large); antifragile: learn, adapt; <a href=\"http://itrevolution.com/the-three-ways-principles-underpinning-devops/\">closely related to DevOps</a> and continous delivery</li>\r\n\t<li><a href=\"http://martinfowler.com/bliki/PurposeOfEstimation.html\">M. Fowler: PurposeOfEstimation</a> - many Agilist disdain estimation, this is a balanced view: \"estimation is valuable when it helps you make a significant decision.\" (F.ex. when deciding what we (don't) have resources for or when in need of coordinating related activities.) It is evil when used as commitments that people are forced to stick to and blamed for not managing to do so. \"Above all be wary of anyone who tells you they [estimates] are always needed, or never needed.\" A. Ferguson: \"[..] it is poor project management (whether by project managers or other team members) that results in a client who thinks estimates are fixed, or that raw estimates = actual effort/duration\".</li>\r\n\t<li>Ron Jeffries: <a href=\"http://pragprog.com/magazines/2013-02/estimation-is-evil\">Estimation is Evil</a> - discusses the problems estimates can cause, issues with requirements gathering up front and their volatility, transparency and politics. Very valuable, highly recommended. See the \"favorite quotes\" at the bottom of this post. Also contains an interesting lesson learnt from the failed Chrysler C3 project: don't try to build a grand new system to replace and fix the old one, fix one problem at a time - worth reading for this alone.</li>\r\n\t<li>Interview with Steve Blank: <a href=\"http://steveblank.com/2013/02/23/why-big-companies-cant-innovate/\">Why Big Companies Can’t Innovate</a> - the 2013 list of the world’s 50 most innovative companies has only a few large, established firms (those that have built innovation into its DNA such as Apple and Google). Established companies are less innovative because they focus in their existing business model, have risk-aversion (while there are many failures on the way to a new business model); finally \"the people who are best suited to search for new business models and conduct iterative experiments usually are not the same managers who succeed at running existing business units.\" - and thus aren't given the chance. \"[..]  the process of starting a new business [..] is fundamentally different from running an existing one. So if you want your company to grow organically, then you need to organize your efforts around these differences.\"</li>\r\n</ul>\r\nArchitecture &amp; Ops\r\n<ul>\r\n\t<li><a href=\"http://youtu.be/8kotnF6hfd8\">M. Fowler: Schemalessness + NoSQL and Consistency</a> (20 + 20 min) two short, very good, balanced talks about NoSQL. He explains schemalessness and consistency and points out common misunderstanding about them so if you are into NoSQL, watch it.</li>\r\n\t<li><a href=\"http://instagram-engineering.tumblr.com/post/13649370142/what-powers-instagram-hundreds-of-instances-dozens-of\">What Powers Instagram: Hundreds of Instances, Dozens of Technologies</a> (2012) - interesting high-level overview of the Instagram infrastructure based on AWS and Python (25 XL instances running Django/Gunicorn behind ELB with 3 Nginxes, sharded PostgreSQL with streaming replication on 12 QXL mem instances with software raid and XFS to freeze when snapshoting, media in S3, Redis, Solr for geo-search, Memcached. <a href=\"http://gearman.org/\">Gearman</a> for task queues, <a href=\"https://github.com/samuraisam/pyapns\">pyapns</a> for notifications. <a href=\"http://munin-monitoring.org/\">Munin</a> for monitoring.)</li>\r\n\t<li><a href=\"http://www.infoq.com/news/2013/02/netflix-api-optimization\">The Netflix API Optimization Story</a> - how Netflix redesigned its APIs to improve performance, reduce chattiness, and power product development and experimentation. The common REST API has become a development bottleneck and a lowest common denominator solution (w.r.t. supporting various clients). The main changes were: usage <a href=\"https://github.com/Netflix/Hystrix#readme\">Hystrix</a> for fault tolerance, each device team managing their own end-points in any JVM languges (primarily Groovy) and re-using common APIs (i.e. pushing some device-specific code to the server) =&gt; able to experiemnt more quickly, using the <a href=\"http://techblog.netflix.com/2013/02/rxjava-netflix-api.html\">Functional Reactive Programming Model</a> and asynchronous APIs (to abstract away thread-safety and parallel execution implementation details from the device teams so that code can execute sync. or async. without them needing to know).</li>\r\n\t<li>Me: <a href=\"/wiki/development/ops-monitoring/#libraries\">Overview of current monitoring libs for Java</a> - Netflix' Servo, Yammer's Metrics, JavaMelody, JavaSimon.</li>\r\n\t<li><a href=\"http://omel.ette.org/blog/2013/02/06/debug-servlets/\">Debug Servlets, or 'HTTP Won; Use It'</a> - expose all debugging info of your services over HTTP - it makes debugging much simpler. We do a part of it and it really helps. Expose config (values, where they come from), logs, log configuration, JMX (setting it up otherwise <a href=\"/2012/09/21/visualvm-monitoring-remote-jvm-over-ssh-jmx-or-not/\">not trivial</a>), version, build number, git hash, server time (timezones tricky), <a href=\"/wiki/development/ops-monitoring/#libraries\">metrics</a>, stack dumps, app-specific status (Hadoop: live nodes, data size etc.). The author recommends <a href=\"http://code.google.com/p/javamelody/\">JavaMelody</a> to collect &amp; visualize many common metrics. Not on security: Make sure to hide passwords and make the endpoints visible only internally. (Tip: consider <a href=\"http://www.jolokia.org/\">Jolokia</a> for exposing JMX over HTTP, see below.)</li>\r\n\t<li><a href=\"http://www.itismycareer.com/jvm_crash_analysis/\">JVM Crash/Core Dump Analysis</a> - 3 common categories of  JVM crash causes (JVM/JIT/JNI) and how to recognize and troubleshoot them</li>\r\n</ul>\r\nOther\r\n<ul>\r\n\t<li><a href=\"http://browserdiet.com/\">How to lose wight in the browser:  The definitive front-end performance guide</a> - a site by a number of experts from Twitter, Opera, Google, and other places with best practices for performant web sites (HTML, CSS, JS, jQuery, images). Ex.: styles up top, scripts down bottom; minify your html, css and JS; async script loading; combine css/JS files into one; cache array lengths while looping; use css sprites for icons.</li>\r\n\t<li>Luke Stevens: <a href=\"http://www.webdesignerdepot.com/2013/01/the-harsh-truth-about-html5s-structural-semantics-part-1/\">The harsh truth about HTML5′s structural semantics (part 1)</a> - \"HTML’s structural elements — article, section, nav and aside — are, at first glance, some of the easiest parts of the HTML5 specification to understand and implement. However, they’re actually some of the most poorly specified, poorly understood, and poorly implemented parts of HTML5.\" Interesting: The \"research\" leading to their establishment was quite random, ignoring a crucial source of information (css IDs).</li>\r\n\t<li><a href=\"http://blog.markpatino.com/six-non-technical-books-every-programmer-should-read/\">Marco Emmanuel Patiño: Six non-technical books every programmer should read</a> - 1. Team Geek: A Software Developer’s Guide to Working Well with Others (-&gt; effective communication and collaboration), 2. The Pragmatic Programmer: From Journeyman to Master, 3. The Passionate Programmer: Creating a Remarkable Career in Software Development, 4. Clean Code: A Handbook of Agile Software Craftsmanship, 5. 97 Things Every Programmer Should Know: Collective Wisdom from the Experts (<a href=\"http://programmer.97things.oreilly.com/wiki/index.php/Contributions_Appearing_in_the_Book\">online</a>), 6. Code Simplicity: The Fundamentals of Software.\r\n<ul>\r\n\t<li>Related: <a href=\"http://javarevisited.blogspot.in/2013/01/top-5-java-programming-books-best-good.html\">Top 5 Java programming books - Best of lot</a> (actually 8) - 1) Head First Java, 2) Effective Java, 3) Thinking in Java, 4) Head First Design Pattern, 5) Concurrency Practice in Java, 6)Java performance, 7) Java Puzzlers, 8) Head First Object Oriented Analysis and Design.</li>\r\n</ul>\r\n</li>\r\n\t<li><a href=\"http://m.motherjones.com/environment/2013/01/lead-crime-link-gasoline\">Humans as slaves of chemistry: America's Real Criminal Element - Lead</a> - a fascinating article about how whole nations can be seriously influenced by a single chemical substance. Aside of that it is also fascinating to observe how we tend to search for causes in our domain of expertise (police, sociologists, ...) and of interest while denying other possible causes, no matter how strong are the proofs. If the facts presented are true, then the fivefold increase in serious crimes in (not only) America since 60s has been caused by the increase of lead in the environment (pushing many people over the edge of ocassional violent loss of control). How many social problems in the world have similar industrial causes? Are we careful enough with what we let into our air and bodies?</li>\r\n</ul>\r\nLanguages\r\n<ul>\r\n\t<li><a href=\"http://newcoder.io/\">newcoder.io: Learning more Python via projects</a> - an excellent next step when you have learned Python syntax via <a href=\"http://learnpythonthehardway.org/\">LPHW</a> or similar; in this tutorial series you will be building real-world apps while learning more of Python. You will play with, Data Visualization, APIs, Web Scraping, Networks, GUI.</li>\r\n\t<li>Brian McCallister: <a href=\"http://skife.org/go/2012/11/18/go_part_1.html\">Go is PHP for the Backend</a> - a very good explanation why you might want to use Go and that you have to first learn \"the Go way\" to avoid insanity, since it is very opinionated and different from what you might be used to. Some pros: \"native code, UNIX friendly, higher level then C, lower level then Python or Ruby, garbage collected, strongly typed, good performance, good concurrency support, etc.\"</li>\r\n\t<li><a href=\"http://danielwestheide.com/blog/2012/11/21/the-neophytes-guide-to-scala-part-1-extractors.html\">The Neophyte's Guide to Scala 1</a> to <a href=\"http://danielwestheide.com/blog/2013/03/20/the-neophytes-guide-to-scala-part-15-dealing-with-failure-in-actor-systems.html\">15</a> (<a href=\"http://danielwestheide.com/blog/tags/scala/\">list</a>) - a good follow-up on the Cursera FP in Scala course, a series of blog posts exploring some topics more in depth. F.ex.: extracotrs (unapply, for pattern-matching), the broad applicability of pattern matching, pattern matching anonymous functions &amp; partial functions <a href=\"http://danielwestheide.com/blog/2012/12/12/the-neophytes-guide-to-scala-part-4-pattern-matching-anonymous-functions.html\">#4</a>, usiong Option idiomaticly<a href=\"http://danielwestheide.com/blog/2012/12/19/the-neophytes-guide-to-scala-part-5-the-option-type.html\"> #5</a>, nice FP error handling with the Try type <a href=\"http://danielwestheide.com/blog/2012/12/26/the-neophytes-guide-to-scala-part-6-error-handling-with-try.html\">#6</a>, Futures, etc. Higly recommended! Thx to Jakob Lind</li>\r\n</ul>\r\nLibs\r\n<ul>\r\n\t<li><a href=\"http://www.jolokia.org/\">Jolokia is remote JMX with JSON over HTTP</a>: a REST API bridged to JMX, with support for security, fine-grained access control, bulk operations. Especially useful if you either 1)  need to perform bulk operations (e.g. get multiple values) or 2) want to access them from something that doesn't support JMX. JSON is in general very easy to use and navigate. You can install Jolokia as a WAR (or mebedd its Servlet), a JVM agent, or attach it on-the-fly to a running JVM.</li>\r\n\t<li><a href=\"http://www.josetteorama.com/zeromq/\">The Appeal and Controversy of ZeroMQ</a> - why to use 0MQ? It is a messaging library that focuses on performance, decentralization and simplicity, solving some really hard problems (sending async. messages w/o locks, distribuing to specific subscribers) and providing a simple API. Main pros: decentralized (no central broker), many languages; cons: no security (but you can use it over SSH).</li>\r\n</ul>\r\n<h2>Talks</h2>\r\n<ul>\r\n\t<li><a href=\"http://ecorner.stanford.edu/authorMaterialInfo.html?mid=3103\">Tim O'Reilly: Create More Value Than You Capture</a> (30 min + questions) - build apps that matter, that change how we do things. Thinking just about money is bad. Try to make the society better, smart, create more value than you capture, solve important problems, help people. Ex. startups: <a href=\"https://www.uber.com/cities\">Uber</a>, <a href=\"https://squareup.com/\">Square</a>, <a href=\"http://codeforamerica.org/about/\">Code for America</a>.</li>\r\n\t<li>TED: <a href=\"http://www.ted.com/talks/bruce_feiler_agile_programming_for_your_family.html\">Bruce Feiler: Agile programming -- for your family</a> (20 min) - an inspirational talk, based on positive experience from multiple families, about applying the agile thinking and values to make our families happier by empowering the children (enlist them in their upbringing, deciding on goals, rewards, punishments), letting them know who they are, being adaptive, having regular \"retrospectives\" (that eventually become cherrished memories). Backed by research. Did you know that the #1 wish of children isn't that parents spend more time with them but that they are less stressed?</li>\r\n</ul>\r\n<h2>Clojure Corner</h2>\r\n<ul>\r\n\t<li><a href=\"https://github.com/clojure/clojure/blob/master/changes.md\">What's new in Clojure 1.5.x</a> - reducers, new threading macros (cond-&gt;, as-&gt;, some-&gt;, ..), various improvements, improved performance, erro messages, doc strings, bug fixes</li>\r\n\t<li><a href=\"http://stuartsierra.com/2013/03/29/perils-of-dynamic-scope\">Stuart Sierra: On the Perils of Dynamic Scope</a> - summary: don't create macros like <em>with-connection</em> binding to a thread-local <em>var</em>; make all methods take the resource as a parameter - thus the user has the freedom to decide when to close the resource and isn't limited to a single thread and can use lazy sequences</li>\r\n\t<li><a href=\"http://programming-puzzler.blogspot.no/2013/03/logic-programming-is-overrated.html\">Logic programming is overrated</a> - core.logic is essentially only a complex DSL for doing an exhaustive search and there is already a nice, clean tool for that: the for comprehension. A logic puzzle can be much more clearly and also efficiently using for. But it is not completely useless - logic programming is good e.g. for running programs backwards, unification is important for writing type checkers, and the new constraint programming piece has good potential. Read also <a href=\"http://swannodette.github.com/2013/03/09/logic-programming-is-underrated/\">Logic Programming is Underrated</a>, which provides a faster core.logic solution than for-comprehension and provides some pointers rgarding the practical usefulness of core.logic.</li>\r\n\t<li>Prismatic - <a href=\"http://blog.getprismatic.com/\">Graph: Abstractions for Structured Computation</a> - How to reduce the complexity overhead in large, real-world, FP systems by decoupling what is done from how it is executed. Graph is a Clojure library enabling a declarative way to describe how data flows between (mostly pure) functions =&gt; \"It allows us to formalize the informal structure of good FP code, and enables <em>higher-order </em>abstractions over these structures that can help stamp out many persistent forms of complexity overhead.\" By decoupling the description of how data flows and the actual execution, we can execute it in different ways (parallelized, with memoization, lazy/eager) and apply various interceptors (for logging etc.). See especially the part \"Graph and complexity overhead.\"</li>\r\n\t<li>Mike Anderson: <a href=\"http://clojurefun.wordpress.com/2013/03/21/game-development-in-clojure-alchemy-7drl-post-mortem/\">Game development in Clojure : Alchemy 7DRL post-mortem</a> (and the previous 7 daily updates, <a href=\"https://github.com/mikera/alchemy\">Alchemy @ GitHub</a>) - an interesting report about game making in Clojure during 7 days, in as functional and immutable style as possible while keeping it sufficiently fast. How do you represent &amp; handle statuf game objects, the world map, game state? The design of the game, what was easy and what hard with Clojure. Tl;dr: search it for \"Some parting thoughts\" (Clojure productive, immutability hard but pays off, prototype objects great, more typing would have helped). \"Making everything immutable in Clojure is harder than it would have been in an OOP language like Java where everything can be encapsulated in mutable classes. In particular, the state update functions are tricky to make both correct and performant. The payoff is big however: in terms of the simplicity and effectiveness later on, and in the conceptual clarity being able to treat the entire game state as an immutable value\". Having REPL is a big win.</li>\r\n\t<li><a href=\"http://maurits.wordpress.com/2013/03/10/refactoring-java-using-clojure-with-the-eclipse-java-development-tools-jdt/\">Refactoring Java using Clojure with the Eclipse Java development tools (JDT)</a> (operation on AST nodes, i.e. little too low level; the <a href=\"http://stackoverflow.com/a/9585503\">Eclipse Refactoring API</a> might be better)</li>\r\n\t<li><a href=\"http://www.pitheringabout.com/?p=778\">Clojure at a Bank – [Our] Clojure Code Immaturity</a> - experiences with going from Java to Clojure: 1) too few comments, too short names =&gt; hard to learn the code; 2) not knowing clojure.core well enough =&gt; reimplementing (if-let, juxt, ...); 3) structure, comment, split up your namespaces well, navigating more complicated then in Java IDEs; 4) reasonably used Macros, Protocols, Defrecords payed off;</li>\r\n\t<li><a href=\"http://www.flyingmachinestudios.com/programming/datomic-for-five-year-olds/\">Datomic for Five Year Olds</a> - explaining the key characteristics of Datomic compared to relational and NoSQL DBs (schema, architecture, programmability/language); doesn't go into details of how it works (e.g. how does Datomic determine what subset of the DB to cache locally and what if it is few GBs); Honey Badger's 2012 talk <a href=\"http://oredev.org/2012/sessions/exploring-datomic-a-database-deconstructed\">Exploring Datomic: a database deconstructed</a> explores the architecture and technical details much more</li>\r\n</ul>\r\n<h2>Tools</h2>\r\n<ul>\r\n\t<li><a href=\"http://downloads.vagrantup.com/tags/v1.1.0\">Vagrant 1.1.0</a> is out (<a href=\"https://github.com/mitchellh/vagrant/blob/master/CHANGELOG.md#110-march-14-2013\">what's new?</a>), with <a href=\"http://www.hashicorp.com/blog/preview-vagrant-aws.html\">support for VMWare Fusion and AWS</a> VM backends in addition to VirtualBox - use the same config to create, provision, stop, destroy and connect to a virtual machine locally or in the cloud (with limited support for shared folders, I'd suppose). V. 1.1 is backwards compatible aside of plugins, upgrade to new config optional.</li>\r\n\t<li>Animated presentations: <a href=\"http://www.artrage.com/\">ArtRage</a> (drawing program, also for iPad), <a href=\"http://www.wacom.com/en/creative/products/pen-tablets/intuos/intuos5-touch-medium\">Wacom Intuos 5</a> (drawing tablet), Screenflow (screen &amp; audio capture) - used for the <a href=\"http://youtu.be/502ILHjX9EE\">Agile in a Nutshell</a> (Agile Product Ownership in a Nutshell) mentioned above</li>\r\n\t<li><a href=\"http://www.spinellis.gr/sw/ckjm/\">ckjm — Chidamber and Kemerer Java Metrics</a> (<a href=\"http://www.ibm.com/developerworks/java/library/j-eaed6/index.html\">via Neal Ford</a>) - a command-line tool (also Maven/Ant plugin) to compute some metrics, outputting text or XML for further processing; <a href=\"http://www.spinellis.gr/sw/ckjm/doc/metric.html\">the metrics</a>: WMC: Weighted methods per class (cyclomatic complexity of its methods), DIT: Depth of Inheritance Tree, NOC: Number of Children, CBO: Coupling between object classes, RFC: Response for a Class, LCOM: Lack of cohesion in methods, NPM: Number of Public Methods, Ca: afferent coupling.</li>\r\n\t<li><a href=\"http://dev.hubspot.com/blog/bulletproof-demos\">Bulletproof Demos: Record &amp; Replay built into Chrome</a> - ever got a failure while demonstrating a web app though it has worked moments ago? No more! You Chrome to record your requests and responses and let its cache handle them during the real demonstration. (Mac: stop Chrome, to record run <em>open -a \"Google Chrome\" --args --record-mode</em>, to replay run <em>open -a \"Google Chrome\" --args --playback-mode</em>. Linux: <em>google-chrome --record-mode</em> and <em>--playback-mode</em>. Win.: run <em>chrome &lt;arg&gt;</em>)</li>\r\n\t<li><a href=\"http://www.usertesting.com/how-it-works\">UserTesting.com</a> (via Ash Maurya, the author of Running Lean) - on-demand usability testing; they have a large base of test users, can select those matching your criteria and unleash them upon your site guided by a script your provide, watch videos of their actions while they verbalize their thinking process, recieve written answers from them, talk to them.</li>\r\n\t<li><a href=\"http://www.mindmup.com/\">MindMup.com</a> - <a href=\"https://github.com/mindmup/\">opensource</a>, free mind-mapping in the cloud by Gojko Adzic &amp; co., with main focus on productivity. Store private maps in Goolge Drive, support for mobile devices, keyboard shortcuts. No registration needed.</li>\r\n</ul>\r\n<h2>Favorite Quotes</h2>\r\n<blockquote>Once we estimated a project to require 9 man-months but were later told that we do not understand a thing and it may not take more then 4. At the end it took over 25 and still wasn't done.<br><br><em>- paraphrasing my collegue Kim Leskovski</em></blockquote>\r\nOn collecting requirements up front:\r\n<blockquote>At the very beginning, we know less about our project than we’ll ever know again. This is the worst possible moment to be making firm decisions about what we “require.”<br><br><em>- Ron Jeffries in <a href=\"http://pragprog.com/magazines/2013-02/estimation-is-evil\">Estimation is Evil: Overcoming the Estimation Obsession</a>\r\n</em></blockquote>\r\nOn the estimate of project delivery date at its initial phase:\r\n<blockquote>It’s based on an unrealistic list of requirements, using weak estimates, made at the moment of maximum ignorance, by people who are always optimistic about their own abilities.\r\n<em>- ibid\r\n</em></blockquote>\r\nOn planning and requirements (the Chrysler’s C3 payroll project, having a payroll expert and a team familiar with the domain):\r\n<blockquote>This was one of the best-planned projects I’ve ever seen, and even so, at least one third of the requirements were added, removed, or substantially changed.\r\n<em>- ibid\r\n</em></blockquote>\r\n<blockquote>[..] a line of code is a liability, not an asset [..]\r\n<em>- Jez Humble in <a href=\"http://agile.dzone.com/articles/jez-humble-why-software\">Why Software Development Methodologies Suck</a>\r\n</em></blockquote>\r\n<blockquote>Agile is not something you do, it is something you are.\r\n<em>- Huib Schoots in Creating my own flow\r\nwith personal kanban, <a href=\"www.agilerecord.com\">Agile Record</a> Feb 2013\r\n</em></blockquote>",
  "excerpt": ""
 },
 {
  "title": "You are not lean unless you have a clear objective and measure",
  "published": "2013-03-19 14:29:51",
  "postType": "post",
  "slug": "/2013/03/19/you-are-not-lean-unless-you-have-a-clear-objective-and-measure/",
  "status": "publish",
  "tags": [],
  "categories": [
   "SW development"
  ],
  "content": "A colleague of mine, Bjørn Remseth, had a good observation:\r\n<blockquote>Without a clear objective you cannot be lean.</blockquote>\r\nThe <a href=\"/why-lean/\">lean approach</a> is, essentially, about optimizing a process, a company. If you don't know what you are optimizing then, by definition, you are not lean.<br><br>The thing being optimized in lean is the value produced by the process, whatever that is. We can see that also from the fact that lean is very focused on eliminating waste where waste is defined as activities that do not contribute to the creation of value.<br><br><strong>Do you know what value you are trying to maximize? Do you have a single number to measure that value? Do you track the number from week to week? </strong><br><br>If not then you perhaps aren't that lean after all.\r\n<h2>Comments</h2>\r\nFrom my experienced colleague Kim Ophus Leskovsky:\r\n<blockquote>The hard part of this fact, however, is to find out how to measure and how to make sure the objective is at the right level. That is, not a fluffy objective everyone can agree on, and not too specific and micro-optimized. How does our objective appreciate the system or optimize the whole? How does our objective make sure it gives us a purpose and in the same time is low level enough so that we can free our potential through autonomy and the feeling of mastery? We talk a lot about skilled craftsmen and good development techniques. This issue requires good leadership that knows how to handle the demanding balances that needs to be fine tuned in order to achieve great results through relevant objectives</blockquote>",
  "excerpt": ""
 },
 {
  "title": "From Stateful Iteration in Python to Stateless Clojure",
  "published": "2013-03-18 22:07:08",
  "postType": "post",
  "slug": "/2013/03/19/from-stateful-iteration-in-python-to-stateless-clojure/",
  "status": "publish",
  "tags": [
   "clojure",
   "python",
   "statelessness"
  ],
  "categories": [
   "General"
  ],
  "content": "I have a piece of Python code that leverages a stateful object and was wondering how to reimplement it in the inherently stateless Clojure, without resorting to its facilities for managing state. It turns out to be simple and beautiful.<br><br>The core of the code is a for loop that transform a list of maps, while also using input from another iterator-like object, a Palette. The Palette has the method next() that remembers the last color used and returns the next one. Here it is:<br><br><pre><code>\r\nclass Palette:\r\n    last_idx = 0\r\n    colors = [&quot;C04000&quot;, ...]<br><br>    def next(self):\r\n        self.last_idx = (self.last_idx + 1) % len(self.colors)\r\n        return self.colors[self.last_idx]<br><br>graph_items = []<br><br>for idx, item in enumerate(item_maps):\r\n    graph_items.append({\r\n            &quot;itemid&quot;: item['itemid'],\r\n            &quot;color&quot;: palette.next(),\r\n            &quot;sortorder&quot;: idx\r\n            })\r\n</code></pre><br><br>In Clojure, we would rather have no such state (for reasons I won't discuss now). However, when writing idiomatic Clojure, we actually don't need to.<br><br>We will use the fact that <em>map</em> - the function that can transform collection items - can take not just one but any number of collections, iterating over all of them in parallel. Instead of using the stateful palette.next(), we will create an infinite sequence of (repeating) colors and pass it into <em>map</em> together with the <em>items</em> collection. We want also the index of the items so we pass in a third sequence, the range from 0 to infinity. The map function will be thus called with (the current index, the current item, the current color).<br><br>Using infinite sequences is quite common (and elegant) in Clojure.<br><br>This is what the code could look like:<br><br><pre><code>\r\n;; An infinite sequence of the colors (starting\r\n;; again with the 1st one, when all exhausted)\r\n(def palette (cycle [&quot;C04000&quot; &quot;...&quot;]))<br><br>(defn make-graph-items [items]\r\n  (map\r\n   (fn [idx item color] {&quot;itemid&quot; (item &quot;itemid&quot;), &quot;color&quot; color, &quot;sortorder&quot; idx})\r\n       (range) items palette))<br><br>(def graph-items (make-graph-items items))\r\n</code></pre>\r\n<h2>Conclusion</h2>\r\nStatelessness is not scary. It is fun.<br><br><em>Disclaimer: I am only learning both Python and Clojure.</em>",
  "excerpt": ""
 },
 {
  "title": "Escaping the Zabbix UI pain: How to create a combined graph for a number of hosts using the Zabbix API",
  "published": "2013-03-20 22:59:33",
  "postType": "post",
  "slug": "/2013/03/21/create-graph-with-zabbix-api/",
  "status": "publish",
  "tags": [
   "ops",
   "python",
   "zabbix"
  ],
  "categories": [
   "General"
  ],
  "content": "<div id=\"main-content\">\r\n<div><br><br>This post will answer two questions:\r\n<ul>\r\n\t<li>How to display the same item, f.ex. Processor load, for a number of hosts on the same graph</li>\r\n\t<li>How to avoid getting crazy from all the slow clicking in the Zabbix UI by using its API</li>\r\n</ul>\r\nI will indicate how it could be done with plain HTTP POST and then show a solution using the Python library for accessing the Zabix API.<br><br>The problem we want to solve is to create a graph that plots the same item for a number of hosts that all are from the same Host group but not all hosts in the group should be included.<br><br><!--more-->\r\n<h2 id=\"EscapingtheZabbixUIpainHowtocreateacombinedgraphforanumberofhostsusingtheZabbixAPI- ZabbixAPI\"> Zabbix API</h2>\r\nZabbix API is a REST API introduced in 1.8 that enables the management of Zabbix resources such as items, triggers, and graphs. The resources are connected together via IDs so you usually need to get a resource by its name, extract its id, and use that to get related resources.<br><br>The <a href=\"https://www.zabbix.com/documentation/1.8/api\" rel=\"nofollow\">API documentation in v1.8</a> is ... lacking so I usually read the <a href=\"https://www.zabbix.com/documentation/2.2/manual/api/reference\" rel=\"nofollow\">v2.2 documentation</a> then check the corresponding page and example in 1.8 and how it will work. The documentation occasionally contains mistakes so don't trust it. (F.ex. <a href=\"https://www.zabbix.com/documentation/1.8/api/item/get\" rel=\"nofollow\">item.get</a>'s <em>filter</em> should be an array but in fact is an object.) It also isn't clear, for get, when fields are ORed and when ANDed and whether you can do anything about it.<br><br>There are multiple libraries for the Zabbix API, I've chosen Python because I like it and the <a href=\"https://github.com/gescheit/scripts/blob/master/zabbix/zabbix_api.py\" rel=\"nofollow\">zabbix_api.py</a> because it seems to be maintained and developed. I had an issue in authorization with it but managed to work around it.\r\n<h3 id=\"EscapingtheZabbixUIpainHowtocreateacombinedgraphforanumberofhostsusingtheZabbixAPI-UsingtheAPI\">Using the API</h3>\r\n<h4 id=\"EscapingtheZabbixUIpainHowtocreateacombinedgraphforanumberofhostsusingtheZabbixAPI-Authenticationauthorization\">Authentication &amp; authorization</h4>\r\nYou usually first authenticate with Zabbix and use the auth token you get from it in all subsequent calls.<br><br><strong>Catch</strong>: Zabbix API must be enabled for the user<br><br>The Zabbix user used for communication with the API must be authorized to use the API (there is a check box for that in Zabbix administration). In our configuration this is off by default and, in our case, users must be added to the Zabbix api group.<br><br>If you do not have access, you will be able to authenticate with the API but other requests will fail with \"No API access\".\r\n<h4 id=\"EscapingtheZabbixUIpainHowtocreateacombinedgraphforanumberofhostsusingtheZabbixAPI-Commongetattributes\">Common get attributes</h4>\r\nThe get requests have some <a href=\"https://www.zabbix.com/documentation/2.2/manual/api/reference_commentary#common_get_method_parameters\" rel=\"nofollow\">common attributes</a> such as\r\n<ul>\r\n\t<li>output = (extend|shorten|refer|...) - how much to include in the output (refer =&gt; only ids, extend =&gt; as much as possible)</li>\r\n\t<li>filter - we will see this below</li>\r\n</ul>\r\n<h2 id=\"EscapingtheZabbixUIpainHowtocreateacombinedgraphforanumberofhostsusingtheZabbixAPI-Implementation\">Implementation</h2>\r\n<h3 id=\"EscapingtheZabbixUIpainHowtocreateacombinedgraphforanumberofhostsusingtheZabbixAPI-CreatingagraphwithHTTPPOST\">Creating a graph with HTTP POST</h3>\r\nYou communicate with the API ny posting JSON to it. The easiset thing is to execute\r\n<div>\r\n<div>\r\n<div>\r\n<div id=\"highlighter_325333\">\r\n<table border=\"0\" cellspacing=\"0\" cellpadding=\"0\">\r\n<tbody>\r\n<tr>\r\n<td>\r\n<div title=\"Hint: double-click to select code\">\r\n<div><code>curl -i -n -X POST --header </code><code>\"Content-Type: application/json\"</code> <code>-d@- https:</code><code>//zabbix.example.com/api_jsonrpc.php</code></div>\r\n</div></td>\r\n</tr>\r\n</tbody>\r\n</table>\r\n</div>\r\n</div>\r\n</div>\r\n</div>\r\nand paste the JSON there, add a new line and press Control-D to finish the input.<br><br>Authenticate with Zabbix:\r\n<div>\r\n<div>\r\n<div>\r\n<div id=\"highlighter_368134\">\r\n<table border=\"0\" cellspacing=\"0\" cellpadding=\"0\">\r\n<tbody>\r\n<tr>\r\n<td>\r\n<div title=\"Hint: double-click to select code\">\r\n<div><code>curl -i -n -X POST --header </code><code>\"Content-Type: application/json\"</code> <code>-d@- https:</code><code>//zabbix.example.com/api_jsonrpc.php</code></div>\r\n<div><code>{</code></div>\r\n<div><code>    </code><code>\"jsonrpc\"</code><code>: </code><code>\"2.0\"</code><code>,</code></div>\r\n<div><code>    </code><code>\"method\"</code><code>: </code><code>\"user.authenticate\"</code><code>,</code></div>\r\n<div><code>    </code><code>\"params\"</code><code>: {</code></div>\r\n<div><code>        </code><code>\"user\"</code><code>: </code><code>\"my zabbix username\"</code><code>,</code></div>\r\n<div><code>        </code><code>\"password\"</code><code>: </code><code>\"my precious\"</code></div>\r\n<div><code>    </code><code>},</code></div>\r\n<div><code>    </code><code>\"auth\"</code><code>: </code><code>null</code><code>,</code></div>\r\n<div><code>    </code><code>\"id\"</code><code>: </code><code>0</code></div>\r\n<div><code>}</code></div>\r\n<div><code>=&gt;</code></div>\r\n<div><code>{</code><code>\"jsonrpc\"</code><code>:</code><code>\"2.0\"</code><code>,</code><code>\"result\"</code><code>:</code><code>\"2dddea29e1d37b9f90069dd129d7a66d\"</code><code>,</code><code>\"id\"</code><code>:</code><code>0</code><code>}</code></div>\r\n</div></td>\r\n</tr>\r\n</tbody>\r\n</table>\r\n</div>\r\n</div>\r\n</div>\r\n</div>\r\n<ul>\r\n\t<li>I believe the value of id isn't important but you need to provide some to get a reasonable response; 0, 1, 2 work fine.</li>\r\n</ul>\r\nGet all items in the Host group Analytics production, using the auth token:\r\n<div>\r\n<div>\r\n<div>\r\n<div id=\"highlighter_921932\">\r\n<table border=\"0\" cellspacing=\"0\" cellpadding=\"0\">\r\n<tbody>\r\n<tr>\r\n<td>\r\n<div title=\"Hint: double-click to select code\">\r\n<div><code>{</code></div>\r\n<div><code>\"jsonrpc\"</code><code>:</code><code>\"2.0\"</code><code>,</code></div>\r\n<div><code>\"method\"</code><code>:</code><code>\"item.get\"</code><code>,</code></div>\r\n<div><code>\"params\"</code><code>:{</code></div>\r\n<div><code>    </code><code>\"output\"</code><code>:</code><code>\"shorten\"</code><code>,</code></div>\r\n<div><code>    </code><code>\"filter\"</code><code>: {</code><code>\"description\"</code><code>: </code><code>\"Processor load15\"</code><code>},</code></div>\r\n<div><code>    </code><code>\"group\"</code><code>: </code><code>\"Analytics production\"</code><code>,</code></div>\r\n<div><code>    </code><code>\"select_hosts\"</code><code>: </code><code>\"extend\"</code><code>,</code></div>\r\n<div><code>    </code><code>\"limit\"</code><code>: </code><code>10</code></div>\r\n<div><code>},</code></div>\r\n<div><code>\"auth\"</code><code>:</code><code>\"2dddea29e1d37b9f90069dd129d7a66d\"</code><code>,</code></div>\r\n<div><code>\"id\"</code><code>:</code><code>2</code></div>\r\n<div><code>}</code></div>\r\n<div><code>=&gt; [{</code><code>\"itemid\"</code><code>:</code><code>\"40002\"</code><code>,</code><code>\"hosts\"</code><code>:[{</code><code>\"maintenances\"</code><code>:[..],</code><code>\"hostid\"</code><code>:</code><code>\"10242\"</code><code>,</code><code>\"proxy_hostid\"</code><code>:</code><code>\"10381\"</code><code>,</code><code>\"host\"</code><code>:</code><code>\"my-server.example.com\"</code><code>,</code><code>\"dns\"</code><code>:</code><code>\"my-server.example.com\"</code><code>,...}]},{</code><code>\"itemid\"</code><code>:</code><code>\"40003\"</code><code>,...</code></div>\r\n</div></td>\r\n</tr>\r\n</tbody>\r\n</table>\r\n</div>\r\n</div>\r\n</div>\r\n</div>\r\nWell, we will skip the rest and go to the real fun - the Python API.\r\n<h3 id=\"EscapingtheZabbixUIpainHowtocreateacombinedgraphforanumberofhostsusingtheZabbixAPI-Creatingagraphwithzabbixapipy\">Creating a graph with zabbix_api.py</h3>\r\nSome notes:\r\n<ol>\r\n\t<li>I had troubles with authorization, I had to specify user &amp; password both in the constructor (for http basic auth. headers) and call the login method to make it work; in theory, only one of these two shall be necessary. (I might have made a mistake somewhere.)</li>\r\n\t<li>There are some advantages over curl such as not needing to specify unimportant attributes such as request id and having automatic mapping between Python lists/dicts and JSON.</li>\r\n</ol>\r\nBefore we show the code, let's see how to use it:\r\n<div>\r\n<div>\r\n<div>\r\n<div id=\"highlighter_238188\">\r\n<table border=\"0\" cellspacing=\"0\" cellpadding=\"0\">\r\n<tbody>\r\n<tr>\r\n<td>\r\n<div title=\"Hint: double-click to select code\">\r\n<div><code>bash$ ipython</code></div>\r\n<div><code>In [</code><code>1</code><code>]: %run create_graph.py</code></div>\r\n<div><code>In [</code><code>2</code><code>]: g = ZabbixGrapher(user=</code><code>\"my zabbix user\"</code><code>, passwd=</code><code>\"my precious\"</code><code>)</code></div>\r\n<div><code>20</code><code>: url: https:</code><code>//zabbix.example.com/api_jsonrpc.php</code></div>\r\n<div><code>20</code><code>: HTTP Auth enabled</code></div>\r\n<div><code>20</code><code>: Sending: {</code><code>\"params\"</code><code>: {</code><code>\"password\"</code><code>: </code><code>\"my precious\"</code><code>, </code><code>\"user\"</code><code>: </code><code>\"my zabbix user\"</code><code>}, </code><code>\"jsonrpc\"</code><code>: </code><code>\"2.0\"</code><code>, </code><code>\"method\"</code><code>: </code><code>\"user.authenticate\"</code><code>, </code><code>\"auth\"</code><code>: </code><code>\"\"</code><code>, </code><code>\"id\"</code><code>: </code><code>0</code><code>}</code></div>\r\n<div><code>20</code><code>: Response Code: </code><code>200</code></div>\r\n<div><code>Logged in, auth: c417623c2d72e0f14ddab044429b80e7</code></div>\r\n<div></div>\r\n<div><code>In [</code><code>3</code><code>]: g.create_graph(</code><code>\"CPU iowait on data nodes(avg1)\"</code><code>, item_key=</code><code>\"system.cpu.util[,iowait,avg1]\"</code><code>, item_descr = None, host_group = </code><code>\"Analytics staging\"</code><code>, hostname_filter_fn = lambda dns: </code><code>\"-data\"</code> <code>in dns)</code></div>\r\n</div></td>\r\n</tr>\r\n</tbody>\r\n</table>\r\n</div>\r\n</div>\r\n</div>\r\n</div>\r\nThe long, scary code itself:\r\n<div>\r\n<div><b>create_graph.py</b></div>\r\n<pre><code>\r\nimport logging\r\nimport sys<br><br>from zabbix_api import ZabbixAPI, ZabbixAPIException<br><br>BOLD = &quot;&#092;&#048;33[1m&quot;\r\nRESET = &quot;&#092;&#048;33[0;0m&quot;<br><br>class Palette:\r\n    last_idx = 0\r\n    colors = [&quot;C04000&quot;, &quot;800000&quot;, &quot;191970&quot;, &quot;3EB489&quot;, &quot;FFDB58&quot;, &quot;000080&quot;,\r\n              &quot;CC7722&quot;, &quot;808000&quot;, &quot;FF7F00&quot;, &quot;002147&quot;, &quot;AEC6CF&quot;, &quot;836953&quot;,\r\n              &quot;CFCFC4&quot;, &quot;77DD77&quot;, &quot;F49AC2&quot;, &quot;FFB347&quot;, &quot;FFD1DC&quot;, &quot;B39EB5&quot;,\r\n              &quot;FF6961&quot;, &quot;CB99C9&quot;, &quot;FDFD96&quot;, &quot;FFE5B4&quot;, &quot;D1E231&quot;, &quot;8E4585&quot;,\r\n              &quot;FF5A36&quot;, &quot;701C1C&quot;, &quot;FF7518&quot;, &quot;69359C&quot;, &quot;E30B5D&quot;, &quot;826644&quot;,\r\n              &quot;FF0000&quot;, &quot;414833&quot;, &quot;65000B&quot;, &quot;002366&quot;, &quot;E0115F&quot;, &quot;B7410E&quot;,\r\n              &quot;FF6700&quot;, &quot;F4C430&quot;, &quot;FF8C69&quot;, &quot;C2B280&quot;, &quot;967117&quot;, &quot;ECD540&quot;,\r\n              &quot;082567&quot;]<br><br>    def next(self):\r\n        self.last_idx = (self.last_idx + 1) % len(self.colors)\r\n        return self.colors[self.last_idx]<br><br>class ZabbixGrapher:<br><br>    def __init__(self, user, passwd, log_level=logging.INFO):<br><br>        try:\r\n            # I had to spec. user+psw here to use Basic http auth to be able\r\n            # to log in even though I supply them to login below;\r\n            # otherwise the call failed with 'Error: HTTP Error 401: Authorization Required'\r\n            self.zapi = ZabbixAPI(\r\n                server=&quot;https://zabbix.example.com&quot;,\r\n                path=&quot;/api_jsonrpc.php&quot;,\r\n                user=user, passwd=passwd,\r\n                log_level=log_level) # or DEBUG<br><br>            # BEWARE: The user must have access to the Zabxi API enabled (be\r\n            # in the Zabbix API user group)\r\n            self.zapi.login(user, passwd)\r\n            print &quot;Logged in, auth: &quot; + self.zapi.auth\r\n        except ZabbixAPIException as e:\r\n            msg = None\r\n            if &quot;&quot; in str(e):\r\n                msg = &quot;Connection to Zabbix timed out, it's likely having temporary problems, retry now or later'&quot;\r\n            else:\r\n                msg = &quot;Error communicating with Zabbix. Please check your authentication, Zabbix availability. Err: &quot; + str(e)<br><br>            print BOLD + &quot;\\n&quot; + msg + RESET\r\n            raise ZabbixAPIException, ZabbixAPIException(msg), sys.exc_info()[2]<br><br>    def create_graph(self,\r\n                     graph_name=&quot;CPU Loads All Data Nodes&quot;,\r\n                     item_descr=&quot;Processor load15&quot;,\r\n                     item_key=None,\r\n                     host_group=&quot;Analytics production&quot;,\r\n                     hostname_filter_fn=lambda dns: &quot;-analytics-prod-data&quot; in dns and (&quot;-analytics-prod-data01&quot; in dns or dns &gt;= &quot;aewa-analytics-prod-data15&quot;),\r\n                     #show_legend = True - has no effect (old Z. version?)\r\n                     ):<br><br>        palette = Palette()\r\n        try:<br><br>            items = self.get_items(item_descr = item_descr, item_key = item_key, host_group = host_group)<br><br>            if not items:\r\n                raise Exception(&quot;No items with (descr=&quot; + str(item_descr) +\r\n                                &quot;, key=&quot; + str(item_key) + &quot;) in the group '&quot; +\r\n                                host_group + &quot;' found&quot;)<br><br>            # Transform into a list of {'host':.., 'itemid':..} pairs,\r\n            # filter out unwanted hosts and sort by host to have a defined order\r\n            item_maps = self.to_host_itemid_pairs(items, hostname_filter_fn)\r\n            item_maps = sorted(\r\n                filter(lambda it: hostname_filter_fn(it['host']), item_maps),\r\n                key = lambda it: it['host'])<br><br>            if not item_maps:\r\n                raise Exception(&quot;All retrieved items filtered out by the filter function; orig. items: &quot; +\r\n                                str(item_maps))<br><br>            # The graph will be created on the 1st item's host:\r\n            graph_host = item_maps[0]['host']<br><br>            ## CREATE GRAPH\r\n            # See https://www.zabbix.com/documentation/2.0/manual/appendix/api/graph/definitions\r\n            graph_items = []<br><br>            for idx, item in enumerate(item_maps):\r\n                graph_items.append({\r\n                        &quot;itemid&quot;: item['itemid'],\r\n                        &quot;color&quot;: palette.next(),\r\n                        &quot;sortorder&quot;: idx\r\n                        })<br><br>            graph = self.zapi.graph.create({\r\n                    &quot;gitems&quot;: graph_items,\r\n                    &quot;name&quot;: graph_name,\r\n                    &quot;width&quot;:900,\r\n                    &quot;height&quot;:200\r\n                    #,&quot;show_legend&quot;: str(int(show_legend))\r\n                    })<br><br>            print &quot;DONE. The graph %s has been created on the node %s: %s.&quot; % (graph_name, graph_host, str(graph))\r\n        except Exception as e:\r\n            msg = None\r\n            if &quot;No API access while sending&quot; in str(e):\r\n                msg = &quot;The user isn't allowed to access the Zabbix API; go to Zabbix administration and enable it (f.ex. add the group API access to the user)'&quot;\r\n            else:\r\n                msg = &quot;Error communicating with Zabbix. Please check your request and whether Zabbix is available. Err: &quot; + str(e)<br><br>            print BOLD + &quot;\\n&quot; + msg + RESET\r\n            raise type(e), type(e)(msg), sys.exc_info()[2]<br><br>    def get_items(self, item_descr = None, item_key = None, host_group = None):\r\n        if not item_descr and not item_key:\r\n            raise ValueError(&quot;Either item_key or item_descr must be provided&quot;)<br><br>        ## GET ITEMS to include in the graph\r\n        # See (Zabbix 2.0 so not 100% relevant but better doc)\r\n        # https://www.zabbix.com/documentation/2.0/manual/appendix/api/item/get\r\n        filters = {}\r\n        if item_descr: filters[&quot;description&quot;] = item_descr\r\n        if item_key: filters[&quot;key_&quot;] = item_key<br><br>        return self.zapi.item.get({\r\n                &quot;output&quot;:&quot;shorten&quot;,\r\n                &quot;filter&quot;: filters,\r\n                &quot;group&quot;: host_group,\r\n                &quot;select_hosts&quot;: &quot;extend&quot;\r\n                })<br><br>    @staticmethod\r\n    def to_host_itemid_pairs(items, hostname_filter_fn):\r\n        # List of (host, itemid) pairs sorted by host\r\n        items_by_host = []<br><br>        for item in items:\r\n            itemid = item['itemid']\r\n            dns = item['hosts'][0]['dns']<br><br>            if hostname_filter_fn(dns):\r\n                items_by_host.append({&quot;host&quot;: dns, &quot;itemid&quot;: itemid})<br><br>        return items_by_host\r\n</code></pre><br><br></div>\r\n<h2 id=\"EscapingtheZabbixUIpainHowtocreateacombinedgraphforanumberofhostsusingtheZabbixAPI-Conclusion\">Other ways</h2>\r\nAs my colleague Markus Krüger has noted:\r\n<blockquote>\r\n<div>You could also use auto registration or auto discovery to add hosts to groups, then extract aggregated data across all hosts in the host group. (Granted, that only works if you want data from <em>all</em> hosts in the group - but if you don't want the data, don't add the host to that group.) That way, no manual work is needed to add monitoring and graphing across multiple instances winking into and out of existence.</div>\r\n<div>Some links:</div>\r\n<div><a href=\"https://www.zabbix.com/documentation/2.0/manual/discovery/auto_registration\" rel=\"nofollow\">Auto registration</a> (2.0 docs, but should be fairly accurate for 1.8.3 as well)</div>\r\n<div><a href=\"https://www.zabbix.com/documentation/1.8/manual/auto-discovery\" rel=\"nofollow\">Auto discovery</a></div>\r\n<div><a href=\"https://www.zabbix.com/documentation/1.8/manual/config/host_groups\" rel=\"nofollow\">Host groups</a></div>\r\n<div><a href=\"https://www.zabbix.com/documentation/1.8/manual/config/items#aggregated_checks\" rel=\"nofollow\">Aggregated checks</a></div>\r\nThat being said, Zabbix is still fairly awkward to work with.</blockquote>\r\nThis makes it possible to get aggregate metrics such as avg, max, min, sum of a metric for the whole host group. Using auto iscovery and auto registration makes it possible to assign hosts to groups automatically.\r\n<h2>Conclusion</h2>\r\nUsing the API is easy and quick, especially with Python. Working the the UI is so slow and painful that I really recommend using the API.<br><br></div>\r\n</div>",
  "excerpt": ""
 },
 {
  "title": "Markdown + JavaScript = Great HTML Presentation Decks",
  "published": "2013-03-24 17:22:28",
  "postType": "post",
  "slug": "/2013/03/24/markdown-javascript-great-html-presentation-decks/",
  "status": "publish",
  "tags": [
   "presentation"
  ],
  "categories": [
   "Tools"
  ],
  "content": "You can easily create beatiful, interactive, simple presentations by writing them in <a href=\"http://daringfireball.net/projects/markdown/\">Markdown</a> (falling back to HTML whenever needed) with special markers separating the individual slides and using JavaScript to render it into an interactive HTML presentation. We will now look at a few tools that can help you with that. My favorite one is Reveal.js that has recently got out-ot-the-box support for full Markdown presentations.<br><br><!--more-->\r\n<h2>Presentation frameworks</h2>\r\n<h3>Reveal.js</h3>\r\n<ul>\r\n\t<li><a href=\"https://github.com/hakimel/reveal.js/\">Reveal.js at GitHub</a>, <a href=\"http://lab.hakim.se/reveal-js/\">live demo</a> introducing many of its features</li>\r\n\t<li>Popular, beautiful, many capabilities</li>\r\n\t<li>PDF export, speaker notes (show on demand or on another device via node.js)</li>\r\n\t<li>The presentation is in HTML but individual slides may contain Markdown (this will result in a number of vertical and/or horizontal slides/sections):\r\n<pre>&lt;section data-markdown&gt;\r\n    &lt;script type=\"text/template\"&gt;\r\n        Markdown body of a slide here ...\r\n    &lt;/script&gt;\r\n&lt;/section&gt;</pre>\r\n</li>\r\n\t<li>Moreover, <a href=\"https://github.com/hakimel/reveal.js/#external-markdown\">the whole presentation may be loaded from a Markdown file</a>:\r\n<pre>&lt;section data-markdown=\"/my_presentation.md\" data-separator=\"^\\n---\\n\" data-vertical=\"^\\n\\n\"&gt;\r\n     Markdown body of a slide here ...\r\n&lt;/section&gt;</pre>\r\n<ul>\r\n\t<li>Beware: Both the index.html and the presentation .md file must be served by the same HTTP server due to security limitations; a simple one likely available on your machine is <code>python -m SimpleHTTPServer</code></li>\r\n\t<li>The two other attributes are optional. <code>---</code> sourrounded by blank lines is the default separator for horizontal slides (none for vertical ones).</li>\r\n</ul>\r\n</li>\r\n\t<li>Code syntax higlighting via <a href=\"http://softwaremaniacs.org/soft/highlight/en/\">highlight.js</a></li>\r\n\t<li>Overview mode (overview over all the slides)</li>\r\n\t<li>You can also create and share Reveal.js presentation online via rvl.io</li>\r\n</ul>\r\n<h3>deck.js</h3>\r\n<ul>\r\n\t<li><a href=\"https://github.com/imakewebthings/deck.js\">deck.js</a>: \"A JavaScript library for building modern HTML presentations\"</li>\r\n\t<li>Markdown supported within slides with the <a href=\"https://github.com/tmbrggmn/deck.js-markdown\">deck.js-markdown</a> extension</li>\r\n\t<li>Similarly to Reveal.js, the presentation is still HTML with <code>&lt;section&gt;...&lt;/section&gt;</code> but the slides content may be Markdown</li>\r\n</ul>\r\n<h3>MarkdownPresenter</h3>\r\n<ul>\r\n\t<li><a href=\"https://github.com/chrishulbert/MarkdownPresenter\">MarkdownPresenter at GitHub</a></li>\r\n\t<li>minimalistic, little older</li>\r\n\t<li>uses showdown.js to transform a standard Markdown document into HTML</li>\r\n\t<li>slides separated by ! surrounded by empty lines</li>\r\n\t<li>move around with &lt;-, -&gt; and reload it (staying on the same slide) with a space (useful during writing)</li>\r\n</ul>\r\n<h3>Slidedown</h3>\r\n<ul>\r\n\t<li>Contary to the other, JS-based frameworks, this tool is written in Ruby and the presentation HTML must be generated from Markdown offline</li>\r\n\t<li>Generate syntax-highlighted slides from Markdown</li>\r\n\t<li><a href=\"http://nakajima.github.com/slidedown/#0\">Slidedown presentation of slidedown</a></li>\r\n\t<li><a href=\"https://github.com/nakajima/slidedown\">slidedown at GitHub</a></li>\r\n\t<li>the whole presentation is in Markdown, slides separated by <code>!SLIDE</code></li>\r\n\t<li>syntax highlighting (put your code between <code>@@@ ruby</code> and <code>@@@</code>)</li>\r\n\t<li>last commit Feb 2012</li>\r\n</ul>\r\n<h2>Tools</h2>\r\n<h3>Showdown.js: Markdown to HTML via JS</h3>\r\n<ul>\r\n\t<li><a href=\"https://github.com/coreyti/showdown\">Showdown at GitHub</a></li>\r\n\t<li><a href=\"http://softwaremaniacs.org/playground/showdown-highlight/\">Try Showdown online</a></li>\r\n\t<li>supports custom extensions (regexp replace, filter callback)</li>\r\n</ul>\r\n<h3>PageDown</h3>\r\n<ul>\r\n\t<li><a href=\"http://code.google.com/p/pagedown/wiki/PageDown\">PageDown</a> is the JavaScript Markdown previewer used at Stack Overflow - renders Markdown into HTML</li>\r\n\t<li>usable on client or server side (with node.js)</li>\r\n\t<li>based on a fork of showdown.js</li>\r\n\t<li>no support for presentation but it could easily be extended via its hooks</li>\r\n</ul>\r\n<h3>Highlight.js: Automatic source code highlighting</h3>\r\n<ul>\r\n\t<li><a href=\"http://softwaremaniacs.org/soft/highlight/en/\">Home page</a></li>\r\n\t<li>\"it works automatically: finds blocks of code, detects a language, highlights it\"</li>\r\n\t<li>2/2013: 54 languages, bundled with 26 style themes</li>\r\n</ul>\r\n<h2>Other resources</h2>\r\n<ul>\r\n\t<li><a href=\"http://www.impressivewebs.com/html-slidedeck-toolkits/\">Roundup of HTML-Based Slide Deck Toolkits</a> - Fathom.js, impress.js, 5lide, Slidedown, deck.js, html5slides (Google HTML5 slide template) and a number of others</li>\r\n</ul>",
  "excerpt": ""
 },
 {
  "title": "Tools for Editor - Browser Integration for Interactive JS/HTML Development",
  "published": "2013-03-25 14:25:52",
  "postType": "post",
  "slug": "/2013/03/25/tools-for-editor-browser-integration-for-interactive-jshtml-development/",
  "status": "publish",
  "tags": [
   "html",
   "JavaScript",
   "productivity",
   "web"
  ],
  "categories": [
   "Tools"
  ],
  "content": "Chrome Development Tools and similar ones are great for interactive, exploratory coding of JavaScript, HTML, and CSS - but the changes aren't persistent and the tools haven't the power of a programmer's editor. I'd like to be able to use a powerful editor yet be able to see changes to JS/HTML/CSS without having to save-[compile]-reload and I want to be able to execute pieces of JS in the context of the browser. Fortunately, there are ways to get at least some of this and it is getting continually better. Let's see what tools we have now.<br><br>These tools usually use either remoting capabilities of the browser or a <a href=\"http://en.wikipedia.org/wiki/Push_technology\">long-polling connection</a> to the web site, sending and executing JavaScript.<br><br><!--more-->\r\n<h2>The Present</h2>\r\n<strong>Update</strong> 4/13: <a href=\"http://www.lighttable.com/\">LightTable</a> seems to <a href=\"http://docs.lighttable.com/#start\">support a lot of live editing</a> stuff (more in <a href=\"http://www.chris-granger.com/2013/04/28/light-table-040/\">a blog post</a>)\r\n<h3>Sublime Web Inspector</h3>\r\n<a href=\"http://sokolovstas.github.com/SublimeWebInspector/\">Sublime Web Inspecto</a>r is a recently released addon for Sublime Text that supports live reload of js/css/less upon save (and maybe even without saving) and enables JS debugging and evaluation of a JS selection. Check out this <a href=\"http://www.youtube.com/watch?feature=player_embedded&amp;v=LaH_43N34Jg\">8 min demo</a> of the reloading and debugging capabilities (I recommend to jump forward when the author is typing).\r\n<h3>Limited but working: Auto-reload with guard and Remote Control</h3>\r\nUsing the Firefox plugin <a href=\"https://addons.mozilla.org/en-US/firefox/addon/remote-control/\">Remote Control</a> and a build tool such as <a href=\"https://github.com/guard/guard\">Guard</a>, a page can be automatically reloaded whenever a js/html/css/... file changes.<br><br>To use:\r\n<ol>\r\n\t<li>Install Guard and the Remote Control Firefox plugin</li>\r\n\t<li>Add the R.C. icon to the Firefox toolbar (View - Toolbars - Customize, find the icon and drag it next to the locatin bar)</li>\r\n\t<li>Start Remote Control - click the icon, it shall turn from red to green</li>\r\n\t<li>(Optional) Test R.C.: <code>telnet localhost 32000</code>, type <code>reload</code> and ENTER, it shall return '{}' and the currently open page shall be reloaded</li>\r\n\t<li>Run Guard to watch for changes: run <code>guard</code> in your project directory with configuration such as this:<pre><code>\r\n# Guardfile\r\nguard 'shell' do\r\n  watch(%r{.*\\.(js|html|css)$}) {|m| `echo &quot;Reloading #{m[0]}&quot;; echo reload | nc -c localhost 32000`}\r\nend\r\n</code></pre></li>\r\n</ol>\r\nHow it works? Guard watches files for changes and whenever one is detected, it sends 'reload' to the port where the Remote Control plugin listens. ('reload' is i shortcut for window.location.reload(); you can send any javascript for execution.)<br><br>You could use any build tool other than Guard as long as it can execute commands when files change, f.ex. the JavaScript-based <a href=\"http://ruudud.github.com/2012/12/22/grunt/\">Grunt</a>.\r\n<h4>Disadvantages</h4>\r\n<ul>\r\n\t<li>The page is reloaded =&gt; all state is lost, plus it might be slow</li>\r\n\t<li>You'd still need to use the Firebug/Chrome dev tool console to experiment with JS, i.e. no support for evaluating snippets of JS in the context of the browser</li>\r\n</ul>\r\n<h3>The LiveReload Chrome Plugin</h3>\r\nThe <a href=\"https://chrome.google.com/webstore/detail/livereload/jnihajbhpnppcggbcgedagnkighmdlei?hl=en\">LiveReload plugin for Chrome</a>:\r\n<blockquote>Provides Chrome browser integration for the official LiveReload apps (Mac &amp; Windows) and third-parties like guard-livereload and yeoman.</blockquote>\r\nI guess you could use it without the <a href=\"http://livereload.com/\">official (commercial) LR apps</a> but I hadn't time to try it.\r\n<h3>Yeoman &amp; Live Reloading</h3>\r\n<a href=\"http://yeoman.io/\">Yeoman</a> is a build and project tool with built-in live preview server and support for LiveReload.<br><br>It's main disadvantage for me was that it required a particular structure of the project.<br><br>In theory it should also be possible to run a custom http server and set up and run <a href=\"http://livereload.com/\">livereload</a> manually to update the browser with your changes on the fly but I fialed to get that setup up when I tried due to problems with LiveReload, which have been fixed since that.\r\n<h3>Emacs-specific Solutions</h3>\r\n<h4>Simple, powerful but buggy: skewer-mode</h4>\r\n<a href=\"https://github.com/skeeto/skewer-mode\">skever-mode</a> tries to achieve the same as swank-js but in pure elisp with a trivial setup. It is possible to evaluate JS in the context of the browser etc. It looks nice but I have encountered some issues:\r\n<ul>\r\n\t<li>It seemed to only work for JS, not for HTML.</li>\r\n\t<li>The built-in server failed to pick up changes to HTML and I haven't found a way to force it to reload them other than restarting Emacs.</li>\r\n</ul>\r\nI guess there is a better way to use it though... .<br><br>Disadvantages: the scripts jQuery and /skewer must be to every page that should support live reloading (though you can use some tricks to insert the dependecies into a page from the browser).\r\n<h4>Powerful but complex to set up: Swank-js</h4>\r\n<a href=\"http://emacsrocks.com/e11.html\">Swank-js</a> is promissing but very complex setup, according to the reports, so I haven't tried it. Also there hasn't been much development lately.\r\n<h2>The Bright Future</h2>\r\n<h3>Future Firefox DevTools: Remote control everything, code-in-browser</h3>\r\nAccording to the post <a href=\"http://paulrouget.com/e/devtoolsnext/\">Future Firefox DevTools</a>, breaing the editor &lt;&gt; browser &lt;&gt; devtools cycle is the number 1 request. The team is exploring mainly two options and that is authoring in the browser with an incorporated editor and making all the dev tools and Firefox controllable from external applications.<br><br>Here is a 1 min demo of editing CSS in SublimeText with the changes being immediately applied to Firefox:<br><br>http://www.youtube.com/watch?feature=player_embedded&amp;v=UrnB8lZnx4I\r\n<h2>Related</h2>\r\n<a href=\"http://blog.kenneth.io/blog/2013/05/21/our-web-development-workflow-is-completely-broken/\">Our web development workflow is completely broken</a> - a good description of the pains of web development, i.e. the large distance between an app in a browser and the JS/LESS/.. files creating it, and a proposal of a better world with good, unified remote debugging tools integrated into our favorite editors\r\n<h2>Help!</h2>\r\nDo you know any other good tools that can enable interactive web development? Let me know!<br><br>(Perhaps <a href=\"https://c9.io/\">Cloud9 IDE</a>?)",
  "excerpt": ""
 },
 {
  "title": "The Value and Perils of Performance Benchmarks in the Wake of TechEmpower''s Web Framework Benchmark",
  "published": "2013-04-01 12:12:35",
  "postType": "post",
  "slug": "/2013/04/01/the-value-and-perils-of-performance-benchmarks-in-the-wake-of-techempowers-web-framework-benchmark/",
  "status": "publish",
  "tags": [
   "benchmark",
   "opinion",
   "performance"
  ],
  "categories": [
   "General",
   "Testing"
  ],
  "content": "The TechEmpower's Web <a href=\"http://www.techempower.com/blog/2013/03/28/framework-benchmarks/\">Framework Benchmark</a> is quite interesting but the <a href=\"https://news.ycombinator.com/item?id=5454775\">comments following it</a> at HackerNews are even more so. That is at least the constructively critical ones that highlight many of the issues with benchmarks while also reminding us of their value. One could formulate the benchmark paradox:<br><br><blockquote>Benchmarks are important for rational technological choices yet it is very hard if not impossible to perform them in a sensible way.</blockquote><br><br>I would like to record here some of the important points, mainly as a future reference for myself for whenever I will be dealing with benchmarking.<br><br><!--more--><br><br><h2>Some background</h2><br><br>The benchmark published by TechEmpower's developers compares the performance of many web frameworks written in different languages and run on two different hardware configurations in three tests: returning a simple, hard-coded JSON, performing a single random select and returning it, and performing an increasing number of selects during a request. They have tried to configure the frameworks for best performance and ask the community to help them tune them (as nobody can know everything). The goal was to establish a \"baseline performance,\" i.e. one from which everything can only get worse; not to assess the performance of the frameworks in general as it is impossible without real use scenarios.<br><br>The <a href=\"https://github.com/TechEmpower/FrameworkBenchmarks\">benchmark and setups are available</a> at GitHub. It might be interesting to check also the <a href=\"https://github.com/TechEmpower/FrameworkBenchmarks/commits/master\">history</a> to see how individual frameworks have been tuned over time based on advice from experts.<br><br><h2>The value and perils of benchmarking</h2><br><br><h3>Key points</h3><br><br><ul>\n    <li>General: Constructive criticism, preferably accompanied by pull requests, is valuable; \"this is bullshit\" comments are not</li>\n    <li>Include other metrics than only peak resp./sec (e.g. latency, max and avg response time from the end-user's point of view)</li>\n    <li>The configuration of the framework, server etc. and the choice of server/... matters, occasionally a lot =&gt; tune for your use cases\n<ul>\n    <li>Details may matter a lot as well - for example whether the JSON ObjectMapper is created only once or for each request anew</li>\n</ul>\n</li>\n    <li>If the difference between the frameworks A nad B is 10ms vs 100ms per request: does it mean that B is ten times slower or that it is  slower by 90 ms? That is a big difference once the request processing itself gets more resource-intensive =&gt; beware (raw performance) stats &amp; conclusions</li>\n    <li>The benchmark is comparing apples with oranges, i.e. rich frameworks such as Play! and raw infrastructural elements such as Netty; be aware of that</li>\n    <li>Raw performance for edge cases (such as returning a hard-coded string) matters little for real-world cases (&lt;=&gt; compare the drop in the scale of the differences between simple response and multiple DB queries)</li>\n    <li>Mean is not enough. There should be also at least standard deviation, preferably also the key percentiles</li>\n    <li>The more realistic test scenario the less we know what we actually measure as the chance for other/invisible influences (confounding) grows rapidly</li>\n</ul><br><br>Me: Asynchronous isn't always better, it has its own overhead when switching the tasks executed by a thread. It is only beneficial if the number of threads is a limiting factor.<br><br><h3>Quotes &amp; comments</h3><br><br><a href=\"https://news.ycombinator.com/item?id=5457033\">bradleyland #1</a>:<br><br><blockquote>I fully respect the JVM family of languages as well. I just think that Mark Twain said it best when he said: \"There are three kinds of lies: lies, damned lies, and statistics.\" It's not that the numbers aren't true, it's that they may not matter as much, and in the way, that we initially perceive them.\n...\nIssue #1) The 30-50x performance difference only exists in a very limited scenario that you're unlikely to encounter in the real world.\n...\nThe error would be in extrapolating that a move to Gemeni or Node.js would give you a 37x or 15x performance increase in your application. To understand why this is an error, we jump down to the \"Database access test (multiple queries)\" benchmark. [JH: the difference in that test was much smaller]\n...\nIssue #2) Performance differences for one task doesn't always correlate proportionally with performance differences for all tasks.</blockquote><br><br><a href=\"https://news.ycombinator.com/item?id=5457180\">bradleyland #2</a>:<br><br><blockquote>In statistics, there exists something called confounding variables. Confounding variables are factors that affect your outcome, but are hidden, or are outside your control. As your example becomes more complex the opportunity for confounding to impact your result goes up significantly\n....\nBasing your choice of framework on speed alone is a pretty bad idea. When you select a framework, you need to optimize for success, and the factors that determine the success of a project are often less related to the speed of a framework and more related to the availability of talent and good tools.</blockquote><br><br><h3>Side note: You need to know statistics for benchmarking</h3><br><br>Zed Shaw has published an excellent rant \"<a href=\"http://zedshaw.com/essays/programmer_stats.html\">Programmers Need To Learn Statistics Or I Will Kill Them All</a>\" pointing out some common errors when doing benchmarking and performance testing:<br><br><ol>\n    <li>Beware of your <a href=\"http://en.wikipedia.org/wiki/Confidence_interval\">confidence level</a> (e.g. 95% =&gt; the true value of the measured metric is with 95% probability within the interval mean+- std.dev.) and calculate the sample size accordingly, beware different sampling strategies (a batch of 1000 vs. 10 batches of 100 experiments). Don't just guesstimate that e.g. 1000 repetitions is enough.</li>\n    <li>An average without a std.dev. is useless (=&gt; consistency of behavior)</li>\n    <li><a href=\"http://en.wikipedia.org/wiki/Confounding\">Confounding</a> (a hidden variable influencing both the variable you control and the one you measure) =&gt; it is impossible to compare two things unless you can either control or account for the influence of all other factors, which you usually can't</li>\n</ol><br><br><h2>Conclusion</h2><br><br>Use benchmarks but be always very cautious about them. Try to benchmark in multiple different ways, using different hardware, different tools. Always also perform performance testing and monitoring on your real application with real scenarios and setup (again preferably in multiple ways) - the results are likely to differ a lot from all benchmarks.<br><br>For a Java app you can start by profiling it using VisualVM's profiler based on thread dump snapshots, then start to track performance at important spots using a <a href=\"/wiki/development/ops-monitoring/#libraries\">performance monitoring library</a> while correlating it with CPU and memory usage.<br><br><h2>See also</h2><br><br><ul>\n    <li>My wiki: <a href=\"/wiki/development/testing/performance-testing-for-webapps-notes/\">Performance Testing for Webapps Notes</a></li>\n    <li>You might enjoy also other <a href=\"/tag/opinion/\">posts on effective development</a>.</li>\n</ul>",
  "excerpt": ""
 },
 {
  "title": "Most interesting links of April ''13",
  "published": "2013-04-30 21:59:29",
  "postType": "post",
  "slug": "/2013/04/30/most-interesting-links-of-april-13/",
  "status": "publish",
  "tags": [
   "agile",
   "bigdata",
   "clojure",
   "human",
   "learning",
   "scrum"
  ],
  "categories": [
   "General",
   "SW development",
   "Testing",
   "Top links of month"
  ],
  "content": "<h2>Recommended Readings</h2>\r\n<h3>The top top article</h3>\r\n<a href=\"http://onstartups.com/tabid/3339/bid/97052/Screw-You-Joel-Spolsky-We-re-Rewriting-It-From-Scratch.aspx\">How To Survive a Ground-Up Rewrite Without Losing Your Sanity</a> (recommended by Kent Beck) - sometimes you need to actually rewrite an important <em>part</em> of a system; here we learn about two such rewrites, one which went well and one that failed badly - and what are the important differences.<br><br>The pain of a rewrite: \"it's [a major rewrite] going to take insanely longer than you expect\" - because: \"there's this endless series of weird crap encoded in the data in surprising ways\" and it takes days to convert them, \"It's brutally hard to reduce scope\" (you cannot drop features, edge cases), \"There turn out to be these other system that use 'your' data\".<br><br>To succeed you need: 1) Determine clear business-visible wins to justify the effort that will be much higher than expected and to know when to give up / what to postpone; 2) Do it extremely incrementally (&lt;-&gt;  <a href=\"http://www.facebook.com/notes/facebook-engineering/software-design-glossary/10150309412413920\" target=\"_blank\">Succession</a>) - break it into a series of small, safe steps, each generating a business value and learning of its own thus enabling early and frequent economical tradeoffs (stop, shift priorities, ...) - ex.: rewrite a single reports, migrate its data, switch customers to it, go on to the next one - complete slice of functionality =&gt; a more realistic estimate soon =&gt; reprioritisation; incrementalism requires you to be able to write data both to the old and new system, which is hard but always pays off: \"Here's what I'm going to say: always insert that dual-write layer. <em>Always</em>. It's a minor, generally somewhat fixed cost that buys you an incredible amount of insurance.\" 3) \"Abandoning the Project Should Always Be on the Table\" (&lt;- known biz value, better estimate based on early feedback).<br><br>Some Specific Tactics: Shrink Ray FTW (a graph of how much has been already replaced =&gt; motivation), Engineer The Living Hell Out Of Your Migration Scripts (tests, robustness, error handling, restartability), If Your Data Doesn't Look Weird, You're Not Looking Hard Enough.\r\n<h3>Methodology, agile, lean</h3>\r\n<ul>\r\n\t<li><a href=\"http://martinfowler.com/articles/newMethodology.html\">M. Fowler: The New Methodology</a> - a good description of the rise of Agile, the motivation for it, the various Agile methodologies (XP, Lean, Scrum etc.) and what is required to be able to apply an agile approach. Main points: Agile is adaptive (vs. predictive) and relies heavily on people and their judgement and skills (vs. treating them as same, replacable units) - which also leads to the need of leadership instead of (command&amp;control) management. Discusses unpredictability of requirements and scope, foolishness of separating design and implementation, difficulty of measurement of SW development, continuous improvement etc. Quotes: \"However letting go of predictability doesn't mean you have to revert to uncontrollable chaos. Instead you need a process that can give you control over an unpredictability. That's what adaptivity is all about.\"</li>\r\n\t<li><a href=\"http://www.reliableplant.com/Read/9818/toyota\">The Toyota concept of 'respect for people'</a> - many state that they respect their workers but fail to really understand what it means; it is not about freedom of act, it is about a mutual respect, leveraging the strengths of each other: worker's experience and insight and manager's broader overview, as demonstrated by the problem-solving dialog and challenges (problem - root cause - solution - measure of success, the manager challenging the worker's answers). Also a nice example how the evaluation of individual performance leads to a much worse system and high turnover compared to a whole-oriented company.</li>\r\n\t<li><a href=\"http://pagilista.blogspot.jp/2013/04/fixed-bid-agile-without-cognative.html\">Fixed Bid Agile Without Cognitive Dissonance</a> - a refreshing take on fixed-scope projects and Agile; yes, they are bad but sometimes the client has no other choice so what best we can make out of it? The core advice: Agree \"a pragmatic change management protocol (along with a contingency built into the pricing)\" (push for lower initial requirements granularity, customer involvement, flexibility of functionality) =&gt; \"you can gain significant agile benefits for clients who wouldn't otherwise accept them\".</li>\r\n\t<li><a href=\"http://agileatlas.org/atlas/scrum\">Agile Atlas: Scrum</a> - a good description of Scrum and its values, roles, artifacts, and activities</li>\r\n</ul>\r\n<h3>Learning, psychology, estimates</h3>\r\n<ul>\r\n\t<li><a href=\"http://www.daedtech.com/how-developers-stop-learning-rise-of-the-expert-beginner\">How Developers Stop Learning: Rise of the Expert Beginner</a> - sometimes you meet people with experience-indicating titles that are actually little competent, perhaps leading incompetent IT departments. Why? They, unchallenged by competent peers or broader IT community, came to believe that they are \"experts\" while actually being only little more advanced beginners, better than their beginner colleagues but still lacking any understanding of the big picture and the knowledge of what they do not know, trapped in the \"<a href=\"http://en.wikipedia.org/wiki/Four_stages_of_competence#The_four_stages\">unconscious incompetence</a>\" stage. The post explains this in a more detail and is followed up an explanation how it can lead to the rise of a mediocre SW group in \"<a href=\"http://www.daedtech.com/how-software-groups-rot-legacy-of-the-expert-beginner\">How Software Groups Rot: Legacy of the Expert Beginner</a>\".</li>\r\n\t<li><a href=\"http://blog.hut8labs.com/coding-fast-and-slow.html\">Coding, Fast and Slow: Developers and the Psychology of Overconfidence</a> (via <a href=\"https://twitter.com/peterskeide\">@peterskeide</a>) - why are we so bad at estimating (inherent complexity of SW vs. our overconfidence) and why it cannot be fixed. We can learn to somehow estimate tasks of few hours length (less complex, plenty of practice opportunities). The question is: \"how you can your dev team generate a ton of value, <em>even though</em> you can not make meaningful long-term estimates?\"</li>\r\n\t<li><a href=\"http://techcrunch.com/2013/04/20/cognitive-overhead/\">Cognitive Overhead, Or Why Your Product Isn’t As Simple As You Think</a> (via <a href=\"https://twitter.com/JiriJerabek\">@JiriJerabek</a>) - to make apps more accessible to users, we try to make them simple - but \"simple\" might be different from what you expect. The important thing is not less steps, less features, less elements, but lower cognitive overhead, i.e. “how many logical connections or jumps your brain has to make in order to understand or contextualize the thing you’re looking at.” Good examples of unexpectadly high / pleasantly low cognitive overhead, some tips, even suprising ones such as make people do more (to be more involved in the process - e.g. bump their phones), slow down your product.</li>\r\n</ul>\r\n<h3>Other</h3>\r\n<ul>\r\n\t<li><a href=\"http://blog.iterate.no/2013/04/18/economies-of-scala/\">Economies of Scala</a> - a case for using Scala over Java, supported by data: many capable developers want to use it but there are few opportunities for them - and getting developers is one of the main challenges.</li>\r\n\t<li><a href=\"http://johannesbrodwall.com/2013/03/08/a-canonical-repository-test/\">A canonical Repository test</a> - a nice standard way to test a \"DAO\"; highlights: use of  <a href=\"https://github.com/alexruiz/fest-assert-2.x\">FEST assert 2</a> for clean and nice checks, no unimportant details in the test (f.ex. details of the test data hidden in randomPerson() and randomOder(Person)).</li>\r\n\t<li><a href=\"http://www.fastcolabs.com/3007862/tracking/how-think-engineer\">How To Think Like An Engineer</a> - some nice ideas such as: \"Build A Simple First Version: With People, Not Code\" - \"Technology is not always the best solution, because technology is not always the simplest solution.\", i.e. don't automate everything from the start (examples from Netflix, Amazon); \"Rather than trying to do everything at once, break down the functions of your company into smaller goals.\" - and focus at one at a time</li>\r\n\t<li><a href=\"http://m.techcrunch.com/2013/04/27/economies-of-scale-as-a-service/\">Economies Of Scale As A Service</a> (do not mix up with Scala! :-))- an interesting description of the trend away from ownership to the rental of important resources (servers, manufacturing capabilities, personal cars, ...) and the resulting changes in the society, business, and industry</li>\r\n\t<li><a href=\"http://www.troyhunt.com/2012/06/our-password-hashing-has-no-clothes.html\">Troy Hunt: Our password hashing has no clothes</a> (or the much shorter though biased <a href=\"http://codahale.com/how-to-safely-store-a-password/\">How To Safely Store A Password</a>) - MD5 and SHA are not safe enough due to brute-force attack enabled by GPUs, irrespective key size; it's crucial to use hashing algorithms designed for passwords (and thus sufficiently slow) - f.ex. <a href=\"http://en.wikipedia.org/wiki/Bcrypt\">bcrypt</a>, <a href=\"http://security.stackexchange.com/a/6415\">or PBKDF2</a> or the newer <a href=\"http://www.tarsnap.com/scrypt.html\">scrypt</a>.</li>\r\n\t<li><a href=\"http://www.techempower.com/blog/2013/03/26/everything-about-java-8/\">Everything about Java 8</a> - a well-made summary of what should come in Java 8, based on the current state, discussing the finer points: static and default (non-static, overridable) methods on interfaces, lambdas (do I need to mentione that?!) and method references (String::valueOf, Object::toString, myVar::toString, ArrayList::new); good discussion of the various use cases and limitations of lambdas (capturing x non-c., ..); java.util.stream for functional operations on value streams (filter, map, reduce etc.); java.time inspired by Joda, more concurrency utilities (e.g. CompletableFuture for chaining futures); String.join (finally!), <a href=\"http://javadocs.techempower.com/jdk18/api/java/util/Optional.html\">Optional</a> ~ Scala's Option &amp; more; yummy!</li>\r\n\t<li><a href=\"http://www.daedtech.com/how-to-keep-your-best-programmers\">How To Keep Your Best Programmers</a> - what motivates capable programmers to stay/leave? The author lists some common reasons and concludes that, ultimately, all are linked to the desire <a href=\"http://www.youtube.com/watch?v=u6XAPnuFjJc\">for autonomy, mastery, or purpose</a>. However he goes further and proposes that, to keep talented devs, you must offer them an appealing narrative (regarding their actions and a result, related to autonomy/mastery/purpose) and reaffirm/update it frequently; ex.: “With the work that we’re giving you over the next few months, you’re going to become the foremost NoSQL expert in our organization.” \"At any point, both you and the developers on your team should know their narratives.\" - so that they will be \"constant points of job satisfaction and purpose.\"</li>\r\n</ul>\r\n<h2>Clojure Corner</h2>\r\n<ul>\r\n\t<li><a href=\"http://yogthos.net/blog/44\">Clojure Data Analysis Cookbook review</a> - \"<a href=\"http://www.packtpub.com/clojure-data-analysis-cookbook/book\">The book</a> provides a collection of recipes for accomplishing common tasks associated with analyzing different types of data sets. It starts out by showing how to read data from a variety of sources such as JSON, CSV, and JDBC. [..] how to sanitize the collected data and sample large data sets. [..] a number of different strategies for processing it.\" How to present them with ClojureScript and  <a href=\"http://nvd3.org/\">NVD3</a> (D3.js components). \"Some of the highlights include using the Clojure STM, parallel processing of the data, including useful tricks for partitioning, using <a href=\"http://clojure.com/blog/2012/05/08/reducers-a-library-and-model-for-collection-processing.html\">reducers</a>, and distributed processing with Hadoop and Casalog.\"</li>\r\n</ul>\r\n<h2>Favorite Quotes</h2>\r\n<blockquote>once again, trying to do it *and* do it right was too much all at once, resulting in little progress and little learning.<br><br><em>- Kent Beck's <a href=\"https://twitter.com/KentBeck/status/323902105834360833\">tweet 2013-04-16</a></em></blockquote>\r\nA true agile development process can be recognized by its continual evolution:\r\n<blockquote>A project that begins using an adaptive process won't have the same process a year later. Over time, the team will find what works for them, and alter the process to fit.<br><br><em>- Martin Fowler in <a href=\"http://martinfowler.com/articles/newMethodology.html\">The New Methodology</a>\r\n</em></blockquote>",
  "excerpt": ""
 },
 {
  "title": "Book Review & Digest: Boyd: The Fighter Pilot Who Changed the Art of War (Relevant for IT/Business)",
  "published": "2013-04-29 20:41:14",
  "postType": "post",
  "slug": "/2013/04/29/book-review-digest-boyd-the-fighter-pilot-who-changed-the-art-of-war-relevant-for-itbusiness/",
  "status": "publish",
  "tags": [
   "book"
  ],
  "categories": [
   "General"
  ],
  "content": "<a href=\"http://www.amazon.com/Boyd-Fighter-Pilot-Who-Changed/dp/0316796883/\">This book</a> is about a great person, about change, about one of the largest bureaucracies and dysfunctional organizations, about projects gone astray, about warfare and its latest evolution. Many of the challenges and ideas that we encounter in the book are not limited to the military domain but <a href=\"www.amazon.com/Certain-Win-Strategy-Applied-Business/dp/1413453767/\">apply also to business</a> and IT. It is worth reading whether you are  a military person, somebody trying to push through a change, a business person, or interested in thinking and organizations.<br><br><!--more-->\r\n<h2>Highlights</h2>\r\n<a href=\"http://en.wikipedia.org/wiki/John_Boyd_(military_strategist)\">John R. Boyd</a> was a fascinating person. He changed aerial fight by replacing gut feelings with tactics, maneuvers and contra-maneuvrs. He developed a theory that dramatically changed how fighter airplanes are designed and - against the will of Pentagon - designed the best fighter til the time, F16. Not stopping there, he revived Sun Tzu's thinking and introduced maneuver warfare, relying on agility, deception, and quick thinking, to replace the attrition warfare with its massive, force-aginst-force battles. Once again, against the will of many generals, maneuver warfare made its way through and saw its stellar moment in the Gulf War, reportedly under Boyds direct influence.<br><br>Boyd with his colleagues have brought about many changes and had to fight hard against Pentagon's resistance to change, so typical of large bureaucratic organizations. They both won and lost many battles, sacrificing their careers to be able to do something meaningful. There is a lot we can learn from this - often seemingly irrational and absurd - resistance to change and the successes and failures of the Boyd cabal in the fight.<br><br>It's also highly interesting to read about the absurdities and dysfunction of Pentagon and the military, especially with respect to the rejection of innovative thinking, absurd budgeting and weapon-acquisition projects, and a social organization that bolsters careerism and eliminates deviations. It's tragic and fascinating to read about the weapon acquisition and design projects that lead to exploded budgets, gold-plating resulting in airplanes that should do everything but suck in all of it, and ultimately the production of weapons that make generals and the military industry happy but that the soldiers using them would never buy. The American military as presented is quite dysfunctional in the sense that there are many interests detrimental to its primary goal of effective national defense. Personal interests, internal politics with the goal of securing higher budget than other departments, fear of change. (I'm afraid it is quite similar in our army, from the bits I have heard.)<br><br>As one reader <a href=\"http://www.amazon.com/review/R2YT33FKBMVMAJ/ref=cm_cr_dp_title?ie=UTF8&amp;ASIN=0316796883&amp;nodeID=283155&amp;store=books\">writes</a>:\r\n<blockquote>[..] this book can be regarded as an excellent case study of the pathology of bureaucracy [..]</blockquote>\r\nNoteworthy: Ideas of maneuver warfare applicable to the business too (-&gt; books): learn &amp; react faster; communicate the mission and empower teams to proceed toward it independently, using their situational knowledge.\r\n<h2>Reflections</h2>\r\nA number of points from the book is applicable more broadly and also specifically to business and projects.<br><br>One thing that really stroke me is that he not only was good at what he did (fighter pilot) but also though about it extensively. I believe that we should think more about what and how we do.<br><br>The philosophy of maneuver warfare - learn quickly, decide based on the current situation rather than following a plan, communicate the objective and let the workers figure out the best way to achieve it rather than micro-managing them, build effective, independent teams.<br><br>The military projects are not dissimilar to some business projects - project goals out of touch with reality, many stakeholders resulting in compromise solutions good for nothing, serious and deliberate underestimation of risks and costs.<br><br>Similarly, the dysfunction of the military organization, its internal political fights, resistance to change, lack of unity, shared values and goals has parallels in big organizations in all other domains.<br><br>The military seems to be the antithesis of agile and lean organization and is therefore worth studying.<br><br>One of the really inspirational sides of this story is that it shows us that a single person can change the world - with some talent, luck, good friends, and hard work.\r\n<h2>Appendix</h2>\r\n<h3>Quotes</h3>\r\n<blockquote>As Boyd later explained, \"You gotta challenge all assumptions. If you don't, what is doctrine on day one becomes dogma forever after.\"<br><br>A commander can use this temporal discrepancy (a form of fast transient) to select the <em>least-expected</em> action rather than what is predicted to be the <em>most-effective</em> action. The enemy can also figure out what might be the most effective. To take the least-expected action disorients the enemy. It causes him to pause, to wonder, to question. This means that as the commander compresses his own time, he causes time to be stretched out for his opponent. The enemy falls farther and farther behind in making relevant decisions.<br><br>To attack the mind of the opponent, to unravel the commander before a battle even begins, is the essence of fighting smart.<br><br>[..] The Japanese Art of War, [..] talks of \"swordlessness,\" or the ability to defend oneself without a weapon, a concept that by implication means using the enemy's weapon against him. Cleary says this technique can be used in debate, negotiations, and all other forms of competition. He says sworlessness is the \"crowning achievement of the warrior's way.\"<br><br>\"There is not just one solution to a problem,\" he said. \"There are two or three or five ways to solve a problem. Never commit to a single solution.\"<br><br>He [Chet Richards] later went to work for Lockheed and began studying the fabled Toyota production system, which he found \"frighteningly familiar\" from his study of maneuver conflict. [..] The underlying ideas of mutual trust, mission orders, and individual responsibility, and the concepts of \"harmony\" and \"flow\" and - most of all - the manipulation of time as a production tool were central ideas both in the Toyota system and the strategy of maneuver conflict.<br><br>Boyd put it more succinctly: \"You can't change big bureaucracies until they have a disaster.\"</blockquote>\r\n<h3>Various Highlights</h3>\r\n<ul>\r\n\t<li>prior to F16, Soviet airplanes were in general better than the American ones</li>\r\n\t<li>gold-plating: deterioration of the original winning F16 prototype (YF16): bomb holders etc. =&gt; more weight =&gt; more fuel =&gt; bigger wings =&gt; less maneuverability</li>\r\n\t<li>the horrors of politics (Navy picking the losing prototype of F16, Airforce x Navy forcing its plane on each other, ...); dysfunction: \"Your worst enemy is not the communist SSSR but a colonel from another branch of the military that seeks to get higher budget at your expense.\"</li>\r\n\t<li>know the ways of the bureaucracy to be able to defeat it, \"do your homework\"</li>\r\n\t<li>projects: over-optimistic numbers, generals &amp; industry knowing and cooperating to get budget from the politicians - highly understated budget, costs, time</li>\r\n\t<li>denial of risks, weaknesses, and costs of weapons (B-1 bomber, the armored vehicle, missiles)</li>\r\n\t<li>there seems to be no responsibility or retrospective when projects fail terribly to deliver what was promised and in budget</li>\r\n\t<li>creative thinking requires destructive deduction (destructure the existing concepts) and constructive synthesis (combine the elements in a new way)</li>\r\n\t<li>attrition (force-based) warfare reminds me of the attempts to save projects by throwing more people and money at them</li>\r\n\t<li>as mentioned before, the change of bureaucracy (or organization/cultures in general) is hard, despite logic, evidence, benefits (see the case of Dr. Semmelweis that discovered that if doctors wash hands prior to helping with birth, they can drastically reduce mortality in the hospital - yet was, despite the facts, rejected and ignored http://en.wikipedia.org/wiki/Ignaz_Semmelweis)</li>\r\n</ul>",
  "excerpt": ""
 },
 {
  "title": "Most interesting links of May ''13",
  "published": "2013-05-31 21:59:35",
  "postType": "post",
  "slug": "/2013/05/31/most-interesting-links-of-may-13/",
  "status": "publish",
  "tags": [
   "clojure",
   "failure",
   "leanstartup",
   "security",
   "skills",
   "tdd",
   "trends"
  ],
  "categories": [
   "General",
   "SW development",
   "Tools",
   "Top links of month"
  ],
  "content": "<h2>Recommended Readings</h2>\r\n<ul>\r\n\t<li><a href=\"http://www.thoughtworks.com/radar\">ThoughWorks Technology Radar May 2013</a> - Maven replaced by Gradle, Clojure and Scala on adopt, big enterprise SW and WS-* out, lot of interesting stuff to adopt or assess</li>\r\n\t<li><a href=\"http://codemanship.co.uk/parlezuml/blog/?postid=1170\">Straw Man TDD: debunking 6 common TDD myths</a> (via M.Fowler) - such as TDD = {no upfront design, 2*longer development, # hard-to-change test code}.</li>\r\n\t<li><a href=\"http://sijinjoseph.com/programmer-competency-matrix/\">Programmer Competency Matrix</a> - a nice overview of a programmer needs to know in different areas (computer science: data structures etc., SW engineering: SCM etc., programming: defensive coding, IDE etc.) + what experience and knowledge they need, split into 4 levels. Where are you?</li>\r\n\t<li><a href=\"http://www.dzone.com/articles/12-most-destructive\">The 12 most disruptive technologies</a> of the next 10 years according to McKinsey - 1. mobile internet, 2. automation of knowledge work, 3. internt of things, 4. cloud, 5. advanced robotics, 6. [near-]autonomous vehicles, 7. next-generation genomics, 8. energy storage, 9. 3D printing, 10. advanced materials, ...; the <a href=\"http://www.slideshare.net/adigaskell/mgi-disruptive-technologiesfullreportmay20131?ref=http://www.dzone.com/articles/12-most-destructive\">full 178 page report</a>.</li>\r\n\t<li><a href=\"http://architects.dzone.com/articles/your-login-form-posts-https\">Your login form posts to HTTPS, but you blew it when you loaded it over HTTP</a> - summary: without https, anybody between the server and the client can inject anything (e.g. a key logger) into the web page; exploit example</li>\r\n\t<li><a href=\"http://news.ncsu.edu/releases/wms-murphyhill-age-2013/\">Older Is Wiser: Study Shows Software Developers’ Skills Improve Over Time</a> (from an analysis of StackOverflow)- and older developers have much broader skill set and know about subjects</li>\r\n</ul>\r\nAgile\r\n<ul>\r\n\t<li><a href=\"http://news.slashdot.org/story/13/05/25/139218/worlds-biggest-agile-software-project-close-to-failure\">Discussion: World's Biggest 'Agile' Software Project Close To Failure</a> - what is/isn't agile, agile vs. waterfall etc; a nice collection of all the possible opinions and misunderstandings. Some of my favorites: <a href=\"http://news.slashdot.org/comments.pl?sid=3785177&amp;cid=43822773\">waste</a>: '<em>[..]An \"agile\" project cannot fail and cost Billions because it must always deliver runnable software with a maximum of a few weeks delay</em>[..]' (runnable = delivering value), <a href=\"http://news.slashdot.org/comments.pl?sid=3785177&amp;cid=43822535\">separation</a>: '<em>[..] my experience has been that separating the designer/architect role from the developer role is fraught with pitfalls. The people writing the code should be the ones designing it, [..]</em>', <a href=\"http://news.slashdot.org/comments.pl?sid=3785177&amp;cid=43821273\">stability</a>: '<em>[..] On the successful projects that I've worked with in Agile, there's strong stakeholders, good architecture keeping the vision in place and project management that keeps things well orchestrated. Without those in the mix, it'll fail just like all software projects. [..]</em>', <a href=\"http://news.slashdot.org/comments.pl?sid=3785177&amp;cid=43822061\">waterfall success</a>, <a href=\"http://news.slashdot.org/comments.pl?sid=3785177&amp;cid=43822585\">people issue</a>: '<em><em></em>The problem here isn't waterfall/agile. The problem here isn't .Net/Linux. The problem here is the parties involved. [politicians and IT dinosaurs]</em>' (learn what's needed from drunk, bitching employees; ignore official nonsense requirements),: <a href=\"http://news.slashdot.org/comments.pl?sid=3785177&amp;cid=43826395\">simplicity</a> '<em>[..] It would probably be a lot easier if they started by making a simpler tool - instead of trying to calculate everybody's entitlements everywhere [..]</em>', <a href=\"http://news.slashdot.org/comments.pl?sid=3785177&amp;cid=43825093\">agile suitability</a>: '<em>[..] You cannot use Agile to build a 100-mile canal, as the whole thing would be useless even if you completed 99 miles. [..]</em>'.\r\nSome people seem to believe that agile means no architecture and no/too little planning. Some believe that agile = hack now, fix later.</li>\r\n</ul>\r\nStartups etc.\r\n<ul>\r\n\t<li><a href=\"http://adii.me/scaleability-on-day-1\">Why do we worry about scaleability on Day 1?</a> (via @simenfur) -  you can fake/do many things manually to get started to validate your service and eventually to provide it to real, paying customers without lot of features/automation that you might believe to be essential; many real-world examples of this. <a href=\"http://42floors.com/blog/manual-scaling\">Quoting 42Floors</a>: “In fact, when you look at each aspect of our operations, you will find a fairly sophisticated manual operations process predating every piece of technology that we’ve built.” Buffer <a href=\"http://joel.is/post/46894258442/5-things-that-seem-essential-that-we-launched-buffer\">launched a business without 5 seemingly essential ingredients</a>, f.ex. upgrade from a free to paid account. ... Try the <a href=\"http://benogle.com/2013/03/25/an-idea-for-non-technical-founders-service-first-business.html\">“service-first” approach</a>!</li>\r\n\t<li><a href=\"http://www.whiteboardmag.com/confessions-of-a-lean-startup-how-i-got-my-first-customers-without-having-a-product/\">Confessions of a lean startup: how I got my first customers without having a product</a> (in 7 weeks) - an interesting story of verifying that an idea is worht pursuing by getting paying customers before there was any product (doing it manually for them), the tools and approaches to use and mistakes to avoid (attract people - signups - interviews &amp; pitches - paying customers - development)</li>\r\n</ul>\r\n<h2>Clojure Corner</h2>\r\n<ul>\r\n\t<li>B. Batsov's <a href=\"https://github.com/bbatsov/clojure-style-guide#readme\">Clojure Style Guide</a> (based on JoC etc.) at GitHub</li>\r\n\t<li><a href=\"http://codequarterly.com/2011/rich-hickey/\">Code quaterly interview with R. Hickey</a> (2011) - motivation behind Clojure (simplicity,..), reusability in C. (vs. Java); many valuable things</li>\r\n\t<li><a href=\"http://corfield.org/blog/post.cfm/clojure-in-the-enterprise\">Clojure in the Enterprise?</a> - about the differences between the Clojure and the enterprise java  (with heavy frameworks such as JPA, JSF, mutable state) ways and difficulties of introducing Clojure due to old-fashioned thinking, limited skills, etc. \"<em>Take away objects, mutable state, variables, loops... a lot of Java developers are immediately all at sea and have no idea how to solve even basic problems. They'll try to bend Clojure to their OOP way of thinking and they'll most likely fail.</em>\"\r\nWorld Singles' experience with Clojure: \"<em>We love Clojure. It's made development a lot more fun. We're able to solve harder problems, make changes faster, leverage multi-core concurrency more effectively, and we have a much smaller code base to maintain.</em>\"</li>\r\n\t<li><a href=\"http://blog.8thlight.com/colin-jones/2013/05/21/extract_temp_to_query.html\">Replace Temp with Query in Clojure</a> - in this post we can follow an interesting refactoring from a deeply nested if &amp; let code to a much flatter one (featuring <em>cond</em> to test multiple conditions (instead of guard conditions used in imperative languages) <em><a href=\"http://clojuredocs.org/clojure_core/clojure.core/delay\">delay</a></em> to be ably to bind an expression to a local variable without evaluating it yet)</li>\r\n\t<li><a href=\"http://nightweb.net/blog/clojure-on-android.html\">The Why and How of Clojure on Android</a> (4/2013) - about the experience of using Clojure on Android, which is little slow and crazy but fun. From the author of the <a href=\"https://play.google.com/store/apps/details?id=net.nightweb\">Nightweb</a> app. Key components:  <a href=\"https://github.com/sattvik/neko\">neko</a> Clojure wrappers for Android and for <a href=\"https://github.com/alexander-yakushev/lein-droid\">lein-droid</a> building w/o an IDE. <a href=\"http://clojure-android.blogspot.no/2012/07/on-ui-stuff-asynchronousity-and-power.html\">Nicer than Java</a>! (This GSoC proposal shows the <a href=\"http://clojure-android.blogspot.no/2013/06/gsoc-2013-proposal.html\">limitations/future of neko.</a>)</li>\r\n\t<li><a href=\"http://ecmendenhall.github.io/blog/blog/2013/05/27/learning-clojure-macros-with-speclj/\">Reconstructing Clojure Macros With Speclj</a> - a good idea to learn macros by trying to create one's own implementation of existing Clojure macros, driven by tests that define the expected behavior of the macro (using macroexpand, macroexpand-1, macroexpand-all)</li>\r\n\t<li><a href=\"http://ianeslick.com/2013/05/24/advanced-inspector-middleware-for-clojure-nrepl/\">Advanced inspector middleware for Clojure nREPL</a> and Emacs (<a href=\"https://github.com/vitalreactor/nrepl-inspect\">nrepl-inspector on GitHub</a>) - C-c C-i or nrepl-inspect to inspect interactively the value of a var (beware: (require 'nrepl-inspect) fails, however calling nrepl-inspect as a function is ok). Related: <a href=\"http://ianeslick.com/2013/05/17/clojure-debugging-13-emacs-nrepl-and-ritz/\">Clojure Debugging ’13: Emacs, nREPL, and Ritz</a> (May 17th) - what works, what is missing, how to set up</li>\r\n\t<li>Pithering About » <a href=\"http://www.pitheringabout.com/?p=937\">REPL bootstrap pimpage</a> - neat tricks with a custom bootstrap REPL namespace - print last few commits and git branch, pre-loading common libs</li>\r\n</ul>\r\n<h2>Tools</h2>\r\n<ul>\r\n\t<li><a href=\"http://fishshell.com/\">Fish Shell</a> 2.0 finally released (among others adding the ability to set the title of iTerm tabs properly); <a href=\"http://ridiculousfish.com/shell/release_notes.html\">release notes</a>, <a href=\"http://ascii.io/a/3213\">1m demo of some coolness</a></li>\r\n</ul>\r\n<h2>Favorite Quotes</h2>\r\n<blockquote>C, C#, and Java:\r\nApplying some of the best ideas of the 1970s to the problems of today.<br><br><em>- Stuart Halloway in <a href=\"http://www.infoq.com/presentations/Clojure-tips\">Clojure in the Field</a>, 2013 (slide 6)\r\n</em></blockquote>",
  "excerpt": ""
 },
 {
  "title": "Becoming A Better Programmer Through The Study of Good And Bad Code & Design",
  "published": "2013-05-19 09:22:59",
  "postType": "post",
  "slug": "/2013/05/19/becoming-a-better-programmer-through-the-study-of-good-and-bad-code-design/",
  "status": "publish",
  "tags": [
   "learning"
  ],
  "categories": [
   "General"
  ],
  "content": "Reading books about good design and good coding practices such as Clean Code is very helpful but it isn't enough to become a good programmer. We need to see both good and bad code in practice, perhaps many times, to start to really understand and appreciate the principles and qualities of clean/good code. (And, of course, we must write code.) However our chances of encountering a noteworthy good or bad piece of code and realizing its qualities (or lack thereof) are limited and highly dependant on the project and people we work with. In an attempt to increase the chances and help other - especially junior - developers to encounter and evaluate more interesting pieces of code, I have started a new blog, <a href=\"http://wondersofcode.wordpress.com/\">Wonders of Code</a>. When I encounter a code snippet lacking in some qualities, I re-implement it in a better way and publish both together with an analysis of their pros and cons and relating those to the  principles of readability, maintainability, and clean code in general.<br><br>This is an experiment and I hope to hear from the community if this is something that can really help people or not. I would also love to get contributions from other developers, to cover a broader range of opinions and examples. Comments and contributions are welcomed and appreciated!<br><br><!--more-->\r\nI should add that criticizing others' code is a rather arrogant activity. I am certainly not a master of clean code and do not write perfect code myself. I try to approach every source code from the perspective that it is the best code the given developer could have created under the particular circumstances (time, knowledge, etc.) and that essentially any code can be improved upon. So we usually can't really blame the author for the lack of some qualities and the lack of perfection. Additionally, quality is, into a certain extent, in the eye of the beholder. Programming, as everything else, is about compromises between various forces and these compromises differ based on experience and preferences. We can't always say that one is better than another. But I believe that it is still valuable to analyze and try to improve upon a piece of source code, however relative my particular values and preferences are, and that it can help others form their understanding, opinion, and critical thinking.<br><br>Now please head for <a href=\"http://wondersofcode.wordpress.com/\">Wonders of Code</a>, read the examples already there, comment, contribute! Thank you.",
  "excerpt": ""
 },
 {
  "title": "Lesson Learned: Don''t Use Low-Level Lib To Test High-Level Code",
  "published": "2013-05-20 22:10:38",
  "postType": "post",
  "slug": "/2013/05/21/lesson-learned-dont-use-low-level-lib-to-test-high-level-code/",
  "status": "publish",
  "tags": [
   "clojure",
   "design",
   "slicing"
  ],
  "categories": [
   "Testing"
  ],
  "content": "<strong>Summary</strong>: Using a fake http library to test logic two levels above HTTP is unnecessarily complex and hard to understand. Fake instead the layer directly below the logic you want to test and verify the low-level HTTP interaction separately. In general: Create thin horizontal slices for unit testing, checking each slice separately with nicely focused and clear unit tests. Then create a coarse-grained vertical (integration-like) test to test across the slices.<br><br>The case: I want to test that the method <em>login</em> sends the right parameters and transforms the result as expected. <em>Login</em> invokes <em>post-raw</em> which calls an HTTP method. Originally I have tried to test it by using the library <a href=\"https://github.com/myfreeweb/clj-http-fake#readme\">clj-http-fake</a> but it proved to be unnecessarily complex. It would be much better to fake <em>post-raw</em> itself for testing <em>login</em> and test the original <em>post-raw</em> and its HTTP interaction separately, using that library.<br><br><!--more-->There are two problems with using the low-level clj-http-fake library for testing the login function:\r\n<ol>\r\n\t<li>Both the calls I need to make need to be wrapped in its <em>with-fake-routes</em>, which makes the test more complex.</li>\r\n\t<li>More seriously, I need to drop down from the level of Clojure data structures to JSON encoded as a String. The transformations between the two would pollute the test and be meaningless from the point of view of what I want to test.</li>\r\n</ol>\r\nSolution: Run instead <em>login</em> with a fake version of <em>post-raw</em> and, if desirable, test <em>post-raw</em> with clj-http-fake separately.<br><br>Pseudocode:<br><br><pre><code>\r\n// &quot;Business&quot; logic\r\nfunction login(..)\r\n   authorizationToken = post-raw(...)\r\n   return (new function derived from post-raw with some parameters such as auth.token bound)<br><br>// Test\r\n...\r\nfake post-raw(request) to return &quot;my-authorization-token&quot;\r\nvar post-authenticated = login(..)\r\nassert post-authenticated is function\r\nfake post-raw(request) to return request\r\nassert post-authenticated(dummy-values) = {dummy-values + the auth. params}\r\n// Testing post-raw isn't important now\r\n</code></pre><br><br>See the <a href=\"https://github.com/jakubholynet/clj-zabbix-api\">clj-zabbix-api</a>'s <a href=\"https://github.com/jakubholynet/clj-zabbix-api/blob/faa0775bca674dbc064326995ab3aa5cf6bdee4b/test/clj_zabbix_api/core_test.clj\">core_test.clj</a> for the full Clojure test and <a href=\"https://github.com/jakubholynet/clj-zabbix-api/blob/faa0775bca674dbc064326995ab3aa5cf6bdee4b/src/clj_zabbix_api/core.clj\">core.clj</a> for the code. Disclaimer: It is not very good Clojure code. I am just learning :-)",
  "excerpt": ""
 },
 {
  "title": "Accessing An Artifact''s Maven And SCM Versions At Runtime",
  "published": "2013-05-22 15:47:05",
  "postType": "post",
  "slug": "/2013/05/22/accessing-an-artifacts-maven-and-scm-versions-at-runtime/",
  "status": "publish",
  "tags": [
   "Maven"
  ],
  "categories": [
   "Tools"
  ],
  "content": "You can easily tell Maven to <a href=\"http://maven.apache.org/shared/maven-archiver/examples/manifest.html#Adding_Implementation_And_Specification_Details\">include the version</a> of the artifact and its Git/SVN/... revision in the JAR manifest file and then access that information at runtime via getClass().getPackage.<a href=\"http://docs.oracle.com/javase/6/docs/api/java/lang/Package.html#getImplementationVersion%28%29\">getImplementationVersion()</a>.<br><br>(All credit goes to Markus Krüger and other colleagues.)<br><br><!--more--><br><br><h2>Include Maven artifact version in the manifest</h2><br><br>(Note: You will actually not want to use it, if you also want to include a SCM revision; see below.)<br><br>pom.xml:<br><br>https://gist.github.com/holyjak/5628583<br><br>The resulting MANIFEST.MF of the JAR file will then include the following entries, with values from the indicated properties:<br><br><pre><code>Built-By: ${user.name}\r\nBuild-Jdk: ${java.version}\r\nSpecification-Title: ${project.name}\r\nSpecification-Version: ${project.version}\r\nSpecification-Vendor: ${project.organization.name\r\nImplementation-Title: ${project.name}\r\nImplementation-Version: ${project.version}\r\nImplementation-Vendor-Id: ${project.groupId}\r\nImplementation-Vendor: ${project.organization.name}\r\n</code></pre><br><br>(Specification-Vendor and Implementation-Vendor come from the POM's organization/name.)<br><br><h2>Include SCM revision</h2><br><br>For this you can either use the <a href=\"http://mojo.codehaus.org/buildnumber-maven-plugin/\" rel=\"nofollow\">Build Number Maven plugin</a> that produces the property ${buildNumber}, or retrieve it from <a href=\"https://wiki.jenkins-ci.org/display/JENKINS/Building+a+software+project#Buildingasoftwareproject-JenkinsSetEnvironmentVariables\" rel=\"nofollow\">environment variables passed by Jenkins</a> or Hudson (SVN_REVISION for Subversion, GIT_COMMIT for Git).<br><br>For git alone, you could also use the <a href=\"https://github.com/ktoso/maven-git-commit-id-plugin\">maven-git-commit-id-plugin</a> that can either replace strings such as ${git.commit.id} in existing resource files (using maven's resource filtering, which you must enable) with the actual values or output all of them into a git.properties file.<br><br>Let's use the buildnumber-maven-plugin and create the manifest entries explicitely, containing the build number (i.e. revision)<br><br>https://gist.github.com/holyjak/5628612<br><br><h2>Accessing the version &amp; revision</h2><br><br>As mentioned above, you can access the manifest entries from your code via <a href=\"http://docs.oracle.com/javase/6/docs/api/java/lang/Package.html#getImplementationVersion%28%29\">getClass().getPackage.getImplementationVersion()</a> and <a href=\"http://docs.oracle.com/javase/6/docs/api/java/lang/Package.html#getImplementationTitle%28%29\">getClass().getPackage.getImplementationTitle()</a>.<br><br><h2>Pitfalls</h2><br><br>According to <a href=\"http://stackoverflow.com/questions/2712970/how-to-get-maven-artifact-version-at-runtime/2713013#comment19760527_2713013\">some reports</a> (), OpenJDK doesn't read the implementation version etc. attributes from a manifest. I have tried with OpenJDK 6 and 7 and it worked well.<br><br><h2>References</h2><br><br><ul>\n    <li><a href=\"http://stackoverflow.com/questions/2712970/how-to-get-maven-artifact-version-at-runtime/2713013#2713013\">SO: How to get Maven Artifact version at runtime?</a></li>\n    <li><a href=\"http://maven.apache.org/shared/maven-archiver/examples/manifest.html#Adding_Implementation_And_Specification_Details\">Maven Archiver documentation</a></li>\n</ul>",
  "excerpt": ""
 },
 {
  "title": "Tip: Include Context And Propose Solutions In Your Error Messages",
  "published": "2013-05-23 08:15:04",
  "postType": "post",
  "slug": "/2013/05/23/tip-include-context-and-propose-solutions-in-your-error-messages/",
  "status": "publish",
  "tags": [
   "exception",
   "usability"
  ],
  "categories": [
   "General"
  ],
  "content": "A Puppet run has failed with an error message like this:\r\n<blockquote>\"No matching selector for 'prod' at some_puppet_file.pp:31\"</blockquote>\r\nIf you know puppet well enough, you will immediatelly know what is wrong and how to fix it. But what if you don't know what a 'selector' is? Interpreting error messages is often hard without deep knowledge of the software. Be nice to the users / fellow programmers, do not expect they know everything, and include helpful context and preferably also suggest some possible solutions. If the message read instead:\r\n<blockquote>\"No matching selector for 'prod' at some_puppet_file.pp:31; the available selectors are 'production', 'test', 'staging'; have you forgotten to add 'prod' or default?\"</blockquote>\r\nwouldn't it be much more clear and helpful?",
  "excerpt": ""
 },
 {
  "title": "Ignore requirements to gain flexibility, value, insights! The power of why",
  "published": "2013-06-01 15:01:42",
  "postType": "post",
  "slug": "/2013/06/01/ignore-requirements-to-gain-flexibility-value-insights-the-power-of-why/",
  "status": "publish",
  "tags": [
   "experience",
   "lean",
   "methodology",
   "opinion",
   "requirements"
  ],
  "categories": [
   "General",
   "SW development"
  ],
  "content": "I would like to share an eye-opening experience I have recently made. I have learned that if we do not just passively accept the requirements given to us but carefuly analyse the reasons behind them (and the reasons behind the reasons), we gain incredible power and flexibility. By understanding the real value behind it and by discovering other, related sources of value, we might find a superior solution and, more importantly, we gain a few degrees of freedom in the solution space, the ability to scope up or down the solution and optimize it with respect to other solutions. Let's see how a seemingly fixed requirement can be easily expanded or shrinked once we bother to trully understand it.<br><br><!--more--><br><br>The requirement to<br><br><blockquote>Be fully compliant with the accessibility law and its requirements on usability w.r.t. physically impaired users.</blockquote><br><br>could be taken as is and we could run crazy adding proper labels, navigation helpers and whatnot. But what if we stop and ask the simple question why?<br><br><ol>\n    <li>Be fully compliant with the accessibility law</li>\n    <li>Why? So that we won't pay a fine.</li>\n    <li>Why? Because we don't want our profits decreased.</li>\n</ol><br><br>Now this triggers a few thoughts:<br><br><ul>\n    <li>Couldn't we increase our profit more if we used the development resources needed for the compliance on something else? (Where gain &gt; fine.) What is the actual cost of not fullfilling the law (at least for some time)?</li>\n    <li>Or maybe we could actually do more than the law requires. We would thus perhaps attract more of impaired customers (gain 1) and we could even gain a positive social reputation and our customers might be thus willing to pay slightly more knowing that they are helping a good cause (gain 2) and it could help distinguish us from our competitors and help our marketing (gain 3).</li>\n</ul><br><br>Voilà! We have found out that we actually don't \"have to\" fulfill the requirement and discovered few more ways to increase our profit.<br><br>We have thus gained the freedom of decision: We may implement less than the law requires, paying a fine, in exchange for another gain. Or we can do more than presribed, using it as a positioning and marketing tool. Or we can do exactly as asked - but it is us who decides, based on all the other factors and constraints at any given moment. This freedom and flexibility is what enables projects to succeed (i.e. deliver business value exceeding the costs) in the face of constantly changing conditions.<br><br><h2>Conclusion</h2><br><br>Understanding the true value behind requirements gives us a great flexibility in how to attain the value and provides a foundation for rational trade-offs between various values and constraints. It can also lead us to alternative courses of action and other, more important gains. Net result: more insight, more flexibility, more business value created.<br><br>Don't get me wrong - I am not suggesting that you should ignore your stakeholders. Just the opposite, I am asking you to leverage the maximum of their knowledge and to truly respect them by caring to discover they actual needs. But regarding requirements, we should be cautious - as <a href=\"http://www.leanessays.com/2011/08/dont-separate-design-from.html\">Mary Poppendieck said</a>:<br><br><blockquote>All too often, detailed requirements lists and backlogs of stories are actually bad system design done by amateurs.</blockquote><br><br>Inspired? Read the great book(let) <a href=\"http://impactmapping.org/book\">Impact Mapping</a> (<a href=\"http://impactmapping.org/site/impact_mapping_20121001_sample.pdf\">sample</a>) and, if you live in Oslo or London, attend the next (free) <a href=\"http://www.meetup.com/Oslo-Software-Architecture/events/106940192/\">Real Software Architecture course</a> organized by Tom and Kai Gilbs (<a href=\"http://www.gilb.com/CourseSchedule\">schedule</a>).<br><br>I would like to thank <a href=\"http://gojko.net/\">Gojko Adzic</a>, <a href=\"http://www.gilb.com/\">Tom Gilb</a>, and Elena Abilova for inspiration and help. The credit for applying 5 whys to requirements belongs to Tom Gilb. This experience originated at Tom and Kai's course while me and Elena worked on an exercise.<br><br><p style=\"text-align:center;\"><em>You might enjoy also other <a href=\"/tag/opinion/\">posts on effective development</a>.</em></p>",
  "excerpt": ""
 },
 {
  "title": "Most interesting links of June ''13",
  "published": "2013-06-30 21:59:51",
  "postType": "post",
  "slug": "/2013/06/30/most-interesting-links-of-june-13/",
  "status": "publish",
  "tags": [
   "bigdata",
   "clojure",
   "DevOps",
   "fp",
   "frontend",
   "Git",
   "java",
   "lean",
   "performance",
   "simulation",
   "waste"
  ],
  "categories": [
   "General",
   "Languages",
   "Testing",
   "Tools",
   "Top links of month"
  ],
  "content": "<h2>Recommended Readings</h2>\r\nAgile, process, SW dev, people etc.\r\n<ul>\r\n\t<li><a href=\"http://leanprocrastination.com/blog/2012/08/real-options-a-mindset/\">Real Options—a Mindset</a> - an intro into the <a title=\"Chris Matts' and Olav Maassen's original article on InfoQ\" href=\"http://www.infoq.com/articles/real-options-enhance-agility\">Real Options</a> approach, which has been quite a hot topic and a transformational way of thinking for a number of inspiring people (<a href=\"http://twitter.com/tastapod\">Dan North</a>, <a href=\"http://twitter.com/lunivore\">Liz Keogh</a> etc.). \"Real Options help us to better make decisions and commitments with three simple principles: Options have value. Options expire. Never commit early unless you know why.\" We can \"pay\" to keep our options open longer, i.e. to avoid commiting prematurely.</li>\r\n\t<li>Demystifying the CHAOS report's claim of ~ 1/2 features being unused: the Standish Group's CHAOS report has been often quoted for its \"finding\" that a large percentage of features in applications is never/rarely used. However this claim seems to have never been confirmed, their \"research\" is reportedly not very scientific and not publicly available for scrutiny.  <a href=\"https://plus.google.com/app/basic/stream/z13kf1ujhs2fufrxb04cez5a5uitjd4j4hw\">Critique by Laurent Bossavit</a> (2013), Jorge Aranda's <a href=\"http://catenary.wordpress.com/2008/09/24/standish-the-chaos-report-and-science/\">Standish, the CHAOS report, and science</a>. Thx to <a href=\"https://twitter.com/smalltalk80/status/345120991019683841\">@smalltalk80</a> for pointing this out! However there is one research, <a href=\"http://ai.stanford.edu/~ronnyk/ExPThinkWeek2009Public.pdf\">Online Experimentation at Microsoft</a>, that supports the claim, in a different context but the same problem applies to features: \"Evaluating well-designed and executed experiments that were designed to improve a key metric, only about one-third were successful at improving the key metric!\"</li>\r\n\t<li><a href=\"http://firstround.com/article/Why-Yammer-believes-the-traditional-engineering-organizational-structure-is-dead#\">Why Yammer believes the traditional engineering organizational structure is dead</a> - small teams, small projects (2-10 people, 2-10 weeks), no separation into front/middle tier/backend team (=&gt; communication, design obstacle); have instead people specializing in these areas and construct feature teams from them based on the actual needs; engineers, not managers do eng. decisions; all aligned via focusing on the same 3 key metrics. Small projects =&gt; constant sense of urgency (and excitement): Often very long projects cause engineers to lose track of the end goal.  Think of it in terms of hiking: start fresh &amp; excited, get tired and losing track of the goal, excited again at the end =&gt; cut out the middle part, keep them in the exciting state where they can measure progress and see it visually; it’s the only way to maintain urgency and morale. Focus: people alwasy work only at one (short) project at a time (there are special bug-fixing teams for maintenance tasks with people rotating in&amp;out).</li>\r\n\t<li><a href=\"http://www.agileproductdesign.com/blog/agile_is_culture_not_process.html\" rel=\"nofollow\">Agile development is more culture than process</a> - Why thinking of agile as culture and not just process explains resistance and difficulty in teaching and learning the approach - and should be taught so =&gt; 1. Underscore agile values that motivate practice; 2. Identify organization values that compete with agile values, conflict of values; 3. Be sensitive to culture shock.</li>\r\n\t<li><a href=\"http://www.wired.com/business/2012/02/zuck-letter/\">Mark Zuckerberg's Letter to Investors: 'The Hacker Way'</a> (quite long, you might want to read only \"The Hacker Way\" part at the end) - about Facebook's \"unique culture and management approach\" - \"Hackers believe that something can always be better, and that nothing is ever complete.\" \"Hackers try to build the best services over the long term by quickly releasing and learning from smaller iterations rather than trying to get everything right all at once.\" \"Instead of debating for days [..], hackers would rather just prototype something and see what works.\" \"Hacker culture is also extremely open and meritocratic.\" \"Many of our most successful products came out of hackathons, [..].\" &lt;=&gt; five core values: Focus on Impact (focus on solving the most important problems, be good at finding the biggest problems to work on); Move Fast (\"[..] if you never break anything, you’re probably not moving fast enough.\"); Be Bold (\"Building great things means taking risks.\"); Be Open (=&gt; effort to make as much info as possible visible to all); Build Social Value (\"[..] Facebook exists to make the world more open and connected, and not just to build a company. \")</li>\r\n\t<li>Dave Nicolett: <a href=\"http://davenicolette.wordpress.com/2013/05/31/i-know-how-to-tie-my-shoes/\">I know how to tie my shoes</a> - on the difficulty of convincing people to try unfamiliar software development techniques - \"<em>People change the way they operate when they are experiencing some sort of inconvenience or negative feedback. As long as things are going along reasonably well, people don’t go out of their way to change the way they work.</em>\" (with few exceptions) You can learn to <a href=\"http://www.youtube.com/watch?v=gbaHxsilsKI\">tie your shoes in a split second</a>, but why to invest the effort? You'd need to set aside assumptions, suppress habits, practice. You can argument there are many inconveniences (bugs, criticism for slow delivery, ...) but \"Unfortunately, that’s all pretty normal, and most people in the software field are accustomed to it.  They don’t see it as a problem that calls for them to change their practices. Most of them probably have a hard time visualizing a different reality.\" =&gt; Maybe that’s the reason there’s been no satisfactory answer to the question of how to convince people to adopt different practices. We shouldn’t be trying to convince people to do anything. We should be helping people solve their problems and achieve their goals. If they are satisfied with the outcomes they achieve using their current methods, then there is no problem to solve.</li>\r\n\t<li>Kent Beck: <a href=\"https://www.facebook.com/note.php?note_id=582918968407638\">Pace of Progress = Pace of Feedback</a> - '\"The pace of my progress is completely constrained by the pace of my feedback\". If I want to go faster, it's hard to achieve by going faster. I can almost always optimize my feedback loop, though.' \"The second lesson from this episode is that it's not just the duration of the feedback loop that matters, it's also the quality. All week I was working in tiny little iterations. Without producing useful information, though, those iterations could be as small or as large as I liked, I was still just going to spin my wheels.\" =&gt; \"<em>The next time I seem to be going slow, I'm going to look at my whole feedback loop--duration, quality and my ability to respond to the information.</em>\"</li>\r\n\t<li><a href=\"http://www.jrothman.com/blog/htp/2013/06/what-google-has-learned-about-how-to-hire-people.html\">What Google Has Learned About How to Hire People</a> - interview results have no relation to actual performance on the job: \"We looked at tens of thousands of interviews, and everyone who had done the interviews and what they scored the candidate, and how that person ultimately performed in their job. We found zero relationship. It’s a complete random mess.\" \"Instead, what works well are structured behavioral interviews, where you have a consistent rubric for how you assess people, [..]\" 'Behavioral interviewing also works — where you’re not giving someone a hypothetical, but you’re starting with a question like, “Give me an example of a time when you solved an analytically difficult problem.”' Link to an interesting book, <a href=\"http://www.jrothman.com/books/hiring-geeks-that-fit/\" target=\"_blank\">Hiring Geeks That Fit</a>.</li>\r\n</ul>\r\nCool tech stuff\r\n<ul>\r\n\t<li><a href=\"http://elixir-lang.org/\">The Elixir language</a> - Clojure + Ruby + Erlang - a functional meta-programming aware language built on top of the Erlang VM; a dynamic language with flexible syntax with macros support that leverages Erlang's abilities to build concurrent, distributed, fault-tolerant applications with hot code upgrades. First-class support for pattern matching, polymorphism via protocols, etc. (via <a href=\"https://twitter.com/bodil\">@bodil</a>)</li>\r\n\t<li><a href=\"http://extremesoftwaretesting.com/Techniques/RandomTesting.html\">Random Testing</a> seems to be gaining popularity and looks very interesting; at NDC Oslo, John Hughes has presented how <a href=\"http://www.quviq.com/documents/QuviqFlyer.pdf\">QuickCheck</a>, which generates random sequences of API calls, has been successfully used to find bugs in the Riak DB and a file system that a human would never think of, and Stuart Halloway has presented simulation testing with <a href=\"https://github.com/Datomic/simulant/wiki/Overview\">Simulant</a>, which runs predefined actions according to a probabilistic model (e.g. 100 traders, each having 1h mean time between trades and mean traded amount 100, the test runs for 4 simulated hours). Something worth exploring!</li>\r\n\t<li> Dmytro Navrotskyy's collection of <a href=\"https://gist.github.com/dypsilon/5819504\">Frontend Development resources and learning materials</a> for tools (grunt, unused css detection,..), best practices (<a href=\"http://bradfrostweb.com/blog/post/atomic-web-design/\">Atomic Design</a>, ...), JS/CSS frameworks, typography, animation, visualization, useful on-line services,  and many more (via Herman Schistad)</li>\r\n\t<li><a href=\"http://highscalability.com/blog/2013/5/13/the-secret-to-10-million-concurrent-connections-the-kernel-i.html\">The Secret To 10 Million Concurrent Connections - The Kernel Is The Problem, Not The Solution</a>: To have really fast SW, you need to implement your own core services (FS, net driver (packet handling), thread scheduling, ..) tuned for your app. You need to be aware of the clock-time cost of cache misses, memory access etc.. Custom solutions are times faster than what the general OS kernel can offer. =&gt; \"data plane oriented system\" Core areas and solutions for them: packet scalability, multi-core scalability (locks are expensive), memory scalability.</li>\r\n</ul>\r\nOther\r\n<ul>\r\n\t<li>M. Fowler: <a href=\"http://martinfowler.com/bliki/EmbeddedDocument.html\">EmbeddedDocument</a> - a pattern for working with JSON flowing in/out of our services (REST &lt;-&gt; JSON-friendly DB) without unnecessary conversions but with good encapsulation; naive approach: json -&gt; object graph -&gt; (processing) -&gt; json; \"In many of these situtiations a better way to proceed is to keep the data in a JSONish form, but still wrap it with objects to coordinate manipulation.\" - use a lib to parse the JSON into a generic structure (e.g. a structure of lists, and maps/dicts) and store in a field of an object defining methods that encapsulate it - f.ex. for an Order we could have a method returning the customer and another computing the cost, accessing the underlying generic structure. The user of the wrapper object doesn't need to know/care about the underlying structure. \"The sweet spot for an embedded document is when you're providing the document in the same form that you get it from the data store, but still want to do some manipulation of that data. [..] The order object needs only a constructor and a method to return its JSON representaiton. On the other hand as you do more work on the data - more server side logic, transforming into different representations - then it's worth considering whether it's easier to turn the data into an object graph.\"</li>\r\n\t<li><a href=\"http://www.thoughtworks.com/big-data-analytics\">ThoughtWorks' Approach To Big Data Analytics</a> - an inspiring, brief read. Some really good points such as \"It’s not about Data. It’s about Insight and Impact\" =&gt; \"focus on the questions you’d love to answer for your business\" =&gt; \"changing big data from a technological problem to a business solution.\" Also \"The value of data is only realised through insight. And insight is useless until it’s turned into action.\" Measure the value you gain at each step. See  <a title=\"Read more about agile analytics\" href=\"http://www.informit.com/articles/article.aspx?p=1743274\">Introducing Agile Analytics: A Value-Driven Approach to Business Intelligence and Data Warehousing</a> by Ken Collier</li>\r\n\t<li><a href=\"http://www.wired.com/opinion/2013/02/big-data-means-big-errors-people/\">Wired.com, Nassim Taleb: Beware the Big Errors of 'Big Data'</a> - in big data, noise has much stronger effect and in a large enough dataset we will always find spurious (i.e. false) relationships =&gt; beware! \"Well, if I generate (by simulation) a set of 200 variables — completely random and totally unrelated to each other — with about 1,000 data points for each, then it would be near impossible not to find in it a certain number of “significant” correlations of sorts. But these correlations would be entirely spurious.\"</li>\r\n\t<li><a href=\"http://blog.smartbear.com/devops/a-taste-of-salt-like-puppet-except-it-doesnt-suck/\">A Taste of Salt: Like Puppet, Except It Doesn’t Suck</a> - a deescription of Salt and the tools around by an enthusiastic user with deep experience with Puppet. Highlights: Light-weight communication over ZeroMQ, very active community, simplicity, configuration is YAML, Salt-cloud can spin instances in EC2/Openstack/..., Salt-virt does the same for virtual machines (KVM/Xen/...), Salt-vagrant, Salt-monitor (work in progess) can ask all the server for their stats. \"Having stood up a number of different configuration management systems across a wide variety of environments, I’ve yet to find a solution that’s as rapid to deploy, simple to scale, or as well architected as Salt.\"</li>\r\n\t<li><a href=\"http://chadfowler.com/blog/2013/06/23/immutable-deployments/\">Trash Your Servers and Burn Your Code: Immutable Infrastructure and Disposable Components</a> - leveraging the lectures of PF to have a stable infrastructure - instead of updating servers, throw them away and create a new one from scratch (requires virtualization/cloud); this is something that <a href=\"http://techblog.netflix.com/2013/03/ami-creation-with-aminator.html\">Netlfix</a> is doing and also Comoyo is moving towards</li>\r\n\t<li><a href=\"http://eviltrout.com/2013/06/15/ember-vs-angular.html\">Robin Ward: AngularJS vs Ember</a> - a nice overview of the different approaches of the two; the author is strongly pro-Ember, claiming that AngularJS is much closer to low-end libraris like Backbone/Knockout and that you will often need the additional features of Ember. The comments provide the right countrweight to the biased post and form thus a good whole together.</li>\r\n\t<li><a href=\"http://blogs.jetbrains.com/idea/2013/06/scala-productivity-a-survey-of-the-community/\">Scala Productivity. A Survey of the Community</a> - people (that asnwered) seem to be productive with Scala right from the start</li>\r\n</ul>\r\nNon-tech\r\n<ul>\r\n\t<li><a href=\"http://techcrunch.com/2013/06/01/after-your-job-is-gone/\">After Your Job Is Gone</a> - an interesting essay on the future, which, according to the author, we can already see happening, when technology will take away most of our work and we will not need to work all day. Not very optimistic, though (the author predicts few reach and many poor people).</li>\r\n</ul>\r\n<h2>Clojure Corner</h2>\r\n<ul>\r\n\t<li><a href=\"http://clojurecup.com/\">Clojure Cup 2013</a>, Sept 28-29 - create something cool with Clojure/ClojureScript within 48h and perhaps win a price! #fun</li>\r\n\t<li><a href=\"https://groups.google.com/forum/m/#!msg/clojure/a4Dp8gdHev8/aWGmJah-124J\">Clojure use in the industry</a> - examples at an e-mail forum - Netflix, Puppet Labs (e.g. <a href=\"https://github.com/puppetlabs/puppetdb\">PuppetDB</a>), UBS (<a href=\"http://www.infoq.com/presentations/Clojure-Java-Story\">talk</a>), Deutsche Bank (<a href=\"http://skillsmatter.com/podcast/scala/real-world-clojure\">talk</a>, <a href=\"https://groups.google.com/d/msg/london-clojurians/ES8AuxXI0Nk/xwA7_-CAZBkJ\">some details</a>), <a href=\"http://dev.clojure.org/display/community/Clojure+Success+Stories\">Citigroup</a> (<a href=\"https://groups.google.com/d/msg/london-clojurians/ES8AuxXI0Nk/_F5ghQtC6i8J\">reportedly</a> \"the largest private sector deployment of Clojure to date,\" 11/2012), <a href=\"http://getprismatic.com/\" target=\"_blank\">getprismatic.com</a> (with frontend moving to ClojureScript; -&gt; <a href=\"http://www.infoq.com/presentations/Why-Prismatic-Goes-Faster-With-Clojure\">Why Prismatic Goes Faster With Clojure</a>), Roomkey.com (details in a <a href=\"http://is.gd/RAvhqG\">Relevance podcast</a>), <a href=\"http://www.mastodonc.com/\">MastodonC.com</a> (big data), Trend Micro, Walmart, <a href=\"http://beanstalkapp.com/\" target=\"_blank\">beanstalkapp.com</a>, ReadyForZero.com (50kLoC),  <a href=\"http://www.cognician.com/\" target=\"_blank\">www.cognician.com</a> (20kLoC), <a href=\"http://worldsingles.com/\">World Singles</a> (13kLoC) and more... (<a href=\"https://groups.google.com/forum/?fromgroups#!searchin/london-clojurians/production/london-clojurians/ES8AuxXI0Nk/4xgY52znaUcJ\">another similar thread</a>)</li>\r\n\t<li>Stuart Sierra's <a href=\"http://thinkrelevance.com/blog/2013/06/04/clojure-workflow-reloaded\">My Clojure Workflow, Reloaded</a> (6/2013) - mainly about reloading changes into REPL, working around things that are not reloaded/left over =&gt; restart the app from scratch after significant changes =&gt; the app as a transient object =&gt; no global state, careful management of resources, :dev profile with :source-paths to a dir with user.clj (autoloaded by repl, pre-loading useful stuff) and dev util deps</li>\r\n\t<li><a href=\"http://adambard.com/blog/clojure-batteries-included/\">Adam Bard's walk-through useful Clojure libs</a> - f.ex. clojure.[data.[csv xml json] inspector java.shell java.browse xml], tools.logging, clojure.core.[match logic typed contracts ...]</li>\r\n\t<li><a href=\"https://juxt.pro/\">Juxt.pro</a>: Jon Pither's and Malcolm Sparks' \"network of experienced IT professionals who specialise in the Clojure programming language,\" providing training, consulting, talks</li>\r\n\t<li>Anthony Grimes: <a href=\"http://blog.raynes.me/blog/2011/11/27/the-clojure-community-and-me/\">The Clojure Community and Me</a> (2011) - an exciting insight into the embracing and supportive Clojure community</li>\r\n\t<li>In <a href=\"http://blog.bigml.com/2013/06/21/clojure-based-machine-learning/\">Clojure-based Machine Learning</a>: \"Our backend is 99.4% coded in Clojure, and 66% of the team [of 3] had never programmed seriously in any Lisp, let alone Haskell or Prolog (heck, not even I (the remaining 33%) had actually tried anything non-mainstream for real in a big project!) Maybe some Ruby, and lots and lots of Java and C and C++. But they accepted the challenge after reading around and learning the basics, and 3 months later you couldn’t take Clojure from their prying hands.\"</li>\r\n\t<li><a href=\"http://www.pitheringabout.com/?p=995\">J. Pither: TDD and Clojure</a> - \"If you were to create a shopping list of things you really want for your development experience then what would you put at the top?\" =&gt; 1. rapid feedback on changes, 2. REPL (place to explore and to play with your code &lt;=&gt; TDD), 3. FP and Immutability (\"FP and dynamic languages lead to a lot less code. There’s less ceremony, less modeling. Because you’re managing less code you do less large scale refactorings.\" =&gt; TDD needed less), 4. Regression Tests (\"It’s my current opinion that what you get left out of TDD once you have amazingly fast feedback and a REPL is regression testing.\")</li>\r\n</ul>\r\n<h2>Tools/Libs</h2>\r\nTools\r\n<ul>\r\n\t<li>More <a href=\"https://coderwall.com/p/euwpig\">beautiful and colorful git log</a>, by Filipe Kiss (via <a href=\"https://twitter.com/lcdutoit\">@lcdutoit</a>) You may also want to have a look at <a href=\"http://blogs.atlassian.com/2013/05/git-tig/\">tig</a>, which is a text-based UI for git with the default view similar to git <a href=\"http://stedolan.github.io/jq/\">log.</a></li>\r\n\t<li><a href=\"http://stedolan.github.io/jq/\">jq</a> (via <a href=\"https://twitter.com/lcdutoit\">lcdutoit</a>) - sed/awk/grep for JSON - slice, filter, map, transform structured data</li>\r\n\t<li><a href=\"http://www.semanticmerge.com/java.html\">SemanticMerge</a> (Windows) - a Java-aware merge tool - free beta (I haven't tried it)</li>\r\n</ul>\r\nLibs\r\n<ul>\r\n\t<li><a href=\"https://code.google.com/p/jetlang/\">JetLang</a> - a high performance java threading library for in-memory messaging, based upon <a href=\"http://code.google.com/p/retlang\" rel=\"nofollow\">Retlang</a> (via <a href=\"https://twitter.com/tastapod\">@tastapod</a>, used likely in a trading SW).</li>\r\n</ul>\r\n<h2>Favorite Quotes</h2>\r\n<blockquote>Agile [is] in NOT a process — it’s a philosophy.<br><br><em>- Joe Wroblewski <a href=\"http://dannorth.net/2013/01/15/accelerating-agile/comment-page-1/#comment-10593\">in a comment</a> to a blog post\r\n</em></blockquote>\r\n<blockquote>Teach culture first, then process and techniques<br><br><em>- Jeff Patton in <a href=\"http://www.agileproductdesign.com/blog/agile_is_culture_not_process.html\" rel=\"nofollow\">Agile development is more culture than process</a>\r\n</em></blockquote>\r\n<blockquote>If a candidate came telling me that s/he wanted to program only in, say, Java because that’s what s/he knows best and that s/he doesn’t really feel prepared or interested in learning and using, say, Clojure (or any other language, really), I wouldn’t hire her/him in a million years, no matter what language my project were using, and no matter how many thousands of candidates like this one I had at my disposal.\r\n<em>- José Antonio Ortega in <a href=\"http://blog.bigml.com/2013/06/21/clojure-based-machine-learning/\">Clojure-based Machine Learning</a></em></blockquote>\r\n<blockquote>We shouldn’t be trying to convince people to do anything. We should be helping people solve their problems and achieve their goals. If they are satisfied with the outcomes they achieve using their current methods, then there is no problem to solve.\r\n<em>- <em>Dave Nicolett</em> in <a href=\"http://davenicolette.wordpress.com/2013/05/31/i-know-how-to-tie-my-shoes/\">I know how to tie my shoes</a>\r\n</em></blockquote>",
  "excerpt": ""
 },
 {
  "title": "Making Sense Out of Datomic, The Revolutionary Non-NoSQL Database",
  "published": "2013-06-16 21:39:43",
  "postType": "post",
  "slug": "/2013/06/16/making-sense-out-of-datomic-the-revolutionary-non-nosql-database/",
  "status": "publish",
  "tags": [
   "clojure",
   "database",
   "datomic",
   "fp",
   "performance"
  ],
  "categories": [
   "Databases"
  ],
  "content": "I have finally managed to understand one of the most unusual databases of today, Datomic, and would like to share it with you. Thanks to Stuart Halloway and his workshop!\r\n<h2 id=\"why-why\">Why? Why?!?</h2>\r\nAs we shall see shortly, Datomic is very different from the traditional RDBMS databases as well as the various NoSQL databases. It even isn't a database - it is a database on top of a database. I couldn't wrap my head around that until now. The key to the understanding of Datomic and its unique design and advantages is actually simple.<br><br>The mainstream databases (and languages) have been designed around the following constraints of 1970s:\r\n<ul>\r\n\t<li>memory is expensive</li>\r\n\t<li>storage is expensive</li>\r\n\t<li>it is necessary to use dedicated, expensive machines</li>\r\n</ul>\r\nDatomic is essentially an exploration of what database we would have designed if we hadn't these constraints. What design would we choose having gigabytes of RAM, networks with bandwidth and speed matching and exceeding harddisk access, the ability to spin and kill servers at a whim.<br><br><!--more--><br><br>But Datomic isn't an academical project. It is pragmatic, it wants to fit into our existing environments and make it easy for us to start using its futuristic capabilities now. And it is not as fresh and green as it might seem. Rich Hickey, the master mind behind Clojure and Datomic, has reportedly thought about both these projects for years and the designs have been really well thought through.\r\n<h2 id=\"the-weird-architecture-of-datomic\">The Weird Architecture of Datomic</h2>\r\n<ol>\r\n\t<li>Datomic is a database on top of another database (or rather storage) - in-memory, a file system, a traditional RDBMS, Amazon Dynamo.</li>\r\n\t<li>You do not send your query to the server and get back the result. Instead, you get back all the data you need to execute the query and run the query - and all subsequent queries - locally. Thus, \"joins\" are pretty cheap and you can do plenty of otherwise impossible things (combine data from multiple databases and local data structures, run any code on them, ...). Each application using Datomic - a \"peer\" - will have the data it needs, based on its unique needs and usage patterns, close to itself.</li>\r\n\t<li>All writes go through one component, called Transactor, which essentially <a href=\"http://en.wikipedia.org/wiki/Isolation_%28database_systems%29#Serializable\">serializes</a> the writes, thus ensuring <a href=\"http://en.wikipedia.org/wiki/ACID\">ACID</a>. It might sound as a bottleneck but it isn't for most practical purposes<sup><a href=\"#ref1\">[1]</a></sup> given the design and typical application needs. (Reportedly, Datomic could handle all transactions for all credit cards in the world. Listen to the experiences of Room Key with their rather write-heavy load in the <a href=\"http://thinkrelevance.com/blog/2013/06/12/kurt-zimmer-of-room-key-podcast-episode-033\">Relevance Podcast with Kurt Zimmer (Podcast Episode 033)</a>.)</li>\r\n\t<li>Datomic works quite similarly to a version control system such as Git. It never overwrites data, there are no updates. You only mark the data as not valid anymore and add new data, which produces a new version of the database (think of git hash / svn revision number). You can then query the latest state of the database or the state as of a particular version. (Of course the whole database isn't copied whenever you add a fact to it. Datomic is smart and efficient.)</li>\r\n\t<li>It is not a single, monolithic server, the storage, transactor, and peers are physically separate pieces.</li>\r\n</ol>\r\nWhat has made this possible?\r\n<ul>\r\n\t<li>Network access as fast as or faster then disk access =&gt; can fetch all the data over the network</li>\r\n\t<li>Plenty of memory =&gt; can store a substantial subset of it on each peer according to its actual needs</li>\r\n\t<li>Storage is huge and cheap =&gt; we can easily store historical data</li>\r\n\t<li>Experiences with efficient, immutable, \"persistent\" data structures used in modern FP languages =&gt; cheap creation of new \"database values\"</li>\r\n</ul>\r\n<h2 id=\"the-unique-value-proposition-and-capabilities-of-datomic\">The Unique Value Proposition And Capabilities of Datomic</h2>\r\nWe have now learned about and hopefully understood the unique design of Datomic. But what does it give to us, what does it distinguish from other databases?<br><br>The architecture, together with few other design decisions, provides the following key characteristics:\r\n<ul>\r\n\t<li>Programmability - data, schema, query input/output, transaction metadata are all just elementary data structures that you have fully available at the peer and can thus combine and process in powerful ways unimaginable before</li>\r\n\t<li>Persistence/accountability - you never lose history, can annotate transactions with metadata about who/why etc., support for finding out how things were, how they have been changing, performing what-if analysis</li>\r\n\t<li>Elastic scalability - since a lot of the load has been pushed to the peers</li>\r\n\t<li>Flexibility - no rigid schema, easy to navigate and combine and cache data based on each peer's unique needs, extensibility via data functions</li>\r\n</ul>\r\n<h2 id=\"closing-notes\">Closing Notes</h2>\r\nDatomic has similar goals as relational databases (especially ACID) and could be used in similar use cases. Performance-wise, if writes are more important than reads, if you need to write really a lot of data each second continuously, or if you have over billions of \"rows\" then you might prefer another solution. Thanks to the design and recommended architecture for heavily loaded installations, i.e. with memcached in front of the storage, the performance of the backend isn't so important (as the peers have the data they need locally or get it from memcached) so it should be selected more based on the usage-related characteristics.\r\n<h2 id=\"summary\">Summary</h2>\r\nThe design of Datomic - peers fetching data and running queries locally, a single coordinator of writes (transactor), building on existing databases/storage tools (and keeping all the history) seemed very strange and perhaps inefficient to me until I realized that the traditional databases are designed around constraints that do not exist anymore. Datomic now makes sense to me and seems as a tool with intriguing capabilities and great potential. I hope you see it the same way now :-).<br><br>I have left out some interesting topics such as what data structures can be stored in Datomic and the data model and query model used. To learn about these and more about Datomic, head to <a href=\"http://www.flyingmachinestudios.com/programming/datomic-for-five-year-olds/\">Datomic for Five Year Olds</a> and <a href=\"http://www.datomic.com/\">Datomic's home page</a>.\r\n<h2>Bonus Links</h2>\r\n<ul>\r\n\t<li><a href=\"https://groups.google.com/forum/#!msg/datomic/elUJPIVkolo/stUs817r6RUJ\">Data functions for optimistic and pesimistic locking</a> in Datomic (forum answer)</li>\r\n\t<li>HighScalability.com: <a href=\"http://highscalability.com/blog/2010/6/28/voltdb-decapitates-six-sql-urban-myths-and-delivers-internet.html\">VoltDB Decapitates Six SQL Urban Myths and Delivers Internet Scale OLTP in the Process</a> - description of the architecture of VoltDB, that has a few things in common with Datomic (single-threaded writes, \"stored procedures\" as units of transaction etc.)</li>\r\n\t<li><a href=\"http://voltdb.com/dig-deeper/what-is-voltdb.php\">VoltDB</a> - Mike Stonebraker's incredibly scaleable, SQL, ACID database that also breaks up with the constraint of 70s and leverages huge RAM, single-threaded access etc.</li>\r\n</ul>\r\n<sup id=\"ref1\">[1]</sup> Harizopoulos, S., Abadi, D. J., Madden, S., &amp; Stonebraker, M. (2008, June). <a href=\"http://128.148.32.110/courses/cs227/papers/looking-glass.pdf\">OLTP through the looking glass, and what we found there</a>. In <i>Proceedings of the 2008 ACM SIGMOD international conference on Management of data</i> (pp. 981-992). ACM. - this paper shows that traditional RDBMS spend nearly 30% time on locking and latching, that could be eliminated with single-threaded access, as is also done in VoltDB. See also the <a href=\"http://voltdb.com/downloads/datasheets_collateral/technical_overview.pdf\">VoltDB whitepaper</a>.",
  "excerpt": ""
 },
 {
  "title": "Brief Intro Into Random/Stochastic/Probabilistic/Simulation/Property-Based Testing",
  "published": "2013-06-28 07:48:35",
  "postType": "post",
  "slug": "/2013/06/28/brief-intro-into-randomstochasticprobabilistic-testing/",
  "status": "publish",
  "tags": [
   "clojure",
   "random",
   "simulation"
  ],
  "categories": [
   "Testing"
  ],
  "content": "John Hughes and Stuart Halloway had very interesting talks about <a href=\"http://en.wikipedia.org/wiki/Random_testing\">random testing</a> at NDC Oslo, a topic I have been ignorant of but want to explore more now. Contrary to the typical example-based unit tests where the developer specifies inputs, interactions, and specific validations, random testing generates random input data and/or sequences of interactions and the verification is based on more general checks. Random testing can check many more cases than a developer would ever write and cases that a human would never think of. It can thus discover defects impossible to find by the traditional testing, as has been demonstrated f.ex. on Riak.<br><br>Random testing typically starts by creating (likely a very simplified) model of the system under test. The model is then used to generate the random data inputs and/or sequences of actions (method calls). Then the tests are executed and their input and output data captured. Finally the results are validated, either against predefined \"system properties,\" i.e. invariants that should always hold true, or manually by the developer.<br><br>Related/also known as: <a href=\"http://www.nofluffjuststuff.com/conference/raleigh/2013/08/session?id=29335\">generative testing</a>,  <a href=\"http://blog.jessitron.com/2013/04/property-based-testing-what-is-it.html\">property-based testing</a> (<a href=\"http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.37.2924\">a paper</a>).<br><br><!--more--><br><br><em>Disclaimer: My knowledge of random testing and the tools described below is still quite shallow so there are likely to be inaccuracies, if not mistakes. Corrections are highly welcomed.</em><br><br><h2 id=\"case-1-stochastic-testing-with-quickcheck\">Case 1: Stochastic Testing With QuickCheck</h2><br><br><em>(Video: <a href=\"https://vimeo.com/68383317\">John Hughes: Race Conditions, Distribution, Interactions--Testing the Hard Stuff and Staying Sane</a>. Also <a href=\"https://vimeo.com/68331689\">Certifying your car with Erlang</a>.)</em><br><br>John Hughes, one of the key people behind Haskell, created the famous Haskell testing library <a href=\"www.quviq.com/documents/QuviqFlyer.pdf\">QuickCheck</a> in 1999. He has later founded a commercial company <a href=\"http://www.quviq.com/index.html\">QuviQ</a> that uses an Erlang version of QuickCheck to test critical systems, such as those in cars, written in Erlang, C, or other supported languages.<br><br>QuickCheck generates random sequences of calls with random input data.<br><br>If we wanted to test an implementation of a stack, we would:<br><br><ol>\n    <li>Define a model describing the available methods and when it is legal to call them (e.g. we cannot pop an empty stack)</li>\n    <li>Define system properties/postconditions that should always be true, f.ex. that the length of the stack after pop is one less than before</li>\n    <li>Run QuickCheck - it would generate in a controlled random manner and execute many test sequences, likely using some smart logic</li>\n    <li>In the case of a failure, QuickCheck would try to find the smallest subset of the input leading to the failure (shrinking); it would also save the state to make it possible to rerun the same failed test again</li>\n</ol><br><br>According to Hughes, already surprisingly simple models can discover a number of defects. For example in the case of the key-value store Riak, which is nowadays perhaps one of the best tested databases thanks to QuviQ, a failing corner case was found using only a single key and few concurrent clients.<br><br>Randomly generated operation sequences can discover corner cases that a human would never think of, as demonstrated on the slide below, where the sequence \"open file - close file - open file - lookup - insert - insert\" seems to be OK but renders the file invalid, throwing premature eof upon next access.<br><br><a href=\"/images/2013/06/hughes-dets_bug_found.jpg\"><img class=\"alignnone  wp-image-3101\" src=\"/images/2013/06/hughes-dets_bug_found.jpg\" alt=\"hughes-dets_bug_found\" width=\"614\" height=\"1027\" /></a><br><br>QuivQ has successfully used QuickCheck f.ex. to <a href=\"http://www.quviq.com/newsdb?show={2012,3,8}\">check embedded software in Volvo cars</a>, to <a href=\"http://www.quviq.com/newsdb?show={2011,9,23}\">track notorious race conditions in Erlang's built-in database</a> (the dets slide above), to <a href=\"http://www.erlang-factory.com/upload/presentations/255/RiakInside.pdf\">improve Riak</a> and <a href=\"http://www.quviq.com/successes.html\">in many other cases</a>.<br><br>QuickCheck has been ported to many other languages - there is f.ex. <a href=\"https://bitbucket.org/kotarak/clojurecheck\">ClojureCheck</a>, <a href=\"https://github.com/rickynils/scalacheck\">ScalaCheck</a>, <a href=\"https://bitbucket.org/blob79/quickcheck\">Quickcheck for Java</a>. See also introduction into <a href=\"http://www.haskell.org/haskellwiki/Introduction_to_QuickCheck2\">Haskell QuickCheck2</a>.<br><br>Note: The <em><a href=\"https://vimeo.com/68331689\">Certifying your car with Erlang</a></em> introduces QuickCheck a little more and than describes its application to testing car software stacks and components from different vendors and their conformance to a standard (found 200+ bugs in the implementations and 100+ ambiguities in the standard and thus different implementations, with relatively little code). Also introduces mocking (to test components in isolation) and testing of clusters of components.<br><br><h2 id=\"case-2-simulationprobabilistic-testing-with-simulant\">Case 2: Simulation/Probabilistic Testing With Simulant</h2><br><br><em>(Video: <a href=\"https://vimeo.com/68378950\">Stuart Halloway: Simulation Testing</a>.)</em><br><br><a href=\"https://github.com/Datomic/simulant/wiki\">Simulant</a> is a Clojure library for simulation testing based on a probabilistic model, developed by Stuart Halloway. All inputs, outputs, runtime and other information is stored in a database and it is thus possible to compare runs in different times and even to perform new validations on old data.<br><br>Using Simulant involves the following steps, demonstrated on the example of a <a href=\"https://github.com/Datomic/simulant/wiki/Example\">simple system of traders</a>:<br><br><ol>\n    <li>You construct a <a href=\"https://github.com/Datomic/simulant/wiki/Models\">model</a> and corresponding <a href=\"https://github.com/Datomic/simulant/wiki/Tests\">test descriptions</a> that describes what agents there are in the system, what actions they can perform, and the type, frequency, and intensity of those actions in probabilistic terms. In the example, there is only one type of agent, a typical trader, that has start amount $1000, mean time between trades 1 hour, and mean trade amount $100. We want to have 1000 of them.</li>\n    <li>Next you run the simulation, on one or multiple machines, likely using the ability to \"speed up time.\" Simulant will simulate the agents, recording everything into Datomic.</li>\n    <li>Next you can manually explore the end state of the system and the data collected during and about the simulation and/or run automated checks. F.ex. we expect that there is still $100k in the system, that no trader has negative balance, that there has been no failed trades, and that the number of trades is approximately 400 +- 10%.</li>\n</ol><br><br>In a typical system you would have more than one agents (i.e. different user profiles - frequent trader, small trader, big trader, ...) and more actions and more randomness (different start balances, trades could depend on a probability function changing in time etc.)<br><br>The fact that everything is recorded in a DB makes it possible to for example go later back and compare execution performance of the trade function over time.<br><br><h2 id=\"conclusion\">Other Tools</h2><br><br><a href=\"https://code.google.com/p/randoop/\">Randoop</a> is a java tool that \"randomly, but smartly, generates sequences of methods and constructor invocations for the classes under test, and uses the sequences to create [JUnit] tests.\" It \"uses feedback obtained from executing the sequence as it is being constructed, in order to guide the search toward sequences that yield <em>new</em> and <em>legal</em> object states. Inputs that create redundant or illegal states are never extended; this has the effect of pruning the search space.\" The paper <a href=\"http://people.csail.mit.edu/cpacheco/publications/feedback-random.pdf\">Feedback-directed random test generation</a> (2007) describes both the principles behind Randoop and also results from using it and its .NET sibling for testing of 14 widely-deployed, well-tested Java and .NET libraries totaling 780KLOC and a comparison to other types of random testing, f.ex. JPF.<br><br>NASA's <a href=\"http://babelfish.arc.nasa.gov/trac/jpf\">Java Path Finder</a> (JPF) - \"JPF is a highly customizable execution environment for verification of Java™ bytecode programs.\" Essentially, as far as I understand it, JPF provides a special JVM running on top of normal JVM, that collects additional information about the executing program and modifies its execution, for example by executing all - instead of just one - branches of the code, to make it possible to check them all. It is very flexible and supports different execution modes and heuristics for what to skip. Read <a href=\"http://babelfish.arc.nasa.gov/trac/jpf/wiki/intro/what_is_jpf\">What is JPF?</a> and <a href=\"http://babelfish.arc.nasa.gov/trac/jpf/wiki/intro/testing_vs_model_checking\">Testing vs. Model Checking</a>. (Model checking, contrary to testing, is a \"method that exhaustively explores all possible SUT behaviors\" - at least in theory. In practice the state space is too large and must be pruned, leading to blanding of the two.)<br><br><h2>Conclusion</h2><br><br>Random testing is a very powerful and irreplacable technique and we will hopefully see its increased application. There are many approches targetting different situation and trying to deal with the problem of an effective selection of inputs from an impractically large input space. It is worth starting to explore them now.<br><br><h2>Resources</h2><br><br><ul>\n    <li>D. Hamlet. <a href=\"http://web.cecs.pdx.edu/~omse535/hamlet94random.pdf\">Random testing</a>. In Encyclopedia of Software Engineering. John Wiley and Sons, 1994 - the seminal paper about random testing, as it seems</li>\n</ul>",
  "excerpt": ""
 },
 {
  "title": "Installing Latest Node.JS And NPM Modules With Puppet",
  "published": "2013-06-21 14:47:24",
  "postType": "post",
  "slug": "/2013/06/21/installing-latest-node-js-and-npm-modules-with-puppet/",
  "status": "publish",
  "tags": [
   "DevOps",
   "nodejs",
   "puppet"
  ],
  "categories": [
   "Tools"
  ],
  "content": "PuppetLabs' nodejs module is unfortunately quite out of date, providing Node.js 0.6, however there is a simple way to get the latest Node:\r\n<ol>\r\n\t<li>Install the puppetlabs-apt module</li>\r\n\t<li>Add ppa:chris-lea/node.js to apt</li>\r\n\t<li>Install nodejs</li>\r\n\t<li>Steal the npm provider from the puppetlabs-nodejs module</li>\r\n\t<li>Install a npm module</li>\r\n</ol>\r\nCode:<br><br><!--more-->\r\nStealing the npm package provider:\r\n<pre><code>\r\ncd your/puppet/modules/directory\r\nmkdir -p npm-provider/lib/puppet/provider/package\r\ncd npm-provider/lib/puppet/provider/package\r\nwget https://raw.github.com/puppetlabs/puppetlabs-nodejs/master/lib/puppet/provider/package/npm.rb\r\n</code></pre><br><br>Puppet Code:\r\n<pre><code>\r\nclass prepare {\r\n  class { 'apt': }\r\n  apt::ppa { 'ppa:chris-lea/node.js': }\r\n}\r\ninclude prepare<br><br>package {'nodejs': ensure =&gt; present, require =&gt; Class['prepare'],}<br><br>package {'grunt-cli':\r\n    ensure   =&gt; present,\r\n    provider =&gt; 'npm',\r\n    require  =&gt; Package['nodejs'],\r\n}\r\n</code></pre>",
  "excerpt": ""
 },
 {
  "title": "Patterns of Effective Delivery - Challenge Your Understanding Of Agile (RootsConf 2011)",
  "published": "2013-06-22 10:01:24",
  "postType": "post",
  "slug": "/2013/06/22/patterns-of-effective-delivery-challenge-your-understanding-of-agile-rootsconf-2011/",
  "status": "publish",
  "tags": [
   "agile",
   "architecture",
   "effectivity",
   "favourite",
   "lean",
   "patterns",
   "review",
   "team"
  ],
  "categories": [
   "General"
  ],
  "content": "Highlights from <a href=\"http://dannorth.net/\">Dan North</a>'s excellent, inspiring, and insightful <a href=\"http://vimeo.com/24681032\">talk Patterns of Effective Delivery</a> at RootConf 2011. North has a unique take on what agile development is, going beyond the established (and rather limitied and rigid) views. I really recommend this talk to learn more about effective teams, about North's \"shocking,\" beyond-agile experience, and for great ideas on improving your team.<br><br>The talk challenges the absolutism of some widely accepted principles of \"right\" software development such as TDD, naming, the evilness of copy&amp;paste. However the challenge is in a positive way: it makes us think in which contexts these principles really help (in many) and when it might be more effective to (temporarily) postpone them. The result is a much more balanced view and better undestanding of their value. A lot of it is inspired by the theory (and practice) of <a href=\"http://commitment-thebook.com/\">Real Options</a>.<br><br>What are Patterns of Effective Delivery?\r\n<ul>\r\n\t<li>Patterns - strategies that work in a particular context - and <em>not</em> in another (too often we forget the context and to consider the context where a strategy doesn't work / is contra-productive); beware: a part of the context is the experience of the developer; for unexperienced devs it might be better to just stick to a process and applying TDD etc. all the time than trying to guess when they are appropriate and when not without having the experience to decide it right</li>\r\n\t<li>Effective - optimize for something: volume of SW produced? time to market? learning/discovery? certanity? user experience?</li>\r\n\t<li>Delivery - get stuff that is useful out of the door; software is not important, the utility it provides is; know why you write the SW to be able to get better at it</li>\r\n</ul>\r\n<!--more--><br><br>Some of the patterns take years to master and require investment to learn and start getting the benefits. You might need to try (and fail) a few times before getting them right.<br><br>Disclaimer: These are notes that make sense to me. They will likely make only limited or none sense to people that haven't heard the talk. It would be best to go and listen to it instead.\r\n<h2>Selected patterns</h2>\r\n<strong>Spike and Stabilize</strong> (or throw away): traditionally we decide whether we are writing production-grade code (with high rigour such as TDD) or just a throw-away spike before we start coding - i.e. at the moment when we know the least about it. We should rather not decide this uprofnt but \"exercise the option of investing into the quality\" later, based on experience. Start as a spike and if the code proves valuable, stabilize it, refactor, test etc. Evolve the code based on experience (good naming, quality), defer the commitment to the quality of the code =&gt; optimize for learning<br><br>Ex. of spike-and-stabilize regarding test naming: originally named <em>blah</em> - don't know what it should do yet, experimenting, when the code evolves into st. meaningful, name it properly, according to that.<br><br><strong>Ginger Cake</strong> - copy and paste code, rip unrelevant things out until the only important things left, then write tests around; may end up with code that is similar *but not in the ways expected* =&gt; if started with abstracting, it would be the wrong abstraction. It says: \"We know and respect DRY but are not slaves to it.\"<br><br><strong>Short SW Half-Life</strong>: 1) We don't care about the SW but the utility it gives us; if writing it gives us better ideas, we can delete it and do the better thing; 2) how would you write the code if 1/2 of it - but you don't know which half - would be gone in a few weeks? =&gt; start simple (see Spike &amp; St.); extract commonalities, improve quality etc. for code that has already been around for a while and has proven itself useful; Some architecture styles lend themselves better to such quick evolution - small, focused services (popularly known as <a href=\"http://www.infoq.com/presentations/Micro-Services\">micro services</a> (<a href=\"http://2012.33degree.org/pdf/JamesLewisMicroServices.pdf\">slides</a>, esp. p.42+)).\r\n\"Look at the code as it evolves and decide what to invest in.\" (The investment includes thinking about the design.) All code is not equal.<br><br><strong>Create Urgency</strong> - to change a paradigm, the way of thinking, people must be desperate, have no more options, and have the knowledge what to do. =&gt; apply when learning st. new - do it on st. real, under self-inflicted pressure. Ex.: Commit to do an app, with a crazy deadline, using the new tech =&gt; urgency, no more options. Forces to learn only the parts you really need x diff. than what tutorials teach.<br><br><strong>Socratic Testing</strong> (coaching style) - don't tell the team what's wrong with their code, which is threatening and thus hard to accept. Pair with them on writing test and to support the test, make \"helper\" classes etc. that you'd like to see in the prod code. If they really are useful, they will spot it and decide to pull them into the prod code. Make them the hero, don't tell but ask.<br><br><strong>Fits In My Head</strong> - we need code that we can understand and reason about (x big classes, methods, complex models, ...). Keep the code simple, optimize for understandability, readability, obviousness, .... Build Shared Idioms in the team - so that the team members would, given the same context, arive to the same decisions/design. Something should only differ from the usual way of doing it when there is a good reason for i; thus a difference provides a hint, difference is data. F.ex.: all communication over ZeroMQ, only at one place through shared memory - this indicates there is some, most likely performance, reason for it; communication means shouldn't be picked randomly, ad-hoc.<br><br><strong>TDD</strong> - a pattern that, in a *particular context*, may make you much more effective\r\n<h2>Bonus: Micro Services</h2>\r\nFrom James Lewis's talk <a href=\"http://www.infoq.com/presentations/Micro-Services\">Micro Services: Java, the Unix Way</a> (2013) - especially <a href=\"http://2012.33degree.org/pdf/JamesLewisMicroServices.pdf\">slides</a> 42+:\r\n<ul>\r\n\t<li>Use web, do not bypass it - REST, JSON; standardised application protocols and message semantics</li>\r\n\t<li>Small with a single responsibility (does one thing, fits into one's head, small enough to rewrite and throw away rather than maintain)</li>\r\n\t<li>Containerless and installed as well behaved Unix services (executable jar with embedded Jetty + rc.d start scripts and config files)</li>\r\n\t<li>Avoid unnecessary coupling - Domains in different bounded contexts should be distinct – and its ok to have duplication, physical separation to enforce it ; there will be common code, but it should be library and infrastructure code; leverage Conway's Law to support decoupling</li>\r\n\t<li>Provisioned automatically: \"The way to manage the complexity of many small applications is declarative provisioning\" (including instance count, scaling, load balancing)</li>\r\n\t<li>Status aware and auto-scaling - in-app status pages, monitored =&gt; autoscaling</li>\r\n\t<li>Each service is entirely decoupled from it’s clients, scalable, testable and deployable individually</li>\r\n</ul>\r\nDecomposition: product =&gt; set of capabilities (e.g. monitoring, reporting, fulfillment, user) =&gt; each implemented by a set of small apps/services and exposing a uniform interface of Atom Collections. The capabilities form the project by interacting via a uniform interface - HTTP (=&gt; reverse proxies etc.), HATEOS (link relations drive state changes – its an anti-corruption layer that allows the capability to evolve independently of its clients), Standard media types (usable by many types of clients)<br><br>Explict tips from the talk:\r\n<ol>\r\n\t<li>Divide and conquer Start on the outside and model business capabili3es</li>\r\n\t<li>Use Conway’s Law to structure teams (and enforce decoupling)</li>\r\n\t<li>The Last Responsible Moment - Don’t decide everything at the point you know least</li>\r\n\t<li>Be of the web, not behind the web</li>\r\n\t<li>If something is important, make it an explicit part of your design (reify) - ex.: inst. of services creating users by posting to /user, they post a user creation request and get response immediatelly, the user created eventually (reminds me of futures)</li>\r\n\t<li>Favour service choreography over orchestration</li>\r\n\t<li>Use hypermedia controls to decouple services</li>\r\n</ol>\r\nSome tools used: <a href=\"http://www.simpleframework.org/\">SimpleWeb</a>/Jetty, Abdera for Atom, <a href=\"http://smoothiecharts.org/\">Smoothie charts</a> (JS charts for streaming data), Coda Hale's <a href=\"https://github.com/codahale/metrics\">metrics</a>, Graphite. Ops: Fabric with boto, AWS, Puppet, ... .<br><br>But: NO SILVER BULLETS - This stuff is hard - Versioning, Integration, Testing, Deployment; eventual consistency hard for people to wrap head around; ... .<br><br>Note: Comoyo.com, powered by a number of ex-googlers and other smart people, does the same thing. So does, I believe, <a href=\"http://techblog.netflix.com/\">Netflix</a>.\r\n<h2>Related</h2>\r\nIf you liked this, you might also like Dan North's presentations <a href=\"https://vimeo.com/68215534\">Accelerating Agile: hyper-performing teams without the hype</a> and <a href=\"https://vimeo.com/68226771\">Patterns of Effective Teams</a> at NDC Oslo 2013.",
  "excerpt": ""
 },
 {
  "title": "Most interesting links of July ''13",
  "published": "2013-07-31 21:59:42",
  "postType": "post",
  "slug": "/2013/07/31/most-interesting-links-of-july-13/",
  "status": "publish",
  "tags": [
   "agile",
   "architecture",
   "clojure",
   "coaching",
   "erlang",
   "f#",
   "fp",
   "frontend",
   "frp",
   "gamification",
   "innovation",
   "JavaScript",
   "performance"
  ],
  "categories": [
   "General",
   "Tools",
   "Top links of month"
  ],
  "content": "This month focuses on languages and approaches (reactive programming, F#, Erlang, FP talks etc.), agile (need for speed, recommended books), Clojure/Linux/cloud tools and libs.\r\n<h2>Recommended Readings</h2>\r\nDevelopment, agile\r\n<ul>\r\n\t<li><a href=\"http://www.svpg.com/the-need-for-speed\">The Need For Speed</a> - the top 10 reasons for fast development flow (with time to market being one of the less important) - more learning, focus on the MVP, focus on the puprose/goal, happier customers/leadership, better quality (sic!), higher morale (I concur!), push for cotninuous improvement, \"one of the only sustainable differentiators\"; =&gt; \"sense of urgency and motivation\"; \"[..] I continue to meet people and teams that not only move very slow, they don't understand the relationship between speed and innovation, or speed and quality.\"</li>\r\n\t<li><a href=\"http://www.agile42.com/en/blog/2013/07/23/summer-reading-list/\">agile42 Summer Reading List 2013</a> - books recommanded by experienced people/agile experts - lot of interesting stuff! Topics: Communication and Coaching (f.ex. <a href=\"http://www.goodreads.com/book/show/6656887-what-we-say-matters\"><em>Practicing Nonviolent Communication</em></a>), Business (<a href=\"http://www.goodreads.com/book/show/612532.Peak\"><em>How Great Companies Get Their Mojo from Maslow</em></a> ,..),  Learning From the Military, Agile and Technology (e.g. <a href=\"http://www.goodreads.com/book/show/9973202-the-art-of-action\"><em>The Art of Action: How Leaders Close the Gaps between Plans, Actions and Results</em></a>), Agile and Technology (f.ex. <a href=\"http://www.goodreads.com/book/show/17936345-the-people-s-scrum\"><em>The people’s Scrum</em></a>)</li>\r\n\t<li>Dan North: <a href=\"http://dannorth.net/2013/07/05/are-we-nearly-there-yet/\">Are we nearly there yet?</a> - optimize for time to business impact; SW dev as mountaineering (impossible to estimate correctly, many unknown details, dead ends, ...); go fast - but sustainable; the tyranny of backglog (there are multiple paths to the top yet backlog defines only one; have you ever considerably changed it?) \"<em>Instead we could embrace the fact that today we always know more than we did yesterday, and that tomorrow we will know even more. We can take a fresh look up the mountain every time we pause to regroup, to plan.</em>\" =&gt; we ask 1) what gives us the shortest lead time to business impact? 2) what can help us to learn/invalidate more? 3) how to assure our stakeholders we are approaching the goal?</li>\r\n\t<li>Joel on Software: <a href=\"http://www.joelonsoftware.com/items/2012/07/09.html\">Software Inventory</a> (7/2012) - a classical article about the evilness of software inventory (backlogs, issue trackers, undeployed features, ...) '<em>When I hear about product teams that regularly have “backlog grooming” sessions, in which they carefully waste a tiny amount of time and mental energy every day or every week thinking about every single feature which will never be implemented, I want to poke my eyes out.</em>'</li>\r\n\t<li>Job satisfaction self-test: <a href=\"http://flowchainsensei.wordpress.com/2013/07/13/misery-loves-company/\">Twelve questions that define a great place to work</a> - check yourself how satisfied you are with your job (example questions: How well do I know what is expected of me? How often in the past seven days have I received recognition or feedback on my work? How much does the mission/purpose of the company make me feel like my work is important?)</li>\r\n\t<li><a href=\"http://agile.dzone.com/articles/coaching-anti-patterns\">Coaching Anti-Patterns: Prescriptive Agile</a> - a prescriptive coach \"knows\" what is \"right\" and forces it onto the client, without listening to her; instead, we should \"Meet them where they are and leave them in a better place\" =&gt; \"<em>[..] my first responsibility is to understand how and why they came to this practice. How did they come to this decision? What challenges does this approach address? What benefits are they optimizing for?</em>\" Worth remembering AND practicing :)</li>\r\n</ul>\r\nLanguages, paradigms, approaches\r\n<ul>\r\n\t<li><a href=\"http://blog.flowdock.com/2013/01/22/functional-reactive-programming-with-bacon-js/\">Bacon.js Makes Functional Reactive Programming Sizzle</a> - a nice introduction into <a href=\"https://github.com/raimohanska/bacon.js\">Bacon.js</a> that brings <a href=\"http://en.wikipedia.org/wiki/Functional_reactive_programming\">Functional Reactive Programming</a> (FRP) to JavaScript and helps thus escape the callback hell. <a href=\"http://en.wikipedia.org/wiki/Reactive_programming\">Reactive programming</a> has been made popular by Microsoft's <a href=\"http://msdn.microsoft.com/en-us/data/gg577609.aspx\">Rx</a> and recently ported to Java as <a href=\"http://techblog.netflix.com/2013/02/rxjava-netflix-api.html\">RxJava</a> by Netflix. FRP is a subtype of RP with functional concepts (map, filter, immutability, ...). It provides a much cleaner way to handle multiple independent sources of events and reaction to those events, the main concepts are composable Streams of events and Properties, whose values are automatically updated based on a stream. <a href=\"http://nullzzz.blogspot.fi/2012/11/baconjs-tutorial-part-i-hacking-with.html\">Bacon.js Tutorial Part I : Hacking With jQuery</a> provides a nice example of the complexity and ugly code you can run into without (F)RP even for a simple interactive web form, the <a href=\"http://nullzzz.blogspot.fi/2012/11/baconjs-tutorial-part-ii-get-started.html\">Tutorial Part II: Get Started</a> then shows the nicer Bacon.js solution.</li>\r\n\t<li><a href=\"http://www.unlimitednovelty.com/2011/07/trouble-with-erlang-or-erlang-is-ghetto.html\">The Trouble with Erlang (or Erlang is a ghetto)</a> - an objective criticism of Erlang by somebody who seems to be quite experienced with it; as I know very little about Erlang, it was interesting to learn about its weaknesses (no map/dict data structure, slow memory management, poor \"JIT,\" not usable for shared-state concurrency (contrary to e.g. Clojure), immutable state is not necessary and makes some things bad, inconsistent and ugly standard lib, ...)</li>\r\n\t<li><a href=\"http://www.wilfred.me.uk/blog/2013/06/29/multi-paradigm-adventures/\">Adventures in Multi Paradigm Programming</a> - different programming paradigms/approaches re-implemented in Emacs Lisp - interesting 1) to see and compare these different approaches and 2) the flexibility of Lisp. Including iteration - Ruby's map, Python's list comprehension ([an_expression for x in list]), Scala's default argument (_); search - Java's for; arguments: direct, variadic (i.e. any number of args), named args; destructuring and pattern matching in CoffeScript/OCaml style; Haskell-like monads; objects with mixins;  namespaces.</li>\r\n\t<li><a href=\"http://www.simontylercousins.net/journal/2013/3/7/why-bugs-dont-like-f.html\">Why bugs don't like F#</a> - no nulls, immutable data, strong type system, composition of small functions, asynchronous programming abstractions, higher-order functions over collections (no off-by-one), units of measure</li>\r\n</ul>\r\nOther\r\n<ul>\r\n\t<li><a href=\"http://gigaom.com/2013/07/21/ibm-high-fives-netflix-open-source-tools/\">IBM high-fives Netflix open-source tools</a> - it is interesting to see the spreading of Netflix's open source tools for better cloud infrastructures; f.ex. \"<a href=\"http://techblog.netflix.com/2013/03/karyon-nucleus-of-composable-web-service.html\">Karyon,</a> is what Netflix calls the base container for applications and services built using the NetflixOSS ecosystem; <a href=\"http://gigaom.com/2012/09/04/netflix-open-sources-eureka-to-fill-gap-in-amazons-cloud/\">Eureka</a> is mid-tier load balancing; <a href=\"http://gigaom.com/2012/11/26/netflix-open-sources-tool-for-making-cloud-services-play-nice/\">Hystrix</a> controls interactions between myriad distributed services to nip cascading failures in the bud;  and <a href=\"https://github.com/Netflix/ribbon\">Ribbon</a> is a Remote Procedure Call library.\"</li>\r\n\t<li><a href=\"http://augustl.com/blog/2013/zeromq_instead_of_http/\">ZeroMQ instead of HTTP, for internal services</a> (with implementation in Clojure) - an interesting idea of using ZeroMQ - the sockets on steroids library - instead of HTTP in a way compatible with existing HTTP routing libs; advantages of ZeroMQ: automatic retrial (=&gt; can restart the target service withou noticing), speed, reuse of a connection. The trick is to send a http-like structure (i.e. with method, uri, body) and pass that to Compojure or similar (update: there are now <a href=\"https://github.com/lynaghk/zmq-async#zeromq-async\">Clojure/core.async bindings for ZeroMQ</a>)</li>\r\n\t<li><a href=\"http://www.joelonsoftware.com/items/2013/07/22.html\">Joel on Software: Victory Lap for Ask Patents</a> - killing a bad Microsoft patent request in 15 minutes - <a href=\"http://patents.stackexchange.com/\">Ask Patents</a> is a new StackExchange site that enables experts to look at SW patent requests and point to previous existing works that invalidate them; as Joel describes in his successful patent kill story, it is not difficult at all. Hopefully this will manage to really help the patent office and hit woul-be patent trolls hard! #victory</li>\r\n\t<li><a href=\"http://larryferlazzo.edublogs.org/2012/02/26/kathy-sierra-on-gamification-in-education/\">The Dangers Of “Gamification” In Education</a> by Kathy Sierra (a former game designer, a trainer of trainers at Sun, author of the Head First book series) - gamification is often regarded as something very desirable that will improve our lives; however, as Kathy discusses, it has also dark sides and, applied unappropriately, can actually decrease our intrinsic motivation (therefore it should be nearly never used in e.g. education)</li>\r\n\t<li><a href=\"http://gigaom.com/2013/07/21/ibm-high-fives-netflix-open-source-tools/\">Choosing an OSS license doesn’t need to be scary</a> (by GitHub) - a human-readable overview of OSS licenses; you should <a href=\"http://www.theregister.co.uk/2013/07/17/github_launches_choosealicense_dot_com/\"><strong>always assign a license to your GitHub account</strong></a> (<a href=\"http://addalicense.com/\">Add A License</a> can help with that; otherwise it is considered to be \"all rights reserved\" and you are not giving back to the community (I use the same as Clojure, <a href=\"http://choosealicense.com/licenses/\">Eclipse Public License</a>)</li>\r\n</ul>\r\n<h3>Talks</h3>\r\n<ul>\r\n\t<li><a href=\"http://functionaltalks.org/\">FunctionalTalks.org</a> - \"Brilliant people giving brilliant talks on functional programming\" - f.ex. Wilkes Joiner: Functional Reactive Programming, Alexander Gounares: All your cores are belong to us, Katie Miller: Superhero monads, Bryan O’Sullivan: Running A Startup On Haskell, Rich Hickey: Introduction To Clojure, John A. De Goes: Building a Data Science Platform in Scala and many more.</li>\r\n\t<li><a href=\"http://www.infoq.com/presentations/Types-Tests\">Types vs. Tests: An Epic Battle?</a> - \"Amanda Laucher and Paul Snively debate solving problems through types and tests using different approaches.\" - can type system replace tests or vice versa? Interesting intro into the discussion for me. Using F#, Scala &amp; more. Same claims: types don't pay out so much for \"small\" codebases but scale better than tests. Types - Tests is a spectrum, not two single extremes. When a property should hold \"for all,\" a type would be a good match. <a href=\"http://www.cs.cornell.edu/courses/cs6110/2012sp/notes/InductiveTypes.pdf\">Inductive types</a> (Scala, Haskell?) can become quite complex, <a href=\"https://en.wikipedia.org/wiki/Dependent_type\">dependant types</a> (as in <a href=\"http://en.wikipedia.org/wiki/Coq\">Coq</a>) would be much nicer [if I got that right].</li>\r\n\t<li><a href=\"http://www.youtube.com/watch?v=vDbbz-BdyYc\" target=\"_blank\" rel=\"nofollow\">Paul Irish on Web Application Development Workflow</a> (via M. Noddeland) - if you need to do some web development but are not up to date on the state of art, this might be useful - an overview of tools, utilities, services by a Googler and the person behind Modernizr, HTML5 Boilerplate, Yeoman etc. Including <a href=\"https://github.com/paulirish/dotfiles\">effective shell</a> &amp; <a href=\"http://dotfiles.github.io/\">dotfiles.GH</a>, better ssh via .ssh/config and authorized_hosts, the all-in-one dev/build tool <a href=\"http://yeoman.io/\">Yeoman</a> with live reload, <a href=\"http://www.browserstack.com/\">BrowserStack</a> for testing, <a href=\"http://progrium.com/localtunnel/\">LocalTunnel</a> to easily share anything running locally, Chrome Dev Tools support for SASS and testing devices (emulate touch events, screen sizes), JetBrains' <a href=\"http://www.jetbrains.com/webstorm/\">WebStorm</a>, sharing tools via <a href=\"http://setapp.me/\">setapp.me</a>. A genous idea to use GoogleAnalytics to <a href=\"https://github.com/yeoman/insight\" target=\"_blank\">track usage</a> of features in a CLI app!</li>\r\n</ul>\r\n<h2>Other Interesting Stuff</h2>\r\nAzul Systems' high-performance JVM on the Vega architecture (from <a href=\"http://www.unlimitednovelty.com/2011/07/trouble-with-erlang-or-erlang-is-ghetto.html\">The Trouble with Erlang (or Erlang is a ghetto)</a>) looks very interesting:\r\n<blockquote>The other night I tweeted \"<a href=\"https://twitter.com/#!/bascule/status/94267684816031744\">If you're looking for a language that gets multicore concurrency right, look at how Azul implemented Java on their Vega architecture</a>\" and I definitely stand by that. Azul is a company that got a lot of smart hardware and software people together and had them work on designing a custom system which would scale to hundreds of CPU cores (up to 768 of them), heaps that topped 500 GB (up to 768GB), and had the GC pause only 10-20ms at a time. The realtime performance characteristics Azul managed to eek out of their system lead them to often describe their GC as \"pauseless\".</blockquote>\r\nArticles:\r\n<ul>\r\n\t<li><a href=\"http://www.newyorker.com/reporting/2013/07/29/130729fa_fact_gawande?currentPage=all&amp;mobify=0\">SLOW IDEAS - Some innovations spread fast. How do you speed the ones that don’t?</a> - from the annals of medicine but relevant to innovation in SW; some life-changing ideas such as anesthesia spread quickly, others such as the antiseptics take tens of years to take root. (Spolier: if the effect is visible immediately and it is not inconvenient to use, it will spread much faster.)</li>\r\n</ul>\r\n<h2>Clojure Corner</h2>\r\n<ul>\r\n\t<li><a href=\"https://groups.google.com/forum/m/#!topic/clojure/e6Tg4wXLcug\">Discussion: How core.async compares to agents, future and promise?</a> - future/promise: 1 producer, 1 value, multiple consumers; agent: an unbounded queue of functions mutating a single value, with multiple producers and consumers (reading the latest value produced); channel: multiple 1:1 producers/consumers, i.e. a value can only be taken once from the channel, using a bounded queue (=&gt; slow consumers can block fast producers). As mentioned elsewhere, channels is a relatively low-level abstraction and other things can be built on the top of it.</li>\r\n\t<li><a href=\"http://gtrak.wordpress.com/2013/06/26/clojure-tradeoffs/\">Clojure Tradeoffs (design implications and why you should care)</a> - perhaps not very unbiased but interesting anyway :) (shared-memory over other computing paradigms, i.e. message-passing, dynamic over static, speed over convenience, composition over IoC, ...)</li>\r\n\t<li>Rich <a href=\"http://clojure.com/blog/2013/06/28/clojure-core-async-channels.html\">Hickey's post introducing core.async</a> with its Go-like channels as a better alternative to a collback hell (I know everybody has already read it but it is still an important link :))</li>\r\n\t<li>Tools etc.\r\n<ul>\r\n\t<li><a href=\"http://alandipert.tumblr.com/post/55324450821/faster-clojure-startup-with-class-data-sharing\">Faster Clojure Startup with Class Data Sharing</a> - use JVM's capability to include any classes in its boot image and include clojure in it</li>\r\n\t<li><a href=\"https://github.com/xsc/lein-ancient#lein-ancient\">lein-ancient</a> - checks for outdated dependencies and plugins =&gt; run \"lein ancient :all\"</li>\r\n\t<li><a href=\"https://github.com/rkneufeld/lein-try\">lein-try</a> - a Leiningen plugin that enables you to try a library in a REPL in the context of your project without having to add it to project.clj; simply run \"lein try clj-time 0.5.1\" and then in the REPL \"(require '[clj-time.core :refer :all])\" and e.g. \"(date-time 1986 10 14)\"</li>\r\n\t<li><a href=\"https://github.com/TheClimateCorporation/lemur#overview\">Lemur</a>: tool to launch a Hadoop job locally/on EMR from a job definition file + actions before/after</li>\r\n\t<li><strong>Emacs</strong>: sexp fold/expand is very useful for exploring source code (hide all but the first lines of all top-level forms with hs-hide-all) - the built-in <a href=\"http://www.emacswiki.org/emacs/HideShow\">hs-minor-mode</a> can hide/show all, or hide/show/toggle one but the keys for it are cumbersome; <a href=\"https://github.com/shanecelis/hideshow-org.git\">hideshow-org</a> makes it possible to toggle hide/show with TAB, while preserving the original TAB behavior (it does the normal TAB first only only if nothing changes does it expand/fold); very useful!</li>\r\n</ul>\r\n</li>\r\n</ul>\r\n<h2>Tools/Libs</h2>\r\n<ul>\r\n\t<li><a href=\"http://devdocs.io/\">devdocs.io</a> (via <a href=\"https://twitter.com/ruudud/status/356744034984796162\">@palruud</a>): \"an all-in-one API documentation reader for [web] developers,\" navigable via keyboard - JS, HTML, CSS, DOM, DOM events, jQuery, Underscore.js</li>\r\n\t<li><a href=\"http://www.malhar.net/sriram/kilim/\">Kilim</a> - a message-passing framework for Java that provides ultra-lightweight threads and facilities for fast, safe, zero-copy messaging between these threads.</li>\r\n\t<li><a href=\"https://github.com/joel-costigliola/assertj-core#assertj---a-rich-assertions-library-for-java\">AssertJ</a> - a library of assertions similar to fest-assert but providing a richer set of assertions (nicer API then fest-assert, according to a friend)</li>\r\n\t<li><a href=\"http://netflix.github.io/\">NetflixOSS</a> - Netflix, the online streaming gigant, has open-sourced many fascinating components of its cloud infrastructure such as <a href=\"http://techblog.netflix.com/2013/03/karyon-nucleus-of-composable-web-service.html\">Karyon</a>, a blueprint for web-ready components with many features (monitoring,...), <a href=\"http://techblog.netflix.com/2013/06/genie-is-out-of-bottle.html\">Genie</a>/<a href=\"http://techblog.netflix.com/2013/01/hadoop-platform-as-service-in-cloud.html\">Hadoop as a Service</a>, <a href=\"https://github.com/Netflix/servo/wiki\">Servo</a> for monitoring, <a href=\"https://github.com/netflix/archaius\">Archaius</a> for configuration management - too many to list. Check out Chris Fregly's <a href=\"https://github.com/cfregly/fluxcapacitor\">fluxcapacitor</a>, a demo distributed application that uses many of the components</li>\r\n\t<li>Tools to keep a daemon running:\r\n<ul>\r\n\t<li><a href=\"http://mmonit.com/monit/\">Monit</a> - can perform arbitrary actions (e.g. restart) upon many conditions (crash, high resource usage, file change, ...); much wider usage then just keeping daemon programs running; built-in <a href=\"http://mmonit.com/monit/screenshots/\">status dashboard</a></li>\r\n\t<li><a href=\"http://upstart.ubuntu.com/\">Ubuntu's Upstart</a> - running a <a href=\"http://upstart.ubuntu.com/cookbook/#jobs-that-run-forever\">job forever</a>; also support <a href=\"http://upstart.ubuntu.com/cookbook/#run-a-java-application\">for java apps</a> and many more (see <a href=\"http://upstart.ubuntu.com/cookbook/#daemon-behaviour\">expectations of daemon</a> programs)</li>\r\n</ul>\r\n</li>\r\n</ul>",
  "excerpt": ""
 },
 {
  "title": "The Invisible Benefits Of Pair-Programming: Avoiding Wasteful Coding Excursions",
  "published": "2013-07-05 15:50:51",
  "postType": "post",
  "slug": "/2013/07/05/the-invisible-benefits-of-pair-programming-avoiding-wasteful-coding-excursions/",
  "status": "publish",
  "tags": [
   "experience",
   "opinion",
   "pairprogramming",
   "practices",
   "xp"
  ],
  "categories": [
   "General",
   "SW development"
  ],
  "content": "There has been recently <a href=\"http://namcookanalytics.com/high-costs-and-negative-value-of-pair-programming/\">an article</a> about how bad, expensive, and wasteful pair-programming is, since you need double as many developers. It used lines of code (LoC) produced per hour as the main metric. As many have commented, LoC is not the best measure, actually just the opposite, as I want to demonstrate on my experience. (The article is questionable also for other reasons, such as providing no data to back its claims of a pari costing 2.5 times more without any quality benefits, which contradicts f.ex. the studies summarized in ch. 17 of <a href=\"http://www.amazon.com/Making-Software-Really-Works-Believe/dp/0596808321/\">Making Software</a> that show one<sup>1</sup> 1.6* cost + better quality, other 1.15* cost + 15% less failed tests.)<br><br>My main point is that by working with another person that you have to justify your plans to, you can be saved from pursuing suboptimal or unnecessary solution, thus considerably reducing both time spent and lines of code produced (more talk, less [wasteful] code).<br><br><!--more--><br><br>Now to my experience, not the first one of the type.<br><br>I have spent over 1 day implementing a \"cool idea\" - a SQL-like group+select function in Clojure to produce views of my in-memory datastructure so as not to need to access the slow DB. However I have later realized that<br><br><ol>\n    <li>It wasn't needed - I could still use the DB directly, because I was mistakingly thinking I need to use the super-slow Hive while I had the data in reasonably fast MySQL (which turned later out to be also suboptimal but pretty usable with little scripting)</li>\n    <li>I could have implemented it less efficiently (but who cares?) but much more simply and quickly by combining the existing functions (there is a nice group-on function but it can only aggregate one column while I needed two =&gt; call it twice, combine)</li>\n</ol><br><br>If I was pair-programming, I would have had to justify my ideas to my pair who would have likely spotted the faults in my thinking and would have forced me to consider / proposed also other atractive alternatives. (In hindsight, I can think of at least two better ones.) We could thus have easily saved couple of hours and unnecessary lines of codes.<br><br>Therefore pair-programming is good even if it decreases lines of code - or perhaps just because of that.<br><br><p style=\"text-align:center;\"><em>You might enjoy also other <a href=\"/tag/opinion/\">posts on effective development</a>.</em></p><br><br><hr /><br><br><sup>1</sup>) The first study is based on 45 min long programming task so there is little opportunity for time-saving by correcting one's wrong course",
  "excerpt": ""
 },
 {
  "title": "Creating A Chart With A Logarithmic Axis In Incanter 1.5.1",
  "published": "2013-07-12 18:17:35",
  "postType": "post",
  "slug": "/2013/07/12/creating-a-chart-with-a-logarithmic-axis-in-incanter-1-5-1/",
  "status": "publish",
  "tags": [
   "clojure",
   "data",
   "incanter"
  ],
  "categories": [
   "General"
  ],
  "content": "Incanter 1.5.1 doesn't support logarithmic axes, fortunately it is easy to add one manually.<br><br><strong>Update</strong>: <a href=\"https://github.com/liebke/incanter/pull/167\">Pushed improved version to Incanter</a>.<br><br>This is how our final code will look like:<br><br><pre><code>\r\n;; core and charts are the incanter namespaces\r\n(defn plot-power []\r\n  (let [fun #(Math/pow 10 %)\r\n        y-axis (log-axis :label &quot;log(x)&quot;)\r\n        chart (charts/function-plot fun 0 5)]\r\n    (set-axis chart :y y-axis)\r\n    (core/view chart :window-title &quot;LogAxis Test: Incanter fun plot&quot;)))\r\n</code></pre><br><br><!--more--><br><br>And this is the supporting code:<br><br><pre><code>\r\n(defn log-axis\r\n&quot; Create a logarithmic axis.<br><br>  Beware: The data may not contain zero. Otherwise the chart will look\r\n  rather strange (log doesn't like zeros).<br><br>  Options: :base (default 10) base of the logarithm; typically 2 or 10\r\n    :label (default none) the label of the axis\r\n&quot;\r\n  [&amp; options]\r\n  (let [opts (when options (apply assoc {} options))\r\n        base (or (:base opts) 10)\r\n        label (:label opts)]\r\n    (doto (if label\r\n            (LogAxis. label)\r\n            (LogAxis.))\r\n      (.setBase base)\r\n      ;; Use normal numbers instead of 10^num, i.e. 1 inst. of 10^0.0\r\n      (.setStandardTickUnits (NumberAxis/createIntegerTickUnits)))))<br><br>(defmulti set-axis\r\n  &quot;Set the selected axis of the chart, returning the chart.\r\n  (Beware: the axis' label will replace the x-label or y-label set previously on the chart.)<br><br>  Arguments:\r\n    chart - the JFreeChart object whose axis to change\r\n    dimension - depends on the plot type, f.ex. :x or :y for an XYPlot\r\n    axis - the axis to set, an instance of ValueAxis<br><br>  Examples: (use '(incanter core charts))<br><br>    (doto (function-plot #(Math/pow 10 %) 0 5) (set-axis :x (log-axis\r\n      :base 10, :label \\&quot;log(x)\\&quot;)) view)\r\n&quot;<br><br>  (fn [chart dimension axis] (type (.getPlot chart))))<br><br>(defmethod set-axis org.jfree.chart.plot.XYPlot\r\n  ([chart dimension axis]\r\n     {:pre [(#{:x :y} dimension)]}\r\n     (let [plot (.getXYPlot chart)]\r\n       (if (= :x dimension)\r\n         (.setDomainAxis plot axis)\r\n         (.setRangeAxis plot axis)))\r\n     chart))\r\n</code></pre><br><br>Admittedly, this is a little overengineered with the multimethod, but there were reasons for it :-).",
  "excerpt": ""
 },
 {
  "title": "Installing & Troubleshooting Google Analytics 2013 (ga / analytics.js)",
  "published": "2013-07-23 13:50:11",
  "postType": "post",
  "slug": "/2013/07/23/installing-troubleshooting-google-analytics-2013-ga-analytics-js/",
  "status": "publish",
  "tags": [
   "analytics",
   "frontend",
   "google",
   "troubleshooting",
   "web"
  ],
  "categories": [
   "General"
  ],
  "content": "Setting up the new Google Universal Analytics (still in beta) is not completely obvious. You normally won't be able to send events from localhost and it will claim that \"Tracking Not Installed.\" Here are some tips how to use Analytics from localhost and test it.<br><br><!--more-->\r\n<h2>Enabling GA on a site running at localhost</h2>\r\nYou need to <a href=\"http://stackoverflow.com/questions/4375447/can-you-test-google-analytics-on-a-localhost-address\">set cookieDomain to 'none'</a> as suggested by BenSwayne as SO (see the <a href=\"https://developers.google.com/analytics/devguides/collection/analyticsjs/advanced\">docs</a>):<br><br><pre><code>ga('create', 'UA-XXXX-Y', { 'cookieDomain': 'none' });</code></pre>\r\n<h2>Testing GA</h2>\r\nTo check that GA works:\r\n<ol>\r\n\t<li>Enable GA from localhost as described above</li>\r\n\t<li>Open the <a href=\"https://www.google.com/analytics/web/?pli=1#realtime/rt-event/\">Real-Time view</a> in Analytics (GA - Reporting - Real-Time - Events) and</li>\r\n\t<li>In another window, open your webpage and use the Chrome Dev Tools' Console to send an event, f.ex.:\r\n<pre><code>ga('send', 'event', 'my_ga_test', 'it is working!')</code></pre></li>\r\n\t<li>In the Network panel of Chrome Dev Tools, you should see a GET request for<pre><code>http://www.google-analytics.com/collect?...</code></pre></li>\r\n\t<li>The event should appear on the dashboard in no/short time</li>\r\n</ol>\r\n<h2>Why is GA reporting \"Status: Tracking Not Installed\"?!</h2>\r\nThe status report is not reliable and can take up to 72 hrs (or even infinity) to be updated <a href=\"http://productforums.google.com/d/msg/analytics/EZlRmgOCRew/p1v7nowrjOMJ\">according to this post</a> at the Google Product Forums. So do not rely on it. You should be able to check whether GA works as suggested above - or see below.\r\n<h2>Tip: Use the Google Analytics Debugger</h2>\r\n<a href=\"https://chrome.google.com/webstore/detail/google-analytics-debugger/jnkmfdileelhofjcijamephohjechhna?hl=en\">Google Analytics Debugger</a> is a Chrome plugin that provides you with information about what GA is doing and errors in it.\r\n<h2>Alternatives</h2>\r\nYou might also consider using <a href=\"https://github.com/segmentio/analytics.js\">Segment.io's analytics.js</a> (<a href=\"https://segment.io/libraries/analytics.js/\">docs</a>), a NPM component that provides \"hassle-free way to integrate analytics into any web application\" - it supports GA, KISSmetrics, and many others (via <a href=\"https://twitter.com/barlindh\">@barlindh</a>). (You might also want to try <a href=\"https://segment.io/\">Segment.io</a> itself - it \"lets you send your analytics data to any service you want, without you having to integrate with each one individually.\")",
  "excerpt": ""
 },
 {
  "title": "Running A Leiningen/Ring Webapp As A Daemon Via Upstart (Ubuntu)",
  "published": "2013-07-27 09:24:02",
  "postType": "post",
  "slug": "/2013/07/27/running-a-leiningenring-webapp-as-a-daemon-via-upstart-ubuntu/",
  "status": "publish",
  "tags": [
   "clojure",
   "DevOps",
   "linux"
  ],
  "categories": [
   "General"
  ],
  "content": "Running a Java/Clojure app as a daemon on Linux used to be hard but is pretty simple with <a href=\"http://upstart.ubuntu.com/\">Ubuntu Upstart</a> (<a href=\"http://upstart.ubuntu.com/cookbook/\">docs</a>). The short story:\r\n<ol>\r\n\t<li>Create an all-in one <a href=\"https://github.com/technomancy/leiningen/blob/master/doc/TUTORIAL.md#uberjar\">uberjar</a> via \"<kbd>lein with-profile production ring uberjar</kbd>\" (using the <a href=\"https://github.com/weavejester/lein-ring#lein-ring\">lein-ring</a> plugin; a simple <kbd>lein uberjar</kbd> would suffice for an app with a <code>main-</code> method)</li>\r\n\t<li>Create an upstart <kbd>&lt;service name&gt;.conf</kbd> file in /etc/init/</li>\r\n\t<li>Run <kbd>sudo start/stop/status &lt;service name&gt;</kbd></li>\r\n</ol>\r\nAnd of course it works with Puppet too.<br><br><!--more-->\r\n<h2>Example /etc/init/mongodiffer.conf</h2>\r\nExample Upstart config file for the service mongodiffer:<br><br><pre><code>\r\n## Upstart config file (use 'start mongodiffer', 'stop mongodiffer')\r\n## Note: Stdout and stderr will be captured in /var/log/upstart/mongodiffer.log\r\n## (aside of the native log in /var/log/mongodiffer.log)\r\nauthor &quot;Jakub Holy&quot;\r\ndescription &quot;Start the MongoDiffer webapp on its default port (80)&quot;\r\nstart on (local-filesystems and net-device-up IFACE!=lo)\r\n# Note: &quot;start on runlevel [2345]&quot; would also do but I want to be explicit that\r\n# running it w/o network is meaningless\r\n# Must run as root to be able to run on port 80; ugly but quick\r\n#setuid mongodiffer\r\n#setgid mongodiffer\r\nexec java -jar /srv/mongodiffer/clj-analytics-mongodiffer-standalone.jar\r\n## TODO: Consider enabling respawning\r\n# respawn\r\n## Try to restart up to 10 times within 5 min:\r\n# respawn limit 10 300\r\n</code></pre><br><br>The only necessary \"<a href=\"http://upstart.ubuntu.com/cookbook/#stanzas-by-category\">stanzas</a>\" are \"<a href=\"http://upstart.ubuntu.com/cookbook/#start-on\">start on</a>\" and \"<a href=\"http://upstart.ubuntu.com/cookbook/#exec\">exec</a>\" (see also <a href=\"http://upstart.ubuntu.com/cookbook/#run-a-java-application\">Upstart for Java apps</a>). We could also enable <a href=\"http://upstart.ubuntu.com/cookbook/#respawn\">respawning</a> (both the stanzas) so that Upstart would try to start the service again if it crashes. (Of course Clojure service never crash ;-))\r\n<h1>Logging</h1>\r\nI use <a href=\"https://github.com/clojure/tools.logging#logging\">tools.logging</a> with <a href=\"http://logback.qos.ch/\">logback</a> (ch.qos.logback/logback-classic) and its <a href=\"http://logback.qos.ch/manual/appenders.html#RollingFileAppender\">RollingFileAppender</a> with a <a href=\"http://logback.qos.ch/manual/appenders.html#SizeAndTimeBasedFNATP\">SizeAndTimeBasedFNATP</a> to keep the logs to a reasonable size:<br><br><pre><code>\r\n&lt;configuration&gt;<br><br>&lt;appender name=&quot;FILE&quot;&gt;\r\n&lt;file&gt;/var/log/mongodiffer/mongodiffer.log&lt;/file&gt;\r\n&lt;rollingPolicy&gt;\r\n&lt;!-- rollover daily --&gt;\r\n&lt;fileNamePattern&gt;/var/log/mongodiffer/mongodiffer-%d{yyyy-MM}.%i.log&lt;/fileNamePattern&gt;\r\n&lt;timeBasedFileNamingAndTriggeringPolicy&gt;\r\n&lt;!-- or whenever the file size reaches the size --&gt;\r\n&lt;maxFileSize&gt;10MB&lt;/maxFileSize&gt;\r\n&lt;/timeBasedFileNamingAndTriggeringPolicy&gt;\r\n&lt;/rollingPolicy&gt;\r\n&lt;encoder&gt;\r\n&lt;pattern&gt;%d{HH:mm:ss.SSS} [%thread] %-5level %logger{36} - %msg%n&lt;/pattern&gt;\r\n&lt;/encoder&gt;\r\n&lt;/appender&gt;<br><br>&lt;appender name=&quot;STDOUT&quot;&gt;\r\n&lt;encoder&gt;\r\n&lt;pattern&gt;%msg%n&lt;/pattern&gt;\r\n&lt;/encoder&gt;\r\n&lt;/appender&gt;<br><br>&lt;root level=&quot;info&quot;&gt;\r\n&lt;appender-ref ref=&quot;FILE&quot; /&gt;\r\n&lt;appender-ref ref=&quot;STDOUT&quot; /&gt; &lt;!-- Useful when running locally/dev --&gt;\r\n&lt;/root&gt;\r\n&lt;/configuration&gt;\r\n</code></pre><br><br>Stdout and stderr of the service is automatically captured in /var/log/upstart/mongodiffer.log via the default <a href=\"http://upstart.ubuntu.com/cookbook/#console-log\">console log</a> stanza. I haven't been able to find out what to do to make sure that it won't grow infinitely.\r\n<h2>Serving static resources from a Ring uberjar</h2>\r\n<ol>\r\n\t<li>Put the resources under a directory in resources, f.ex. resources/static/ (=&gt; e.g. resources/static/js/zepto/zepto.min.js)</li>\r\n\t<li>Configure the wrap-resource Ring middleware: \"(wrap-resource \"static\")\"</li>\r\n\t<li>Refer to the resources using the path after static (e.g. \"/js/zepto/zepto.min.js\")</li>\r\n</ol>",
  "excerpt": ""
 },
 {
  "title": "Most interesting links of August ''13",
  "published": "2013-08-31 21:59:37",
  "postType": "post",
  "slug": "/2013/08/31/most-interesting-links-of-august-13/",
  "status": "publish",
  "tags": [
   "bestofyear",
   "bigdata",
   "DevOps",
   "human",
   "JavaScript",
   "lean",
   "logging",
   "motivation",
   "vagrant"
  ],
  "categories": [
   "General",
   "Tools",
   "Top links of month"
  ],
  "content": "Sorry folks, this month it will be very brief. I have many more great stuff in the queue but haven't managed to write it down yet. Next month will be heavy :-)\r\n<h2>Recommended Readings</h2>\r\n<ul>\r\n\t<li>Interested in native vs. webapp? Check out <a href=\"http://sealedabstract.com/rants/why-mobile-web-apps-are-slow/\">Why mobile web apps are slow</a> (mobile browser much slower, not much real improvements, weak CPUs,...; seems to be really high-quality, plenty of data) and Sencha's <a href=\"http://www.sencha.com/blog/5-myths-about-mobile-web-performance/\">5 Myths About Mobile Web Performance</a> (Mobile web performance is mostly driven by JavaScript performance on the CPU, CPU-Bound JavaScript has only become faster because of HW improvements, Mobile browsers are already fully optimized, Future hardware improvements are unlikely to help, JavaScript garbage collection is a performance killer).</li>\r\n\t<li><a href=\"http://sealedabstract.com/rants/why-software-projects-are-terrible-and-how-not-to-fix-them/\">Why Software Projects are Terrible and How Not To Fix Them</a> - many teams are not ready to embrace new/better software practices, primarly for two reasons: 1) most of them are nonintuitive (f.ex. adding more people will slow dev down) and need to be sold through a high hierarchy of managament - but people/managers/organizations don't really care, it takes years for good/bad practices to have an impact, which is not relevant \"now.\" 2) Businss objectives change too quickly and SW is blamed for not delivering. Based on evaluating many failed projects. Conclusion: Choose carefully people/organizations your work with. Avoid blame-driven ones. Quote on middle managers: \"<em>He has to put more developers on the project, call a meeting and yell at people, and other arbitrary bad ideas.  Not because he thinks those will solve the problem.  In fact, managers often do this in spite of the fact that they know it’s bad. <strong>Because that’s what will convince upper management that they’re doing their best.</strong></em>\" \"<em>In the vast majority of failed projects I’ve been called to looked at, the managers have not read one book on software engineering.</em>\"</li>\r\n</ul>\r\nData &amp; Analytics\r\n<ul>\r\n\t<li>Big Data: <a href=\"http://oobaloo.co.uk/kafka-for-uswitchs-event-pipeline\">Kafka for uSwitch's Event Pipeline</a> - a better alternative to log files - use LinkedIn's Kafka for messaging, have MR jobs to import latest messages into Hadoop/HDFS. The advantage of Kafka is that it persists the messages for a period of time so it is easy to batch-import and even re-import them. The uSwitch's talk <a href=\"http://vimeo.com/45136211\">Users As Data</a> explains the downsides of log files. LinkedIn's <a href=\"https://github.com/linkedin/camus#intro\">Camus</a> is a tool for importing messages from Kafka to HDFS.</li>\r\n\t<li><a href=\"http://www.slideshare.net/Hadoop_Summit/realtime-analytics-with-storm\">Realtime Analytics with Storm and Hadoop</a> (at Twitter; presentation deck) - pre-aggregate some data into a read-only, random read DB such as ElephantDB, Voldemort, or Manhattan. For newer data use Storm and aggregated data in a read-write, big-data DB such as HBase, Riak, or Cassandra. For stuff that cannot be pre-aggregated you might use <a href=\"https://github.com/nathanmarz/storm/wiki/Distributed-RPC\">Storm's Distributed RPC</a>.</li>\r\n\t<li><a href=\"http://vldb.org/pvldb/vol5/p1771_georgelee_vldb2012.pdf\">The Unified Logging Infrastructure for Data Analytics at Twitter</a> - a paper from late 2012 that presents \"Twitter’s production logging infrastructure and its evolution from application-speciﬁc logging to a uni- ﬁed “client events” log format, where messages are captured in common, well-formatted, ﬂexible Thrift messages\" - with the benefit of \"s streamlined log collection and data analysis\".</li>\r\n</ul>\r\nOther\r\n<ul>\r\n\t<li><a href=\"https://www.facebook.com/download/428991960550526/devops.pdf\">Development and Deployment at Facebook</a> (Kent Beck et. al., 8/2013, 13p paper) - \"<em>More than one billion users log in to Facebook at least once a month to connect and share content with each other. Among other activities, these users upload over 2.5 billion content items every day. In this article we describe the development and deployment of the software that supports all this activity, focusing on the site's primary codebase for the Web front-end.</em>\"</li>\r\n</ul>\r\n<h3>Talks</h3>\r\n<ul>\r\n\t<li>One of the most valuable talks I've seen, in just 18 min: <a href=\"http://www.youtube.com/embed/XD6N8bsjOEE\">The Progress Principle</a> - about the disengagement crisis and motivation at work by Teresa Amabile at TEDx Atlanta (via <a href=\"https://twitter.com/thovden\">@thovden</a>). Disengagement from work is increasing, at all age and salary levels, and leads to unhappy people, low productivity, huge financial losses. Based on analysing diaries of 12k participants, the single <strong>most important engaging and motivating factor is making progress in a meaningful work</strong> (including small wins). A culture of management by fear and punishment for failure creates disengagement and can crush even an innovative, profitable, praised company in a few years. Everybody, though especially the management, creates the culture through their everyday, small actions. If everybody focuses on catalysing progress and supporting their fellow humans through good and bad times, engagement and success will follow. Remove progress inhibitors, nourish the human spirit (acknowledge what we humans value, encourage people). Yet of the managers asked, very few knew of the significance of making progress (or, I can assume, of supporting people and making them happy(er) and the impact of our inner work life (perceptions, emotions, etc.) on our productivity and creativity). The study included two seemingly similar, successfull companies, one with great engagement, another with a new management that managed to destroy the engagement and thus eventually the company. Actions to take: catalyse progress, celebrate wins, encourage and support your colleagues.</li>\r\n</ul>\r\n<h2>Clojure Corner</h2>\r\n<ul>\r\n\t<li><a href=\"http://jafingerhut.github.io/cheatsheet-clj-1.3/cheatsheet-tiptip-cdocs-summary.html\">Wonderful Clojure Cheatsheet 1.5 with tooltips</a> showing the doc and summary of information available at clojuredocs.org (<a href=\"http://jafingerhut.github.io/\">other Clj versions</a>), by Andy Fingerhut</li>\r\n\t<li>Chas Emerick's <a href=\"https://github.com/cemerick/clojure-type-selection-flowchart/\">Clojure type selection flowchart</a> to help you decide whether to use a map, a record, reify, proxy, gen-class, or deftype.  (Reify and proxy don't produce a class but just an instance of an anonymous class; proxy can extend a base class, reify cannot. gen-class produces a class visible from Java and can extend Java classes.  ...)</li>\r\n</ul>\r\n<h2>Tools/Libs</h2>\r\n<ul>\r\n\t<li><a href=\"http://www.docker.io/\">Docker.io</a> - pack, ship and run any application (and its dependencies) as a lightweight container, i.e. essentially \"a VM without the overhead of a VM,\" using <a href=\"http://en.wikipedia.org/wiki/LXC\">linux containers</a> (chroot on steroids with resource limits via <a href=\"https://www.kernel.org/doc/Documentation/cgroups/cgroups.txt\">control groups</a>) see <a href=\"http://www.docker.io/community/#anchor-3\">reports of some uses</a> such as <a href=\"http://blogs.atlassian.com/2013/06/deploy-java-apps-with-docker-awesome/\">Java app deployment</a>, desktop virtualization, automatic <a href=\"http://github.com/keeb/docker-build\">app deployment in GitHub commit</a>. Docker also supports evolving the containers over time, i.e. deploying new version, by pushing just diffs so it's low-overhead. You can <a href=\"http://docs.docker.io/en/latest/use/builder/\">build a container</a> (include files, SW, forward ports, ...) using a Dockerfile. See <a href=\"http://www.youtube.com/watch?v=3N3n9FzebAA\">dotScale 2013 - Solomon Hykes - Why we built Docker</a> for an intro (20 min).</li>\r\n\t<li><a href=\"http://www.packer.io/\">Packer.io</a> - tool for building pre-configured VM images for different platforms (EC2, VirtualBox, ...), remotely similar to Netflix's <a href=\"https://github.com/Netflix/aminator\">Aminator</a>. See <a href=\"http://www.javacodegeeks.com/2013/07/immutable-servers-with-packer-and-puppet.html\">Immutable Servers With Packer and Puppet</a> for an example use case.</li>\r\n\t<li><a href=\"http://cloud-images.ubuntu.com/vagrant/\">Ubuntu-build Vagrant boxes</a> at cloud-images.ubuntu.com/vagrant/</li>\r\n\t<li><a href=\"http://slimerjs.org/\">SlimerJS</a> - PhantomJS-compatible headless browser engine based on Firefox/Gecko (well, it is not fully headless yet but that is planned; the main focus now is full compatibility with PhantomJS' API) (Both work with <a href=\"http://casperjs.org/\">CasperJS</a> for navigational steps/testing.)</li>\r\n\t<li><a href=\"http://progrium.com/localtunnel/#readme\">localtunnel</a> - instantly show locally running webapp/server to the rest of the world (gem install localtunnel,  localtunnel &lt;port to share&gt;, =&gt; share the url returned, e.g. http://xyz.localtunnel.com) - I haven't tried it but it looks simple and very convenient</li>\r\n\t<li><a href=\"http://logstash.net/\">Logstash</a> + <a href=\"http://kibana.org/\">Kibana</a> (via <a href=\"https://twitter.com/mortenberg\">@mortenberg</a>): take control of your logs - while Logstash can collect (from multiple servers/services), parse (over 100 built-in patterns), store, index, search your logs, Kibana is a web interface to seach them, view them in realtime (based on a query) etc. See this <a href=\"http://semicomplete.com/presentations/logstash-puppetconf-2012/#/7\">Logstash slides</a> (9/2012) and an overview of <a href=\"http://kibana.org/about.html\">Kibana's powers</a>. PS: Logstash can also compute metrics and send them to graphite etc. It is typically used with ElasticSearch.</li>\r\n\t<li><a href=\"http://dev.yorhel.nl/ncdu\">ncdu</a> is an interactive, command-like disk usage browser that shows a list of directories sorted by size shown in human-friendly units, you can navigate with arrows and enter and i to show the current dir/file info, d to delete it, q to quit; check out this <a href=\"http://www.tecmint.com/ncdu-a-ncurses-based-disk-usage-analyzer-and-tracker/\">article about ncdu</a> with screenshots and <a href=\"http://linux.die.net/man/1/ncdu\">ncdu man</a> page. Install via Apt etc., run f.ex. with ncdu -x / .</li>\r\n\t<li><a href=\"https://github.com/fgrehm/vagrant-cachier\">vagrant-cachier</a> - Vagrant plugin for caching apt/yum/.. packages locally, thus speeding up destroy+up</li>\r\n</ul>",
  "excerpt": ""
 },
 {
  "title": "Webapp Blue-Green Deployment Without Breaking Sessions/With Fallback With HAProxy",
  "published": "2013-09-05 18:27:40",
  "postType": "post",
  "slug": "/2013/09/05/blue-green-deployment-without-breaking-sessions-with-haproxy-and-jetty/",
  "status": "publish",
  "tags": [
   "continuous_deployment",
   "DevOps",
   "java"
  ],
  "categories": [
   "General"
  ],
  "content": "<strong>Use case</strong>: Deploy a new version of a webapp so that all new users are sent to the new\r\nversion while users with open sessions continue using the previous version\r\n(so that they don't loose their precious session state). Users of the new version\r\ncan explicitely ask for the previous version in the case that it doesn't work as expected and vice versa.<br><br><strong>Benefits</strong>: Get new features to users that need them as soon as possible without affecting\r\nanybody negatively and without risking that a defect will prevent users from achieving their goal\r\n(thanks to being able to fall back to the previous version).<br><br><!--more--><br><br>An alternative to sticky sessions would be to use an external, shared session store (for example Redis). But the overhead and complexity of that wasn't worth the gains in this case.\r\n<h2>Implementation</h2>\r\n<h3>Configuration</h3>\r\nWe will run two instances of our service, on two different ports, with HAProxy in front of them. We will use HAPRoxy's health checks to trick it into believing that one of the instances is partially unwell. HAProxy will thus send it only the existing sessions, while sending all new ones to the other, \"fully healthy,\" instance.<br><br>Notice that even though I run both HAProxy and the instances on the same machine, they could also live on different ones.<br><br>There are actually two solutions. The first one, described here, is simpler, but clients will experience a downtime of ~ 5 sec when an instance actually really is not available (f.ex. crashes). The other solution doesn't suffer from this drawback but requires the ability to reach the instance through two different ports (or perhaps hostnames) for the health checks. Both <a href=\"http://haproxy.1wt.eu/download/1.3/doc/architecture.txt\">solutions are well described in HAProxy's \"architecture\" document</a>: \"<em>4.1 Soft-stop using a file on the servers</em>\" (though we will use a dynamic servlet instead of a static file) and \"<em>4.2 Soft-stop using backup servers</em>\".<br><br>Now go to GitHub to see <a href=\"https://github.com/jakubholynet/experiment-blue-green-jetty\">the proof of concept implementation</a> and read the two sections, 4.1 and 4.2, referenced above. The implementation uses a simple Java webapp running on Tomcat and can be run either on a Linux machine or via <a href=\"http://www.vagrantup.com/\">Vagrant</a>. Follow the instructions and information in the readme.<br><br>The webapp needs to implement support for settable health checks. In our case, the servlet enables POSTs to <code>/health/(enable|disable)</code> to set the availability status and HEAD requests to <code>/health</code> that return either OK or SERVICE UNAVAILABLE based on the status.\r\n<h3>Deployment</h3>\r\nThe deployment is simple:\r\n<ol>\r\n\t<li>Figure out which zone - blue or green - is the current and the previous one - f.ex. by having recorded it into a file.</li>\r\n\t<li>(Optional) Check that the previous instance has no active sessions and take it down. (Not implemented in the PoC.)</li>\r\n\t<li>Deploy over the previous instance (copy the new binary from a remote repository, S3 or whatever)</li>\r\n\t<li>Start the newly deployed instance and verify that it is well, record its zone as the active one.</li>\r\n\t<li>Switch over: Tell the old instance to start reporting to HAProxy that it is unavailable and the new one to report itself as healthy.</li>\r\n\t<li>Drink a cocktail and enjoy.</li>\r\n</ol>\r\nSee the actual <a href=\"https://github.com/jakubholynet/experiment-blue-green-jetty/blob/master/haproxy-vm/deploy-new-build.sh\">implementation in the PoC project</a>.\r\n<h3>Let me see!</h3>\r\nAn old version of the app running in the blue zone (localhost:8080, reloaded in a browser tab where it was opened before the new deployment):<br><br><a href=\"https://lh6.googleusercontent.com/-LUNJMI0O-zk/UipRcxIUeTI/AAAAAAAACp8/onSVyOzOgME/s800/Blue-GreenPoC-old.jpg\"><img alt=\"\" src=\"https://lh6.googleusercontent.com/-LUNJMI0O-zk/UipRcxIUeTI/AAAAAAAACp8/onSVyOzOgME/s800/Blue-GreenPoC-old.jpg\" width=\"800\" height=\"86\" /></a> PoC - old version of the app<br><br>A new version of the app in the green zone (localhost:8080, in a new browser):<br><br><a href=\"https://lh4.googleusercontent.com/-2rRlE3pBGJU/UjmfEgDECcI/AAAAAAAACq8/wnxRJ8tWuEg/s800/Blue-GreenPoC-new-1.jpg\"><img alt=\"\" src=\"https://lh4.googleusercontent.com/-2rRlE3pBGJU/UjmfEgDECcI/AAAAAAAACq8/wnxRJ8tWuEg/s800/Blue-GreenPoC-new-1.jpg\" width=\"800\" height=\"83\" /></a> PoC - the new version of the app<br><br>A part of HAProxy's stats page reporting about the zones (localhost:8081):<br><br><a href=\"https://lh6.googleusercontent.com/-faEc0DWsiQ8/UipRcylsXhI/AAAAAAAACp0/_qZX8dLVlg4/s800/Blue-GreenPoC-haproxy-stats.jpg\"><img class=\"  \" alt=\"\" src=\"https://lh6.googleusercontent.com/-faEc0DWsiQ8/UipRcylsXhI/AAAAAAAACp0/_qZX8dLVlg4/s800/Blue-GreenPoC-haproxy-stats.jpg\" width=\"800\" height=\"85\" /></a> PoC - HAProxy's stats page with the old version (blue) pretending to be down so that new requests go to green\r\n<h2>Credits</h2>\r\nThanks to my colleague Stein Kvarud for the inspiration to use HAProxy.\r\n<h2>Conclusion</h2>\r\nIt is very easy to set up downtime-less blue-green deployment that doesn't break existing sessions and provides the ability to go back to the previous version.",
  "excerpt": ""
 },
 {
  "title": "Clojure REPL stores the latest results in *1, *2, *3, exception in *e",
  "published": "2013-08-24 10:24:06",
  "postType": "post",
  "slug": "/2013/08/24/clojure-repl-stores-the-latest-results-in-1-2-3-exception-in-e/",
  "status": "publish",
  "tags": [
   "clojure",
   "repl"
  ],
  "categories": [
   "Languages"
  ],
  "content": "All Clojure REPL variants (nREPL, REPLy, ..) share some common characteristics, inherited from <a href=\"https://github.com/clojure/clojure/blob/master/src/clj/clojure/main.clj\">clojure.main</a> and <a href=\"https://github.com/clojure/clojure/blob/master/src/clj/clojure/repl.clj\">clojure.repl</a>. One of them, that isn't easy to find out (unless you read e.g. <a href=\"http://clojurebook.com\">Clojure Programming</a>) is the fact that the last three results of evaluating your code are stored in the vars <code>*1</code>, <code>*2</code>, and <code>*3</code>. The last exception that has occured is stored in <code>*e</code>.<br><br>Example:<br><br><pre><code>\r\n;; Inside lein repl, with the user=&gt; prefix removed and output prefixed with ;; =&gt;\r\n1\r\n;; =&gt; 1\r\n2\r\n;; =&gt; 2\r\n3\r\n;; =&gt; 3\r\n4\r\n;; =&gt; 4\r\n(println &quot;results - latest:&quot; *1 &quot;prev:&quot; *2 &quot;oldest:&quot; *3)\r\n;; =&gt; results - latest: 4 prev: 3 oldest: 2\r\n;; =&gt; nil<br><br>(/ 42 0)\r\n;; =&gt; ArithmeticException Divide by zero  clojure.lang.Numbers.divide (Numbers.java:156)\r\n(println &quot;res&quot; *1 &quot;exception&quot; *e)\r\n;; =&gt; res nil exception #&lt;ArithmeticException java.lang.ArithmeticException: Divide by zero&gt;\r\n;; =&gt; nil\r\n</code></pre><br><br>Notice that <code>clojure.repl</code> defines in its namespace some very useful functions and macros such as <code>find-doc</code>, <code>doc</code>, <code>source</code>, <code>apropos</code>, <code>dir</code> (prints a sorted list of public vars in a ns; ex.: <code>(dir clojure.repl)</code>), <code>(root-cause throwable)</code> - check out their <a href=\"http://clojuredocs.org/clojure_core/clojure.repl\">docs at ClojureDocs/clojure.repl</a>.",
  "excerpt": ""
 },
 {
  "title": "Test Puppet config of an existing node using Puppet Master via Vagrant",
  "published": "2013-09-03 11:42:51",
  "postType": "post",
  "slug": "/2013/09/03/test-puppet-config-of-an-existing-node-using-puppet-master-inside-vagrant/",
  "status": "publish",
  "tags": [
   "DevOps",
   "puppet",
   "vagrant"
  ],
  "categories": [
   "Testing"
  ],
  "content": "Are you using Puppet in the client-server setup and want to test the configuration for a particular node without actually changing it? You can do that by fooling Puppet Master into believing that a Vagrant virtual machine (VM) is that node and applying it there. The process is simple: you essentially only need to get the nodes' cert/private key and supply them to Puppet (and likely make sure that the hostname <em>puppet</em> can be resolved from within the VM). Let's see it in detail.<br><br><!--more--><br><br>PS: Credit to my colleague Mikael for discovering the cert+key trick.\r\n<h2>Solution</h2>\r\nI suppose that you have already installed <a href=\"http://www.vagrantup.com/\">Vagrant</a> and <a href=\"https://www.virtualbox.org/\">Virtual Box</a> (VMWare should/could work too), if not, install them and read <a href=\"http://docs.vagrantup.com/v2/getting-started/index.html\">Getting Started</a>.<br><br>Create the Vagrant VM to use for the test. In some directory, which I will call <em>&lt;vagrantdir&gt;</em> from now on, run <em>vagrant init</em> to create a <em>Vagrantfile</em>.<br><br>Next, get <code>/var/lib/puppet/ssl/certs/&lt;hostname&gt;.pem</code> and <code>/var/lib/puppet/ssl/private_keys/&lt;hostname&gt;.pem</code> from the target node. Put them into <em>&lt;vagrantdir&gt;/ssl/(certs|private_keys)/&lt;hostname&gt;.pem</em>. The directory will be visible inside the VM as <em>/vagrant/ssl</em>.<br><br>Update the <em>Vagrantfile</em> to use the <a href=\"http://www.vagrantbox.es/\">OS box</a> or <a href=\"http://cloud-images.ubuntu.com/vagrant/\">Ubuntu base box</a> you want (e.g. <em>config.vm.box_url = \"http://files.vagrantup.com/precise32.box\"</em>) and set up the following provisioners (run in order of appearance), replacing <em>targetnode.example.com</em> with the actual hostname of the target node and <em>puppet.example.com</em> with the Puppet Master's hostname:<br><br><pre><code>\r\n## Vagrantfile snippet\r\n  # 1) Get the signed certificate needed to connect to Puppet Master as the given node\r\n  # Get it from /var/lib/puppet/ssl/certs/&lt;hostname&gt;.pem\r\n  # Note: A fresh agent has only private and public key (gets cert when signed?)\r\n config.vm.provision :shell,\r\n      :inline =&gt; &quot;mkdir -p /etc/puppet/ssl; cp -r /vagrant/ssl /etc/puppet&quot;\r\n  config.vm.provision &quot;puppet_server&quot; do |puppet|\r\n    # BEWARE: Into /etc/hosts, add &lt;puppet master's IP&gt; puppet so that file://[puppet]/.. can work\r\n    puppet.puppet_server = &quot;puppet.example.com&quot;\r\n    puppet.puppet_node = &quot;targetnode.example.com&quot;\r\n    puppet.options = [&quot;--no-daemonize&quot;, &quot;--onetime&quot;, &quot;--verbose&quot;, &quot;--debug&quot;] # add &quot;--env&quot;, &quot;myEnvName&quot; to test a particular environment\r\n  end\r\n··\r\n  config.vm.hostname = &quot;targetnode.example.com&quot;\r\n</code></pre><br><br>When you run <em>vagrant up</em>, the VM should come up, get its keys, connect to the Puppet Master, and obtain and apply the configuration from it.\r\n<h2>Caveats</h2>\r\nThe VM runs on your computer so it likely won't have access to the same network resources (services etc.) as the real node. It will also likely have different devices (important if you run in EC2 and mount EBS disks etc.) unless you manage to configure Virtual Box / the OS to be more like what Puppet expects.<br><br>For example in our case we needed to add \"<em>ln -sf /bin/true /sbin/dhclient</em>\" to the shell provisioner to mock dhclient because otherwise it was run by our setup and got blocked forever.<br><br>If you happen to replace <em>/etc/sudoerrs</em>, you will need to re-enable the user <em>vagrant</em> (who is in the <em>admin</em> group) to run everything without providing a password. One way to do it is to run the following command from inside the VM (you could even add a third provisioner to run it after Puppet but it would not be run if Puppet failed):<br><br><pre><code>echo -e &quot;vagrant\\n&quot; | sudo -S sed -i '$ a\\vagrant  ALL=(ALL) NOPASSWD:ALL' /etc/sudoers</code></pre>\r\n<h2>Note on versions</h2>\r\nTested with Puppet 2.7.x, Vagrant 1.2.7, Virtual Box  4.2.16 on OS X 10.7.",
  "excerpt": ""
 },
 {
  "title": "Most interesting links of September ''13",
  "published": "2013-09-30 21:59:43",
  "postType": "post",
  "slug": "/2013/09/30/most-interesting-links-of-september-13/",
  "status": "publish",
  "tags": [
   "agile",
   "aws",
   "bigdata",
   "book",
   "clojure",
   "design",
   "ethics",
   "framework",
   "JavaScript",
   "lean",
   "performance",
   "shell",
   "toyota"
  ],
  "categories": [
   "General",
   "Languages",
   "Testing",
   "Tools",
   "Top links of month"
  ],
  "content": "<h2>Recommended Readings</h2>\r\n<ul>\r\n\t<li><a href=\"http://highscalability.com/blog/2013/9/13/stuff-the-internet-says-on-scalability-for-september-13-2013.html\">Stuff The Internet Says On Scalability For September 13, 2013</a> - a collection of interesting performance related articles with summaries (via <a href=\"twitter.com/_dagi\">@_dagi</a>)</li>\r\n\t<li><a href=\"http://www.thoughtsofaleanguy.com/2013/07/can-you-copy-culture-nummi-story.html\">Can you copy a culture? The NUMMI story</a> (audio/<a href=\"http://www.thisamericanlife.org/radio-archives/episode/403/transcript\">transcript</a>) - how the GM factory with the worst workforce has been turned around via a good application of <a href=\"http://www.toyota-global.com/company/vision_philosophy/toyota_production_system/\">Toyota Production System</a> - \"a truly inspiring story of human potential and how systems can be designed to bring the best or worst of of people.\" And how GM failed to learn from it and to copy Toyota's culture.</li>\r\n\t<li><a href=\"http://www.reactivemanifesto.org/\">The Reactive Manifesto</a> - why to write reactive SW - \"<em>Reactive applications represent a balanced approach to addressing a wide range of contemporary challenges in software development. Building on an event-driven, message-based foundation, they provide the tools needed to ensure scalability and resilience. On top of this they support rich, responsive user interactions. We expect that a rapidly increasing number of systems will follow this blueprint in the years ahead.</em>\"</li>\r\n\t<li><a href=\"https://moot.it/blog/technology/frameworkless-javascript.html\">Frameworkless JavaScript – Why Angular, Ember, or Backbone don't work for us</a> [Moot discussion platform] (via <a href=\"http://javascriptweekly.com/\">JavaScriptWeekly</a>) Me: Frameworks are not always evil, but are likely overused and there are good cases when rolling your own solution is the best way. Why in Moot? Because the want a minimal API (no framework methods), small code size, small and familiar code base, no dependency hell and external package updates, no lock-in to technology that will be gone in few years, need WebSockets not REST. \"<em>Moot uses native pushState for managing URLs, John Resig's \"<a href=\"http://ejohn.org/blog/javascript-micro-templating/\">micro templating</a>\" for views, and internal communication between model and views happens with a custom event library. There is no router or automatic data-binding.</em>\" The looked at Angular, Ember, Backbone. \"<em>As a result of our combined perfectionism and minimalism, Moot is an extremely lightweight, manageable, and independent web application [..]</em>\"</li>\r\n\t<li>NYT: <a href=\"http://mobile.nytimes.com/2013/09/18/business/global/eiji-toyoda-promoter-of-toyota-way-dies-at-100.html\">Eiji Toyoda, Promoter of the Toyota Way and Engineer of Its Growth, Dies at 100</a> - learn about the life of one of the founders of lean thinking</li>\r\n\t<li>Gojko Adzic: <a href=\"http://gojko.net/2013/09/01/how-we-solved-our-1-product-management-problem/\">How we solved our #1 product management problem</a> - valuable experience of false assumptions, learning from users, and a much helpful UI remake: even if you build a product to scratch your itch, you have to test it with real users</li>\r\n</ul>\r\nBig data\r\n<ul>\r\n\t<li><a href=\"http://www.chrisstucchio.com/blog/2013/hadoop_hatred.html\">Don't use Hadoop - your data isn't that big</a> - a great post about the downside of Hadoop and that there are much better options (large disks, large RAM, Pandas/R/Postgres) for data up to few TBs. \"In addition to being more difficult to code for, Hadoop will also nearly always be slower than the simpler alternatives.\"</li>\r\n\t<li><a href=\"readwrite.com/2013/09/18/gartner-on-big-data-everyones-doing-it-no-one-knows-why\"> Gartner On Big Data: Everyone's Doing It, No One Knows Why</a> - golf talk / hype -driven initiatives FTW! \"According to a recent Gartner report, 64% of enterprises surveyed indicate that they're deploying or planning Big Data projects. Yet <em>even more acknowledge that they still don't know what to do with Big Data</em>.\"</li>\r\n\t<li><a href=\"http://www.draconianoverlord.com/2013/01/22/what-makes-spark-exciting.html\">What makes Spark exciting</a> - why it might be a good replacement for Hive/Hadoop, based on experiences with H/H: \"Hive has served us well for quite a while now. [...]  That said, it has gotten to the point where Hive is more frequently invoked in negative contexts (“damn it, Hive”) than positive. (Primarily due to being hard to test, hard to extend.)\" \"We had heard about Spark, but did not start trying it until being so impressed by the Spark presentation at AWS re:Invent [..] that we wanted to learn more. [..] Spark, either intentionally or serendipitously, addresses both of Hive’s primary shortcomings, and turns them into huge strengths. (Easy to test, extend.) [..] I find the codebase small and very easy to read, [..] –which is a nice consolation compared to the daunting codebases of Hadoop and Hive.\" Cons.: Spark is only pre-1.0, the author hasn't yet tested it heavily.</li>\r\n\t<li><a href=\"http://www.lifehack.org/articles/work/10-ways-make-your-office-fun-work.html\">10 Ways to Make Your Office Fun To Work In</a> - because we spend there plenty of our time so why not have a pleasant/cosy, inspiring environment? Some tips: plants, not-your-boring-enteprprise-look-and-feel, open it to the nature (I <a href=\"http://cdn-5.lifehack.org/wp-content/files/2013/09/SelgasCanoOffice.jpg\">want this!</a>), design it as home, not office, provide play space (I am too into work to want to play but having a resting place for a nap is st. I'd love).</li>\r\n</ul>\r\nBooks\r\n<ul>\r\n\t<li>Book: <a href=\"http://aosabook.org/en/index.html\">The Architecture of Open Source Applications</a> (via <a href=\"https://twitter.com/rmz/status/380498719629512704\">@rmz</a>) - learn by studying architectures of existing systems - \"<em>In these two books, the authors of four dozen open source applications explain how their software is structured, and why. What are each program's major components? How do they interact? And what did their builders learn during their development?</em>\"</li>\r\n\t<li>Book: <a href=\"http://pragprog.com/book/pb7con/seven-concurrency-models-in-seven-weeks\">Seven Concurrency Models in Seven Weeks: When Threads Unravel</a> - \"<em>how to exploit different parallel architectures to improve your code’s performance, scalability, and resilience</em>\" - threads &amp; locks, actors, FP + immutability/futures/promisses, Software Transactional Memory etc., GPU, MapReduce on clusters, ... (<a href=\"http://media.pragprog.com/titles/pb7con/intro.pdf\">intro</a>) Personally, I would prefer from theory to practice approach and mention of <a title=\"Communicating sequential processes\" href=\"http://en.wikipedia.org/wiki/Communicating_sequential_processes\">CSP</a> (-&gt; Go's channels, core.async) and more.</li>\r\n\t<li><a href=\"https://www.linkedin.com/today/post/article/20130925133311-291225-amazon-ceo-jeff-bezos-had-his-top-execs-read-these-three-books?_mSplash=1\">Books Amazon CEO requires his top execs to read</a> (<a href=\"http://www.amazon.com/dp/0060833459/?tag=googhydr-20&amp;hvadid=4236656515&amp;hvpos=1t1&amp;hvexid=&amp;hvnetw=g&amp;hvrand=676821285912340695&amp;hvpone=12.18&amp;hvptwo=&amp;hvqmt=e&amp;hvdev=c&amp;ref=pd_sl_90ud7q00cb_e\" target=\"_blank\">The Effective Executive</a> by Peter Drucker, <a href=\"http://www.amazon.com/Innovators-Solution-Creating-Sustaining-Successful/dp/1578518520/ref=sr_1_1?s=books&amp;ie=UTF8&amp;qid=1380049194&amp;sr=1-1&amp;keywords=The+Innovator%27s+Solution+by+Clayton+Christensen\" target=\"_blank\">The Innovator's Solution</a> by Clayton Christensen, <a href=\"http://www.amazon.com/Goal-Process-Ongoing-Improvement/dp/0884271951/ref=sr_1_1?s=books&amp;ie=UTF8&amp;qid=1380049210&amp;sr=1-1&amp;keywords=The+Goal+by+Eliyahu+Goldratt\" target=\"_blank\">The Goal</a> by Eliyahu Goldratt)</li>\r\n</ul>\r\nOther\r\n<ul>\r\n\t<li><a href=\"http://m.phys.org/news/2013-09-stanford-carbon-nanotube-technology.html\">Stanford engineers build computer using carbon nanotube technology</a> (via <a href=\"https://twitter.com/RiczWest\"><s>@</s>RiczWest</a>)</li>\r\n\t<li>NYT: <a href=\"http://mobile.nytimes.com/blogs/opinionator/2013/09/15/the-banality-of-systemic-evil/\">The Banality of Systemic Evil</a> - a good article about human tendency to \"obey the system\" thus potentially causing evil - and thus the need to resist the system, as heroic individuals such as Snowden, Hammond, Schwartz, Manning. See the famous <a href=\"http://en.wikipedia.org/wiki/Eichmann_in_Jerusalem\">Eichmann in Jerusalem</a> for how \"doing your job\" can create evil - \"<em>[..] what happens when people play their “proper” roles within a system, following prescribed conduct with respect to that system, while remaining blind to the moral consequences of what the system was doing — or at least compartmentalizing and ignoring those consequences.</em>\" (Tip: The book <a href=\"http://www.amazon.com/Moral-Mazes-World-Corporate-Managers/dp/0199729883\">Moral Mazes</a> explores the ethics of decision making within several corporate bureaucracies =&gt; mid-managers rules of life: (1) never go around your boss, (2) tell the boss what she wants to hear, (3) drop what she wants dropped, (4) anticipate what the boss wants so that she doesn't need to act as a boss to get it, (5) do not report something the boss does not want reported, cover it up; the the job &amp; keep your mouth shut.) \"<em>The bureaucracy was telling him [Snowden] to shut up and move on (in accord with the five rules in “Moral Mazes”), but Snowden felt that doing so was <a href=\"http://www.policymic.com/articles/47355/edward-snowden-interview-transcript-full-text-read-the-guardian-s-entire-interview-with-the-man-who-leaked-prism\">morally wrong</a>.</em>\" \"<em>[..] there can be no expectation that the system will act morally of its own accord. Systems are optimized for their own survival and preventing the system from doing evil may well require breaking with organizational niceties, protocols or laws.</em>\"</li>\r\n\t<li><a href=\"http://www.fairphone.com/\">Fairphone</a> - \"<em>A seriously cool smartphone that puts social values first</em>\" (likely the only one not built by poorly paid workers and creating too much ecological burden), for just €325. You can see detailed <a href=\"http://www.fairphone.com/wp-content/uploads/2013/09/Fairphone_Cost_Breakdown_and_Key_Sept2013.pdf\">cost breakdown</a>, <a href=\"http://www.fairphone.com/wp-content/uploads/2013/04/20130910_List-of-Suppliers.pdf\">list of suppliers</a>, <a href=\"http://buy-a-phone-start-a-movement.fairphone.com/specs/\">specs</a>, and essentially everything. This is, in my opinion, super cool! Go and <a href=\"http://www.fairphone.com/#story\">read the story!</a></li>\r\n</ul>\r\n<h2>Clojure Corner</h2>\r\n<ul>\r\n\t<li><a href=\"https://github.com/mcohen01/amazonica\">Amazonica</a> - \"A comprehensive Clojure client for the entire Amazon AWS api.\"</li>\r\n\t<li>Talk <a href=\"http://www.infoq.com/presentations/ritz-clojure\">Ritz, The Missing Clojure Tooling</a> (40min, 9/2013) - thanks to this I finally understood how to use Ritz but it still seems not to work well, f.ex. setting a breakpoint always reported \"Set 0 breakpoints\" (lein ritz/middleware 0.7.0, nrepl-ritz.el 0.7.1); according <a href=\"http://clojure-log.n01se.net/date/2013-08-18.html#03:00a\">to callen</a>, debug-repl is simpler and nicer if you only care about local vars and evaluation. To try ritz: use M-x nrepl-ritz-jack-in, then M-x nrepl-ritz-break-on-exception, exec. f.ex. \"(/ 1 0)\". In the poped-up buffer, t or enter to show frame locals, e to eval a code in the context of the frame etc. If you managed to trigger the debug buffer through a breakpoint, the actions lists would contain STEP etc. (See fun. nrepl-ritz-line-breakpoint)</li>\r\n\t<li>C. Grand's <a href=\"https://github.com/cgrand/spreadmap\">spreadmap</a> - \"library to turn Excel spreadsheets in persistent reactive associative structures\" =&gt; access content via map functions; changing a value updates formula cells using it</li>\r\n\t<li><a href=\"http://hugoduncan.org/post/alembic_reloads_your_project_clj_dependencies/\">Alembic Reloads your Leiningen project.clj Dependencies</a> - add a dependency to your project.clj w/o needing to restart your REPL (just call <em>(alembic.still/load-project)</em>, provided you have it in your lein dependencies). Limitations: cannot remove deps or change versions.</li>\r\n\t<li><a href=\"http://programming-puzzler.blogspot.no/2013/09/defeating-stack-overflows.html\">Defeating stack overflows</a> - techniques for transforming mutually recursive calls etc. into something that won't blow the stack - \"Priming the pump\" (memoize subresults first), core.async</li>\r\n\t<li>Google Groups: <a href=\"https://groups.google.com/forum/m/#!msg/clean-code-discussion/S2NQ65OZ0b8/phZ6A4AjrlQJ\">Clean Architecture for Functional Programming</a> - How do the Clean Architecture and the Clean Code best practices apply to FP (Clojure/Haskell)? Some points: OOP isn't worse than FP, only people do class-oriented programming instead; OO better e.g. for UIs, combining them (func. core, imperative shell) can be sometimes best. Some clean arch. patterns are actually more like functions - \"<em>Interactors and Presenters, for example, do not maintain any state of their own.  Even those objects that do imply some kind of state, such as entities and gateways, keep that state hidden behind boundaries and present a functional interface instead.</em>\"</li>\r\n\t<li><a href=\"https://github.com/MichaelDrogalis/night-vision\">night-vision</a>: <a href=\"http://michaeldrogalis.tumblr.com/post/62057930801/handy-super-light-weight-debugging-utility\">Handy, super light weight debugging utility</a> - add it to your lein profile and then call <code>(night-vision.goggles/introspect-ns! '&lt;name of ns&gt;)</code> and it will print each entry/exit of a function within the scope of the namespace with the argument/return values</li>\r\n\t<li><a href=\"http://www.lispcast.com/nil-punning\">Nil Punning (Or Null Pointers Considered Not So Bad)</a> - a great post about why nil in Clojure is not bad contrary to Java's null (because it is actually an object, you can call functions on it, treat it as false/empty list/map/set, most core functions work on it)</li>\r\n</ul>\r\n<h2>Tools/Libs</h2>\r\n<ul>\r\n\t<li><a href=\"http://bmizerany.github.io/roundup/\">Roundup: Shell script test framework</a> (via <a href=\"https://twitter.com/ruudud\">@ruudud</a>) - seems to be simple, easy; see <a href=\"http://bmizerany.github.io/roundup/roundup.5.html\">roundup(5)</a> for more details</li>\r\n</ul>",
  "excerpt": ""
 },
 {
  "title": "Fixed: Embedded Jetty Fails To Unpack With FileNotFoundException: Not a directory",
  "published": "2013-10-04 11:25:27",
  "postType": "post",
  "slug": "/2013/10/04/fixed-embedded-jetty-fails-to-unpack-with-filenotfoundexception-not-a-directory/",
  "status": "publish",
  "tags": [
   "embedded",
   "java",
   "jetty"
  ],
  "categories": [
   "Languages"
  ],
  "content": "I have built an executable .war with an embedded Jetty and all the dependencies packed in using the Maven Shade and War plugins. When I tried to run it (<code>java -jar &lt;my war&gt;.war</code>) then I got a strange <code>FileNotFoundException</code> during the unpack phase. It was strange because the unpack code actually checks whether a file's parent directory exists and creates it if it doesn't.<br><br>The problem was that I use OS X which has a case-insensitive filesystem. A directory contained both the file LICENSE and the directory license/. When Jetty tried to unpack license/LICENSE.base64.txt, the check for the parent directory (license/) incorrectly succeeded (because it checked n<code>ew File(\"[..]/license/LICENSE.base64.txt\").getParentFile().exists()</code> and that returned true because the file LICENSE already was there, and it wasn't distinguished from the actual directory license; <code>.isDirectory()</code> would have at least failed.) The workaround was to exclude the offensive file from the archive:<br><br><!--more--><br><br><pre><code>\r\n&lt;project ...&gt;\r\n    ...\r\n    &lt;build&gt;\r\n        &lt;plugins&gt;\r\n            &lt;plugin&gt;\r\n                &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;\r\n                &lt;artifactId&gt;maven-shade-plugin&lt;/artifactId&gt;\r\n                &lt;version&gt;1.6&lt;/version&gt;\r\n                &lt;executions&gt;\r\n                    &lt;execution&gt;\r\n                        &lt;phase&gt;package&lt;/phase&gt;\r\n                        &lt;goals&gt;\r\n                            &lt;goal&gt;shade&lt;/goal&gt;\r\n                        &lt;/goals&gt;\r\n                        &lt;configuration&gt;\r\n                            &lt;transformers&gt;\r\n                                &lt;transformer implementation=&quot;org.apache.maven.plugins.shade.resource.ServicesResourceTransformer&quot;/&gt;\r\n                            &lt;/transformers&gt;\r\n                            &lt;finalName&gt;fake-cc-proxy-with-dependencies&lt;/finalName&gt;\r\n                            &lt;filters&gt;\r\n                                &lt;filter&gt;\r\n                                    &lt;artifact&gt;*&lt;/artifact&gt;\r\n                                    &lt;excludes&gt;\r\n                                        &lt;exclude&gt;META-INF/LICENSE&lt;/exclude&gt; &lt;!-- conflicts on OS X with license/) --&gt;\r\n                                    &lt;/excludes&gt;\r\n                                &lt;/filter&gt;\r\n                            &lt;/filters&gt;\r\n                        &lt;/configuration&gt;\r\n                    &lt;/execution&gt;\r\n                &lt;/executions&gt;\r\n            &lt;/plugin&gt;\r\n        &lt;/plugins&gt;\r\n    &lt;/build&gt;\r\n&lt;/project&gt;\r\n</code></pre><br><br>This was the original exception:<br><br><pre><code>\r\n2013-10-02 13:44:16.557:WARN:oejw.WebAppContext:main: Failed startup of context o.e.j.w.WebAppContext@76959acc{/,null,null}{file:/Users/me/FakePM/target/fake-pm-with-dependencies.war}\r\njava.io.FileNotFoundException: /private/var/folders/k0/2842tm752zv1dh4q77_gmgdr0000gn/T/jetty-0.0.0.0-8444-fake-pm-with-dependencies.war-_-any-/webapp/META-INF/license/LICENSE.base64.txt (Not a directory)\r\n    at java.io.FileOutputStream.open(Native Method)\r\n    at java.io.FileOutputStream.&lt;init&gt;(FileOutputStream.java:212)\r\n    at java.io.FileOutputStream.&lt;init&gt;(FileOutputStream.java:165)\r\n    at org.eclipse.jetty.util.resource.JarResource.copyTo(JarResource.java:237)\r\n    at org.eclipse.jetty.webapp.WebInfConfiguration.unpack(WebInfConfiguration.java:478)\r\n    at org.eclipse.jetty.webapp.WebInfConfiguration.preConfigure(WebInfConfiguration.java:72)\r\n    at org.eclipse.jetty.webapp.WebAppContext.preConfigure(WebAppContext.java:453)\r\n    at org.eclipse.jetty.webapp.WebAppContext.doStart(WebAppContext.java:489)\r\n    at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:69)\r\n    at org.eclipse.jetty.util.component.ContainerLifeCycle.start(ContainerLifeCycle.java:108)\r\n    at org.eclipse.jetty.server.Server.start(Server.java:342)\r\n    at org.eclipse.jetty.util.component.ContainerLifeCycle.doStart(ContainerLifeCycle.java:90)\r\n    at org.eclipse.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:58)\r\n    at org.eclipse.jetty.server.Server.doStart(Server.java:290)\r\n    at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:69)\r\n    at no.viatravel.poc.safecc.profilemaster.Main.startServerAndBlock(Main.java:123)\r\n    at no.viatravel.poc.safecc.profilemaster.Main.main(Main.java:38)\r\n2013-10-02 13:44:16.575:INFO:oejs.ServerConnector:main: Started ServerConnector@478bc78e{HTTP/1.1}{0.0.0.0:8444}\r\n</code></pre><br><br>See JarResource.java:230 in jetty 9.0.5.x for the relevant code.",
  "excerpt": ""
 },
 {
  "title": "My Highlights From EuroClojure 2013",
  "published": "2013-10-28 20:11:33",
  "postType": "post",
  "slug": "/2013/10/28/my-highlights-from-euroclojure-2013/",
  "status": "publish",
  "tags": [
   "clojure",
   "conference"
  ],
  "categories": [
   "Languages"
  ],
  "content": "<strong></strong><a href=\"http://euroclojure.com/2013/programme/\">EuroClojure 2013</a> was a nice, small conference. The talks were mostly interesting and often useful and it was wonderful to meet in reality people I only knew from the virtual life or from stories. You can get an impression what it was like from the <a href=\"https://twitter.com/search?q=%23euroclojure&amp;src=tyah\">#euroclojure tweets</a>.<br><br>Below are some noteworthy things from the talks and chats.<br><br><!--more-->\r\n<h2>Other stuff</h2>\r\n<ul>\r\n\t<li><a href=\"http://thechangelog.com/rich-hickeys-greatest-hits/\">Rich Hickey’s Greatest Hits</a> - links to the most popular talks (currently 6) such as Simple Made Easy</li>\r\n\t<li><a href=\"https://github.com/juliangamble/clojure-ants-simulation\">Rich Hiceky's demo simulation of Ants</a> in Clojure - high concurrency, no locking</li>\r\n</ul>\r\n<h2>Slides and code from the talks</h2>\r\nGo to<a href=\"http://lanyrd.com/2013/euroclojure/coverage/\"> EuroClojure 2013 at Lanyrd for links to slides and source code</a> used in the talks.\r\n<h2>Talks</h2>\r\nHere are some things I have found worth remembering from <a href=\"http://euroclojure.com/2013/programme/\">the programme</a>.\r\n<h3>Side notes</h3>\r\nThe MOOC <a href=\"http://www.complexityexplorer.org/online-courses/1\">Introduction to Complexity</a> has been mentioned and recommended.<br><br>The Clojure-driven drone project <a href=\"https://github.com/jarppe/sormilla\">Sormilla</a> at GitHub is an example of using Stuart Sierra's Reload pattern to be able to realod code cleanly w/o restarting REPL, see the interface Service. (I cannot find this part of the code at GitHub and it is 2m old, perhaps the changes with this aren't there yet?) Using clojure/tools.namespace‎'s reload[-all]<br><br>Ruby programmers are perhaps more open-minded towards Clojure than experienced Java devs?\r\n<h3>Zach Tellman's keynote: States and Nomads: Handling Software Complexity</h3>\r\nAbstractions are essentially simplifications that try to hide complexity by either treating multiple moving parts as one or by ignoring some relationships between the moving parts. Therefore all abstractions are imperfect and there are always situations where the underlying complexity leaks through. <strong>Every abstraction (library, framework) has thus a boundary beyond which it isn't useful anymore due to the underlying complexity leaking through.</strong> A civilized discussion should focus on discovering the boundary rather than claiming that something is rubbish because you tried to use it outside of its boundary of usefulness or claiming that it is a silver bullet.<br><br><strong>Local and contextual quality</strong>: Christopher Alexander, the <a href=\"http://en.wikipedia.org/wiki/A_Pattern_Language\">father of design patterns</a>, examines one special \"<a href=\"http://www.google.no/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=1&amp;cad=rja&amp;ved=0CCgQFjAA&amp;url=http%3A%2F%2Fwww.cs.tut.fi%2F~kk%2Fwebstuff%2FFoundationofpatterns.pdf&amp;ei=mrNeUqV_hIbgBOyegJgG&amp;usg=AFQjCNHe2t5fXFUwFsml2wI33eMCXPzDxg&amp;sig2=0oMuxJ3E6Z4gPUT-99ozMQ&amp;bvm=bv.54176721,d.bGE\">quality without a name</a>\" that embodies that a design is good. It is hard to describe and is special by depending very much on the local context and cannot be described and prescribed generally, in the absolute platonic way. How does this quality apply to software?\r\n<blockquote>There is a central quality which is the root criterion of life and spirit in a man, a town, a building, a wilderness. This quality is objective and precise, but it cannot be named.<br><br>- Ch. Alexander: <a href=\"http://books.google.no/books?id=H6CE9hlbO8sC&amp;pg=PA17&amp;lpg=PA17&amp;dq=alexander+%22quality+without+name%22&amp;source=bl&amp;ots=4v-IcjmakL&amp;sig=WYwUx2KuEGqGqGemT-b9m0IHaCE&amp;hl=en&amp;sa=X&amp;ei=mrNeUqV_hIbgBOyegJgG&amp;ved=0CEAQ6AEwAw#v=onepage&amp;q=alexander%20%22quality%20without%20name%22&amp;f=false\">The Timeless Way of Building</a>, Volume 8, page ?19?</blockquote>\r\nZach's reading list containing f.ex. <a href=\"http://dreamsongs.net/Files/PatternsOfSoftware.pdf\">Gabriel, Richard P. Patterns of Software</a> is interesting\r\n<h3>Liberator – free your data with RFC 2616</h3>\r\n<a href=\"http://clojure-liberator.github.io/liberator/\">Liberator</a> is a REST library for Clojure with <a href=\"http://clojure-liberator.github.io/liberator/tutorial/debugging.html\">great troubleshooting capabilities</a>, having a log of past requests and for each of them the decision steps it went through, complete with a graph.\r\n<h3>James Reeves: Functional 3D Game Design</h3>\r\nA 3D game has ~ 16 ms/frame which is not too short for using clojure.<br><br>Performance and reliability oppose each other when going from the least performant, brute force, through caching to mutability =&gt; when in doubt, use brute force (i.e. old good Clojure without perf. optimization). Caching is often good enough.<br><br>Uses the library <a href=\"https://github.com/hugoduncan/criterium\">Criterium</a> for benchmarking.\r\n<h3>Jen Smith: Common Clojure Smells</h3>\r\n<a href=\"https://dl.dropboxusercontent.com/u/18288740/talks/clojuresmells.pdf\">Slides (pdf).</a><br><br>Overview (<a href=\"https://twitter.com/RiczWest/status/389775123642716160\">via Richard West</a>):<br><br><img class=\"alignnone\" alt=\"OOP and Clojure smells and sources\" src=\"https://o.twimg.com/2/proxy.jpg?t=HBhaaHR0cDovL2kwLndwLmNvbS9jaGFuZ2VhcmMuZmlsZXMud29yZHByZXNzLmNvbS8yMDEzLzEwLzIwMTMxMDE0LTE3MjgyNS5qcGc_Zml0PTE2MDAlMkMxNjAwFPQNFOwLABYAEgA&amp;s=ecWX4SMKV81ks96306581zBv18D0SFjpEe5eb2KY9fo\" width=\"890\" height=\"758\" /><br><br>Some of the code smells from OOP apply to Clojure as well, perhaps with some modifications (too large class =&gt; too large namespace) but Clojure has also some of its own, such as:\r\n<ul>\r\n\t<li> Magic Keys - if many functions need to know about keys within (= structure of) a map =&gt; harder to maintain =&gt; try to decouple</li>\r\n\t<li>Locally scoped atoms</li>\r\n\t<li>Indirection by partiality - many derived functions using (partial .. )</li>\r\n\t<li>Macromania - overuse of macros</li>\r\n\t<li>Excessive use of lazy evaluation - a troubleshooting issue since an error may appear much later when the lazy seq is evaluated, far from where it originates =&gt; consider evaluating seqs at borders of responsibility (modules, ...)</li>\r\n\t<li>Many discrete steps with a final one that executes the seq (a.k.a. long pipelines; map + filter + reduce + ...) - an error in the middle will be hard to troubleshoot =&gt; break down</li>\r\n\t<li>Parens proliferation (a.k.a. over-nesting, doing too many things at once) =&gt; break into multiple functions, use -&gt;</li>\r\n</ul>\r\nHopefully this will be a start of a growing collection of Clojure code smells\r\n<h3>Stuart Halloway's keynote: Narcissistic Design</h3>\r\nA thought-provoking presentation about \"tips\" for increasing complexity including a masked criticism of (bad) unit testing (many tests with different setup, ...). It is worth listening to and thinking about.<br><br>See also <a href=\"http://teropa.info/blog/2013/10/15/euroclojure-2013-narcissistic-design.html\">Tero Parviainen's extensive summary of the Narcissistic Design</a> talk.<br><br><a href=\"https://nofluffjuststuff.com/conference/reston/2013/11/session?id=30015\">Narcissistic Design recorded at NoFluffJustStuff.com</a>.<br><br>The 10 steps to job security are:\r\n<ol>\r\n\t<li>Use OO, and don't forget those setter methods!</li>\r\n\t<li>Prefer APIs over data.</li>\r\n\t<li>Start with DSLs.</li>\r\n\t<li>Always connect (and never enqueue).</li>\r\n\t<li>Create abstractions for information (i.e. wrap all data in specific objects/classes)</li>\r\n\t<li>Use static typing across subsystem boundaries.</li>\r\n\t<li>Put language semantics on the wire. (Instead of using a language-agnostic data language like json, edn, or hessian.)</li>\r\n\t<li>Write <em>lots</em> of unit tests.</li>\r\n\t<li>Leverage context.</li>\r\n\t<li>Update information in place.</li>\r\n</ol>\r\n#3 DSLs: When designing, always proceed in this order:\r\n<ol>\r\n\t<li>Design an information model</li>\r\n\t<li>Design an API</li>\r\n\t<li>Design DSL</li>\r\n</ol>\r\nPeople often start at 3 and neglect 3/2, f.ex. SQL is just a DSL without an API and no information model.<br><br>Small x big: It is not only important that you fix bugs or solve problems, you should also ask whether you are actually solving the big problems / defects. Some approaches help with small bugs / design problems but that is not enough.<br><br>Complexity: Work around problems in a layer above rather than fixing them where they are. Ex.: fixing shortcomings of Java in Clojure (f.ex. Java allows multiple instances of false) - duing this guarantees increased complexity.\r\n<h3>Paul Bellamy &amp; Martin Trojer: Using Clojure to Serve The Internet of Things</h3>\r\n<a href=\"https://github.com/martintrojer/euroclojure-demo\">https://github.com/martintrojer/euroclojure-demo</a> - including code for Arduion, clojure webapp collecting tweets, etc.<br><br>Xively started originally as a Rails app, storing both metadata and data from the customer's devices in PostgreSQL. This didn't work well since most devices sent data in the same time (full hour, ...) and Rails/PG did not handle the spikes well.<br><br>They have therefore replaced PG with Cassandra nad considered Node.js (but were discouraged by testimonials from large apps and callback hell) and Go (too new at the time) until they settled for Clojure b/c it was coold and had first-class quality driver for Cassandra (which alone got the performance 10* up).<br><br>They liked Leiningen (even for a Java app) and simple multithreading with pmap. Internally the app uses RabbitMQ.<br><br>Currently replacing REST in devices-server communication with better <a href=\"http://mqtt.org/\">Message Queue Telemetry Transport (MQTT)</a> and<br><br>Wins\r\n<ul>\r\n\t<li>Powerful abstractions - immutable data structures, Lisp power, ....</li>\r\n\t<li>Much more declarative than Rails</li>\r\n\t<li>Language aesthetics - elegant composability of core functions, ...</li>\r\n\t<li>Much better performance than Rails (but then, R. wasn't created for performance)</li>\r\n</ul>\r\nPains\r\n<ul>\r\n\t<li>JVM startup time - partially countd by using <a href=\"http://thinkrelevance.com/blog/2013/06/04/clojure-workflow-reloaded\">Stuart Sierra's Reload workflow</a> to minimize REPL restarts</li>\r\n\t<li>Hard to read / use stack traces (especially from anonymous functions in lazy collections)</li>\r\n\t<li>It is easy to get confusing version clashes in Leiningen when an app and its dependency depend on different versions of the same lib - whatever lands first on classpath is loaded (some lein. plugins may help?)</li>\r\n\t<li>Tooling is most mature around Emacs</li>\r\n\t<li>No debugger =&gt; println-based troubleshooting (ritz isn't there yet) (my tip: see <a href=\"https://github.com/MichaelDrogalis/night-vision\">night-vision.goggles/introspect-ns!</a>)</li>\r\n</ul>\r\n<h3>Clifton Cunningham (CEO) &amp; Jon Pither (dev): Newspaper Massacre</h3>\r\nLot of inspiring stuff here. Daily Mail had 14 years old legacy up with intertwined CMS, publishing platform, and Oracle DB, over 300k LoC of Java/JSP/JS that everybody feared to touch. They did two great things: (1) The CEO decided to foster teams that take end-to-end ownership,  have minimal make-your-own process, do not fear change. (2) They modified the old system to publish events via messaging (initially Mule) whenever anything important happened (new article, ...), these were stored together with the data as JSON in ElasticSearch.<br><br>Thanks to that, Jon &amp; Co. were able to create a Clojure app proof of concept that was able to render the non-trivial front page of Daily Mail in a week, without coupling to the old system. During the following 6 months, they were able to replace the publishing part of the software that has grown for 14 years.<br><br>Technologies:\r\n<ul>\r\n\t<li><a href=\"http://mustache.github.io/\">Moustache</a> for templating - it is cross-language, can also render in the browser for more dynamism, and is fron-end dev friendly</li>\r\n\t<li>Zookeeper and its Clojure wrapper <a href=\"http://avout.io/\">Avout</a> for shared configuration (=&gt; every service has atom(s) that get updated when the config is changed, can use Clojure's <a href=\"http://clojuredocs.org/clojure_core/clojure.core/add-watch\">add-watch</a> on the atoms to be able to react to the changes</li>\r\n\t<li>Riemann with Logstash and Graphite for monitoring exceptions and other events of interest</li>\r\n\t<li>Redis as a golden hammer :) for different things</li>\r\n\t<li>Memcached for pure data caching (which is perhaps not an ideal situation)</li>\r\n\t<li>Apache Camel (that replaced Mule) for integration and messaging (though not really happy with it)</li>\r\n</ul>\r\nFuture plans/ideas:\r\n<ul>\r\n\t<li>Use Datomic instead of ElasticSearch - it has a define schema (x amorphic JSON), it is possible to get snapshot of data at any time for troubleshooting, ...</li>\r\n\t<li>core.contracts and perhaps core.typed or Prismatic's Schema to make the data more defined</li>\r\n</ul>\r\nSome of the code lives at <a href=\"https://github.com/mailonline\">https://github.com/mailonline</a>\r\n<h3>Ryan Greenhall: Templating In Clojure</h3>\r\nNoteworthy:\r\n<ul>\r\n\t<li>Hiccup not suitable for fron-end devs not comfortable with Clojure</li>\r\n\t<li>Enlive breaks easily when relying on selectors and the structure of a page changes (though, reportedly, the proper use is predictor-based rather then selector-based)</li>\r\n\t<li><a href=\"https://github.com/ryangreenhall/clj-jade\">clj-jade</a> - Java+clojure implementation of <a href=\"http://jade-lang.com/\">Jade</a> templating, which is, if I understand it correctly, a combination of <a href=\"http://en.wikipedia.org/wiki/Haml\">HAML</a> (conscise syntax for HTML) and minimalistic templating</li>\r\n\t<li>Personally, I would also give a try to <a href=\"http://mustache.github.io/\">Mustache</a> for Clojure (if you can live with HTML's verbosity)</li>\r\n</ul>\r\nRelated and interesting: <a href=\"https://github.com/bitemyapp/clojure-template-benchmarks\">clojure-template-benchmarks</a> - many templating libs included.\r\n<h3>Christophe Grand: Megarefs</h3>\r\nGitHub: <a href=\"https://github.com/cgrand/megaref\">https://github.com/cgrand/megaref</a><br><br>Far more detailed <a href=\"http://teropa.info/blog/2013/10/16/megarefs.html\">notes by Tero Parviainen</a>.<br><br>As you might know, Datomic uses a single atom to hold its state. I have been wondering how to manage my state as a huge map in one atom (and atoms referenced by an atom seemed strange ...). Now Christophe has clearly thought about the same and came with a nice solution.<br><br>In the first iteration, megaref was just a combination of update-in and swap! but later got better by trying to avoid update conflicts on unrelated branches of the state tree/map (e.g. [:a :b] and [:a :c] as oppossed to the conflicting [:a :b] and [:a :b :c]) and being smart about what to protect against concurrenct access. In the backround, it can use atoms, STM, or (coming) agents to handle concurrent access to the map.<br><br>Unless your app is CPU bound, it is worth giving a try for holding its state.\r\n<h3>Frazer Irving: Enterprise integration with Clojure</h3>\r\nAbout the <a href=\"http://www.amazon.com/o/asin/0321200683/ref=nosim/enterpriseint-20\">Enterprise Integration Patterns</a> book: written by smart people but in a boring style and very prescriptive (i.e. \"this is how to do it\" instead of a discussion)<br><br>Experiences with integration platoforms/tools from Daily Mail:\r\n<ul>\r\n\t<li>Initially used Mule - but nobody understood or wanted to understand its tons of Spring XML files</li>\r\n\t<li>Currently using Apache Camel and its <a href=\"https://github.com/clumsyjedi/clj-camel-holygrail\">Holy Grail</a> Clojure DSL (with ActiveMQ underneath) but not perfectly happy with it\r\n<ul>\r\n\t<li>Camel implements Enterprise Integration Patterns from the book; the disadvantage is that it constraints thinking to these patterns only</li>\r\n\t<li>Hard things are hard (inst. of \"possible\")</li>\r\n\t<li>Positive: mature, plenty of adapters, ...</li>\r\n</ul>\r\n</li>\r\n\t<li>Tried following clojure tools\r\n<ul>\r\n\t<li><a href=\"https://github.com/ztellman/lamina\">Lamina</a> (a tool for \"describing and analyzing streams of data\") - not primarily for enteprise integration (EI); implements channels but currenlty supports only HTTP and websockets (not JMS, ...); good: visualization of what happened to a message, i.e. what &amp; why it went though</li>\r\n\t<li><a href=\"https://github.com/clojurewerkz/eep\">EEP</a> (Embedded Event Processing) - young and experimental, not designed for EI</li>\r\n</ul>\r\n</li>\r\n</ul>",
  "excerpt": ""
 },
 {
  "title": "Most interesting links of October ''13",
  "published": "2013-10-31 21:59:27",
  "postType": "post",
  "slug": "/2013/10/31/most-interesting-links-of-october-13/",
  "status": "publish",
  "tags": [
   "aws",
   "clojure",
   "ClojureScript",
   "design",
   "earth",
   "ecology",
   "Git",
   "innovation",
   "privacy",
   "science",
   "scrum",
   "security"
  ],
  "categories": [
   "General",
   "Languages",
   "Testing",
   "Top links of month"
  ],
  "content": "<h2>Recommended Readings</h2>\r\n<ul>\r\n\t<li><a href=\"http://qz.com/116196/google-engineers-insist-20-time-is-not-dead-its-just-turned-into-120-time/\">Google engineers insist 20% time is not dead—it’s just turned into 120% time</a> - it is interesting to see how has this evolved; \"<em>I have done many engineering/coding 20% projects and other non-engineering projects, with probably 20-40% producing “real” results (<strong>which over 7 years I think has been more than worth it for the company</strong>). But these projects are generally not rewarded.</em>\" [highlight mine]</li>\r\n\t<li><a href=\"http://www.tobiasfors.se/worst-daily-scrum-ever/\">The Worst Daily Scrum Ever</a> - a story whose bad part is a too common reality; if energy is low, nobody asks for / offers help, and people only report status / plans then you are doing the daily scrum wrong and should stop now (but it also documents a nice example of a good, effective scrum)</li>\r\n\t<li><a href=\"http://css.dzone.com/articles/why-responsive-design-waste\">Why Responsive Design is a Waste of Time</a> - a refreshingly critical take on responsive design; the author now aknowledges that it is sometimes worth the pain but the points are still valid - responsive design requires (lot of) extra work, the attempt to create a one-size-fits-all site of course adds considerable complexity (having two separate simple frontends might be better than one that is too complex), also many sites are good enough as they are (especially taking into account the capabilities of mobile browsers)</li>\r\n\t<li><a href=\"http://pythonsweetness.tumblr.com/post/64740079543/how-to-lose-172-222-a-second-for-45-minutes\">How to lose $172,222 a second for 45 minutes</a> - i.e. your bugs are likely not so serious after all :-) A financial company screwed big and ended up bankrupt. The cause? Chaotic DevOps, <strong>not removing old unused code</strong>, reusing a feature flag instead of creating a new one, lack of monitoring. The story in short: They deployed new trading code but failed to notice that it has not been deployed to one of the 8 servers; due to the flag reuse, the old, 10 years unused code has been activated instead. Due to the lack of monitoring they did not notice the cause, tried to roll back while leaving the flag enabled thus effectively activating the bad code on all the servers. =&gt; have proper automated and self-checking deployments, delete old code, do not repurpose old switches.</li>\r\n\t<li><a href=\"http://architects.dzone.com/articles/40-inappropriate-actions-take\">40 Inappropriate Actions to Take Against an Unlocked (Windows) PC</a> - good tips for promoting security and having fun at the same time; I shall keep this at hand :-)</li>\r\n\t<li><a href=\"https://groups.google.com/forum/m/#!topic/clojure/0I7u5yn01qU\">How to go about 'proving' why dynamically typed languages are better</a> - a cultivated and interesting discussion; as argueed, thinking in this direction is itself wrong and in different contexts, different languages will be more appropriate. I also like Phil Lord's \"Programming is a highly fashion-centric occupation for any number of reasons.\" and \"For me, the main advantage is that you are not forced to build complex hierarchies just to support the type system ([..]), and that having only a few abstractions makes it worthwhile adding lots of functions operating over them.\" and L. Petit's \"IMHO, the question is irrelevant. It implicitly assumes that statically typed vs dynamically typed is a black / white choice, and that either 'static wins over dynamic' or 'dynamic wins over static' will be a true statement whatever the context.\" Also a good observation that types are only a subset of function contract enforcement and one of possible implementations.\r\n<ul>\r\n\t<li><a href=\"http://cdsmith.wordpress.com/2011/01/09/an-old-article-i-wrote/\">What to Know Before Debating Type Systems</a> - explanation of common misunderstandings that hinder discussions of static x dynamic typing including a classification of type systems</li>\r\n</ul>\r\n</li>\r\n\t<li><a href=\"/2013/10/28/the-failure-of-governmental-it-learnings-from-healthcare-gov/\">The Failure of Governmental IT (Learnings From HealthCare.gov)</a> - links to a few really good articles about the problems with governmental IT in general and my summary of them</li>\r\n\t<li><a href=\"http://mobile.businessweek.com/articles/2013-10-03/facebooks-new-data-center-in-sweden-puts-the-heat-on-hardware-makers\">Inside the Arctic Circle, Where Your Facebook Data Lives</a> - the designs of data centers used to be proprietary secrets until Fb developed its own and open-sourced them, enabling many Asian manufactures to start creating cheaper datacenters and thus started a revolution in this domain. Facebook's data centers are not general purpose but suitable ot the kind of work they need, but it is still widely applicable. Cool to see how they use natural conditions to get energy needs down and make HW that fits best their needs - that is what I call innovation!</li>\r\n\t<li><a href=\"http://www.academia.edu/\">Academia.edu</a> (via <a href=\"http://twitter.com/RiczWest\">@RiczWest</a>) - a rich source of free research papers - just register as an independant researcher; also lean/agile/systems thinking and other interesting topics</li>\r\n\t<li><a href=\"http://www.bitnative.com/2013/10/07/writing-code-know-your-boundaries/\">Writing Code? Know Your Boundaries</a> - an inspiring way of thinking; we use many technologies in combination (HTML, CSS, JS, SQL, server-side language, ...) and \"<em>the risk for picking the wrong tool for the job is strongest near the boundaries</em>\"; a discussion of the aforementioned boundaries with examples follows, e.g.: \"<em>Avoid putting HTML in JavaScript strings for 'poor man’s templating</em>'\", messing up SQL with html (\"<code>SELECT</code> <code>'&lt;strong&gt;'</code> <code>+ Username + </code><code>'&lt;/strong&gt;'</code> <code>FROM</code> <code>Users</code>\"), CSS+HTML: using inline styles, SQL+server-side: string concatenation to create dynamic SQL queries, \"<em>writing dynamic JavaScript in a string on the server</em>\". I shall keep this in mind!</li>\r\n\t<li>Johannes Brodwall: <a href=\"http://johannesbrodwall.com/2013/09/16/a-canonical-web-test/\">A canonical web test</a> - a simple web app end-to-end smoke test - using an embedded Jetty, a test DB (preferably in-memory), WebDriver to test it (simple: browser.get(\"/people\"), assertThat(browser.findElement(&lt;person id&gt;.contains(&lt;person's name&gt;)); simple, nice, useful</li>\r\n</ul>\r\n<h3>Learning</h3>\r\n<ul>\r\n\t<li><a href=\"http://pcottle.github.io/learnGitBranching/?demo\">LearnGitBranching</a> - an online game to learn branching &amp; rebase in git; use the menu in the lower-right corner to navigate between the levels etc. You can also execute commands \"show goal\", \"hint\", \"level\" to navigate around; pretty cool and great for learning the command line commands</li>\r\n</ul>\r\n<h3>Society &amp; people</h3>\r\nNot a typical topic I share here but really worth it this time.\r\n<ul>\r\n\t<li><a href=\"http://www.theherald.com.au/story/1848433/the-ocean-is-broken/\">The ocean is broken</a> - a saddening story worth reading to learn what does your tuna sandwitch cost and where does all the plastic we use end up. From a sailing trip from Melbourne to US where there were plenty of fish (and birds) 10 years ago - and 2 this year, killed to a noticable degree by huge fishing ships that catch tuna - and kill and throw away all the other \"junk\" fish. Nowadays fish are replaced by plastic and other waste that actually prevents usage of the engine unless somebody can watch for dangerous nets and ropes leftovers. Earth, where are you falling to?</li>\r\n\t<li>The Guardian: <a href=\"http://www.theguardian.com/world/2013/oct/20/young-people-japan-stopped-having-sex\">Why have young people in Japan stopped having sex?</a> - sad and interesting to observe what happens when the system is set up so that people \"can't be bothered\" to have inter-sexual relationships, partnership, and children. Japan needs a good deal of systems thinking to fix its broken society where women do not want children because it would cost them their career and neither men nor women are willing to subjects themselves to the social pressure and demands associated with relationships.</li>\r\n\t<li>The Guardian: <a href=\"http://www.theguardian.com/global-development/2013/oct/17/29-million-people-enslaved-global-index\">29 million people enslaved, says first global index on slavery</a> - welcome to the 21st century! The leading slave countries are India (14M), China (3M), Pakistan (2M). Also, <a href=\"http://www.theguardian.com/world/2013/sep/25/revealed-qatars-world-cup-slaves\">slaves are building the world cup stadion in Qatar</a>.</li>\r\n\t<li><a href=\"http://www.nybooks.com/articles/archives/2013/sep/26/jellyfish-theyre-taking-over/?pagination=false\">They’re Taking Over! - how we managed to destroy sea ecosystems and helped the now unstoppable return of jellyfish</a> - Jellyfish are evidently very veried and extemely resilient and have been hold at bay only by rather complex ecosystems that we managed to destabilize so much that Jellyfish are on their way back to ruling all the sees again (destroying the rests of the ecosystems - i.e. fish - on the way); a sad future for the sea, Earht, and us</li>\r\n</ul>\r\n<h2>Clojure Corner</h2>\r\n<ul>\r\n\t<li><a href=\"https://groups.google.com/forum/m/#!topic/light-table-discussion/BIyWHnRcoWc\">LightTable 0.5.9 got elementary paredit commands</a></li>\r\n\t<li><a href=\"https://github.com/mcohen01/amazonica\">Amazonica</a>: A comprehensive Clojure client for the entire Amazon AWS api - best with a REPL!</li>\r\n\t<li><a href=\"http://michaeldrogalis.tumblr.com/post/65274692089/clojure-understood-the-rush-hour-platform\">Clojure Understood: the Rush Hour Platform</a> - application of the design best practices promoted in the Clojure community (separation of concerns, simplicity, ...) on a project - \"highly accurate vehicle traffic simulations\"; I have only started reading it but it looks highly interesting</li>\r\n\t<li><a href=\"http://www.infoq.com/clojure/\">Clojure content at InfoQ</a> - articles, news, interviews, presentations etc.</li>\r\n\t<li><a href=\"https://kotka.de/blog/2013/10/A_bitter_taste.html\">A bitter taste [of EuroClojure]</a> - we as a community must embrace diversity and stop fostering our egos by mocking other than our holy editor (and, I would add, by mocking other languages and in general mocking whatever); respect and open minds, please!</li>\r\n\t<li><a href=\"https://github.com/noprompt/garden\">Garden - Clojure alternative to scss/less</a> - still needs time to mature and gain tooling support but it is cool that it exists</li>\r\n\t<li>C. Emerick's <a href=\"https://github.com/cemerick/austin\">Austin, the ClojureScript REPL over nREPL</a> - 1) Start nREPL (via lein repl, from your editor...), 2.a) Execute austin's exec to start a ClojureScript REPL in it, backed by headless PhantomJS or a real browser - or, alternatively, 2.b) create a C.S. REPL connected to your webapp, as described in the <a href=\"https://github.com/cemerick/austin/tree/master/browser-connected-repl-sample\">browser-connected-repl-sample</a>. You should watch <a href=\"http://www.youtube.com/watch?v=a1Bs0pXIVXc\">this 8 min demo</a>.</li>\r\n</ul>\r\n<h2>Tools/Libs</h2>\r\n<ul>\r\n\t<li><a href=\"http://inspiretrends.com/10-amazing-famous-google-tools/\">10 Amazing But Not-So-Famous Google Tools</a> - f.ex. 600+ open-source <a href=\"http://www.google.com/fonts/\">Google Fonts</a>, <a href=\"http://inspiretrends.com/10-amazing-famous-google-tools/\">Google Sky</a> - map of &lt;guess what&gt;, <a href=\"http://www.google.com/publicdata/\" target=\"_blank\" rel=\"nofollow\">Google Public Data Explorer</a></li>\r\n</ul>\r\nMac:\r\n<ul>\r\n\t<li><a href=\"https://blog.whitehatsec.com/introducing-whitehat-aviator-a-safer-web-browser/\">WhiteHat Aviator</a> – A Safer Web Browser - WhiteHat, a well-known security company, has released a browser that aims at improving privacy by preventing user tracking (f.ex. but not sending referral URL) and blocking ads even at the cost of occassional slight discomfort, i.e. something that the mainstream browsers are not interested in. So far for OS X only.</li>\r\n\t<li><a href=\"https://github.com/hschmidt/EnvPane\">EnvPane</a> - a preference pane for environment variables for Mac OS X 10.8 (Mountain Lion) - set env. vars for GUI/terminal apps, no need to log out upon change</li>\r\n</ul>\r\n<h2>Favorite Quotes</h2>\r\n<blockquote>Weinberg: Bureaucracy is what we do when we no longer remember why we are doing it\r\n<em>- <a href=\"https://twitter.com/QualityFrog/status/393435929110523904\">via Ben Simo</a>, no source specified so it may be fake but anyway it is valid</em></blockquote>",
  "excerpt": ""
 },
 {
  "title": "The Failure of Governmental IT (Learnings From HealthCare.gov)",
  "published": "2013-10-28 20:57:54",
  "postType": "post",
  "slug": "/2013/10/28/the-failure-of-governmental-it-learnings-from-healthcare-gov/",
  "status": "publish",
  "tags": [
   "agile",
   "government",
   "management"
  ],
  "categories": [
   "General"
  ],
  "content": "The failure of Healthcare.Gov has been discussed a lot but the main causes of the failure are unrelated to the project or to technology and apply similarly to other governments / large projects.<br><br>According to some reasonable articles, the main problems were:\r\n<ol>\r\n\t<li>Byzantine procurement process - those with the best lawyers and experience, not the most capable ones get the job</li>\r\n\t<li>Size - the project is \"too important to fail\" - and thus also too big to succeed; +- 55 contractors creating SW with fixed date, integrating hundreds of insurence providers and some 36 states and various agencies; big-bang style of development and deployment</li>\r\n\t<li>Fragmented responsibility and lack of ability - no one both with enough knowledge and power responsible for the whole project (and lack of the best talent in government IT in general), responsibility spread across tens of contractors and officials likely driven by cover-my-ass motivation (e.g. the procurement officer interested in selecting the cheapest offer that checks all the checkboxes instead of the best one - because who can fire her/him for doing that?)</li>\r\n\t<li>Niagara Falls of waterfall development, constrained by rules and bureaucracy to immobility - extensive legislation, rules, and security requirements together with a fear/blame-driven organization or not good for agile approaches</li>\r\n</ol>\r\nBTW, according to L. Hart (below), 0 federal projects over $5M were delivered on time, only 6.4% of those over $10M have succeeded and full 40% of such projects were canceled. So, under those circumstances, Healthcare.Gov is actually a small miracle.<br><br>Sources:\r\n<ul>\r\n\t<li>Laurence Hart: <a href=\"http://wordofpie.com/2013/10/22/healthcare-gov-fiasco-shows-the-problems-in-federal-it/\">Healthcare.Gov Fiasco Shows the Problems in Federal IT</a> - insight into the broken procurement and many obstacles any federal IT project faces by a person with rich experience with it</li>\r\n\t<li>Merici Vinton: <a href=\"http://techpresident.com/news/24451/9-things-you-should-know-debating-healthcaregov-someone-who-actually-launched-successful\">9 Things You Should Know Before Debating HealthCare.gov, From Someone Who Actually Launched a Successful Government Website</a> - an important story: it is possible to launch a successful government website but it requires special effort and approach. The main advice is:\r\n<ol>\r\n\t<li>\"Never build a website that's too big to fail; instead, start small\" - the CFPB \"launched a pretty basic, consumer facing public website in six to eight weeks\" then gradually added intake for complains regarding various products, one by one. \"We did each rollout in small chunks and built more and more based on what we learned with each integration.\"</li>\r\n\t<li>\"Let's do open source when possible (preferably always).\"</li>\r\n\t<li>\"Let's have in house strategy, design, and tech.\" - i.e. do not outsorce those</li>\r\n</ol>\r\nAlso, involve IT people in the procurement and hiring.</li>\r\n\t<li>Tim Murphy: <a href=\"http://m.motherjones.com/politics/2013/10/obamacare-healthcaregov-harper-reed\">Could Obama's Campaign Tech Gurus Fix Healthcare.gov? Let's Ask 'Em!</a> - the answer is no, mostly not - due to the sheer size, the procurement process, and all the legislation. Quotes the campaign's CTO's twitter: \"The 'secret' here is that the problems are not about tech at all,\" he tweeted on Monday. \"It is about procurement. I can't fix that with my tech chops or my team.\"</li>\r\n</ul>\r\nBy the way, the Government Digital Service team in the UK has become \"recently\" famous for bringing effective IT to the government. It is interesting to read <a href=\"http://mikebracken.com/blog/the-strategy-is-delivery-again/\">about the UK DS strategy</a>, based on delivery - frequent, iterative, repeatedly successfull.<br><br>Thanks to <a href=\"https://twitter.com/flowchainsensei\"><s>@</s>flowchainsensei</a> and <a href=\"https://twitter.com/timoreilly\"><s>@</s>timoreilly</a> for the links.",
  "excerpt": ""
 },
 {
  "title": "Most interesting links of November ''13",
  "published": "2013-11-30 21:59:50",
  "postType": "post",
  "slug": "/2013/11/30/most-interesting-links-of-november-13/",
  "status": "publish",
  "tags": [
   "agile",
   "book",
   "clojure",
   "continuous_deployment",
   "diy",
   "legacy",
   "mongodb",
   "nodejs",
   "SbE",
   "scala",
   "security"
  ],
  "categories": [
   "General",
   "Languages",
   "Top links of month"
  ],
  "content": "<h2>Recommended Readings</h2>\r\nSome interesting topics this time despite me spending lot of time on the <a href=\"https://class.coursera.org/reactive-001/\">Principles of Reactive Programming</a> course: Java x Node.js, REST x other future-proof architectures, scary legacy code. Of course, also plenty of Clojure.<br><br>People, organizations, teams, development:\r\n<ul>\r\n\t<li><a href=\"http://www.thinkers50.com/blog/chris-argyris-1923-2013-appreciation/\">Chris Argyris (1923-2013): An Appreciation - Thinkers 50</a> - recently departed Ch. Argyris is a person whose work you should know, if a bit interested in learning and organizations and how they (dis)function; and since we all work in organizations and want our work to be pleasant, this means all of us. We all want to work in orgs that do double-loop learning, i.e. they actually evovle as they learn. \"<em>Argyris argued that organizations depend fundamentally on people and that personal development is and can be related to work.</em>\" Now stop and go read it!</li>\r\n\t<li>Bob Marshall: <a href=\"http://flowchainsensei.wordpress.com/2013/10/12/the-antimatter-principle/\">The Antimatter Principle</a> - \"<em>the only principle we need for becoming wildly effective at collaborative knowledge work</em>\" - can be summarized as \"attend to folks' needs\" (importantly, including your own) =&gt; find out what people actually need, interpret their behavior (including anger, seemingly irrational or stupid requests etc.) in terms of needs; mastering this will make you excell in communication and effective work. Read the post to find out more.</li>\r\n\t<li><a href=\"http://www.fibonaccikittens.com/2013/11/26/one-idea-one-commit/\">It’s a state of mind: some practical indicators on doing agile vs. being agile</a> - are you agile or are just \"doing agile\"? Read on ti find out, if you dare! F.ex. \"<em>Non Agile teams have a process that slows the review of the changes.</em>\" Cocnlusion: \"<em>An Agile mindset is just that – a state of mind, a set of values. Its a constant questioning, and an opening up to possibilities. Its a predisposition to produce great things.</em>\"</li>\r\n\t<li><a href=\"http://johannesbrodwall.com/2013/11/27/humble-architects/\">Johannes Brodwall:  Humble architects</a> - how to avoid being an architect that does more harm than good, as so many out there? Some tips: Don't assume stupidity, Be aware that you might be wrong, Be careful with technology (i.e. simplicity beats everything; applies so much to us developers too!), Consistency isn't as important as you think (or beware context), Tactical reuse in across systems is suboptimization (i.e. reuse has a cost), separate between (coding) rules and dogma (i.e. is that way unsafe, incomprehensible, or just a heresy w.r.t. a dogma?) Very valuable insights into creating good technical solutions and teams that work.</li>\r\n\t<li><a href=\"http://lizkeogh.com/2013/11/30/the-dream-team-nightmare-a-review/\">Liz Keogh's The Dream Team Nightmare: a Review</a> - a very good review of this adventure-style book about coaching \"agile\" teams through (around?) common pitfalls, provides a good base for deciding whether you shall read the book (Liz essentially says yes)</li>\r\n\t<li><a href=\"http://www.fibonaccikittens.com/2013/11/26/one-idea-one-commit/\">Fibonacci Kittens: One Idea One Commit</a> - a short story of coming from biannual releases to frequent release of individual features; I link to this primarily to spread optimism, if this company managed it then, perhaps, we other can too?</li>\r\n\t<li><a href=\"http://www.thinkers50.com/blog/chris-argyris-1923-2013-appreciation/\">The Eternal Struggle Between Business and Programmers</a> - \"Business: More features! Now! Programmers: More refactoring! Now!\" How can we resolve this eternal conflict of needs? This post reveals how the two parties can find a common ground and mutual understanding (beware, everybody must give up on something) and thus work together rather than against each other.</li>\r\n</ul>\r\nCoding, architecture, legacy\r\n<ul>\r\n\t<li><a href=\"http://z.caudate.me/why-the-future-is-not-restful/\">Why the future is NOT RESTful</a> - always refreshing to read something against the mainstream; \"<em>REST is not fit for the next generation of smart client applications because it has not been designed for smart clients.</em>\" According to the author, a smart client app stack needs: \"1. persistence (storage and query), 2. documents/orm (conversion to tree-like datastructures), 3. data authorization (once authenticated), 4. pub/sub (websocket communications), 5. client db (client-side caching and querying), 6. templating (presentation level)\" <a href=\"http://www.meteor.com/\">Meteor.js</a> has nearly all but #3 thanks to mongodb (1+2), <a href=\"http://www.meteor.com/blog/2012/03/21/introducing-ddp\">dpp</a> (4), mongo on the client (5), <a href=\"http://www.meteor.com/blog/2012/08/31/introducing-spark-a-new-live-page-update-engine\">spark</a> (6). The author considers a similar but Clojure-based stack (with Datomic, Angular etc.) and looks at authorization possibilities. \"<em>Secured, personalised, CRUD operations are the future to a more simplified web.</em>\" We may agree or not but it certainly is worth reading.</li>\r\n\t<li>Michael Feathers (of Working Effectively With Legacy fame): <a href=\"http://michaelfeathers.typepad.com/michael_feathers_blog/2013/11/unconditional-programming.html\">Unconditional Programming</a> - \"<em>Over and over again, I find that better code has fewer if-statements, fewer switches, and fewer loops. Often this happens because developers are using languages with better abstractions. [..] The problem with control structures is that they often make it easy to modify code in bad ways.</em>\" Includes a nice example of replacing if-else with much more readable and safer code.</li>\r\n\t<li><a href=\"http://www.viva64.com/en/a/0083/\">The Quality of Embedded Software, or the Mess Has Happened</a> - an interesting and scary read about terrible spaghetti code (and hardware) that makes some Toyotas to accelerate when the driver tries to break; 11,000 global variables, the key function showing so high cyclomatix complexity that \"<em>makes it impossible not only to test but even maintain this program in any way.</em>\" Then 80k violations of the car industry coding standard cannot surprise. And a safety control that does not work. Interesting that a great manufacturer may have so terrible IT (and Toyota isn't the only one).</li>\r\n\t<li><a href=\"http://mortoray.com/2013/11/27/the-string-type-is-broken/\">The string type is broken</a> - the String type is M. Feathers' favourite example of a leaky abstraction - most languages fail to process/split/count less common Unicode characters properly, the fact that String is implemented as a series of bytes leaks through (UTF-16 langs like Java); worth reading to be aware of the limitations</li>\r\n</ul>\r\nLanguages\r\n<ul>\r\n\t<li><a href=\"http://yogthos.net/blog/49-Why+I%27m+Productive+in+Clojure\">Why I'm Productive In Clojure</a> - some interesting points about simplicity, consciousness, interactive development, power without overwhelming fatures, etc. \"<em>With it [Clojure] I can always easily derive a solution to a particular problem from a small set of general patterns. [..] However, the number of ways that these concepts can be combined to solve all manner of problems appears to be inexhaustible.</em>\"</li>\r\n\t<li><a href=\"https://www.paypal-engineering.com/2013/11/22/node-js-at-paypal/\">Node.js at PayPal</a> - PayPal is switching from Java to Node.js (among others to promote language consistency) and, as a part of that, has implemented the same app in Node and Java; results: Node was done earlier, had less code, performed better (though, as <a href=\"https://twitter.com/dkvasnickajr/status/406727039169732608\">Daniel Kvasnička pointed out</a>, \"<em>Comparing Node.js and servlet-based archs is not fair... compare Node with <a href=\"http://vertx.io/\">@vertx_project</a></em> and you'll get a whole different story ;)\"; also, as <a href=\"https://twitter.com/headius/status/411272451536846849\">Charles Nutter said</a>, \"<em>The <a href=\"https://twitter.com/PayPal\"><s>@</s>PayPal</a> numbers for their Java to Node move are absurd. A JVM app doing 1.8 pages/s isn't slow...it's broken.</em>\")</li>\r\n\t<li><a href=\"http://www.ibm.com/developerworks/java/library/mo-nodejs-1/index.html\">IBM: Developing mobile apps with Node.js and MongoDB, Part 1: A team's methods and results</a> - also IBM has implemented the same (REST) app once with Java and DB2, once with Node and Mongo where Node+Mongo required less work and performed better; one of the great wins was having JSON as a native structure everywhere instead of transforming from/to it so Mongo is, in my opinion, an important factor in this particular case</li>\r\n\t<li><a href=\"http://dynamicsofprogramming.blogspot.ch/2013/11/benefits-of-scala-in-cs1.html\">Dynamics of Programming: Benefits of Scala in CS1</a> - reasons for and experiences with using Scala in an introductory computer science course, worth reading; some of the advantages over Java are consistency (.asInt on String and Double vs. casting/parsing, no \"primitive\" types), REPL with time inference good for learning, functional style enables focus on what rather than how; quite persuasive arguments</li>\r\n</ul>\r\nSecurity\r\n<ul>\r\n\t<li><a href=\"http://www.renesys.com/2013/11/mitm-internet-hijacking/\">The New Threat: Targeted Internet Traffic Misdirection</a> - did you know that internet traffic to any site can be made to go through a particular server without anybody noticing? This has been observed repeatedly in the wild, for banks and other sites. Rather make sure you use strong encryption (NSA-approved, of course ;)).</li>\r\n\t<li><a href=\"http://arstechnica.com/security/2013/10/a-relatively-easy-to-understand-primer-on-elliptic-curve-cryptography/\">A (relatively easy to understand) primer on elliptic curve cryptography</a> - Everything you wanted to know about the next generation of public key crypto - you cannot just read this, you have to study it, which I did not; but it looks good and I guess the time will come when I will come back to it</li>\r\n</ul>\r\nOther\r\n<ul>\r\n\t<li>Prezi:<a href=\"http://prezi.com/vs4kqcgamhy5/intro-to-specification-by-example/\"> Intro to Specification By Example - a journey, not a destination</a> (W. King; via <a href=\"http://twitter.com/mortenberg\">@mortenberg</a>) - a nice presentation that can be used to introduce SbE, with focus on the important things (collaboration) and some practical experiences</li>\r\n\t<li><a href=\"http://katrinatester.blogspot.co.nz/2013/11/mind-maps-and-automation.html\">Mind Maps and Automation</a> (via <a href=\"https://twitter.com/gojkoadzic\"><s>@</s>gojkoadzic</a>) - a smart idea to use a mind map to display break-down of the status of testing of a system (red/orange/green) instead of just one indicator, based on the observations that managers &amp; co. never drill down below the first indicator</li>\r\n\t<li><a href=\"http://kosmothink.com/2013/11/13/2636/\">MIT Technology Review: 10 Breakthrough Technologies 2013</a> - for those interested in the future - f.ex. ultra-efficient solar power, supergrids - highly efficient DC power grids, additive manufacturing - on the verge of using 3-D printing to make jet parts, memory implants</li>\r\n\t<li><a href=\"http://sugru.com/\">Sugru - a genius DIY material</a> for improving anything; also, very nice <a href=\"http://sugru.com/story\">A partial visual history of sugru</a> (via Bjørn Remseth)</li>\r\n</ul>\r\n<h2>Clojure Corner</h2>\r\n<ul>\r\n\t<li><a href=\"https://github.com/stuartsierra/component\">Stuart Sierra's Component</a> - a library for making it easier to implement Stuart's <a href=\"http://thinkrelevance.com/blog/2013/06/04/clojure-workflow-reloaded\">reloadable workflow</a>; a component is something that can be started, stopped, and depend on other components so that it is easier to do interactive REPL development</li>\r\n\t<li>Logan Linn: <a href=\"http://loganlinn.com/blog/2013/11/18/clojureconj-2013/\">Clojure/conj 2013</a> - a pretty good overview of the conference</li>\r\n\t<li><a href=\"http://caribou.github.io/caribou/docs/outline.html\">Caribou</a> - \"<em>the kernel of usefulness that has emerged from years of this basic practice</em>\"- a new Clojure web framework - seems to be interesting</li>\r\n\t<li><a href=\"http://cemerick.com/2013/11/18/results-of-the-2013-state-of-clojure-clojurescript-survey/\">Results of the 2013 State of Clojure &amp; ClojureScript survey</a> and drill-down into <a href=\"http://tech.puredanger.com/2013/11/19/state-of-clojure-language-features/\">what features people want</a> - the most interesting fact is how many more participants use Clojure in production than last year and perhaps also the relatively wide adoption of Datomic among the respondents. Light Table has become the 3rd most popular dev. env., after Emacs and Vim. Some of the most mentioned language features requested were types (=&gt; core.typed, Prismatic's Schema), better error reporting (=&gt; <a href=\"https://github.com/scgilardi/slingshot\">slingshot</a>, <a href=\"https://github.com/MichaelDrogalis/dire\">dire</a>, <a href=\"https://github.com/mmcgrana/clj-stacktrace\">clj-stacktrace</a>, <a href=\"https://github.com/AvisoNovate/pretty\">io.aviso:pretty</a>, etc.), debuger (though progress is being made)</li>\r\n\t<li><a href=\"http://www.packtpub.com/clojure-high-performance-programming/book#overview\">Book: Clojure High Performance Programming</a></li>\r\n\t<li><a href=\"http://java.dzone.com/articles/improving-clojure-feedback\">Improving Clojure Feedback : Stack Traces</a> - making Clojure stacktraces more usable by filtering out noise and linking to relevant content - <a href=\"https://github.com/AvisoNovate/pretty\">io.aviso:pretty</a>,  <a href=\"https://github.com/AvisoNovate/twixt\">io.aviso:twixt</a></li>\r\n\t<li>Clojure Dev discussion: <a href=\"https://groups.google.com/forum/m/#!topic/clojure-dev/lWXYrjaDuIc\">Hashing strategies - Executive summary</a> - \"<em><em></em>In Clojure, however, it is far more common than in Java to use longs, vectors, sets, maps and compound objects comprised of those components (e.g., a map from vectors of longs to sets) as keys in other hash maps.  It appears that Java’s hash strategy is not well-tuned for this kind of usage.  Clojure’s hashing for longs, vectors, sets, and maps each suffer from some weaknesses that can multiply together to create a crippling number of collisions.<em></em></em>\" Ex.: An implementation of N-Queens took forever, spending most time on hash collisions. But be calm, smart Clojurians are working on a solution.</li>\r\n\t<li><a href=\"http://blog.datomic.com/2013/11/datomic-pro-starter-edition.html\">Datomic Pro Starter Edition</a> - Datomic with all storages, Datomic Console, a year of updates, full Datomic programming model; limitations: no HA transactor, no integrated memcached, max 2 peers and 1 transactor</li>\r\n</ul>\r\n<h2>Tools/Libs</h2>\r\n<ul>\r\n\t<li><a href=\"http://www.airpair.com/\">AirPair.com</a> - a new site that enables developers to get help from other devs via remote pairing, code review, code mentoring etc. - a good opportunity to get help / help others (and earn something); I haven't tried it but it sounds pretty interesting</li>\r\n</ul>\r\nMongoDB web stacks\r\n<ul>\r\n\t<li><a href=\"http://www.meteor.com/\">Meteor</a>: JS frontend + MongoDB backend with changes in the DB pushed live to the clients, i.e. MongoDB is used both as the \"application server\" and storage. It seems great for apps where users need to collaborate in real-time with each other, certainly great for quick proof of concepts etc.; worth checking out; it also comes with free (at least for start?) hosting so really good for prototyping - \"a<em>n open-source platform for building top-quality web apps in a fraction of the time.</em>\" The <a href=\"www.meteor.com/screencast\">intro screencast</a> will give you a good overview (10 min).</li>\r\n\t<li><a href=\"http://mean.io/\">Mean.io</a> - MEAN (Mongo, Express, Angular, Node) stack Boilerplate - frontend, backend and storage using the same language and some of the most popular technologies (not that popular = best fit for you :)); it seems to be very new but since it just glues together 4 popular and documented technologies, that should not be an obstacle. There is an <a href=\"http://blog.mongodb.org/post/49262866911/the-mean-stack-mongodb-expressjs-angularjs-and\">intro on the MongoDB blog</a>.</li>\r\n</ul>\r\nOther\r\n<ul>\r\n\t<li><a href=\"http://www.busybox.net/\">BusyBox</a> (get <a href=\"http://intgat.tigress.co.uk/rmy/busybox/index.html\">latest win binary</a> from Tigress.co.uk) - reportedly a better POSIX env for Windows than gow, Cygwin, et al.</li>\r\n</ul>\r\n<h2>Favourite Quotes</h2>\r\n<blockquote>[..] no organization should exist unless it is \"of service\" to its employees, its customers, its community.\r\n<em>- <a href=\"https://twitter.com/tom_peters/status/406081167453343744\">@Tom_Peters 28/11</a></em></blockquote>\r\n<blockquote>I hope you'll agree that there is a certain amount of irony involved in having to write repetitive code\r\n- <em>Dmitri Sotnikov in <a href=\"http://yogthos.net/blog/49-Why+I%27m+Productive+in+Clojure\">Why I'm Productive In Clojure</a></em></blockquote>\r\nHappy teams are productive teams but:\r\n<blockquote>Morale is 95% a function of the prevailing system (the way the work works). Which in turn is a function of the prevailing collective mindset\r\n- <a href=\"https://twitter.com/flowchainsensei/status/399498969686233088\">@flowchainsensei Nov 10th</a></blockquote>",
  "excerpt": ""
 },
 {
  "title": "How I Learned to Avoid Magical Dependency Injection And Love Plain Java",
  "published": "2013-11-27 15:49:47",
  "postType": "post",
  "slug": "/2013/11/27/how-i-learned-to-avoid-magical-dependency-injection-and-love-plain-java/",
  "status": "publish",
  "tags": [
   "cdi",
   "design",
   "DI",
   "REST",
   "simplicity"
  ],
  "categories": [
   "j2ee",
   "Testing",
   "Uncategorized"
  ],
  "content": "A short story about the complexity of magical frameworks and dependency injection with a happy ending, featuring Resteasy, CDI, and JBoss.<br><br>Once upon time, I have created a JAX-RS webservice that needed to supply data to a user's session. I wanted to be fancy and thus created a <code>@Singleton</code> class for the exchange of information between the two (since only a user request serving code can legally access her session, a global data exchange is needed). However sharing the singleton between the REST service and JSF handler wasn't so easy:\r\n<ul>\r\n\t<li>Originally, the singleton was generic: <code>OneTimeMailbox&lt;T&gt;</code> - but this is not supported by CDI so I had to create a derived class (annotated with <code>@Named @Singleton</code>)</li>\r\n\t<li>While everything worked in my Arquillian test, at runtime I got NullPointerException because the <code>@Inject</code>-ed mailbox was null in the service, for reasons unclear. According to the internets, <a href=\"http://michalostruszka.pl/blog/2012/10/31/resteasy-cdi-integration/\">CDI and JAX-RS do not blend well</a> unless you use ugly tricks such as annotating your service with <code>@RequestScoped</code> (didn't help me) or use JBoss' <a href=\"https://community.jboss.org/wiki/RESTEasy-CDIIntegration\">resteasy-cdi</a> module.</li>\r\n</ul>\r\nFinally I got fed up by all the complexity standing in my way and reverted to plain old Java singleton (<code>OneTimeMailbox.getInstance()</code>) while making testing possible with multiple instances by having <del>a setter</del><ins> an alternative constructor</ins> taking the mailbox on each class using it (the service and JSF bean) (using a constructor might be even better).<br><br>Result? Actually better testability and simpler code.<br><br>Bjørn Borud and Johannes Brodwall were right - <a href=\"http://blog.borud.no/2013/03/gorging-on-java-frameworks-and.html\">plain old Java is better than magical frameworks</a> and <a href=\"http://johannesbrodwall.com/2010/11/10/this-dependency-injection-madness-must-end/\">magical DI is evil</a>. (Though they would diapprove of JBoss and likely prefered if I used a plain servlet instead of JAX-RS for my very simple case.)<br><br><strong>Update</strong>: As <a href=\"https://twitter.com/kolman/status/405745218768486400\">pointed out by Daniel Kolman</a> now and others previously, dependency injection itself isn't bad (<a href=\"https://twitter.com/bodil/status/405748891691548672\">though some would argue</a>), it is only magic DI that is a problem. You can well do DI yourself using plain old Java - see <a href=\"http://comoyo.github.io/blog/2013/02/06/the-inverse-of-ioc-is-control/\">Bakksjø: The inverse of IoC is Control</a>, <a href=\"http://blacksheep.parry.org/wp-content/uploads/2010/03/DIY-DI.pdf\">Perry: Do-It-Yourself Dependency Injection</a> (pdf; quote: \"<em>[..] shows how dependency injection can be </em><em>accomplished without any framework. The same benefits provided by frameworks can be realized using </em><em>“do-it-yourself” (DIY) handcrafted code.</em>\"; <a href=\"http://misko.hevery.com/2010/05/26/do-it-yourself-dependency-injection/\">recommended by</a> Google's test master Miško Hevery who is a fan of DI because it helps with testability).",
  "excerpt": ""
 },
 {
  "title": "Code Is Cheap, It''s Knowledge Discovery That Costs",
  "published": "2013-12-06 20:09:57",
  "postType": "post",
  "slug": "/2013/12/06/code-is-cheap-its-knowledge-discovery-that-costs/",
  "status": "publish",
  "tags": [
   "development",
   "opinion"
  ],
  "categories": [
   "SW development"
  ],
  "content": "If we knew exactly what code needs to be written, what needs to be done and how it can be done, we would need very little time to write it. It is the discovery of the knowledge what to build and how to build it that takes all the time. Yet non-developers usually see it as an unacceptable waste to write and then throw away - and perhaps rewrite - code.<br><br><!--more--><br><br><h2>Conclusion</h2><br><br>Do not hesitate to write throw-away code - proofs of concepts, spikes, experiments etc. - and then actually throw it away. Remember the difference between the cost of code typing and knowledge discovery. Hopefully it will make it easier to justify it to non-devs. Especially given that a N+1 attempt usually yields a better result than the previous one since we have learnt something.<br><br>Resist the evil temptation to build further on your \"throw-away \" code. You wrote it optimizing for learning, not for good, understandable, robust code that shall live long. We know how important a good foundation is for a house, why do we think it is different for software?<br><br>P.S.: Dan North had a <a href=\"https://vimeo.com/68215534\">wonderful talk at NDC Oslo 2013</a> about his \"craziest\" project (where business people coded with devs and devs paired with businesses people on their work). They wrote the first version of the business critical system in two weeks and then threw it away and rewrote it in a different language, building on all they have learnt.<br><br><p style=\"text-align:center;\"><em>You might enjoy also other <a href=\"/tag/opinion/\">posts on effective development</a>.</em></p>",
  "excerpt": ""
 },
 {
  "title": "Most interesting links of December ''13",
  "published": "2013-12-31 21:59:36",
  "postType": "post",
  "slug": "/2013/12/31/most-interesting-links-of-december-13/",
  "status": "publish",
  "tags": [
   "clojure",
   "design",
   "DevOps",
   "estimation",
   "ethics",
   "frontend",
   "haskell",
   "JavaScript",
   "media",
   "monitoring",
   "pedestal",
   "scala",
   "spring",
   "web"
  ],
  "categories": [
   "General",
   "Languages",
   "Testing",
   "Top links of month"
  ],
  "content": "<h2>Recommended Readings</h2>\r\nSociety\r\n<ul>\r\n\t<li><a href=\"http://blogs.hbr.org/2012/09/want-to-build-resilience-kill-the-complexity/\">HBR: Want to Build Resilience? Kill the Complexity</a> - a highly interesting, thought provoking article relevant both to technology in particular and the society in general; f.ex.: more security features are bad for they make us behave less safely (risk compensation) and are more fragile w.r.t. unexpected events. \"<em>Complexity is a clear and present danger to both firms and the global financial system: it makes both much harder to manage, govern, audit, regulate and support effectively in times of crisis. [..] Combine complex, Robust-Yet-Fragile systems, risk-compensating human psyches, and risk-homeostatic organizational cultures, and you inevitably get catastrophes of all kinds: meltdowns, economic crises, and the like.</em>\" The solution to future financial crisis is primarily not more regulation but <strong>simplification of the system</strong> - to make it easier to police, tougher to game. We also need to <strong>decrease interconnectednes</strong> (of banks etc.), one of the primary sources of complexity. Also a great example of US Army combatting complex, high-risk situations by employing \"devil's advocates / <strong>professional skeptics</strong>\" trained to help \"<em>avoid the perils of overconfidence, strategic brittleness, and groupthink. The goal is to respectfully help leaders in complex situations unearth untested assumptions, consider alternative interpretations and “think like the other”</em>\".</li>\r\n\t<li><a href=\"http://edgeperspectives.typepad.com/edge_perspectives/2013/12/the-dark-side-of-technology.html\">The Dark Side of Technology</a> - technologies provide great opportunities - but also risks we should be aware of - they create a world of mounting performance pressure for all of us (individuals, companies, states), accelerate the rate of change, increasing uncertanity (=&gt; risk of Taleb's black swans). \"<em>All of this mounting pressure has an understandable but very dangerous consequence. It draws out and intensifies certain cognitive biases [..]</em>\" - magnify our perception of risk, shrink our time horizons, foster a more and more reactive approach to the world, the \"if you win, I will lose\" view, erode our ability to trust anyone - and \"<em>combined effect of these cognitive biases increases the temptation to use these new digital infrastructures in a dysfunctional way: surveillance and control in all aspects of our economic, social and political life.</em>\" =&gt; \"<em>significantly increase[d] the likelihood of an economic, social and political backlash, driven by an unholy alliance between those who have power today and those who have achieved some modest degree of income and success.</em>\"\r\nComplexity theory: the more connected a system is, the more vulnerable it becomes to cascades of disruptive information/action.</li>\r\n\t<li><a href=\"http://mobile.businessweek.com/articles/2013-12-02/what-do-government-agencies-have-against-23andme-uber-and-airbnb\">What Do Government Agencies Have Against 23andMe, Uber, and Airbnb?</a> - innovative startups do not fit into established rules and thus bureaucrats do not know how to handle them and resort to their favourite weapon: saying no, i.e. enforcing rules that harm them (f.ex. France recently passed a law that requires Uber etc. drivers to wait 15 min before picking up a customer so that established taxi services have it easier; wot?!)</li>\r\n\t<li><a href=\"http://www.therealcenter.org/NVCInAction.php\">Nonviolent communication in action</a> - wonderful stories about NVC being applied in difficult situations with a great success</li>\r\n</ul>\r\nTech\r\n<ul>\r\n\t<li><a href=\"http://swannodette.github.io/2013/12/17/the-future-of-javascript-mvcs/\">D. Nolen: The Future of JavaScript MVC Frameworks</a> - highly recommended thought food - about React.js, disadvantages of event-based UI, benefits of immutability, performance, the ClojureScript React wrapper <a href=\"https://github.com/swannodette/om#om\">Om</a>  - \"<em>I simply don't believe in event oriented MVC systems - the flame graph above says it all. [...] Hopefully this gives fans of the current crop of JS MVCs and even people who believe in just using plain JavaScript and jQuery some food for thought. I've shown that a compile to JavaScript language that uses slower data structures ends up faster than a reasonably fast competitor for rich user interfaces. To top it off Om TodoMVC with the same bells and whistles as everyone else weighs in at ~260 lines of code</em>\"</li>\r\n\t<li><a href=\"http://boingboing.net/2013/12/13/british-library-uploads-one-mi.html\">Quora: Michael Wolfe's answer to Engineering Management: Why are software development task estimations regularly off by a factor of 2-3?</a> - a wonderful story explaining to a layman why estimation is hard, on the example of a hike from SF to LA</li>\r\n\t<li><a href=\"https://github.com/felixge/node-style-guide\">Style Guide for JavaScript/Node.js</a> by Felix Geisendörfer, recommended by a respectable web dev; nothing groudn breaking I suppose but great start for a team's standards</li>\r\n\t<li><a href=\"http://johannesbrodwall.com/2013/12/09/why-i-stopped-using-spring/\">Johannes Brodwall: Why I stopped using Spring [IoC]</a> - worth to read criticism of Spring by a respected and experienced architect and developer; summary - dependency injection is good bug \"magical\" frameworks decrease understandability and encourage unnecessarily complex code =&gt; smaller code, , easier to navigate and understand and easier to test</li>\r\n\t<li><a href=\"http://www.leanway.no/misunderstanding-technical-debt/\">Misunderstanding technical debt</a> - a brief discussion of the various forms of tech. debt (crappy code x misaligned design and problem domain x competence debt)</li>\r\n\t<li><a href=\"http://mobile.nytimes.com/2013/11/23/us/politics/tension-and-woes-before-health-website-crash.html\">Tension and Flaws Before Health Website Crash</a> - surprising lack of understanding and tensions between the government and contractors on HealthCare.gov - \"<em>a huge gap between the administration’s grand hopes and the practicalities of building a website that could function on opening day</em>\" - also terribly decision making, shifting requirements (what news!), management's lack of decision power, CGI's blame-shifting. A nice horror story. The former head knew that they should \"greatly simplify the site’s functions\" - but the current head wasn't able to \"talk them out of it\".</li>\r\n\t<li><a href=\"http://engineering.linkedin.com/distributed-systems/log-what-every-software-engineer-should-know-about-real-time-datas-unifying\">The Log: What every software engineer should know about real-time data's unifying abstraction</a> - logs are everywhere and especially important in distributed apps - DB logs, append-only logs, transaction logs - \"<em>You can't fully understand databases, NoSQL stores, key value stores, replication, paxos, hadoop, version control, or almost any software system without understanding logs</em>\" - I have only read a small part but it looks useful</li>\r\n\t<li><a href=\"http://dev.stephendiehl.com/hask/\">What I Wish I Knew When Learning Haskell</a> tl;dr</li>\r\n\t<li><a href=\"http://thinkrelevance.com/blog/2013/11/26/better-than-unit-tests\">Better Than Unit Tests</a> - a good overview of testing approaches beyond unit tests - including \"Automated Contract Testing\" (ability to define a contract for a web service, use it to test it and to simulate it; see <a href=\"https://www.youtube.com/watch?v=Gh9z_l7NdZk\">Internet of Strings</a> for more info), Property-based Testing (test generic properties using random data/calls <a href=\"/2013/06/28/brief-intro-into-randomstochasticprobabilistic-testing/\">as with Quickcheck</a>), Fault Injection (run on multiple VMs, simulate network failures), Simulation Testing <a href=\"/2013/06/28/brief-intro-into-randomstochasticprobabilistic-testing/\">as with Simulant</a>.</li>\r\n\t<li><a href=\"http://softwaredevelopmenttoday.blogspot.no/2013/12/use-noestimates-to-create-options-and.html?utm_source=twitterfeed&amp;utm_medium=twitter&amp;utm_campaign=Feed:+SoftwareDevelopmentToday+(Software+Development+Today)&amp;m=1\">Use #NoEstimates to create options and deliver value reliably</a> - a brief post with an example of an estimation-based vs. no-estimates project (i.e. more focus on delivering early, discovery)</li>\r\n\t<li><a href=\"http://hbr.org/2013/12/how-google-sold-its-engineers-on-management/ar/1\">How Google Sold Its Engineers on Management</a> - managers may be useful after all :-); a report about Google's research into management and subsequent (sometimes radical) improvements in management style/skills and people satisfaction; I love that Google hasn't HR but \"people ops\"</li>\r\n\t<li><a href=\"http://5whys.com/blog/technical-disobedience.html\">Roy Osherove: Technical Disobedience</a> - take nothing for granted, don't let the system/process stop you, be creative about finding ways to improve your team's productivity; there always is a way. Nice examples.</li>\r\n\t<li><a href=\"http://blog.8thlight.com/uncle-bob/2013/12/10/Thankyou-Kent.html\">Uncle Bob: Extreme Programming, a Reflection</a> - a reflection on changes in the past ~ 14 years since XP that have seen many of the \"extreme\" practices becoming mainstream</li>\r\n\t<li><a href=\"http://labs.openviewpartners.com/anti-meeting-manifesto/\">The Anti-Meeting Manifesto</a> - essentially a checklist and tips for limitting meetings to minimum</li>\r\n</ul>\r\nOther\r\n<ul>\r\n\t<li><a href=\"http://paper.li/BuildSafe/1310328866\">Ethics Daily</a> - a freuently published collection of ethics-related links, articles, talks etc.</li>\r\n\t<li><a href=\"http://boingboing.net/2013/12/13/british-library-uploads-one-mi.html\">British Library uploads one million public domain images to the net for remix and reuse</a> - from 17th-19th century books, <a href=\"http://www.flickr.com/photos/britishlibrary\">available at Flicker</a>; it asks for help categorizing and documenting them, <a href=\"https://github.com/BL-Labs/imagedirectory\">metadata of the images at GitHub</a> (with links to Flicker); great project, interesting pics</li>\r\n\t<li><a href=\"https://dionyziz.com/oath/\">The Software Engineers' Oath</a> - lets bring ethics back to our daily (work) lives - respect the knowledge of others, use technology for good (!!!), keep learning, writing code for people, not ashamed to admit lack of knowledge, respect for privacy, obligation to make lifes of humans better, ...</li>\r\n</ul>\r\n<h3>Talks</h3>\r\n<ul>\r\n\t<li><a href=\"http://2013.jsconf.eu/speakers/pete-hunt-react-rethinking-best-practices.html\">Pete Hunt: React: Rethinking best practices</a> (JSConf 2013, 30 min) - one of the most interesting talks about frontend development, design, and performance I have heard this year, highly recommended. Facebook's <a href=\"http://facebook.github.io/react/\">React</a> JavaScript framework  is a fresh and innovative challenger in the MVC field. It is worthwile to learn why they parted ways with the popular approach of templates (spoiler: concern separation, cohesion x coupling, performance). Their approach with virtual DOM enables some cool things (run in Node, provide HTML5-like events in any browser with consistent behavior, ...). Key: templates are actually tightly coupled to display logic (controllers) via the model view tailored for them (i.e. Controller must know what specific data &amp; in what form View needs) =&gt; follow cohesion and keep them together componets, separate from other components and back-end code. Also, state changing over time at many places is hard =&gt; re-render the whole app rather than in-place updates. Also, the <a href=\"https://github.com/swannodette/om/blob/master/README.md\">ClojureScript Om wrapper</a> enables even more performance optimizations thanks to immutable data structures etc.</li>\r\n\t<li><a href=\"http://skillsmatter.com/podcast/java-jee/some-musings-on-scala-and-clojure-by-a-long-time-scala-dude\">David Pollak: Some musings on Scala and Clojure by a long time Scala dude</a> (46 min) - a subjective but balanced comparison of Scala and Clojure and their strengths/weaknesses by the author of the Scala Lift framework (doing Scala since 2006, Clojure since 2013)</li>\r\n</ul>\r\n<h2>Clojure Corner</h2>\r\n<ul>\r\n\t<li><a href=\"http://hoplon.io/\">Hoplon</a> - a reportedly interesting web framework using ClojureScript and targetting single-page apps, with \"a spreadsheet-like dataflow programming environment\"</li>\r\n\t<li><a href=\"https://github.com/pedestal/pedestal/blob/master/app/examples/walkthrough.clj\">Peek at the new, simpler Pedestal API using core.async </a></li>\r\n\t<li><a href=\"http://yogthos.net/blog/52\">Review: Clojure high performance programming</a> - \"<em>If you're looking for a refresher or a primer on the topics discussed, then it's not a bad place to start. However, if you're looking for a comprehensive discussion on doing high performance programming with Clojure, you'll likely be left wanting.</em>\"</li>\r\n\t<li><a href=\"http://blog.jenkster.com/2013/12/a-cider-excursion.html\">Clojure On Emacs - A CIDER Workflow Hack</a> - using Cider's <em>cider-interactive-eval</em> to execute Clojure code on a keystroke in the REPL, f.ex. to run tests, refresh your env., or print an atom you are actively working with; neat!</li>\r\n\t<li><a href=\"http://www.infoq.com/presentations/clojure-core-async\">Clojure core.async Channels</a> by Hickey, StrangeLoop 2013 - introduction into the design and rationale for core.async vs. alternative solutions such as actors and RxJava</li>\r\n\t<li>Discussion: <a href=\"https://groups.google.com/forum/#!msg/clojure/fbX1XCs4VTQ/N66ol1nQ8Y0J\">Good resources on dataflow based programming</a> [w.r.t. Pedestal] - I wasn't even aware that Pedestal is based on dataflows; the recommended (though highly opinionated) articles were 1. <a href=\"http://my.opera.com/Vorlath/blog/2008/01/06/simple-example-of-the-difference-between-imperative-functional-and-data-flow\" target=\"_blank\">http://my.opera.com/Vorlath/blog/2008/01/06/simple-example-of-the-difference-between-imperative-functional-and-data-flow</a> and 2. <a href=\"http://www.google.com/url?q=http%3A%2F%2Fmy.opera.com%2FVorlath%2Fblog%2F2008%2F07%2F25%2Fhierarchies-and-equivalence&amp;sa=D&amp;sntz=1&amp;usg=AFQjCNEq0K1Bcot_GLNwzL-MBN6G2yHM5g\" target=\"_blank\">http://my.opera.com/Vorlath/blog/2008/07/25/hierarchies-and-equivalence</a>. Also the book <a href=\"http://dataflowbook.com/cms/\">Dataflow and Reactive Programming Systems</a> that should ship 4/2014.</li>\r\n</ul>\r\n<h2>Tools/<a href=\"http://sirona.incubator.apache.org/\">Libs</a></h2>\r\n<ul>\r\n\t<li><a href=\"http://sirona.incubator.apache.org/\">Apache Sirona</a> - a new monitoring tool in the Apache incubator - \"a simple but extensible monitoring solution for Java applications\" with support for HTTP, JDBC, JAX-RS, CDI, ehcache, with data published e.g. to Graphite or <a href=\"https://github.com/square/cube\">Square Cube</a>. It is still very new.</li>\r\n\t<li><a href=\"http://kent.doddsfamily.us/genie/\">GenieJS</a> - Ctrl-Space to popup a command-prompt for your web page, inspired by <a href=\"http://www.alfredapp.com/\">Alfred</a> (type ' to see all possible commands)</li>\r\n</ul>\r\n<h2>Favourite Quotes</h2>\r\n<blockquote>A good #agile team considers their backlog inaccurate. It is merely a list of assumptions that must be tested &amp; refined by shipping product\r\n<em>- <a href=\"https://twitter.com/mick_maguire/status/410465093382455296\">@mick maguire 12/10</a></em></blockquote>\r\n<blockquote>Ada Lovelace (1st program), Grace Hopper (1st compiler), Adele Goldberg (1st OO language), why would anyone think women aren't in computing?\r\n- <a href=\"https://mobile.twitter.com/climagic/status/410516394338705408?screen_name=climagic\">@Dan North 12/11</a></blockquote>\r\n<blockquote>There will always be a shortage of talented, self-motivated creative professionals who will unquestioningly follow orders.\r\n- <a href=\"https://mobile.twitter.com/substack/status/409288656089014272\">@Thomas K Nilsson 12/7</a></blockquote>\r\n<blockquote>Estimation paradox = If something unpredictable happens, predict how long it will take to fix it\r\n- <a href=\"https://twitter.com/HolyJak/status/411401221258620928\">me 12/7</a></blockquote>\r\n<blockquote>IT systems can be inspired by AK-47 a.k.a. <a href=\"http://en.wikipedia.org/wiki/AK-47\">Kalashnikov</a>. The rifle was purposefully designed to be simple and to be tolerant to imperfections in most parts; as a result, it required essentially no maintenance and was extremely reliable.\r\n- summarized from Roman Pichlík's <a href=\"http://www.dagblog.cz/2013/12/odkaz-michaila-kalasnikova-softwarovemu.html\">Odkaz Michaila Kalašnikova softwarovému vývoji</a></blockquote>",
  "excerpt": ""
 },
 {
  "title": "Bad Code: Are We Thinking Too Little?",
  "published": "2013-12-30 23:07:47",
  "postType": "post",
  "slug": "/2013/12/31/bad-code-are-we-thinking-too-little/",
  "status": "publish",
  "tags": [
   "design",
   "legacy",
   "opinion"
  ],
  "categories": [
   "General"
  ],
  "content": "Do we not think enough when coding? Do we jump to the first solution without really considering the problem, without trying to analyze and decompose it and understand the components and orthogonal forces invovled? Is that the cause of bad code (together with time press) and the reason why we typically see a \"patchvolution\" rather than evolution (of design)?<br><br>For example I want a certain item on my list shown grayed out because it has been marked for removal or is currently being edited and I therefore add a flag called <em>isDisabled</em>. But if I really thought about it, I would likely call it based on the purpose rather than display, e.g. <em>isBeing Edited</em>. And I have often observed that I/we tend to jump to the first acceptable solution without trying to consider other, (radically) different and perhaps better alternatives. That is easily explained with our inborn intelectual laziness and we certainly can agree that we should not overthink things and that we need to ship but still, shouldn't we try to think a little more?<br><br>The Clojure community has been very inspiring for me in this regard. There is a strong focus on spending more time on the problem than the solution to really understand it, and on separating the different concerns involved and adressing them separately, as well as on achieving simplicity. One of the manifestation is the strong preference of small, focused, composable libraries over frameworks. F.ex. it took couple of years for Clojure to get support for named arguments - but the result - <a href=\"http://blog.jayfields.com/2010/07/clojure-destructuring.html\">destructuring</a> - is something much more powerful, that now pervades the whole languages (of course, this is a language, not an app). When you listen to Rich Hickey talking f.ex. about <a href=\"http://www.infoq.com/presentations/clojure-core-async\">core.async</a> (vs. actors, Reactive Extensions etc.) you see that the man thought deeply about the problem, alternatives, and their pros and cons.<br><br>May be we should spend little more time with our problems before jumping to solutions, no matter how much we like to solve things. Perhaps we would end up with a much better code than we typically have, and thus considerably lower maintenance costs.<br><br>Ref: <a href=\"http://www.infoq.com/presentations/Simple-Made-Easy\">Simple <em>Made Easy</em></a>, <a href=\"http://www.drdobbs.com/architecture-and-design/the-clojure-philosophy/240150710\">The Clojure Philosophy</a> from Joy of Clojure.<br><br><p style=\"text-align:center;\"><em>You might enjoy also other <a href=\"/tag/opinion/\">posts on effective development</a>.</em></p>",
  "excerpt": ""
 },
 {
  "title": "2013 in review",
  "published": "2013-12-31 14:29:49",
  "postType": "post",
  "slug": "/2013/12/31/2013-in-review/",
  "status": "publish",
  "tags": [],
  "categories": [
   "Uncategorized"
  ],
  "content": "The WordPress.com stats helper monkeys prepared a 2013 annual report for this blog.<br><br><a href=\"/2013/annual-report/\"><img alt=\"\" src=\"http://www.wordpress.com/wp-content/mu-plugins/annual-reports/img/2012-emailteaser.png\" width=\"100%\" /></a><br><br>Here's an excerpt:\r\n<blockquote>The Louvre Museum has 8.5 million visitors per year. This blog was viewed about <strong>140,000</strong> times in 2013. If it were an exhibit at the Louvre Museum, it would take about 6 days for that many people to see it.</blockquote>\r\n<a href=\"/2013/annual-report/\">Click here to see the complete report.</a>",
  "excerpt": ""
 },
 {
  "title": "Most interesting links of January ''14",
  "published": "2014-01-31 21:59:49",
  "postType": "post",
  "slug": "/2014/01/31/most-interesting-links-of-january-14/",
  "status": "publish",
  "tags": [],
  "categories": [
   "General",
   "Top links of month"
  ],
  "content": "<h2>Recommended Readings</h2>\r\n<ul>\r\n\t<li><a href=\"http://www.thoughtworks.com/radar/\">ThoughtWorks latest interactive Technology Radar 1/2014</a>(fixed <a href=\"http://thoughtworks.fileburst.com/assets/technology-radar-jan-2014-en.pdf\">link to pdf for Jan 2014</a>:)</li>\r\n\t<li><a href=\"http://www.leanway.no/competence-debt/\">The other kind of software debt - competency debt</a></li>\r\n</ul>\r\n<span style=\"font-size:1.5em;line-height:1.5em;\">Clojure Corner</span>\r\n<ul>\r\n\t<li>David Nolen's interactive <a href=\"https://github.com/swannodette/om/wiki/Tutorial\">Om tutorial for LightTable</a></li>\r\n\t<li>Discussion: <a href=\"https://groups.google.com/forum/m/#!msg/clojure/YMlg1UPre2o/f6ZUVaEky7IJ\">Helping newcomers get involved in Clojure projects</a> - Leiningen and some (in future all) ClojureWerkz projects have bugs tagged as newbie/begginer-friendly</li>\r\n</ul>\r\n<h2>Tools/Libs</h2>\r\n<h2>Favourite Quotes</h2>\r\nBoeing about unavoidable child issues with the new Dreamliner aircraft:\r\n<blockquote>Nei. Selvfølgelig vil man at alt skal være perfekt. Vi gjorde mer testing på dette flyet enn vi har gjort på noen andre fly. Du kan teste og teste, men realiteten er at du ikke alltid vil finne alt. Ingen fly har blitt satt i drift og oppnådd 100 prosent pålitelighet med det samme. Noen oppnår det aldri, svarte Fleming.\r\n-<a href=\"http://www.dn.no/forsiden/naringsliv/article2753750.ece\"> DN.no - Vi har gode og dårlige dager</a> 2014-01-24</blockquote>",
  "excerpt": ""
 },
 {
  "title": "A Secret Weapon Against Technical Debt",
  "published": "2014-02-02 20:59:08",
  "postType": "post",
  "slug": "/2014/02/02/the-secret-weapon-against-technical-debt/",
  "status": "publish",
  "tags": [
   "development",
   "legacy"
  ],
  "categories": [
   "General"
  ],
  "content": "<em>(Cross-posted from <a href=\"http://blog.iterate.no/2014/02/02/the-secret-weapon-against-technical-debt/\">blog.iterate.no</a>.)</em><br><br>Technical debt is not the only monster we have to fight - it has a hidden evil twin,  <a href=\"http://www.leanway.no/competence-debt/\">as pointed out by Niklas Björnerstedt</a>: Competence Debt. The rope of ignorance that binds our hands and suffocates us by fear so that we don't dare to change the system. Technical debt makes change difficult because the structure of the system does not support it. Competence debt makes change difficult because we do not know the system well enough, what &amp; where to change and what impacts a change may have.<br><br>There is an often neglected tool at our fingertips that might help us fight competence debt. Its name is - behold - JavaDoc. An example from practice: I have returned to a client after two years and needed to understand the functionality of a part of the system. And, to my surprise, I found my own JavaDoc providing exactly the answer I was looking for. A colleague of mine mentioned that I should get the award for the \"most documenting developer\". But I don't do it for fun or just to help my bad memory and to be nice to my colleagues. It is an important contribution to the fight against the ever growing hydra of legacy code. Next time you code, try to remember that you are not typing code, but fighting. As every fight, it is hard - but do not give up or the enemy will prevail.<br><br>Side note: Writing JavaDoc that helps yet is not too verbose and not too likely to get outdated soon is hard. Getting the right balance - neither too little nor too much, focusing on the why and the broader context and relationships instead of the changing implementation etc. is difficult. But it is worth it. Help yourself, help your fellow colleagues, strike the hydra. Write good JavaDoc.<br><br><em>PS: This post is about competence debt even though the title mentions technical debt, sorry for the confusion (even though they are two sides of the same coin). And \"good enough\" documentation, though important, is not the sole remedy, as well as developers' lack of knowledge is not the sole cause of competence debt. Also, Niklas provides a more in-depth review of the technical &amp; competence debt terms in <a href=\"http://www.leanway.no/misunderstanding-technical-debt/\">Misunderstanding technical debt</a>  (tech. debt as evolving understanding [but not code] and crappy code). He wrote also <a href=\"http://www.leanway.no/a-deeper-look-at-competence-debt/\">A deeper look at Competence debt</a>.</em>",
  "excerpt": ""
 },
 {
  "title": "JBoss Modules Suck, It''s Impossible To Use Custom Resteasy/JAX-RS Under JBoss 7",
  "published": "2014-02-04 09:15:57",
  "postType": "post",
  "slug": "/2014/02/04/jboss-modules-suck-its-impossible-to-use-custom-resteasyjax-rs-under-jboss-7/",
  "status": "publish",
  "tags": [
   "enterprise",
   "java",
   "jboss"
  ],
  "categories": [
   "j2ee"
  ],
  "content": "Since JBoss EAP 6.1 / AS 7.2.0 is modular and you can exclude what modules are visible to your webapp, you would expect it to be easy to ignore the built-in implementation of JAX-RS (Rest Easy 2.3.6) and use a custom one (3.0.6). However, sadly, this is not the case. You are stuck with what the official guide suggests, i.e. <a href=\"http://docs.jboss.org/resteasy/docs/3.0.6.Final/userguide/html/Installation_Configuration.html#upgrading-as7\">upgrading Rest Easy globally</a> - provided that no other webapp running on the server becomes broken by the upgrade.<br><br><!--more--><br><br>This should be enough to exclude the built-in Rest Easy and be able to use a version included in the webapp:<br><br><pre><code>\r\n&lt;!-- jboss-deployment-structure.xml --&gt;\r\n&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;\r\n&lt;jboss-deployment-structure&gt;\r\n   &lt;deployment&gt;\r\n       &lt;exclude-subsystems&gt;\r\n           &lt;subsystem name=&quot;resteasy&quot;/&gt;\r\n       &lt;/exclude-subsystems&gt;\r\n   &lt;/deployment&gt;\r\n &lt;/jboss-deployment-structure&gt;\r\n</code></pre><br><br>However it is far from working. This <em>nearly</em> does the job (though few of the exclusions might be unnecessary):<br><br><pre><code>\r\n&lt;!-- jboss-deployment-structure.xml --&gt;\r\n&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;\r\n&lt;jboss-deployment-structure&gt;\r\n   &lt;deployment&gt;\r\n       &lt;exclude-subsystems&gt;\r\n           &lt;subsystem name=&quot;resteasy&quot;/&gt;\r\n       &lt;/exclude-subsystems&gt;\r\n     &lt;exclusions&gt;\r\n       &lt;module name=&quot;org.apache.log4j&quot; /&gt;\r\n       &lt;module name=&quot;org.apache.commons.logging&quot;/&gt;\r\n       &lt;module name=&quot;org.jboss.as.jaxrs&quot;/&gt;\r\n       &lt;module name=&quot;org.jboss.resteasy.resteasy-jaxrs&quot;/&gt;\r\n       &lt;module name=&quot;org.jboss.resteasy.resteasy-cdi&quot;/&gt;\r\n       &lt;module name=&quot;org.jboss.resteasy.jackson-provider&quot;/&gt;\r\n       &lt;module name=&quot;org.jboss.resteasy.resteasy-atom-provider&quot;/&gt;\r\n       &lt;module name=&quot;org.jboss.resteasy.resteasy-hibernatevalidator-provider&quot;/&gt;\r\n       &lt;module name=&quot;org.jboss.resteasy.resteasy-jaxb-provider&quot;/&gt;\r\n       &lt;module name=&quot;org.jboss.resteasy.resteasy-jettison-provider&quot;/&gt;\r\n       &lt;module name=&quot;org.jboss.resteasy.resteasy-jsapi&quot;/&gt;\r\n       &lt;module name=&quot;org.jboss.resteasy.resteasy-multipart-provider&quot;/&gt;\r\n       &lt;module name=&quot;org.jboss.resteasy.resteasy-yaml-provider&quot;/&gt;\r\n       &lt;module name=&quot;org.codehaus.jackson.jackson-core-asl&quot;/&gt;\r\n       &lt;module name=&quot;org.codehaus.jackson.jackson-jaxrs&quot;/&gt;\r\n       &lt;module name=&quot;org.codehaus.jackson.jackson-mapper-asl&quot;/&gt;\r\n       &lt;module name=&quot;org.codehaus.jackson.jackson-xc&quot;/&gt;\r\n       &lt;module name=&quot;org.codehaus.jettison&quot;/&gt;\r\n       &lt;module name=&quot;javax.ws.rs.api&quot;/&gt;\r\n     &lt;/exclusions&gt;\r\n   &lt;/deployment&gt;\r\n &lt;/jboss-deployment-structure&gt;\r\n</code></pre><br><br>However, only nearly. The problem is that the exclusion of <em>javax.ws.rs.api</em> has no effect. It seems as the core Java EE APIs cannot be excluded. Dead end.<br><br>BTW, this are my final jax-rs related dependencies:<br><br><pre><code>\r\n// resteasyVersion = '3.0.6.Final'\r\ncompile group: 'org.jboss.resteasy', name: 'jaxrs-api', version: resteasyVersion\r\ncompile group: 'org.jboss.resteasy', name: 'resteasy-jaxrs', version: resteasyVersion\r\ncompile group: 'org.jboss.resteasy', name: 'resteasy-jackson2-provider', version: resteasyVersion // JSONP\r\ncompile group: 'org.jboss.resteasy', name: 'async-http-servlet-3.0', version: resteasyVersion // Required at runtime\r\ncompile group: 'org.jboss.resteasy', name: 'resteasy-servlet-initializer', version: resteasyVersion // Required at runtime\r\n</code></pre>\r\n<h2>An approximate history of failed attempts</h2>\r\nI do not remember anymore exactly all the dead ends I went through but here is an approximate overview of the exceptions I got at deployment or runtime.<br><br><code>java.lang.ClassNotFoundException: org.jboss.resteasy.plugins.server.servlet.HttpServlet30Dispatcher</code><br><br>- fixed likely by adding <code>org.jboss.resteasy:async-http-servlet-3.0:3.0.6.Final</code> to the dependencies<br><br><code>java.lang.ClassCastException: myapp.rs.RestApplication cannot be cast to javax.servlet.Servlet</code><br><br>- fixed likely by adding <code>org.jboss.resteasy:resteasy-servlet-initializer:3.0.6.Final</code> to the dependencies<br><br><code>java.lang.NoSuchMethodError: org.jboss.resteasy.spi.ResteasyProviderFactory.&lt;init&gt;(Lorg/jboss/resteasy/spi/ResteasyProviderFactory;)V</code><br><br>- fixed likely by adding more of the RestEasy/Jackson modules to the exclusion list<br><br><code>java.lang.NoSuchMethodError: org.jboss.resteasy.specimpl.BuiltResponse.getHeaders()Ljavax/ws/rs/core/MultivaluedMap;</code><br><br>- this is the ultimate one that cannot be fixed; the problem is that <code>BuiltResponse</code> from <code>resteasy-jaxrs</code> inherits from <code>javax.ws.rs.core.Response</code> however the version of <a href=\"http://grepcode.com/file/repo1.maven.org/maven2/org.jboss.resteasy/jaxrs-api/3.0.4.Final/javax/ws/rs/core/Response.java#Response.getHeaders%28%29\">this class from jaxrs-api-3.0.6.Final.jar</a> is ignored in favour of <code>Response</code> from JAX-RS 1.1 from the <code>javax.ws.rs.api</code> module (<code>/jboss-eap-6.1.0/modules/system/layers/base/javax/ws/rs/api/main/jboss-jaxrs-api_1.1_spec-1.0.1.Final-redhat-2.jar</code>), which lacks the <code>getHeaders</code> method and, as mentioned, cannot be excluded. (Thanks to <a href=\"http://stackoverflow.com/a/19708873\">allprog for hinting at this confilct</a>!)\r\n<h2>Conclusion</h2>\r\nThe only way to use a newer JAX-RS is to upgrade the JBoss modules. If that would break some other webapps, you are stuck.<br><br>Lessons learned: Application servers with the plenty of out-of-the-box, well-integrated (?) functionality seem attractive but when you run into conflicting libraries and classloading issues, their value diminishes rapidly. Starting with something simple that you control fully, such as Jettty, is perhaps in the long run a better solution. Also, running multiple webapps on the same server was perhaps smart in 2000 but is not worth the pain nowadays. We have plenty of disk space and memory so reuse of libraries is unimportant and the ability to manage global settings for all apps at one place has certainly better alternatives. Microservices FTW!<br><br><strong>Update</strong>: As Yannick has pointed out, the conclusion seems too general and unjustified. That is because I have arrived to it already before and this problem with JBoss serves only as another confirmation.<br><br><strong>Update 2</strong>: <a href=\"#comment-6404\">Bill Burke has proposed a solution, see below</a>.\r\n<h3>Follow up</h3>\r\nI've updated Rest Easy in JBoss, however that proved not to be enough. It took me a while to find out that I must make sure to exclude some/all jboss/resteasy/javax dependencies from my WAR (with the important exception of <code>resteasy-servlet-initializer</code>) - having them there led sometimes to NoClassDefFoundException for a class that was there, a typical classloader hell.<br><br>I needed even more time to find out that while core parts of Rest Easy are available automatically to the application, I needed to add <em> &lt;module name=\"org.jboss.resteasy.resteasy-jackson2-provider\" services=\"import\"/&gt;</em> to <em>jboss-deployment-structure.xml</em> to use Jackson 2 (the services=import is crucial, without it the Jackson2 is ignored by Rest Easy and it will use the Jackson 1 instead, leading to confusing failures to deserialize some JSON).<br><br>I can blame all the wasted time on my lack of deeper knowledge of JBoss and Rest Easy. But for me, it is another argument for preferring simpler solutions that I control fully, such as a jetty-based stack.",
  "excerpt": ""
 },
 {
  "title": "Demonstration of Ansible Features With Control & Test VMs",
  "published": "2014-02-16 18:09:24",
  "postType": "post",
  "slug": "/2014/02/16/demonstration-of-ansible-features-with-control-test-vms/",
  "status": "publish",
  "tags": [
   "ansible",
   "DevOps"
  ],
  "categories": [
   "Tools"
  ],
  "content": "I have created a small project to demonstrate some features of Ansible, the new DevOps hotness, including Vagrant VMs for running Ansible and for testing the configuration. Either go straight to\r\n<p style=\"padding-left:30px;\"><a href=\"https://github.com/jakubholynet/ansible-example-with-vm\">https://github.com/jakubholynet/ansible-example-with-vm</a></p>\r\nor continue reading the copy &amp; paste here.<br><br>This project has three things of interest:\r\n<ol>\r\n\t<li>A non-trivial Ansible configuration that demonstrates couple of useful features and tricks</li>\r\n\t<li>A Vagrant/VirtualBox virtual machine with Ansible &amp; co. to make it easy to run it (even on Windows)</li>\r\n\t<li>Another VM that can be used to test the configuration</li>\r\n</ol>\r\nAnd of course all the plumbing that makes them work together. It might be therefore a good base for Ansible projects of your own.<br><br><!--more--><br><br><em>Disclaimer: I am quite new to Ansible.</em>\r\n<h3><a href=\"https://github.com/jakubholynet/ansible-example-with-vm#little-background-ansible-and-vagrant\" name=\"little-background-ansible-and-vagrant\"></a>Little background: Ansible and Vagrant</h3>\r\n<a href=\"http://docs.ansible.com/\">Ansible</a> is a devops tool for configuring servers over SSH, using just Python. It is similar to Puppet and Chef but does not need you to install anything on the servers (essentialy every *nix has Python 2.4+ and SSH, and it even works with the old RHEL 5.9), the configuration is by defaut pushed from the control machine instead of pulled by the servers, and it has strong focus on simplicity. It is less mature than Puppet and has fewer plugins and no support for Windows yet but the simplicity, minimal requirements, and push model are good reasons to consider it.<br><br><a href=\"http://www.vagrantup.com/\">Vagrant</a> is a command-line tool for creating, configuring, and managing virtual machines, f.ex. using <a href=\"https://www.virtualbox.org/\">VirtualBox</a>. It also integrates them with the host machine by directory sharing, port forwarding, and password-less ssh. In essence, you need few text files and get a fully functional, configured, and integrated environment in a VM.\r\n<h3><a href=\"https://github.com/jakubholynet/ansible-example-with-vm#demonstrated-features--tricks\" name=\"demonstrated-features--tricks\"></a>Demonstrated features &amp; tricks</h3>\r\n<h4><a href=\"https://github.com/jakubholynet/ansible-example-with-vm#vagrant---ansible-integration-tips\" name=\"vagrant---ansible-integration-tips\"></a>Vagrant - Ansible integration tips</h4>\r\nSet <code>config.ssh.forward_agent = true</code> in the <code>ansible-vm</code> to make it easier to make your prive keys available to Ansible for SSH into remote machines. (See \"Testing locally\" below for more details.)<br><br>Add <code>mount_options: ['dmode=0775','fmode=0664']</code> for mounting the directory with Ansible configuration so that the inventory file won't seem to be executable to Ansible.\r\n<h4><a href=\"https://github.com/jakubholynet/ansible-example-with-vm#ansible\" name=\"ansible\"></a>Ansible</h4>\r\n<em>General</em>: Use roles to split configuration into separate concerns (jboss, vagrant), use variables to handle variation between environments and usages of a role (f.ex. JBoss' ports, <code>jboss_host_type</code> = <code>master|slave</code>, <code>env</code> = <code>vagrant|staging|production</code>). Use tags to mark parts of the configuration so that those parts can be picked and executed without the rest (f.ex. <code>jboss_module</code>, <code>jboss_configuration</code>, <code>vagrant</code>).<br><br><em>Secret local credentials vars file</em>: the configuration includes variables from the file <code>secret_vars.yml</code>, which is added to <code>.gitignore</code> so that it won't be checked into Git and every user has to create her own local copy based on <code>secret_vars.yml.example</code>. Thus sensitive credentials never leave the local machine.<br><br><em>Reuse via parametrized include and simulating <code>creates</code> for <code>get_url</code></em>. To avoid the need to keep downloaded archives, I use <code>stat</code> to check for the presence of a file/directory and <code>while</code> to skip <code>get_url</code> if it exists. The whole thing is in a task include file, <code>roles/jboss/tasks/fetch-module.yml</code>, that is parametrized so that it can be reused to fetch and unpack three different modules - see <code>roles/jboss/tasks/modules.yml</code>.<br><br><em>Multiple environments</em> - here<code>vagrant</code> and <code>staging</code> via two different inventory files.\r\n<h4><a href=\"https://github.com/jakubholynet/ansible-example-with-vm#gotchas\" name=\"gotchas\"></a>Gotchas</h4>\r\nIf Ansible seems to freeze while executing a command, make sure that the command is not trying to ask for user input, as was my case with <code>unzip</code> that wanted to know what to do with existing files (fixed by running it with <code>-o</code> to force overwrite them).\r\n<h3><a href=\"https://github.com/jakubholynet/ansible-example-with-vm#automated-configuration-of-jboss\" name=\"automated-configuration-of-jboss\"></a>Automated configuration of JBoss</h3>\r\nJBoss configuration using Ansible so it is possible to automatically apply it to a server. Some of the files (-&gt; templates) are parametrized with variables that are defined f.ex. in <code>group_vars/appservers</code>, the host inventory file (f.ex. <code>vagrant</code>), and <code>secret_vars.yml</code>.<br><br><strong>BEWARE</strong>: Copy <code>secret_vars.yml.example</code> to <code>secret_vars.yml</code> and set the right credentials there.\r\n<h2><a href=\"https://github.com/jakubholynet/ansible-example-with-vm#ansible-1\" name=\"ansible-1\"></a>Ansible</h2>\r\n<h3><a href=\"https://github.com/jakubholynet/ansible-example-with-vm#prerequisities\" name=\"prerequisities\"></a>Prerequisities</h3>\r\nYou will need\r\n<ul>\r\n\t<li>(Windows: ssh, f.ex. the one from the Putty installer)</li>\r\n\t<li><a href=\"https://www.virtualbox.org/wiki/Downloads\">VirtualBox</a> (f.ex. 4.3.6)</li>\r\n\t<li><a href=\"http://www.vagrantup.com/\">Vagrant</a> (f.ex. 1.4.3)</li>\r\n\t<li>Vagrant vbguest plugin (after having installed vagrant, run <code>vagrant plugin install vagrant-vbguest</code>)</li>\r\n</ul>\r\n<h3><a href=\"https://github.com/jakubholynet/ansible-example-with-vm#how-is-it-set-up\" name=\"how-is-it-set-up\"></a>How is it set up</h3>\r\nThe Vagrant/VirtualBox VM <code>ansible-vm</code> has Ansible installed and may be used to run it against the test VM or staging. The test VM itself, <code>centos-vm</code>, may be used to test the changes locally before staging. As described above, you will need to create <code>secret_vars.yml</code> with secret credentials.<br><br>Under Linux/Mac, you may install and use Ansible directly, without <code>ansible-vm</code>.\r\n<h3><a href=\"https://github.com/jakubholynet/ansible-example-with-vm#briefly-about-vagrant\" name=\"briefly-about-vagrant\"></a>Briefly about Vagrant</h3>\r\nVagrant is a command-line tool that can create, set up, and manage VirtualBox virtual machines.<br><br>You need to know:\r\n<ul>\r\n\t<li>Run <code>vagrant up</code> in <code>centos-vm</code> or <code>ansible-vm</code> to create, configure, and start the VM\r\n<ul>\r\n\t<li>Run <code>vagrant reload</code> after you did <code>up</code> for the first time, if new Guest Additions were installed</li>\r\n</ul>\r\n</li>\r\n\t<li>Run <code>vagrant ssh</code> to ssh into the machine as the user <code>vagrant</code>, which has full sudo rights.</li>\r\n\t<li>Run <code>vagrant halt</code> to stop a VM and <code>vagrant destroy</code> if you want to destroy it (to re-create it from scratch)</li>\r\n</ul>\r\nNotice that Vagrant automatically shares the vm directory as <code>/vagrant</code> with the VM (and we also share this directory as <code>/Infrastructure</code>) and it can forward ports from the guest VM to the host so that you can access services running in the VM via <code>locahost:&lt;the forwarded port&gt;</code> which we use a lot in the <code>centos-vm</code>.\r\n<h3><a href=\"https://github.com/jakubholynet/ansible-example-with-vm#structure-of-the-configuration\" name=\"structure-of-the-configuration\"></a>Structure of the configuration</h3>\r\nMost of the config is inside \"roles\" such as \"jboss\" and \"vagrant\", see the <code>./roles/</code> directory.\r\n<h3><a href=\"https://github.com/jakubholynet/ansible-example-with-vm#usage\" name=\"usage\"></a>Usage</h3>\r\n<h4><a href=\"https://github.com/jakubholynet/ansible-example-with-vm#testing-locally\" name=\"testing-locally\"></a>Testing locally</h4>\r\nUse the test CentOS VM. To enable password-less execution of ansible against the test VM, it is recommended to use ssh-agent, adding the vagrant key to it via <code>ssh-add ~/.vagrant.d/insecure_private_key</code>.<br><br>Windows: Use Git Bash and <a href=\"https://help.github.com/articles/working-with-ssh-key-passphrases#auto-launching-ssh-agent-on-msysgit\">enable ssh-agent</a> as described in GitHub Help, adding the line <code>ssh-add ~/.vagrant.d/insecure_private_key</code> to it. Use the same Bash (?) to run <code>vagrant up</code> under <code>ansible-vm</code>.<br><br>Alternatively, run ansible with <code>--ask-pass</code> or <code>-k</code>, the password is \"vagrant\".\r\n<ol>\r\n\t<li>Run the test <code>centos-vm</code> - go to the directory and run <code>vagrant up</code></li>\r\n\t<li>Run <code>ansible-vm</code> - go to the directory and run <code>vagrant up</code> and then <code>vagrant ssh</code></li>\r\n\t<li>In the Ansible VM run <code>cd /Infrastructure</code> and run f.ex. <code>ansible-playbook -vi vagrant site.yml</code></li>\r\n</ol>\r\nNote: The <code>ansible-vm</code> setup assumes that IP of the host machine as visible from the VM is <code>10.0.2.2</code> (test with f.ex. <code>route</code>)\r\n<h4><a href=\"https://github.com/jakubholynet/ansible-example-with-vm#dry-run\" name=\"dry-run\"></a>Dry-run</h4>\r\nAnsible can try to predict some of the changes it would need to do:\r\n<pre><code> ansible-playbook -vi staging site.yml -u &lt;your user name&gt; [--ask-sudo-pass] --check --diff\r\n</code></pre>\r\n<h4><a href=\"https://github.com/jakubholynet/ansible-example-with-vm#application-of-changes-to-staging\" name=\"application-of-changes-to-staging\"></a>Application of changes to staging</h4>\r\nInside the <code>Infrastructure/</code> directory, run:\r\n<pre><code>ansible-playbook -vi staging site.yml -u &lt;your user name&gt; [--ask-pass] [--ask-sudo-pass] [--tags &lt;comma-separated tags&gt;] [--private-key=key file]\r\n</code></pre>\r\nNotes:\r\n<ul>\r\n\t<li>Ansible will ssh as the provided user to the machines listed in the staging file (\"-u jakub\" =&gt; \"ssh jakub@app(1|2).staging.example.com\")</li>\r\n\t<li><code>--ask-pass</code> is necessary if ssh asks for password, i.e. if you haven't set up password-less ssh</li>\r\n\t<li><code>--ask-sudo-pass</code> (or <code>-K</code>) is necessary if your user hasn't password-less sudo access on the server</li>\r\n\t<li>You can use <code>--tags</code> to execute only a subset of the tasks (provided the have been tagged); ex.: <code>--tags newrelic,jboss_module,jboss_configuration</code></li>\r\n</ul>\r\n<h2>Sources</h2>\r\n<a href=\"https://github.com/jakubholynet/ansible-example-with-vm\">https://github.com/jakubholynet/ansible-example-with-vm</a>",
  "excerpt": ""
 },
 {
  "title": "Most interesting links of February ''14",
  "published": "2014-02-28 21:59:12",
  "postType": "post",
  "slug": "/2014/02/28/most-interesting-links-of-february-14/",
  "status": "publish",
  "tags": [
   "clojure",
   "continuous_deployment",
   "development",
   "human",
   "JavaScript",
   "learning",
   "performance",
   "REST",
   "web"
  ],
  "categories": [
   "General",
   "Languages",
   "Tools",
   "Top links of month"
  ],
  "content": "<h2>Recommended Readings</h2>\r\nDevelopment\r\n<ul>\r\n\t<li><a title=\"Falsehoods Programmers Believe About Names\" href=\"http://www.kalzumeus.com/2010/06/17/falsehoods-programmers-believe-about-names/\" rel=\"bookmark\">Falsehoods Programmers Believe About Names</a> - summary: there are no rules that apply to names, do not assume anything (my favourite: 12 + 13)</li>\r\n</ul>\r\n<ul>\r\n\t<li><a href=\"http://nathanmarz.com/blog/principles-of-software-engineering-part-1.html\">Nathan Marz: Principles of Software Engineering, Part 1</a> - Nathan has worked with Big Data at Twitter and other places and really knows the perils or large, distributed, real-time systems and this post contains plenty of valuable advice for making robust, reliable SW. Main message: \"<em>there's a lot of <strong>uncertainty</strong> in software engineering</em>\"; every SW operates correctly only for a certain range of inputs (including volume, HW it runs on, ...) and you never control all of them so there always is an opportunity for failure; you can't predict what inputs you will encounter in the wild. <em>\"[..] while software is deterministic, you can't treat it as deterministic in any sort of practical sense if you want to build robust software.</em>\" \"<em><strong>Making software robust is an iterative process</strong>: you build and test it as best you can, but inevitably in production you'll discover new areas of the input space that lead to failure. Like rockets, it's <strong>crucial to have excellent monitoring</strong> in place so that these issues can be diagnosed.</em>\". From the content: Sources of uncertainty (bugs, humans, requirements, inputs, ..), Engineering for uncertainty (minimize dependencies, lessen % of cascading failure [JH: -&gt; <a href=\"https://github.com/Netflix/Hystrix\">Hystrix</a>], measure and monitor)\r\n<ul>\r\n\t<li><a href=\"http://nathanmarz.com/blog/suffering-oriented-programming.html\">Suffering-oriented programming</a> is certainly also worth reading (summary: do not start with great designs; only start generalizing and creating libs when you have suffered enough from doing things more manually and thus learned the domain; make it possible &gt; make it beautiful &gt; make it fast, repeat)</li>\r\n</ul>\r\n</li>\r\n\t<li><a href=\"http://www.go.cd/\">ThoughtWorks open-sources Go, continuous delivery platform</a> - good bye, Jenkins! - better support for pipelines etc., see <a href=\"http://www.go.cd/features/\">features</a> and <a href=\"http://www.thoughtworks.com/products/docs/go/current/help/concepts_in_go.html\">elementary concepts</a></li>\r\n\t<li><a href=\"http://msdn.microsoft.com/en-us/library/dn568099.aspx\">Cloud Design Patterns: Prescriptive Architecture Guidance for Cloud Applications</a> (recommended by <a href=\"https://twitter.com/markusbk\">@markusbk</a> so it must be good); Patterns: Cache-aside, Circuit Breaker, Compensating Transaction, Competing Consumers, Compute Resource Consolidation, Command and Query Responsibility Segregation (CQRS), Event Sourcing, External Configuration Store, Federated Identity, Gatekeeper, Health Endpoint Monitoring, Index Table, Leader Election, Materialized View, Pipes and Filters, Priority Queue, Queue-based Load Leveling, Retry, Runtime Reconfiguration, Scheduler Agent Supervisor, (data) Sharding, Static Content Hosting (-&gt; CDN), Throttling, Valet Key.\r\nGuidance topics: Asynchronous Messaging Primer, Autoscaling, Caching, Compute Partitioning, Data Consistency Primer, Data Partitioning, Data Replication and Synchronization, Instrumentation and Telemetry, Multiple Datacenter Deployment, Service Metering</li>\r\n\t<li><a href=\"http://mooc.cs.helsinki.fi/clojure\">MOOC course Functional programming with Clojure</a> at Uni of Helsinki - to get started you need, I suppose, follow the \"<a href=\"http://iloveponies.github.io/120-hour-epic-sax-marathon/index.html\">Material and course content</a>\" - essentially read the text for each chapter, clone its repo, submit pull requests to get your work graded</li>\r\n\t<li><a href=\"http://www.thoughtworks.com/insights/blog/case-continuous-delivery\">Jez Humble: The Case for Continuous Delivery</a> - read to persuade manager about CD: \"Still, many managers and executives remain unconvinced as to the benefits [of CD], and would like to know more about the economic drivers behind CD.\" CD reduces waste: \"[..]online controlled experiments (A/B tests) at Amazon. This approach created hundreds of millions of dollars of value[..],\" reduces risks: \"[..] Etsy, has a great <a href=\"http://www.usievents.com/en/conferences/8-paris-usi-2011/sessions/968-john-allspaw\">presentation</a> which describes how deploying more frequently improves the stability of web services.\" CD makes development cheaper by reducing the cost of non-value-adding activities such as integration and testing. F.ex. HP got dev. costs down by 40%, dev cost/program by 78%</li>\r\n</ul>\r\nWeb\r\n<ul>\r\n\t<li><a href=\"http://freshbrewedcode.com/jimcowart/2012/03/19/client-side-messaging-in-javascript-part-3-anti-patterns/\" rel=\"bookmark\">Client-side messaging in JavaScript – Part 3 (anti-patterns)</a> (via <a href=\"https://twitter.com/ruudud\">@ruudud</a> so it must be worth reading)</li>\r\n\t<li><a href=\"http://jakearchibald.github.io/request-quest/\">Request Quest</a> (via <a href=\"https://twitter.com/jraregris\">@jraregris</a>) - entertaining and educational intractive quiz regarding what does (not) trigger a request in browsers and differences between them (and deviances from the standard) - img, script, css, etc.</li>\r\n\t<li><a href=\"http://soundadvice.id.au/blog/2009/06/13/\">The REST Statelessness Constraint</a> - a nice post about statelessness in REST if you, like me, don't know REST so much in depth; highlights: Statelesness (and thus the requirement for clients to send their state with every request) is a trade-off crucial for web-scale and partially balanced by caching - while typical enterprise apps have different needs (more state, less scale) so REST isn't a perfect match. Distinguish application (client-side) and server (resources) state. Using a DB to hold the state still violates the requirement. Use links to transfer some state (e.g. contain a link to fetch the next page of records in the response).</li>\r\n\t<li><a href=\"http://reactive-extensions.github.io/learnrx/\">Functional Programming in Javascript</a> - an interactive tutorial teaching map, filter, mergeAll, reduce, zip</li>\r\n</ul>\r\nOther\r\n<ul>\r\n\t<li><a href=\"http://www.infoq.com/code-mesh-2013/\">CodeMesh 2013 presentations</a> - good stuff! F.ex. Refactoring Functional Programs: Past and Future, Distribution, Scale and Flexibility with ZeroMQ, Deepak Giridharagopal on Puppet, Immutable Deployments, Analyzing Systems with PuppetDB, Francesco Cesarini and Viktor Klang on the Reactive Manifesto and more</li>\r\n\t<li><a href=\"http://edgeperspectives.typepad.com/edge_perspectives/2011/11/cognitive-biases-in-times-of-uncertainty.html\">Cognitive Biases in Times of Uncertainty</a> - people under pressure/stress start to focus on risks over gains and (very) short-term rather than long-term and thus also adopt 0-some mindset (i.e. if sb. else wins, I loose) =&gt; polarization into we x them and focus on getting as big piece of the cake possible at any price, now, dismissal of collaboration. With accelerating rate of change in the society due to technology, this is exactly what is happening. How to counter it? Create more positive narratives than the threat-based ones (views of the world), support them via short-term gains. Bottom line: each of us must work on spreading a more positive attitude to save us from bleak future.</li>\r\n\t<li><a href=\"http://www.manning.com/marz/\">Book - Nathan Marz: Big Data</a> - I dislike the big data hype (and, with passion, Hadoop) but would love to read this book; it presents a fresh look at big data processing, heavily inspired by functional programming. Nathan has plenty of experiences from Twitter and creating <a href=\"http://storm.incubator.apache.org/\">Storm</a> and <a href=\"http://cascalog.org/\">Cascalog</a> (both in Clojure, btw.). Read ch 1:  <a href=\"http://www.manning.com/marz/BDmeapch1.pdf\" target=\"_blank\">A new paradigm for big data</a>.</li>\r\n\t<li>Facebook Engineering: <a href=\"https://m.facebook.com/notes/facebook-engineering/the-mature-optimization-handbook/10151784131623920\">The Mature Optimization Handbook</a> (or go directly to the <a href=\"http://carlos.bueno.org/optimization/mature-optimization.pdf\">pdf</a>,   <a href=\"http://m.facebook.com/l.php?u=http%3A%2F%2Fcarlos.bueno.org%2Foptimization%2Fmature-optimization.epub&amp;h=hAQHRignh&amp;s=1\" target=\"_blank\">ePub</a>, <a href=\"http://m.facebook.com/l.php?u=http%3A%2F%2Fcarlos.bueno.org%2Foptimization%2Fmature-optimization.mobi&amp;h=GAQFDKjj1&amp;s=1\" target=\"_blank\">Mobi</a>). If you get bored, jump directly to ch 5. Instrumentation.</li>\r\n</ul>\r\nClojure Corner\r\n<ul>\r\n\t<li><a href=\"https://github.com/prismofeverything/schmetterling/blob/master/README.md\">Schmetterling - Debug running clojure processes</a> from the browser! - upon an exception, the process will pause and S. will show the stack, which you can navigate and see locals and run code in the context of any stack frame; you can also trigger it from your code</li>\r\n\t<li><a href=\"https://github.com/JonyEpsilon/gorilla-repl\">Gorilla REPL</a> (<a href=\"https://raw.github.com/JonyEpsilon/gorilla-repl/master/screenshot.png\">screenshot</a>, 11min <a href=\"http://vimeo.com/87118206\">video</a>)- interactive web-based notebook where you can mix text (with Markdown formatting), mathematical formulas via LaTeX, graphs, tables, Clojure code. Great for exploring and, at the same time, describing data. &lt;3</li>\r\n\t<li><a href=\"http://scattered-thoughts.net/blog/2014/02/17/local-state-is-harmful/\">Local state is harmful</a> - how can we answer the questions about when/why did state X change, how did output Y get where it is? Make state explicit, f.ex. one global map holding all of it, and perhaps not just the current state but also history - thus we can easily query it. Prismatic' Graph can be used to make the state map, watches to keep history. Inspired by databases (Datomic is an excellent example of SW where answering such questions is trivial)</li>\r\n\t<li>S. Corfield:<a href=\"http://corfield.org/blog/post.cfm/insanely-useful-leiningen-plugins\"> Insanely Useful Leiningen Plugins</a> - <a href=\"https://github.com/xsc/lein-ancient\">lein-ancient</a> (find updated deps), <a href=\"https://github.com/kumarshantanu/lein-exec/\">lein-exec</a> (execute Clj from cmd.line / scripts in Clj), <a href=\"https://github.com/rkneufeld/lein-try\">lein-try</a> (try a lib in REPL), <a href=\"https://github.com/jonase/eastwood\">Eastwood</a> - a lint tool for Clojure</li>\r\n\t<li><a href=\"https://github.com/ptaoussanis/sente\">Sente - Clojure(Script) + core.async + WebSockets/Ajax</a> - a tiny 600 LoC library for websockets (with fall-back to long-polling) communication between ClojureScript frontend and clojure backend, using EDN, support for request-reply and multiple user windows/tabs (<a href=\"https://groups.google.com/forum/m/#!msg/clojure/5J4L8pbGwGU/O1RSsiKE_JUJ\">comparison with Chord</a> (no non-WS fallback or req/resp))</li>\r\n\t<li><a href=\"http://nicholaskariniemi.github.io/2014/02/25/clojure-bootstrapping.html\">Nicholas Kariniemi: Why is Clojure bootstrapping so slow?</a> - don't blame the JVM, most time spent in clojure.core according to this analyzes on JVM and Android (create and set vars, load other namespaces); some proposals for improving it - lazy loading, excluding functionality not used, ...</li>\r\n\t<li><a href=\"http://blog.lauripesonen.com/cheat-your-way-to-running-cljs-on-node/\">Cheat your way to running CLJS on Node</a> - (ab)use D. Nolen's mies template intended for client-side cljs development to create a Node project; the trick: compile everything into 1 file so that Node does not fail to find dependencies, disable source maps etc. Update: the <code>nodecljs</code> template now does this</li>\r\n\t<li>\r\n<p style=\"display:inline !important;\"><a href=\"https://github.com/mynomoto/lt-clojure-tutorial\">lt-clojure-tutorial</a> - A Clojure tutorial optimized for <a href=\"http://www.lighttable.com/\">Light Table</a>, ported from Nolen's cljs tutorial</p>\r\n</li>\r\n</ul>\r\n<h2>Tools/Libs</h2>\r\n<ul>\r\n\t<li><a href=\"http://www.charlesproxy.com/\">Charles - web debugging proxy application</a> (via <a href=\"https://twitter.com/ruudud\">@ruudud</a>) - to view all of the HTTP and SSL / HTTPS traffic between their machine and the Internet (shareware)</li>\r\n</ul>",
  "excerpt": ""
 },
 {
  "title": "The Risks Of Big-Bang Deployments And Techniques For Step-wise Deployment",
  "published": "2014-02-17 15:57:01",
  "postType": "post",
  "slug": "/2014/02/17/the-risks-of-big-bang-deployments/",
  "status": "publish",
  "tags": [
   "deployment",
   "opinion"
  ],
  "categories": [
   "SW development"
  ],
  "content": "<em>If you ever need to persuade management why it might be better to deploy a larger change in multiple stages and push it to customers gradually, read on.</em><br><br><img class=\"alignleft\" style=\"margin-right:10px;\" title=\"By demplex.deviantart.com\" src=\"https://lh5.googleusercontent.com/-tbJyBUX-TPo/UwRnJ_kVDpI/AAAAAAAACto/PvdejoXUTw4/w533-h512-no/explosion_by_demplex-d5vrrpr.png\" alt=\"\" width=\"320\" height=\"307\" />A deployment of many changes is risky. We want therefore to deploy them in a way which minimizes the risk of harm to our customers and our companies. The deployment can be done either in an all-at-once (also known as big-bang) way or a gradual way. We will argue here for the more gradual (\"stepwise\") approach.<br><br><h2>Big-bang or stepwise deployment?</h2><br><br>A big-bang deployment seems to be the natural thing to do: the full solution is developed and tested and then replaces the current system at once. However, it has two crucial flaws.<br><br><!--more--><br><br>First, it assumes that most defects can be discovered by testing. However, due to differences in test/prod environments, unknown dependencies, and the sheer scale of a typical larger system there always will be problems that are not discovered until production deployment or even until the application runs for a while in production (which <a href=\"http://www.dn.no/forsiden/naringsliv/article2753750.ece\">applies even to airplanes</a>). The more parts have been changed, the more of these production defects will happen at the same time. A gradual deployment makes it possible to discover and handle them one by one.<br><br>Second, the more complex the deployment, the higher chance of human error(s), i.e. the deployment itself is a likely source of serious defects.<br><br>Some of the drawbacks of a big-bang deployment in more detail:<br><br><ol>\n    <li>Complexity: A big-bang deployment requires coordination of many people and \"moving parts\" that depend on each other, providing a huge opportunity for human mistake (i.e. there <em>will be</em> mistakes).</li>\n    <li>Lot of time: Such a deployment requires lot of time (typically also more than planed/expected) and thus lot of downtime when users cannot use the system.</li>\n    <li>Hard troubleshooting: With a network of inter-dependent parts that changed all at the same time, while perhaps also changing the infrastructure (i.e. connections between them), it is extremely hard to pinpoint the source of defects, thus considerably increasing the time to detect and correct defects while also increasing the risk of people stepping on the toes of each other and \"panic fixes\" that either cause more problems than they remove or are not good enough (as the rollback that sped up <a href=\"http://pythonsweetness.tumblr.com/post/64740079543/how-to-lose-172-222-a-second-for-45-minutes\">Knight's downfall</a>).</li>\n    <li>Rollback is likely either impossible or equally time-consuming and risky as the deployment itself, thus increasing the impact of defects and inviting even more human errors.</li>\n    <li>Impact: Deploying everything to all users at the same time means that everybody will be impacted by a potential defect/error/mistake.</li>\n    <li>Long freeze: All needs to be tested together after all development is finished, which requires a lot of time while the code is frozen and no more fixes and changes can get into production for weeks.</li>\n</ol><br><br><h2>Risk mitigation</h2><br><br>The goal of a good deployment plan is to mitigate the risk of the deployment and get it to an acceptable level. There are two aspects to risk: the <em>probability</em> of a defect and the <em>impact</em> of the defect. The following table shows how the possible measures affect them:<br><br><table border=\"1px\">\n<tbody>\n<tr>\n<th>Defect probability reduction</th>\n<th>Defect impact reduction</th>\n</tr>\n<tr>\n<td>testing</td>\n<td>\n<ul>\n    <li>stepwise deployment</li>\n    <li>gradual migration of users to the new version (f.ex. 1 in 1000 or particular subsets)</li>\n    <li>rollback mechanism</li>\n</ul>\n</td>\n</tr>\n<tr>\n<td></td>\n<td><em>=&gt; these also lead to much lower time to detect and fix defects</em></td>\n</tr>\n</tbody>\n</table><br><br><h2>Practices for stepwise deployment</h2><br><br>Enable stepwise deployment: Use <a href=\"/wiki/development/parallel-design-parallel-change/\">parallel change</a> and other <a href=\"http://www.amazon.com/dp/0321601912?tag=contindelive-20\">Continuous Delivery</a> techniques to make it possible to deploy updated components independently from each other and to switch on/off new features and to switch what versions of the components they depend on are currently used. (Parallel change - keeping the old and new code and being able to use one or the other - is crucial here. Also notice that parallel change applies also to data - you will need to evolve your data schema gradually and keep both old and new one at the same time in a period of time.)<br><br>Enable rollback. The previous measure - stepwise deployment - makes it also easy(ier) to roll-back the changes by switching to a previous version of a dependency or by switching back to the old code.<br><br>Migrate users gradually to the new version, i.e. expose the new version only to a small subset of the users initially and increase that subset until everybody uses it. This can be done f.ex. by deploying to only a subset of servers and sending a random/particular subset of users to the new servers but there are also ways if you have only a single machine. (See f.ex. my post <a title=\"Permanent link to Webapp Blue-Green Deployment Without Breaking Sessions/With Fallback With HAProxy\" href=\"/2013/09/05/blue-green-deployment-without-breaking-sessions-with-haproxy-and-jetty/\" rel=\"bookmark\">Webapp Blue-Green Deployment Without Breaking Sessions/With Fallback With HAProxy</a>.)<br><br>Monitoring - make sure you are able to monitor flow of users through the system and detect any anomalies and errors early, long before angry calls from the business. Tools such as <a href=\"http://logstash.net/\">Logstash</a>, Google Analytics (with custom events from JavaScript), <a href=\"http://dev.opera.com/articles/view/client-side-error-logging/\">client-side error logging</a> via one of<a href=\"https://plus.google.com/+PaulIrish/posts/12BVL5exFJn\"> existing services</a> or a custom solution are invaluable.<br><br><h2>Making the right decision</h2><br><br>Henrik Kniberg (Spotify, Lean from Trenches) <a title=\"Dyr lärdom från PUST: hur undvika nya IT-fiaskon?\" href=\"http://blog.crisp.se/2014/02/21/henrikkniberg/pust-lardomar\">describes how the Swedish police decided</a>, under the influence of its CIO and an Oracle/Siebel consultant and against the will of the IT department, to throw away the successful PUST project, implemented in an agile way, and do it from scratch based on Siebel, i.e. a standardized platform, with the wishfull-thining-driven idea of lowered operational/maintenance costs. They also decided against iterative development and in favor of a single big-bang deployment at the end. It was a disaster. Kniberg takes to main lessons from this fiasko:<br><br><ol>\n    <li>Never take important technical decision without involving those that should build the solution. (Hint: \"involving\" does not mean asking for input and then deciding however you want anyway.)</li>\n    <li>Work iteratively, in collaboration with the right users, deploy early limited pilot versions to the right users, improve the product continually based on their feedback.</li>\n</ol><br><br>Main point for me: When management decides whether it should do a gradual or a big-bang deployment, it should take the opinion of developers and ops people really seriously and not just as one of inputs.<br><br><p style=\"text-align:center;\"><em>You might enjoy also other <a href=\"/tag/opinion/\">posts on effective development</a>.</em></p>",
  "excerpt": ""
 },
 {
  "title": "Seek Understanding",
  "published": "2014-02-23 14:48:47",
  "postType": "post",
  "slug": "/2014/02/23/seek-understanding/",
  "status": "publish",
  "tags": [
   "human",
   "opinion"
  ],
  "categories": [
   "General"
  ],
  "content": "The most important lesson I have learned in 2013 is that I won't change anything by writing critical blog posts and talking to like-minded people. Fostering the \"we vs. them,\" we who are right vs. them idiots sentiment is ineffective, even destructive. To be able to achieve anything, I have to talk to the people with opposite opinions and understand them. They are rarely ***holes and typically have good reasons for their opinions. Only by understanding those reasons and the background, history, and emotions they stem from - and hopefully helping the \"opponents\" understand some of my reasons and context - we can find a common ground and common goals that we can build upon to go further - perhaps not in harmony but still together rather than against each other.<br><br>Talking to people is difficult. Having my dearly hold beliefs exposed to discussion and criticism is painful. Trying to find a common ground with people with totally different needs, experiences, and ideas about the best way to do software development in a particular context is challenging. But only by doing so, and by being open to changing my own stance, I can hope to influence the stance of other \"stakeholders\" and thus bring a positive change to a project or organization.<br><br>Side note: It's funny that the more I learn about IT the more I realize that the main challenges and solutions we encounter are not about technology, but about the fundamentally human in us. Also the approach advocated here - seeking understanding and respect in spite of disagreement instead of the radically adversarial \"we vs. them\" thinking - is crucial not just for IT, but also for building a better society. So far it unfortunately seems that politicians - especially in the US but not just there - tend to prefer the wrong approach. And also the willingness to expose one's beliefs to discussion and the openness to change are important not only for talking to people, but for being able to keep developing mentally and spiritually, as put so well by M. Scott Peck in <a href=\"http://www.amazon.com/Road-Less-Traveled-Timeless-Traditional/dp/0743243153/\">The Road Less Traveled</a>.<br><br>I'd like to thank to Markus Krüger for showing me the power of talking to people and to Marshall B. Rosenberg's <a href=\"http://www.amazon.com/Nonviolent-Communication-A-Language-Life/dp/1892005034\">Nonviolent Communication: A Language of Life</a> for being so inspirational on this path.<br><br><p style=\"text-align:center;\"><em>You might enjoy also other <a href=\"/tag/opinion/\">posts on effective development</a>.</em></p>",
  "excerpt": ""
 },
 {
  "title": "Handling Deployments When Provisioning JBoss domain.xml (With Ansible)",
  "published": "2014-02-24 14:54:18",
  "postType": "post",
  "slug": "/2014/02/24/handling-deployments-when-provisioning-jboss-domain-xml-with-ansible/",
  "status": "publish",
  "tags": [
   "ansible",
   "DevOps",
   "jboss"
  ],
  "categories": [
   "General"
  ],
  "content": "It is tricky to manage JBoss with a provisioner such as Puppet or Ansible because its <code>domain.xml</code> contains not only rather static configuration but also sections that change quite often such as <code>deployments</code>. So how can we manage the static parts of <code>domain.xml</code> with f.ex. Ansible while still enabling developers to deploy at will via <code>jboss-cli</code> (and thus changing the <code>&lt;deployments&gt;</code> sections of the file)? Here is one possible solution, based on extracting the sections from the current file and merging them into the template.<br><br><!--more--><br><br>We will use XSLT stylesheets to extract the deployments sections via <code>xsltproc</code> run as a command, storing their output into variables that will be then used in the <code>domain.xml</code> template. (<code>xsltproc</code> has been chosen since it already was on our servers.)<br><br>Here are the Ansible tasks themselves:<br><br><pre><code>\r\n## JBoss merge deployment info from the existing domain.xml if any and copy the final domain.xml\r\n# Note: &lt;deployments&gt; is added at 2 places to domain.xml whenever an app is deployed via JBoss CLI, we need to keep them\r\n- name: Make sure xsltproc is installed\r\n  yum: name=libxslt state=installed\r\n  tags: jboss_configuration<br><br>- name: Copy XSLT stylesheets for domain.xml data extraction\r\n  copy: src={{ item }} dest=/tmp\r\n  with_items:\r\n    - extract_domain_deployments.xslt\r\n    - extract_servergroup_deployments.xslt\r\n  tags: jboss_configuration<br><br>- name: Check if domain.xml already present\r\n  stat: path=/opt/jboss/jboss-{{ jboss_version_short }}/domain/configuration/domain.xml\r\n  register: domain_xml_stat\r\n  tags: jboss_configuration<br><br>- name: Extract domain/deployments from domain.xml, if present\r\n  command: /usr/bin/xsltproc /tmp/extract_domain_deployments.xslt /opt/jboss/jboss-{{ jboss_version_short }}/domain/configuration/domain.xml\r\n  register: domain_deployments\r\n  when: domain_xml_stat.stat.exists is defined and domain_xml_stat.stat.exists == true\r\n  tags: jboss_configuration<br><br>- name: Extract server-groups//deployments from domain.xml, if present\r\n  command: /usr/bin/xsltproc /tmp/extract_servergroup_deployments.xslt /opt/jboss/jboss-{{ jboss_version_short }}/domain/configuration/domain.xml\r\n  register: servergroup_deployments\r\n  when: domain_xml_stat.stat.exists is defined and domain_xml_stat.stat.exists == true\r\n  tags: jboss_configuration<br><br>- name: Copying domain.xml configuration file\r\n  template: src=domain.xml dest=/opt/jboss/jboss-{{ jboss_version_short }}/domain/configuration/\r\n  notify: restart jboss-eap\r\n  tags: jboss_configuration\r\n</code></pre><br><br>The <code>extract_domain_deployments.xslt</code> stylesheet:<br><br><pre><code>\r\n&lt;xsl:stylesheet version=&quot;1.0&quot;\r\n    xmlns:j=&quot;urn:jboss:domain:1.5&quot;\r\n    xmlns:xsl=&quot;http://www.w3.org/1999/XSL/Transform&quot;&gt;<br><br>&lt;!-- Output the domain/deployments element of domain.xml as is, without namespaces etc. --&gt;<br><br>&lt;xsl:output omit-xml-declaration=&quot;yes&quot;/&gt;\r\n&lt;xsl:template match=&quot;/&quot;&gt;\r\n  &lt;xsl:apply-templates select=&quot;j:domain/j:deployments&quot; /&gt;\r\n&lt;/xsl:template&gt;<br><br>&lt;xsl:template match=&quot;*&quot; name=&quot;identity&quot;&gt;\r\n  &lt;xsl:element name=&quot;{name()}&quot;&gt;\r\n    &lt;xsl:apply-templates select=&quot;node()|@*&quot; /&gt;\r\n  &lt;/xsl:element&gt;\r\n&lt;/xsl:template&gt;<br><br>&lt;!-- Copy content as is --&gt;\r\n&lt;xsl:template match=&quot;node()|@*&quot; priority=&quot;-2&quot;&gt;\r\n  &lt;xsl:copy&gt;\r\n    &lt;xsl:apply-templates select=&quot;node()|@*&quot; /&gt;\r\n  &lt;/xsl:copy&gt;\r\n&lt;/xsl:template&gt;<br><br>&lt;/xsl:stylesheet&gt;\r\n</code></pre><br><br>\r\nThe (quite similar) <code>extract_servergroup_deployments.xslt</code> stylesheet:<br><br><pre><code>\r\n&lt;xsl:stylesheet version=&quot;1.0&quot;\r\n    xmlns:j=&quot;urn:jboss:domain:1.5&quot;\r\n    xmlns:xsl=&quot;http://www.w3.org/1999/XSL/Transform&quot;&gt;<br><br>&lt;!-- Output the domain/server-groups/server-group/deployments element of domain.xml as is, without namespaces etc. --&gt;<br><br>&lt;xsl:output omit-xml-declaration=&quot;yes&quot;/&gt;\r\n&lt;xsl:template match=&quot;/&quot;&gt;\r\n  &lt;xsl:apply-templates select=&quot;j:domain/j:server-groups/j:server-group/j:deployments&quot; /&gt;\r\n&lt;/xsl:template&gt;<br><br>&lt;xsl:template match=&quot;*&quot; name=&quot;identity&quot;&gt;\r\n  &lt;xsl:element name=&quot;{name()}&quot;&gt;\r\n    &lt;xsl:apply-templates select=&quot;node()|@*&quot; /&gt;\r\n  &lt;/xsl:element&gt;\r\n&lt;/xsl:template&gt;<br><br>&lt;!-- Copy content as is --&gt;\r\n&lt;xsl:template match=&quot;node()|@*&quot; priority=&quot;-2&quot;&gt;\r\n  &lt;xsl:copy&gt;\r\n    &lt;xsl:apply-templates select=&quot;node()|@*&quot; /&gt;\r\n  &lt;/xsl:copy&gt;\r\n&lt;/xsl:template&gt;<br><br>&lt;/xsl:stylesheet&gt;\r\n</code></pre><br><br>The XSLT is so complex because we only have XSLT 1.0 and need to get rid of any namespace declarations that would normally be output. (See <a href=\"http://lenzconsulting.com/namespaces-in-xslt/#too%5Fmany%5Fnamespaces\">E. Lenz' Too Many Namespaces</a> for background and better options in XSLT 2.0).\r\n<h2>Disadvantages</h2>\r\nWhen we execute Ansible with --check --diff, it will always report that it would remove deployments from the file because it doesn't run the extraction commands.",
  "excerpt": ""
 },
 {
  "title": "JavaServer Faces Are Evil (draft)",
  "published": "2014-02-24 16:14:24",
  "postType": "post",
  "slug": "/2014/02/24/javaserver-faces-are-evil-draft/",
  "status": "publish",
  "tags": [],
  "categories": [
   "Uncategorized"
  ],
  "content": "<h2>1. Problem</h2>\r\nLet me start with a story. Once upon time\r\n<ul>\r\n\t<li>there were 2 developers</li>\r\n\t<li>working together for 1 day</li>\r\n\t<li>to produce 2 lines of hackish JavaScript</li>\r\n</ul>\r\nWhy? <em>Because JSF makes it hard to do anything its authors haven't expected when designing it.</em><br><br>----<br><br>Let me repeat it: 2 experienced consultants, working 1 day to produce 2 ugly lines of code.<br><br>Can you smell the scent of money burning?<br><br>And this is my point today: Frameworks are bloody expensive.<br><br>... A point I want to demonstrate on the example of JSF.\r\n<h2>2. Exploration</h2>\r\nWhat is JSF?\r\n<ul>\r\n\t<li>Standard Java EE web framework that abstracts away HTTP - and provides a stateful tree of components, familiar from desktop UIs</li>\r\n\t<li>It renders the tree into HTML and reflects user actions back to the tree and eventually to the model POJOs bound to the components</li>\r\n\t<li>Tries to abstract away HTML/CSS/JS (shiled; hidden in components)</li>\r\n\t<li>It does everything: Data binding with type conversion, validation, navigation, i18n, templating etc.</li>\r\n</ul>\r\nSo what is wrong with JSF? (goto ihatejsf.com)\r\n<ul>\r\n\t<li>The main problem: it is a complex beast; ex.:\r\n<ul>\r\n\t<li>6-10 phase req-resp lifecycle, and good luck if you need something that does not fit it!</li>\r\n\t<li>JSF is a component fwrk - yet creating a component in JSF 1 was a lot of work; much easier now but the complexity is still there, only hidden</li>\r\n\t<li>The complexity is shown on failures such as the infamous \"duplicate id\" error when rendering</li>\r\n</ul>\r\n</li>\r\n\t<li>No separation of concerns: A complected, all-in-one black box =&gt; stuck with author's choices</li>\r\n\t<li>Tries to hide how web works (http/html/css/etc) =&gt; of course a leaky abstraction! (Hibernate, anyone?)</li>\r\n\t<li>Pluggable yet inflexible and limited/ing</li>\r\n</ul>\r\n<a href=\"http://thoughtworks.fileburst.com/assets/technology-radar-jan-2014-en.pdf\">ThoughtWorks Technology Radar 1/2014</a>:\r\n<blockquote>We continue to see teams run into trouble using JSF - JavaServer Faces - and<strong> are recommending you avoid this technology</strong>.<br><br>Teams seem to choose JSF because it is a J2EE standard without really evaluating whether the programming model suits them. We think JSF is flawed because it tries to abstract away HTML, CSS and HTTP, exactly the reverse of what modern web frameworks do. JSF , like ASP.NET webforms, attempts to create statefulness on top of the stateless protocol HTTP and ends up causing a whole host of problems involving shared server-side state. We are aware of the improvements in JSF 2.0, but think<strong> the model is fundamentally broken</strong>.<br><br>We recommend teams use simple frameworks and embrace and understand web technologies including HTTP, HTML and CSS.</blockquote>\r\nHow does that apply to frameworks in general?\r\n<ul>\r\n\t<li>Frameworks are supposed to tackle the intrinsic complexity but add their own</li>\r\n\t<li>They make it easy to start (especially if you have no opinion about how to do things)\r\n- but eventually you hit the walls of accidental complexity and inflexible design\r\n<ul>\r\n\t<li>&lt;- N. Ford: <em>Why everybody eventually hates Maven</em></li>\r\n</ul>\r\n</li>\r\n\t<li>(Achieving simplicity is hard)</li>\r\n</ul>\r\n<h2>3. Way out</h2>\r\nFrameworks are not bad per se, only due to the costs they incur. What would and \"ideal\" framework that does not incur them look lik?<br><br><a href=\"http://creshosk.deviantart.com/\"><img class=\"alignright\" title=\"By Creshosk\" alt=\"\" src=\"http://fc05.deviantart.net/fs71/f/2011/172/6/f/dinky_hooves_by_creshosk-d3jkx53.png\" width=\"60\" height=\"70\" /></a>\r\n<ul>\r\n\t<li>Sensible out-of-the-box behavior</li>\r\n\t<li>Let you easily<em> drop down</em> to any lower level in the <em>extent desired</em> (not “all or none”)</li>\r\n</ul>\r\n&lt;=&gt;\r\n<ul>\r\n\t<li>Doesn’t force a radically different abstraction</li>\r\n\t<li>Empowers, doesn’t hide/take any power from devs</li>\r\n\t<li>Doesn’t try to do/know everything</li>\r\n</ul>\r\nExamples\r\n<ul>\r\n\t<li>Clojure: Composable libs doing 1 thing well</li>\r\n\t<li>Ubuntu</li>\r\n\t<li>Spring JDBC</li>\r\n</ul>\r\nIt is always a cost-benefit decision - but we tend to forget the cost and exaggerate the benefit.\r\n<h2>4. Take away</h2>\r\nWhen you hear \"framework,\" remember this:<br><br><img alt=\"\" src=\"http://www.netanimations.net/Dollar-bill-burning-animated-gif.gif\" width=\"127\" height=\"160\" />",
  "excerpt": ""
 },
 {
  "title": "Ansible Troubleshooting Tips",
  "published": "2014-03-04 14:18:16",
  "postType": "post",
  "slug": "/2014/03/04/ansible-troubleshooting-tips/",
  "status": "publish",
  "tags": [
   "ansible",
   "DevOps"
  ],
  "categories": [
   "Tools"
  ],
  "content": "<em>Few tips for troubleshooting Ansible, based on my brief experiences with Ansible 1.4 (read: do not rely on this info too much).</em>\r\n<h2>Run ansible-playbook in the verbose mode</h2>\r\n<tt>ansible-playbook -vvvv ...</tt> will provide you with plenty of details of what is going on. (Notice that additional v:s, starting from none, add more detail.)\r\n<h2><a href=\"https://github.com/jakubholynet/ansible/blob/devel/docsite/rst/playbooks_troubleshooting.rst#use-hackingtest-module\" name=\"use-hackingtest-module\"></a>Use ./hacking/test-module</h2>\r\nCheck out Ansible sources and use the <tt>./hacking/test-module</tt> script - see <a href=\"https://github.com/jakubholynet/ansible/blob/devel/docsite/rst/playbooks_troubleshooting.rst#id1\">Developing Modules</a>.<br><br><!--more-->\r\n<h2><a href=\"https://github.com/jakubholynet/ansible/blob/devel/docsite/rst/playbooks_troubleshooting.rst#keep-remote-files-and-execute-them-manually\" name=\"keep-remote-files-and-execute-them-manually\"></a>Keep remote files and execute them manually</h2>\r\n<em>Note: This is quite a hack; it is preferred to use the the test-module.</em><br><br>Set the environment variable <tt>ANSIBLE_KEEP_REMOTE_FILES=1</tt> to keep files that Ansible copied to the server so that you can execute them directly on the server yourself and thus troubleshoot them better:\r\n<pre>$ export ANSIBLE_KEEP_REMOTE_FILES=1\r\n$ ansible-playbook ...</pre>\r\nThen, on the server, in the home directory of the user used for ssh-ing, look into <tt>.ansible/tmp/ansible-&lt;unique id&gt;/&lt;module name or \"arguments\"&gt;</tt>. F.ex. to execute manually a command that has failed:\r\n<pre>$ python ./ansible-1392625678.65-85585787027596/command</pre>\r\n<h2><a href=\"https://github.com/jakubholynet/ansible/blob/devel/docsite/rst/playbooks_troubleshooting.rst#common-issues\" name=\"common-issues\"></a>Common issues</h2>\r\n<h3><a href=\"https://github.com/jakubholynet/ansible/blob/devel/docsite/rst/playbooks_troubleshooting.rst#the-halting-issue-ansible-freezes-while-executing-a-command\" name=\"the-halting-issue-ansible-freezes-while-executing-a-command\"></a>The halting issue: Ansible \"freezes\" while executing a command</h3>\r\nThe command is perhaps waiting for user input. Always make sure to execute commands in a non-interactive mode if possible.<br><br>Try to find the command process on the server and kill it while running Ansible with <tt>-vvvv</tt> or/and use <tt>ANSIBLE_KEEP_REMOTE_FILES</tt>and run the Ansible files manually, as suggested above.\r\n<h3><a href=\"https://github.com/jakubholynet/ansible/blob/devel/docsite/rst/playbooks_troubleshooting.rst#ansible-fails-right-at-start-perhaps-with-authentication-or-permission-failure-for-a-new-node\" name=\"ansible-fails-right-at-start-perhaps-with-authentication-or-permission-failure-for-a-new-node\"></a>Ansible fails right at start, perhaps with \"Authentication or permission failure\", for a new node</h3>\r\nAnsible currently doesn't handle SSH problems very transparently, even when run with <tt>-vvvv</tt>. Such a failure could be caused by SSH asking to accept the node's key. In each case, exclude SSH as the cause by SSH-ing into the node manually in the same way as Ansible does so when you run Ansible, it will already have been added to <tt>known_hosts</tt>.<br><br><em>Note: I believe this is fixed/improved in Ansible 1.5</em>.",
  "excerpt": ""
 },
 {
  "title": "Petitioning EU to act against Russian aggression in Ukraine",
  "published": "2014-03-05 10:10:12",
  "postType": "post",
  "slug": "/2014/03/05/petitioning-eu-to-act-against-russian-aggression-in-ukraine/",
  "status": "publish",
  "tags": [],
  "categories": [
   "Uncategorized"
  ],
  "content": "<a href=\"https://secure.avaaz.org/en/petition/European_Union_Catherine_Ashton_Herman_van_Rompuy_Act_on_Ukraine_Immediately/?ckXgJdb\"><img class=\"alignleft\" alt=\"join the campaign\" src=\"https://avaazdo.s3.amazonaws.com/do_generic_en.jpeg\" width=\"300\" height=\"170\" /></a>As a citizen of a country that has been invaded by Hilter in 1938 under the pretext of protecting local Germans and again invaded by Russia in 1968, I cannot watch another such invasion and annexation taking place in Europe while EU does little of any consequences.<br><br>Please consider signing the petition to EU to act against Russian aggression with all the political and economical power it has, even if - oh the horror - will cost our wallets too.<br><br><span style=\"font-size:large;\">Click here to join:\r\n<a href=\"https://secure.avaaz.org/en/petition/European_Union_Catherine_Ashton_Herman_van_Rompuy_Act_on_Ukraine_Immediately/?ckXgJdb\">European Union, Catherine Ashton, Herman van Rompuy: Act on Ukraine. Immediately!</a></span>",
  "excerpt": ""
 },
 {
  "title": "Recursive Copy In Ansible 1.5 And --diff",
  "published": "2014-03-05 13:18:16",
  "postType": "post",
  "slug": "/2014/03/05/recursive-copy-in-ansible-1-5-and-diff/",
  "status": "publish",
  "tags": [
   "ansible",
   "DevOps"
  ],
  "categories": [
   "Tools"
  ],
  "content": "Ansible 1.5 has partial support for recursive copy of files:\r\n<ul>\r\n\t<li>the <a href=\"http://docs.ansible.com/synchronize_module.html\">synchronize</a> module, using rsync\r\n<ul>\r\n\t<li>cons: does not support group=, owner=</li>\r\n\t<li>-C and --diff - it does not print diff of the files changed; when running ansible with -v, it will print output of<a href=\"http://rsync.samba.org/ftp/rsync/rsync.html\"> rsync's --itemize-changes</a>, i.e., for each changed file/dir, something like \"&lt;f.st...... conf/httpd.conf\\n\" (&lt; = file uploaded, s = size changed, t = timestamp changed, . = this attribute has not been changed)</li>\r\n</ul>\r\n</li>\r\n\t<li>the <a href=\"http://docs.ansible.com/copy_module.html\">copy</a> module\r\n<ul>\r\n\t<li>-C --diff - it only reports \"changed\" without naming the changed files or showing diffs (unless there is only one changed file)</li>\r\n</ul>\r\n</li>\r\n\t<li>the local_action module, used to run rsync manually (essentially the same as synchronize but more control)</li>\r\n\t<li>So <span style=\"font-size:14px;line-height:1.5em;\">the only way to do a kind of recursive copy with working diff is to use </span><code style=\"font-size:14px;line-height:1.5em;\">copy </code><span style=\"font-size:14px;line-height:1.5em;\">with </span><a style=\"font-size:14px;line-height:1.5em;\" href=\"http://docs.ansible.com/playbooks_loops.html#looping-over-fileglobs\">with_fileglob</a><span style=\"font-size:14px;line-height:1.5em;\"> for each directory and subdirectory :-(</span></li>\r\n</ul>\r\nTo check differences (without diff) manually:<br><br><pre><code>rsync -e ssh -vrnc --itemize-changes source/dir myuser@myserver:/opt/dest/</code></pre><br><br>where v= verbose, r = recursive, n = dry-run, c = check based on checksum, not timestamp+size; a typical output for a changed file is <code>&lt;fcsT...... httpd.conf</code> (&lt; = to be uploaded, f = it is a file, c = checksum differ, s = size differ, T = timestamp would be updated).",
  "excerpt": ""
 },
 {
  "title": "Frustration-Driven Development - Towards DevOps, Lean, Clojure",
  "published": "2014-03-17 19:45:50",
  "postType": "post",
  "slug": "/2014/03/17/frustration-driven-development-towards-devops-lean-clojure/",
  "status": "publish",
  "tags": [
   "opinion"
  ],
  "categories": [
   "SW development"
  ],
  "content": "<p style=\"text-align:center;\"><em>A post about development practices, speed, and frustration.</em></p><br><br>My wife has mentioned that she likes my passion for doing things right in software development. That made me thinking, why do I actually care so much and do not just enjoy the coding itself? It boils down to that I am not happy until my code is in production. <em>Seeking the satisfaction of having my code used by and helping people while trying to eliminate all unnecessary mental drain is behind all the practices that I embrace and evangelize.</em> It's a drug I like to take often, in small doses.<br><br><blockquote>practices = f(max(delivered value), min(mental energy))</blockquote><br><br>So how does this relate to DevOps, Continuous Delivery, testing, single-piece-flow, Lean Startup, Clojure? It is simple.<br><br><!--more--><br><br><h3>Build It Fast</h3><br><br>I care about <strong>DevOps and Continuous Delivery</strong> because they are about getting my stuff out as soon as possible. I love to build &amp; ship, get it used right after finishing. Having my work sitting in a queue - for a code review, testing, deployment - is frustrating. I want to finish it, see it running, being used, and working well and put it off my brain so that i can focus on the next thing with a clear mind. That is why also single-piece-flow sounds so attractive to me. If my work is not deployed, used, and thus confirmed to be OK and useful, it is not finished. It may come back due to defects and I have no proof that it actually was worthwhile. The lack of the it's-working-and-valuable gratification and the mental drain of having multiple unfinished things (see <a href=\"http://en.wikipedia.org/wiki/Bluma_Zeigarnik#The_Zeigarnik_Effect\">Zeigarnik effect</a>) is frustrating.<br><br><h3>Build The Right Thing</h3><br><br>For the same reason I care about <strong>users and building the right thing</strong>, i.e. something that they actually will use and benefit from, while also making it as user-friendly as possible. A tight contact with users/business, A/B testing and other Lean Startup techniques, user monitoring are some of great tools and practices that help us ensure that we indeed build the right thing. I am a very skeptical person. History has shown many times that we are terrible at predicting what users need / want so I don't believe in the value of a product until I see data that prove it. As Mary Poppendieck famously put it, \"Show me the money!\" I'm convinced that development is primarily about discovery - both of value (for users) and of the technical (challenges and solutions). The degree of uncertainty may vary but it is always there. It is frustrating to see projects following blindly the course set by an \"omniscient\" stakeholder / PM / architect.<br><br><h3>Build It Right</h3><br><br>I also care a lot about <strong>testing, TDD, and the \"build quality in\"</strong> of lean. I want to get the fruit of my work to users to improve their lives ASAP and then delete it from my brain. But defects make it come back. So without good quality, I may never know whether I am actually finished or not. <a href=\"http://www.lunalindsey.com/2013/10/splines-theory-spoons-metaphor-for.html\">Context switching and re-loading the previous work into my mind is mentally tiring</a>. Also, I dislike testing phases and code freeze, they are obstacles - not just rocks, but mountains - on the path from code to value. Therefore good quality built in, automated tests, and all the Continuous Delivery practices are crucial.<br><br>I crave for improving people's (users') lives. I want to have the satisfaction of this drug of mine often and quickly. Struggling with spaghetti legacy code is slowing me down. Therefore I care about <strong>good and simple architecture and design</strong> (DRY, SRP and all the stuff). I care a lot for refactoring; a true professional aims for long-term sustainable high development speed over quick fixes. I have been too often on the bad end of \"let's hack this quickly now and pay the price later.\"<br><br><h3>Use The Best Tools</h3><br><br>My love for producing value for users also explains why I have grown to <strong>dislike Java and like Clojure</strong> (though it can be generalized to other languages, f.ex. C# vs. F#). In Java, it feels very wasteful to keep repeating myself due to weak abstractions and to write heaps of boilerplate code (all those getters, Comparators etc.) Clojure is <a href=\"http://paulgraham.com/avg.html\">much more powerful</a>, with abstractions that make it easy to \"say things once\" such as higher-order functions and multimethods, and is malleable to fit the problem at hand like a glove (thanks to macros etc.). Java, on the other hand, forces me to fit the problem to the language and to write loads of boilerplate code. Also, in Clojure, REPL enables truly interactive and exploratory development, with an extremely short feedback loop and thus helps me go fast. My favorite example of the Clojure-Java dichotomy is a map-reduce job written using the Clojure library Cascalog vs. what it would look like in plain Hadoop Java. (It is a little pears-and-apples comparison but demonstrates the point of <a href=\"http://nathanmarz.com/blog/introducing-cascalog-a-clojure-based-query-language-for-hado.html\">90% business code</a> vs. <a href=\"https://hadoop.apache.org/docs/r1.2.1/mapred_tutorial.html#Example%3A+WordCount+v1.0\">90% boilerplate code</a>).<br><br>For similar reasons, when I have to use a framework or a library, I prefer one that actually makes my life simpler and does not make me fight it all the time. (So no to JSF.)<br><br><h3>People Matter Too</h3><br><br>Organizations based on trust, with good inter-personal relationships, are the most conductive for creativity and productivity. I therefore prefer <a href=\"http://flowchainsensei.wordpress.com/2013/09/15/rightshifting-and-the-marshall-model-class-101/\">synergistic/chaordic organizations</a> (over analytic or, Cthulhu save us, toxic ones) and good teams.<br><br><h2>Few Historical Examples</h2><br><br>Project Gnomes: This was a technically great project, with DevOps, full control over everything, frequent releases. Yet it frustrated me because I did not believe in the value of the product being built.<br><br>Project Blackjack: On the positive side, this was a very business/users-oriented project driven by actual needs of real users. But it was in the stone age of development, with outdated technologies, hosting and thus all environment changes outsourced to a less-than-flexible international company with changes taking from days to months, and the development was little too much focused on risk.<br><br><h2>Why Should The Business Care?</h2><br><br>The business does care about making money, not about making me happy. So why should they care about my frustration? Why should they care about starting to get value from IT ASAP? About verifying that an investment of IT resources is really worth it? About avoiding defects and downtimes (and lost customers and sales)?<br><br>Ehm, do I need to answer?<br><br><em>(Also, happy developers = productive developers so yes, they should care about our satisfaction and frustrations.)</em><br><br><h2>Summary</h2><br><br>For me, development is essentially about maximizing value &lt;=&gt; minimizing the idea-to-\"cash\" time. This naturally leads to DevOps, Continuous Delivery, lean startup practices and thinking, \"build the quality in,\" single piece flow, and it drives my choice of tools and languages.<br><br>Psychologically, it is about maximizing gratification while minimizing mental drain, i.e. the expenditure of mental energy.<br><br><p style=\"text-align:center;\"><em>You might enjoy also other <a href=\"/tag/opinion/\">posts on effective development</a>.</em></p>",
  "excerpt": ""
 },
 {
  "title": "Most interesting links of March ''14",
  "published": "2014-03-31 21:59:26",
  "postType": "post",
  "slug": "/2014/03/31/most-interesting-links-of-march-14/",
  "status": "publish",
  "tags": [
   "clojure"
  ],
  "categories": [
   "General",
   "Top links of month"
  ],
  "content": "<h2>Recommended Readings</h2>\r\n<h2>Clojure Corner</h2>\r\n<ul>\r\n\t<li><a href=\"http://dev.solita.fi/2014/03/18/pimp-my-repl.html\">Timo Mihaljov's Pimp My REPL</a> (3/2014)- really great tips - user.clj, :dev profile, user-wide config in .lein/profiles.clj, tools.namespace, making funs available everywhere &amp; more via Vinyasa, form println with Spyscope, debug-repl, difform, clj-ns-browser</li>\r\n</ul>\r\n<h2>Tools/Libs</h2>\r\n<ul>\r\n\t<li><a href=\"https://github.com/krukow/clj-ds\">clj-ds</a> - Clojure immutable datastructures extracted from Clojure and made easier for use directly in Java</li>\r\n</ul>\r\n<h2>Favourite Quotes</h2>",
  "excerpt": ""
 },
 {
  "title": "Ansible: Best practices for deriving host-level var from a group var",
  "published": "2014-03-19 09:04:38",
  "postType": "post",
  "slug": "/2014/03/19/ansible-best-practices-for-deriving-host-level-var-from-a-group-var/",
  "status": "publish",
  "tags": [
   "ansible"
  ],
  "categories": [
   "Tools"
  ],
  "content": "I have a cluster and a group variable (in test/staging/prod) holding the hostname of the cluster master. For each host, I want to derive a variable which is set to either \"slave\" or \"master\" and use it in templates.<br><br>This can be done with <a href=\"http://docs.ansible.com/set_fact_module.html\">set_fact</a>:<br><br><pre><code>\r\n---\r\n# group_vars/staging:\r\njboss_master_host: barad-dur.example.com\r\n</code></pre><br><br>&nbsp;<br><br><pre><code>\r\n---\r\n# roles/xxx/tasks/main.yml:\r\n- name: Set default jboss_host_type\r\n  set_fact: jboss_host_type=slave\r\n- name: Set jboss_host_type to master if master\r\n  set_fact: jboss_host_type=master\r\n  when: jboss_master_host == inventory_hostname\r\n</code></pre><br><br>We could simplify that by using more advanced Jinja:<br><br><pre><code>\r\n---\r\n# roles/xxx/tasks/main.yml:\r\n- name: Set jboss_host_type var\r\n  set_fact: jboss_host_type={{ 'master' if jboss_master_host == inventory_hostname else 'slave' }}\r\n</code></pre><br><br>but <a href=\"https://groups.google.com/d/msg/ansible-project/EyuXI_HVoL0/eGVGLsroeE4J\">it is preferred not to use logic coded in Jinja2</a>.<br><br>// Ansible 1.5.3",
  "excerpt": ""
 },
 {
  "title": "HttpServletRequest: requestURI/requestURL/contextPath/servletPath/pathInfo/queryString",
  "published": "2014-03-24 12:10:14",
  "postType": "post",
  "slug": "/2014/03/24/httpservletrequest-requesturirequesturlcontextpathservletpathpathinfoquerystring/",
  "status": "publish",
  "tags": [
   "java",
   "servlet",
   "web"
  ],
  "categories": [
   "Languages"
  ],
  "content": "I never remember what some of these <a href=\"http://docs.oracle.com/javaee/6/api/javax/servlet/http/HttpServletRequest.html\">HttpServletRequest</a> methods return so here is an example:<br><br><pre><code>\r\nURL METHODS BREAKDOWN (JavaEE 6):\r\n- requestURL  = http://localhost:8080/myapp/users/profile.xhtml\r\n- requestURI  = /myapp/users/profile.xhtml = contextPath + servletPath + pathInfo\r\n- contextPath = /myapp = the first segment after hostname (unless the app runs and the root app with context /)\r\n- servletPath = /users/profile.xhtml (part after contextPath to the servlet that handled the request)\r\n- pathInfo    = null (what remains after servletPath up to the queryString; would return '/dummy' if the url was '.../profile.xhtml/dummy?id=007')\r\n- queryString = id=007\r\n</code></pre>",
  "excerpt": ""
 },
 {
  "title": "How To Generate A Valid Credit Card Number For A Bin (First 6 Digits)",
  "published": "2014-03-25 11:45:57",
  "postType": "post",
  "slug": "/2014/03/25/how-to-generate-a-valid-credit-card-number-for-a-bin-first-6-digits/",
  "status": "publish",
  "tags": [
   "groovy",
   "java"
  ],
  "categories": [
   "General",
   "Languages",
   "Testing"
  ],
  "content": "There is plenty of generators that can produce numbers that are valid credit card numbers according to the <a href=\"http://en.wikipedia.org/wiki/Luhn_algorithm\">Luhn check</a> and specific rules of the individual issuer companies. However I have not found anything that would generate the missing digits given a <a href=\"http://en.wikipedia.org/wiki/Bank_card_number\">bin</a>, i.e. the first 6 digits of a credit card (the \"bank identification number\"). So I created one, reverse-engineering <code>org.apache.commons.validator.routines.CreditCardValidator</code> from <a href=\"http://commons.apache.org/proper/commons-validator/\">common-validator</a> 1.4:<br><br><pre><code>\r\n// Groovy:\r\n/** Map RegExp from C.C.Validator to the total length of the CC# */\r\nbinReToLen = [\r\n        (~/^(3[47]\\d{0,13})$/) : 13+2, // amex\r\n        (~/^30[0-5]\\d{0,11}$/) : 11+3, // diners 1\r\n        (~/^(3095\\d{0,10})$/) : 10+4, // diners 2\r\n        (~/^(36\\d{0,12})$/) : 12+2,     // diners 3\r\n        (~/^|3[8-9]\\d{0,12}$/) : 12+2,  // diners 4\r\n        (~/^(5[1-5]\\d{0,14})$/) : 14+2, // master\r\n        (~/^(4)(\\d{0,12}|\\d{15})$/) : 12+1 // visa\r\n        // Discover cards omitted\r\n]<br><br>/** Bin is e.g. 123456 */\r\ndef completeCCn(String bin) {\r\n    def ccnFill = &quot;1&quot; * 19\r\n    int ccnLen = lenForBin(bin)<br><br>    def ccnWithoutCheck = bin + ccnFill[0..&lt;(ccnLen - 6 - 1)] // - bin, - check digit<br><br>    def check = computeLuhncheckDigit(ccnWithoutCheck)<br><br>    return &quot;$ccnWithoutCheck$check&quot;\r\n}<br><br>def lenForBin(String bin) {\r\n    def match = binReToLen.find { it.key.matcher(bin).matches() }\r\n    if (match == null) {\r\n        throw new RuntimeException(&quot;Bin $bin does not match any known CC issuer&quot;)\r\n    }\r\n    match.value\r\n}<br><br>def computeLuhncheckDigit(def ccnWithoutCheck) {\r\n    org.apache.commons.validator.routines.checkdigit.LuhnCheckDigit.LUHN_CHECK_DIGIT.calculate(ccnWithoutCheck)\r\n}<br><br>completeCCn('465944') // =&gt; 4659441111118\r\n</code></pre><br><br>Testing FTW!",
  "excerpt": ""
 },
 {
  "title": "Framework Joy: Load in Hibernate Updates Data",
  "published": "2014-03-31 11:23:18",
  "postType": "post",
  "slug": "/2014/03/31/framework-joy-load-in-hibernate-updates-data/",
  "status": "publish",
  "tags": [
   "hibernate"
  ],
  "categories": [
   "j2ee"
  ],
  "content": "Would you ever guess that this line<br><br><pre><code>\r\n// Load Buyer from DB by id using Spring's HibernateTemplate:\r\nfinal Buyer traveller = (Buyer) hibernateTemplate.load(Buyer .class, new Long(id));\r\n</code></pre><br><br>could lead to a constraint-validation exception during a batch update or delete and re-insert rows (loosing all columns Hibernate does not know about)? I was quite surprised.<br><br>In particular buyer's bonusCards get deleted and re-inserted, because Hibernate believes that the collection of cards is dirty, even though it has just loaded it from the DB. I am not exactly sure why (<a href=\"http://www.javacodegeeks.com/2012/03/hibernate-performance-tips-dirty.html\">preventing false positives in dirty checks requires some black magic</a>), this is the configuration:<br><br><pre><code>\r\n&lt;class name=&quot;Buyer&quot; ...&gt;\r\n...\r\n    &lt;set name=&quot;bonusCards &quot; table=&quot;bonus_cards&quot;&gt;\r\n        &lt;key column=&quot;buyer_id&quot;/&gt;\r\n        &lt;composite-element class=&quot;BonusCard&quot;&gt;\r\n            &lt;property name=&quot;number&quot; column=&quot;number&quot; not-null=&quot;false&quot;/&gt;\r\n            &lt;property name=&quot;expiredate&quot; column=&quot;expdate&quot;/&gt;\r\n            ...\r\n        &lt;/composite-element&gt;\r\n    &lt;/set&gt;\r\n&lt;/class&gt;\r\n</code></pre><br><br>Of course Hibernate certainly has good reasons to update and delete+re-insert data upon load and we could certainly get rid of (some of) these updates by configuring Hibernate better. But it still demonstrates nicely the hidden cost of using a complex framework - in this case, it behaves quite unexpectedly and requires extensive knowledge to set up properly and to troubleshoot.",
  "excerpt": ""
 },
 {
  "title": "Most interesting links of April ''14",
  "published": "2014-04-30 21:59:31",
  "postType": "post",
  "slug": "/2014/04/30/most-interesting-links-of-april-14/",
  "status": "publish",
  "tags": [
   "clojure",
   "ClojureScript",
   "reuse",
   "seo",
   "web"
  ],
  "categories": [
   "General",
   "Languages",
   "Top links of month"
  ],
  "content": "<h2>Recommended Readings</h2>\r\n<ul>\r\n\t<li><a href=\"http://johannesbrodwall.com/2014/03/24/the-economics-of-reuse/\">The economics of reuse</a> - developing code for reuse costs much more than for one need - it might cost 300% more to develop and save you 75% of work when (re)using it instead of developing from scratch (if one of the factors goes down, the other one typically goes down too). Summary: \"<em>That means that <strong>to get any value from your reused component, you better have five or more reusers</strong> or you have to find a way to substantially improve the [reuse value factor] or [reusability cost factor]. Very smart people have failed to do this.</em>\"</li>\r\n\t<li><a href=\"http://manning.com/kuhn/\">Book in making: Reactive Design Patterns</a> (1st ch free)</li>\r\n</ul>\r\nSharing data on the web\r\n<ul>\r\n\t<li><a href=\"http://www.heppnetz.de/projects/goodrelations/\">GoodRelations: The Web Vocabulary for E-Commerce</a> - make data about your company, products, opening hours etc. more SEO-friendly and understandable to a computer by <a href=\"http://wiki.goodrelations-vocabulary.org/Quickstart#HTML_Patterns_for_Rich_Markup\">adding some semantic markup</a>. If more sites did this, the web would be much easier to navigate. (GoodRelations has been added almost entirely to the <a href=\"http://schema.org/\">schema.org</a> vocabulary so you can use just schema.org with microdata or <a href=\"http://wiki.goodrelations-vocabulary.org/Cookbook/Schema.org\">schema.org where possible and G.R. to extend it</a>.)</li>\r\n</ul>\r\n<h2>Clojure Corner</h2>\r\n<ul>\r\n\t<li><a href=\"http://blog.8thlight.com/andrew-zures/2014/03/08/combining-clj-and-cljs-libraries.html\">8th Light: Combining Clojure and ClojureScript Libraries</a> (3/2014) - really good and detailed article / tutorial using <a href=\"https://github.com/lynaghk/cljx\">CLJX</a> and platform-specific platform.clj[s] files to share code between Clojure and ClojureScript. It also recommends a file structure (src/(clj|cljs)/), demonstrates testing, discusses macro development, shows how to pack both into one jar.</li>\r\n</ul>\r\n<h2>Tools/Libs</h2>\r\n<h2>Favourite Quotes</h2>",
  "excerpt": ""
 },
 {
  "title": "Kioo: How To Replace The Whole Body",
  "published": "2014-04-08 11:14:47",
  "postType": "post",
  "slug": "/2014/04/08/kioo-how-to-replace-the-whole-body/",
  "status": "publish",
  "tags": [
   "ClojureScript",
   "kioo"
  ],
  "categories": [
   "Languages"
  ],
  "content": "<ins datetime=\"2014-04-09T14:48:02+00:00\">\r\nThis whole post in unnecessary since it is simply possible to <a href=\"https://github.com/ckirkendall/kioo/pull/15#issuecomment-39970887\">use a snippet directly without a template</a>, as kindly explained by Creighton Kirkendall.\r\n</ins><br><br><div style=\"text-decoration:line-through;\">\r\n<a href=\"https://github.com/ckirkendall/kioo\">Kioo</a>, the enlive-inspired templating library for React.js and derived libs such as Om, normally works by matching selectors against elements inside <code>&lt;body&gt;</code> and transforming the matched elements while also keeping all the other ones. But what if you want to keep just the single matched element and drop all the others? You need some tricks and I will demonstrate one possible way.<br><br><em>Dislaimer: This is a result of my experimentation, not deep knowledge if Kioo.</em><br><br><!--more--><br><br>This template HTML:<br><br><pre><code>\r\n&lt;!-- kiootest.html --&gt;\r\n&lt;html lang=&quot;en&quot;&gt;\r\n  &lt;body&gt;\r\n    &lt;div id=&quot;contentOne&quot;&gt;Cool content modified by &lt;span id=&quot;name&quot;&gt;???&lt;/span&lt;/div&gt;                                           \r\n    &lt;div id=&quot;contentTwo&quot;&gt;place holder 2&lt;/div&gt;\r\n  &lt;/body&gt;\r\n&lt;/html&gt;\r\n</code></pre><br><br>turned into an Om component with this code:<br><br><pre><code>\r\n(ns experiment.core\r\n  (:require-macros [kioo.om :refer [defsnippet deftemplate]])\r\n  (:require [om.core :as om :include-macros true]\r\n            [kioo.om :as kioo]))\r\n(deftemplate kiootest &quot;kiootest.html&quot; [_]\r\n  {[:#contentOne :#name] (kioo/content &quot;#inserted by Kioo#&quot;)})<br><br>(om/root #(om/component (kiootest %)) (atom {}) \r\n         {:target (. js/document (getElementById &quot;om-shop-list2&quot;))})\r\n</code></pre><br><br>would produce this HTML (the wrapping om-shop-list2 is not produced by the template):<br><br><pre><code>\r\n&lt;div id=&quot;om-shop-list2&quot;&gt;\r\n  &lt;div id=&quot;contentOne&quot; data-reactid=&quot;.5.1&quot;&gt;\r\n    &lt;span data-reactid=&quot;.5.1.0&quot;&gt;Cool content modified by&lt;/span&gt;\r\n    &lt;span id=&quot;name&quot; data-reactid=&quot;.5.1.1&quot;&gt;#inserted byKioo#&lt;/span&gt;\r\n  &lt;/div&gt;\r\n  &lt;div id=&quot;contentTwo&quot; data-reactid=&quot;.5.3&quot;&gt;place holder 2&lt;/div&gt;\r\n&lt;/div&gt;\r\n</code></pre><br><br>This is not what we want - we want to use <em>contentOne</em> but ignore the rest of the template, i.e. <em>contentTwo</em>. You might think of using <code>[:body]</code> to match and substitute the full content of the template but that will not work. The reason is that Kioo normally matches your selectors only against tags inside <code>&lt;body&gt;</code>. If you want to match <code>body</code> itself, you need to use slightly different syntax where you explicitely define the root element selector (either <code>:root</code>, which would match the full html, I suppose, or f.ex. <code>:body</code>).<br><br>So we will use a snippet to extract and modify the part of the HTML we want to keep and specify an explicit root selector (instead of the default <code>[:body :&gt; any-node]</code>) on the template to match and replace the whole body:<br><br><pre><code>\r\n(defsnippet kiootest-one &quot;kiootest.html&quot; [:#contentOne] [_]\r\n  {[:#name] (content &quot;Kioo&quot;)})<br><br>(deftemplate kiootest &quot;kiootest.html&quot; [_]\r\n  [:body] {[:body] (substitute (kiootest-one _))})\r\n;;  ^- custom root selector\r\n;;            ^- inside the selected &lt;body..&gt;..&lt;/body&gt;, match the body element itself<br><br>(om/root #(om/component (kiootest %)) (atom {}) \r\n         {:target (. js/document (getElementById &quot;om-shop-list2&quot;))})<br><br></code></pre><br><br>which will produce the desired<br><br><pre><code>\r\n&lt;div id=&quot;om-shop-list2&quot;&gt;\r\n  &lt;div id=&quot;contentOne&quot; data-reactid=&quot;.4&quot;&gt;\r\n    &lt;span data-reactid=&quot;.4.0&quot;&gt;Cool content modified by&lt;/span&gt;\r\n    &lt;span id=&quot;name&quot; data-reactid=&quot;.4.1&quot;&gt;Kioo&lt;/span&gt;\r\n  &lt;/div&gt;\r\n&lt;/div&gt;\r\n</code></pre><br><br><h2>Summary</h2>\r\nKioo by default matches your selectors against <code>[:body :&gt; any-node]</code> so you cannot match <code>:body</code> itself. You should rarely need it - especially if you control the HTML and can wrap the content of body into a <code>div</code> that you can then normally match against with Kioo. However, if necessary, you can also provide a custom root selector using the syntax <code>[&lt;your selector&gt; {&lt;selectors and transforms&gt;}]</code>, f.ex. <code>(deftemplate ... [:body] {[:body] (substitute (your-snippet-name _))})</code>.<br><br></div>",
  "excerpt": ""
 },
 {
  "title": "Kioo: How to Troubleshoot Template Processing",
  "published": "2014-04-08 13:40:28",
  "postType": "post",
  "slug": "/2014/04/08/kioo-how-to-troubleshoot-template-processing/",
  "status": "publish",
  "tags": [
   "ClojureScript",
   "kioo",
   "troubleshooting"
  ],
  "categories": [
   "Languages"
  ],
  "content": "So you have created an Om/Reagent/React component using a <a href=\"https://github.com/ckirkendall/kioo\">Kioo</a> template and the result is not as you expected, perhaps just an empty element? Let me share what I have discovered about troubleshooting this (though I am no expert). You will se how to invoke the underlying Clojure function component* manually, how to expand the deftemplate macro, how to call the resulting JavaScript function, and what the intermediate forms look like.<br><br><!--more--><br><br>Give this HTML template:<br><br><pre><code>\r\n&lt;!-- kiootest.html --&gt;\r\n&lt;html&gt;\r\n  &lt;body&gt;\r\n    &lt;div id=&quot;content&quot;&gt;place holder&lt;/div&gt;\r\n  &lt;/body&gt;\r\n&lt;/html&gt;\r\n</code></pre><br><br>and ClojureScript code with Om and Kioo:<br><br><pre><code>\r\n(deftemplate kiootest &quot;kiootest.html&quot; [_]\r\n  {[:#content] (kioo/content &quot;#Inserted by Kioo#&quot;)})<br><br>(om/root #(om/component (kiootest %)) (atom {})\r\n         {:target (. js/document (getElementById &quot;a-container-div&quot;))})\r\n</code></pre><br><br>how do we troubleshoot the processing and rendering of the template?\r\n<h2>1. Macroexpand with tracing</h2>\r\nThe first step is to expand the deftemplate macro, which also matches the selectors against the HTML. We will use the wonderful <a href=\"https://github.com/clojure/tools.trace\">clojure.tools.trace</a> library and its <a href=\"http://clojure.github.io/tools.trace/#clojure.tools.trace/trace-ns\">trace-ns</a> to automatically log and calls and return values during the processing to understand what is going on.<br><br>In Clojure (not ClojureScript!) REPL that has the template on its classpath:<br><br><pre><code>\r\n;; Clojure REPL\r\n(&gt;trace-ns 'kioo.core) ;; this is clojure.tools.trace/trace-ns\r\n;; =&gt; nil\r\n(require '[kioo.core :as kh]) ; =&gt; nil\r\n(require '[kioo.om :as ko])   ; =&gt; nil\r\n(macroexpand-1 '(deftemplate kiootest &quot;kiootest.html&quot; [_]\r\n  {[:content] (kioo/content &quot;#Inserted by Kioo#&quot;)}))\r\n;; =&gt;\r\n;;(def kiootest (clojure.core/fn [_]\r\n;;   (clojure.core/let\r\n;;    [ch37298 (kioo.core/flatten-nodes\r\n;;      [&quot;\\n    &quot;\r\n;;       (clojure.core/apply om.dom/div\r\n;;        (cljs.core/clj-&gt;js {:className nil, :style nil, :id &quot;content&quot;})\r\n;;        (kioo.core/flatten-nodes [&quot;place holder&quot;]))\r\n;;       &quot;\\n  &quot;])]\r\n;;    (if (clojure.core/= 1 (clojure.core/count ch37298))\r\n;;     (clojure.core/first ch37298)\r\n;;     (clojure.core/apply om.dom/span nil ch37298)))))\r\n</code></pre><br><br>(Side note: this is Clojure's macroexpand-1. ClojureScript has also one, in cljs.analyze, but it failed for me due to unresolved dependencies.)<br><br>We can see that Kioo copies the <code>div#content</code>. However I made a mistake in the selector (<code>:content</code> instead of <code>:#content</code>) so it does not attach the transformation and just preserves the original content, <code>\"place holder\"</code>. Let me fix it:<br><br><pre><code>\r\n(macroexpand-1 '(ko/deftemplate kiootest &quot;kiootest.html&quot; [_]\r\n    {[:#content] (kh/content &quot;#Inserted by Kioo#&quot;)}))\r\n;; =&gt;\r\n;; (def kiootest (clojure.core/fn [_]\r\n;; (clojure.core/let [ch22901\r\n;;   (kioo.core/flatten-nodes\r\n;;    [&quot;\\n    &quot;\r\n;;     ((kioo.core/handle-wrapper kioo.om/make-dom)\r\n;;      ((kh/content &quot;#Inserted by Kioo#&quot;) ;; &lt;- attach the content transformation to the div#content\r\n;;       {:tag :div,\r\n;;        :attrs {:className nil, :style nil, :id &quot;content&quot;},\r\n;;        :content (kioo.core/flatten-nodes [&quot;place holder&quot;]),\r\n;;        :sym om.dom/div}))\r\n;;     &quot;\\n  &quot;])]\r\n;;  (if (clojure.core/= 1 (clojure.core/count ch22901))\r\n;;   (clojure.core/first ch22901)\r\n;;   (clojure.core/apply om.dom/span nil ch22901)))))\r\n</code></pre><br><br>This time I got it right and can see the <code>kh/content</code> transformation applied to the <code>div</code> node (which also has its original <code>:content</code>).<br><br>Let's see what is in the trace log (selected parts; refer to <a href=\"https://github.com/ckirkendall/kioo/blob/master/src/kioo/core.clj\">kioo.core</a> to see the important macros and methods - deftemplate, snippet*, component*, map-trans (map, i.e. apply, transformations)):<br><br><pre><code>\r\nTRACE t22897: (kioo.core/snippet* &quot;kiootest.html&quot; ({[:#content] (kh/content &quot;#Inserted by Kioo#&quot;)}) [_] {:emit-trans ...})\r\n...\r\nTRACE t22899: | | (kioo.core/component* &quot;kiootest.html&quot; ({[:#content] (kh/content &quot;#Inserted by Kioo#&quot;)}) {:emit-trans ...})\r\nTRACE t22900: | | | (kioo.core/eval-selector [:body :&gt; #&lt;core$constantly$fn__4051 clojure.core$constantly$fn__4051@5829013f&gt;]) ;; the default root selector [:body :&gt; any-node]\r\n...\r\nTRACE t22902: | | | (kioo.core/map-trans (&quot;\\n    &quot; {:tag :div, :attrs {:id &quot;content&quot;}, :content (&quot;place holder&quot;)} &quot;\\n  &quot;) {[:#content] (kh/content &quot;#Inserted by Kioo#&quot;)})\r\nTRACE t22903: | | | | (kioo.core/eval-selector [:#content])\r\nTRACE t22903: | | | | =&gt; [:#content]\r\nTRACE t22904: | | | | (kioo.core/attach-transform (kh/content &quot;#Inserted by Kioo#&quot;))\r\n...\r\nTRACE t22902: | | | =&gt; [&quot;\\n    &quot; {:tag :div, :attrs {:id &quot;content&quot;}, :content [&quot;place holder&quot;],\r\n                        :trans (kh/content &quot;#Inserted by Kioo#&quot;)} &quot;\\n  &quot;]\r\n... ;; calls to compile, compile-node, producing flatten-nodes etc.\r\n</code></pre><br><br>Line #3 will be useful later, line #12 is important because it shows that the transformation has been attached to the expected node. If the selector did not match it (as in the <code>:content</code> case), the result would be different (no <code>:trans</code>):<br><br><pre><code>\r\n;; Wrong selector :content, did not match the div =&gt; no :trans attached:\r\nTRACE t22887: | | | =&gt; [&quot;\\n    &quot;\r\n                        {:tag :div,\r\n                         :attrs {:id &quot;content&quot;},\r\n                         :content [&quot;place holder&quot;]}\r\n                        &quot;\\n  &quot;]\r\n</code></pre><br><br><h2>2. Invoking component* manually</h2>\r\nOnce we know how is <code>component*</code> invoked , we can call it directly to speed up our experimenting:<br><br><pre><code>\r\n;; Based on: TRACE t22899: | | (kioo.core/component* &quot;kiootest.html&quot; ({[:#content] (kh/content &quot;#Inserted by Kioo#&quot;)}) {:emit-trans ...})\r\n;; =&gt;\r\n(println (kh/component* &quot;kiootest.html&quot;\r\n               [{[:#content] &quot;DUMMY-KIOO-TRANSF&quot;}] ;; CompilerException No such var: kh/content if using (kh/content &quot;#Inserted by Kioo#&quot;) =&gt;\r\n               kh/react-emit-opts))\r\n;; =&gt; nil\r\n;; (clojure.core/let\r\n;;  [ch22943\r\n;;   (kioo.core/flatten-nodes\r\n;;    [((kioo.core/handle-wrapper kioo.core/make-dom)\r\n;;      (DUMMY-KIOO-TRANSF\r\n;;       {:tag :div,\r\n;;        :attrs {:className nil, :style nil, :id content},\r\n;;        :content (kioo.core/flatten-nodes [place holder]),\r\n;;        :sym js/React.DOM.div}))])]\r\n;;  (if (clojure.core/= 1 (clojure.core/count ch22943))\r\n;;   (clojure.core/first ch22943)\r\n;;   (clojure.core/apply js/React.DOM.span nil ch22943)))\r\n</code></pre><br><br>Notice that I need to wrap the sel+transf map in a vector (or '(..))\r\nand that I had to remove <code>(kh/content ...)</code> since it lead to a CompilerException (I guess there is a way to solve that.)<br><br>Calling component* directly like this, even with the limitations, makes it possible for me to find out more easily where my transformation ends up.\r\n<h2>3. The resulting JavaScript</h2>\r\nI can find the following, little daunting but actually not so complicated output in the compiled app.js file, which is direct cljs-&gt;js translation of the macro expansion above:<br><br><pre><code>\r\nexperiment.core.kiootest = function kiootest(_) {\r\n  var ch56433 = kioo.core.flatten_nodes.call(null, new cljs.core.PersistentVector(null, 3, 5, cljs.core.PersistentVector.EMPTY_NODE,\r\n[&quot;\\n    &quot;,\r\nkioo.core.handle_wrapper.call(null, kioo.om.make_dom)\r\n  .call(null, kioo.om.content.call(null, &quot;#Inserted by Kioo#&quot;)\r\n    .call(null, new cljs.core.PersistentArrayMap(null, 4, [\r\n      // Translation of ':tag :div':\r\n      new cljs.core.Keyword(null, &quot;tag&quot;, &quot;tag&quot;, 1014018828), new cljs.core.Keyword(null, &quot;div&quot;, &quot;div&quot;, 1014003715),\r\n      new cljs.core.Keyword(null, &quot;attrs&quot;, &quot;attrs&quot;, 1107056660),\r\n      new cljs.core.PersistentArrayMap(null,\r\n  3, [new cljs.core.Keyword(null, &quot;className&quot;, &quot;className&quot;, 1004015509), null, new cljs.core.Keyword(null, &quot;style&quot;, &quot;style&quot;, 1123684643), null,\r\n        new cljs.core.Keyword(null, &quot;id&quot;, &quot;id&quot;, 1013907597), &quot;content&quot;], null), // == :id &quot;content&quot;\r\n      new cljs.core.Keyword(null, &quot;content&quot;, &quot;content&quot;, 1965434859), kioo.core.flatten_nodes.call(null, new cljs.core.PersistentVector(null, 1, 5,\r\ncljs.core.PersistentVector.EMPTY_NODE, [&quot;place holder&quot;], null)),\r\nnew cljs.core.Keyword(null, &quot;sym&quot;, &quot;sym&quot;, 1014018617), om.dom.div], null))),\r\n&quot;\\n  &quot;],\r\n  null));\r\n  if (cljs.core._EQ_.call(null, 1, cljs.core.count.call(null, ch56433))) {\r\n    return cljs.core.first.call(null, ch56433);\r\n  } else {\r\n    return cljs.core.apply.call(null, om.dom.span, null, ch56433);\r\n  }\r\n};\r\n</code></pre><br><br>Little hard to read but still a direct translation of the cljs code.<br><br>We can also call the function in JS console, which returns a JS object representing a React.js component:<br><br><pre><code>\r\n&gt; experiment.core.kiootest(null)\r\nConstructor {props: Object, _owner: null, _lifeCycleState: &quot;UNMOUNTED&quot;, _pendingProps: null, _pendingCallbacks: null…}\r\n// Expanded and filtered:\r\nConstructor {props: ...\r\n  props: Object\r\n     children: Array[3]\r\n       0: &quot;↵    &quot; // the &quot;\\n  &quot; we have seen previously\r\n       1: Constructor\r\n            props: Object\r\n              children: &quot;#Inserted by Kioo#&quot;\r\n              id: &quot;content&quot;\r\n  __proto__: ReactDOMComponent\r\n       2: &quot;↵    &quot;\r\n</code></pre><br><br><h2>4. Testing selectors</h2>\r\nSelectors are run at compile time and are actually processed by Enlive and can be thus tested with Enlive.<br><br>Examples:<br><br><pre><code>\r\n(require '[net.cgrand.enlive-html :as e])\r\n(def html &quot;\r\n  &lt;section&gt;\r\n    &lt;form class='classless'&gt;&lt;/form&gt;\r\n    &lt;div class='animal'&gt;Giraffe&lt;/div&gt;\r\n    &lt;div class='animal'&gt;Tapir&lt;/div&gt;\r\n  &lt;/section&gt;\r\n&quot;)\r\n(e/select (e/html-snippet html) [[:.animal (e/nth-of-type 1)]])\r\n=&gt; ({:tag :div, :attrs {:class &quot;animal&quot;}, :content (&quot;Giraffe&quot;)})\r\n;; Or, the same thing but reading from a file / classpath:\r\n;; (e/select (e/html-resource (clojure.java.io/file &quot;/tmp/animals.html&quot;)) [[:.animal (e/nth-of-type 1)]])\r\n;; (e/select (e/html-resource &quot;/classpath/to/animals.html&quot;) [[:.animal (e/nth-of-type 1)]])\r\n</code></pre><br><br><h2>Summary</h2>\r\nClojure's macroexpand-1 with tools.trace are the best tools for troubleshooting Kioo templates. However we can go all the way to the generated JavaScript and resulting React.js object.<br><br>Improvements suggestions are welcomed :-).",
  "excerpt": ""
 },
 {
  "title": "How to create and run Gatling 2.0 tests",
  "published": "2014-04-28 15:00:57",
  "postType": "post",
  "slug": "/2014/04/28/how-to-create-and-run-gatling-2-0-tests/",
  "status": "publish",
  "tags": [
   "gatling",
   "performance"
  ],
  "categories": [
   "Testing",
   "Tools"
  ],
  "content": "Getting up and running with <a href=\"http://gatling-tool.org/\">Gatling</a> perf. tests as I would like so I record this for my future reference.\r\n<h3>0. Create a project:</h3><br><br><pre><code>$ mvn archetype:generate \\\r\n   -DarchetypeCatalog=http://repository.excilys.com/content/groups/public/archetype-catalog.xml\r\n   -Dfilter=io.gatling:\r\n</code></pre><br><br>(The trailing \":\" in the filter is important.)\r\n<h3>1. Import to IntelliJ</h3>\r\nIn IntelliJ choose to import an object, instead of \"from sources\" select \"from external model\" and then Maven. You will also need to have the Scala plugin installed and, when imported, you will likely need to right-click on pom.xml and Maven - Reimport.\r\n<h3>2. Record a simulation</h3>\r\n<ol>\r\n\t<li>Run the <code>src/test/scala/Recorder.scala</code> (right-click - Run 'Recorder')</li>\r\n\t<li>Set the port it should listen on, f.ex. 8000 (maybe you also need to set port for HTTPS, f.ex. 8001), set the target app (perhaps localhost, &lt;some port&gt;, &lt;some https/dummy port&gt;)</li>\r\n\t<li>Optionally set the class name of the recorded simulation and the target package (the output goes to <code>src/test/scala/&lt;package&gt;/&lt;name&gt;.scala</code>)</li>\r\n\t<li>Click [Start !]</li>\r\n\t<li>Go to your browser and <a href=\"https://support.mozilla.org/en-US/kb/server-not-found-connection-problem#w_firefox-connection-settings\">configure it to use the recorder as its HTTP[s] proxy</a></li>\r\n\t<li>Browse localhost:8000/your_app as you want for the test</li>\r\n\t<li>Click [Stop and save] in the Recorder UI</li>\r\n</ol>\r\n<!--more-->\r\n<h3>4. Modify the recorder simulation as you want</h3>\r\n<h3>8. Run a simulation from the IDE</h3>\r\nModify <code>src/test/scala/Engine.scala</code> by adding the following:<br><br><pre><code>\r\nprops.runDescription(&quot;N/A&quot;) // do not ask for a descr. upon run\r\nprops.simulationClass(&quot;your_package.YourSimulation&quot;) // do not ask for a simulation to run upon run\r\n</code></pre><br><br>Now run Engine as an app (right-clikc - Run 'Engine').\r\n<h3>16. Make it possible to run via 'mvn test'</h3>\r\nAdd this to your pom, adjust the includes/excludes as needed:<br><br><pre><code>\r\n...\r\n    &lt;pluginRepositories&gt;\r\n        &lt;pluginRepository&gt;\r\n            &lt;id&gt;excilys&lt;/id&gt;\r\n            &lt;name&gt;Excilys Repository&lt;/name&gt;\r\n            &lt;url&gt;http://repository.excilys.com/content/groups/public&lt;/url&gt;\r\n        &lt;/pluginRepository&gt;\r\n    &lt;/pluginRepositories&gt;\r\n...\r\n   &lt;build&gt;\r\n      &lt;plugins&gt;\r\n            &lt;plugin&gt;\r\n                &lt;!-- Run all [matching] tests] on mvn test --&gt;\r\n                &lt;groupId&gt;io.gatling&lt;/groupId&gt;\r\n                &lt;artifactId&gt;gatling-maven-plugin&lt;/artifactId&gt;\r\n                &lt;version&gt;${gatling.version}&lt;/version&gt;\r\n                &lt;configuration&gt;\r\n                    &lt;simulationsFolder&gt;src/test/scala&lt;/simulationsFolder&gt;\r\n                    &lt;includes&gt;\r\n                        &lt;include&gt;**/your_package/*.scala&lt;/include&gt;\r\n                    &lt;/includes&gt;\r\n                    &lt;!--excludes&gt;\r\n                        &lt;exclude&gt;**/SomeBadTest.scala&lt;/exclude&gt;\r\n                    &lt;/excludes--&gt;\r\n                    &lt;!-- &lt;simulationClass&gt;foo.Bar&lt;/simulationClass&gt; --&gt;\r\n                &lt;/configuration&gt;\r\n                &lt;executions&gt;\r\n                    &lt;execution&gt;\r\n                        &lt;phase&gt;test&lt;/phase&gt;\r\n                        &lt;goals&gt;&lt;goal&gt;execute&lt;/goal&gt;&lt;/goals&gt;\r\n                    &lt;/execution&gt;\r\n                &lt;/executions&gt;\r\n            &lt;/plugin&gt;\r\n</code></pre><br><br>Voilà, <code>mvn test</code> will now run the simulation(s?).\r\n<h3>32. Support multiple configurations</h3>\r\nI like to define multiple simulation configs in the same file and switch between them as I explore the performance. This is what I do:<br><br><pre><code>\r\nval httpProtocol = http.baseURL(&quot;http://localhost:8000&quot;)<br><br>case class TestSetup(repeat: Int, users: InjectionStep, label: String) // &lt;-- config holder<br><br>val sequentialUserTest = TestSetup(repeat = 100, atOnce(1 user), &quot;sequential 1 user&quot;)\r\nval oneUserPer4sTest = TestSetup(repeat = 2, constantRate(0.25 userPerSec).during(5 minutes), &quot;1 usr/4s, 2 req / user&quot;)\r\nval threeCentIn5Mins = TestSetup(repeat = 5, ramp(300).over(5 minute), &quot;300 usr w/ 5 req in 5 mins&quot;)<br><br>val testSetUp = sequentialUserTest // &lt;-- config selection (could be also done at runtime)<br><br>val scn = scenario(s&quot;&quot;&quot;&lt;something&gt; ${testSetUp.label}&quot;&quot;&quot;)\r\n    .repeat(testSetUp.repeat) {\r\n      exec(http(&quot;&lt;something ...&gt;&quot;)\r\n        .get( &quot;&quot;&quot;/index.html&quot;&quot;&quot;)\r\n        ...\r\n        )\r\n}\r\nsetUp(scn.inject(testSetUp.users)).protocols(httpProtocol)\r\n</code></pre>",
  "excerpt": ""
 },
 {
  "title": "Clojure: How To Prevent \"Expected Map, Got Vector\" And Similar Errors",
  "published": "2014-04-30 15:56:52",
  "postType": "post",
  "slug": "/2014/04/30/clojure-how-to-prevent-expected-map-got-vector-and-similar-errors/",
  "status": "publish",
  "tags": [
   "clojure"
  ],
  "categories": [
   "Languages"
  ],
  "content": "What my Clojure code is doing most of the time is transforming data. Yet I cannot see the shape of data being transformed - I have to know what the data looks like on the input and hold a mental model of how they change at each step. But I make mistakes. I make mistakes in my code so that the data does not correspond anymore to the model it should follow. And I make mistakes in my mental model of what the data currently looks like, leading likely to a code error later on. The end result is the same - a little helpful exception <em>at some later step</em> regarding wrong shape of data. There are two problems here: The error typically provides too little useful information and it usually manifests later than where the code/model mistake actually is. I therefore easily spend an hour or more troubleshooting these mistakes. In addition to that, it is also hard to read such code because a reader lacks the writer's mental model of the data and has to derive it herself - which is quite hard especially if the shape of the input data is not clear in the first place.<br><br>I should mention that I of course write tests and experiment in the REPL but I still hit these problems so it is not enough for me. Tests cannot protect me from having a wrong model of the input data (since I write the [unit] tests based on the same assumptions as the code and only discover the error when I integrate all the bits) and even if they help to discover an error, it is still time-consuming the root cause.<br><br>Can I do better? I believe I can.<br><br><!--more--><br><br>The hard to troubleshoot errors with delayed manifestation and hard to understand code that communicates only half of the story (the transformations but not the shape of the data being transformed) is the price we pay for the power of dynamic typing. But there are strategies to lower this price. I want to present three of them: small, focused functions with good names, destructuring as documentation, and judicious use of pre- and post- conditions.<br><br>The content of this post is based on what I learned from Ulises Cerviño Beresi during one of the free <a href=\"https://groups.google.com/forum/#!searchin/clojure/Clojure$20Office$20Hours/clojure/kYzh_wAZM8c/lVJf1PnrxiYJ\">Clojure Office Hours</a> he generously <a href=\"https://ucb.youcanbook.me/\">offers</a>, similarly to <a href=\"https://leifpoorman.youcanbook.me/\">Leif</a> in the US.<br><br>So we need to make the shape of data more obvious and to fail fast, preferably with a helpful error message.<br><br>The main idea is:<br><br><ol>\n    <li>Break transformations into small, simple functions with clear names</li>\n    <li>Use destructuring in function arguments to document what data is expected</li>\n    <li>Use pre- and post-conditions (and/or asserts) both as checks and documentation</li>\n    <li>(All the testing and interactive exploration in REPL that you already do.)</li>\n</ol><br><br><h3>A simplified example</h3><br><br>We have a webshop that sells discounted cars. We also have occasional campaigns with increased discounts for selected cars. For each car we have also a number of keywords people can use to find it and categories it belongs to. Below is code that processes raw car + campaigns + search keywords data from a DB query, first the original and then the refactored one with checks:<br><br>https://gist.github.com/holyjak/74b2c6ea20b25d020c8b<br><br><h3>A real-world example</h3><br><br>We have a webshop that sells discounted cars. Each car we sell has a base discount (either an absolute amount or percentage) and we also have occasional campaigns for selected cars. For each car we have also a number of keywords people can use to find it.<br><br><h4>Original code</h4><br><br>Below is code that processes raw car + campaigns + search keywords data from a DB query, selected the best applicable campaign and computing the final discount:<br><br>https://gist.github.com/holyjak/61d780888f12c3a31b60<br><br><h4>Defects and me</h4><br><br>I had originally two [discovered] errors in the code and both took me quite a while to fix - first I forgot to convert JSON from string into a map (wrong assumption about input data) and then I run <em>merge-campaigns</em> directly on the list of car+campaign lists instead of mapping it (the <em>sequential?</em> precondition did not help to detect this error). So the transformations are clearly too error-prone.<br><br>The stack traces did not contain enough helpful context info (though a more experienced Clojurist would have certainly found and fixed the root causes much faster):<br><br><pre><code>\r\n## Forgotten -&gt;json:\r\njava.lang.NullPointerException:\r\n clojure.lang.Numbers.ops Numbers.java:  961\r\n  clojure.lang.Numbers.gt Numbers.java:  227\r\n  clojure.lang.Numbers.gt Numbers.java: 3787\r\n       core/discount-size     cars.clj:   13\r\n    core/compute-discount     cars.clj:   36\r\n-------------\r\n## Forgotten (map ..):\r\njava.lang.ClassCastException: clojure.lang.PersistentVector cannot be cast to clojure.lang.IPersistentMap\r\n              RT.java:758 clojure.lang.RT.dissoc\r\n            core.clj:1434 clojure.core/dissoc\r\n            core.clj:1436 clojure.core/dissoc\r\n          RestFn.java:142 clojure.lang.RestFn.applyTo\r\n             core.clj:626 clojure.core/apply\r\ncars.clj:36 merge-campaigns\r\n...\r\n</code></pre><br><br>&nbsp;<br><br><h4>Refactored</h4><br><br>This is the code refactored into smaller functions with checks (and it certainly can be improved much more):<br><br>https://gist.github.com/holyjak/fb5cc1b18415df0c6daf<br><br><h2>Downsides</h2><br><br>The main problem with pre- and post-conditions is that they do not provide any useful context in their error message and do not support adding a custom message. An error like<br><br><code>Assert failed: (let [a (key m)] (or (nil? a) (instance? java.sql.Array a))) cars.clj:18 user/jdbc-array-to-set</code><br><br>is better than not failing fast but does not tell as what the invalid value was and which of the thousands of cars had the invalid value.<br><br>Also, the checks are performed at runtime so they have a performance cost. This might not be a problem with checks such as (map?) but could be with f.ex. (every?).<br><br><h2>What about duplication?</h2><br><br>Do you repeat the same checks again and again? Then you could either copy them using <code>with-meta</code> (they end-up in metadata anyway) or reuse the explicitely:<br><br><pre><code>\r\n(defn with-valid-car [f] (fn [car] {:pre [:make :model :year]} (f car)))<br><br>(def count-price (with-valid-car (fn [car] (do-something car))))\r\n;; or make &amp; use a macro to make it nicer\r\n</code></pre><br><br><h2>What about static types</h2><br><br>This looks arguably like a good case for static types. And yes, I come from Java and lack them. On the other hand, even though static typing would solve the main category of problems, it creates new ones and has its liits.<br><br>A) I have actually quite a number of \"types\" here so it would require lot of classes to model fully:<br><br><ol>\n    <li>Raw data from the DB - car with campaign fields and keywords, category_ref as java.sql.Array</li>\n    <li>Car with keywords as a sequence</li>\n    <li>Car with category_ref as a sequence</li>\n    <li>Car with a nested :campaign \"object\"</li>\n    <li>Car with a nested :best-campaign object and with :rate (you could have :rate there from start, set initially to nil, but then you'd still need to ensure that the final function sets it to a value)</li>\n</ol><br><br>B) A key strength of Clojure is the use of generic data structures - maps, vectors, lazy sequences - and powerful, easy to combine generic functions operating on them. It makes integrating libraries very easy since everything is just a map (and not a custom type that needs to be converted) and you can always transform these with your old good friends functions - whether it is a Korma SQL query definition, result set, or a HTTP request. Static types take this away.<br><br>C) Types permit only a subset of checks that you might need (that is unless you use Haskell :)) - they can check that a thing is a car but not that a return value is in the range 7 ... 42.<br><br>D) Some functions do not care about the type, only its small part - f.ex. jdbc-array-to-set only cares about the argument being a map, having the key, and if set, the value being a <em>java.sql.Array</em>.<br><br><h2>What else is out there?</h2><br><br><ul>\n    <li><a href=\"http://typedclojure.org/\">core.typed</a></li>\n    <li><a href=\"https://github.com/Prismatic/schema\">prismatic/schema</a></li>\n    <li>contracts programming with <a href=\"https://github.com/clojure/core.contracts\">core.contracts</a></li>\n</ul><br><br><h2>Conclusion</h2><br><br>Using smaller functions and pre+post conditions, I can discover errors much earlier and also document the expected shape of the data better, even more so with destructuring in fn signatures. There is some duplication in the pre/post conditions and the error messages are little helpful but is much better. I guess that more complex cases may warant the use of core.contracts or even core.typed / schema.<br><br>What strategies do you use? What would you improve? Other comments?<br><br>I encourage you to fork and improve the gist and share your take on it.<br><br><strong>Updates</strong><br><br><ol>\n    <li>Lawrence Krubner recommends using <a href=\"https://github.com/MichaelDrogalis/dire#preconditions\">dire</a> to capture the arguments and return value to provide a useful error message</li>\n    <li>Alf Kristian recommends adding more tests and integration tests and if it is not enough, using core.typed rather than :pre and :post (<a href=\"https://github.com/clojure-cookbook/clojure-cookbook/blob/d0b080d6a702ffcf630a9091ba6f75bb0989f0e2/10_testing/10-09_hof-typed.asciidoc\">example</a>)</li>\n</ol>",
  "excerpt": ""
 },
 {
  "title": "Graphite Shows Metrics But No Data - Troubleshooting",
  "published": "2014-05-05 11:08:09",
  "postType": "post",
  "slug": "/2014/05/05/graphite-shows-metrics-but-no-data-troubleshooting/",
  "status": "publish",
  "tags": [
   "graphite",
   "monitoring"
  ],
  "categories": [
   "Tools"
  ],
  "content": "My <a href=\"http://graphite.readthedocs.org/en/latest/\">Graphite</a> has all the metrics I expect but shows no data for them. Communication between my app and Graphite clearly works otherwise the metrics would not have appeared in the list but why is there no data?\r\n<h3>Update: Graphite data gotchas that got me</h3>\r\n(<em>These gotchas explain why I did not see any data.</em>)\r\n<ol>\r\n\t<li><strong>Graphite shows aggregated, not raw data</strong> if the selected query period (24h by default) is greater than the retention period of the highest precision. F.ex. with the schema <span class=\"comment-copy\">\"1s:30m,1m:1d,5m:2y\"</span> you will see data at the 1s precision only if you select period less than or equal to the past 30 minutes. With the default one, you will see the 1-minute aggregates. This applies both to the UI and whisper-fetch.py.</li>\r\n\t<li><strong>Aggregation drops data unless by default at least 50% of available data slots have values</strong> (xFilesFactor=0.5). I.e. if your app sends data at a rate more than twice slower than Graphite expects them, they will never show up in aggregates. F.ex. with the schema <span class=\"comment-copy\">\"1s:30m,1m:1d,5m:2y\"</span>  you must sends data at least 30 times within a minute for them to show in an aggregate.</li>\r\n</ol>\r\nI suppose that whisper-dump.py would show the raw data.\r\n<h3>Lesson learned: Always send data to Graphite in *exactly* same rate as its highest resolution</h3>\r\nAs described above, if you send data less frequently than twice the highest precision (if 1s =&gt; send at least every 2s), aggregation will ignore the data, with the default xFilesFactor=0.5 (a.k.a. min 50% of values reqired factor). On the other hand, if you send data more frequently than the highest precision, <span class=\"comment-copy\">only the last data point received in each of the highest precision periods is recorded, others ignored - that's why f.ex. <a href=\"https://github.com/etsy/statsd/blob/master/docs/graphite.md#correlation-with-statsds-flush-interval\" rel=\"nofollow\">statsD flush period must = Graphite period</a>.</span><br><br><!--more--><br><br><hr /><br><br>&nbsp;\r\n<h3>Exploring the whisper storage</h3>\r\nWe can go directly to its <code>whisper</code> storage and see is there f.ex. for the metric <code>ring.request.active.count</code>:\r\n<pre>ll -h /opt/graphite/storage/whisper/ring/requests/rate/count.wsp\r\n-rw-r--r-- 1 root root 2.5M May  5 11:01 /opt/graphite/storage/whisper/ring/requests/rate/count.wsp</pre>\r\nOK, so the file is there and is not empty. What does it contain?\r\n<pre>$ whisper-fetch.py ./count.wsp | tail -n1\r\n1399287780    None</pre>\r\nThe data is hard to read, let's pretty print it:\r\n<pre>$ whisper-fetch.py --pretty ./count.wsp | tail -n1\r\nMon May  5 11:02:00 2014    None</pre>\r\nOK, so the data is as expected but the value is None. Let's verify that:\r\n<pre>$ whisper-fetch.py --pretty --json ./count.wsp\r\n{\r\n\"start\" : 1399193520,\r\n\"end\" : 1399279920,\r\n\"step\" : 60,\r\n\"values\" : [null, null, ...]\r\n}</pre>\r\nWe can get the same data also via the API: <a href=\"http://graphite-webapp.example.com/render?from=-24h&amp;target=ring.request.active.count&amp;title=Testing&amp;rawData=true\">http://graphite-webapp.example.com/render?from=-24h&amp;target=ring.request.active.count&amp;title=Testing&amp;rawData=true</a><br><br>So the values are indeed null. According to the docs: \"If no value is recorded at a particular timestamp bucket in a series, the value will be None (null).\".<br><br>We were able to find out what data and for what period Graphite has by reading directly its whisper files. The next step will be to find out why the values are null.<br><br><strong>Update</strong>: What did I do wrong? I have not noticed that whisper-fetch shows me data aggregated to the next, 1 min precision, because I have asked for a period longer than the 30 min rentention period of my 1s precision (the default period of 24h). I also did not know that aggregation results in None if there are too few data points.\r\n<h3>Logs</h3>\r\nI run Graphite via Nginx so /var/log/nginx/error.log and /var/log/gunicorn/graphite.log might help.<br><br>Graphite's own logs are f.ex. /opt/graphite/storage/log/carbon-cache/carbon-cache-a/listener.log (and console.log, creates.log  etc.) and /opt/graphite/storage/log/webapp/*.log.\r\n<h3>Experimenting</h3>\r\nLets manually push some data to Graphite, namely its data collecting daemon Carbon, to see what happens.<br><br><code>echo \"jakub.test 42 $(date +%s)\" | nc 0.0.0.0 2003 # Carbon listens at 2003</code><br><br>A minute or so later:\r\n<pre>$ whisper-fetch.py --pretty /opt/graphite/storage/whisper/jakub/test.wsp | head -n1\r\nSun May  4 12:19:00 2014\tNone\r\n$ whisper-fetch.py --pretty /opt/graphite/storage/whisper/jakub/test.wsp | tail -n1\r\nMon May  5 12:09:00 2014\tNone\r\n$ whisper-fetch.py --pretty /opt/graphite/storage/whisper/jakub/test.wsp | grep -v None | wc -l\r\n0</pre>\r\nWhat is happening? Carbon has created the metric and filled with \"no data\" for the past ~ 24 hours (it is, I believe, the default behavior to automatically add data for each period in the past 24h when creating a metric) but the value I sent to it is not there.\r\n<h3>ngrep: What data is being sent?</h3>\r\nLet's us see what data is actually being sent to carbon by intercepting the traffic on port 2003 with <a href=\"http://ngrep.sourceforge.net/usage.html\">ngrep</a> (thanks to Tim Zetha for <a href=\"https://answers.launchpad.net/graphite/+question/246005\">the tip</a>):\r\n<pre>graphite-server$ sudo ngrep -d any port 2003 &amp; # Intercept packets on any (eth, lo, ..) device, port 2003\r\ninterface: any\r\nfilter: (ip or ip6) and ( port 2003 )\r\ngraphite-server$ echo -e \"jakub.test2  45 $(date +%s)\" | sudo nc localhost 2003\r\n####\r\nT 127.0.0.1:34696 -&gt; 127.0.0.1:2003 [AP]\r\n  jakub.test2  45 1399362193.                                                              \r\n####^Cexit\r\n23 received, 0 dropped</pre>\r\n\"T\" means this is TCP (and not f.ex. U[DP]), the letters in [] are <a href=\"http://support.microsoft.com/kb/169292\">TCP flags</a> as <a href=\"http://sourceforge.net/p/ngrep/code/ci/16ba99a863a89dab25cbf8e9ca410b19a7494c42/tree/ngrep.c#l885\">printed by ngrep</a> (Ack, Fin = no more data, Sync = during conn setup, ...). A \"#\" is reportedly displayed for each non-matching packet (use -e[mpty] to print more of them). Notice that ngrep captures both in- and out-going packets.<br><br>------<br><br>PS: I have <a href=\"http://serverfault.com/questions/593157/graphite-shows-none-for-all-data-points-even-though-i-send-it-data\">asked for tips at StackExchange</a>.",
  "excerpt": ""
 },
 {
  "title": "Most interesting links of May ''14",
  "published": "2014-05-31 21:59:59",
  "postType": "post",
  "slug": "/2014/05/31/most-interesting-links-of-may-14/",
  "status": "publish",
  "tags": [
   "clojure",
   "cloud",
   "DevOps",
   "e-mail",
   "haskell",
   "mentoring",
   "podcast",
   "privacy",
   "security",
   "sharing",
   "ssh"
  ],
  "categories": [
   "General",
   "Languages",
   "Tools",
   "Top links of month"
  ],
  "content": "<h2>Recommended Readings</h2>\r\n<ul>\r\n\t<li><a href=\"http://thecodelesscode.com/case/143\">Monolith</a> - from The Codeless Code - fables and koans for the SW engineer - the Monad monolth #Haskell #fun</li>\r\n\t<li><a href=\"http://daniel.haxx.se/http2/\">http2 explained</a> (pdf, 27 pages) - cons of http 1 (huge spec / no full impl., wasteful use of TCP &lt;=&gt; latency [x spriting, inlining, concatenation, sharding]) =&gt; make it less latency sensitive, fix pipelining (issue a req before previous one finished), stop the need for ever increasing # connections, remove/reduce optional parts of http. Http2 is binary; multiple \"streams\" over 1 connection =&gt; much less conns, faster data delivery; header/data compression; [predictive] resource pushing; . Inspired by SPDY. Chrome and Mozilla will only support it over TLS, yay! (see also <a href=\"https://istlsfastyet.com/\">Is TLS Fast Yet?</a> [yes, it is]) Promise: faster, more responsive web pages &amp; deprecation of http/1 workarounds =&gt; simplified web dev.</li>\r\n</ul>\r\nSpecial\r\n<ul>\r\n\t<li><a href=\"http://exercism.io/\">exercism.io - crowd-sourced good code mentorship</a> - get an exercise, implement it in any of the supported language(s), submit and get feedback, repeat; when finished, you too can comment the same excercise submitted by others while working on your next assignment. Languages include Clojure, JS, Scala, Python, Haskell, Go, Elixir, Java, and more.</li>\r\n</ul>\r\nPodcasts (FP &amp; related)\r\n<ul>\r\n\t<li><a href=\"http://cognitect.com/podcast\">Cognicast</a> (also <a href=\"https://itunes.apple.com/us/podcast/thinkrelevance-the-podcast/id498067022\">@ iTunes</a>) - Clojure, FP, etc.</li>\r\n\t<li><a href=\"http://www.functionalgeekery.com/\">Functional Geekery</a> (<a href=\"https://itunes.apple.com/us/podcast/functional-geekery/id790455326?mt=2&amp;uo=4\">@ iTunes</a>) - A podcast on Functional Programming, covering topics across multiple languages.</li>\r\n\t<li><a href=\"http://mostlylazy.com/\">Mostly λazy</a>…a Clojure podcast by Chas Emerick</li>\r\n\t<li><a href=\"http://podcasts.thoughtbot.com/giantrobots\">Giant Robots Smashing into other Giant Robots</a> - \"a weekly technical podcast discussing development, design, and the business of software development\"</li>\r\n\t<li><a href=\"http://www.se-radio.net/\">Software Engineering Radio</a> (@ iTunes) - \"The goal is to be a lasting educational resource, not a newscast. Every two to four weeks, a new episode is published that covers all topics software engineering. Episodes are either tutorials on a specific topic, or an interview with a well-known expert from the software engineering world.\"</li>\r\n\t<li><a href=\"http://engineervsdesigner.com/\">EngineerVsDesigner</a> - design insight (<a href=\"http://itunes.apple.com/us/podcast/engineervsdesigner/id454034646\">@ iTunes</a>) - product design podcast - the latest digital design news, tips &amp; tricks, Q&amp;A, and an industry special guest</li>\r\n</ul>\r\nOther\r\n<ul>\r\n\t<li><a href=\"http://www.theregister.co.uk/2014/05/27/keylogging_botnet_menaces_retailers/\">Swiping your card at local greengrocers? Miscreants will swipe YOU in a minute </a></li>\r\n\t<li><a href=\"http://www.lukew.com/ff/entry.asp?1880\">UX London: Prototype &amp; Test In Five Days</a></li>\r\n\t<li><a href=\"http://io9.com/the-science-and-neuroscience-behind-bruce-lees-incr-1581421570\">The Science—And Neuroscience—Behind Bruce Lee's Amazing One-Inch Punch</a></li>\r\n\t<li><a href=\"http://blog.factual.com/clojure-office-hours\">The ‘Office Hours’ Meetup</a> - Factual Blog</li>\r\n\t<li><a href=\"http://en.m.wikibooks.org/wiki/Write_Yourself_a_Scheme_in_48_Hours\">Write Yourself a Scheme in 48 Hours</a> - Wikibooks, open books for an open world - good way to learn Haskell, implementing Scheme in it</li>\r\n</ul>\r\n<h2>Clojure Corner</h2>\r\n<ul>\r\n\t<li><a href=\"https://www.youtube.com/watch?v=enwIIGzhahw\">core.async walkthrough for practicioners</a> (12/2013; original title \"Core.Async\") - Tim Baldrige 40m talk from Conj is a must-watch for anybody that wants to understand and use core.async. <a href=\"https://github.com/halgari/clojure-conj-2013-core.async-examples\">Examples from and beyond the talk</a> are at GitHub. Highlights: While take! takes a callback, &lt;!!  wraps that into a promise so that it blocks and returns the value. Thread is similar to future, running the code asynchronously, but returns a channel instead of a promise. So does go, only it does not use real threads but simulated light-weight ones via a state machine and parking. Tim shows the different buffers (normal, dropping = earliest values kept, sliding = latest valus kept). Other topics: alts!!, ...\r\nRelated vids by Tim: <a href=\"https://www.youtube.com/watch?v=WSgg-TQLsdw\">Core.Async Channel Internals</a>, <a href=\"https://www.youtube.com/watch?v=R3PZMIwXN_g\">Core Async Go Macro Internals - Part I</a>, <a href=\"https://www.youtube.com/watch?v=SI7qtuuahhU\">Core Async Go Macros - Part II</a></li>\r\n\t<li><a href=\"http://zeroturnaround.com/rebellabs/challenge-your-functional-programming-abilities-with-clojure-leiningen/\">Clojure, Leiningen and Functional Programming for Java developers</a>- implementing a queue in a functional way</li>\r\n</ul>\r\n<h2>Tools/Libs</h2>\r\n<ul>\r\n\t<li><a href=\"http://owncloud.org/\">ownCloud</a> - your own Dropbox/Google Drive, run on your server - sharing files between devices / PCs / web, syncing calendar and contacts, collaborative editing of documents (ODF)</li>\r\n\t<li><a href=\"https://www.mailpile.is/\">Mailpile</a> - \"A modern, fast web-mail client with user-friendly encryption and privacy features.\", to be self-hosted on a PC, RaspberryPI, USB stick</li>\r\n\t<li><a href=\"http://aenima-x.github.io/BlackHole/\">Blackhole</a> - role-based ssh proxy - an app that enables you to manage what users can ssh to what server as a particular user, from users' point of view this is a ssh proxy; useful if many people need access to many servers but you do not want to add them all as users on those servers.</li>\r\n\t<li><a href=\"https://wuala.com/\">Wuala - Secure Cloud Storage</a> - Backup. Sync. Share. Access Everywhere. - Dropbox alternative, secure by default</li>\r\n\t<li><a href=\"http://facebook.github.io/fb-flo/\">fb-flo - Facebook's live-coding tool</a></li>\r\n\t<li><a href=\"http://owncloud.org/\" target=\"_blank\">owncloud.org</a> - self-hosted Dropbox-like service with calendar and contact sync and more</li>\r\n</ul>\r\n<h2>Favourite Quotes</h2>",
  "excerpt": ""
 },
 {
  "title": "core.async: \"Can''t recur here\" in ClojureScript but OK in Clojure",
  "published": "2014-05-12 12:59:16",
  "postType": "post",
  "slug": "/2014/05/12/core-async-cant-recur-here-in-clojurescript-but-ok-in-clojure/",
  "status": "publish",
  "tags": [
   "ClojureScript"
  ],
  "categories": [
   "Languages"
  ],
  "content": "With the latest core.async and ClojureScript (<code>core.async \"0.1.303.0-886421-alpha\"</code> and <code>clojurescript \"0.0-2202\"</code> as well as the older <code>core.async \"0.1.267.0-0d7780-alpha\"</code> and <code>clojurescript \"0.0-2173\"</code>), the following function compiles just fine in Clojure but fails in ClojureScript:<br><br><pre><code>\r\n(defn cljs-cannot-recur! []\r\n  (go-loop [v nil]\r\n    (when-let [next-val (&lt;! (timeout 300))]\r\n      (recur next-val))))\r\n</code></pre><br><br>The error in ClojureScript is<br><br><pre><code>\r\nclojure.lang.ExceptionInfo: Can't recur here at line 23 /my/path/core.cljs ::\r\n  {:tag :cljs/analysis-error, :file &quot;/my/path/core.cljs&quot;, :line 23, :column 7}\r\n             core.clj:4403 clojure.core/ex-info\r\n             ... // very long stacktrace of 0 value\r\n</code></pre><br><br>Workaround: replace <code>(go-loop ..)</code> with <code>(go (loop ..))</code>.<br><br>Another fun fact: <a href=\"https://github.com/clojure/clojurescript/blob/r2197/src/clj/cljs/core.clj\">ClojureScript's core.async</a> lacks (at least) <a href=\"http://clojure.github.io/core.async/#clojure.core.async/alt!\">alt!</a> (I did work around it by using alts! so it is not a show-stopper but still the difference is irritating and I fail to understand why it is missing.)<br><br>Oh, joy!",
  "excerpt": ""
 },
 {
  "title": "ClojureScript/Om: Spurious \"Minified exception occured\" With Advanced Optimizations",
  "published": "2014-05-13 09:41:56",
  "postType": "post",
  "slug": "/2014/05/13/clojurescriptom-spurious-minified-exception-occured-with-advanced-optimizations/",
  "status": "publish",
  "tags": [
   "ClojureScript",
   "om"
  ],
  "categories": [
   "Languages"
  ],
  "content": "After having upgraded to Om 0.6.3. and ClojureScript 2197, I suddenly got the following error in the browser when loading the .js compiled with <code>:optimizations :advanced</code>:\r\n<blockquote>Uncaught Error: Minified exception occured; use the non-minified dev environment for the full error message and additional helpful warnings.</blockquote>\r\nIn the dev mode, i.e. without any optimizations, the code worked just fine - the same thing that <a href=\"http://logs.lazybot.org/irc.freenode.net/%23clojurescript/2014-04-24.txt\">Frozenlock has experienced</a>.<br><br>After downgrading, removing Om, and upgrading again it suddnely dissapeared and now Om 0.6.3. and ClojureScript 2197 work just fine. So I suppose that after having changed the versions, I should have properly deleted all generated files (and not just my myapp.min.js).<br><br>I hope this helps to somebody.",
  "excerpt": ""
 },
 {
  "title": "Clojure/Java: Prevent Exceptions With \"trace missing\"",
  "published": "2014-05-19 08:03:33",
  "postType": "post",
  "slug": "/2014/05/19/clojurejava-prevent-exceptions-with-trace-missing/",
  "status": "publish",
  "tags": [
   "clojure",
   "java"
  ],
  "categories": [
   "Languages"
  ],
  "content": "The other day I got this little helpful exception from Clojure:<br><br><pre><code>\r\n(cond (&gt;= nil 1) :unreachable)\r\n;=&gt; NullPointerException [trace missing]\r\n</code></pre><br><br>- no line number or anything to troubleshoot it.<br><br>It turns out <a href=\"https://github.com/technomancy/leiningen/issues/1025#issuecomment-38253962\">it is not Clojure's failure but a HotSpot optimization</a> that can apply to <code>NullPointerException</code>, <code>ArithmeticException</code>, <code>ArrayIndexOutOfBoundsException</code>, <code>ArrayStoreException</code>, and <code>ClassCastException</code>. The remedy is to run the JVM with<br><br><pre><code>\r\n-XX:-OmitStackTraceInFastThrow\r\n</code></pre><br><br>From Oralce JDK release notes:\r\n<blockquote>The compiler in the server VM now provides correct stack backtraces for all \"cold\" built-in exceptions. For performance purposes, when such an exception is thrown a few times, the method may be recompiled. After recompilation, the compiler may choose a faster tactic using preallocated exceptions that do not provide a stack trace. To disable completely the use of preallocated exceptions, use this new flag: <code>-XX:-OmitStackTraceInFastThrow</code>.</blockquote>\r\nMany thanks to Ivan Kozik for the info!",
  "excerpt": ""
 },
 {
  "title": "Fixing clojurescript.test failing with \"ReferenceError: Can''t find variable: cemerick\"",
  "published": "2014-05-21 10:14:18",
  "postType": "post",
  "slug": "/2014/05/21/fixing-clojurescript-test-failing-with-referenceerror-cant-find-variable-cemerick/",
  "status": "publish",
  "tags": [
   "ClojureScript",
   "Testing"
  ],
  "categories": [
   "Languages",
   "Testing"
  ],
  "content": "<a href=\"https://github.com/cemerick/clojurescript.test\">ClojureScript.test</a> (0.3.0; <code>cemerick.cljs.test</code>) may fail with this confusing exception:<br><br><pre><code>ReferenceError: Can't find variable: cemerick</code></pre><br><br>due to couple of reasons:\r\n<ol>\r\n\t<li>Your test namespaces do not require <code>cemerick.cljs.test</code> (and thus it is missing from the compiled .js; requiring macros is not enough)</li>\r\n\t<li>cljsbuild has not included any of your test files (due to wrong setup etc.; this is essentially another form of #1)</li>\r\n\t<li>You are trying to test with the node runner but have built with <code>:optimizations</code> <code>:none</code> or <code>:whitespace</code> (for node you need to concatenate everything into a single file, which only happens if you use <code>:simple</code> or <code>:advanced</code> optimizations)</li>\r\n</ol>\r\nThere is a <a href=\"https://github.com/cemerick/clojurescript.test/pull/59/\">pull request to provide a better error message</a> but until then you have to be aware of these problems.<br><br>Example failures from all the runners:<br><br><!--more--><br><br><pre><code>\r\nSuccessfully compiled &quot;target/cljs/testable.js&quot; in 18.207 seconds.\r\nRunning ClojureScript test: rhino\r\njs: &quot;/var/folders/k0/2842tm752zv1dh4q77_gmgdr0000gn/T/rhino-runner8958189739208289289.js&quot;, line 50: uncaught JavaScript runtime exception: ReferenceError: &quot;cemerick&quot; is not defined.\r\n\tat /var/folders/k0/2842tm752zv1dh4q77_gmgdr0000gn/T/rhino-runner8958189739208289289.js:50<br><br>Running ClojureScript test: node<br><br>/private/var/folders/k0/2842tm752zv1dh4q77_gmgdr0000gn/T/node-runner9185102801545573161.js:26\r\ncemerick.cljs.test.set_print_fn_BANG_(function(x) {\r\n^\r\nReferenceError: cemerick is not defined\r\n    at Object.&lt;anonymous&gt; (/private/var/folders/k0/2842tm752zv1dh4q77_gmgdr0000gn/T/node-runner9185102801545573161.js:26:1)\r\n    at Module._compile (module.js:456:26)\r\n    at Object.Module._extensions..js (module.js:474:10)\r\n    at Module.load (module.js:356:32)\r\n    at Function.Module._load (module.js:312:12)\r\n    at Function.Module.runMain (module.js:497:10)\r\n    at startup (node.js:119:16)\r\n    at node.js:901:3\r\nSubprocess failed\r\nRunning ClojureScript test: phantom\r\nReferenceError: Can't find variable: cemerick<br><br>  phantomjs://webpage.evaluate():2\r\n  phantomjs://webpage.evaluate():5\r\n  phantomjs://webpage.evaluate():5\r\nReferenceError: Can't find variable: cemerick<br><br>  phantomjs://webpage.evaluate():2\r\n  phantomjs://webpage.evaluate():8\r\n  phantomjs://webpage.evaluate():8\r\n# phantomjs freezes here\r\n</code></pre>\r\n",
  "excerpt": ""
 },
 {
  "title": "Most interesting links of June ''14",
  "published": "2014-06-30 21:59:55",
  "postType": "post",
  "slug": "/2014/06/30/most-interesting-links-of-june-14/",
  "status": "publish",
  "tags": [
   "android",
   "clojure",
   "economics",
   "fun",
   "human",
   "nodejs",
   "privacy",
   "psychology",
   "workplace"
  ],
  "categories": [
   "General",
   "Languages",
   "Tools",
   "Top links of month"
  ],
  "content": "<h2>Recommended Readings</h2>\r\n<ul>\r\n\t<li><a href=\"http://notes.ericjiang.com/posts/751\">The emperor’s new clothes were built with Node.js</a> - I know sadly little about Node.js but this goes against the hype and is thus interesting. So what does Node.js give us? Performance 1-5x slower than Java [like Clojure] according to the Benchmarks Game (contrary to other benchmarks with the opposite result as mentioned in the comments), use of a single CPU/core on our multi-cpu, multi-core machines, callback hell. At the same time, there are good non-blocking servers available in other languages (Clojure's http-kit, Vert.x, etc.) (Update: From the comments it seems that f.ex. the \"callback hell\" situation is geting better with 0.11, fibers and other things I do not know anything about. Also Sandro has a nice anti-comment (No. 36).)\r\nThe <a href=\"https://www.youtube.com/watch?v=bzkRVzciAZg&amp;feature=kp\">Node.js Is Bad Ass Rock Star Tech</a> 5 min video is a nice companion :)</li>\r\n\t<li><a href=\"https://www.youtube.com/watch?v=BKorP55Aqvg\">The Expert (Short Comedy Sketch)</a>  (7 min) - you've certainly seen this one but I had to put it here; a young engineer is hammered into being an \"Of course I can do it, I am an expert\" 'expert/consultant' during a business meeting. Maybe you too have experienced a dialog with the business where your true expert opinion was crushed by the business people's insistence on their absurd requirements?</li>\r\n\t<li><a href=\"https://pack.resetthenet.org/\">Reset The Net - Privacy Pack</a> - privacy-enhancing apps for PC/mobile</li>\r\n\t<li><a href=\"http://blog.bethcodes.com/the-dyslexic-programmer\">The Dyslexic Programmer</a> (via Kent Beck) - interesting read about quite a different way to percieve and think about code, the advantages of IDEs.</li>\r\n\t<li><a href=\"http://blog.docker.com/2014/06/its-here-docker-1-0/\">It’s Here: Docker 1.0</a> =&gt; more stable from now on</li>\r\n\t<li><a href=\"https://m.facebook.com/notes/kent-beck/learning-about-tdd-the-purpose-of-istdddead/768162959883237\">Kent Beck: Learning About TDD: The Purpose of #isTDDDead</a> - what is the purpose and value of TDD? Where are the limits of its value? \"<em>I recognize that TDD loses value as tests take longer to run, as the number of possible faults per test failure increases, as tests become coupled to the implementation, and as tests lose fidelity with the production environment.</em>\"</li>\r\n\t<li><a href=\"http://blog.idonethis.com/spotify-growth-mindset/\">Failure &amp; Cake: A Guide to Spotify’s Psychology of Success</a> - want to be innovative and successfull? Learn to embrace failure, nurture the \"growth mindset\" (failure as opportunity to improve) rather than the \"fixed mindset\" (I do not learn and every failure shows I have no value). Read this if you want your org to be a better place to work!</li>\r\n</ul>\r\nNon-tech\r\n<ul>\r\n\t<li><a href=\"http://www.psychedelic-library.org/staf3.htm\">LSD — The Problem-Solving Psychedelic</a> - I never knew that drugs could be used to something positive, with an incredible effect. Are you stuck with a tech/design/art problem? Try LSD! :-)</li>\r\n\t<li><a href=\"http://www.theguardian.com/commentisfree/2014/jun/09/french-public-debt-audit-illegitimate-working-class-internationalim?CMP=twt_gu\">The French are right: tear up public debt – most of it is illegitimate anyway</a> - \"<em>Debt audits show that austerity is politically motivated to favour social elites. [..] 60% of French public debt is illegitimate</em>\" - not improving the lives of people but thos at power/rich. Time to reconsider this debt business and ways to make our system better?</li>\r\n\t<li><a href=\"http://www.forbes.com/sites/stevedenning/2014/06/03/why-financialization-has-run-amok/\">Forbes: Why Financialization Has Run Amok</a> - Wall Street is the kind and companies do everything to look better in its eyes - including giving up on opportunities. The might of the finance sector is destructive to our economy and distorts it, away from producing more value to making financial institutions richer, away from (value) creative activities to distributive ones. The article describes the problem and proposes a solution including limiting the size and leverage of banks, taxing financial transactions etc. Example of the effects: \"[<em>..] a cabal of senior IBM executives and the managers of some big investment firms got together and devised a five-year scheme—IBM’s Roadmap 2015—for increasing IBM’s earnings per share—and their own compensation—through measures that are not only increasing earnings per share but also steadily crippling IBM’s ability to innovate and compete [..]</em>\"</li>\r\n\t<li><a href=\"http://m.theatlantic.com/magazine/archive/2013/11/why-we-fightand-can-we-stop/309525/\">Why Can't We All Just Get Along? The Uncertain Biological Basis of Morality</a> - very interesting criticism of \"morality\" that is mostly based on emotions and thus contradictory, a good argument for utilitarian morality [not that it hasn't its own challenges]. According to the author, many conflicts are nor primarily due to divergent values but due to different interpretation of the reality and history (such as \"who has right to this land?\"). People suffer \"<em>[..] from a deep bias—a tendency to overestimate their team’s virtue, magnify their grievances, and do the reverse with their rivals.</em>\" \"<em>This is the way the brain works: you forget your sins (or never recognize them in the first place) and remember your grievances. [..] As a result, the antagonisms confronting you may seem mysterious, and you may be tempted to attribute them to an alien value system.</em>\" This leads to partial judgements that play very badly with another psychological feature - \"<em>Namely: the sense of justice—the intuition that good deeds should be rewarded and bad deeds should be punished.</em>\" \"<em>When you combine judgment that’s naturally biased with the belief that wrongdoers deserve to suffer, you wind up with situations like two people sharing the conviction that the other one deserves to suffer. Or two groups sharing that conviction. And the rest is history.</em>\" And \"<em>The most common explosive additive is the perception that relations between the groups are zero-sum—that one group’s win is the other group’s loss.</em>\" =&gt; \"<em>So maybe the first step toward salvation is to become more self-aware.</em>\"\r\n\"<em>When you’re in zero-sum mode and derogating your rival group, any of its values that seem different from yours may share in the derogation. Meanwhile, you’ll point to your own tribe’s distinctive, and clearly superior, values as a way of shoring up its solidarity. So outsiders may assume there’s a big argument over values. But that doesn’t mean values are the root of the problem.</em>\"\r\nThose who choose not to act in the <a href=\"http://en.wikipedia.org/wiki/Trolley_problem\">trolley dilemma</a> \"<em>[..] are just choosing to cause five deaths they won’t be blamed for rather than one death they would be blamed for. Not a profile in moral courage!</em>\"</li>\r\n</ul>\r\n<h2>Clojure Corner</h2>\r\n<ul>\r\n\t<li><a href=\"http://youtu.be/NvxyTKyXSRg\">The Case for Clojure</a> (video, 5 min) - a short video arguing for Clojure as a good solution language based on its simplicity, power, and fun factor. There are many claims and few facts (as dictated by the short length) but it might be interesting for somebody.</li>\r\n\t<li><a href=\"http://crossclj.info/\">CrossClj.info</a> - cross-reference of many OSS Clojure projects - find all uses of a fn across the projects, all fns with a given name, all projects using ring, ... . Search by fn, macro, var, ns, prj.</li>\r\n\t<li><a href=\"http://yobriefca.se/blog/2014/05/19/the-weird-and-wonderful-characters-of-clojure/\">The Weird and Wonderful Characters of Clojure</a> - '<em>A reference collection of characters used in Clojure that are difficult to \"google\"</em>.'</li>\r\n</ul>\r\n<h2>Tools/Libs</h2>\r\n<ul>\r\n\t<li><a href=\"http://www.howtogeek.com/136198/efficiently-manage-your-gmail-with-the-multiple-inboxes-lab/\">Gmail: Multiple Mailboxes</a> - split the UI into multiple sections, one showing the normal inbox and the other ones e-mails determined by a query using the <a href=\"https://support.google.com/mail/answer/7190?hl=en\">extensive search &amp; filtering language of Gmail</a>.</li>\r\n\t<li><a href=\"http://wiki.cyanogenmod.org/index.php?title=About\">CyanogenMod</a> - an OSS Android distribution featuring the latest Android OS and supporting many devices (incl. Kindle Fire, ..) Lot of <a href=\"https://fsfe.org/campaigns/android/liberate.en.html\">good links on the FSFE Liberate your device! campaign page</a></li>\r\n</ul>",
  "excerpt": ""
 },
 {
  "title": "Review: Clojure for Machine Learning (Ch 1-3)",
  "published": "2014-06-26 09:16:44",
  "postType": "post",
  "slug": "/2014/06/26/review-clojure-for-machine-learning-ch-12/",
  "status": "publish",
  "tags": [
   "BI",
   "book",
   "clojure",
   "review"
  ],
  "categories": [
   "Languages"
  ],
  "content": "<a href=\"http://www.packtpub.com/clojure-for-machine-learning/book\"><img class=\"alignleft\" src=\"http://dgdsbygo8mp3h.cloudfront.net/sites/default/files/imagecache/productview/4351OS.jpg\" alt=\"Book cover\" width=\"125\" height=\"151\" /></a>Pack Publishing has asked me to review their new book, <a href=\"http://www.packtpub.com/clojure-for-machine-learning/book\">Clojure for Machine Learning</a> (4/2014) by Akhil Wali. Interested both in Clojure and M.L., I have taken the challenge and want to share my impressions from the first chapters. Regarding my qualification, I am a medium-experienced Clojure developer and have briefly encountered some M.L. (regression etc. for quantitive sociological research and neural networks) at the university a decade ago, together with the related, now mostly forgotten, math such as matrices and derivation.<br><br>In short, the book provides a good bird-eye view of the intersection of Clojure and Machine Learning, useful for people coming from both sides. It introduces a number of important methods and shows how to implement/use them in Clojure but does not - and cannot - provide deep understanding. If you are new to M.L. and really like to understand things like me, you want to get a proper textbook(s) to learn more about the methods and the math behind them and read it in parallel. If you know M.L. but are relatively new to Clojure, you want to skip all the M.L. parts you know and study the code examples and the tools used in them. To read it, you need only elementary knowledge of Clojure and need to be comfortable with math (if you haven't worked with matrices, statistics, or derivation and equations scare you, you will have a hard time with some of the methods). You will learn how to implement some M.L. methods using Clojure - but without deep understanding and without knowledge of their limitations and issues and without a good overview of alternatives and the ability to pick the best one for a particular case.<br><br><!--more--><br><br>The main topics are matrices, linear regression, data categorization (f.ex. Bayesian classification, k-nearest neighbors, decision trees), neural networks, selection and evaluation of data, support vector machines, data clustering, anomaly detection and recommendation, big data. Some of the tools being used are Incanter, clj-ml (primarily a wrapper of Weka),  <a href=\"http://github.com/jimpil/enclog\">Enclog</a> (neural networks), <a href=\"http://bigml.com/\">BigML</a> (facade for ML cloud services).<br><br>Some impressions from the first chapters (ch 1 - 2 take 1/3 of the book):\r\n<ul>\r\n\t<li>I miss the big picture - f.ex. what kinds of regression methods are there, how to know which is appropriate? How to choose which of the 3-4 categorization methods to use in a given case? Again, a good textbook on M.L. would complement this pragmatically oriented book well.</li>\r\n\t<li>As mentioned, the book demonstrates what is possible but does not provide enough explanation and math theory to be able to really understand some of the more complex methods. You won't be able to go and start deriving and optimizing good regression models just based on this text.</li>\r\n\t<li>Ch1 introduces matrices which are later used f.ex. to compute the parameters of an Ordinary Least Squares regression model. It mentions a number of concepts without elaborating their meaning such as eigen-vector and determinant.</li>\r\n\t<li>It would be nice if the author pointed regularly to good online/offline resources where the curious reader can learn more about the math, concepts, and methods being introduced.</li>\r\n</ul>\r\nTip: You might want to check out the <a href=\"https://www.coursera.org/course/ml\">Stanford Machine Learning online course at Coursera</a>, which also draws from numerous case studies and applications.<br><br><em>Disclaimer: I have been unconditionally provided with a free copy of the e-book prior to reveiwing it.</em>",
  "excerpt": ""
 },
 {
  "title": "Most interesting links of July ''14",
  "published": "2014-07-31 21:59:44",
  "postType": "post",
  "slug": "/2014/07/31/most-interesting-links-of-july-14/",
  "status": "publish",
  "tags": [
   "bigdata",
   "clojure",
   "ClojureScript",
   "design",
   "economics",
   "human",
   "linux",
   "mobile",
   "society",
   "types"
  ],
  "categories": [
   "General",
   "Languages",
   "Top links of month"
  ],
  "content": "<h2>Recommended Readings</h2>\r\n<ul>\r\n\t<li>Video: <a href=\"http://www.infoq.com/presentations/dynamic-static-typing\">The Unreasonable Effectiveness of Dynamic Typing for Practical Programs</a> - a static-typing zealot turned friend of dynamic typing under the experience of real-world projects and problems shares thoughts about the limits of type systems (f.ex. both energy and <a title=\"moment of force, the tendency of a force to rotate an object about an axis\" href=\"https://en.wikipedia.org/wiki/Torque\">torque</a> are measured in N*m yet cannot be combined) and their cost: according to the <a href=\"http://dl.acm.org/citation.cfm?doid=1869459.1869462\">Hanenberg's experiment about static and dynamic typing</a> =&gt; the time required to handle the time chacker &gt; time to debug the errors that it would have caught. According to a review of issues at GitHub, only 2% of reported issues for JS, Clojure, Python, and Ruby are type errors and for a large, closed-source Python project type/name/attribute errors were 1%. \"<em>I have come to believe that tests are a much better investment [than static typing].</em>\" Rigorous type system/model =&gt; limited applicability (due to different needs) &lt;=&gt; modelling some things with types doesn't cut it. \"<em>Are the costs of static typing offset by a few percent fewer defects? Is agility more important than reliability?</em>\" \"<em>Static types are anti-modular</em>\" - too a tight coupling. \"<em>Static type checking comes at the expense of complexity, brittleness and a tendency to monoliths.</em>\"\r\n(Personally I miss static typing - but that is perhaps due to having relied on it for so long.)</li>\r\n\t<li><a href=\"http://www.thoughtworks.com/radar/#/\">ThoughtWorks Tech Radar July 2014</a> (<a href=\"http://thoughtworks.fileburst.com/assets/technology-radar-july-2014-en.pdf\">pdf</a>): f.ex. Ansible in Adapt, Masterless Chef/Puppet in Trial, Machine image as a build artifact: Trial, PostgreSQL for NoSQL: Trial, Adopt <a href=\"https://dropwizard.github.io/dropwizard/\">Dropwizard</a> (Rest 4 Java), Go lang, Reactive Extensions across langs [JH: <a href=\"https://github.com/Netflix/RxJava\">RxJava</a>, <a href=\"https://github.com/Reactive-Extensions/RxJS\">RxJS</a>, ..]; Asses <a href=\"/2013/06/28/brief-intro-into-randomstochasticprobabilistic-testing/\">Property-based (generative) testing</a>, ... . Other highlights: <a href=\"https://www.mapbox.com/\">Mapbox</a> (open-source mapping platform), <a href=\"http://openid.net/connect/\">OpenID Connect</a> as a less complex and thus promising alternative to SAML/generic OAuth, <a href=\"http://thoughtworks.github.io/pacto/\">Pacto</a>/<a href=\"https://github.com/realestate-com-au/pact\">Pact</a> for Consumer-Driven Contracts (contract =&gt; simulate consumers/stubb producers =&gt; test your REST clients against the contract so that the rest of tests can assume it is correct and use a stubbed client), <a href=\"https://helloreverb.com/developers/swagger\">Swagger</a> for REST documentation.</li>\r\n\t<li><a href=\"http://johannesbrodwall.com/2014/07/10/the-madness-of-layered-architecture/\">The madness of layered architecture</a> - a nice critique of over-designed \"enterprise\" apps, why that is a problem (SRP, cost of code, unclear where to do a change, ....), why it is different from the successful layered network stack of Ethernet/IP/TCP/... (because in an app, all layers are on the same level of abstraction); bottom line: do not add a layer unless you have a really good reason (hint: the advice of a consultant/speaker does not count as one)</li>\r\n\t<li><a href=\"http://www.infoq.com/articles/qcon-new-york-2014\">Key Takeaway Points and Lessons Learned from QCon New York 2014</a> (viz <a href=\"twitter.com/RiczWest\">@RiczWest</a>) - \"[..] <em>deep insights into real-world architectures and state of the art software development practices, from a practioner’s perspective.</em>\" - architectures of Fb, Foursquare etc., continuous delivery, creating culture, real world functional programming, ... .</li>\r\n\t<li><a href=\"http://radar.oreilly.com/2014/07/questioning-the-lambda-architecture.html\">Questioning the Lambda Architecture</a> (J. Kreps of LinkedIn) - maintaining the same processing in two very different systems (one batch, one stream &amp; real-time) is a maintenance nightmare =&gt; improve the RT/stream processing to handle re-processing and thus both (using e.g. Kafka to store the data and thus be able to re-play them)</li>\r\n\t<li><a href=\"https://developers.google.com/webmasters/smartphone-sites/website-improvement-checklist\">Google: Checklist for mobile website improvement</a></li>\r\n\t<li><a href=\"http://m.infoworld.com/t/hadoop/why-google-cloud-dataflow-no-hadoop-killer-245212\">Google Dataflow and the transition from batch to stream processing</a> - G. Dataflow might not be a Hadoop killer due to requiring that the data are in the Google Cloud but the trend is clear, going away from batch processing to more stream-oriented processing with tools like Spark, Flume etc. that are faster thanks to using memory better and more flexible thanks to not being limited to the rigitd two-stage model of map-reduce. (Reportedly, Google - the one that made Map-Reduce popular - doesn't use it anymore.)</li>\r\n\t<li><a href=\"http://augustl.com/blog/2014/extracting_java_to_folder_no_installer_osx/\">OS X: Extract JDK to folder, without running installer</a></li>\r\n</ul>\r\nSociety, economics, people\r\n<ul>\r\n\t<li><a href=\"http://blogs.hbr.org/2014/06/the-power-of-meeting-your-employees-needs/\">HBR: The Power of Meeting Your Employees’ Needs</a> - people feel better, perform better, are more engaged and likely to stay longer (=&gt; profitability) when 4 basic needs are met: physical [energy] renewal (=&gt; give opportunity, encourage to take a nap or do whatever that helps), value - feeling of being valued by the company, ability to focus, purpose (i.e. serving something larger than ourselves). \"<em>What’s surprising about our survey’s results is how dramatically and positively getting these needs met is correlated with every variable that influences performance. It would be statistically significant if meeting a given need correlated with a rise of even one or two percentage points in a performance variable such as engagement, or retention. Instead, we found that <strong>meeting even one of the four core needs had a dramatic impact on every performance variable we studied</strong>. [..] when all four needs are met, the effect on engagement rises from 50% for one need, to 125%. Engagement, in turn, has been positively correlated with profitability. [..] employers with the most engaged employees were 22% more profitable than those with the least engaged employees.</em>\"\r\n\"<em>[..] those who were encouraged to take intermittent breaks reported they were 50% more engaged, more than twice as likely to stay with the company, and twice as healthy overall. Valuing and encouraging renewal requires no financial investment. What it does require is a willingness among leaders to test their longstanding assumption that that performance is best measured by the number of hours employees puts in – and the more continuous the better — rather than by the value they generate, however they choose to do their work.</em>\"</li>\r\n\t<li><a href=\"http://www.politico.com/magazine/story/2014/06/the-pitchforks-are-coming-for-us-plutocrats-108014_full.html\">The Pitchforks Are Coming… For Us Plutocrats</a> - increasing inequality will eventually lead to the collapse of the sysem (at least so does teach the history). It is people - primarily the middle class - that are the source of the wealth of the society, they produce and also consume most. Thus it is necessary to support them ...</li>\r\n\t<li><a href=\"http://knowledge.wharton.upenn.edu/article/u-s-corporate-world-became-bull-market-corruption-bad-conduct/\">Why the U.S. Corporate World Became ‘A Bull Market for Corruption’</a> - Enron, GM, Goldman Sachs, ... - we hear more and more the names of large corporations in the context of negligence and misues of their customers and investors. It seems that leadership (in the lead by example sense) has died out as well as the feeling of responsibility when one wields power over her customers/investors/markets. Instead, we have the me-first and  money at any cost thinking. Organizations are designed to shield higher-ups from responsibility (meetings with no records...). High pay for short term gains, failure to punish high ranking people.</li>\r\n\t<li>(US) <a href=\"http://www.washingtonpost.com/posteverything/wp/2014/07/08/this-is-what-happened-when-i-drove-my-mercedes-to-pick-up-food-stamps/\">This is what happened when I drove my Mercedes to pick up food stamps</a> - the experience of life in poverty after dropping down from $125k to $25k/year in two months due to childbirth, real estate market crash, and loss of a job. \"<em>Using the coupons was even worse. The stares, the faux concern, the pity, the outrage — I hated it. [..] That’s the funny thing about being poor. Everyone has an opinion on it, and everyone feels entitled to share. [..] Poverty is a circumstance, not a value judgment. I still have to remind myself sometimes that I was my harshest critic. That the judgment of the disadvantaged comes not just from conservative politicians and Internet trolls. It came from me, even as I was living it.</em>\"</li>\r\n</ul>\r\n<h2>Clojure Corner</h2>\r\n<ul>\r\n\t<li><a href=\"http://domkm.com/posts/2014-06-15-isomorphic-clojure-1/\">Isomorphic Clojure[Script], part I</a> - enjoying all the benefits of Single-Page Apps while avoiding their drawbacks (SEO, slower page load, accessibility etc.) - a SPA that can be pre-rendered by the server. Using Om/React, JDK8 with the Nashorn JS engine, core.async, Sente (bi-dirrectional HTTP/WS communication over core.async) and Clojure in the JVM, ClojureScript in Nashorn in the JVM, and ClojureScript in the browser. Example app: <a href=\"https://github.com/DomKM/omelette\">Omelette</a>.</li>\r\n\t<li><a href=\"http://thegeez.net/2014/04/30/datascript_clojure_web_app.html\">clj-crud: a relatively feature-complete example of a Clojure web</a> (4/2014; <a href=\"https://github.com/thegeez/clj-crud\">GitHub</a>) - using Component, Liberator (REST), Datascript + Quiescent (=&gt; React.js), Enlive, Friend etc. including couple of unit-test and ui-test libraries</li>\r\n\t<li><a href=\"https://github.com/nilswloka/conclujon\">Conclujon: Acceptance testing tool</a> (α), Clojure reimplementation of <a href=\"http://concordion.org/\">Concordion</a>, a beautifully simple ADD tool</li>\r\n\t<li><a href=\"https://github.com/frenchy64/dynalint\">dynalint: human-friendly error messages during dev</a> - Clojure typically provides little helpful and sometimes confusing error messages thrown from somewhere deep in the implementation, such as \"<em>Don't know how to create ISeq from: java.lang.Long at clojure.lang.RT.seqFrom</em>\" while we want st. like \"<em>First argument to clojure.core/first must be seqable: 1 (instance of class java.lang.Long</em>\" - and that's what Dynalint does. In the tradition of defensive programming, it adds checks and good error messages to Vars at runtime. You typically run it only during dev, triggering it from the REPL.</li>\r\n\t<li><a href=\"http://grimoire.arrdem.com/\">Grimoire</a> (Reid McKenzie) - a more up-to-date replacement for ClojureDocs</li>\r\n\t<li><a href=\"http://adambard.com/blog/greatest-clojure-hits/\">Adam Bard's Top Clojure Articles</a> for beginners and intermediate Clojure devs - f.ex. Five Mistakes Clojure Newbies Make, Acceptable Error Handling in Clojure, Clojure Reducers for Mortals</li>\r\n\t<li>J. Wilk: <a href=\"http://blog.josephwilk.net/clojure/isolating-external-dependencies-in-clojure.html\">Isolating External Dependencies in Clojure</a> - a nice overview of the options and their pros and cons - with-redefs, alter-var-root, Midje (using alter-var-root in a more controlled manner), higher-order-functions (#1!) etc.</li>\r\n\t<li><a href=\"https://gist.github.com/philandstuff/299cda371c7e74b03f18\">philandstuff's detailed notes from Euroclojure 2014</a></li>\r\n</ul>\r\n<h2>Tools/Libs</h2>\r\n<ul>\r\n\t<li><a href=\"http://nixos.org/nixos/about.html\">NixOS</a> (via <a href=\"twitter.com/bodil/\">@bodil</a>) - a new interesting \"purely functional\" Linux distribution - system configuration is fully declarative (think of Puppet/Chef) and it is always trivial to roll back, you can have multiple versions of a package, users can install non-global SW</li>\r\n\t<li><a href=\"http://influxdb.com/\">InfluxDB</a> - time series, metrics, and events DB that scales; contrary to Graphite it can store richer data than Graphite and its single value; additional highlights: authorization for individual data, roll-up/clean old data, https API. Written in Go.</li>\r\n</ul>",
  "excerpt": ""
 },
 {
  "title": "Notes From CodeMesh 2014",
  "published": "2014-11-03 18:14:26",
  "postType": "post",
  "slug": "/2014/11/03/notes-from-codemesh-2014/",
  "status": "publish",
  "tags": [
   "clojure",
   "conference",
   "quickcheck"
  ],
  "categories": [
   "Languages",
   "Testing",
   "Tools"
  ],
  "content": "My consise highlights from CodeMesh 2014.<br><br><a href=\"https://gist.github.com/philandstuff/f9f95030acff9a14fa76\">Philip Potter has very good CodeMesh notes as well</a>, as usually.<br><br><span style=\"color:#ff0000;\"><strong>TODO: Check out the papers mentioned in the  <a style=\"color:#ff0000;\" href=\"http://www.codemesh.io/codemesh2014/eric-redmond\">NoSQL is Dead talk</a>. (&lt;- slides)</strong></span>\r\n<h2>Tutorial: QuickCheck (John Hughes)</h2>\r\n<h5>General</h5>\r\n<ul>\r\n\t<li>QC =&gt; Less code, more bugs found</li>\r\n\t<li>QC tests are based on models of the system under test - with some kind of a simple/simplified state, legal commands, their preconditions, postconditions, and how they impact the state. The model is typically much smaller and simpler than the imple code.</li>\r\n\t<li>QuickCheck CI (<a href=\"http://quickcheck-ci.com/\">quickcheck-ci.com</a>) - free on-line service for running CI tests for a GitHub project. Pros: You don't need QC/Erlang locally to play with it, it provides history of tests (so you never loose a failed test case), it shows test coverage also for failed tests so you see which code you can ignore when looking for the cause.</li>\r\n\t<li>See John's GitHub repo with examples - <a href=\"https://github.com/rjmh/\">https://github.com/rjmh/</a></li>\r\n</ul>\r\n<h5>Shrinking (a.k.a. simplification)</h5>\r\n<ul>\r\n\t<li>Doesn't just make the example shorter by leaving things out by tries a number of strategies to simplify the exmple, typically defined by the corresponding generators - f.ex. numbers are simplified to 0, lists to earlier elements (as in \"(elements [3, 4, 5])\") etc.</li>\r\n\t<li>You may implement your own shrinking strategies. Ex.: Replace a command with \"sleep(some delay)\" - so that we trigger errors due to timeouts. (A noop that just waits for a while is simpler than any op).</li>\r\n</ul>\r\n<h5>Bug discovery</h5>\r\n<ol>\r\n\t<li>Run QC; assuming a test failed:</li>\r\n\t<li>Instead of diving into the implementation, use first QC to check your hypothesis of what constitutes \"bad input\" by excluding the presumed bad cases - f.ex. \"it fails when input has 8 characters\" =&gt; exclude tests with 8 and rerun, if you find new failures you know the hypothesis doesn't cover all problems - and you will perhaps refine it to  \"fails when it has a multiple of 8 chars etc. We thus learn more about the wrong behavior and its bounds. Assumption we want to verify: No (other) tests will fail.</li>\r\n\t<li>Do the opposite - focus on the problem, i.e. modify the test case to produce only \"bad cases\". Assumption we want to verify: all tests will fail.</li>\r\n</ol>\r\n<h5>QC vs. example-based testing</h5>\r\nQC code tends to be 3-6* smaller than implementation (partly thanks to the consiseness of Erlang) and fairly simple.<br><br>The case of Vovlo: 3k pages of specs, 20 kLOC QC, 1M LOC C implementations, found 200 bugs and 100 problems (contradictions, unclarities) in the specs. It took 2-3 years of working on it on and off.<br><br>Erlang dets storage race conditions: 100 LOC QC, 6 kLOC Erlang impl.\r\n<h5>Testing stateful stuff</h5>\r\nInvoke dfferent API calls (\"commands\") until one of presumabely legal calls fails due to an accumulated corrupted state. This is an iterative process where we evolve our model of the system - commands, their preconditions (when they can be legally invoked), postconditions, and our repreentation of the state.<br><br>Ex.: Testing of a circular queue. Commads: push (legal on non-full queue), get (legal on non-empty), create new =&gt; generates sequences of new and pushs and gets.\r\n<h5>Testing race conditions</h5>\r\nPrecondition: Run on a multicore PC or control the process scheduler.\r\n<ul>\r\n\t<li>There are many possible correct results (valid interleavings) of parallel actions =&gt; impractical to enumerate and thus to test with example-based tests</li>\r\n\t<li>Correct result is such that we can order (interleave) the concurrently executed actions such that we get a sequential execution yielding the same result. F.ex. an incorrect implementation of a sequence number generator could return the same number to two concurrent calls - which is not possible if the calls were done sequentially.</li>\r\n</ul>\r\n<h5>Testing data structures</h5>\r\nMap the DS to a simpler one and use that as the model - f.ex. a list for a tree (provided there is a to_list function for the tree).\r\n<h2>Tutorial: Typed Clojure (Ambrose Bonnaire-Sergeant)</h2>\r\nNote: The documentation (primarily introductory one) could be better\r\n<h5>Resources</h5>\r\n<ul>\r\n\t<li><a href=\"http://typedclojure.org/\">typedclojure.org</a> and <a href=\"https://github.com/typedclojure\">typedclojure@GitHub</a></li>\r\n\t<li><a href=\"https://github.com/typedclojure/core.typed-example\">core.typed-example</a> (currently little outdated but in the process of updating)</li>\r\n\t<li><a href=\"https://gist.github.com/frenchy64/51eef88234e2a2eb3c77\">Prismatic Schema vs. typed.clojure</a> by Ambrose - pros and cons of both</li>\r\n\t<li><a href=\"https://github.com/typedclojure/lein-typed\">lein-typed</a> - plugin to check your code (<code>lein typed check</code>)</li>\r\n</ul>\r\n<h5>Defining types</h5>\r\n<ol>\r\n\t<li>separately: (ann ..)</li>\r\n\t<li>around: wrap in (ann-form &lt;defn&gt; &lt;type def.&gt;)</li>\r\n\t<li>inside: use t/fn, t/defprotocol etc.</li>\r\n</ol>\r\n<h5>Gradual introduction of typed.clojure</h5>\r\n<ul>\r\n\t<li>wrap everything in (t/tc-ignore ...)</li>\r\n\t<li>for unchecked fns you depend on, add (ann ^:no-check somefn [...])</li>\r\n\t<li>If you stare at a type error, consider using contracts (prismatic/Schema or pre/post conds etc.)</li>\r\n</ul>\r\n<h5>Other</h5>\r\n<ul>\r\n\t<li>f.ex. Cursive, Vim (,...?) have support for clojure.typed - show type errors in the source ....</li>\r\n\t<li>core.typed has # deps =&gt; don't use in prod - see https://github.com/typedclojure/core.typed-example/blob/master/project.clj</li>\r\n</ul>\r\n<h2>Keynote: Complexity (Jessica Kerr, Dan North)</h2>\r\n<ul>\r\n\t<li>Always have tasks of all three types: research (=&gt; surface conplexity), kaizen (cont. improvement, improvement of the imprv. process), coding - these 3 interlave the whole time</li>\r\n\t<li>A team needs skills in a number of areas, it isn't just coding - evaluation of biz valuedelivered, monitoring, programming, testing, deployment, DB, FS, networks, ... .</li>\r\n</ul>\r\n<h2>Keynote: Tiny (Chad Fowler)</h2>\r\nKeep things tiny to be efficient (tiny changes, tiny teams, tiny projects, ...).\r\n<ul>\r\n\t<li>Research by armies and in SW dev [TODO: find the two slides / qsm, Scrum] shows that teams of max 5-6 work best\r\n<ul>\r\n\t<li><strong>Teams of 7+ take considerably more time and thus money</strong> (5* more wrt. one study) to complete the same thing</li>\r\n\t<li>=&gt; small, autonomous teams with separate responsabilities (decomosition, SRP etc. FTW!)</li>\r\n</ul>\r\n</li>\r\n\t<li>Human capacity to deal with others is limited - one company creates a new department whenever size exceeds 100</li>\r\n\t<li>Big projects fail; Standish CHAOS report - only cca 10% larger projects succeed compared to nearly 80% of small ones (summed together: 39% succeed)</li>\r\n\t<li>Note: 1 month is not a short iteration</li>\r\n</ul>\r\n<h2>Distributed Programming (Reid Draper)</h2>\r\n<h5>RPC is broken</h5>\r\n- it tries to pretend a remote call is same as local but:\r\n<ul>\r\n\t<li>what if the call never returns?</li>\r\n\t<li>the connection breaks? (has the code been executed or not yet?)</li>\r\n\t<li>what about serialization of arguments (file handles, DB conn.,...)</li>\r\n</ul>\r\nIt ignores the special character of a remote code and the 8 fallacies of distributed progr.\r\n<h5>Message passing</h5>\r\nis batter than RPC. There is also less coupling as the receiver itself decides what code to call for a specific message.\r\n<h5>Bloom</h5>\r\nThe <a href=\"http://www.bloom-lang.net/features/\">Bloom lang</a> from the <a href=\"http://boom.cs.berkeley.edu/\">BOOM research</a> project explores new, better ways of distributed programming. Currently implemented as a Ruby DSL.<br><br>From its page (highlight mine):\r\n<blockquote>Traditional languages like Java and C are based on the <a title=\"Von Neumann on Wikipedia\" href=\"http://en.wikipedia.org/wiki/Von_Neumann_architecture\">von Neumann</a> model, where a program counter steps through individual instructions in order. Distributed systems don’t work like that. Much of the pain in traditional distributed programming comes from this mismatch:  programmers are expected to bridge from an ordered programming model into a disordered reality that executes their code.  Bloom was designed to match–and exploit–the disorderly reality of distributed systems.  <strong>Bloom programmers write programs made up of unordered collections of statements, and are given constructs to impose order when needed.</strong></blockquote>\r\n<h5>Correctness testing of concurrent stuff</h5>\r\n<ul>\r\n\t<li>Unit testing unsuitable - there are just too many combinations of correct results and can only test the cases the dev can think of</li>\r\n\t<li>=&gt; generate the tests - property-based testing / QuickCheck</li>\r\n\t<li>PULSE - an addon to property-based testing that tries to trigger concurrency problems by using a scheduler that tries different interleavings of actions (randomly but repeatedly) [Erlang]</li>\r\n\t<li>Simulation testnng - Simulant</li>\r\n</ul>\r\n<h5>Benchmarking</h5>\r\nBeware the effects of GC, page cache, cronjob (e.g. concurrently running backup), SW updates =&gt; running a simple load test for few mins is not enough.\r\n<h2>Cheats &amp; Liars: The Martial Art of Protocol Design (Pieter Hintjens)</h2>\r\nPieter is the brain behind AMQP, ZeroMQ and <a href=\"http://cultureandempire.com/html/edgenet.html\">EdgeNet</a> (protocols for anonymous, secure, peer-to-peer internet). He has shared great insights into designing good protocols, the dirty business surrounding protocols and standardization, and troll-proof organization of communities (as a self-roganizing, distributed team).<br><br>More: See <a href=\"http://hintjens.wdfiles.com/local--files/books/zguide-c.pdf\">Ch.6 The ØMQ Community</a> in the online The ZeroMQ Guide - for C Developers. (He has also <a href=\"http://hintjens.com/books\">other interesting online or paid books</a>.)\r\n<ul>\r\n\t<li>Protocol is a contract for working together</li>\r\n\t<li>IT should be minimalistic and specific, name the participants, ...</li>\r\n\t<li>Protocols and their strandardization are prey to \"psychopatic\" organizations that want to hijack them for their own profit (by pushing changes that benefit them, taking over the standardization process, ...) (Pieter has experienced it e.g. with AMQP; these trolls always show up). It's advantegous to take control of a successful protocol so that you can make money off it or build stuff on it and sell that. Examples:\r\n<ul>\r\n\t<li>Microsoft MS Doc XML  - this \"open\" spec f.ex. reportedly defines that one functions works \"as Word 95\"</li>\r\n\t<li>A company pushing changes that nobody else really understands, thus undermining compatibility of implementations</li>\r\n\t<li>Pushing such changes that an implementor can claim compliance to the standard yet implement it so that his products only work with his products</li>\r\n\t<li>Crazy/proprieetary protocol extensions, patenting/trademarking/copyrighting the spec (e.g. TM on Bluetooth)</li>\r\n</ul>\r\n</li>\r\n\t<li>Hijacking-safe protocol creation process (beware \"predatory maliciousness\"):\r\n<ul>\r\n\t<li>The specs is GPL =&gt; nobody can capture it (e.g. ZeroMQ)</li>\r\n\t<li>The community has clear rules and deals with trolls by kicking them out</li>\r\n\t<li>There is a good process for evolving the spec</li>\r\n</ul>\r\n</li>\r\n\t<li>How to spec i protocol?\r\n<ul>\r\n\t<li>Start with a very, very small and simple contract - only add things that you <em>desperately need</em> - e.g. ZeroMQ v1 had no versioning, security, metadata (versioning added in v2, metadata in v3, ecurity later). You don't know what you really need until you try it. F.ex. even the original AMQP has 60-75% waste in it!!!!</li>\r\n\t<li>Do very slow and gradual evolution</li>\r\n\t<li>Layering is crucial - keep your protocol on one layer, only specify relevant things, leave the other layers for other specs so they can evolve and age in different speed; the more in a spec the earlier will st. be outdated (Pizza contract says nothing about the kitchen, f.ex.)</li>\r\n</ul>\r\n</li>\r\n\t<li>Community and cooperation (See the <a href=\"http://hintjens.wdfiles.com/local--files/books/zguide-c.pdf\">Ch.6 The ØMQ Community</a> mentioned above.)\r\n<ul>\r\n\t<li>community needs clear rules to keep trolls away (and they always pop up)</li>\r\n\t<li>don't just absorb the damage trolls do, ban them</li>\r\n\t<li>self-org., decentralized team</li>\r\n</ul>\r\n</li>\r\n</ul>\r\n<h2>PureScript (Bodil Stokke)</h2>\r\nWorking with larger JavaScript apps (&gt; 100 LOC :-)) is painful, primarily due to the lack of type checking and thus requiring one to take lot of care when chaning code so that nothing breaks at runtime. TypeScript is a possible solution but it still feels limited.<br><br>PureScript is very Haskell-like language compiled to JS. It is a pure functional lang, effects are performed only via the Effect Monad (Eff). It is pragmatic w.r.t. interoperability - it is possible to embedd JS code and just add a signature to it, the compiler will trust it.<br><br>Moreover, you can use property-basd testing with QuickCheck and Functional Reactive Programming with Bodil's <a href=\"https://github.com/bodil/purescript-signal\">Signal library</a>. Isn't that wonderful?!<br><br>See the <a href=\"https://github.com/bodil/purescript-is-magic\">PureScript Is Magic</a> code at GitHub, primarily the 150 LOC <a href=\"https://github.com/bodil/purescript-is-magic/blob/master/src/Main.purs\">Main.purs</a>.<br><br>&lt;3<br><br>Category theory notes:\r\n<ul>\r\n\t<li>Semigroup is a domain with a cumulative operation (e.g. ints with +)</li>\r\n\t<li>Monoid (?) is a semigroup with a unit element, i.e. one where \"element operation unit = element\" as 0 for + or 1 for *.</li>\r\n</ul>\r\n<h2>Megacore, Megafast, Megacool (Kevin Hammond)</h2>\r\nInteresting research project ParaPhrase for parallelization of code through automatic refactoring and application of any of supported topologies (Farm, Pipeline, Map, ...) - <a href=\"http://paraphrase-ict.eu/\">ParaPhrase-ict.eu</a> and <a href=\"http://www.project-advance.eu/\">www.project-advance.eu</a> (in general the promises of automatizatio regarding fixing software development problems have have hugely underdelivered but still something might be possible). In some cases their solution managed to do in hours what a developer did in days.<br><br>Quote Bob Harper:\r\n<blockquote>The only thing that works for parallelism is functional programming</blockquote>\r\nPS: C++17 is going to have support for parallel and concurrent programming.\r\n<h2> Categories for the Working Programmer (Jeremy Gibbons)</h2>\r\nAn elementary intro into category theory in 10 points, yet I got immediately lost. It might be worth to <a href=\"http://www.codemesh.io/static/upload/media/14153791979335jeremygibbons.pdf\">study the slides</a> and look for more <a href=\"http://www.cs.ox.ac.uk/jeremy.gibbons/\">resources at the author's uni page</a> and not-so-active blog <a href=\"http://patternsinfp.wordpress.com/\">Patterns in Functional Programming </a>.\r\n<h2> NoSQL is Dead (Eric Redmond)</h2>\r\nMain message: There is just too many differences between NoSQL DBs for this expression to be meaningful.\r\n<h2>Lobby talks</h2>\r\n<h3>Hacking people</h3>\r\nI had an inpiring lunch chat with Chad and a Polish lady whose name I unfortunately don't know. Their companies do fascinating stuff to leverage the potential of their humans - one has replaced top-down management wrt. projects with environment where there are clear objectives (increase monthly active users) and the freedom to come with ideas to contribute to them, recruit other people for the idea and, if successful, go implement it (while continually measuring against the objectives). Clearly enough it is not easy, some people have troubles trying to manage everything or doing what they believe in without checking the real implect on the objectives etc. but it already provides more value then before. This has been going on for just a few months so hopefully when it settles more we will hear about their experience.<br><br>The other company realized that people are different (wow! how could our industry ignore that?!) and started to go psychological profiling of employees to understand what type of team member they are - a driver, a worker, a critic who is always hunting for possible issues and problems etc. And they compose teams so that they have the right mix of different personalities to avoid both insurpasable conflicts and the risks of group-think.<br><br>I believe this is the future of our industry - really understand people and \"hack\" our organizations to leverage that for greater happiness and better results.\r\n<h2>Non-talks</h2>\r\n<ul>\r\n\t<li>Jessica Kerr: <a href=\"https://github.com/jessitron/teamo\">Simulation of team work and the effect of (no) slack</a><br><br><pre><code></code></pre><br><br>- what happens when you let your programmers crunch work without any slack time? And when you introduce slack? Jessica has made this Scala simulation to produce the results we would expect - much more even production in the slack case, lot of rework after deploying features in the non-slack version. Not at all scientific but very nice when you want to *show* your higher-ups what happens when you do the former or the latter. Some people hear much more to a visual stimuli (even though totally made to conform to the message you want to get across) than tons of theory.</li>\r\n\t<li><a href=\"http://aphyr.com/posts/313-strong-consistency-models\">Aphyr - [313] Strong consistency models</a> - \"strong consistency\" is a much broader term than I expected and not all consistency models are so consistent :-) Check out especially this <a href=\"http://aphyr.com/data/posts/313/family-tree.jpg\">consistency family tree image</a>.</li>\r\n</ul>",
  "excerpt": ""
 },
 {
  "title": "Tiny, Tiny Steps - Experience Report Developing A Feature In Minimal Value-Adding Increments",
  "published": "2014-11-10 21:27:20",
  "postType": "post",
  "slug": "/2014/11/10/tiny-tiny-steps/",
  "status": "publish",
  "tags": [
   "design",
   "lean",
   "opinion"
  ],
  "categories": [
   "SW development"
  ],
  "content": "<em>A post for those who want to see what an iterative, MVP-driven development of a feature looks like.</em><br><br><blockquote><a href=\"https://twitter.com/lukew/status/532828788590399488\">@lukew:</a> Start with the simplest version you can. It's much easier to add complexity than to remove it.</blockquote><br><br>Once upon time, there was a webshop portal with hundreds of partner webshops displayed on the front page. Potential users wanted to find out if their favorite webshops or a particular type of goods were available, existing users wanted to find a shop quickly. Therefore it was decided to implement search. But how to do that?<br><br><!--more--><br><br><h2>Alternative 1: The waterfall search</h2><br><br>We have immediatelly switched on our engineering brains and started looking at Solr/Lucene and the APIs of the webshops to be able to import their goods catalogues so that our users could find everything from one place. Luckily enough, we havent went far along this path. It would certainly take us weeks while the users would still have been stuck with the same unusable, unsearchable grid of webshops with only few broad categories to help them.<br><br><h2>Alternative 2: Minimal viable feature growing iteratively</h2><br><br>After the original diversion, I have focused on getting value to the users ASAP. Thus the development was as follows:<br><br><ol>\n    <li>Purely client-side search (or rather filtering) in webshop names, a case-insensitive matching of a substring</li>\n    <li>Addition of a library that can do fuzzy matching so that even misspelled names are found</li>\n    <li>Addition of keyword search - for each webshop we had tens of keywords such as \"shoes\" or \"sport\" so I transferred those to the browser as well and started to search them too. (The display of the results has evolved accordingly. I have also introduced lazy loading of these data not to impact initial load time.)</li>\n    <li>I've moved the search to the server-side to save clients from having to fetch so much data and thus increase load size, especially on mobile devices. This also opened possibilities for searching other sources later on. That is where we stopped for the time being. (Thanks to using ClojureScript at frontend and Clojure at backend, this was mostly copy &amp; paste.)</li>\n</ol><br><br>The good thing was that every few days we could have delivered increased value to the users. And I was also able to test the search on a frined (thank you, Fredrik!) early in the process and improve the UI considerably. (Weak search with good UI/UX may well beat great search with terrible one, it turns out.)<br><br><h2>What could have been improved</h2><br><br>It wasn't perfect though:<br><br><ul>\n    <li>We actually did not deploy the individual iterations to the users for other reasons (but we could!)</li>\n    <li>We had no monitoring in place and thus couldn't know whether users used it (and thus that it was worthwile to develop it further) and how they used it or failed to use it.</li>\n    <li>I'd have loved to see the impact on our conversion rates and active user base.</li>\n</ul><br><br><h2>Conclusion</h2><br><br>I love iterative development, doing the minimal thing possible to push value to users and get real feedback on it ASAP. In this case it turned out that a far simpler solution than originally envisioned, developed in few days, was sufficient. Win win.<br><br><p style=\"text-align:center;\"><em>You might enjoy also other <a href=\"/tag/opinion/\">posts on effective development</a>.</em></p>",
  "excerpt": ""
 },
 {
  "title": "Book Review & Digest: Capital In The Twenty-First Century",
  "published": "2014-11-21 19:52:00",
  "postType": "post",
  "slug": "/2014/11/21/book-review-digest-capital-in-the-twenty-first-century/",
  "status": "publish",
  "tags": [
   "book",
   "economy",
   "justice",
   "society"
  ],
  "categories": [
   "General"
  ],
  "content": "<em>My key takeaways and highlights from the book. This is not an objective and consistent review.</em><br><br><a href=\"http://www.amazon.com/Capital-Twenty-First-Century-Thomas-Piketty-ebook/dp/B00I2WNYJW/\">Capital in the Twenty-First Century</a> by Thomas Piketty is together with <a href=\"http://www.amazon.com/Thinking-Fast-Slow-Daniel-Kahneman-ebook/dp/B00555X8OA/\">Thinking, Fast and Slow</a>, the most important book on society I've ever read. And together with Rawls' <a href=\"http://www.amazon.com/Theory-Justice-John-Rawls/dp/0674000781/ref=sr_1_2?s=books&amp;ie=UTF8&amp;qid=1416518866&amp;sr=1-2&amp;keywords=rawls\">A Theory of Justice</a> it has shaped my opinions on society and justice. All politicians and good people interested in politics and inequality should study it. It is unique in leveraging over 200 hundred years of data from different countries and using those as the base of the discussion of the evolution, laws, and future of capital and (in)justice in its distribution.<br><br>Key points:<br><br><ul>\n<li>Growth cannot be 4-5% forever. In the long term, 1-1.5% is more realstic (and still far more than in the past). Higher growth is typical of countries catching up to more advanced economies (such as Europe to US, UK after WW2, China to the West nowadays).</li>\n<li>Return on capital, typically 4-5% (before taxes), is thus far higher than the growth of economy and salaries. The result is that the rich get ever richer, taking ever more of the national income. (Consequently, the poorer half has ever less of it.)</li>\n<li>To keep democracy and have a stable society, this has to be adressed politically.</li>\n</ul><br><br><!--more--><br><br><h2>Digest</h2><br><br>Growth in the long term and historically is slow, 0-1% (already 1%pa results in +35% in a generation, now what after 300 years?!). Piketty guesses that in 21st century the growth will be 1 - 1.5%.\nReturn on capital in 21.c. is 3-4% (1 less than 100yrs ago due to taxes).\nMost countries have 4-6 years of national income of capital (approx. all private, public capital (mainly schools, hospitals etc) - debt are close to 0). This is rising since the fall 1914-45 and likely to continue.\nAs economical and population growth decrease, the importance of past wealth grows and it accumulates even more (1ppa = +35% in 1 generation), inequality grows.\nInequality is countered by distribution of knowledge / skills and growth.\nInflation: essentially none prior to 1914, helped to kill the great national debts of WW1+2.<br><br>Income from labor as % of national income for top 10% vs. lowest 50%:<br><br><ul>\n<li>Scandinavia 70s-80s 20% X 35%</li>\n<li>Fr, De 25 vs 30</li>\n<li>US 35 X 25 - most unequal ever, growing. I.e. in EU the poorer half earns 40% more.</li>\n</ul><br><br>Capital: in EU, top 10% own 60%, bottom 50% virtually 0 (generally income inequality in Europe very stable past 100 years (% of total income from labor to top 10 x bottom 50%). Equalization only thx to fall of capital and income from it due to WW1+2 (and resulting political changes).<br><br>To decrease capital inequality: higher tax on capital and it's gains (was up to 30% but decreases due to fight for c. among countries), decrease return on capital (happening), increase growth (likely, from 0.x to 1.x%).<br><br>Global inequality of wealth in the early 2010s appears to be comparable in magnitude to that of Europe 1900-1910. Top 0.1% owns 20%, top 1% 50%,top 10% 80-90%. Bottom half owns 5%.(Reminder: in EU, top 10% has 60%).<br><br>Return on capital grows with its size. F.ex. US universities with 0.1s billion earn ~6%, those with 1s bil ~10%. The richest ones invest only 10% in normal stocks etc. while the rest goes to less accessible investments with higher ROI (unlisted stocks, raw materials,...) - requires expensive expertise to access/manage.<br><br>According to official stats, all rich countries have negative balance of ownership (few %), so do the poor ones. Explanation: the rich ones actually own abroad more than foreigners own in them but lot (10+%) of the ownership is hidden in tax havens (= tax evasion).<br><br>US (and UK) had confiscatory progressive tax on top incomes, around 90% in US til 80s. They were removed by the conservative revolutions of Reagan, Thatcher powered by feeling of loosing to other economies - though this was only a mechanical effect of catching up after the destruction of WW1+2. The resulting rise of top salaries had no positive effect on growth. The only effect is greater inequality, smaller pay for the poorest half.<br><br>Debt removal: tax on capital &gt; inflation &gt; austerity. Such a tax requires good information sharing, much better than what we have (to find out who owns what).<br><br>EU: Eurozone cannot proceed without a common way to manage it's finances, ie. common budget, taxes, and institutions necessary to manage them.<br><br><h2>Conclusion</h2><br><br>Return on capital is much higher than growth in the long run, leading to a society of rentiers and ever greater inequalities, which leads to social tension and eventually a revolution.\nTo take control of capitalism and prevent infinite growth of capital (and thus inequalities), we need a (global) progressive tax on capital. That is not possible without global information sharing, to know who owns what. \"Capital\" here means everything, cash, real estates, bonds, stocks.",
  "excerpt": ""
 },
 {
  "title": "Connect Tunnelblick to VPN automatically after wake up",
  "published": "2014-12-12 12:33:22",
  "postType": "post",
  "slug": "/2014/12/12/connect-tunnelblick-to-vpn-automatically-after-wake-up/",
  "status": "publish",
  "tags": [
   "osx",
   "security"
  ],
  "categories": [
   "Tools",
   "Uncategorized"
  ],
  "content": "Need: Make sure that VPN is always running except when at work.<br><br>Partial solution: Make sure VPN is always running with \"connect when computer starts\" and using an AppleScript to connect after waking up from sleep. Disconnect manually when at work.<br><br>Future: Check the current location (wifi name? IP?) and do not connect when at work.<br><br><!--more--><br><br><h2>Tunnelblick config</h2><br><br>Select \"When computer starts\" for the VPN config option \"Connect\".<br><br><h2>(Re)Connect to VPN after wake up from sleep</h2><br><br><h3>Wake-up script</h3><br><br>Create the AppleScript <code>~/wake.sh</code> to connect VPN and display a notification about it (OS X 10.9+):<br><br><pre><code>\r\n#!/usr/bin/osascript\r\n# Start Tunnelblick VPN after wakeup (run via sleepwatcher)\r\n# See /Users/me/Library/LaunchAgents/de.bernhard-baehr.sleepwatcher-20compatibility.plist<br><br>tell application &quot;Tunnelblick&quot;\r\n  connect &quot;MY_VPN&quot;\r\n  ## Uncomment v to wait until the connection is establieshed:\r\n  # get state of first configuration where name = &quot;MY_VPN&quot;\r\n  # repeat until result = &quot;CONNECTED&quot;\r\n  #   delay 1\r\n  #   get state of first configuration where name = &quot;MY_VPN&quot;\r\n  # end repeat\r\nend tell<br><br>display notification &quot;(See ~/wake.sh)&quot; with title &quot;Tunneblick  connecting...&quot;\r\n</code></pre><br><br><h3>Running the wake-up script</h3><br><br>We will use sleepwatcher, install it f.ex. via brew:<br><br><pre><code>brew install sleepwatcher</code></pre><br><br>And create a launch agent to start it with the wake script, based on the example provided by brew when installing (<code>/usr/local/Cellar/sleepwatcher/2.2/de.bernhard-baehr.sleepwatcher-20compatibility-localuser.plist</code>, renamed and modified) - <code>~/Library/LaunchAgents/de.bernhard-baehr.sleepwatcher.plist</code>:<br><br><pre><code>\r\n...\r\n&lt;!--string&gt;-s ~/.sleep&lt;/string--&gt;\r\n&lt;string&gt;-w ~/wake.sh&lt;/string&gt;\r\n</code></pre><br><br><h2>Testing it</h2><br><br>Start the launch agent:<br><br><pre><code>launchctl load ~/Library/LaunchAgents/de.bernhard-baehr.sleepwatcher.plist</code></pre><br><br>Now make your computer sleep, wake it up and see if you get the notification (click on the notification icon if it doesn't show up) and if VPN starts.<br><br>Troubleshooting - run the wake.sh manually from the command line (provided that you chmod +x it first).<br><br><h2>Resources</h2><br><br><ul>\n    <li><a href=\"Login to iChat\">Run Mac Script on Wake from Sleep: Login to iChat</a></li>\n    <li><a href=\"http://macosxautomation.com/mavericks/notifications/01.html\">The AppleScript \"display notification\" command</a></li>\n    <li><a href=\"https://code.google.com/p/tunnelblick/wiki/cAppleScriptSupport\">Tunnelblick wiki: AppleScript Support</a> (see the <a href=\"https://groups.google.com/forum/#!topic/tunnelblick-discuss/1MDrN6__mdA/discussion\">example</a>)</li>\n</ul>",
  "excerpt": ""
 },
 {
  "title": "The blog''s year 2014 in review",
  "published": "2015-01-05 09:20:17",
  "postType": "post",
  "slug": "/2015/01/05/2014-in-review/",
  "status": "publish",
  "tags": [],
  "categories": [
   "Uncategorized"
  ],
  "content": "The WordPress.com stats helper monkeys prepared a 2014 annual report for this blog.<br><br><a href=\"/2014/annual-report/\"><img src=\"//s0.wp.com/wp-content/mu-plugins/annual-reports/img/2014-emailteaser.png\" alt=\"\" width=\"100%\" /></a><br><br>Here's an excerpt:<br><br><blockquote>The Louvre Museum has 8.5 million visitors per year. This blog was viewed about <strong>170,000</strong> times in 2014. If it were an exhibit at the Louvre Museum, it would take about 7 days for that many people to see it.</blockquote><br><br><a href=\"/2014/annual-report/\">Click here to see the complete report.</a>",
  "excerpt": ""
 },
 {
  "title": "Notes On Automated Acceptance Testing (from the Continuous Delivery book)",
  "published": "2015-01-08 12:44:32",
  "postType": "post",
  "slug": "/2015/01/08/notes-on-automated-acceptance-testing-from-the-continuous-delivery-book/",
  "status": "publish",
  "tags": [
   "book",
   "continuous_deployment"
  ],
  "categories": [
   "SW development",
   "Testing"
  ],
  "content": "<em>(<a href=\"http://blog.iterate.no/2015/01/08/notes-on-automated-acceptance-testing-from-the-continuous-delivery-book/\">Cross-posted from blog.iterate.no</a>)</em><br><br>These are my rather extensive notes from reading the chapter 8 on Automated Acceptance Testing in the <a title=\"Book at Amazon\" href=\"http://www.amazon.com/Continuous-Delivery-Deployment-Automation-Addison-Wesley/dp/0321601912/\">Continuous Delivery bible</a> by Humble and Farley. There is plenty of very good advice that I just had to take record of. Acceptance testing is an exciting and important subject. Why should you care about it? Because:<br><br><blockquote>We know from experience that without excellent automated acceptance test coverage, one of three things happens: Either a lot of time is spent trying to find and fix bugs at the end of the process when you thought you were done, or you spend a great deal of time and money on manual acceptance and regression testing, or you end up releasing poor-quality software.</blockquote><br><br><!--more--><br><br>(Ch8 focuses primarily on \"functional\" req., ch9 on \"non-functional\" or rather cross-functional requirements.)<br><br><ul>\n    <li>acceptance tests are business-facing, story level test asserting it's complete and working run in a prod-like env; also serves as a regression test</li>\n    <li>manual testing is expensive =&gt; done infrequently =&gt; defects discovered late when there is little time to fix them and we risk to introduce new refression defects</li>\n    <li>Acc.T. put the app through a series of states =&gt; great for discovering threading problems, emergent behavior in event-driven apps, bugs due to architectural mistakes, env/config problems</li>\n    <li>expensive if done poorly</li>\n</ul><br><br><h3><a id=\"user-content-how-to-create-maintainable-acc-t-suites\" class=\"anchor\" href=\"#how-to-create-maintainable-acc-t-suites\"></a>How to Create Maintainable Acc. T. Suites</h3><br><br><ol>\n    <li>Good acceptance criteria (\"<a href=\"http://en.wikipedia.org/wiki/INVEST_%28mnemonic%29\">INVEST</a>\" - especially valuable to users, testable)</li>\n    <li>Layered implementation:\n<ol>\n    <li>Acceptance criteria (Given/When/Then) - as xUnit tests or with Concordion/FitNesse/...</li>\n    <li>Test implementation - it's crucial that they use a (business) domain-specific language (DSL), no direct relation to UI/API, which would make it brittle</li>\n    <li>Application driver layer - translates the DSL to interactions with the API/UI, extracts and returns results</li>\n</ol>\n</li>\n    <li>Take care to keep test implementation efficient and well factored, especially wrt. managing state, handling timeouts, use of test doubles. Refactor.</li>\n</ol><br><br><h4><a id=\"user-content-testing-against-gui\" class=\"anchor\" href=\"#testing-against-gui\"></a>Testing against GUI</h4><br><br><ul>\n    <li>it's most realistic but complex (to set up, ..), brittle, hard to extract results, impossible with GUI technologies that aren't testable</li>\n    <li>if GUI is a thin layer of display-only code with no business/application logic, there is little risk in bypassing it and using the API it talks to directly - this is recommended whenever possible (plus, perhaps, few UI [smoke] tests)</li>\n</ul><br><br><h3><a id=\"user-content-creating-acc-tests\" class=\"anchor\" href=\"#creating-acc-tests\"></a>Creating Acc. Tests</h3><br><br><ul>\n    <li>all (analyst, devs, testers) define acceptance criteria to ensure they all understand and testability</li>\n</ul><br><br><h4><a id=\"user-content-acceptance-criteria-as-executable-specifications\" class=\"anchor\" href=\"#acceptance-criteria-as-executable-specifications\"></a>Acceptance Criteria as Executable Specifications</h4><br><br>(See <a href=\"http://en.wikipedia.org/wiki/Behavior-driven_development\">BDD</a>) - the plain text specifications are bound to actual tests so that they have to be kept up to date [JH: \"Living Documentation\"]<br><br><h3><a id=\"user-content-the-application-driver-layer\" class=\"anchor\" href=\"#the-application-driver-layer\"></a>The Application Driver Layer</h3><br><br><ul>\n    <li>provides business-level API and interacts with the application; f.ex. <code>admin_api.createUser(\"Dave\")</code> or <code>app_api.placeOrder(\"Dave\", {\"product\": \"Chocolate\", \"quantity\": \"5kg\"})</code> - that both translate into a complex sequence of interactions with the API/UI of the app</li>\n    <li>tip: aliasing key values - createUser(\"Dave\") actually creates a user with a random name but aliases it to \"Dave\" in the course of the test =&gt; readable test, unique data</li>\n    <li>tip: defaults - test data are created with reasonable defaults so that a test only needs to set what it cares about - so <code>createUser</code> takes many optional parameters (tlf, email, balance, ...)</li>\n    <li>a well done driver improves test reliability thanks to reuse - only 1/few places to fix on a change</li>\n    <li>develop it iteratively, start with a few cases and simple tests, extend on-demand</li>\n</ul><br><br><h4><a id=\"user-content-how-to-express-your-acceptance-criteria\" class=\"anchor\" href=\"#how-to-express-your-acceptance-criteria\"></a>How to Express Your Acceptance Criteria</h4><br><br><ol>\n    <li>Internal DSL, i.e. in your programming language (f.ex. JUnit tests using App. Driver) - simple(r), refactoring-frinedly, scary for business people</li>\n    <li>External DSL - using FitNesse, Concordion etc. to record the acceptance criteria in plain text or HTML - easy to read and browse for non-tech people but more overhead to create, maintain, keep in synch with the tests [JH: This can be added on top of the internal DSL, pulling up test parameters]</li>\n</ol><br><br>The Window Driver Pattern: Decoupling the Tests from the GUI<br><br><ul>\n    <li>W.D. is the part of App.Driver responsible for interaction with the GUI</li>\n    <li>may be split into multiple, for each distinct part of the application [standard coding best practice]</li>\n    <li>write your tests so that if a new GUI is added, e.g. a gesture-based one, we only need to switch the driver without changing the test</li>\n</ul><br><br><h3><a id=\"user-content-implementing-acceptance-tests\" class=\"anchor\" href=\"#implementing-acceptance-tests\"></a>Implementing Acceptance Tests</h3><br><br><ul>\n    <li>Topics: state, handling of asynchronicity and timeouts, data management, test doubles management etc.</li>\n</ul><br><br><h4><a id=\"user-content-state-in-acceptance-testing\" class=\"anchor\" href=\"#state-in-acceptance-testing\"></a>State in Acceptance Testing</h4><br><br><ul>\n    <li>\"[..] getting the application ready to exhibit the behavior under test is often the most difficult part of writing the test.\" p204</li>\n    <li>we can't eliminate state; try to minimize dependency on complex state\n<ul>\n    <li>=&gt; resist the tendency to use prod DB dump; instead, maintain a controlled, minimal set of data; we want to focus on testing behavior, not data.</li>\n    <li>this minimal coherent set of data should be represented as a collection of scripts; ideally they use the app's public API to put it into the correct state - less brittle than dumping data into the DB - see ch12</li>\n</ul>\n</li>\n    <li>tests are ideally atomic, including independent =&gt; no hard-to-troubleshoot failures due to timing, possible to run in parallel\n<ul>\n    <li>an ideal test also creates all it needs and tidies up afterwards (this is admittedly difficult)</li>\n    <li>tip: establish a transaction, roll back after the test - however this typically isn't possible if we treat acceptance testing as end-to-end testing as recommended [p205]</li>\n</ul>\n</li>\n    <li>\"The most effective approach to acceptance testing is to use the features of your application to isolate the scope of the tests.\" - f.ex. create a new user for every test, given independent user accounts</li>\n    <li>if there is no way around tests sharing data, be very careful, they'll be very fragile; don't forget tear down</li>\n    <li>worst possible case: unknown start state, impossible to clean up =&gt; make the tests <em>very</em> defensive (verify preconditions, ...)</li>\n</ul><br><br><h4><a id=\"user-content-process-boundaries-encapsulation-and-testing\" class=\"anchor\" href=\"#process-boundaries-encapsulation-and-testing\"></a>Process Boundaries, Encapsulation, and Testing</h4><br><br><ul>\n    <li>preferably tests can act/verify without needing any priviledged access (back doors) to the app - don't succumb to the temptation to introduce such back doors, rather thing hard about design, improve modularity/encapsulation/verifiability [p206]</li>\n    <li>if back doors the only option, 2 possibilities; both lead to brittle, high-maintenance code:\n<ol>\n    <li>Add test-specific API that enables you to modify the state/behavior of the app (e.g. switch WS for a stub for a particular call)</li>\n    <li>React to \"magic\" data values (this is ugly, reserve it for your stubs)</li>\n</ol>\n</li>\n</ul><br><br><h4><a id=\"user-content-managing-asynchrony-and-timeouts\" class=\"anchor\" href=\"#managing-asynchrony-and-timeouts\"></a>Managing Asynchrony and Timeouts</h4><br><br><ul>\n    <li>asynchrony arises f.ex. due to asynchronous communication, threads, transactions</li>\n    <li>push asycnhronous behavior (wait for response, retries, ...) to the App Driver, expose synchronous API to the tests =&gt; easier to write tests, fewer places to tune; so in a test we will have f.ex. <code>sendAsyncMsg(m);verifyMsgProcessed();</code> and in the driver's sendAsyncMsg: <code>while(!timeout) if(pollResult) return; else sleep N; continue;</code></li>\n    <li>tip: instead of waiting for MAX_TIMEOUT and then polling the result, retry polling it more frequently until response or timeout. If possible, replace polling with hooking into events generated by the system (i.e. register a listener) } both result in a faster response</li>\n</ul><br><br><h4><a id=\"user-content-using-test-doubles\" class=\"anchor\" href=\"#using-test-doubles\"></a>Using Test Doubles</h4><br><br><ul>\n    <li>Automated acceptance tests are not the same as User Acceptance Tests, i.e. they shouldn't use (all) the real external systems, we need to ensure correct, known initial state and an external system we don't control prevents that [JH: unless it's stateless?]</li>\n    <li>dilemma: integration is difficult to get it right and a common source of errors =&gt; test integration points carefully and effectively X external systems take out our control of the app's state and perhaps cannot handle the load generated by testing. One possible solution is to:\n<ol>\n    <li>Create and use test doubles for all ext. systems</li>\n    <li>Create small test suites around every integration point using the real system</li>\n</ol>\n</li>\n    <li>a benefit of test doubles is that they add points where we can control the behavior, simulate communication failures, simulate error responses or responses under load etc., that might be difficult to provoke in the real system</li>\n    <li>minimize and contain the dependencies on ext. systems - preferably one gateway/adapter per system</li>\n</ul><br><br><h4><a id=\"user-content-testing-external-integration-points\" class=\"anchor\" href=\"#testing-external-integration-points\"></a>Testing External Integration Points</h4><br><br><ul>\n    <li>these integration tests may need to run less frequently due to limitations of the target systems and might thus require a separate stage in the pipeline</li>\n    <li>focus on likely problems; f.ex. in an evolving systems the schemas and contracts we rely upon will change and thus we want to test them</li>\n    <li>\"[..] there is usually a few obvious scenarios to simulate in most integrations\" =&gt; do these, add more as defects are discovered. This approach isn't perfect but good wrt. cost/benefit.</li>\n    <li>only test calls and data that you use and care about, not everything &lt;- cost/benefit</li>\n</ul><br><br><h3><a id=\"user-content-the-acceptance-testing-stage\" class=\"anchor\" href=\"#the-acceptance-testing-stage\"></a>The Acceptance Testing Stage</h3><br><br><ul>\n    <li>fail the build if acceptance tests fail without a compromise; \"stop the line\"</li>\n    <li>tip: record the interaction of the test and UI for troubleshooting, e.g. via <a href=\"http://www.unixuser.org/%7Eeuske/python/vnc2flv/index.html\">Vnc2flv</a> [2/2010]</li>\n    <li>\"We know from experience that without excellent automated acceptance test coverage, one of three things happens: Either a lot of time is spent trying to find and fix bugs at the end of the process when you thought you were done, or you spend a great deal of time and money on manual acceptance and regression testing, or you end up releasing poor-quality software.\" p213</li>\n</ul><br><br><h4><a id=\"user-content-keeping-acceptance-tests-green\" class=\"anchor\" href=\"#keeping-acceptance-tests-green\"></a>Keeping Acceptance Tests Green</h4><br><br>Due to their slowness, devs don't wait for the result of acceptance tests and thus tend to ignore their failure =&gt; build-in discipline. If you let the tests rot, they will eventually die away or it will cost you more to fix them before the release (delayed feedback, lost context, ...).<br><br><h4><a id=\"user-content-deployment-tests\" class=\"anchor\" href=\"#deployment-tests\"></a>Deployment Tests</h4><br><br>Ideal acceptance tests are atomic, set up and celan up their own data and thus have minimal dependency on existing state, and use public channels (API,..) instead of back doors. On the other hand, deployment tests are intended to verify, for the first time, that our deployment script works on a prod-like env. so they consist of a few smoke tests checking that the env. is configured as expected, communication links between components are up&amp;running. They run before functional acc. tests and fail the build immediately (instead for letting the acc. tests time out due to dead dependencies etc.). If we have other slow but important tests (f.ex. expelled from the commit stage), we can run them here as well.<br><br><h3><a id=\"user-content-acceptance-test-performance\" class=\"anchor\" href=\"#acceptance-test-performance\"></a>Acceptance Test Performance</h3><br><br><ul>\n    <li>being comprehensive and realistic (close to UI) is more important than speed; on large projects they often take few hours. Speedup tips below.</li>\n</ul><br><br><h4><a id=\"user-content-refactor-common-tasks\" class=\"anchor\" href=\"#refactor-common-tasks\"></a>Refactor Common Tasks</h4><br><br><ul>\n    <li>factor out and reuse common tasks, especially in setup code, make the efficient</li>\n    <li>setup via API is faster than via UI; sadly, sometimes it is unavoidable to preload test data to DB or use back door though we thus riks differences between these and what the UI would create</li>\n</ul><br><br><h4><a id=\"user-content-share-expensive-resources\" class=\"anchor\" href=\"#share-expensive-resources\"></a>Share Expensive Resources</h4><br><br>Ideally we share nothing but this is usually too slow; typically we share at least the instance of the app for all tests. On a project it was considered to share the instance of Selenium (=&gt; more complex code, risk of session leaks) but finally they rather parallelized the tests.<br><br><h4><a id=\"user-content-parallel-testing\" class=\"anchor\" href=\"#parallel-testing\"></a>Parallel Testing</h4><br><br>Run multiple tests concurrently, perhaps against a single system instance - provided they're isolated.<br><br><h4><a id=\"user-content-using-compute-grids\" class=\"anchor\" href=\"#using-compute-grids\"></a>Using Compute Grids</h4><br><br>Especially useful for single-user systems, very slow tests, or to simulate very many users. See f.ex. <a href=\"http://docs.seleniumhq.org/projects/grid/\">Selenium Grid</a>.",
  "excerpt": ""
 },
 {
  "title": "Continuous Delivery Digest: Ch.9 Testing Non-Functional Requirements",
  "published": "2015-01-08 14:59:28",
  "postType": "post",
  "slug": "/2015/01/08/continuous-delivery-digest-ch-9-testing-non-functional-requirements/",
  "status": "publish",
  "tags": [
   "continuous_deployment",
   "performance"
  ],
  "categories": [
   "Testing"
  ],
  "content": "<em>(<a href=\"http://blog.iterate.no/2015/01/08/notes-on-automated-acceptance-testing-from-the-continuous-delivery-book/\">Cross-posted from blog.iterate.no</a>)</em><br><br>Digest of chapter 9 of the <a title=\"Book at Amazon\" href=\"http://www.amazon.com/Continuous-Delivery-Deployment-Automation-Addison-Wesley/dp/0321601912/\">Continuous Delivery bible</a> by Humble and Farley. See also the <a href=\"/2015/01/08/notes-on-automated-acceptance-testing-from-the-continuous-delivery-book/\">digest of ch 8: Automated Acceptance Testing</a>.<br><br>(\"cross-functional\" might be better as they too are crucial for functionality)<br><br><ul>\n    <li>f.ex. security, usability, maintainability, auditability, configurability but especially capacity, throughput, performance</li>\n    <li>performance = time to process 1 transaction (tx); throughput = #tx/a period; capacity = max throughput we can handle under a given load while maintaining acceptable response times.</li>\n    <li>NFRs determine the architecture so we must define them early; all (ops, devs, testers, customer) should meet to estimate their impact (it costs to increase any of them and often they go contrary to each other, e.g. security and performance)</li>\n    <li>das appropriate, you can either create specific stories for NFRs (e.g. capacity; =&gt; easier to prioritize explicitely) or/and add them as requirements to feature stories</li>\n    <li>if poorly analyzed then they constrain thinking, lead to overdesign and inappropriate optimization</li>\n    <li>only ever optimize based on facts, i.e. realistic measurements (if you don't know it: developers are really terrible at guessing the source of performance problems)</li>\n</ul><br><br>A strategy to address capacity problems:<br><br><!--more--><br><br><ol>\n    <li>Decide upon an architecture; beware process/network boundaries and I/O in general</li>\n    <li>Apply stability/capacity patterns and avoid antipatterns - see <a href=\"https://pragprog.com/book/mnee/release-it\">Release It!</a></li>\n    <li>Other than that, avoid premature optimization; prefer clear, simple code; never optimize without a proof it is necessary</li>\n    <li>Make sure your algorithms and data structures are suitable for your app (O(n) etc.)</li>\n    <li>Be extremely careful about threading (-&gt; \"blocked threads anti-pattern\")</li>\n    <li>Create automated tests asserting the desired capacity; they also will guide you when fixing failures</li>\n    <li>Only profile to fix issues identified by tests</li>\n    <li>Use real-world capacity measures whenever possible - measure in your prod system (# users, patterns of behavior, data volumes, ...)</li>\n</ol><br><br><h3><a id=\"user-content-measuring-capacity\" class=\"anchor\" href=\"#measuring-capacity\"></a>Measuring Capacity</h3><br><br>There are different possible tests, f.ex.:<br><br><ul>\n    <li>Scalability testing - how does the response time of an individual request and # concurrent users changes as we add more servers, services, or threads?</li>\n    <li>Longevity t. - see performance changes when running for a long time - detect memory leaks, stability problems</li>\n    <li>Throughput t. - #tx/messages/page hits per second</li>\n    <li>Load t. - capacity as functional of load to and beyond the prod-like volumes; this is the most common</li>\n    <li>it's vital to use realistic scenarios; on the contrary, technical benchmark-style measurements (# reads/s from DB,..) can be sometimes useful to guard against specific problems, to optimize specific areas, or to choose a technology</li>\n    <li>systems do many things so it's important to run different capacity tests in parallel; it's impossible to replicate prod traffic =&gt; use traffic analysis, experience, intuition to achieve as close a simulation as possible</li>\n</ul><br><br><h4><a id=\"user-content-how-to-define-success-or-failure\" class=\"anchor\" href=\"#how-to-define-success-or-failure\"></a>How to Define Success or Failure</h4><br><br><ul>\n    <li>tip: collect measurements (absolute values, trends) during the testing and present them in a graphical form to gain insight into what happened</li>\n    <li>too strict limits will lead to intermittent failures (f.ex. when network overloaded by another operation) X too relaxed limits =&gt; won't discover a partial drop in capacity =&gt;\n<ol>\n    <li>Aim for stable, reproducible results - isolate the test env as much as possible</li>\n    <li>Tune the pass threshold up once it passes at a minimum acceptable level; back down if it starts failing after a commit due to well-understood and acceptable reason</li>\n</ol>\n</li>\n</ul><br><br><h4><a id=\"user-content-capacity-testing-environment\" class=\"anchor\" href=\"#capacity-testing-environment\"></a>Capacity-Testing Environment</h4><br><br><ul>\n    <li>replicates Prod as much as possible; extrapolation from a different environment is highly speculative, unless based on good measurements. \"Configuration changes tend to have nonlinear effect on capacity characteristics.\" p234</li>\n    <li>an exact replica of Prod sometimes impossible or not sensible (small project, capacity little important, or when prod has 100s of servers) =&gt; capacity testing can be done on a subset of prod servers as a part of Canary Releasing, see p263</li>\n    <li>scaling is rarely linear, even if the app is designed for it; if test env is a scaled-down prod, do few scalings runs to measure the size effect</li>\n    <li>saving money on a downscaled test env is a false economy if capacity is critical; no matter what it won't be able to find all issues and it will be expensive to fix them later - see the storu on p236</li>\n</ul><br><br><h4><a id=\"user-content-automating-capacity-testing\" class=\"anchor\" href=\"#automating-capacity-testing\"></a>Automating Capacity Testing</h4><br><br><ul>\n    <li>it's expensive but if important, it must be a part of the deployment pipeline</li>\n    <li>these tests are complex, fragile, easily broken with minor changes</li>\n    <li>Ideal tests: use real-world scenarios; predefine success threshold; relatively short duration to finish in a reasonable time; robust wrt. change to improve maintainability; composable into larger-scale scenarios so that we can simulate real-world patterns of use; repeatable and runnable sequentially or in parallel =&gt; suitable both for load and longevity testing</li>\n    <li>start with some existing (robust and realistic) acceptance tests, adapt them for capacity testing - add success threshold and auditability to scale up</li>\n</ul><br><br>Goals:<br><br><ol>\n    <li>Creat realistic, prod-like load (in form and volume)</li>\n    <li>Test realistic but pathological real-life loading scenarios, i.e. not just the happy path; tip: identify the most expensive transactions and double/triple their ratio</li>\n</ol><br><br>To scale up, you can record the communication generated by acceptance tests, postprocess it to scale up (multiply, insert unique data where necessary), reply at high volume<br><br><ul>\n    <li>Question: Where to record and play back:\n<ol>\n    <li>UI - realistic but impractical for 10,000s users (and expensive)</li>\n    <li>Service/public API (e.g. HTTP req.)</li>\n    <li>Lower-level API (such as a direct call to the service layer or DB)</li>\n</ol>\n</li>\n</ul><br><br><h4><a id=\"user-content-testing-via-ui\" class=\"anchor\" href=\"#testing-via-ui\"></a>Testing via UI</h4><br><br><ul>\n    <li>Not suitable for high-volume systems, when too many clients are necessary to generate a high load (partially due to UI client [browser] overhead); also expensive to run many machines</li>\n    <li>UI condenses a number of actions (clicks, selections) into few interactions with back-end (e.g. 1 form submission) that has a more stable API. To answer: are we interested in performance of the clients or of the back-end.</li>\n    <li>\"[..] we generally prefer to avoid capacity testing through the UI.\" - unless the UI itself or the client-server interaction are of a concern</li>\n</ul><br><br><h4><a id=\"user-content-recording-interactions-against-a-service-or-public-api\" class=\"anchor\" href=\"#recording-interactions-against-a-service-or-public-api\"></a>Recording Interactions against a Service or Public API</h4><br><br><ul>\n    <li>run acceptance tests, record in/outputs (e.g. SOAP XML, HTTP), replace what must vary with placeholders (e.g. ${ORDER_ID}), create test data, merge the two</li>\n    <li>Recommended compromise: Aim to change as little as possible between instances of a test - less coupling between the test and test data, more flexible, less fragile. Ex.: unique orderId, customerId but same product, quantity.</li>\n</ul><br><br><h4><a id=\"user-content-using-capacity-test-stubs-to-develop-tests\" class=\"anchor\" href=\"#using-capacity-test-stubs-to-develop-tests\"></a>Using Capacity Test Stubs To Develop Tests</h4><br><br>In high-performance systems testing may fail because the tests themselves do not run fast enough. To discover this case, run them originally against a no-op stub of the application.<br><br><h3><a id=\"user-content-adding-capacity-tests-to-the-deployment-pipeline\" class=\"anchor\" href=\"#adding-capacity-tests-to-the-deployment-pipeline\"></a>Adding Capacity Tests to the Deployment Pipeline</h3><br><br><ul>\n    <li>beware that warm-up time may be necessary (JIT, ...)</li>\n    <li>for known hot spots, you can simple \"guard tests\" already to the commit stage</li>\n    <li>typically we run them separately from acceptance tests - they've different environment needs, perhaps are long-running, we want to avoid undesirable interactions between acceptance and capacity tests; acceptance test stage may include a few performance smoke tests</li>\n</ul><br><br><h3><a id=\"user-content-other-benefits-of-capacity-tests\" class=\"anchor\" href=\"#other-benefits-of-capacity-tests\"></a>Other Benefits of Capacity Tests</h3><br><br>Composable, scenario-based tests enable us to simulate complex interactions, together with prod-like env we can<br><br><ul>\n    <li>reproduce complex prod defects</li>\n    <li>detect/debug memory leaks</li>\n    <li>evaluate impact of garbage collection (GC); tune GC</li>\n    <li>tune app config and 3rd party app (OS, AS, DB, ...) config</li>\n    <li>simulate worst-day scenarios</li>\n    <li>evaluate different solutions to a complex problem</li>\n    <li>simulate integration failures</li>\n    <li>measure scalability with different hardware configs</li>\n    <li>load-test communication with external systems even though the tests were originally designed for stubbed interfaces</li>\n    <li>rehears rollback</li>\n    <li>and many more ...</li>\n</ul>",
  "excerpt": ""
 },
 {
  "title": "Focus & Do the Simplest Thing Possible",
  "published": "2015-01-09 23:37:50",
  "postType": "post",
  "slug": "/2015/01/10/focus-do-the-simplest-thing-possible/",
  "status": "publish",
  "tags": [
   "opinion"
  ],
  "categories": [
   "SW development"
  ],
  "content": "<a href=\"https://www.flickr.com/photos/archer10/2212600119/in/photolist-4nw9VV-dC8RjF-a1Wc78-FCfZX-bsiz8v-aAPMWG-j1phGk-gLuLzN-imrCVb-an35tY-97LbDK-pcLbnb-f1s7hT-qFrir3-jCc6hY-dCd6L4-3S78FC-7n6Sy-6Y1VGy-7zVYAy-dMFMXD-gXhJy8-ab5d1N-nWSgRn-fKVh47-bzdFzn-eJsEtY-5KYpcE-kZrPbz-9X5d6w-q4e14s-bkcYqj-pqTYE9-pQ8juv-nFvsE2-pfJ2of-nyDNG4-8rkjTZ-iJWtcx-8Nab5k-appic5-n4vNa-eJewv1-jmtXAY-iwcbYt-hJE4bi-4wqtM1-jktjU7-qiEi8q-9a5aCa\"><img class=\"size-full wp-image-4163\" title=\"Yak at Yundrok Yumtso Lake\" src=\"/images/2015/01/yak-by-dennis_jarvis.jpg\" alt=\"\" width=\"240\" height=\"180\" /></a> Credit: Dennis Jarvis, CC<br><br>Are you tired of days spent in front of the screen, with no results to show? Have you once again engaged in <a href=\"http://sethgodin.typepad.com/seths_blog/2005/03/dont_shave_that.html\">yak shaving</a>? Today, after having failed previously, I have finally managed to solve a problem while avoiding this trap by following rigorously two guidelines preached by grandmaster programmers. Be warned: Following this approach, you will get a working solution - but you won't like it. It will be ugly, stained by compromises, far from the elegant solution you wish for. But if your resources are limited and you want to avoid death by too many yaks, this is your only option. But first, what are these guidelines?<br><br>One: Maintain a laser-sharp <em>focus</em>. A great programmer is constantly aware of what she is trying to achieve and never strays far from it. If the path leads away, she backs up. If something else pops up, she writes it down for later and gets back to the job. This is essentially about deciding what <em>not</em> to do. (Many thanks to Kent Beck for <a href=\"/2012/09/12/programming-like-kent-beck/\">sharing his focus secret</a>!)<br><br><!--more--><br><br>Two: Always find the <em>simplest, smallest thing</em> - a stepping stone - that moves you toward the goal. It might not be especially pretty but perfect is the enemy of good. (\"Make it work, make it right, make it fast.\" - Kent's father, reportedly.)<br><br>In addition, there are a few more crucial ingredients. Awarness of cost/benefit so that you know when to give up because it is not worth the effort. Coming up with various alternatives so that you don't get locked to a single solution. Doing the most unclear and risky things first rather than the nice, easy ones.<br><br>Side note: This awareness of one's goal and possible alternatives at different points of the journey reminds me a lot of the <a href=\"https://mikadomethod.wordpress.com/2010/02/02/the-mikado-method-in-under-a-minute/\">Mikado Method</a> and, inspired by it, I use <a href=\"http://mindmup.com/\">mind maps</a> to keep a track of this.<br><br><h2>My story</h2><br><br>My goal, that I have previously failed to achieve due to too many dead ends, was to introduce tests to our front-end application. This was complicated by the use of bleeding edge technologies (=&gt; you'll bleed when using them) such as EcmaScript 6 and React/Jest, the need to stub/mock parts of the application (<a title=\"XMLHttpRequest\" href=\"https://en.wikipedia.org/wiki/XMLHttpRequest\">XHR</a>) that were <a title=\"Node.js: require()\" href=\"http://nodejs.org/api/all.html#all_require\"><code>required</code></a> by the module under test, and a build relying on Browserify and Gulp.<br><br>As my highly respected colleague and master of all things front-end Pål Ruud commented:<br><br><blockquote>Mix of Jest, Browserify and ES6 has turned out to be really difficult to make to play together. :-(<br><br>I believe I made six different attempts to get a test to run, with different combinations of test frameworks and 6to5, es6ify, traceur.</blockquote><br><br>One of my weaknesses is that I find it difficult to resist such a challenge. Especially regarding missing testing. So I begun my attempt by listing the goal, alternatives, and top risks:<br><br><a href=\"/images/2015/01/woop-testing-mindmup-1.jpg\"><img class=\"size-full wp-image-4151\" src=\"/images/2015/01/woop-testing-mindmup-1.jpg\" alt=\"Mind map of the problem\" width=\"521\" height=\"421\" /></a> Mind map of the problem<br><br>This lists the goal - which, fully expressed, would read \"<em>Create the simplest possible test of a simple method of a <a href=\"http://facebook.github.io/flux/docs/overview.html\">(Flux) Store</a> class,</em>\" the main questions (such as whether to run the tests under Node.js or the browser), and, in red, the points of highest risk - the necessity to pre-process the ES6 files and to <a href=\"http://martinfowler.com/articles/mocksArentStubs.html\">mock (or rather stub)</a> XHR during the tests.<br><br>The simplest &amp; smallest guideline implied that I should reuse the build workflow we already had - Gulp with browserify taking care of es6to5, reactifying etc. - and thus run tests in the browser instead on Node.js (which is considerably slower but also less constraining, enabling us to test also UI-related code in the future). Among the technologies discussed with Pål I have thus also opted for the more mature ones (primarily <a href=\"http://karma-runner.github.io/0.12/index.html\">Karma</a> over <a href=\"https://github.com/airportyh/testem\">Testem</a>). It also required that I stayed with the built-in <code>assert</code> rather than using something fancy like Chai (though switching over could be a future step). So here is the resulting plan:<br><br><ol>\n    <li>Verify we will be able to mock XHR during tests (otherwise we'd need to either find a different solution or change the design to factor out XHR calls) &lt;- proxyquireify</li>\n    <li>Create a dummy test and make Browserify include in the output .js file</li>\n    <li>Get a minimal Karma+Mocha test running in a browser, not touching our production code yet</li>\n    <li>Require the Store from the test and verify we can call a simple method on it</li>\n    <li>Stub XHR so that we can test an actual business method though, for the sake of simplicity, we won't care about data returned by XHR</li>\n</ol><br><br>This led me indeed to a solution though it is very far from what I would like to have. I had to intentionally sacrificy a lot for the sake of getting a working solution [soon]:<br><br><ul>\n    <li>Ability to run tests instantly (i.e. &lt; 3s) and automatically as soon as I save a file - this requirement has nothing to do with the goal itself and is a path to yak hordes</li>\n    <li>Running tests under Node instead of a browser that incurs a great overhead due to browserifying, es6to5-fying, and JSX-fying and starting a real browser</li>\n    <li>Using the less invasive PhantomJS (it failed for some reason, while Chrome worked)</li>\n    <li>Running tests from our watch task or as a part of our build task - for the sake of simplicity, I have created a separate task that has to be invoked separately</li>\n    <li>Being able to make XHR calls return data synchronously in a test so that I could fake what back-end would return and verify the outcome (we use Promises that run asynchronously; there are workarounds but well beyond the scope of my goal - and making our stores decoupled from XHR is anyway a better solution)</li>\n</ul><br><br>I am sure we will eventually find a solution for all of these. But the most important thing is that we made a first step in that direction and that we can now create and run tests (however slow it is). I can finally sleep without Kent hunting me in my dreams :-).<br><br><h2>Conclusion</h2><br><br>To be able to arrive to a solution in a reasonable time, we must be able to focus on our true (and minimalist) goal and take small and simple steps - even though our heart of programmer is bleeding at their lack of elegance and efficiency. Once we have a solution, we can iteratively improve it. In any case, imperfect something always beats a perfect nothing. (Well, unless we talk about Zen.)<br><br>Needless to say, I still suck both at maintaining the focus and doing the simple but inelegant.<br><br><p style=\"text-align:center;\"><em>You might enjoy also other <a href=\"/tag/opinion/\">posts on effective development</a>.</em></p>",
  "excerpt": "Are you tired of days spent in front of the screen, with no results to show? Have you once again engaged in yak shaving? Today, after having failed previously, I have finally managed to solve a problem while avoiding this trap by following rigorously two guidelines preached by grandmaster programmers. Be warned: Following this approach, you will get a working solution - but you won't like it. It will be ugly, stained by compromises, far from the elegant solution you wish for. But if your resources are limited and you want to avoid death by too many yaks, this is your only option. But first, what are these guidelines?<br><br>One: Maintain a laser-sharp focus. A great programmer is constantly aware of what she is trying to achieve and never strays far from it. If the path leads away, she backs up. If something else pops up, she writes it down for later and gets back to the job. This is essentially about deciding what not to do. (Many thanks to Kent Beck for sharing his focus secret!)"
 },
 {
  "title": "Running JavaScript Tests On a CI Server With Karma, Chrome And Fake X",
  "published": "2015-01-13 11:34:01",
  "postType": "post",
  "slug": "/2015/01/13/running-javascript-tests-on-a-ci-server-with-karma-chrome-and-fake-x/",
  "status": "publish",
  "tags": [
   "JavaScript"
  ],
  "categories": [
   "Languages",
   "Testing"
  ],
  "content": "So I want to run my JavaScript tests in a browser on our CI server. But the server has no graphical environment and the tests do not run under P<a href=\"https://github.com/google/traceur-compiler/issues/908#issuecomment-38468174\">hantomJS 1.x because it uses too old WebKit</a> without ES5. The solution? <a href=\"https://github.com/google/traceur-compiler/issues/908#issuecomment-54529495\">Use a real browser and fake X via Xvfb</a>. The browser I use is Chrome though Firefox would like work as well.<br><br>In code:\n<!--more--><br><br><pre><code>\r\n$ sudo apt-get install xvfb chromium-browser\r\n$ test -e /tmp/.X99-lock || sudo /usr/bin/Xvfb :99 &amp;\r\n### Inside my app dir:\r\n$ export DISPLAY=:99.0\r\n$ export CHROME_BIN=/usr/bin/chromium-browser\r\n$ npm install # this will also fire my Karma/Mocha tests\r\n</code></pre><br><br>Notice that we start the fake X, tell Chrome that it should use its display via exporting DISPLAY (screen .0 is the default but I could have explicitely started Xvfb with f.x. \"Xvfb :99 -screen 0 1024x768x24 ...\") and use the <a href=\"http://karma-runner.github.io/0.10/config/browsers.html\">&lt;BROWSER&gt;_BIN ENV variable</a> to tell the karma-chrome-launcher to use /usr/bin/chromium-browser  instead of the default google-chrome.<br><br>Last but not least, we need to run Chrome without sandbox (at least on my server it failed with \"PID namespaces supported Network namespace supported but failed: errno = Operation not permitted.\" This is done via a <a href=\"https://github.com/karma-runner/karma-chrome-launcher/blob/master/README.md#configuration\">custom luncher</a> in <code>karma.conf.js</code>:<br><br><pre><code>\r\nmodule.exports = function(config) {\r\n  config.set({\r\n    browsers: ['Chrome'], // Note: PhantomJS does not work due to pre-ES5\r\n    customLaunchers: {\r\n      Chrome_without_sandbox: {\r\n        base: 'Chrome',\r\n        flags: ['--no-sandbox'] // with sandbox it fails under Docker\r\n      }\r\n    },\r\n    frameworks: ['mocha'],\r\n    files: ['app/w/dist/app-test.js']\r\n  });\r\n};\r\n</code></pre><br><br>Finally, here are some relevant packages from <code>package.json</code>:<br><br><pre><code>\r\n    &amp;quot;karma&amp;quot;: &amp;quot;~0.12&amp;quot;,\r\n    &amp;quot;karma-mocha&amp;quot;: &amp;quot;~0.1&amp;quot;,\r\n    &amp;quot;karma-chrome-launcher&amp;quot;: &amp;quot;~0.1&amp;quot;,\r\n    &amp;quot;mocha&amp;quot;: &amp;quot;~2.1.0&amp;quot;,\r\n</code></pre>",
  "excerpt": ""
 },
 {
  "title": "Challenging Myself With Coplien''s Why Most Unit Testing is Waste",
  "published": "2015-01-26 11:46:02",
  "postType": "post",
  "slug": "/2015/01/26/challenging-myself-with-copliens-why-most-unit-testing-is-waste/",
  "status": "publish",
  "tags": [
   "opinion"
  ],
  "categories": [
   "Testing"
  ],
  "content": "James O. Coplien has written in 2014 the thought-provoking essay <a href=\"http://www.rbcs-us.com/documents/Why-Most-Unit-Testing-is-Waste.pdf\">Why Most Unit Testing is Waste</a> and further elaborates the topic in his <a href=\"http://www.rbcs-us.com/documents/Segue.pdf\">Segue</a>. I love testing but I also value challenging my views to expand my understanding so it was a valuable read. When encountering something so controversial, it's crucial to set aside one's emotions and opinions and ask: \"Provided that it is true, what in my world view might need questioning and updating?\" Judge for yourself how well have I have managed it. (Note: This post is not intended as a full and impartial summary of his writing but rather a overveiw of what I may learn from it.)<br><br>Perhaps the most important lesson is this: <strong>Don't blindly accept fads, myths, authorities and \"established truths.\" Question everything, collect experience, judge for yourself.</strong> As J. Coplien himself writes:<br><br><blockquote>\n  Be skeptical of yourself: measure, prove, retry. Be skeptical of me for heaven’s sake.\n</blockquote><br><br>I am currently fond of unit testing so my mission is now to critically confront Coplien's ideas and my own preconceptions with practical experience on my next projects.<br><br>I would suggest that the main thing you take away isn't \"minimize unit testing\" but rather \"value thinking, focus on system testing, employ code reviews and other QA measures.\"<br><br>I'll list my main take-aways first and go into detail later on:\n<!--more--><br><br><ul>\n<li>Think! Communicate! Tools and processes (TDD) cannot introduce design and quality for you</li>\n<li>The risk mitigation provided by unit tests is highly overrated; it's better to spend resources where return on investment in terms of increased quality is higher (system tests, code reviews etc.)</li>\n<li>Unit testing is still meaningful in some cases</li>\n<li>Actually, testing - though crucial - is overrated. Analyse, design, and use a broad repertoire of quality assurance techniques</li>\n<li>Regarding automated testing, focus on system tests. Integrate code and run them continually</li>\n<li>Human insight beats machines; employ experience-based testing including exploratory testing</li>\n<li>Turn asserts from unit test into runtime pre-/post-condition checks in your production code</li>\n<li>We cannot test everything and not every bug impacts users and is thus worth discovering and fixing (It's wasteful to test things that never occur in practice)</li>\n</ul><br><br>I find two points especially valuable and thought-provoking, namely the (presumed) fact that the efficiency/cost ratio of unit testing is so low and that the overlap between what we test and what is used in production is so small. Additionally, the suggestion to use heavily pre- and post-condition checks in production code seems pretty good to me. And I agree that we need more automated acceptance/system tests and alternative QA techniques.<br><br><h3>Think!</h3><br><br>Unit testing is sometimes promoted as a way towards a better design (more modular and following principles such as <a href=\"http://en.wikipedia.org/wiki/Single_responsibility_principle\">SRP</a>). However, according to Kent Beck, tests don’t help you to create a better design - they only help to surface the pain of a bad design. (TODO: Reference)<br><br>If we set aside time to think about design for the sake of a good design, we will surely get a better result than when we employ tools and processes (JUnit, TDD) to force us to think about it (in the narrow context of testability). (On a related note, the \"<a href=\"http://tech.puredanger.com/2010/10/25/clojure-hdd/\">hammock-driven development</a>\" is also based on the appreciation of the value of thinking.)<br><br>Together with thinking, it is also efficient to discuss and explore design with others.<br><br><blockquote>\n  [..] it’s much better to use domain modeling techniques than testing to shape an artefact.\n</blockquote><br><br>I heartily agree with this.<br><br>(Side note: Though thinking is good, overthinking and premature abstraction can lead us to waste resources on overengineered systems. So be careful.)<br><br><h3>How to achieve high quality according to Coplien</h3><br><br><ul>\n<li>Communicate and analyse better to minimize faults due to misunderstanding of requirements and miscommunication</li>\n<li>Don't neglect design as faults in design are expensive to fix and hard to detect with testing</li>\n<li>Use a broad repertoire of quality assurance techniques such as code reviews, static code analysis, pair programming, inspections of requirements and design</li>\n<li>Focus automated testing efforts on system (and, if necessary, integration) tests while integrating code and running these tests continually</li>\n<li>Leverage <a href=\"http://www.softwaretestinggenius.com/anatomy-of-various-types-of-experience-based-testing-techniques\">experience-based testing</a> such as exploratory testing</li>\n<li>Employ defensive and design-by-contract programming. Turn asserts in unit test into runtime pre-/post-condition checks in your production code and rely on your stress tests, integration tests, and system tests to exercise the code</li>\n<li>Apply unit testing where meaningful</li>\n<li>Test where risk of defects is high</li>\n</ul><br><br>Tests cannot catch faults due to miscommunication/bad assumptions in requirements and design, which reportedly <a href=\"http://www.isixsigma.com/industries/softwareit/defectprevention-reducing-costs-and-enhancing-quality/\">account for 45% of faults</a>. Therefore <strong>communication and analysis</strong> are key.<br><br>Unit testing in particular and testing in general is just one way of ensuring quality, and reportedly not the most efficient one. It is therefore best to <strong>combine a number of approaches</strong> for defect prevention and detection, such as those mentioned above. (I believe that in particular formal inspection of requirements, design, and code is one of the most efficient ones. Static code analysis can also help a lot with certain classes of defects.) (Also there is a history of high-quality software with little or no unit testing, I believe.)<br><br>As argued below, unit testing is wasteful and provides a low value according to Coplien. Thus you should focus on tests that <strong>check the whole system</strong> or, if not practical, at least parts of it - system and integration tests. (I assume that the automated acceptance testing as promoted by <a href=\"https://en.wikipedia.org/wiki/Specification_by_example\">Specification by Example</a> belongs here as well.) Provide \"hooks\" to be able to observe the state and behavior of the system under test as necessary. Given modern hardware and possibilities, these tests should run continually. And developers should integrate their code and submit it for testing frequently (even the delay of 1 hour is too much). Use debugging and (perhaps temporary?) unit tests to pinpoint sources of failures.<br><br><em>My thoughts: I agree that whole-system tests provide more value than unit tests. But I believe that they are typically much more costly to create, maintain and run since they, by definition, depend on the whole system and thus have to relate to the whole (or a non-negligible portion) of it and can break because of changes at number of places. It is also difficult to locate the cause of a failure since they invoke a lot of code. And if we should test a small feature thoroughly, there would typically be a lot of duplication in its system tests (f.ex. to get the system to the state where we can start exercising the feature). Therefore people write more lower-level, more focused and cheaper tests as visualized in the famous <a href=\"http://martinfowler.com/bliki/TestPyramid.html\">Test Pyramid</a>. I would love to learn how Mr. Coplien addresses these concerns. In any case we should really try to get at least a modest number of automated acceptance tests; I have rarely seen this.</em><br><br>Experienced testers are great at guessing where defects are likely, simulating unexpected user behavior and generally breaking systems. <strong>Experience-based - f.ex. exploratory - testing</strong> is thus irreplaceable complement to (automated) requirements-based testing.<br><br><strong>Defensive and design-by-contract programming</strong>: Coplien argues that most asserts in unit tests are actually pre- and post-condition and invariant checks and that it is therefore better to have them directly in the production code as the <a href=\"http://en.wikipedia.org/wiki/Design_by_contract\">design-by-contract</a> programming proposes. You would of course need to generalize them to <a href=\"http://www.scalatest.org/user_guide/property_based_testing\">property-based</a> rather than value-based assertions, f.ex. checking that the length of concatenated lists is the sum of the length of the individual lists, instead of concrete values. He writes:<br><br><blockquote>\n  Assertions are powerful unit-level guards that beat most unit tests in two ways. First, each one can do the job of a large number (conceivably, infinite) of scenario-based unit tests that compare computational results to an oracle [me: because they check properties, not values]. Second, they extend the run time of the test over a much wider range of contexts and detailed scenario variants by extending the test into the lifetime of the product.\n</blockquote><br><br>If something is wrong, it is certainly better to catch it and fail soon (and perhaps recover) than silently going on and failing later; failing fast also makes it much easier to locate the bug later on. You could argue that these runtime checks are costly but compared to the latency of network calls etc. they are negligible.<br><br><strong>Some unit tests have a value</strong> - f.ex. regression tests and testing algorithmic code where there is a \"formal oracle\" for assessing their correctness. Also, as mentioned elsewhere, unit tests can be a useful debugging (known defect localization) tool. (Regression tests should still be preferably written as system tests. They are valuable because, in contrary to most unit tests, they have clear business value and address a real risk. However Mr. Coplien also proposes to delete them if they haven’t failed within a year.)<br><br><h3>Doubts about the value of unit testing</h3><br><br><blockquote>\n  In summary, it seems that agile teams are putting most of their effort into the quality improvement area with the least payoff.\n  ...\n  unless [..] you are prevented from doing broader testing, unit testing isn’t the best you can do\n</blockquote><br><br><ul>\n<li>\"Most software failures come from the interactions between objects rather than being a property of an object or method in isolation.\" Thus testing objects in isolation doesn’t help</li>\n<li>The cost to create, maintain, and run unit tests is often forgotten or underestimated. There is also cost incurred by the fact that unit tests slow down code evolution because to change a function we must also change all its tests.</li>\n<li>In practice we often encounter unit tests that have little value (or actually a negative one when we consider the associated costs) (F.ex. a test that essentially only verifies that we have set up mocks correctly)</li>\n<li>When we test a unit in isolation, we will likely test many cases that in practice do not occur in the system and we thus waste our limited resources without adding any real value; the smaller a unit the more difficult to link it to the business value of the system and thus the probability of testing something without a business impact is high</li>\n<li>The significance of code coverage and the risk mitigation provided by unit tests is highly overrated; in reality there are so many possibly relevant states of the system under test, code paths and interleavings that we can hardly approach the coverage of 1 in 10<sup>12</sup>.</li>\n<li>It's being claimed that unit tests serve as a safety net for refactoring but that is based upon an unverified and doubtful assumption (see below)</li>\n<li>According to some studies, the efficiency of unit testing is much lower than that of other QA approaches (<a href=\"http://namcookanalytics.com/wp-content/uploads/2013/08/Software-Defect-Origins-and-Removal-Methods2013.pdf\">Casper Jones 2013</a>)</li>\n<li>Thinking about design for the sake of design yields better results than design thinking forced by a test-first approach (as discussed previously)</li>\n</ul><br><br><h4>Limited resources, risk assessment, and testing of unused cases</h4><br><br>One of the main points of the essays is that our resources are limited and it is thus crucial to focus our quality assurance efforts where it pays off most. Coplien argues that unit testing is quite wasteful because we are very likely to test cases that never occur in practice. One of the reasons is that we want to test the unit - f.ex. a class - in its entirety while in the system it is used only in a particular way. It is typically impossible to link such a small unit to the business value of the application and thus to guide us to test cases that actually have business value. Due to polymorphism etc. there is no way, he argues, a static analysis of an object-oriented code could tell you whether a particular method is invoked and in what context/sequence. Discovering and fixing bugs that are in reality never triggered is waste of our limited resources.<br><br>For example a <a href=\"https://en.wikipedia.org/wiki/Associative_array\">Map (Dictionary)</a> provides a lot of functionality but any application uses typically only a small portion of it. Thus:<br><br><blockquote>\n  One can make ideological arguments for testing the unit, but the fact is that the map is much larger as a unit, tested as a unit, than it is as an element of the system. You can usually reduce your test mass with no loss of quality by testing the system at the use case level instead of testing the unit at the programming interface level.\n</blockquote><br><br>Unit tests can also lead to <a href=\"http://david.heinemeierhansson.com/2014/test-induced-design-damage.html\">\"test-induced design damage\"</a> - degradation of code and quality in the interest of making testing more convenient (introduction of interfaces for mocking, layers of indirection etc.).<br><br>Moreover, the fact that unit tests are passing does not imply that the code does what the business needs, contrary to acceptance tests.<br><br>Testing - at any level - should be driven by risk assessment and cost-benefit analysis. Coplien stresses that risk assessment/management requires at least rudimentary knowledge of statistics and information theory.<br><br><h4>The myth of code coverage</h4><br><br>A high code coverage makes us confident in the quality of our code. But the assumption that testing reproduces the majority of states and paths that the code will experience in deployment is rather dodgy. Even 100% line coverage is a big lie. A single line can be invoked in many different cases and testing just one of them provides little information. Moreover, in concurrent systems the result might depend on the interleaving of concurrently executing threads, and there are many. It may also - directly or indirectly - depend on the state of the whole system (an extreme example - a deadlock that is triggered only if the system is short of memory).<br><br><blockquote>\n  I define 100% coverage as having examined all possible combinations of all possible paths through all methods of a class, having reproduced every possible configuration of data bits accessible to those methods, at every machine language instruction along the paths of execution. Anything else is a heuristic about which absolutely no formal claim of correctness can be made.\n</blockquote><br><br><em>My thoughts: Focusing on the worst-case coverage might be too extreme, even though nothing else has a \"formal claim of correctness.\" Even though humans are terrible at foreseeing the future, we perhaps still have a chance to guess the most likely and frequent paths through the code and associated states since we know its business purpose, even though we will miss all the rare, hard-to-track-down defects. So I do not see this as an absolute argument against unit testing but it really makes the point that we must be humble and skeptical about what our tests can achieve.</em><br><br><h4>The myth of the refactoring and regression safety net</h4><br><br>Unit tests are often praised as a safety net against inadvertent changes introduced when refactoring or when introducing new functionality. (I certainly feel much safer when changing a codebase with a good test coverage (ehm, ehm); but maybe it is just a self-imposed illusion.) Coplien has a couple of counterarguments (in addition to the low-coverage one):<br><br><ul>\n<li>Given that the whole is greater than a sum of its parts, testing a part in isolation cannot really tell you that a change to it hasn't broken the system (a theoretical argument based on Weinberg’s Law of Composition)</li>\n<li>Tests as a safety net to catch inadvertent changes due to refactoring - \"[..] it pretends that we can have a high, but not perfect, degree of confidence that we can write tests that examine only that portion of a function’s behavior that that will remain constant across changes to the code.\"</li>\n<li>\"Changing code means re-writing the tests for it. If you change its logic, you need to reevaluate its function. [...] If a change to the code doesn’t require a change to the tests, your tests are too weak or incomplete.\"</li>\n</ul><br><br><h3>Tips for reducing the mass of unit tests</h3><br><br>If the cost of maintaining and running your unit tests is too high, you can follow Coplien's guidelines for eliminating the least valuable ones:<br><br><ol>\n<li>Remove tests that haven't failed in a year (informative value &lt; maintenance and running costs)</li>\n<li>Remove tests that do not test functionality (i.e. don't break when the code is modified)</li>\n<li>Remove tautological tests (f.ex. <code>.setY(5); assert x.getY() == 5</code>)</li>\n<li>Remove tests that cannot be tracked to business requirements and value</li>\n<li>Get rid of unit tests that duplicate what system tests do; if they're too expensive to run, create subunit integration tests.</li>\n</ol><br><br>(Notice that theoretically, and perhaps also practically speaking, a test that never fails has zero information value.)<br><br><h3>Open questions</h3><br><br>What is Coplien's definition of a \"unit test\"? Is it one that checks an individual method? Or, at the other end of the scale, a one that checks an object or a group of related objects but runs quickly, is independent of other tests, manages its own setup and test data, and generally does not access the file system, network, or a database?<br><br>He praises testing based on Monte Carlo techniques. What is it?<br><br>Does the <a href=\"http://en.wikipedia.org/wiki/System_testing\">system testing</a> he speaks about differ from <a href=\"http://en.wikipedia.org/wiki/Behavior-driven_development\">BDD</a>/Specification by Example way of automated acceptance testing?<br><br><h3>Coplien's own summary</h3><br><br><blockquote><article class=\"markdown-body\">\n<ul>\n    <li>Keep regression tests around for up to a year — but most of those will be system-level tests rather than unit tests.</li>\n    <li>Keep unit tests that test key algorithms for which there is a broad, formal, independent oracle of correctness, and for which there is ascribable business value.</li>\n    <li>Except for the preceding case, if X has business value and you can test X with either a system test or a unit test, use a system test — context is everything.</li>\n    <li>Design a test with more care than you design the code.</li>\n    <li>Turn most unit tests into assertions.</li>\n    <li>Throw away tests that haven’t failed in a year.</li>\n    <li>Testing can’t replace good development: a high test failure rate suggests you should shorten development intervals, perhaps radically, and make sure your architecture and design regimens have teeth</li>\n    <li>If you find that individual functions being tested are trivial, double-check the way you incentivize developers’ performance. Rewarding coverage or other meaningless metrics can lead to rapid architecture decay.</li>\n    <li>Be humble about what tests can achieve. Tests don’t improve quality: developers do.</li>\n    <li>[..] most bugs don’t happen <em>inside</em> the objects, but <em>between</em> the objects.</li>\n</ul>\n</article></blockquote><br><br><h3>Conclusion</h3><br><br>What am I going to change in my approach to software development? I want to embrace the <a href=\"http://en.wikipedia.org/wiki/Design_by_contract#Description\">design-by-contract</a> style runtime assertions. I want to promote and apply automated system/acceptance testing and explore ways to make these tests cheaper to write and maintain. I won't hesitate to step off the computer with a piece of paper to do some preliminary analysis and design. I want to experiment more with some of the alternative, more efficient QA approaches. And, based on real-world experiences, I will critically scrutinize the perceived value of unit testing as a development aid and regression/refactoring safety net and the actual cost of the tests themselves and as an obstacle to changing code. I will also scrutinize Coplien's claims such as the discrepancy between code tested and code used.<br><br>What about you, my dear reader? Find out for yourself what works for you in practice. Our resources are limited - use them on the most efficient QA approaches. Inverse the test pyramid - focus on system (and integration) tests. Prune unit tests regularly to keep their mass manageable. Think.<br><br><h3>Follow-Up</h3><br><br>There is a recording of <a href=\"https://www.youtube.com/watch?v=KtHQGs3zFAM\">Jim Coplien and Bob Martin debating TDD</a>. Mr. Coplien says he doesn't have an issue with <a href=\"http://butunclebob.com/ArticleS.UncleBob.TheThreeRulesOfTdd\">TDD as practiced by Uncle Bob</a>, his main problem is with people that forego architecture and expect it to somehow magically emerge from tests. He stresses that it is important to leverage domain knowledge when proposing an architecture. But he also agrees that architecture has to evolve and that one should not spend \"too much\" time on architecting. He also states that he prefers design by contract because it provides many of the same benefits as TDD (making one think about the code, outside view of the code) while it also has a much better coverage (since it applies to all input/output values, not just a few randomly selected ones) and it at least \"has a hope\" being traced to business requirements. Aside of that, his criticism of TDD and unit testing is based a lot on experiences with how people (mis)use it in practice. Side note: He also mentions that behavior-driven development is \"really cool.\"<br><br><h3>Related</h3><br><br>Slides from Coplien's keynote <a href=\"http://testingassembly.ttlry.mearra.com/sites/testingassembly.ttlry.mearra.com/files/JamesCoplien20140925FiSTBKeynote.pdf\">Beyond Agile Testing to Lean Development</a><br><br><a href=\"http://martinfowler.com/articles/is-tdd-dead/\">The \"Is TDD Dead?\" dialogue</a> - A series of conversations between Kent Beck, David Heinemeier Hansson, and Martin Fowler on the topic of Test-Driven Development (TDD) and its impact upon software design. <a href=\"https://www.facebook.com/notes/kent-beck/learning-about-tdd-the-purpose-of-istdddead/768162959883237\">Kent Beck's reasons for participating</a> are quite enlightening:<br><br><blockquote>\n  I'm puzzled by the limits of TDD--it works so well for algorithm-y, data-structure-y code. I love the feeling of confidence I get when I use TDD. I love the sense that I have a series of achievable steps in front of me--can't imagine the implementation? no problem, you can always write a test. I recognize that TDD loses value as tests take longer to run, as the number of possible faults per test failure increases, as tests become coupled to the implementation, and as tests lose fidelity with the production environment. How far out can TDD be pushed? Are there special cases where TDD works surprisingly well? Poorly? At what point is the cure worse than the disease? How can answers to any and all of these questions be communicated effectively?\n</blockquote><br><br>(If you are short of time, you might get an impression of the conversations in <a href=\"http://zombiecodekill.com/?s=TDD+Is\">these summaries</a>)<br><br>Kent Beck's <a href=\"https://www.facebook.com/notes/kent-beck/rip-tdd/750840194948847\">RIP TDD</a> lists some good reasons for doing TDD (and thus unit testing) (Aside of \"Documentation,\" none of them prevents you from using tests just as a development aid and deleting them afterwards, thus avoiding accumulating costs. It should also be noted that people evidently are different, to some TDD might indeed be a great focus and design aid.)<br><br>Martin Fowler's <a href=\"http://martinfowler.com/articles/testing-culture.html\">Goto Fail, Heartbleed, and Unit Testing Culture</a> (<a href=\"https://twitter.com/dfkaye/status/559794942303039488\">via @dfkaye</a>)<br><br>Brian Marick has written a great analysis of the value (and cost) of automated (high-level) testing in his  <a href=\"http://www.exampler.com/testing-com/writings/automate.pdf\">When Should a Test Be Automated?</a> Highly recommended! (See <a href=\"http://holyjak.tumblr.com/post/109568969799/when-should-a-test-be-automated\">my highlights</a>.)",
  "excerpt": ""
 },
 {
  "title": "Fix Shell Script Run via SSH Hanging (Jenkins)",
  "published": "2015-02-17 13:11:23",
  "postType": "post",
  "slug": "/2015/02/17/fix-shell-script-run-via-ssh-hanging-jenkins/",
  "status": "publish",
  "tags": [],
  "categories": [
   "Uncategorized"
  ],
  "content": "There is an important difference between running a script manually (<code>ssh machine; machine$ ./script.sh</code>) and running it via ssh (<code>ssh machine &lt; script.sh</code>): in the letter case the connection will not close when the script finishes but will stay open until stdout/stderr are closed or a timeout occurs. In Jenkins it will therefore seem as if the script hangs.<br><br>So if your shell scripts starts any background job, make sure to redirect all its output to somewhere:<br><br><pre><code>\nnohup some-background-task &amp;&gt; /dev/null   # No space between &amp; and &gt; !\n</code></pre><br><br>This has bitten me when trying to deploy an application from the Jenkins CI using SSH and a shell script.<br><br>References: http://www.snailbook.com/faq/background-jobs.auto.html",
  "excerpt": ""
 },
 {
  "title": "The Are No Silver Bullets: Which Error Handling Style to Pick For a Given Configuration of Constraints?",
  "published": "2015-02-18 10:24:37",
  "postType": "post",
  "slug": "/2015/02/18/which-error-handling-style-to-pick-for-a-given-configuration-of-constraints/",
  "status": "publish",
  "tags": [
   "design",
   "opinion"
  ],
  "categories": [
   "SW development"
  ],
  "content": "Kent Beck in his <a href=\"https://www.facebook.com/notes/kent-beck/patterns-enhance-craft-step-3-a-handful-of-solutions/911063088926556\">Patterns Enhance Craft Step 3: A Few Good Solutions</a> highlights an important fact about software development:<br><br><blockquote>We encounter repeating <span style=\"text-decoration:underline;\">configurations of forces/constraints</span> that have only a <span style=\"text-decoration:underline;\">handful of \"solution families\"</span> and the optimal solution(s) depend on the <span style=\"text-decoration:underline;\">relative weights</span> of these constraints.</blockquote><br><br>For example when deciding what error handling style we should choose when calling an unreliable rutine:<br><br><blockquote>Depending on whether readability, reliability, automated analysis, performance, or future maintenance are most important you could reasonably choose any one of:\n<ul>\n    <li>Exceptions</li>\n    <li>Return value plus errno</li>\n    <li>Exceptional value (e.g. Haskell's Maybe)</li>\n    <li>Success and failure callbacks</li>\n</ul>\n</blockquote><br><br>So there is no single perfect error handling style to rule them all.<br><br>Kent further explains that the forces shaping most design decisions are generated internal to the process of design, not by external constraints: whether we're building a barn or an airport, the list of forces influencing the roofing decision is the same - snow, wind, etc. - but their relative strengths may be different. Internal forces in SW development include use of the same bits of logic repeatedly, code made for/by people, etc.. F.ex. the forces influencing naming a variable do not depend on what SW we are building but on its purpose, lifetime, etc. We encounter some configurations of these constraints again and again and a catalogue of design patterns representing the \"solution families\" mentioned above can guide us towards the most suitable solution for given weights.<br><br><h3>Conclusion</h3><br><br>When designing a solution, it is helpful to think in terms of these forces and their relative strengths. There is no single superior solution (a.k.a. silver bullet) as different configurations of forces and their weights might be best suited by radically different solutions. Keeping this on our minds might prevent design discussions from dengenerating into an argument.",
  "excerpt": ""
 },
 {
  "title": "A Usable Node.js REPL for Emacs",
  "published": "2015-03-11 21:55:27",
  "postType": "post",
  "slug": "/2015/03/11/a-usable-node-repl-for-emacs/",
  "status": "publish",
  "tags": [
   "emacs",
   "nodejs",
   "productivity"
  ],
  "categories": [
   "Languages",
   "Tools"
  ],
  "content": "Being used to the excellent REPL in Clojure(Script), I was surprised to find out that Node.js REPL is somewhat weak and that its support in Emacs is not actively maintained. I anyway managed to get a usable REPL with these three components:<br><br><ol>\n    <li>The Emacs <a href=\"https://github.com/abicky/nodejs-repl.el\">nodejs-repl package</a> (nearly 2 years old)</li>\n    <li>J. David Smith's <a href=\"https://gist.github.com/emallson/0eae865bc99fc9639fac\">nodejs-repl-eval.el </a>to be able to send code to the REPL (binding <code>nodejs-repl-eval-dwim</code> to <code>C-x C-e</code> so that I can execute the current sexp/region)</li>\n    <li><a href=\"https://github.com/jakubholynet/dotfiles/blob/0d4070e0379fbb4d978435a8d508154f0fd4a979/.live-packs/jholy-pack/lib/nodejs-repl-eval.el\">My own extension of nodejs-repl-eval.el</a> that takes care of escaping JS constructs that the REPL interprets in a special way</li>\n</ol><br><br>Regarding #3: The problem with the <a href=\"https://nodejs.org/api/repl.html#repl_repl_features\">Node.js REPL</a> is that valid JS code does not always behave correctly in the REPL. This is because: 1) <code>_</code> is a special variable (the last result) while in code it is often used for the underscore/lodash library; 2) The<a href=\"http://stackoverflow.com/a/21741233/204205\"> REPL also interprets lines somewhat separately</a> and tries to execute <code>&lt;dot&gt;&lt;name&gt;</code> as a REPL command, breaking chained calls that start on a new line. My solution uses some RegExp magic to turn<br><br><pre><code>\r\nvar _ = require(&quot;lodash&quot;); // #1a conflicting use of _\r\n_.chain([1,2])             // #1b conflicting use of _\r\n   .first()                // #2 interpreted as non-existing REPL command '.first'\r\n   .value();\r\n</code></pre><br><br>into<br><br><pre><code>\r\nvar __ = require(&quot;lodash&quot;);  // #1a Notice the doubled _\r\n__.chain([1,2]).             // #1b Notice the doubled _\r\n   first().                  // #2 Notice the dot has moved to the previous line\r\n   value();\r\n</code></pre><br><br>when the code is being sent to the REPL",
  "excerpt": ""
 },
 {
  "title": "There will be failures – On systems that live through difficulties instead of turning them into a catastrophy",
  "published": "2015-03-17 14:42:04",
  "postType": "post",
  "slug": "/2015/03/17/there-will-be-failures-on-systems-that-live-through-difficulties-instead-of-turning-them-into-a-catastrophy/",
  "status": "publish",
  "tags": [
   "failure",
   "ops",
   "patterns"
  ],
  "categories": [
   "SW development"
  ],
  "content": "Our systems always depend on other systems and services and thus may and will be subject to failures – network glitches, dropped connections, load spikes, deadlocks, slow or crashed subsystems. We will explore how to create robust systems that can sustain blows from its users, interconnecting networks, and supposedly allied systems yet carry on as well as possible, recovering quickly – instead of aggreviating these difficulties and turning them into an extended outage and potentially substiantial financial loss. In systems not designed for robustness, even a minor and transient failure tends to cause a chain reaction of failures, spreading destruction far and wide. Here you will learn how to avoid that with a few crucial yet simple stability patterns and the main antipatterns to be aware of. Based primarily on the book Release It! and Hystrix. (<em>Presented at Iterate winter conference 2015; re-posted from blog.iterate.no.</em>)<br><br><!--more--><br><br>Often we speak abut building the right thing, building it right. Today: Building it to survive.<br><br><h2>Motivation</h2><br><br>There is a special moment in a developer's life. The moment one afternoon when a sales campaign has started or the streaming of a major sports event kicks off - and you watch your servers light up like torches, one by one. CPU usage is low, network, memory, disk are OK, the database is perfectly healthy - yet no request are coming through. You are loosing credibility, customers, and perhaps hundreds of thousands of kronas - and still have no idea what is wrong. Hours later you finally find out that a firewall has silently dropped long-lived connections to the database, causing a rare error condition that the code handled badly, never releasing the connections - leading to threads blocked forever waiting for a connection.<br><br>The way we write software is very susceptible to cascading failures like this - a small spark leads to a total collapse of the system, even though the spark itself has soon died out.<br><br>Everything will fail. How to stop the sparks of these failures from spreading and setting ablaze the whole system? How to write software that survives and recovers?<br><br><h2>(Anti)patterns</h2><br><br>This is my selection of the 5 main patterns and 5 main antipatterns from the Stability section of Michael Nygard's <a href=\"https://pragprog.com/book/mnee/release-it\">Release It!</a>:<br><br><strong>TODO: Image</strong><br><br>The red boxes are the antipatterns that help to create and spread stability problems. The green elipses are patterns that help to contain and isolate the problems so that they do not spread.<br><br><h3>Antipatterns: How failures spread and multiply</h3><br><br><ol>\n    <li><strong>Cascading Failures</strong>\n<ul>\n    <li>= problems in a down-stream system bring down an upstream system</li>\n    <li>Talk core: contain a failure to prevent from spreading, survive it, recover ASAP</li>\n    <li>Ex.: webshop &amp; in-stock? status -&gt; inventory WS -&gt; inventory IS -&gt; DB with lock on a popular item =&gt; failure propagation</li>\n    <li>A system is like a Norwegian wooden town; firewalls have to be intentionally included to prevent fire from spreading and beurning it all</li>\n</ul>\n</li>\n    <li><strong>Integration Points</strong>\n<ul>\n    <li>= cascading failures spread through them &lt;&gt; firewalls; I.P. = whenever we call something: DB, WS, cache, ...; may &amp; will fail</li>\n    <li>Error responses (2nd best thing after success)</li>\n    <li>Slow responses (due to TCP ACK retry, ...)</li>\n    <li>Or the call never returns</li>\n    <li>Unexpected data: too much (unbounded result set), rubbish; ex.: a DB query that normally returns 10 rows suddenly returns 10M =&gt; eternity to transform &amp; crash due to running out of memory</li>\n    <li>=&gt; be paranoid</li>\n</ul>\n</li>\n    <li><strong>Blocked Threads</strong>\n<ul>\n    <li>= the tool of cascading failures; found close to I.P.; due to resource (f.ex. DB connection) pools / synchronization</li>\n    <li>Low-level synchronization =&gt; you got it wrong, deadlocks / inconsistency =&gt; use higher-level constructs, libraries, <a href=\"http://clojure.org/concurrent_programming\">languages</a></li>\n</ul>\n</li>\n    <li><strong>Chain Reactions</strong>\n<ul>\n    <li>= same instances behind a load balancer with the same issue manifested under high load (a leak / timing issue)</li>\n    <li>When one fails, load increases and the others are the more likely to fail</li>\n    <li>=&gt; realistic stress testing, longevity testing</li>\n</ul>\n</li>\n    <li><strong>Slow Responses</strong>\n<ul>\n    <li>Slow is worse than a failure - consumes resources in caller &amp; callee</li>\n    <li>One slow call not a problem but many concurrent ones yes</li>\n    <li>No reason to wait longer than user wait time / SLA</li>\n</ul>\n</li>\n</ol><br><br><h3>Patterns: The protective firewalls</h3><br><br><ol>\n    <li><strong>Timeouts</strong>\n<ul>\n    <li>Timeout is your best friend; always apply when calling something</li>\n    <li>(Often \"infinity\" by default; different timeouts might need to be set, e.x. JDBC: connection, query, ...)</li>\n    <li>Consider retry - but delayed, with an increasing interval</li>\n    <li>Protects from Blocked Threads, Slow Responses</li>\n</ul>\n</li>\n    <li><strong>Circuit Breaker</strong>\n<ul>\n    <li>= similar to a fuse; wraps an Integration Point, monitors failures and timeouts and if too many in a period then it concludes the system is down and will start an error immediatelly to future invocations without calling it; but it will let a request through once upon while to check whether the system has not recovered</li>\n    <li>Prevents resource exhaustion due to a troubled dependency</li>\n    <li>Use to protect yourself from a cascading failure</li>\n    <li>Use to protect the callee by cutting off load when in troubles</li>\n    <li>Consider a fallback solution</li>\n    <li>This is the main protection against Cascading Failures, the main firewall around an I.P.</li>\n</ul>\n</li>\n    <li><strong>Bulkheads</strong>\n<ul>\n    <li>= watertight compartments in a ship that save it from sinking when there is a hole</li>\n    <li>= contain a failure through dedicated, separate resources =&gt; important, often applied in IT</li>\n    <li>At different granularity: bind a thread to 1 CPU; use a limited thread pool (x exhausting all threads); HW redundancy; cluster sub-group</li>\n    <li>Ex.: Airline IS, prevent problems in flight status check from breaking traveller check-in by giving dedicated app servers to each of them</li>\n    <li>Ex.: separate request threads for admin requests, root user quota on Linux</li>\n    <li>Contain a Chain Reaction, preserve partial functionality</li>\n</ul>\n</li>\n    <li><strong>Steady State</strong>\n<ul>\n    <li>= if a process accummulates a resource, another one must <em>automatically</em> recycle it</li>\n    <li>Ex.: log files, cache, data in a DB</li>\n    <li>Violation =&gt; Chain Reaction</li>\n</ul>\n</li>\n    <li><strong>Fail Fast</strong>\n<ul>\n    <li>= if you know you're going to fail, fail at once to save resources and protect self/the callee from an overload</li>\n    <li>Ex.: Elementary user input validation prior to invoking an expensive call, checking dependency availability (are all C.B. open?)</li>\n    <li>Ex.: Do not let more than max users from web to app servers (x latency &amp; nobody served)</li>\n</ul>\n</li>\n</ol><br><br><h2>Ref: Hystrix</h2><br><br>Hystrix is a Java framework by Netflix for resilient distributed communication; uses thread pools (= Bulkheads) with Timeouts and Circuit Breakers (and optional caching and fallback data) + monitoring and instant reconfigurability. It is useful to read about what it does to get a more practicle idea of how to apply these patterns.<br><br><h2>Bonus topics</h2><br><br><ul>\n    <li>Applying the stability patterns is great but not really enough; you want to add good monitoring and notifications =&gt; discover/locate problems =&gt; help to recover (if it cannot recover automatically)</li>\n    <li>Graceful degradation: write your system so that it can function without non-core functionality (such as the in stock check mentio)ned above)</li>\n    <li>Test Harness (another pattern from Release It!) - a fake service that can simulate all kinds of problems (accepting connectio)ns but never responding, returning rubbish data, ...); implementing the patterns isn't really finished until you test the result</li>\n    <li>Release It! has more (anti)patterns and covers other areas than stability</li>\n</ul><br><br><h2>Conclusion</h2><br><br><ul>\n    <li>Be paranoid about both your callers and callees</li>\n    <li>Apply timeouts, circuit breaker, steady state, fail fast, ...</li>\n    <li>Learn what Hystrix does</li>\n    <li>At least browse through Release It!</li>\n</ul>",
  "excerpt": ""
 },
 {
  "title": "Git pre-commit hook that fails if \"it.only\" used (Jest/Jasmine)",
  "published": "2015-03-27 20:03:43",
  "postType": "post",
  "slug": "/2015/03/27/git-pre-commit-hook-that-fails-if-it-only-used-jestjasmine/",
  "status": "publish",
  "tags": [
   "Git",
   "JavaScript"
  ],
  "categories": [
   "Testing"
  ],
  "content": "One of the annoying things with <a href=\"https://github.com/facebook/jest/\">Jest</a> is that while it enables you to run only a single test by using <code>it.only</code>, it does not report this in any noticeable way. Thus you can end up in the same situation as we did, not running many tests without knowing it. (Oh yeah, if we only did review the code properly ...).<br><br>This git pre-commit hook will fail when you introduce <code>it.only</code> into the code:<br><br>https://gist.github.com/holyjak/53e9b514112e9dc1b2f5",
  "excerpt": ""
 },
 {
  "title": "AWS CloudWatch Alarms Too Noisy Due To Ignoring Missing Data in Averages",
  "published": "2015-03-31 11:24:34",
  "postType": "post",
  "slug": "/2015/03/31/aws-cloudwatch-alarms-too-noisy-due-to-undesirable-handling-of-missing-data/",
  "status": "publish",
  "tags": [
   "aws",
   "monitoring",
   "ops"
  ],
  "categories": [
   "General",
   "Tools"
  ],
  "content": "I want to know when our app starts getting slower so I sat up an alarm on the Latency metric of our ELB. According to the AWS Console, \"<em>This alarm will trigger when the blue line [average latency over the period of 15 min] goes above the red line [2 sec] for a duration of 45 minutes.</em>\" (I.e. it triggers if Latency &gt; 2 for 3 consecutive period(s).) This is exactly what I need - except that it is a lie.<br><br>This night I got 8 alarm/ok notifications even though the average latency has never been over 2 sec for 45 minutes. The problem is that <strong>CloudWatch ignores null/missing data</strong>. So if you have a slow request at 3am and no other request comes until 4am, it will look at [slow, null, null, null] and trigger the alarm.<br><br>So I want to configure it to treat null as 0 and preferably to ignore latency if it only affected a single user. But there is no way to do this in CloudWatch.<br><br><strong>Solution</strong>: I will likely need to run my own job that will read the metrics and produce a normalized, reasonable metric - replacing null / missing data with 0 and weight the average latency by the number of users in the period.",
  "excerpt": ""
 },
 {
  "title": "Backup WD MyCloud to S3/Glacier with duplicity (build instructions included)",
  "published": "2015-04-03 13:03:19",
  "postType": "post",
  "slug": "/2015/04/03/backup-wd-mycloud-to-s3glacier-with-duplicity-build-instructions-included/",
  "status": "publish",
  "tags": [
   "backup"
  ],
  "categories": [
   "Tools"
  ],
  "content": "How to back up your precious files stored on the WD My Cloud NAS into S3 with the slow but low-cost storage class \"Glacier\".<br><br>How does the backup work: duplicity does its job and uploads files to S3. The large data archives are recognized by S3 Lifecycle rules that we set up based on their prefix and moved to the Glacier storage class soon after upload. (It takes hours to restore something from Glacier but its cost is orders of magnitude lower than that of S3 itself). We leave metadata files in S3 so that duplicity can read them.<br><br>90% of this is based on <a href=\"http://www.x2q.net/2013/02/24/howto-backup-wd-mybook-live-to-amazon-s3-and-glacier/\">http://www.x2q.net/2013/02/24/howto-backup-wd-mybook-live-to-amazon-s3-and-glacier/</a> and the WD build guide (<a href=\"http://community.wd.com/t5/WD-My-Cloud/GUIDE-Building-packages-for-the-new-firmware-someone-tried-it/m-p/770653#M18650\">http://community.wd.com/t5/WD-My-Cloud/GUIDE-Building-packages-for-the-new-firmware-someone-tried-it/m-p/770653#M18650</a> and the update at <a href=\"http://community.wd.com/t5/WD-My-Cloud/GUIDE-Building-packages-for-the-new-firmware-someone-tried-it/m-p/841385#M27799\">http://community.wd.com/t5/WD-My-Cloud/GUIDE-Building-packages-for-the-new-firmware-someone-tried-it/m-p/841385#M27799</a>). Kudos to the authors!<br><br>You will need to:<br><br><ol class=\"task-list\">\n    <li>Build duplicity and its dependencies (since WD Debian v04 switched to page size of 64kB, all pre-built binaries are unusable)</li>\n    <li>Configure S3 to move the data files to Glacier after 0 days</li>\n    <li>Create your backup script - see <code>backup-pictures-to-s3.sh</code></li>\n    <li>Schedule to run incremental backups regularly via Cron</li>\n    <li>Preferably test restore manually</li>\n</ol><br><br><!--more--><br><br><h2>0. Download sources for this \"miniproject\"</h2><br><br>Download the files for this from the GitHub repository <a href=\"https://github.com/jakubholynet/blog/tree/master/miniprojects/mycloud-duplicity-backup\">miniprojects/mycloud-duplicity-backup</a> via Git or <a href=\"https://github.com/jakubholynet/blog/archive/master.zip\">as .zip</a>.<br><br><h2>1. Build duplicity and its dependencies</h2><br><br>See <a href=\"https://github.com/jakubholynet/blog/blob/master/miniprojects/mycloud-duplicity-backup/mycloud-build-vm/README.md\"><code>./mycloud-build-vm/README.md</code></a> This is based on duplicity 0.6.24 (available in the Jessie release of Debian); the older one in Wheezy does not support the crucial option <code>--file-prefix-archive</code>.<br><br><h2><a id=\"user-content-2-configure-s3\" class=\"anchor\" href=\"https://github.com/jakubholynet/blog/tree/master/miniprojects/mycloud-duplicity-backup#2-configure-s3\"></a>2. Configure S3</h2><br><br>Create a backup bucket - either call it <code>my-backup-bucket</code> or update the backup script with your bucket name. (Duplicity can sometimes create it but especially if you want it in an European zone, it might be easier to create it manually).<br><br>Set rules to move the large data files to Glacier (they will remain visible in the bucket but their Storage Class will become Glacier soon after upload; they will not be visible directly in Glacier). Given the example backup script and the two prefixes it uses, you want to configure add Lifecycle rules for both:<br><br><ul class=\"task-list\">\n    <li>Rule Name: Archive to Glacier</li>\n    <li>Apply the Rule to: A prefix - either bob-data- or shared_pictures-data-</li>\n    <li>Action on Objects: Archive Only</li>\n    <li>Archive to the Glacier Storage Clas 0 days after the object's creation date.</li>\n</ul><br><br>Tip: Create a dedicated user for backups via AWS IAM, having access only to the backup bucket; this is the Policy you would want to create (modify the bucket name as appropriate):<br><br><pre><code>{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Effect\": \"Allow\",\n      \"Action\": \"s3:*\",\n      \"Resource\": [\"arn:aws:s3:::my-backup-bucket\", \"arn:aws:s3:::my-backup-bucket/*\"]\n    }\n  ]\n}\n</code></pre><br><br><h2><a id=\"user-content-3-create-your-backup-script\" class=\"anchor\" href=\"https://github.com/jakubholynet/blog/tree/master/miniprojects/mycloud-duplicity-backup#3-create-your-backup-script\"></a>3. Create your backup script</h2><br><br>Modify the attached <a href=\"https://github.com/jakubholynet/blog/blob/master/miniprojects/mycloud-duplicity-backup/backup-pictures-to-s3.sh\"><code>backup-pictures-to-s3.sh</code></a>:<br><br><ul class=\"task-list\">\n    <li>Set your AWS ID and secret</li>\n    <li>Modify the supported <code>SRC_ARG</code>, <code>SOURCE</code>, and <code>PREFIX</code> values</li>\n</ul><br><br>Notice that the script sets a prefix for all the files (data archive, manifest, ...) to distinguish backups of different directories and also adds another prefix (<code>data-</code>) to the archive files so that we can move just these to Glacier.<br><br><h2><a id=\"user-content-4-schedule-to-run-incremental-backups-regularly-via-cron\" class=\"anchor\" href=\"https://github.com/jakubholynet/blog/tree/master/miniprojects/mycloud-duplicity-backup#4-schedule-to-run-incremental-backups-regularly-via-cron\"></a>4. Schedule to run incremental backups regularly via Cron</h2><br><br>For example to backup pictures every Tuesday and phone pictures every Wednesday at 20:00, add this to crontab:<br><br><pre><code>0 20 * * 2 /root/backup-pictures-to-s3.sh pictures\n0 20 * * 3 /root/backup-pictures-to-s3.sh phone\n</code></pre><br><br><h2><a id=\"user-content-5-preferably-test-restore-manually\" class=\"anchor\" href=\"https://github.com/jakubholynet/blog/tree/master/miniprojects/mycloud-duplicity-backup#5-preferably-test-restore-manually\"></a>5. Preferably test restore manually</h2><br><br>See <a href=\"https://github.com/jakubholynet/blog/blob/master/miniprojects/mycloud-duplicity-backup/restore.example\"><code>./restore.example</code></a>. You likely also want to try these: <code>duplicity list-current-files [options] target_url</code>, <code>duplicity verify [options] source_url target_dir</code>, <code>duplicity collection-status [options] target_url</code> to verify the backup is alright.<br><br><h2><a id=\"user-content-caveats\" class=\"anchor\" href=\"https://github.com/jakubholynet/blog/tree/master/miniprojects/mycloud-duplicity-backup#caveats\"></a>Caveats</h2><br><br>You likely want to run a full backup some time and clean up old (incremental) backups. This has to be done manually.<br><br><h2>Binaries</h2><br><br>I prefer to build my binaries myself but if you prefer, you may <a href=\"https://drive.google.com/file/d/0BzTnTPlEXKaFNThwbXpaLWYzNlk/view?usp=sharing\">download by duplicity and dependencies .debs here</a>; I will eventually remove them but likely not before 8/2015.",
  "excerpt": ""
 },
 {
  "title": "iTerm coprocess reporting result of (Mocha) tests run via nodemon",
  "published": "2015-04-30 06:33:57",
  "postType": "post",
  "slug": "/2015/04/30/iterm-coprocess-reporting-result-of-mocha-tests-run-via-nodemon/",
  "status": "publish",
  "tags": [
   "nodejs",
   "productivity"
  ],
  "categories": [
   "Tools"
  ],
  "content": "See <a href=\"https://gist.github.com/holyjak/e04ad994c7ce664076ef\">this gist</a>:<br><br><!--more--><br><br>https://gist.github.com/holyjak/e04ad994c7ce664076ef",
  "excerpt": ""
 },
 {
  "title": "My Highlights from Continuous Delivery and DevOps Conference 2015",
  "published": "2015-04-30 07:33:57",
  "postType": "post",
  "slug": "/2015/04/30/my-highlights-from-continuous-delivery-and-devops-conference-2015/",
  "status": "publish",
  "tags": [
   "continuous_deployment",
   "DevOps"
  ],
  "categories": [
   "General"
  ],
  "content": "The first <a href=\"http://www.code-conf.com/osl15/\" target=\"_blank\">Continuous Delivery and DevOps Conference</a> in Oslo is over. It was nice to see so many people interested in the topic. I would have preferred more practical talks of the \"how we did it\" type over the \"why\" type but it was OK, though next year I would prefer flatMap. Here are my highlights:<br><br><ul>\n    <li>Atmel is using a physical robot to plug and connect a particular configuration of circuit boards to test; your automated testing challenges cannot be greater than theirs!</li>\n    <li>Continuous Delivery <a href=\"https://twitter.com/Juergen_Muench/status/593323622934171648\">decreases the risk</a> of outage and time-to-recovery while enabling faster innovation, correlates with higher profits; <a href=\"https://twitter.com/sebrose/status/593419976784097282\">No efficiency improvement will outperform cycle time reduction</a></li>\n    <li><a href=\"https://twitter.com/HolyJak/status/593402032553328642\">Estimation pathologies</a>; focus on value rather than costs</li>\n    <li>Stop talking about requirements, they are fake; they're just beliefs about what may add value to customers. Use hypothesis instead!</li>\n    <li>Cisco: Most of the tools increasing productivity (and some innovation) were produced by engineers in their \"spare\" time; <a href=\"http://www.amazon.com/Slack-Getting-Burnout-Busywork-Efficiency/dp/0932633617/\">slack time</a> is thus crucial</li>\n    <li>How does Cisco grow professionalism : optimise for the 10% best, not the 10% weakest developers; slack time; make everything visible; encourage code reviews but avoid making them mandatory; <a href=\"https://twitter.com/HolyJak/status/593422453575163904\">see the slide</a></li>\n    <li>CALMS: Culture, Automation, Lean, Measurement, Sharing. The pillars of devOps</li>\n    <li>Cisco invested a lot in crafting their build system, tailored test frameworks, and emulators to be able to get quick and quality feedback - because it pays off\n<ul>\n    <li>“Make you own build system” says @olvemaudal at @CoDeOSL. IME this is inevitable for non-trivial projects, and a good investment.</li>\n</ul>\n</li>\n    <li><a href=\"https://github.com/finn-no/unleash/blob/master/README.md\" target=\"_blank\">Unleash: Feature Toggles</a> server and Java/Node client by FINN.no</li>\n    <li>\"They asked for a report while they actually need just a list of data, the result of a simple SQL query; have we listened to them, we would have wasted hours creating a report in the report framework with logos and all the crap.\"</li>\n</ul><br><br>Slides:<br><br><ul>\n    <li><a href=\"http://www.slideshare.net/steinim/devops-or-die\">DevOps or Die!</a></li>\n</ul>",
  "excerpt": ""
 },
 {
  "title": "Hack: Quickly Verify That All Your Mocha/Chai Tests Have Valid Assertions",
  "published": "2015-05-06 14:05:36",
  "postType": "post",
  "slug": "/2015/05/06/hack-quickly-verify-that-all-your-mochachai-tests-have-valid-assertions/",
  "status": "publish",
  "tags": [
   "JavaScript"
  ],
  "categories": [
   "Testing"
  ],
  "content": "<a href=\"http://chaijs.com/\">Chai</a> is a popular Node/browser assertion library. However - as everything - it has its flaws. <a href=\"https://github.com/moll/js-must#asserting-on-property-access\">An important flaw is that it performs checks on property access</a> - and if you e.g. misspell the name of an assertion, it will be just ignored (for there is no way for Chai to know that you tried to access a non-existent property). This may be <a href=\"https://github.com/chaijs/chai/issues/407\">fixed in the future with ES6 proxies</a> but so far you risk having tests that actually do not test anything. Though you should of course always develop your tests so that they initially fail and thus you know they actually assert something :-).<br><br>Anyway, there is a neat quick way to verify that all your tests have at least one valid assertion - simply replace <code>expect</code> with <code>expect.not</code>.\n<!--more--><br><br>If you use <a href=\"http://mochajs.org/\">Mocha</a> and its <code>mocha.opts</code> to have a single file (<code>common.js</code> in my case) that imports Chai and exposes it to all tests then you have a single place do do this:<br><br><pre><code>\r\n// file: test/mocha.opts\r\n--require test/common\r\n--recursive\r\n// file: test/common.js\r\n// Before: global.expect = require(&quot;chai&quot;).expect;\r\nvar expect = require(&quot;chai&quot;).expect;\r\nglobal.expect = function(target) {\r\n    return expect(target).not;\r\n}\r\n</code></pre><br><br>When this change is in place, you expect all your tests to fail. If any one is passing then it has no valid assertions.<br><br>Enjoy.",
  "excerpt": ""
 },
 {
  "title": "All-in-one Docker with Grafana, InfluxDB, and cloudwatch-to-graphite for AWS/Beanstalk monitoring",
  "published": "2015-05-07 06:29:59",
  "postType": "post",
  "slug": "/2015/05/07/all-in-one-docker-with-grafana-influxdb-and-cloudwatch-to-graphite-for-awsbeanstalk-monitoring/",
  "status": "publish",
  "tags": [
   "cloud",
   "DevOps",
   "Docker",
   "ops"
  ],
  "categories": [
   "General"
  ],
  "content": "I have derived the Docker container <a href=\"https://github.com/jakubholynet/docker-grafana-influxdb-cloudwatch\">docker-grafana-influxdb-cloudwatch</a> that bundles <a href=\"http://grafana.org/\">Grafana dashboards</a>, <a href=\"http://influxdb.com/\">InfluxDB</a> for metrics storage, and runs <a href=\"https://github.com/crccheck/cloudwatch-to-graphite\">cloudwatch-to-graphite</a> as a cron job to fetch selected metrics from AWS CloudWatch and feed them into the InfluxDB using its Graphite input plugin. It is configured so that you can run it in AWS Elastic Beanstalk (the main problem being that only a single port can be exposed - I therefore use Nginx to expose the InfluxDB API needed by Grafana at :80/db/).<br><br><!--more--><br><br><h2>Highlights</h2><br><br><ul>\n    <li>It's derived from <a href=\"https://github.com/kamon-io/docker-grafana-influxdb\">kamon-io/docker-grafana-influxdb</a> but based on <a href=\"http://phusion.github.io/baseimage-docker/\">phusion/baseimage</a> rather than raw Ubuntu as this supports cron and presumably solves some deficiencies wrt. Docker</li>\n    <li>InfluxDB API is exposed also at port 80 so that it can be easily run in Elastic BeanStalk</li>\n    <li>It enables the Graphite InfluxDB plugin</li>\n    <li>It runs cloudwatch-to-graphite's leadbutt to fetch metrics from CloudWatch</li>\n    <li>Grafana configuration fixed not to hardcode InfluxDB as locahost</li>\n</ul><br><br><h2>Why?</h2><br><br>I've created this to be able to run a monitoring dashboard on Elastic Beanstalk to get overview of our AWS infrastructure.<br><br><ul>\n    <li>CloudWatch only keeps metrics for the past 2 week, doesn't provide customizable dashboards, and cannot be exposed without the need for authentication</li>\n    <li>Beanstalk supports running docker containers - I just need to upload a .zip with the Dockerfile and files (it also supports multiple container setups but then I'd need to publish the images into a repository; the same holds for <a href=\"http://aws.amazon.com/ecs/details/\">Amazon EC2 Container Service</a></li>\n</ul><br><br><h2>Limitations</h2><br><br><ul>\n    <li>I haven't managed yet to make the InfluxDB storage persistent (preferably stored on an EBS volume) though I've tried (ideas welcome!); a re-deployment results in loss of data</li>\n    <li>You want to keep the number of metrics collected minimal as you have only 1M API calls free and it can get expensive for a large infrastructure</li>\n    <li>This is likely not suitable for high load and large volumes of data</li>\n</ul><br><br><h2>Get it!</h2><br><br><a href=\"https://github.com/jakubholynet/docker-grafana-influxdb-cloudwatch\">https://github.com/jakubholynet/docker-grafana-influxdb-cloudwatch</a>",
  "excerpt": ""
 },
 {
  "title": "OS X: Using scutils to discover whether/what a web proxy is in use",
  "published": "2015-05-07 11:10:54",
  "postType": "post",
  "slug": "/2015/05/07/os-x-using-scutils-to-discover-whetherwhat-a-web-proxy-is-in-use/",
  "status": "publish",
  "tags": [
   "osx",
   "productivity",
   "tool"
  ],
  "categories": [
   "General"
  ],
  "content": "When looking for ways to discover whether a proxy is being used by OS X, you will be typically pointed to<br><br><code>networksetup -getwebproxy </code><br><br>However that does not always work - for example when using \"Auto Proxy Discovery\" and/or \"Automatic Proxy Configuration\" with a proxy.pac file. <code>scutils --proxy</code> seems to detect all these cases (though it cannot give you the proxy when using auto config, I suppose):\n<!--more--><br><br><pre><code>\r\n# With &quot;Automatic Proxy Configuration&quot;\r\n$ scutil --proxy\r\n&lt;dictionary&gt; {\r\n  ExceptionsList : &lt;array&gt; {\r\n    0 : *.local\r\n    1 : 169.254/16\r\n  }\r\n  FTPPassive : 1\r\n  ProxyAutoConfigEnable : 1\r\n  ProxyAutoConfigURLString : http://proxconf.example.com/proxy.pac\r\n}<br><br># With &quot;Auto Proxy Discovery&quot;\r\n$ scutil --proxy\r\n&lt;dictionary&gt; {\r\n  ExceptionsList : &lt;array&gt; {\r\n    0 : *.local\r\n    1 : 169.254/16\r\n  }\r\n  FTPPassive : 1\r\n  ProxyAutoConfigEnable : 1\r\n  ProxyAutoConfigURLString : http://112.43.172.105/proxy.pac\r\n  ProxyAutoDiscoveryEnable : 1\r\n}<br><br># With manual HTTP proxy configuration\r\n$ scutil --proxy\r\n&lt;dictionary&gt; {\r\n  ExceptionsList : &lt;array&gt; {\r\n    0 : *.local\r\n    1 : 169.254/16\r\n  }\r\n  FTPPassive : 1\r\n  HTTPEnable : 1\r\n  HTTPPort : 8888\r\n  HTTPProxy : http://example.com\r\n}<br><br># No proxy\r\n$ scutil --proxy\r\n&lt;dictionary&gt; {\r\n  ExceptionsList : &lt;array&gt; {\r\n    0 : *.local\r\n    1 : 169.254/16\r\n  }\r\n  FTPPassive : 1\r\n}\r\n</code></pre><br><br>See Alex Argo's <a href=\"https://gist.github.com/alexargo/4657760\">proxysetup.sh Gist for proxy detection</a> and proxy env variable configuration.",
  "excerpt": ""
 },
 {
  "title": "Mounting an EBS volume to Docker on AWS Elastic Beanstal",
  "published": "2015-06-02 11:51:51",
  "postType": "post",
  "slug": "/2015/06/02/mounting-an-ebs-volume-to-docker-on-aws-elastic-beanstalk/",
  "status": "publish",
  "tags": [
   "aws",
   "cloud",
   "Docker",
   "ops"
  ],
  "categories": [
   "General"
  ],
  "content": "Mounting an EBS volume to a Docker instance running on Amazon Elastic Beanstalk (EB) is surprisingly tricky. The good news is that it is possible.<br><br>I will describe how to automatically create and mount a new EBS volume (optionally based on a snapshot). If you would prefer to mount a specific, existing EBS volume, you should check out <a href=\"https://github.com/leg100/docker-ebs-attach\">leg100's docker-ebs-attach</a> (using AWS API to mount the volume) that you can use either in a multi-container setup or just include the relevant parts in your own Dockerfile.<br><br>The problem with EBS volumes is that, if I am correct, a volume can only be mounted to a single EC2 instance - and thus doesn't play well with EB's autoscaling. That is why EB supports only creating and mounting a fresh volume for each instance.<br><br><!--more--><br><br>Why would you want to use an auto-created EBS volume? You can already use a docker VOLUME to mount a directory on the host system's ephemeral storage to make data persistent across docker restarts/redeploys. The only advantage of EBS is that it survives restarts of the EC2 instance but that is something that, I suppose, happens rarely. I suspect that in most cases EB actually creates a new EC2 instance and then destroys the old one. One possible benefit of an EBS volume is that you can take a snapshot of it and use that to launch future instances. I'm now inclined to believe that a better solution in most cases is to set up automatic backup to and restore from S3, f.ex. using <a href=\"http://duplicity.nongnu.org/\">duplicity</a> with its S3 backend (<a href=\"/2015/04/03/backup-wd-mycloud-to-s3glacier-with-duplicity-build-instructions-included/\">as I do for my NAS</a>).<br><br>Anyway, here is how I got EBS volume mounting working. There are 4 parts to the solution:<br><br><ol>\n    <li>Configure EB to create an EBS mount for your instances</li>\n    <li>Add custom EB commands to format and mount the volume upon first use</li>\n    <li>Restart the Docker daemon after the volume is mounted so that it will see it (<a href=\"https://forums.aws.amazon.com/thread.jspa?messageID=625243\">see this discussion</a>)</li>\n    <li>Configure Docker to mount the (mounted) volume inside the container</li>\n</ol><br><br>1-3.: .ebextensions/01-ebs.config:<br><br><pre><code>\r\n# .ebextensions/01-ebs.config\r\ncommands:\r\n  01format-volume:\r\n    command: mkfs -t ext3 /dev/sdh\r\n    test: file -sL /dev/sdh | grep -v 'ext3 filesystem'\r\n    # ^ prints '/dev/sdh: data' if not formatted\r\n  02attach-volume:\r\n    ### Note: The volume may be renamed by the Kernel, e.g. sdh -&gt; xvdh but\r\n    #       /dev/ will then contain a symlink from the old to the new name\r\n    command: |\r\n      mkdir /media/ebs_volume\r\n      mount /dev/sdh /media/ebs_volume\r\n      service docker restart # We must restart Docker daemon or it wont' see the new mount\r\n    test: sh -c &quot;! grep -qs '/media/ebs_volume' /proc/mounts&quot;\r\noption_settings:\r\n   # Tell EB to create a 100GB volume and mount it to /dev/sdh\r\n   - namespace: aws:autoscaling:launchconfiguration\r\n     option_name: BlockDeviceMappings\r\n     value: /dev/sdh=:100\r\n</code></pre><br><br>4.: Dockerrun.aws.json and Dockerfile:<br><br><code>Dockerrun.aws.json</code>: mount the host's <code>/media/ebs_volume</code> as <code>/var/easydeploy/share</code> inside the container:\n<pre><code>\r\n{\r\n  &quot;AWSEBDockerrunVersion&quot;: &quot;1&quot;,\r\n  &quot;Volumes&quot;: [\r\n    {\r\n      &quot;HostDirectory&quot;: &quot;/media/ebs_volume&quot;,\r\n      &quot;ContainerDirectory&quot;: &quot;/var/easydeploy/share&quot;\r\n    }\r\n  ]\r\n}\r\n</code></pre><br><br><code>Dockerfile</code>: Tell Docker to use a directory on the host system as <code>/var/easydeploy/share</code> - either a randomly generated one or the one given via the <code>-m</code> mount option to <code>docker run</code>:\n<pre><code>\r\n...\r\nVOLUME [&quot;/var/easydeploy/share&quot;]\r\n...\r\n</code></pre>",
  "excerpt": ""
 },
 {
  "title": "AWS API: Proper syntax for filtering by tag name and value (e.g. describeInstances)",
  "published": "2015-06-11 12:48:22",
  "postType": "post",
  "slug": "/2015/06/11/aws-api-proper-syntax-for-filtering-by-tag-e-g-describeinstances/",
  "status": "publish",
  "tags": [
   "aws",
   "ops"
  ],
  "categories": [
   "[Dev]Ops"
  ],
  "content": "It took me quite a while to figure out the right syntax for filtering instances by tag name and value in the <a href=\"http://docs.aws.amazon.com/AWSJavaScriptSDK/latest/AWS/EC2.html#describeInstances-property\">AWS EC2 API's describeInstances</a>.<br><br>The documentation is not exactly crystal-clear to me:<br><br><blockquote>\n<ul>\n    <li><code>tag</code>:<i>key</i>=<i>value</i> - The key/value combination of a tag assigned to the resource, where <code>tag</code>:<i>key</i> is the tag's key.</li>\n</ul>\n</blockquote><br><br>Anyway, here is the proper syntax, provided we are interested in the tag <em>elasticbeanstalk:environment-name</em>:<br><br><pre><code>\r\n    var params = {\r\n        Filters: [\r\n            {\r\n                Name: 'tag:elasticbeanstalk:environment-name',\r\n                Values: ['mySuperApp']\r\n            }\r\n        ]\r\n    };\r\n    ec2.describeInstances(params);\r\n</code></pre><br><br>So the name of the tag is embedded in the Name part and not, as I initially understood,\n<del datetime=\"2015-06-11T12:39:09+00:00\"><code>{ Name: 'tag', Values: ['elasticbeanstalk:environment-name=mySuperApp'] }</code></del><br><br>Credit: <a href=\"https://github.com/aws/aws-cli/issues/368#issuecomment-24805473\">garnaat</a>.",
  "excerpt": ""
 },
 {
  "title": "Why do companies fail at adopting Functional Programming?",
  "published": "2015-06-17 09:36:30",
  "postType": "post",
  "slug": "/2015/06/17/why-do-companies-fail-at-adopting-functional-programming/",
  "status": "publish",
  "tags": [],
  "categories": [
   "Uncategorized"
  ],
  "content": "According to the NDC Oslo talk <a href=\"http://ndcoslo.oktaset.com/t-31341\">Lean and Functional Programming</a> by <a href=\"https://twitter.com/bryan_hunter\">Bryan Hunter</a>, these are the reasons why companies fail to adopt FP:<br><br><ul>\n    <li>They say \"our developers aren't smart enough\" (to use F#, Erlang) [they should invest in their education!]</li>\n    <li>Culture of hiding problems =&gt; little incentive to adopt a paradigm that solves/prevents them if they're invisible</li>\n    <li>Overburden =&gt; not time</li>\n    <li>Implementing changes (FP) without first proving them (<a href=\"https://en.wikipedia.org/wiki/PDCA\">PDCA</a>) - blindly rewriting something in F#/... can fail; it's better to have a value-proposition hypothesis and prove it with a limited experiment first</li>\n    <li>The prioritise short-term (e.g. fire-fighting) over long-term (removing the root causes of problems)</li>\n</ul><br><br>Tip for driving FP adoption: Find a pragmatist in pain - e.g. a business person experiencing problems that FP could have prevented.",
  "excerpt": ""
 },
 {
  "title": "NDC: Async and Streaming JavaScript, We''re All Doing it Wrong! (Promises, Streams, Rx)",
  "published": "2015-06-17 13:17:47",
  "postType": "post",
  "slug": "/2015/06/17/ndc-async-and-streaming-javascript-were-all-doing-it-wrong-promises-streams-rx/",
  "status": "publish",
  "tags": [],
  "categories": [
   "Uncategorized"
  ],
  "content": "By Matthew Podwysocki<br><br><h3>Events</h3><br><br>Lot of work (setup, remove listeners ...), not composable.<br><br><h3>Promises</h3><br><br>No way to abort promise in progress. (Me: has to remember to check for errors: <code>then(onOk, onError)</code>.)<br><br>No try-catch-finally; only try-catch.<br><br><h3>Streams</h3><br><br>Node: Stream 1 were terrible (pause/resume unusable, data sent before ready, ...).<br><br><!--more--><br><br>Streams 2: A lot to trip over. Streams 3: Similar.<br><br>WHATWG Streams:<br><br><ul>\n<li>focused on low-level I/I, not on object mode</li>\n<li>Think Node Streams + Promises</li>\n</ul><br><br><h3>Reactive Programming</h3><br><br>Behavior: values over time\nEvent: discrete phenomena with a value and a time<br><br>\"The majority of your asynchronous code is written with just a few <em>flexible</em> functions.\"<br><br><h4>The general theory of reactivity</h4><br><br><pre><code>                ^\nmultiple values |   iterable        observable\nsingle value    |   value           promise\n                ----------------------------------&amp;gt;\n                    sync            async\n</code></pre><br><br>Observables: No need for low-level programming, combine existing powerful primitives (<code>debounce</code>, <code>flatMapLatest</code>, ...).<br><br><h3>JS Future</h3><br><br><h4>Async/Await a la C#?</h4><br><br><ul>\n<li>for promises</li>\n</ul><br><br><h4>Dart: Async progr. with futures and streams</h4><br><br>Futures = promises, streams unify IO and events, mirrors Rx by adding map/... .<br><br><h4>Observables coming to ES2016</h4><br><br>See https://github.com/zenparsing/es-observable/blob/master/README.md<br><br><h3>Resources</h3><br><br><ul>\n<li>http://jhusain.github.io/learnrx/</li>\n<li>http://rxmarbles.com/ - visual presentation of fns</li>\n<li>http://xgrommx.github.io/rx-book/</li>\n<li>visual debugger for async code with Rx:\nhttp://jaredforsyth.com/rxvision/</li>\n<li>RxJS Pacman game ex.: https://github.com/Reactive-Extensions/RxJS/blob/master/examples/pacman-unicode/index.html (and http://www.sitepoint.com/building-pacman-with-bacon-js/)</li>\n</ul>",
  "excerpt": ""
 },
 {
  "title": "Example: Functional Reactive Programming decisively beats Imperative on simplicity, length",
  "published": "2015-06-17 14:31:30",
  "postType": "post",
  "slug": "/2015/06/17/example-functional-reactive-programming-decisively-beats-imperative-on-simplicity-length/",
  "status": "publish",
  "tags": [
   "elm",
   "functional"
  ],
  "categories": [
   "Languages"
  ],
  "content": "<a href=\"https://twitter.com/theburningmonk\">@theburningmonk</a> Yan Cui has a <a href=\"http://www.slideshare.net/theburningmonk/tour-of-language-landscape\">nice example demonstrating how Functional Reactive Programming</a> [slides 185 - 206] (with <a href=\"http://elm-lang.org/guide/reactivity\">Elm's Signals</a>) yields a much shorter and easier to understand (one you know FRP) code than an imperative code with mutations spread all over the code base.<br><br><h2>The game</h2><br><br>Use the Up and Down keys to move the platforms and thus bounce the ball from left to right and back:<br><br><a href=\"/images/2015/06/screenshot-game.png\"><img class=\"alignnone size-medium wp-image-4390\" src=\"/images/2015/06/screenshot-game.png?w=300\" alt=\"screenshot-game\" width=\"300\" height=\"300\" /></a><br><br><h2>The imperative solution</h2><br><br><!--more--><br><br><pre><code>\r\nprivate var arrowKeyUp:Bool; \r\nprivate var arrowKeyDown:Bool;\r\nprivate var platform1:Platform; \r\nprivate var platform2:Platform; \r\nprivate var ball:Ball;<br><br>function keyDown(event:KeyboardEvent):Void {\r\n  if (currentGameState == Paused &amp;&amp; event.keyCode == 32) { \r\n    setGameState(Playing);\r\n  } else if (event.keyCode == 38) {\r\n    arrowKeyUp = true;\r\n  }else if (event.keyCode == 40) {\r\n    arrowKeyDown = true;\r\n  } \r\n}\r\n  \r\nfunction keyUp(event:KeyboardEvent):Void { \r\n    if (event.keyCode == 38) {\r\n    arrowKeyUp = false;\r\n  } else if (event.keyCode == 40) {\r\n    arrowKeyDown = false;\r\n  } \r\n}\r\n  \r\nfunction everyFrame(event:Event):Void { \r\n  if(currentGameState == Playing){\r\n    if (arrowKeyUp) {\r\n      platform1.y -= platformSpeed;\r\n    }\r\n    if (arrowKeyDown) {\r\n      platform1.y += platformSpeed; \r\n    }\r\n    if (platform1.y &lt; 5) platform1.y = 5; \r\n    if (platform1.y &gt; 395) platform1.y = 395;\r\n  ￼} \r\n}\r\n</code></pre><br><br><h2>The FRP solution</h2><br><br><pre><code>\r\ntype alias Platform = {x:Int, y:Int}\r\ndefaultPlatform = {x=5, y=0}<br><br>delta = Time.fps 20\r\ninput = Signal.sampleOn delta Keyboard.arrows<br><br>cap x = max 5 &lt;| min x 395\r\n-- ^- prevent the ball leaving the board<br><br>p1 : Signal Platform\r\np1 = foldp (\\{x, y} s -&gt; {s | y &lt;- cap &lt;| s.y + 5*y})\r\n          defaultPlatform \r\n          input\r\n</code></pre><br><br>If you have never seen Elm or a reactive program before, this is not very legible. But once you invest a little into learning, you will reap the benefits forever.<br><br><h2>Conclusion</h2><br><br>Imperative sucks, F(R)P is power! :-)",
  "excerpt": ""
 },
 {
  "title": "Notes from Troy Hunt''s Hack Yourself First workshop",
  "published": "2015-06-17 14:58:09",
  "postType": "post",
  "slug": "/2015/06/17/notes-from-troy-hunts-hack-yourself-first-workshop/",
  "status": "publish",
  "tags": [
   "privacy",
   "security"
  ],
  "categories": [
   "General"
  ],
  "content": "<p class=\"p1\">Troy Hunt (<a href=\"https://twitter.com/troyhunt\">@troyhunt</a>, <a href=\"http://www.troyhunt.com/\">blog</a>) had a great, very hands-on 2-day workshop about webapp security at NDC Oslo. Here are my notes.</p><br><br><h3 class=\"p1\">Highlights - resources</h3><br><br><p class=\"p1\"><span class=\"s1\">Personal security and privacy</span></p><br><br><ul class=\"ul1\">\n    <li class=\"li1\"><span class=\"s5\"><a href=\"https://www.entropay.com/\"><span class=\"s2\">https://www.entropay.com/</span></a></span><span class=\"s1\"> - a Prepaid Virtual Visa Card</span></li>\n    <li class=\"li1\"><span class=\"s1\">mailinator.com - tmp email</span></li>\n    <li class=\"li1\"><span class=\"s1\">f-secure VPN</span></li>\n    <li class=\"li1\"><span class=\"s5\"><a href=\"https://www.netsparker.com/\"><span class=\"s2\">https://www.netsparker.com/</span></a></span><span class=\"s1\"> - scan a site for issues (insecure cookies, framework disclosure, SQL injection, …) (lot of $k)</span></li>\n</ul><br><br><p class=\"p1\"><span class=\"s1\">Site security</span></p><br><br><ul class=\"ul1\">\n    <li class=\"li1\"><span class=\"s5\"><a href=\"https://report-uri.io/\"><span class=\"s2\">https://report-uri.io/</span></a></span><span class=\"s1\"> - get reports when CSP rules violated; also displays CSP headers for a site in a human-friendly way</span></li>\n    <li class=\"li1\"><span class=\"s5\"><a href=\"https://securityheaders.io/\"><span class=\"s2\">https://securityheaders.io/</span></a></span><span class=\"s1\"> check quality of headers wrt security</span></li>\n    <li class=\"li1\"><span class=\"s1\">free SSL - <a href=\"http://www.startssl.com/\"><span class=\"s6\">http://www.startssl.com/</span></a>, <a href=\"https://www.cloudflare.com/\"><span class=\"s6\">https://www.cloudflare.com/</span></a> (also provides web app firewall and other protections) ; </span></li>\n    <li class=\"li5\"><span class=\"s4\">SSL quality check: <a href=\"https://www.ssllabs.com/ssltest/\"><span class=\"s2\">https://www.ssllabs.com/ssltest/</span></a> </span></li>\n    <li class=\"li1\"><span class=\"s5\"><a href=\"https://letsencrypt.org/\"><span class=\"s2\">https://letsencrypt.org/</span></a></span><span class=\"s1\"> - free, automated, open Certificate Authority (Linux Found., Mozilla)</span></li>\n    <li class=\"li1\"><span class=\"s1\">HSTS Preload - tell Chrome, FF that your site should only be ever loaded over HTTPS - <a href=\"https://hstspreload.appspot.com/\"><span class=\"s6\">https://hstspreload.appspot.com/</span></a></span></li>\n</ul><br><br><p class=\"p1\"><span class=\"s1\">Breaches etc.</span></p><br><br><ul class=\"ul1\">\n    <li class=\"li5\"><span class=\"s7\"><a href=\"http://arstechnica.com/security/2015/06/hack-of-cloud-based-lastpass-exposes-encrypted-master-passwords/\"><span class=\"s2\">http://arstechnica.com/security/2015/06/hack-of-cloud-based-lastpass-exposes-encrypted-master-passwords/</span></a></span></li>\n    <li class=\"li5\"><span class=\"s7\"><a href=\"https://twitter.com/jmgosney\"><span class=\"s2\">https://twitter.com/jmgosney</span></a></span><span class=\"s4\"> - one of ppl behind <a href=\"http://t.co/foXRFfdHV9\"><span class=\"s12\">http://passwordscon.org </span></a>. <a href=\"http://t.co/CqoqCIRS6t\"><span class=\"s12\">http://password-hashing.net </span></a> experts panel. Team Hashcat. </span></li>\n    <li class=\"li5\"><span class=\"s7\"><a href=\"http://arstechnica.com/security/2012/12/25-gpu-cluster-cracks-every-standard-windows-password-in-6-hours/\"><span class=\"s2\">http://arstechnica.com/security/2012/12/25-gpu-cluster-cracks-every-standard-windows-password-in-6-hours/</span></a></span><span class=\"s4\"> </span></li>\n</ul><br><br><p class=\"p1\"><span class=\"s1\">To follow</span></p><br><br><ul class=\"ul1\">\n    <li class=\"li5\"><span class=\"s4\">! <a href=\"http://krebsonsecurity.com/\"><span class=\"s2\">http://krebsonsecurity.com/</span></a></span></li>\n    <li class=\"li5\"><span class=\"s4\">! <a href=\"http://www.troyhunt.com/\"><span class=\"s2\">http://www.troyhunt.com/</span></a></span></li>\n    <li class=\"li5\"><span class=\"s4\">! <a href=\"https://www.schneier.com/\"><span class=\"s2\">https://www.schneier.com/</span></a></span></li>\n    <li class=\"li1\"><span class=\"s1\">! <a href=\"https://twitter.com/mikko\"><span class=\"s6\">https://twitter.com/mikko</span></a> (of F-Secure) also great [TED] talks</span></li>\n    <li class=\"li1\"><span class=\"s1\">kevin mitnick (jailed for hacking; twitter, books)</span></li>\n</ul><br><br><!--more--><br><br><p class=\"p1\"><span class=\"s1\">Books</span></p><br><br><ul class=\"ul1\">\n    <li class=\"li5\"><span class=\"s7\"><a href=\"http://www.amazon.com/We-Are-Anonymous-LulzSec-Insurgency/dp/0316213527\"><span class=\"s2\">http://www.amazon.com/We-Are-Anonymous-LulzSec-Insurgency/dp/0316213527</span></a></span><span class=\"s4\"> - easy read, hard to put down</span></li>\n    <li class=\"li5\"><span class=\"s7\"><a href=\"http://www.amazon.com/Ghost-Wires-Adventures-Worlds-Wanted/dp/1441793755\"><span class=\"s2\">http://www.amazon.com/Ghost-Wires-Adventures-Worlds-Wanted/dp/1441793755</span></a></span><span class=\"s4\"> - about Mitnick’s hacking, social engineering, living on the run</span></li>\n    <li class=\"li5\"><span class=\"s4\">? <a href=\"http://www.amazon.com/Art-Intrusion-Exploits-Intruders-Deceivers/dp/0471782661/ref=sr_1_1?s=books&amp;ie=UTF8&amp;qid=1434466205&amp;sr=1-1&amp;keywords=the+art+of+intrusion&amp;pebp=1434466211598&amp;perid=19A26C170G9Q547TNGW0\"><span class=\"s2\">http://www.amazon.com/Art-Intrusion-Exploits-Intruders-Deceivers/dp/0471782661/</span></a></span></li>\n    <li class=\"li5\"><span class=\"s4\">Mitnick: <a href=\"http://www.amazon.com/Art-Deception-Controlling-Element-Security/dp/076454280X/ref=sr_1_1?s=books&amp;ie=UTF8&amp;qid=1434466237&amp;sr=1-1&amp;keywords=the+art+of+deception&amp;pebp=1434466244836&amp;perid=1ZVNQKRH89H3A414N295\"><span class=\"s2\">http://www.amazon.com/Art-Deception-Controlling-Element-Security/dp/076454280X/</span></a> - social engineering</span></li>\n</ul><br><br>Other<br><br><ul class=\"ul1\">\n    <li class=\"li5\"><span class=\"s7\"><a href=\"https://www.xssposed.org/\"><span class=\"s2\">https://www.xssposed.org/</span></a></span></li>\n    <li class=\"li5\"><span class=\"s4\">See <a href=\"https://www.drupal.org/SA-CORE-2014-005\"><span class=\"s2\">https://www.drupal.org/SA-CORE-2014-005</span></a></span></li>\n    <li class=\"li5\"><span class=\"s7\"><a href=\"https://www.youtube.com/watch?v=Qvhdz8yE_po\"><span class=\"s2\">https://www.youtube.com/watch?v=Qvhdz8yE_po</span></a></span><span class=\"s4\"> - Havij example</span></li>\n    <li class=\"li5\"><span class=\"s7\"><a href=\"http://www.troyhunt.com/2013/07/everything-you-wanted-to-know-about-sql.html\"><span class=\"s2\">http://www.troyhunt.com/2013/07/everything-you-wanted-to-know-about-sql.html</span></a></span><span class=\"s4\">, <a href=\"http://www.troyhunt.com/2010/05/owasp-top-10-for-net-developers-part-1.html\"><span class=\"s2\">http://www.troyhunt.com/2010/05/owasp-top-10-for-net-developers-part-1.html</span></a>, <a href=\"http://www.troyhunt.com/2012/12/stored-procedures-and-orms-wont-save.html\"><span class=\"s2\">http://www.troyhunt.com/2012/12/stored-procedures-and-orms-wont-save.html</span></a>, </span></li>\n    <li class=\"li1\"><span class=\"s1\">Googlee: find config files with SA access info: `inurl:ftp inurl:web.config filetype:config sa`</span></li>\n    <li class=\"li5\"><span class=\"s7\"><a href=\"https://scotthelme.co.uk/hardening-your-http-response-headers/\"><span class=\"s2\">https://scotthelme.co.uk/hardening-your-http-response-headers/</span></a></span><span class=\"s4\"> and <a href=\"https://securityheaders.io/\"><span class=\"s2\">https://securityheaders.io/</span></a></span></li>\n    <li class=\"li5\"><span class=\"s7\"><a href=\"https://developer.mozilla.org/en-US/docs/Web/Security/Public_Key_Pinning\"><span class=\"s2\">https://developer.mozilla.org/en-US/docs/Web/Security/Public_Key_Pinning</span></a></span><span class=\"s4\"> - prevent MITM</span></li>\n    <li class=\"li1\"><span class=\"s1\">wappalyzer chrome plugin displaying info about the server and client that can be detected (jQuery, NewRelic, IIS, win OS, …)</span></li>\n    <li class=\"li5\"><span class=\"s7\"><a href=\"http://www.troyhunt.com/2015/05/do-you-really-want-bank-grade-security.html\"><span class=\"s2\">http://www.troyhunt.com/2015/05/do-you-really-want-bank-grade-security.html</span></a></span></li>\n    <li class=\"li5\"><span class=\"s7\"><a href=\"http://www.troyhunt.com/2012/05/everything-you-ever-wanted-to-know.html\"><span class=\"s2\">http://www.troyhunt.com/2012/05/everything-you-ever-wanted-to-know.html</span></a></span></li>\n    <li class=\"li6\"><span class=\"s11\">tool: <a href=\"https://github.com/gentilkiwi/mimikatz\"><span class=\"s6\">https://github.com/gentilkiwi/mimikatz</span></a> </span><span class=\"s1\">extract plaintexts passwords, hash, PIN code and kerberos tickets from memory on Windows</span></li>\n</ul><br><br><h3 class=\"p1\">Notes</h3><br><br><ul class=\"ul1\">\n    <li class=\"li1\"><span class=\"s1\"><a href=\"http://hackyourselffirst.troyhunt.com/\">HackYourselfFirst.troyhunt.com</a> - an example app with many vulnerabilities</span></li>\n    <li class=\"li1\"><span class=\"s1\">Note: maximizing your browser window will share info about your screen size, which might help to identify you</span></li>\n    <li class=\"li3\"><a href=\"https://haveibeenpwned.com/\"><span class=\"s2\">haveibeenpwned.com</span></a><span class=\"s3\"> - Troy's online DB  of hacked accounts</span></li>\n</ul><br><br><p class=\"p1\"><span class=\"s1\">Tips</span></p><br><br><ul class=\"ul1\">\n    <li class=\"li1\"><span class=\"s1\">check robots.txt to know what to access</span></li>\n</ul><br><br><p class=\"p1\"><span class=\"s1\">Example Issues</span></p><br><br><ul class=\"ul1\">\n    <li class=\"li1\"><span class=\"s1\">no https on login page</span></li>\n    <li class=\"li1\"><span class=\"s1\">insecure psw requirements</span></li>\n    <li class=\"li1\"><span class=\"s1\">cookies not secure flag =&gt; sent over http incl. AuthCookie)</span></li>\n    <li class=\"li1\"><span class=\"s1\">psw sent in clear text in confirm email</span></li>\n    <li class=\"li1\"><span class=\"s1\">user enumeration, f.eks. an issue with AdultFriendFinder - entry someone’s email to login to find out whether they’ve an account</span></li>\n    <li class=\"li1\"><span class=\"s1\">post illegal chars, get them displayed =&gt; injection</span></li>\n    <li class=\"li1\"><span class=\"s1\">no anti-automation (captcha)</span>\n<ul class=\"ul1\">\n    <li class=\"li1\"><span class=\"s1\">login confirm. email &amp; autom. creating 1m accounts =&gt; sending 1m emails =&gt; pisses ppl off, likely increase one’s spam reputation (=&gt; harder to send emails)</span></li>\n</ul>\n</li>\n    <li class=\"li1\"><span class=\"s1\">brute-force protection?</span></li>\n</ul><br><br><!--more--><br><br><p class=\"p1\"><span class=\"s1\"><b>### XSS</b></span></p><br><br><p class=\"p1\"><span class=\"s1\">Reflected XSS: display unescaped user input</span></p><br><br><ul class=\"ul1\">\n    <li class=\"li1\"><span class=\"s1\">Encoding context: HTML, JS, CSS … have diff. escape sequences for the same char (e.g. &lt;) - look at where they’re mixed</span></li>\n    <li class=\"li1\"><span class=\"s1\">Check the encoding consistency - manual encoding, omitting some chars</span></li>\n    <li class=\"li1\"><span class=\"s1\">JS =&gt; load ext resources, access cookies, manipulate the DOM</span></li>\n</ul><br><br><p class=\"p1\"><span class=\"s1\">Task: stal authCookie via search</span></p><br><br><p class=\"p1\"><span class=\"s1\"><b>### SQL injection</b></span></p><br><br><p class=\"p1\"><span class=\"s1\">Error-based injection: when the DB helps us by telling us what is wrong -&gt; use ti learn more and even show some data</span></p><br><br><p class=\"p5\"><span class=\"s4\">Ex.: <a href=\"http://hackyourselffirst.troyhunt.com/Make/10?orderby=supercarid\"><span class=\"s2\">http://hackyourselffirst.troyhunt.com/Make/10?orderby=supercarid</span></a> &lt;—— supercarid is a column name</span></p><br><br><ul class=\"ul1\">\n    <li class=\"li1\"><span class=\"s1\">orderby=(select * from userprofile) …</span></li>\n    <li class=\"li1\"><span class=\"s1\">learn about DB sructure, force an exception that shows the valueex.: (select top 1 cast(password) as int from userprofile) =&gt; “Conversion failed for the nvar value ‘passw0rd …’\"</span></li>\n</ul><br><br><p class=\"p1\"><span class=\"s1\">Tips</span></p><br><br><ul class=\"ul1\">\n    <li class=\"li1\"><span class=\"s1\">think of SQL commands that disclose structure: sys.(tables,columns), system commands</span></li>\n    <li class=\"li1\"><span class=\"s1\">enumerate records: nest queries: select top X ows asc then top 1 rows from that desc</span></li>\n    <li class=\"li1\"><span class=\"s1\">write out how you think the query works / is being constructed internally </span></li>\n    <li class=\"li1\"><span class=\"s1\">cast things to invalid types to disclose values in err msgs (or implicit cast due to -1 ..)</span></li>\n</ul><br><br><p class=\"p1\"><span class=\"s1\">#### Defenses</span></p><br><br><ul class=\"ul1\">\n    <li class=\"li1\"><span class=\"s1\">whitelist input data types (id=123 =&gt; onlyallow ints)</span></li>\n    <li class=\"li1\"><span class=\"s1\">enumerable values - check against an appropr. whitelist</span></li>\n    <li class=\"li1\"><span class=\"s1\">if the value is stored - who uses it, how? making query/insertion safe</span></li>\n    <li class=\"li1\"><span class=\"s1\">permissions: give read-only permissions as much as possible; don’t use admin user from your webapp</span></li>\n</ul><br><br><p class=\"p1\"><span class=\"s1\"><b>### Mobile apps</b></span></p><br><br><ul class=\"ul1\">\n    <li class=\"li1\"><span class=\"s1\">Look at HTTP req for sensitive data - creds, account, …</span></li>\n    <li class=\"li1\"><span class=\"s1\">Apps may ignore certificate validations</span></li>\n    <li class=\"li1\"><span class=\"s1\">In your app: param tampering, auth bypass, direct object refs</span></li>\n    <li class=\"li1\"><span class=\"s1\">Weak  often: airlines, small scale shops, fast foods, …</span></li>\n</ul><br><br><p class=\"p1\"><span class=\"s1\">Tips</span></p><br><br><ul class=\"ul1\">\n    <li class=\"li1\"><span class=\"s1\">certificate pining - the app has the fingerprint of the server cert. hardcoded and doesn’t trust even “valid” MITM certificate (banks, dropbox, …)x</span></li>\n</ul><br><br><p class=\"p1\"><span class=\"s1\"><b>### CSRF Cross-Site Request Forgery</b></span></p><br><br><p class=\"p1\"><span class=\"s1\">= make the user send a request =&gt; their auth cookie included</span></p><br><br><ul class=\"ul1\">\n    <li class=\"li1\"><span class=\"s1\">async Ajax req to another site forbidden but that doesn’t apply to normal post</span></li>\n</ul><br><br><p class=\"p1\"><span class=\"s1\">Protection</span></p><br><br><ul class=\"ul1\">\n    <li class=\"li1\"><span class=\"s1\">anti-forgery tags</span></li>\n</ul><br><br><p class=\"p1\"><span class=\"s1\"><b>### Understanding fwrk disclosure</b></span></p><br><br><ul class=\"ul1\">\n    <li class=\"li1\"><span class=\"s5\"><a href=\"http://www.shodanhq.com/\"><span class=\"s2\">http://www.shodanhq.com/</span></a></span><span class=\"s1\"> -&gt; search for “drupal 7” -&gt; pwn</span></li>\n</ul><br><br><ul class=\"ul1\">\n    <li class=\"li1\"><span class=\"s1\">How disclosed:</span></li>\n</ul><br><br><ul class=\"ul1\">\n    <li class=\"li1\"><span class=\"s1\">headers</span></li>\n    <li class=\"li1\"><span class=\"s1\"> familiar signs - jsessionid cookie for java, …</span></li>\n    <li class=\"li1\"><span class=\"s1\">The default error and 404 responses may help to recognize the fwr</span></li>\n    <li class=\"li1\"><span class=\"s1\">HTML code (reactid), “.do” for Sttruts</span></li>\n    <li class=\"li1\"><span class=\"s1\">implicit: order of headers (Apache x IIS), paths (capitalized?), response to improper HTTP version/protocol, </span>\n<ul class=\"ul1\">\n    <li class=\"li1\"><span class=\"s1\">=&gt; likely still possible to figure out the stack but not possible to simple search for fwrk+version</span></li>\n</ul>\n</li>\n</ul><br><br><p class=\"p1\"><span class=\"s1\"><b>### Session hijacking</b></span></p><br><br><p class=\"p1\"><span class=\"s1\">Steal authentication cookie =&gt; use for illegal requests.</span></p><br><br><ul class=\"ul1\">\n    <li class=\"li1\"><span class=\"s1\">Persistence over HTTP of auth., session: cookie, URL (but URL insecure - can be shared)</span></li>\n    <li class=\"li1\"><span class=\"s1\">Session/auth ID retrieval: insecure transport, referrer, stored in exceptions, XSS</span></li>\n    <li class=\"li1\"><span class=\"s1\">Factors limiting hijacking: short duration expiry, keyed to client device / IP (but IPs may rotate, esp, on mobile devices =&gt; be very cautious)</span></li>\n</ul><br><br><p class=\"p1\"><span class=\"s1\"><b>DAY 2</b></span></p><br><br><p class=\"p1\"><span class=\"s1\"><b>--------</b></span></p><br><br><p class=\"p1\"><span class=\"s1\"><b>### Cracking passwords</b></span></p><br><br><p class=\"p1\"><span class=\"s1\">Password hashing: </span></p><br><br><ul class=\"ul1\">\n    <li class=\"li1\"><span class=\"s1\">salt: so that 2 ppl choosing the same psw will have a different hash =&gt; cracking is # salts * # passwords inst. of just N</span></li>\n    <li class=\"li1\"><span class=\"s1\">has cracking tips:</span>\n<ul class=\"ul1\">\n    <li class=\"li1\"><span class=\"s1\">character space [a-zA-Z0-9]</span></li>\n    <li class=\"li1\"><span class=\"s1\">Dictionary: passw0rd, …</span></li>\n    <li class=\"li1\"><span class=\"s1\">Mutations: manipulation and subst. of characters</span></li>\n</ul>\n</li>\n</ul><br><br><p class=\"p1\"><span class=\"s1\">Tips:</span></p><br><br><ul class=\"ul1\">\n    <li class=\"li1\"><span class=\"s1\">1Password , LastPass, ….</span></li>\n    <li class=\"li1\"><span class=\"s1\">GPU ~ 100* faster than CPU</span></li>\n</ul><br><br><p class=\"p1\"><span class=\"s1\">#### Ex: Crack with hashcat</span></p><br><br><p class=\"p1\"><span class=\"s1\">common psw dict + md5-hashed passwords =&gt; crack</span></p><br><br><p class=\"p1\"><span class=\"s1\">./hashcat-cli64.bin --hash-type=0 StratforHashes.txt hashkiller.com.dic # 23M psw dict -&gt; Recovered.: 44 326/860 160 hashes [obs duplications] in 4 min (speed 135.35k plains)</span></p><br><br><p class=\"p1\"><span class=\"s1\">Q: What dictionary we use? Do we apply any mutations to it?</span></p><br><br><p class=\"p1\"><span class=\"s1\"><b>### Account enumeration</b></span></p><br><br><ul class=\"ul1\">\n    <li class=\"li1\"><span class=\"s1\">= Does XY have an account?</span></li>\n    <li class=\"li1\"><span class=\"s1\">Multiple vectors (psw reset, register a new user with the same e-mail, …)</span></li>\n    <li class=\"li1\"><span class=\"s1\">Anti-automation: is there any? It may be inconsistent across vectors</span></li>\n    <li class=\"li1\"><span class=\"s1\">Does it matter? (&lt;&gt; privacy needs)</span></li>\n    <li class=\"li1\"><span class=\"s1\">How to “ask” the site and how to identify + and - responses?</span></li>\n    <li class=\"li1\"><span class=\"s1\">Timing attacks: distinguish positive x negative response based on the latency differing between the two</span></li>\n</ul><br><br><p class=\"p1\"><span class=\"s1\"><b>### HTTPS</b></span></p><br><br><p class=\"p1\"><span class=\"s1\">Confidentiality, Integrity, Authenticity</span></p><br><br><p class=\"p1\"><span class=\"s1\">Traffic hijacking: <a href=\"https://www.wifipineapple.com/\"><span class=\"s6\">https://www.wifipineapple.com/</span></a> - wifi hotspot with evil capabilities</span></p><br><br><ul class=\"ul2\">\n<ul class=\"ul3\">\n    <li class=\"li1\"><span class=\"s1\">monitor probe requests (the phone looks for networks it knows), present yourself as one of those, the phone connects autom. (if no encryption)</span></li>\n</ul>\n</ul><br><br><ul class=\"ul1\">\n    <li class=\"li1\"><span class=\"s1\">Consider everything sent over HTTP to be compromised</span></li>\n    <li class=\"li1\"><span class=\"s1\">Look at HTTPS content embedded in untrusted pages (iframes, links) - e.g. payment page embedded in http</span></li>\n</ul><br><br><p class=\"p1\"><span class=\"s1\">Links</span></p><br><br><ul class=\"ul1\">\n    <li class=\"li1\"><span class=\"s1\">HSTS Preload - tell Chrome, FF that your site should only be ever loaded over HTTPS - <a href=\"https://hstspreload.appspot.com/\"><span class=\"s6\">https://hstspreload.appspot.com/</span></a></span></li>\n    <li class=\"li5\"><span class=\"s7\"><a href=\"https://www.owasp.org/index.php/HTTP_Strict_Transport_Security\"><span class=\"s2\">https://www.owasp.org/index.php/HTTP_Strict_Transport_Security</span></a></span><span class=\"s4\"> header</span></li>\n</ul><br><br><p class=\"p1\"><span class=\"s1\"><b>### Content Scurity Policy header</b></span></p><br><br><p class=\"p5\"><span class=\"s8\"><a href=\"https://developer.chrome.com/extensions/contentSecurityPolicy\">https://developer.chrome.com/extensions/contentSecurityPolicy</a></span><span class=\"s4\"> See e.g. <a href=\"https://haveibeenpwned.com/\"><span class=\"s2\">https://haveibeenpwned.com/</span></a> headers</span></p><br><br><p class=\"p1\"><span class=\"s1\">w/o CSP</span></p><br><br><ul class=\"ul1\">\n    <li class=\"li1\"><span class=\"s1\">anything can be added to the page via a reflected XSS risk</span></li>\n    <li class=\"li1\"><span class=\"s1\">Anyth, can be added to the DOM downstream (on a proxy)</span></li>\n</ul><br><br><p class=\"p1\"><span class=\"s1\">With CSP the browser will only load resources you white-list; any violations can be reported</span></p><br><br><p class=\"p1\"><span class=\"s1\">Use e.g. <a href=\"https://report-uri.io/home/generate\"><span class=\"s6\">https://report-uri.io/home/generate</span></a> to create it and the report to watch for violations to fine tune it.</span></p><br><br><p class=\"p1\"><span class=\"s1\"><b>### SQL injection cont'd</b></span></p><br><br><p class=\"p1\"><span class=\"s1\">(Yesterday: Error-Based)</span></p><br><br><p class=\"p1\"><span class=\"s1\"><b>#### Union Based SQLi</b></span></p><br><br><p class=\"p1\"><span class=\"s1\">Modify the query to union whatever other data and show them. More data faster than error-based inj.</span></p><br><br><p class=\"p1\"><span class=\"s1\">Ex.: <a href=\"http://hackyourselffirst.troyhunt.com/CarsByCylinders?Cylinders=V12\"><span class=\"s6\">http://hackyourselffirst.troyhunt.com/CarsByCylinders?Cylinders=V12</span></a> :  V12 -&gt; `V12' union select voteid, comments collate SQL_Latin1_General_CP1_CI_AS from vote-- `</span></p><br><br><p class=\"p1\"><span class=\"s1\"><b>#### Blind Boolean (laborious)</b></span></p><br><br><p class=\"p1\"><span class=\"s1\">Blind inj.: We can’t always rely on data being explicitly returned to the UI =&gt; ask a question, draw a conclusion about the data.</span></p><br><br><p class=\"p1\"><span class=\"s1\">Ex: </span></p><br><br><p class=\"p5\"><span class=\"s8\"><a href=\"http://hackyourselffirst.troyhunt.com/Supercar/Leaderboard?orderBy=PowerKw&amp;asc=false\">http://hackyourselffirst.troyhunt.com/Supercar/Leaderboard?orderBy=PowerKw&amp;asc=false</a></span><span class=\"s4\"> -&gt; </span></p><br><br><p class=\"p1\"><span class=\"s1\">ordedby =&gt; case when (select count(*) from userprofile) &gt; 1 then powerkw else topspeedkm end</span></p><br><br><p class=\"p1\"><span class=\"s1\"> </span></p><br><br><p class=\"p1\"><span class=\"s1\">Extract email: Is ascii of the lowercase char #1 &lt; ascii of m ?</span></p><br><br><p class=\"p1\"><span class=\"s1\">Automation: SqlMap</span></p><br><br><p class=\"p1\"><span class=\"s1\"><b>#### Time based blind injection</b></span></p><br><br><p class=\"p1\"><span class=\"s1\">When no useful output returned but yes/no responses differ significantly in how much time they take. F.ex. ask the db to delay the OK response.</span></p><br><br><p class=\"p1\"><span class=\"s1\">MS SQL: IF ‘b’ &gt; ‘a’ WAITFOR DELAY ’00:00:05'</span></p><br><br><p class=\"p1\"><span class=\"s1\"><b>### Brute force attacks</b></span></p><br><br><ul class=\"ul1\">\n    <li class=\"li1\"><span class=\"s1\">Are there any defences? Often not</span></li>\n    <li class=\"li1\"><span class=\"s1\">How are defences impl?</span>\n<ul class=\"ul1\">\n    <li class=\"li1\"><span class=\"s1\">block the req resources</span></li>\n    <li class=\"li1\"><span class=\"s1\">block the src IP</span></li>\n    <li class=\"li1\"><span class=\"s1\">rate limit (by src IP)</span></li>\n</ul>\n</li>\n</ul><br><br><p class=\"p1\"><span class=\"s1\"><b>### Automation</b></span></p><br><br><ul class=\"ul1\">\n    <li class=\"li1\"><span class=\"s1\">penetration testing apps and services such as Netsparker, WhiteHatSec</span></li>\n    <li class=\"li1\"><span class=\"s1\">targets identification: shodan, googledorks, randowm crawling</span></li>\n    <li class=\"li1\"><span class=\"s1\">think aout the actions that adhere to a pattern - sql injection, fuzzing (repeat a req. trying diff. values for fields - SQLi, …), directory enumeration</span></li>\n    <li class=\"li1\"><span class=\"s1\">automation can be used for good - test your site</span></li>\n    <li class=\"li1\"><span class=\"s1\">tip: have autom. penetration testing (and perhaps static code analysis) as a part fo your build pipeline</span></li>\n</ul><br><br><p class=\"p1\"><span class=\"s1\">Task: Get DB schema using sqlmap (see python2.7 sqlmap.py --help)</span></p><br><br><p class=\"p1\"><span class=\"s1\"><b>### Protection</b></span></p><br><br><p class=\"p1\"><span class=\"s1\">Intrusion Detection System (IDS) - e.g. Snort</span></p><br><br><p class=\"p1\"><span class=\"s1\">Web Application Firewall (WAF) - e.g. CloudFare ($20/m)</span></p><br><br><p class=\"p1\"><span class=\"s1\"><b>### Various</b></span></p><br><br><ul class=\"ul1\">\n    <li class=\"li1\"><span class=\"s1\"><img src=\"bad\" alt=\"\" /></span></li>\n</ul>",
  "excerpt": ""
 },
 {
  "title": "NDC Oslo 2015: Talk notes, recommended talks (security, FP, etc.)",
  "published": "2015-06-19 13:25:47",
  "postType": "post",
  "slug": "/2015/06/19/ndc-oslo-2015-talk-notes-recommended-talks-security-fp-etc/",
  "status": "publish",
  "tags": [],
  "categories": [
   "General"
  ],
  "content": "A great conference. A good deal of good talks.<br><br><h2>To (perhaps) check later</h2><br><br>Wednesday<br><br><ul>\n<li><a href=\"http://ndcoslo.oktaset.com/t-30297\">Practical CSS tips &amp; tricks for backend developers</a> - really useful tips! <a href=\"https://vimeo.com/131189626\">video</a></li>\n<li><a href=\"http://ndcoslo.oktaset.com/t-30200\">No Estimates, Let's Explore the Possibilities</a> <a href=\"https://vimeo.com/131194136\">video</a></li>\n<li><a href=\"http://ndcoslo.oktaset.com/t-30267\">Form with Function: Adding Behavior with CSS</a> - recommended by a friend (modal dialogs, tab switching, ...) <a href=\"https://vimeo.com/131410261\">video</a></li>\n<li>? <a href=\"http://ndcoslo.oktaset.com/t-30197\">Anti-fragile and feedback. Trying to make up for the failures of \"agile.\"</a> <a href=\"https://vimeo.com/131410262\">video</a></li>\n<li>? <a href=\"http://ndcoslo.oktaset.com/t-30229\">JavaScript Forensics</a> - not sure what this is about but it might be interesting</li>\n<li>? <a href=\"http://ndcoslo.oktaset.com/t-30207\">Designing and Programming Accessible Website and App UIs</a> <a href=\"https://vimeo.com/131631491\">video</a></li>\n</ul><br><br>Thursday<br><br><ul>\n<li>? <a href=\"http://ndcoslo.oktaset.com/t-30270\">Declarative REST: State Machines for the Web</a> <a href=\"https://vimeo.com/131631886\">video</a></li>\n<li><a href=\"http://ndcoslo.oktaset.com/t-30328\">Continuous Delivery for Architects</a> - Neal Ford <a href=\"https://vimeo.com/131632251\">video</a></li>\n<li>? <a href=\"http://ndcoslo.oktaset.com/t-30282\">Desktop applications using JavaScript and Electron</a> <a href=\"https://vimeo.com/131632606\">video</a></li>\n<li>? <a href=\"http://ndcoslo.oktaset.com/t-30156\">High Performance in the Critical Rendering Path</a> - how to make pages to load fast <a href=\"https://vimeo.com/131634704\">video</a></li>\n<li><a href=\"http://ndcoslo.oktaset.com/t-30327\">This is Water</a> - Neal Ford - an excursion into a strange, fantastical world with things like immutable database server, phoenix machines, and lambdas. <a href=\"https://vimeo.com/131634703\">video</a></li>\n<li><a href=\"http://ndcoslo.oktaset.com/t-30317\">Securing Web APIs – Patterns &amp; Anti-Patterns</a> <a href=\"https://vimeo.com/131635255\">video</a></li>\n<li>? <a href=\"http://ndcoslo.oktaset.com/t-30333\">Functional Data</a> - event sourcing &amp; FP <a href=\"https://vimeo.com/131636650\">video</a></li>\n<li><a href=\"http://ndcoslo.oktaset.com/t-30184\">Authentication and authorization in modern JavaScript web applications – how hard can it be?</a> <a href=\"https://vimeo.com/131636653\">video</a></li>\n<li>? <a href=\"http://ndcoslo.oktaset.com/t-30259\">Taking other peoples money: A guide to online payments</a> <a href=\"https://vimeo.com/131639827\">video</a></li>\n<li>? <a href=\"http://ndcoslo.oktaset.com/t-30246\">Running Docker and Containers in Development and Production</a> <a href=\"https://vimeo.com/131639823\">video</a></li>\n<li><a href=\"http://ndcoslo.oktaset.com/t-30185\">Not Even Close: The State of Computer Security</a></li>\n</ul><br><br>Friday<br><br><ul>\n<li><a href=\"http://ndcoslo.oktaset.com/t-30291\">595 billions income - untouched by human hands</a> <a href=\"https://vimeo.com/131641013\">video</a></li>\n<li><a href=\"http://ndcoslo.oktaset.com/t-30301\">Boosting security with HTTP headers</a> <a href=\"https://vimeo.com/131641011\">video</a></li>\n<li><a href=\"http://ndcoslo.oktaset.com/t-30205\">The rest of ReST</a> - we'll look at the challenges of building usable real-world ReST APIs: Hypertext Application Language (HAL), HTTP Patch, ... <a href=\"https://vimeo.com/131641615\">video</a></li>\n<li>? <a href=\"http://ndcoslo.oktaset.com/t-30240\">How do you scale a logging infrastructure to accept a billion messages a day?</a> - DB -&gt; ELK -&gt; ELK + Kafka <a href=\"https://vimeo.com/131642357\">video</a></li>\n<li>? <a href=\"http://ndcoslo.oktaset.com/t-30288\">Learning Client Hypermedia from the Ground Up</a> - how to move specific knowledge of 1) addresses, 2) inputs, and 3) workflow out of the client app and place it into the message =&gt; a more robust, adaptable, and resilient client <a href=\"https://vimeo.com/131642790\">video</a></li>\n<li>? <a href=\"http://ndcoslo.oktaset.com/t-30188\">Make it Faster - Lessons Learned from Benchmarking NoSQL on the AWS Cloud</a> - best practices for performing database benchmarking on the AWS cloud &amp; how to get more speed and efficiency in your production workloads <a href=\"https://vimeo.com/131642787\">video</a></li>\n<li>? <a href=\"http://ndcoslo.oktaset.com/t-30262\">Crafting Evolvable Web API Representations</a> - like structuring for evolution, sizing for optimum caching, the different ways to include metadata, ... <a href=\"https://vimeo.com/131643022\">video</a></li>\n<li>? <a href=\"http://ndcoslo.oktaset.com/t-30335\">Mob Programming, A Whole Team Approach</a> <a href=\"https://vimeo.com/131643015\">video</a></li>\n<li>? <a href=\"http://ndcoslo.oktaset.com/t-30319\">Removing barriers</a> - JetBrains's good and bad expericences with minimizing management <a href=\"https://vimeo.com/131644347\">video</a></li>\n</ul><br><br><h2>Keynote Data and Goliath ☆☆☆☆</h2><br><br><!--more--><br><br>https://vimeo.com/131115865<br><br>Inspiring, slightly eye-opening!<br><br>Key points: We live in a society of ubiqutious surveillance. We need to share data to get great services yet we need to ensure personal privacy and security - finding the right balance will be a major dialog in the near future. Currently we share too much, too freely. Even high-tech, presumabely super secret surveillance tools and SW had their cousins presented at security conferences =&gt; anybody can build these, and many do. Either everybody gets to spy - or nobody does =&gt; build security in.<br><br>Check out Schneier's book Data and Goliath and blog.<br><br><h2>Lean and FP ☆☆</h2><br><br>https://vimeo.com/131189623<br><br>Nice intro to Lean and FP, some nice points (e.g. <a href=\"/2015/06/17/why-do-companies-fail-at-adopting-functional-programming/\">why do companies fail in adopting FP</a>). A little new stuff for me; it wasn't a waste of time but perhaps I could have seen a more valuable talk.<br><br><h2>A tour of the language landscape ☆☆</h2><br><br>https://vimeo.com/131192406<br><br>It's interesting to learn about various cool capabilities of other languages. But it is more useful as an inspiration, there is little you can start using in your daily work. The <a href=\"http://www.slideshare.net/theburningmonk/tour-of-language-landscape\">slides</a> are worth going through.<br><br>Covered:<br><br><ul>\n<li>F#: Pipes (~ Clojure threading macro), Type Providers (e.g. get autocompletion, compile-time checks for browsing your Amazon S3 bucket), Unit-of-Measure (=&gt; <code>2 + 2</code> fails), Statically Resolved Type Parameters</li>\n<li>Clojure: Macros</li>\n<li>Go: Implicit Interface Implementation (define an interface with a method; everything having the method autom. implements it, no need to tag those (which would be impossible for 3rd party code) =&gt; type safety and convenience)</li>\n<li>Rust: Borrowed Pointers (autom. memory management without GC overhead - a piece of code owns a pointer =&gt; destroyed when the scope is left but can \"borrow\" it to code (of not longer scope) that it calls)</li>\n<li>Erlang: Actor Model, Bit Syntax</li>\n<li>Idris: Dependent Types, Uniqueness Types</li>\n<li>Elm: Signals (reactive programming (Rx))</li>\n</ul><br><br>Also: <a href=\"/2015/06/17/example-functional-reactive-programming-decisively-beats-imperative-on-simplicity-length/\">Example: Functional Reactive Programming decisively beats Imperative on simplicity, length</a><br><br><h2>Async and Streaming JavaScript, We're All Doing it Wrong! ☆☆☆</h2><br><br>https://vimeo.com/131196784<br><br>Useful. Highlights limitations of / issues with Promises and (Node, WHATWG Streams). Demonstrates how Reactive Programming (e.g. RxJS) is a superior solution. About the coming inclusion of (some of) Rx in JS.<br><br>See <a href=\"/2015/06/17/ndc-async-and-streaming-javascript-were-all-doing-it-wrong-promises-streams-rx/\">NDC: Async and Streaming JavaScript, We’re All Doing it Wrong! (Promises, Streams, Rx)</a><br><br><h2>Learning from Haskell ☆☆☆</h2><br><br>https://vimeo.com/131409651<br><br>Venkat Subramaniam is a skilled speaker. This was fun and enriching look at what we can learn from Haskell and hopefully use in our daily programming even if we use C#.<br><br>See <a href=\"https://twitter.com/HolyJak/status/611171678559817728\">list of the lessons learned</a>.<br><br><h2>50 Shades of AppSec ☆☆☆</h2><br><br>https://vimeo.com/131411406<br><br>Fun, scary. Examples of some hacks, surprisingly terrible security at many places, demo of tools that hack a site for you. Recommended as an eye opener to the importance of security.<br><br>Included:<br><br><ul>\n<li>Bishop:\n&gt; Bishop is a vulnerability scanner that searches websites in the background while you browse, looking for exposed version control systems, misconfigured administrative tools, and more. With a whitelisting regex system, you can easily restrict this tool to hosts that you are authorized to scan.</li>\n<li>Havij: Find &amp; elverage SQL injection vulnerabilities automatically</li>\n<li>Hire a hacker on-line: https://hackerslist.com/</li>\n</ul><br><br><hr /><br><br><h2>Idioms for building distributed fault-tolerant applications w/ Elixir ☆☆</h2><br><br>https://vimeo.com/131631884<br><br>A light introduction to the Erlang VM and Elixir.<br><br>FP:<br><br><ul>\n<li>Explicit over implicit state</li>\n<li>Transformation over mutation</li>\n</ul><br><br>Elixir is a distributed &gt; concurrent &gt; FP lang (in the order of importance).<br><br>Elixir goals: Compatibility, Extensibility =&gt; macros, Productivity.<br><br><ul>\n<li>Productivity: 1st class docs, tooling (ExUnit, IEx, Mix), hex packages</li>\n</ul><br><br>Demo: Agents, pattern matching, tools, supervision, streams (=&gt; lazy computations), ... .<br><br><h2>Event Sourcing and DDD with F# ☆</h2><br><br>https://vimeo.com/131632601<br><br>After a brief introduction of E.S. (without going into why/when), the speaker presented E.S. as two functions (decide, evolve) and went on implementing a simple card game in F# using that. Cool: Own given-when-then test \"framework\" in just few lines of code. The talk concluded with demonstration of plugging in an actual <a href=\"https://geteventstore.com/\">Event Store </a> server and <code>load</code> + <code>save</code> functions and using an Agent to hold the current state.<br><br><pre><code>\nCommand + [state]: (decide) -&gt; event(s) -&gt; store them, evolve the state\n^--------------------------------------------/\n</code></pre><br><br><code>decide: fn(state, command) -&amp;gt; Events</code>\n<code>evolve: fn(initial state, state, Event) -&amp;gt; state</code><br><br>A little too low-level both on F# and even sourcing but OK to follow on the some-understanding level. My main lesson learned is that F# looks nice, concise, powerful. And FP is certainly a good match for E.S.<br><br><h2>Phoenix - a framework for the modern web ☆☆</h2><br><br>https://vimeo.com/131633172<br><br>Elixir with Phoenix (and Plug) =&gt; Performance and Productivity.<br><br>The most frequent quote:<br><br><blockquote>\n  It's just a function call\n</blockquote><br><br><ul>\n<li>Request lifecycle: Endpoints -&gt; Routers -&gt; Controllers</li>\n</ul><br><br>Productivity<br><br><ul>\n<li>Middleware = just functions =&gt; compositions</li>\n<li>Helpful errors (and web view); \"if you can't understand an error, it's a bug\"</li>\n<li>Just mix in the comments generator to enable comments in the page and add the\ngenerated controller to your pipeline</li>\n<li><code>mix ecto.migrate</code> =&gt; data migrations</li>\n<li>static assets with Brunch (Node; combine, minify, watch for changes, ...)</li>\n<li>ES6 transpiler included</li>\n<li>live reload (html, css, ..)</li>\n</ul><br><br>Performance<br><br><ul>\n<li>Under-1ms response times</li>\n<li>Views and templates: precompiled, fast, function calls. Views render templates (embedded elixir, HAML, or another). Thx to metaprogramming, <code>render</code> becomes just string concat. at runtime.</li>\n<li>Ex.: <a href=\"https://onfido.com/blog/using-cpus-elixir-on-raspberry-pi2/\">Phoenix on RaspberryPi</a> (16MB mem, 540req/s serving a simple HTML)</li>\n<li>Robust concurrency model - extremely lightweight processes ( no global pauses; load balances on IO and CPU</li>\n<li>Pattern-matched route dispatch, the VM is very fast at it (Note: Convenience fn to get route for a controller/... =&gt; metaprogramming posibilities)</li>\n<li>Channels (Pub/Sub): trivial realtime communication (for connected devices) - WebSockets with minimal code Clients for the browser (fall-back to long-polling), for Objective-C, eventually Android. Embedded devices: <a href=\"https://en.wikipedia.org/wiki/Constrained_Application_Protocol\">CoAP</a> instead of WS. Can use Redis, ... . Synchronous0like communication possible; JS ex.: <code>chan.push(..).receive(\"ok\", okFn).receive(\"error\", errFn)</code>.</li>\n<li>Distributed cluster support (that's what Erlang always did with multiple communicating switches)</li>\n<li>Everything is a separate process =&gt; one channel crashing cannot harm other channels.</li>\n</ul><br><br>Ex.: <code>Chat.Endpoint.broadcast(\"rooms:lobby\", \"new_msg\", %{username: \"me\", body: \"hello\"})</code> =&gt; all connected clients receive it, no matter whether local or remote.<br><br><ul>\n<li>Erlang: Erlang handles 1/2 of the world's telecom traffic. Reported 99.999999999% availability.</li>\n<li>WhatsApp: 2M conn/server; 400M users, 30 engineers</li>\n<li>Update your code while the app is running! Apps that run forever.</li>\n</ul><br><br><a href=\"https://github.com/h4cc/awesome-elixir\">Awesome Elixir: A curated list of amazingly awesome Elixir and Erlang libraries, resources etc.</a><br><br><h2>The Power and Practicalities of Immutability ☆☆☆☆</h2><br><br>https://vimeo.com/131635253<br><br><blockquote>\n  In F#, <code>mutable</code> is the keyword of shame.\n</blockquote><br><br>Immutability (assignment-less programming where mutation is replaced by transformation) doesn't remove mutation it just pushes it to lower-level code - the same we did with <code>goto</code>, which disappeared from our code but still is in the bytecode/asm/.. .<br><br><blockquote>\n  Assignment is to Functional Programming as <code>goto</code> is to Structural Programming.\n</blockquote><br><br>How to program w/o assignments:<br><br><ul>\n<li>Recursion; cons:</li>\n<li>It can blow up the stack (tail-cole optim.)</li>\n<li>Some problems do not fit it naturally</li>\n<li>Move mutation to lower level =&gt; build from a higher-level, safe building blocks;\nEx.: for loop -&gt; <code>list.Select(e =&amp;gt; e*2)</code></li>\n</ul><br><br>The problems<br><br><ul>\n<li>Mutability</li>\n<li>Hard to reason about the code (especially if multiple variables)</li>\n<li>Difficult to manage state transitions; concurrency difficult;</li>\n<li>Imperative progr. (e.g. a for-loop)</li>\n<li>I need to say both what and how to do (like a toddler - fun on the 1st day, not the other 18 years :-))</li>\n<li>Mutating variables all the time</li>\n</ul><br><br>Benefits of immutability (and pure functions)<br><br><ul>\n<li>easy to reason, understand, explain, test</li>\n<li>memoization</li>\n<li>referential transparency (it's possible to replace a call with its result) =&gt; optimizations (exec. reordering, running concurrently, memoization, ..)</li>\n<li>immutability enables laziness (e.x: <code>{1,2,3,4}.Where(e =&amp;gt; e &amp;gt; 3).Where(e =&amp;gt; e % 2 == 0).Select(double).firstOrDefault()</code> - all the checks and the doubling are only executed 0-3 times)</li>\n<li>immutability makes parallelization affordable</li>\n</ul><br><br>Notes<br><br><ul>\n<li>Examples in C#, F#</li>\n<li>Ex.: sum, double a list, ...</li>\n<li>\"Encapsulation\" = \"I don't care\" :)</li>\n</ul><br><br><h2>How to turn software into competitive business advantage ☆☆☆☆</h2><br><br>https://vimeo.com/131637103<br><br>Gojko Adzic is my favourite speaker, with many good thoughts (and experiences).<br><br><blockquote>\n  Continuous delivery has huge side-effects. Exploit them and open new business opportunities.\n  \n  Fast is good when there is human control over it - when business people have no say in what gets updated when, they loose control (and are unhappy).\n</blockquote><br><br><ul>\n<li>Can we control C.D. or are we loosing control of it?</li>\n<li>Ex.: Vehicle charger =&gt; possible fire: for Tesla it was just an over-night automatic software update contrary to GM that had to recall the cars.</li>\n<li>Marketing side-effect of C.D.: No more big releases to have press conference about</li>\n<li>C.D. is important for devs but we don't want to piss off users</li>\n<li>UX: CD (i.e. partial delivery) =&gt; user confusion</li>\n</ul><br><br>Gojko's 3 rules<br><br>C.D. nay not ...<br><br><ol>\n<li>confuse users</li>\n<li>interrupt users' work of sessions</li>\n<li>disrupt or prevent marketing initiatives</li>\n</ol><br><br>Deployment != Release<br><br><ul>\n<li>Release is a marketing event, biz decides.</li>\n<li>We need to support running multiple versions of the SW in production (so current users are not interrupted, biz may decide when to switch over)</li>\n<li>Problem: data. Ex. solution: add data (format) version field</li>\n<li>Gentle deployment: Release a new version in || to the old one, enable (and motivate) users to switch at will while preserving the ability to go back (if they encounter any issues ...)</li>\n</ul><br><br><blockquote>\n  Continuous Delivery without multi-versioning is irresponsible!\n</blockquote><br><br>2 things to remember:<br><br><ul>\n<li>Decouple deployment and release</li>\n<li>Give 2% of users a 100% solution, do not force-feed 100% users with 2% of scope</li>\n</ul><br><br><h2>Modern architectural patterns for the cloud</h2><br><br>https://vimeo.com/131637608<br><br>Perhaps not a bad overview of various patterns (DB replication, sharding; CQRS, event sourcing, map reduce). Too little knew at start and then I lost focus :)<br><br><hr /><br><br><h2>Get Unblocked (unleash your creativity) ☆☆☆</h2><br><br>https://vimeo.com/131640717<br><br>Fun, inspiring. Good tips for overcoming our internal barriers to creativity (and a happier life). <a href=\"http://creativedo.se/ndcoslo-gu\">Slides</a>. <a href=\"http://denisejacobs.com/projects/banishing-your-inner-critic/\">Book: Banish Your Inner Critic</a>.<br><br><blockquote>\n  The entire industry is broken - managers are from Mars, developers from Venuse. Micromanagement, open spaces / cubicles, time pressure, demanding clients, bureaucracy, ... .\n</blockquote><br><br><ul>\n<li>Face and ID your internal critic</li>\n<li>Impostor syndrom (\"I don't deserve this, I am not good enough for it\")</li>\n<li>Don't compare yourself to other people</li>\n<li>Perfectionism (focus on the product rather than the creative process)\n(Pottery exp.: 1/2 tries to make the best pot, 1/2 as many as possible =&gt;\nthe latter had more and many really good.)</li>\n<li>Procrastination (feeds Perf. and v.v.)</li>\n<li>Banish slave words from your vocabulary - Eliminate should/must/ought to/...</li>\n<li>\"Failure is only the opportunity to begin again more intelligently.\" H. Ford</li>\n<li>Stressed? Make it really bad on purpose =&gt; overcome the block of trying to be perfect.</li>\n<li>Get into the <a href=\"http://www.meditations-uk.com/images/information/brain_waves.jpg\">Alpha brain waves mode</a> (more relaxed than the normal beta)</li>\n<li>Breath to re-focus</li>\n<li>Lay down</li>\n<li>Daydream / space out</li>\n<li>Take shower</li>\n<li>Get physical - movement allows the hemispheres to sync, ...</li>\n<li>Exercise discipline</li>\n<li>Manage time (if stressed =&gt; no place for creativity)</li>\n<li>Make \"To DON'T\" lists - what not to do (stop, delegate, ...)</li>\n<li>Say NO to distractions (see http://theheadphonesrule.com/)</li>\n<li>Apps: Consider the <a href=\"https://www.rescuetime.com/\">RescueTime</a> app =&gt; increase awarness; Mac: <a href=\"https://heyfocus.com/\">HeyFocus.com</a> when on, stops you from going to distractive pages and apps; GetConcentrating.com; browser extensions, .. - see the slide</li>\n<li>Single-task (instead of multi-tasking) - e.g. the <a href=\"http://pomodorotechnique.com/\">Pomodoro Technique</a>; especially useful when you do something you don't like to do (during the 5 min break activate via a walk, laying down, having a look at the sky, ...)</li>\n<li>Do it with others - we come up with better / different things when working with others. Avoid sameness! =&gt; diverse environments. Share your ideas. Share mistakes. Amplify the ideas of others - try to help them to build them. Make your partned look good.</li>\n<li>\"Yes, and ..\" technique (useful for meetings!) - don't shut down others' ideas - \"yes, we can do this - and we can do this other thing\"</li>\n</ul><br><br>Fear:<br><br><blockquote>\n  F.alse\n  E.vidence\n  A.ppearing\n  R.eal\n  \n  (Or Fuck Everything And Run)\n</blockquote><br><br>Watch:<br><br><ul>\n<li><a href=\"http://www.ted.com/talks/charles_limb_your_brain_on_improv?language=en\">TED: Charles Limb: Your brain on improv</a> - ?neurological view on creativity.</li>\n<li><a href=\"http://www.ted.com/talks/amy_cuddy_your_body_language_shapes_who_you_are?language=en\">TED: Amy Cuddy: Your body language shapes who you are</a></li>\n</ul><br><br><h2>A security testers toolkit ☆☆☆☆</h2><br><br>https://vimeo.com/131641274<br><br>Awesome! Scary! You have to see this! This is a real eye opener, demonstrating how easy hacking can be (especially with cooperating users via little social engineering).<br><br><blockquote>\n  You can only fight the way you practice - Miyamoto Musashi\n</blockquote><br><br>Tools<br><br><ul>\n<li>Kali Linux</li>\n<li><code>nmap</code> (network mapper)</li>\n<li>Veil fwrk - avoid anti-virus</li>\n<li>Metasploit</li>\n<li><a href=\"http://beefproject.com/\">BeEF</a> - The Browser Exploitation Framework</li>\n</ul><br><br>Vulnerabilities<br><br><ul>\n<li>To find: https://cve.mitre.org/ - more info at the web.nvd.nist.gov (linked)</li>\n<li>To exploit: https://www.exploit-db.com/</li>\n<li>To find possible targets: <a href=\"https://www.shodan.io/\">shodan.io</a> - search by SW (e.g. \"IIS 6.0\") and <a href=\"https://www.punkspider.org/\">punkspider</a> - search for vulner. in a given site or domain: \".no\". <a href=\"http://www.bishopfox.com/resources/tools/google-hacking-diggity/attack-tools/\">Search Diggity</a> - incl. Google Hacking DB - also a good learning source about vulnerabilities (what does it search for?)</li>\n</ul><br><br>Kali Linux<br><br><ul>\n<li><a href=\"https://www.offensive-security.com/kali-linux-vmware-arm-image-download/\">Kali Linux VMs</a></li>\n<li>Many hacking tools</li>\n<li>Demo (see <a href=\"http://www.computersecuritystudent.com/SECURITY_TOOLS/METASPLOITABLE/EXPLOIT/lesson8/\">exploiting vsftpd</a>):</li>\n<li>Run against <a href=\"http://sourceforge.net/projects/metasploitable/\">Metasploitable is an intentionally vulnerable Linux virtual machine</a></li>\n<li>Zenmap: GUI for <code>nmap</code></li>\n<li>Metasploit - provides an interactive shell; need to know the exploit: <code>use exploit/unix/ftp/vsftpd_234_backdoor; set RHOST ; exploit</code></li>\n<li>Wifi hacking</li>\n<li><a href=\"http://www.blackmoreops.com/2014/01/08/recommended-usb-wireless-cards-kali-linux/\">Use a wifi card enabling monitoring, compatible with Kali</a> - e.g. one of the Alpha cards</li>\n<li><a href=\"http://www.aircrack-ng.org/\">Aircrack-ng</a> - WPA-PSK keys cracking program</li>\n<li>airmon-ng =&gt; start the device in monitor mode, list devices around, ...</li>\n<li>WPS (Wi-Fi Protected Setup) is <a href=\"http://www.howtogeek.com/176124/wi-fi-protected-setup-wps-is-insecure-heres-why-you-should-disable-it/\">very crackable</a></li>\n<li><a href=\"https://github.com/SilverFoxx/PwnSTAR\">PwnSTAR</a> - soft access point - set up an AP, nmap scan clients, ...</li>\n<li><a href=\"http://www.fastandeasyhacking.com/\">Armitage</a> - GUI - if nmap, metasploit complicated, this is a nice, visual representation of the network and vulnerabilities on it; scan net -&gt; scan a host -&gt; \"Attacks - Find Attacks\" (Hail Mary - lunches 100s of exploits, not stealthy at all). Also a paid version Cobalt Strike, more powerful.</li>\n<li>BeEF - hook into a website, take over a browser =&gt; detect extensions, send commands to them, metasploit, social eng. attacks, ... Send fake flash/java/last pass update, petty theft - \"facebook session timed out\" popup (e.g. on any site with Fb integration), a Clippy help offer, ... .</li>\n<li><a href=\"https://www.veil-framework.com/\">Veil</a> - SW avoidance toolkit - generate payloads against machines, take them over - create f.ex. a \"call home\" .exe (connects to your metasploit server later command the app and take over the PC) (call it e.g. LastPassUpdate.exe, FlashUpdate.exe, ...)</li>\n<li><code>load espia; screengrab; keyscan_start; keyscan_dump;</code> <code>getsystem</code> =&gt; elevate to local admin; <code>load incognito; add_user XYZ myPsw; add_localgroup_user Administrators XYZ</code></li>\n</ul><br><br><a href=\"https://github.com/byt3bl33d3r/MITMf\">Framework for Man-In-The-Middle attacks</a> - =&gt; <a href=\"https://sathisharthars.wordpress.com/2015/02/27/bypassing-hsts-http-strict-transport-security-with-mitmf/\">Bypassing HSTS (HTTP Strict Transport Security) with MITMf</a> - downgrade the connection to HTTP\n* The PC with MITMf makes itself to be the gateway for the victim PC\n* Tip: <code>http://wwww.google.com</code> - can YOU spot the 4th w?; skandiabanken.no =&gt; webskandiabanken.no\n* Only works if the user hasn't accessed the page before in this browser, cookies and HSTS list are clear (wifi coffees &amp; online banking = bad!)<br><br><h2>Going beyond OWASP ☆☆</h2><br><br>https://vimeo.com/131642364<br><br>Walk through some past vulnerabilities in .NET. Some really nice hacks. Likely worth watching.<br><br>Few interesting examples:<br><br><ul>\n<li><a href=\"http://www.anchor.com.au/blog/2012/12/how-to-explain-hash-dos-to-your-parents-by-using-cats/\">HashDoS attack</a> due to consistent hashing, putting all form fields starting with the same latter to the same bucket (common in other languages too)</li>\n<li>When encrypting, also sign it so that when you get an encrypted stuff back, you're sure you did indeed produce it (there was an endpoint allowing to check whether st. is properly encrypted =&gt; play with bytes and high math to encrypt st. w/o the key)</li>\n<li>Misusing REST - constructing URLs from user input =&gt; make sure the input does not contain path (e.g. user = \"./admin\"), query strings, # chars, anything else affecting the path - basically 0-9a-Z</li>\n<li>in Turkey, \"interesting\".ToUpper() != \"INTERESTING\"; ppl make security decisions based on string comparison (.NET: string.Compare(a,b, ))</li>\n<li>Unicode has \"full width\" chars: ＜ (＜); when put into SQL varchar, it becomes normal \" don't use non-unicode columns to store Unicode</li>\n<li>Common cryptographic mistakes: e.g. key / init.vector reuse (=&gt; larger attack surface). Writing own crypto.</li>\n<li>Hashing concat. strings - but hash(builtin+securely) == hash(built+insecurely) =&gt; do len(builtin) + hash(builtin) + len(securely) + hash(securely)</li>\n<li>Cert pining - do; checking the thumbprint is fragile, check the signing chain, subject name too</li>\n<li>Time-incons. hashing =&gt; timing attacks =&gt; don't do early exit (when (mis)match found)</li>\n<li>MVC in web apps with auto-binding data to objects assign even properties that normally are not in the form (but added by a hacker), e.g. ID - \"over-binding\"</li>\n<li>Don't trust file names from uploads</li>\n<li>Zip bombs - tiny file which recursively uncompress; e.g. 42.zip (42kB) =&gt; 4.5 petabytes</li>\n<li>XML bombs - e.g. <a href=\"https://en.wikipedia.org/wiki/Billion_laughs\">Billion Laughs</a>; preventable by turning of DTD Parsing</li>\n</ul><br><br><h2>Making Hacking Child’s Play ☆</h2><br><br>A fun talk though it contained only little new after being to Troy's workshop and the other talk.<br><br><ul>\n<li><a href=\"http://map.ipviking.com/\">Live DDOS attacks map</a></li>\n<li>Script kiddies with many twitter followers using <a href=\"https://en.wikipedia.org/wiki/Low_Orbit_Ion_Cannon\">Low Orbit Ion Cannon</a> =&gt; DDOS</li>\n</ul><br><br><h2>Knowledge is power! The guide to measure what matters. ☆</h2><br><br>https://vimeo.com/131644108<br><br>Essentially an intro into StatsD. I had to leave early.",
  "excerpt": ""
 },
 {
  "title": "Book Review & Digest: Release It! Design and Deploy Production-Ready Software",
  "published": "2015-07-22 06:36:15",
  "postType": "post",
  "slug": "/2015/07/22/book-review-digest-release-it-design-and-deploy-production-ready-software/",
  "status": "publish",
  "tags": [
   "architecture",
   "book",
   "ops",
   "performance"
  ],
  "categories": [
   "[Dev]Ops"
  ],
  "content": "By Michael T. Nygard, 2007, ISBN: 978-0-9787-3921-8<br><br>My digest and review of the book.<br><br><h1>Review</h1><br><br>Of the books I have read, <a href=\"https://pragprog.com/book/mnee/release-it\">Release It!</a> is the one I would require all \"senior\" developers to read (together with something like <a href=\"http://eu.wiley.com/WileyCDA/WileyTitle/productCd-0470856122.html\">Architecting Enterprise Solutions: Patterns for High-Capability Internet-based Systems</a>). Especially the first part on stability with its patterns and anti-patterns is a must read. Without knowing and applying them, we create systems that react to problems like a dry savannah to a burning match. I found also to next to last chapter, #17 Transparency, very valuable, especially the metrics and design of the OpsDB and observation practices.<br><br>One thing I have left out of the digest which is really worth reading are the war stories that introduce each section, they are really interesting, inspiring, and educational.<br><br><h1>Extra Links</h1><br><br><ul>\n<li>Release It! slides: http://gotocon.com/dl/jaoo-sydney-2009/slides/MichaelT.Nygard_FailureComesInFlavoursPart2.pdf</li>\n<li>https://github.com/Netflix/Hystrix/</li>\n<li>Netflix's Dependency Command talks about using circuit breakers and a thread pool limit http://techblog.netflix.com/2012/02/fault-tolerance-in-high-volume.html</li>\n<li><a href=\"https://msdn.microsoft.com/en-us/library/dn600223.aspx\">MSDN Guidance for Cloud Applications: Design Patterns</a> - Circuit Breaker and many more highly useful patterns</li>\n</ul><br><br><h1>Stability</h1><br><br>Stability x longevity bugs<br><br><img class=\"wp-image-4449 size-large\" src=\"/images/2015/07/releaseit-patterns.jpg?w=660\" alt=\"ReleaseIt-patterns\" width=\"660\" height=\"465\" /> Selected (anti)patterns<br><br><h2>Stability antipatterns</h2><br><br><h3>Integration points</h3><br><br>Integration point = call to a DB, WS, ... . Stability risk #1.<br><br><!--more--><br><br><ul>\n<li>Every will eventually fail</li>\n<li>Many possible errors: network, application, ...</li>\n<li>Symptomps: protocol violation, slow response, hang, abruptedly closed connections, ...</li>\n<li>Be defensive to prevent cascading failures when the remote system is having problems - Circuit Breaker, Timeouts, Decoupling Middleware, Handshaking; use Test Harness to test</li>\n<li>Ex.: connections refused (catch: it can take a <em>long</em> time to find out that you cannot connect, f.ex. when it is listening but unable to process requests or when ACKs do not arrive and it keeps on retrying); a firewall may throw away an old connection without telling anyone, silently dropping packets</li>\n</ul><br><br><h3>Chain Reactions</h3><br><br>Load-balanced application with a defect (typically resource leak or load-related crash). If the defect is triggered in one instance and it fails, the remaining ones are the more likely to fail (increased load, ...). Bulkheads can help by splitting nodes into separate sets with separate, smaller chain reactions occuring hopefully at different times. Can lead to a cascading failure in a calling layer.<br><br><ul>\n<li>One server down jeopardizes the rest</li>\n<li>Hunt for resource leaks</li>\n<li>Hunt for obscure timing bugs - traffic can trigger obscure race conditions; if a deadlock kills a server then increased load on the remaining ones is more likely to trigger it as well</li>\n<li>Defend with Bulkheads, use Circuit Breaker on the caller's side</li>\n</ul><br><br><h3>Cascading Failures</h3><br><br>= problems in one layer cause problems in callers - often due to drained resource pools<br><br><ul>\n<li>Be paranoid about Integration Points</li>\n<li>C.F. often results from a resource pool that gets exhausted when threads check out the resource and get blocked because their call never returns and other threads wait for the resource. A safe resource pool should always limit the time a thread can wait to check out a resource.</li>\n<li>A Circuit Breaker protects your system by avoiding calls out to the troubled Integration Point, using Timeouts ensures that you can come back from a call out to the troubled one</li>\n</ul><br><br><h3>Users</h3><br><br><ul>\n<li>Users consume memory =&gt; minimize session size, use session only for caching so that you can purge its content if memory gets tight (and re-create when needed again). F.ex. in Java use SoftReferences. Beware that session lives until last interaction + timeout, which defaults to 30 min (multiply that by too many users ...)</li>\n<li>Users do weird, random things, don't expect them to behave as you expect; if there is a weak spot, they'll find it</li>\n<li>Malicious users are out there - keep up-to-date, prevent SQL injection etc.</li>\n<li>Sometimes users come in really, really big mobs =&gt; hangs, deadlocks, obscure race conditions; run special stress tests to hammer deep links or hot URLs</li>\n<li>Beware artificial users such as bots and indexing spiders - they do many requests in no time, may ignore cookies (=&gt; each one results in a new session)</li>\n</ul><br><br><h3>Blocked Threads</h3><br><br><ul>\n<li>f.ex. When checking out resources from a connection pool, dealing with caches or object registries, making calls to external systems,or synchronizing threads</li>\n<li>The Blocked Threads pattern is the proximate cause of most failures; the lead to Chain Reactions and Cascading Failures</li>\n<li>Scrutinize resource pools – threads often blocked on them; f.ex. a deadlock in a DB or incorrect exception handling (and thus a failure to release a connection)</li>\n<li>Use proven primitives for concurrency instead of creating your own (see <code>java.util.concurrent</code>)</li>\n<li>Defend with Timeouts so that no deadlock lasts forever – always use them</li>\n<li>Beware the code you cannot see – f.ex. in libraries</li>\n</ul><br><br><h3>Attacks of Self-Denial</h3><br><br>Ex.: An email from marketing to a selected user group with a special deal – which they will share further and suddenly the page if flooded by users. All servers waiting to acquire a lock to update the same, popular item (=&gt; prefer shared-nothing architecture or at least apply decoupling middleware or make the shared resource itself horizontally scalable through redundancy and a synchronization protocol).<br><br><ul>\n<li>Be informed – make sure that if there is a marketing campaign, you know about it. Make sure it doesn't use deep links (bypassing your caching proxy), watch our for embedded session Ids in URLs. Create a static “landing zone” pages for the first click from these offers.</li>\n<li>Protect shared resources in the case of traffic surges. Watch out for increased front-end load causing exponentially increasing back-end processing.</li>\n<li>Expect rapid redistribution (i.e. spreading wide and far) of any cool or valuable offer – there is no such thing as distribution to a limited user set</li>\n</ul><br><br><h3>Scaling Effects</h3><br><br>Something that worked in small scale leads to problem when the system is scaled up. Whenever we have a many-to-one or many-to-few relationship, we might run into problems when the “more” side increases, f.ex. the DB may crash when going from 2 AS – 1 DB to 10 AS – 1 DB. A common problem is point-to-point communication.<br><br><ul>\n<li>Examine scale differences between production and QA environments to spot Scaling Effects – patterns that work fine in small environments or one-to-one environments might slow down or fail completely when you move to production sizes</li>\n<li>Watch out for point-to-point communication – it scales badly since # connections increases as the square of participants</li>\n<li>Watch out for shared resources – they can be a bottleneck, a capacity constraint, and a threat to stability. If you have one, stress test it heavily. Make sure its clients will keep working if it gets slow or locks up.</li>\n</ul><br><br><h3>Unbalanced Capacities</h3><br><br>U.C. is a special case of Scaling Effects: one side of a relationship scales up much more than the other side. Ex.: Many web servers that typically serve mostly static content and only few dynamic pages provided by back-end servers; if the traffic pattern (workload) suddenly changes, i.e. many users coming to the dynamic functionality, the front-end servers will flood the few back-end ones. It might be impractical to match their capacities for rare spikes so build them both to be resilient in the face of a tsunami of requests. For the front-end, Circuit Breaker will help by relieving the pressure on the back-end when responses get slow or connections get refused. For the back-end, use Handshaking to inform the front-end to throttle back on the requests. Also consider Bulkheads to reserve capacity on the back-end for other transaction types.<br><br><ul>\n<li>Examine, compare server and thread counts, especially in Prod vs. QA</li>\n<li>Observe near scaling effects and users</li>\n<li>Stress both sides of the interface; if you hammer the back-end with 10* more requests than historical max on its most expensive transaction, does it fail or slow down and eventually recover? What does the front-end do when the back-end stops responding or gets very slow?</li>\n</ul><br><br><h3>Slow Responses</h3><br><br>Generating a slow response is worse than refusing a connection or returning and error as it ties up resources in both caller and callee. They usually result from excessive demand or due to an underlying problem, f.ex. memory leaks and the resulting garbage collection, network congestion.<br><br><ul>\n<li>Slow Responses triggers Cascading Failures, the upstream system will too slow down and become vulnerable to stability problems</li>\n<li>For websites, Slow Responses causes more traffic as users hit \"reload\"</li>\n<li>Consider Fail Fast - f.ex. if your SLA requires response in 100ms and a moving average over the last 20 calls exceeds it, you can start refusing requests (the upstream system must be prepared for that)</li>\n<li>Hunt for memory leaks or resource contention (f.ex. too few DB connections)</li>\n</ul><br><br><h3>SLA Inversion</h3><br><br>SLA Inversion = a system that must meet a high-availability SLA depends on systems of lower availability. But the best SLA you can provide is the one of your dependency with the worst SLA.<br><br>Solution: 1) Decouple from the lower SLA systems so that your app can continue functioning without them, degrade gracefully. Decoupling middleware is excellent for this. At least employ circuit breakers to protect from your dependencies. 2) Determine a realistic SLA and, instead of the whole system, focus on the availability of specific functions/features w.r.t. their dependencies.<br><br>Ex.: Allow customers to continue purchasing even when delivery scheduling isn't available.<br><br><ul>\n<li>For every service, your system depends on transport layer availability, naming services (DNS), and application-level protocols and any of these can fail.</li>\n<li>If built naively, the probability of failure of your system is the joint probability of a failure in any component or service so P(up) = (1 - P(internal failure)) * P(dependency 1 up) * ... * P(dependency N up). So for five dependencies with 99.9% availability we can get at most 99.5%.</li>\n</ul><br><br><h3>Unbounded Result Sets</h3><br><br>\"Design with skepticism, and you will achieve. Ask, 'What can system X do to hurt me?' and then design a way to dodge, duck, dip, dive, and dodge whatever wrench your supposed ally throws.\" p95 One of those systems is your DB - what if it suddenly returns 5M rows instead of the usual hundreds?<br><br><ul>\n<li>Use realistic, production-sized data volumes in testing/dev</li>\n<li>Don't rely on the data producers to create a limited amount of data</li>\n<li>Put limits into other application-level protocols: WS calls, RMI, XML-RPC, ... are all vulnerable to returning huge collections of objects, thereby consuming too much memory (and keeping on working long after the user has lost interest)</li>\n<li>Unbounded result sets are a common cause of Slow Responses; they can result from violation of Steady State</li>\n</ul><br><br><h2>Stability patterns</h2><br><br><h3>Use Timeouts</h3><br><br>Rarely you want to wait forever (or many minutes).<br><br><ul>\n<li>Apply to Integration Points, Blocked Threads, and Slow Responses; they prevent calls to I.Points from becoming Blocked T. and thus avert Cascading Failure.</li>\n<li>Combine with Circuit Breaker (trigger when too many) and Fail Fast (to inform your callers you are not able to process requests).</li>\n<li>Apply to recover from unexpected failures - when an operation is taking too long, we sometimes do not care why, we just need to give up and keep moving</li>\n<li>Consider delayed retries - the network or remote system problems causing them won't be resolved right away so immediate retries make it only worse and make the user wait even longer for the inevitable failure response.</li>\n</ul><br><br>HttpClient example: <code>RequestConfig.custom()\n.setConnectionRequestTimeout(1000).setConnectTimeout(1000).setSocketTimeout(1000).build();</code><br><br><h3>Circuit Breaker</h3><br><br>A Circuit Breaker wraps an Integration Point and works like a fuse, \"melting\" (opening) when a number of calls to the system fail or time out in a row, thus making subsequent request fail fast without consuming too much resources and easying load on the remote systems. Occassionally it lets a call through to check whether the system hasn't become responsive again.<br><br>It works great with graceful degradation, i.e. offering limited yet still useful functionality to users when a subsystem becomes unavailable.<br><br><ul>\n<li>Don't do it if it hurts - C.B. is the fundamental pattern for protecting your system from all manner of Integration Points problems. When there is a difficulty with them , stop calling them!</li>\n<li>Use together with Timeouts</li>\n<li>Expose, track, and report its state changes to Ops</li>\n</ul><br><br><a href=\"https://msdn.microsoft.com/en-us/library/dn589784.aspx\">MSDN's Circuit Breaker Pattern</a> page is pretty good. <a href=\"http://martinfowler.com/bliki/CircuitBreaker.html\">Martin Fowler's introduction of Circuit Breaker</a> with a simple example implementation in Ruby and useful links.<br><br>Impl. in Java with Spring AOP and JMX: https://code.google.com/p/jianwikis/wiki/CircuitBreakerDesignPattern, <a href=\"https://github.com/krukow/clojure-circuit-breaker\">Clojure implementation</a>.<br><br><h3>Bulkheads</h3><br><br>Bulkheads are water-tight compartments in a ship; when there is a hole, water floods only one compartment, saving the ship from sinking. Similarly you may partition your resources (servers etc.) and assign the partitions to particular clients/functions so that a failure doesn't affect all and/or more important functionality/clients are protected from failures triggered by less important ones. Physical redundancy is the most common form, protecting from HW failures. A small-scale example is binding a process to only a subset of CPUs. Inside of a process, you might create separate thread groups dedicated to different functions - f.ex. separate request-handling thread pool for administrative functionality. Ex.: A failure in flight status functionality won't stop check-in from working.<br><br><ul>\n<li>The Bulkheads pattern partitions capacity to preserve partial functionality when bad things happen</li>\n<li>The partitioning leads to less efficient use of capacity (but virtualization might mitigate that into an extent - move VMs between the partitions on demand)</li>\n<li>Pick a useful granularity - thread pools inside an app, CPUs in a server, or servers in a cluster</li>\n<li>Very important with shared services model, when many systems depend in your application; you don't want to bring them all down when Chain Reactions happen</li>\n</ul><br><br><h3>Steady State</h3><br><br>For every mechanism that accumulates a resource (data in a DB, log files, memory consumed by a cache), some other mechanism must recycle that resource.<br><br><ul>\n<li>Avoid fiddling - manual human intervention leads to problems; eliminate the need for recurring human intervention (disk cleanups, nightly restarts) through\nautomation</li>\n<li>Purge data with application logic - an application knows better than DBA how to purge old data while preserving consistency and its sanity (f.ex. w.r.t. ORM)</li>\n<li>Limit the amount of memory a cache can consume so that it doesn't cause problems</li>\n<li>Roll the logs - don't keep an unlimited amount of log files, configure log file rotation based on size</li>\n</ul><br><br><h3>Fail Fast</h3><br><br>If a system can determine in advance that it will fail in an operation, it's better to fail fast.<br><br><ul>\n<li>Avoid Slow Responses and Fail Fast - if you system cannot meet its SLA, inform the callers quickly without waiting for an error or timeout (&lt;&gt; Circuit Breaker)</li>\n<li>Reserve resources, verify Integration Points early - e.g. fail at once if a crucial CircuitBreaker is open</li>\n<li>Use for input validation - do basic user input validation even before you reserve resources not to waste them if f.ex. a required attribute is missing</li>\n<li>Ex.: Refuse a connection at once if there are already too many users in the system (=&gt; throttling to a manageable level so that we keep a reasonable level of service for the users already there)</li>\n</ul><br><br><h3>Handshaking</h3><br><br><ul>\n<li>signaling between devices that regulate communication between them; it protects the server by allowing it to throttle its own workload. Sadly, HTTP and RMI doesn't handshake well.</p></li>\n<li><p>Create cooperative demand control - use client-server handshaking for demand throttling to serviceable levels; both must be built to support it</p></li>\n<li>Conside health checks as an application-level workaround for the lack of H., use where the cost of an additional call is much less than the cost of calling and failing</li>\n<li>Build H. into your own low-level protocols</li>\n</ul><br><br><h3>Test Harness</h3><br><br><p>A test harness emulates the remote system of an Integration Point and can simulate many errors (network, protocol, application-level) to test most/all of the failure modes. \"A good test harness should be devious. It should be as nasty and vicious are real-world system will be.\" [126] \"The test harness should act like a little hacker, trying all kinds of bad behavior to break callers.\" [128]<br><br><ul>\n<li>A socket connection can be refused, sit in a listen queue until the caller times out, the remote end my reply with a SYN/ACK and then never send any data, it can send nothing but RESET packets, it may report a full receive window and never drain the data, the connection can be established, but the remote end never sends a byte of data, the conn.can be established but packets lost causing retransmit delays, conn.est. but the remote never ACK receiving a packet, causing endless retransmits, the service can accept a request, send response headers (supposing HTTP), and never send the response body; the srv can send 1 byte of the response every 30 sec; it can send HTML instead of the expected XML; it may send MB when kB of data expected; it can refuse all auth. credentials.</li>\n<li>Emulate out-of-spec failures</li>\n<li>Stress test caller - slow/no/garbage responses, ..</li>\n</ul><br><br><h3>Decoupling Middleware</h3><br><br>A well-done middleware integrates (by passing data and events) and decouples (by hiding specific knowledge, calls to other systems) systems.<br><br>Scale:<br><br>Same host, time, process<br><br><ul>\n<li>In-process method calls</li>\n<li>Interprocess communication (shared mem, pipes, semaphores, ..)</li>\n<li>RPC (RMI, HTTP, ..) // same time, diff. host and process</li>\n<li>Message Oriented Middleware (MQ, SMTP, SMS, ..)</li>\n<li>Tuple Spaces (Java/Giga/T Spaces)</li>\n</ul><br><br>Different time, host, process<br><br><ul>\n<li>Decide at the last responsible moment; this is an architecture decision that is expensive to change</li>\n<li>Avoid many failure modes though total decoupling (of servers, layers, applications)</li>\n<li>Learn many architectures, and choose among them</li>\n</ul><br><br><hr /><br><br>Quiz - what is wrong here:<br><br><pre><code>\ntry { ... }\nfinally {\nif (stmt != null) stmt.close();\nif (conn != null) conn.close();\n}\n</code></pre><br><br><ul>\n<li>stmt may rarely throw an exception and the conn will thus never be closed, leading to connection pool exhaustion</li>\n</ul><br><br><h1>Capacity</h1><br><br>User sessions are the Achilles heel - they consume memory, and, if replication enabled, CPU and bandwidth.<br><br>Load testing: real world isn't polite to the site. Search engine spiders may ignore cookies create a new session on each request (while generating many requests). Scrapers and shopbots do the same.<br><br>=&gt; don't test the system just the way it is meant to be used<br><br>Useful tools<br><br><ul>\n<li>If every request creates a session, verify the client handles cookies properly and send those who don't to a \"how to enable cookies\" page</li>\n<li>Capability to cap the number of requests to the system so that we can keep sessions below the crash limit</li>\n<li>Detect and block IPs, subnets etc. that create evil traffic</li>\n</ul><br><br><h2>Capacity</h2><br><br><ul>\n<li>Performance: how fast the sys processes a single transaction</li>\n<li>Throughput: # tx / a time span</li>\n<li>Scalability: 1) throughput as f(load); 2) how the systems can be scaled up by adding capacity</li>\n<li>Capacity: the max throughput the sys can sustain, for a given workload, while maintaining an acceptable response time for each individual tx (the workload may change radically e.g. when users are interested in different services during a particular season)</li>\n<li>Constraint: There is always one (current) constraint &lt;&gt; theory of constraints</li>\n</ul><br><br>Capacity myths: CPU, bandwidth, and storage are cheap.<br><br><h2>Capacity antipatterns</h2><br><br><h3>9.1 Resource Pool Contention</h3><br><br>\"Used well, [DB] connection pools, like all resource pools, can improve capacity by improving throughput. Left untended, however, resource pools can quickly become the biggest bottleneck in an application.\" [167] - when there is contention for the resource , i.e. less than needed available; the requesting thread is then blocked indefinitely. Also, each connection - even whine idle - consumes resources on the remote system.<br><br><ul>\n<li>Eliminate Contention under normal load</li>\n<li>If possible, size resource pools to the request thread pool</li>\n<li>Prevent vicious cycles: contention =&gt; tx take longer =&gt; more contention</li>\n<li>Watch for the Blocked Threads pattern (capacity =&gt; stability issues)</li>\n</ul><br><br><h3>Excessive JSP fragments</h3><br><br><h3>AJAX Overkill</h3><br><br>Ajax = many more requests coming from the browser to the server, more rapidly. The req and resp will typically be smaller. Used poorly, it will place more burden on the web an app servers.<br><br>Session thrashing - ensure session affinity so AJAX req go to the server having the user's session. Make sure you don't create a new session for each req.<br><br><h3>Overstaying Sessions</h3><br><br>How long a session stays in mem after the last req (as we have now way of knowing the user went away for good) - defaul(ed) to 30min in Java. Look at your data to determine session timeout: e.g. avg + 1 std dev. In practice it will be ~ 10 min for a retail site, 5 min for a media gateway, up to 25 for travel-industry sites. Even better is to make sessions unnecessary. F.ex. in-mem copy of persistent data may be dropped and recreated at any time (keep keys, not whole objects).<br><br><h3>Wasted space in HTML</h3><br><br>Every byte consumes bandwidth, memory, processing resources on different networking equipment and the servers. Omit needless characters, remove whitespace, replace HTML tables with CSS layout.<br><br><h3>The Reload button</h3><br><br>If the site is slow, users may start hitting Reload in hope of getting a presumabely stuck response, thus increasing the load even more. (The app server doesn't know it should stop processing the previous one.) Make your site fast so that users never think of doing this.<br><br><h3>Handcrafted SQL</h3><br><br>ORM =&gt; predictable, repetitive SQL. Predictable access patterns of SQL are good for capacity, b/c a competent DBA can tune the DB for them. OO developers suck at relational queries and create expensive queries inconsistent with the tuning for the rest of the app.<br><br>Common problems: joins on non-indexed columns, joining too many tables, .. .<br><br>=&gt; minimize, check with a DBA, verify gains against real data.<br><br><h3>DB Eutrophication</h3><br><br><ul>\n<li>slow buildup of sludge that eventually kills it</p></li>\n<li><p>Create indexes</p></li>\n<li>Purge sludge = old data (mv from prod servers elsewhere, ...)</li>\n<li>Keep reports out of Prod</li>\n</ul><br><br><h3>Integration Point Latency</h3><br><br><p>Calling a remote point takes time + its processing time, don't ignore that. A performance issue at first may become capacity issue of the whole system. Avoid chatty remote protocols.<br><br><h3>Cookie Monsters</h3><br><br>=&gt; keep cookies small; they're sent with every request.<br><br><h2>Capacity Patterns</h2><br><br><h3>Pool Connections</h3><br><br>Use &amp; remember to protect callers from blocking forever. Size them for max throughput.<br><br><h3>Use Caching Carefully</h3><br><br>Limit cache sizes. Build a flush mechanism. Don't cache trivila objects. Compare access and change frequency.<br><br><h3>Precompute content</h3><br><br>Not everything needs to be dynamic and even not all the dynamic stuff changes equally often.<br><br><h3>Tune the garbage collector</h3><br><br>\"In Java applications, garbage collection tuning is the quickest, and easiest way to see some capacity improvements. An untuned application running at production volumes and traffic will probably spend 10% of its time collecting garbage. That should be reduced to 2% or less.\" [205] (Remember this was written in 2007.)<br><br><h1>PART IV General Design Issues</h1><br><br><h1>11. Networking</h1><br><br>Topics: Multihomed servers, getting routing right, virtual IP addresses.<br><br><h1>12. Security</h1><br><br>Topics: The Principle of Least Privilege (separate user/app, ...), Configured Passwords (separately in encrypted files, ...).<br><br><h1>13. Availability</h1><br><br>Gathering and documenting requirements (refer to these whenever responsible for defining availability!), load balancing, reverse proxying, clustering .<br><br><h1>14. Administration</h1><br><br><h2>Does QA match production?</h2><br><br>Keeps app separated if sep. in prod to prevent hidden dependencies. Zero, One, Many - if having many nodes in prod, have 2 in QA. Just buy the gear: \"I've seen hours of downtime result from presence of firewalls or load balancers in production that did not exist in QA.\" [238]<br><br><h3>14.s Start-up and Shutdown</h3><br><br>Build a clear start-up sequence into the app so that everything starts in the right order and must complete before requests are served. Init. at least some conn for each conn. pool (Fail Fast).<br><br>Clean shutdown: have a mode where existing tx are completed (remember a timeout) but new request not accepted.<br><br>CLI interfaces for administration are best (&lt;&gt; scripting) x GUIs.<br><br><h1>PART IV Operations</h1><br><br><h2>17 Transparency</h2><br><br>= qualities allowing personnel to gain insight into the system's historical trends, present conditions, instantaneous state, and future projections.<br><br><h3>Perspectives</h3><br><br><ul>\n<li>Historical Trending - system and biz level metrics in the OpsDB =&gt; trends</li>\n<li>Predicting the future (how many users can we handle, ..)</li>\n<li>Present status - the state of each app and HW - mem, garbage coll. (frequency ,..), threads for each pool, DB conn pools, traffic stats for each request channel, biz tx for each type, users (demographics, #, usage patterns, errors encountered, ...), Integration points, circuit breakers</li>\n<li>instantaneous behavior a.k.a. what the *** is going on? &lt;&gt; monitoring systems, thread dumps, stack traces, errors in log files, ...</li>\n</ul><br><br><h3>Designing for Transparency</h3><br><br>Start early. You need visibility into the whole system to avoid local optimization.<br><br><h3>Enabling Technologies</h3><br><br><h3>Logging</h3><br><br><ul>\n<li>Configurable location (=&gt; a different drive)</li>\n<li>Levels: only log as error/sever what requires attention from Ops; not every exception is an error</li>\n<li>Catalog of messages (asked for by ops) - use the internationalization tool in your IDE to produce it easily; include keys for easy lookup - e.g. the created i8n keys =&gt; unique, easy to lookup</li>\n<li>Human factor: convey clear, accurate, actionable information so that humans under stress can interpret it correctly; make it readable for humans and their pattern-matching ability</li>\n<li>Include ID of the transaction to track it across components</li>\n</ul><br><br><h3>Monitoring systems</h3><br><br>Standards<br><br><ul>\n<li>SNMP - widely supported, old; supporting a custom SW is laborious</li>\n<li>CIM (1996, successor to SNMP) - more dynamic, superior; not too widespread</li>\n<li>JMX - great for JVM-based apps</li>\n</ul><br><br>What to expose<br><br><ul>\n<li>Traffic indicators: page requests [total], tx counts, concurrent sessions</li>\n<li>Resource pool health: enabled state, total resources, r. checked out, high-water mark, # r. created/destroyed, # times checked out, # threads blocked waiting for r., # times a thread has blocked</li>\n<li>DB connection health: # SQL exceptions, # queries, avg response time to q.</li>\n<li>Integration point health: state of circuit breaker, # timeouts, # requests, avg response time, # good responses, # network/protocol/app errors, IP address of the remote endpoint, current # concurrent requests, concurrent req. high-water mark</li>\n<li>Cache health: items in c., memory used by c., cache hit rate, items flushed by garbage collector, configured upper limit, time spent creating items</li>\n</ul><br><br><h3>Operations Database (OpsDB)</h3><br><br>Logging &amp; monitoring expose the immediate behavior/status but unsuitable for the historical/future perspective =&gt; accumulate status, metrics in a (ops) DB.<br><br>OpsDB high-level structure<br><br><pre><code>\n*|-|*\n/-1-Node-*-(needs)*-Feature\n*|\nObservation-*-1-Observation Type\n|\n- one of Measurement, Event, Status\n</code></pre><br><br><ul>\n<li><em>Feature</em> - a unit of biz-significant functionality (related to avail SLAs); typically implemented across multiple hosts (web, app, DB, ..), network equipment such as FW, switch etc. - <em>Node</em> represents any of these active nodes (typically it suffices to represent hosts and apps). Optionally track what nodes use other nodes.</li>\n<li><em>Observations</em>: <em>Measurements</em> are mostly periodic performance stats; <em>Statuses</em> are state transitions (c.breaker on/off, ...). <em>ObservationType</em> defines the name and concrete subtype of the Obs.</li>\n</ul><br><br>Eventually we add:<br><br><pre><code>\n/-1-ObservationType\n1|\nExpectation-*-1-ExpectationType\n|\n- one of NominalRange, ExpectedTime, ExpectedStatus\n</code></pre><br><br><em>Expectation</em> = an allowed range for a metric, a time frame in which an event must [not] occur, an allowed status; violation =&gt; alert. Set based on historical data. (Beware false positives = crying the wolf!). Eventually the expectation values may become functions of the business rhythm (day/night, special seasons, ...)<br><br><h3>Supporting processes</h3><br><br>Build an effective feedback process, i.e. only share meaningful data that is act on responsively . See Plan-Do-Check-Act, Boyd's OODA etc.<br><br><h4>Keys to Observation</h4><br><br>Watch for both trends and outliers. Include continuous improvement.<br><br><ul>\n<li>Every week, review the past w. problems, look for recurring ones and most time consuming ones, for particular troublesome subsystems/3rd party/integr.point.</li>\n<li>Every month, look at the total volume of problems, consider the distribution of pr. types. The trends should be decrease in severity and volume.</li>\n<li>Daily or weekly look for exceptions, stack traces in logs =&gt; find most common sources, consider whether they indicate serious problems or gaps in error handling.</li>\n<li>Review help desk calls for common issues =&gt; UI improvements, more robustness</li>\n<li>If there are too many problems to review, look for top categories and sample them randomly</li>\n<li>Every 4-6 months, recheck that old correlations still hold true</li>\n<li>At least monthly look at data volumes and query stats</li>\n<li>Check the DB for the most expensive queries; have their q. plans changed? Is there a new €€€ query? &lt;=&gt; accumulation of data somewhere. Check for table scans =&gt; missing indices.</li>\n<li>Look at the daily and weekly envelope of demand and sys metrics; are traffic patterns changing? if a popular time is dropping in popularity, the sys is probably too slow at those times; if there is a plateau then perhaps there is a limiting factor, e.g. responsiveness of the system.</li>\n</ul><br><br>The emphasis shifts from reactive to predictive. Old metrics/reports loose value.<br><br>For each metric being reviewed: How does it compare to the historical norms? If the trend continues, what happens to the correlated metric (# users x responsiveness); how long can it continue before hitting a limiting factor and what will happen then? =&gt; interpretation &amp; decisions<br><br><h2>18. Adaptation</h2><br><br>Topics: Adaptatable SW design, dependency injection, object design, XP coding practices, agile DBs, adaptable enterprise architecture, dependencies within a system, d. between systems: protocols/DBs, releases shouldn't hurt (0 downtime deployments, ...)",
  "excerpt": ""
 },
 {
  "title": "AWS: Passing private configuration to a Docker container (via S3)",
  "published": "2015-07-29 06:32:49",
  "postType": "post",
  "slug": "/2015/07/29/aws-passing-private-configuration-to-a-docker-container-via-s3/",
  "status": "publish",
  "tags": [
   "aws",
   "Docker"
  ],
  "categories": [
   "[Dev]Ops"
  ],
  "content": "Philipp Garbe describes how to pass environment variables that you want to keep private to a public Docker instance run on Amazon Web Services (beanstalk or ECS) in his post <a href=\"http://pgarbe.github.io/blog/2015/07/10/how-to-run-hubot-in-docker-on-aws-ec2-container-services-part-3/\">How to Run HuBot in Docker on AWS EC2 Container Services - Part 3</a>. The trick is:<br><br><ol>\n    <li>Put them into an <code>env.sh</code> file that you can source on S3 (and allow the appropriate EC2 IAM role to access it)</li>\n    <li>As a part of your startup CMD, run <code>aws s3 cp</code> to fetch and then source it</li>\n</ol><br><br>Here is his example of the CMD from a Dockerfile:<br><br><pre><code>\r\nCMD [&quot;/bin/sh&quot;, &quot;-c&quot;, &quot;aws s3 cp --region eu-west-1 s3://your-bucket/env.sh .; . ./env.sh; bin/hubot --adapter slack&quot;]\r\n</code></pre><br><br>See the <a href=\"https://github.com/pgarbe/tatsu-hubot\">full source code in his GitHub repo</a>. Thanks for sharing, Phillipp!",
  "excerpt": ""
 },
 {
  "title": "Fixing a mysterious .ebextensions command time out (AWS Elastic Beanstalk)",
  "published": "2015-07-29 08:05:48",
  "postType": "post",
  "slug": "/2015/07/29/fixing-a-mysterious-ebextensions-command-time-out-aws-elastic-beanstalk/",
  "status": "publish",
  "tags": [
   "aws"
  ],
  "categories": [
   "[Dev]Ops"
  ],
  "content": "Our webshop, <a href=\"https://nettbutikk.netcom.no/\">nettbutikk.netcom.no</a>, runs on AWS Elastic Beanstalk and we use <code>.ebextensions/</code> to customize the environment. I have been just trying to get <a href=\"https://github.com/buger/gor\">Gor</a> running on our leader production instance to replay some traffic to our staging environment so that we get a much richer feedback from it. However the <code>container_command</code> I used caused the instance to time out and trash the environment, against all reason. The documentation doesn't help and troubleshooting this is hard due to lack of feedback and time-consuming. Luckily I have arrived to a solution.<br><br><!--more--><br><br>This is the working solution:<br><br>https://gist.github.com/holyjak/a73291e696eb3f873cb2<br><br>(The <a href=\"https://forums.aws.amazon.com/message.jspa?messageID=567946#567946\">S3 private bucket access is a story of its own</a>, requiring and addition of AWS::CloudFormation::Authentication and a change of the bucket policy.)<br><br>The key points are starting <code>gor</code> in the background with <code>&amp;</code> and, the magic ingredient that took me so long to figure out, the redirection of the command's output to <code>/dev/null</code> (the redirection inside the script likely doesn't need to be there with respect to this problem; I have it because I don't want any output to accumulate on the disk).<br><br>I do not know if I need to redirect both stdin and stderr of <code>/opt/gor-in-background</code> and why I need to do it but without it I got the infamous<br><br><blockquote>\n<p class=\"p1\"><span class=\"s1\">[time N+1] INFO Command execution completed on all instances. Summary: [Successful: 1, TimedOut: 1]. </span></p>\n<p class=\"p1\"><span class=\"s1\">[time N] WARN The following instances have not responded in the allowed command timeout time (they might still finish eventually on their own): [i-1e35c2b3].</span></p>\n</blockquote><br><br>and the instance continued to time out even when I tried to re-deploy a working version and never managed to deliver logs.<br><br><strong>Troubleshooting tip</strong>: Clone the target env a few times and use those to test changes multiple times and multiple changes in parallel to speed up the process.<br><br><h2>Summary</h2><br><br>If you (container) command leads to a time out, try to redirect its stdout and/or stderr to <code>/dev/null</code>.<code></code><br><br><em>Thanks to <a href=\"http://stackoverflow.com/a/16341391/204205\">João Abrantes for the redirection idea</a>!</em>",
  "excerpt": ""
 },
 {
  "title": "AWS ebextensions: Avoiding \"Could not enable service\" (or .. disable ..)",
  "published": "2015-07-30 12:08:56",
  "postType": "post",
  "slug": "/2015/07/30/aws-ebextensions-avoiding-could-not-enable-service-or-disable/",
  "status": "publish",
  "tags": [
   "aws"
  ],
  "categories": [
   "[Dev]Ops"
  ],
  "content": "If you are adding a service entry to your <code>.ebextensions/</code> config to run a service in AWS Elastic Beanstalk and it fails with either <em>\"Could not enable service [..]\"</em> or <em>\"Could not disable service [..]\"</em> (based on the value of <code>ensureRunning</code>), <a href=\"http://serverfault.com/a/29801/40563\">make sure that the service init.d file supports chkconfig</a>, i.e. contains the comments it looks for.",
  "excerpt": ""
 },
 {
  "title": "Running Gor, the HTTP traffic replayer, as a service on AWS Elastic Beanstalk",
  "published": "2015-07-30 12:32:42",
  "postType": "post",
  "slug": "/2015/07/30/run-gor-the-http-traffic-replayer-as-a-service-on-aws-elastic-beanstalk/",
  "status": "publish",
  "tags": [
   "aws"
  ],
  "categories": [
   "[Dev]Ops"
  ],
  "content": "<a href=\"https://github.com/buger/gor\">Gor</a> is a great utility for replicating (a subset of) production traffic to a staging/test environment. Running it on AWS Elastic Beanstalk (EB) has some challenges, mainly that it doesn't support running as a daemon and that there isn't any documentation/examples for doing this. Well, here is a solution:<br><br><!--more--><br><br>https://gist.github.com/holyjak/476b2d3c79f00a465304<br><br>Highlights<br><br><ol>\n    <li>We want to run Gor as a service (instead of just a background + nohup command) because that is the only way to ensure it will keep running even as EB adds and removes nodes.</li>\n    <li>Use the <a href=\"http://libslack.org/daemon\">daemon</a> utility to run Gor as a daemon (which it does not support out of the box). Daemon is small and works well. It will ignore gor's output and automatically restart it if it dies.</li>\n    <li>Create an init.d script for gor. To support ebextensions's <code>ensureRunning</code>, it has to <a href=\"/2015/07/30/aws-ebextensions-avoiding-could-not-enable-service-or-disable/\">support chkconfig</a></li>\n    <li>The test for whether daemon is installed cannot be just <code>! rpm -q daemon</code> but needs to be <code>/bin/sh -c \"! rpm -q daemon\"</code>; the <code>test</code> property seems to require a single command to execute</li>\n    <li>The files are downloaded from a private S3 bucket (which needs to be accessible by the EC2 role used and have the policy to allow access to the files in question)</li>\n</ol><br><br>Side note<br><br>I originally wanted to run Gor only on a single node using a container_command with leader_only to enable it on just that node. However that does not work because this is only run when the app is deployed but not when autoscaling adds new nodes (f.ex. after killing some old ones - typically starting with the leader). The new nodes are somewhat cloned from the existing ones, so they have the package, service, etc., but the command does not run there. And there is no \"leader\" concept outside of the EB deployment process. So the only option is to run Gor on all the nodes.",
  "excerpt": ""
 },
 {
  "title": "Shipping a Refactoring & Feature One Tiny Slice at a Time, to Reduce Risk",
  "published": "2015-09-01 08:37:20",
  "postType": "post",
  "slug": "/2015/09/01/shipping-a-refactoring-feature-one-tiny-slice-at-a-time-to-reduce-risk/",
  "status": "publish",
  "tags": [
   "design",
   "lean"
  ],
  "categories": [
   "SW development"
  ],
  "content": "<em>You don’t need to finish a feature and your users don’t need to see it to be able to release and start battle-testing it. Slice it as much as possible and release the chunks ASAP to shorten the feedback loop and decrease risk.</em><br><br>My colleagues have been working on a crucial change in our webshop - replacing our legacy shopping cart and checkout process with a new one and implementing some new, highly desired functionality that this change enables. We have decided to decrease the risk of the change by doing it first only for product accessories. However the business wanted the new feature included and that required changes to the UI. But the UI has to be consistent across all sections so we would need to implement it also for the main products before going live - which would necessitate implementing also the more complex process used by the main products (and not yet supported by the new backend). And suddenly we had a a load of work that would take weeks to complete and would be released in a big bang deployment.<br><br>Such a large-scale and time-consuming change without any feedback from reality whatsoever and then releasing it all at once, having impact on all our sales - I find that really scary (<a href=\"/2014/02/17/the-risks-of-big-bang-deployments/\">and have fought it before</a>). It is essentially weeks of building risk and then releasing it in a big kaboom. How could we break it down, to release it in small slices, without making the business people unhappy?<br><br><!--more--><br><br>Then we realised that we don’t need to do both the \"refactoring\"<sup>1</sup> (introducing the new client-side shopping cart and switching to the new backend) and the new features all at once. And that we can first let the new shopping cart talk to the old backend just as the application always has done - and then later, perhaps in parallel, start talking (also) to the new backend (<a href=\"/wiki/development/parallel-design-parallel-change/\">see Parallel Change</a>). We don’t need to change the UI and the users don’t need to notice there is any change. So this became our new battle plan:<br><br><ol>\n    <li class=\"p1\"><span class=\"s1\">Implement the new client-side shopping cart, i.e. an object where the UI stores whatever the user selects - which is then eventually sent to the old backend; keep the checkout process as-is. Do this initially only for accessories</span></li>\n    <li class=\"p1\">Extend it later also to the main products</li>\n    <li class=\"p1\">Integrate incrementally the new backend, talking to it in parallel to using the old one; incrementally switch over to the new one</li>\n    <li class=\"p1\">Implement the new UI everywhere</li>\n    <li class=\"p1\">Implement the new features</li>\n</ol><br><br>(Some of the steps may interleave so we have certain freedom of experimentation and discovery.) Each step, or even a part of it, is released to production as soon as possible so that when the next chunk arrives, it will be battle-tested. The risk and uncertainty are minimised, and we nearly always work on production code.<br><br>PS: Many thanks to Alex York an my other colleagues for their help<br><br><sup>1</sup>) Arguably this is not (just) a refactoring since we do not change only the internal structure.",
  "excerpt": ""
 },
 {
  "title": "Storytelling as a Vehicle of Change: Introducing ClojureScript for the Heart and Mind",
  "published": "2015-10-07 05:31:58",
  "postType": "post",
  "slug": "/2015/10/07/storytelling-as-a-vehicle-of-change-introducing-clojurescript-for-the-heart-and-mind/",
  "status": "publish",
  "tags": [
   "change",
   "ClojureScript",
   "human"
  ],
  "categories": [
   "General",
   "Languages"
  ],
  "content": "People don't really like changes yet change we must in this fast-developing world. How to introduce a change, or rather how to inspire people to embrace a change? That is one of the main questions of my professional life.<br><br>I have recently talked about Functional programming (FP) in JavaScript and compared it to ClojureScript, which was designed for FP. To my surprise the team proposed to give ClojureScript a try and we agreed to have a live coding session, implementing a new functionality in our internal part of our webshop using ClojureScript. But how to kindle this little flame of motivation to keep it going, despite hurdles that will certainly come? And here I got a few interesting ideas.<br><br><ol>\n    <li>An experienced speaker once recommended sharing personal experiences (even - or especially - if they make me vulnerable) as it is much easier for people to relate to them than to general statements.</li>\n    <li><span class=\"s1\">A <a href=\"http://blog.cognitect.com/cognicast/074\">Cognicast eposide</a> mentioned storytelling as a great tool for introductory guides. We humans are natural storytellers, we think in stories and relate to them much more easily - so a story should be great also to communicate the value of a change.</span></li>\n    <li><span class=\"s1\">My ex-colleague Therese Ingebrigtsen gave an inspiring talk presenting some points from <a href=\"http://www.amazon.com/Switch-Change-Things-When-Hard/dp/0385528752\">The Switch</a> - mainly that we need to address the recipient's minds with rational arguments, but also their hearts to involve their emotion (e.g. by drawing a picture of the new bright future), and that it is important to show a clear path forward.</span></li>\n</ol><br><br><!--more--><br><br>Based on these ideas I created the following battle plan.<br><br><ol>\n    <li><strong>Address the mind</strong> - Repeat the conclusion of my FP in JavaScript talk - the recommendation to use ClojureScript as a language designed for FP, with a top-notch data-manipulation library and one of the best immutable data implementations, compiled size that rivals that of JavaScript with a few libraries, and super-powers in the form of <a href=\"http://clojure.org/macros\">macros</a>, <a href=\"http://www.braveclojure.com/core-async/\">core.async</a> and <a href=\"https://github.com/clojure/core.match/wiki/Overview\">core.match</a>.\n<table>\n<tbody>\n<tr>\n<td>\n<img class=\"alignnone size-full wp-image-4490\" src=\"/images/2015/09/flying-car-small.jpeg\" alt=\"flying-car-small\" width=\"207\" height=\"123\" />\n</td><td>\n<img class=\"alignnone size-medium wp-image-4491\" src=\"/images/2015/09/plane-futuristic-small.png?w=161\" alt=\"plane-futuristic-small\" width=\"161\" height=\"123\" /></td>\n</tr><tr>\n<td><em>You can make JavaScript fly...</em></td><td><em>But why not to use something<br>\ndesigned for flying?</em></td></tr>\n</tbody>\n</table>\n</li>\n    <li><strong>Highlight the importance</strong> of this work - How the internal admin pages have grown in importance and functionality and thus need more attention and development.</li>\n    <li><strong>Tell a story and share a personal experience</strong> - I have retold my painful experience of working on the admin pages to improve our troubleshooting capabilities, which often required several restarts to see a change and how that frustrated and slowed me down, making it impossible to get into a flow. Everybody has experienced this and has appreciated how unproductive it is. (#2, 3, 4 form the story - the growth of the admin pages, the pain of developing them, the ease of doing so with ClojureScript &amp; Co.)</li>\n    <li><strong>Address the heart, draw a picture of a bright future</strong>: I have played the 6 min video <a href=\"https://www.youtube.com/watch?v=KZjFVdU8VLI\">Interactive programming Flappy Bird in ClojureScript</a> that demonstrated the very opposite of my painful experience. Everybody was impressed and envious.</li>\n    <li>Finally, I have <strong>live-coded</strong> the new feature, using REPL-driven programming to explore the data and develop the code on the go with Figwheel to make interactive programming in the browser a reality. Even though I have encountered some obstacles (such as mistakes and print timing out due to data size), it was well received - I believe that was thanks to the previous points (and thanks to having wonderful colleagues :-)).</li>\n</ol><br><br>So my impression is that this approached worked really well. An interesting result was that despite all the goodness of ClojureScript, it turned out that the main selling point for us was interactive development. (You can get something similar with <a href=\"https://gaearon.github.io/react-hot-loader/\">React Hot Loader</a> but it doesn't work on the server side (Node) and making your state reloadable is a much smaller challenge in Cljs thanks to immutable data and clear data management constructs such as atoms.)<br><br>Perhaps I should highlight that I haven't tried to manipulate my colleagues or play any tricks on them. All this is just about how to effectively communicate something I am passionate about, highlighting the important points in a way compatible with how the audience thinks.",
  "excerpt": ""
 },
 {
  "title": "Nginx: Protecting upstream from overload on cache miss",
  "published": "2015-10-01 05:09:35",
  "postType": "post",
  "slug": "/2015/10/01/nginx-protecting-upstream-from-overload-on-cache-miss/",
  "status": "publish",
  "tags": [],
  "categories": [
   "[Dev]Ops"
  ],
  "content": "These 2 magical lines will protect your upstream server from possible overload of many users try to access the same in cached or expired content:&nbsp;<br><br><blockquote>proxy_cache_use_stale updating timeout; # Serve the cached version even when outdated while refreshing it\nproxy_cache_lock on; # Only one req is allowed to load/refresh the item, others wait / get the stale one&nbsp;</blockquote><br><br>You can verify this using Shopify's Toxiproxy.&nbsp;<br><br>&lt;3 Nginx",
  "excerpt": ""
 },
 {
  "title": "Refactoring & Type Errors in Clojure: Experience and Prevention",
  "published": "2015-10-06 10:37:15",
  "postType": "post",
  "slug": "/2015/10/06/refactoring-type-errors-in-clojure/",
  "status": "publish",
  "tags": [
   "clojure",
   "ClojureScript",
   "refactoring"
  ],
  "categories": [
   "Languages"
  ],
  "content": "While refactoring a relatively simple Clojure code to use a map instead of a vector, I have wasted perhaps a few hours due to essentially type errors. I want to share the experience and my thoughts about possible solutions since I encounter this problem quite often. I should mention that it is quite likely that it is more a problem (an opportunity? :-)) with me rather than the language, namely with the way I write and (not) test it.<br><br>The core of the problem is that I write chains of transformations based on my sometimes flawed idea of what data I have at each stage. The challenge is that I cannot see what the data is and have to maintain a mental model while writing the code, and I suck at it. Evaluating the code in the REPL as I develop it helps somewhat but only when writing it - not when I decide to refactor it.<br><br><!--more--><br><br>https://gist.github.com/holyjak/8f711c8634ae4e8eeeed",
  "excerpt": ""
 },
 {
  "title": "An answer to CircleCI''s \"Why we’re no longer using Core.typed\"",
  "published": "2015-10-06 20:44:10",
  "postType": "post",
  "slug": "/2015/10/06/an-answer-to-circlecis-why-were-no-longer-using-core-typed/",
  "status": "publish",
  "tags": [
   "clojure",
   "core.typed"
  ],
  "categories": [
   "Languages"
  ],
  "content": "CircleCI has recently published a very useful post \"<a href=\"http://blog.circleci.com/why-were-no-longer-using-core-typed/\">Why we’re no longer using Core.typed</a>\" that raises some important concerns w.r.t. <a href=\"http://typedclojure.org/\">Typed Clojure</a> that in their particular case led to the cost overweighting the benefits. CircleCI has a long and positive relation to Ambrose Bonnaire-Sergeant, the main author of core.typed, that has addressed their concerns in his recent Strange Loop talk \"<a href=\"https://www.youtube.com/watch?v=yG9CffLlXx0\">Typed Clojure: From Optional to Gradual Typing</a>\" (gradual typing is also explained in his 6/2015 blog post \"<a href=\"http://frenchy64.github.io/2015/06/19/gradual-typing.html\">Gradual typing for Clojure</a>\"). For the sake of searchability and those of us who prefer text to video, I would like to summarise the main points from the response (spiced with some thoughts of my own).<br><br><!--more--><br><br><em>Disclaimer: All the useful information comes from Ambrose. All the errors and misinterpretations, if any, are mine.</em><br><br><h2>The concerns</h2><br><br>(It should be noted that CircleCI has quite a large codebase with ~ 90 typed namespaces.)<br><br><ol>\n    <li>Slow checking - If you work on multiple files, you need to re-scan them all which takes very long time on a large project</li>\n    <li>Mixing of typed and untyped code and thus the use of types with :no-check leads to weakened guarantees; both inside one's own codebase and when interacting with untyped libraries (see #4).</li>\n    <li>Some expressions cannot by typed (get-in, ...) and it is difficult to distinguish whether an error is caused by core.typed's limitations or an actual defect in the code being checked</li>\n    <li>It's costly to maintain type for untyped 3rd-party libraries</li>\n    <li>It is difficult to find out the right type signature for some expressions</li>\n</ol><br><br><h2>The solutions</h2><br><br>Summary: The situation is already better and will be much better when gradual typing is fully finished.<br><br><strong>#1 Slow checking</strong> - this is already solved by the Typed REPL and the caching built into require / load.<br><br>Ambrose Bonnaire-Sergeant (ABS): But the Typed REPL is still work in progress, \"In particular, it doesn't play nicely with many tools that use the current namespace to evaluate tools-specific things (eg. autocompletions). [...] it's undocumented and unproven\" though the require/load caching might be split out and used separately as it doesn't suffer from these problems.<br><br><strong>#2 Mixing of typed and untyped code</strong> and thus lack of compile-time guarantees - this will be solved by gradual typing when finished by adding runtime checks to these types (and adding runtime checks to ensure that untyped code cannot pass illegal values to typed code)<br><br><strong>#3 Expressions that are impossible / hard to type</strong> - I don't think this has been addressed in the talk, though I have seen in the Google Group that the community continually thinks about ways to be able to type more Clojure idioms. <em>My thoughts: </em>T<i>here should be a first-class support for these, i.e. a well known, well supported and easy to use way to work around these. Something like the solution for external untyped code where we provide our own type signature and mark it with \":no-check\". (Though I obviously have no idea what this solution for the particular problem of type uncheckable expressions would be.) Also, it should not be impossible to modify the error reporting to clearly distinguish errors caused by core.typed's limitations and those by defects in the code being checked.</i><br><br>ABS: \"The most significant work on this front (ie. supporting more idioms at compile-time) has been incremental since 2013. Overhauls are needed for the challenges CircleCI use as examples.\"<br><br><strong>#4 Cost of maintaining type signatures</strong> for 3rd party libraries - this will be still costly but much more valuable and reliable as these types will be turned into runtime guarantees. <em>My thoughts: This is no different from using Prismatic Schema, there you too need to check that external code conforms to your contracts.</em><br><br>ABS: One interesting idea is to convert existing Schema annotations to core.typed for libs that have them.<br><br><strong>#5 The difficulty of finding out the right type signatures</strong> of more complex functions - this hasn't been addressed. <em>My thoughts: Making it easier to derive type signature is certainly an interesting are for exploration though likely outside of the main focus now. It would be great to run a function with few examples of its usage through some magical box and get back a type signature for it :-)</em><br><br>ABS: \"I'm personally mostly interested in using compile-time data to infer types at the moment, which would again require some overhauls if at all possible. Your suggestion has been successfully used in practice though, see <a href=\"http://www.cs.umd.edu/projects/PL/druby/\" target=\"_blank\">DRuby</a>. I would like to know if this approach works on typical Clojure code. IME types in many Clojure programs aren't especially polymorphic or higher-order when crossing function boundaries, functions often take a map or some other simple value, so there's probably something worth investigating.\"<br><br><h2>Conclusion</h2><br><br>Core.typed is relevant and useful in many cases. With the progress towards Gradual Typing it will become even much more powerful and useful on mixed typed-untyped code based.<br><br><h2>Useful additional resources</h2><br><br><ul>\n    <li><a href=\"https://groups.google.com/forum/#!forum/clojure-core-typed\">core.typed e-mail group</a> - f.ex. \"<a href=\"https://groups.google.com/d/msg/clojure-core-typed/XItabfiBoGw/cB7IIOhbh9wJ\">Future directions for core.typed</a>\" from 7/2015</li>\n    <li><a href=\"https://github.com/clojure/core.typed/wiki/Limitations\">Wiki: Limitations of core.typed</a></li>\n    <li><a href=\"http://dev.clojure.org/jira/browse/CTYP\">core.typed Jira</a></li>\n</ul><br><br><h2>Key slides from the talk</h2><br><br><a href=\"/images/2015/10/img_0739.png\"><img class=\"alignnone size-medium wp-image-4474\" src=\"/images/2015/10/img_0739.png?w=300\" alt=\"IMG_0739\" width=\"300\" height=\"169\" /></a> <a href=\"/images/2015/10/img_0741.png\"><img class=\"alignnone size-medium wp-image-4475\" src=\"/images/2015/10/img_0741.png?w=300\" alt=\"IMG_0741\" width=\"300\" height=\"169\" /></a> <a href=\"/images/2015/10/img_0743.png\"><img class=\"alignnone size-medium wp-image-4476\" src=\"/images/2015/10/img_0743.png?w=300\" alt=\"IMG_0743\" width=\"300\" height=\"169\" /></a> <a href=\"/images/2015/10/img_0744.png\"><img class=\"alignnone size-medium wp-image-4477\" src=\"/images/2015/10/img_0744.png?w=300\" alt=\"IMG_0744\" width=\"300\" height=\"169\" /></a> <a href=\"/images/2015/10/img_0746.png\"><img class=\"alignnone size-medium wp-image-4478\" src=\"/images/2015/10/img_0746.png?w=300\" alt=\"IMG_0746\" width=\"300\" height=\"169\" /></a> <a href=\"/images/2015/10/img_0747.png\"><img class=\"alignnone size-medium wp-image-4479\" src=\"/images/2015/10/img_0747.png?w=300\" alt=\"IMG_0747\" width=\"300\" height=\"169\" /></a> <a href=\"/images/2015/10/img_0750.png\"><img class=\"alignnone size-medium wp-image-4480\" src=\"/images/2015/10/img_0750.png?w=300\" alt=\"IMG_0750\" width=\"300\" height=\"169\" /></a> <a href=\"/images/2015/10/img_0751.png\"><img class=\"alignnone size-medium wp-image-4481\" src=\"/images/2015/10/img_0751.png?w=300\" alt=\"IMG_0751\" width=\"300\" height=\"169\" /></a> <a href=\"/images/2015/10/img_0755.png\"><img class=\"alignnone size-medium wp-image-4482\" src=\"/images/2015/10/img_0755.png?w=300\" alt=\"IMG_0755\" width=\"300\" height=\"169\" /></a>",
  "excerpt": ""
 },
 {
  "title": "Upgrade or not to upgrade dependencies? The eternal dilemma",
  "published": "2015-10-20 13:07:57",
  "postType": "post",
  "slug": "/2015/10/20/upgrade-or-not-to-upgrade-the-eternal-dilemma/",
  "status": "publish",
  "tags": [
   "experience",
   "learning",
   "TeliaSonera"
  ],
  "categories": [
   "SW development"
  ],
  "content": "<p style=\"text-align:center;\"><em><a href=\"http://teliasonera.github.io/tech-blog/blog/upgrade-or-not-to-upgrade-the-eternal-dilemma/\">Cross-posted from TeliaSonera Tech blog</a>.</em></p><br><br>Handling dependencies is one of important challenges in any software project - and especially in the fast-moving JavaScript world. Our <a href=\"http://teliasonera.github.io/tech-blog/blog/upgrade-or-not-to-upgrade-the-eternal-dilemma/nettbutikk.netcom.no\">Nettbutikk</a> team just had a heated discussion about handling upgrades of our dependencies that continuous our learning journey lined with failures (or rather \"experiments that generated new knowledge\" :-)).<br><br><h2 id=\"failed-attempt-one-let-tools-do-it\">Failed attempt one: Let tools do it</h2><br><br>Originally we let <code>npm</code> automatically do minor upgrades but that turned out to be problematic as even minor version changes can introduce bugs and having potentially different (minor) versions on our different machines and in production makes troubleshooting difficult.<br><br><!--more--><br><br>Also, this only takes care about minor version changes. When we decided to do the bigger updates, we had a lot of work and testing to do, making sure all the new versions work together. Troubleshooting of upgrade problems was difficult since many libraries were changed at once so pinpointing the source of a new defect was nontrivial.<br><br><h2 id=\"failed-attempt-two-let-a-human-do-it\">Failed attempt two: Let a human do it</h2><br><br>Next we decided to freeze the library versions completely and let the one of us that had the operations role that week run <code>npm outdated</code>, update all dependencies, and verify everything still worked.<br><br>Thus we ensured that we were almost always up-to-date and that we typically had only a small job to do, with just a small potential for problems. However it wasn't frictionless either. It might require one or few hours (for proper testing and occasional troubleshooting) every week, a time we would have rather used on creating new value. And sometimes the upgrade did introduce problems - some spot and fixed immediately, but some taking more time to discover and fix. Once it took two weeks to find out that something broke due to a <code>Reflux</code> upgrade - and finding out that the cause was the upgrade wasn't easy.<br><br><h2 id=\"new-experiment-upgrade-as-needed\">New experiment: Upgrade as-needed</h2><br><br>Our reliable though-challenger Alex pointed out that upgrades give us typically little value at a relatively high cost. So we have decided to try not upgrading libraries unless we would have a good reason to do it (such as a known security problem or a new functionality we want). It is obviously not optimal and the upgrades might be big and painful but we will try it for a while and evaluate how it works for us.<br><br><h2 id=\"conclusion\">Conclusion</h2><br><br>Handling and upgrading dependencies is difficult and costly. It's important to evaluate the cost-benefit ration and experiment to find the \"least bad\" approach and balance for a particular team. Development is fun.",
  "excerpt": ""
 },
 {
  "title": "Moving Too Fast For UX? Genuine Needs, Wrong Solutions",
  "published": "2015-11-12 10:04:13",
  "postType": "post",
  "slug": "/2015/11/12/moving-too-fast-for-ux-genuine-needs-wrong-solutions/",
  "status": "publish",
  "tags": [
   "development",
   "lean",
   "worklog"
  ],
  "categories": [
   "SW development"
  ],
  "content": "<p style=\"text-align:center;\"><em>Cross-posted <a href=\"http://teliasonera.github.io/tech-blog/blog/moving-too-fast-for-ux-genuine-needs-wrong-solutions/\">from the TeliaSonera tech blog</a></em></p><br><br>Our UX designer and interaction specialist - a wonderful guy - has shocked us today by telling us that we (the developers) are moving too fast. He needs more time to do proper user experience and interface design – talk to real users, collect feedback, design based on data, not just hypotheses and gut feeling. To do this, he needs us to slow down.<br><br>We see a common human \"mistake\" here: where the expression of a genuine need gets mixed in with a suggestion for satisfying it. We are happy to learn about the need and will do our best to satisfy it (after all, we want everybody to be happy, and we too love evidence-based design) but we want to challenge the proposed solution. There is never just one way to satisfy a need – and the first proposed solution is rarely the best one (not mentioning that this particular one goes against the needs of us, the developers).<br><br><!--more--><br><br>So after some thought we proposed a better solution for satisfying the \"better UX\" need: our rewrite of the current system will simply copy the design of the existing system, and we will change it later on, when UX is ready to start experimenting with a new design. Thus we can get feedback on technical aspects of the new solution (performance, etc.) soon, while the UX-team designs a solution based on thorough user insight and data.<br><br>Do you also experience that people mix needs and (suboptimal) solution proposals? Perhaps you do it yourself?",
  "excerpt": ""
 },
 {
  "title": "Troubleshooting And Improving HTTPS/TLS Connection Performance",
  "published": "2015-11-27 14:24:20",
  "postType": "post",
  "slug": "/2015/11/27/troubleshooting-and-improving-httpstls-connection-performance/",
  "status": "publish",
  "tags": [
   "experience",
   "performance",
   "TLS"
  ],
  "categories": [
   "General"
  ],
  "content": "Our team has struggled with slow calls to the back-end, resulting in unpleasant, user-perceivable delays. While a direct (HTTP) call to a backend REST service took around 50ms, our median time was around 300ms (while using HTTPS and a proxy between us and the service).<br><br>We have just decreased that time to median of 80ms by making sure to keep the connections alive and reusing them, which in Node.js can be achieved via using an https.agent and setting its keepAlive: true (see the <a href=\"https://nodejs.org/api/tls.html\">Node TLS documentation</a>).<br><br>PayPal has a couple of additional useful tips in their 4/2014 post <a href=\"https://www.paypal-engineering.com/2014/04/01/outbound-ssl-performance-in-node-js/\">Outbound SSL Performance in Node.js</a>, mainly:<br><br><ul>\n    <li>Disable expensive SSL ciphers (if you don't need their strength)</li>\n    <li>Enable SSL session resume, if supported by the server, for shorter handshakes - the StrongLoop post \"How-to Improve Node.js HTTPS Server Performance\" explains <a href=\"https://strongloop.com/strongblog/improve-the-performance-of-the-node-js-https-server/\">how to enable SSL session resume</a></li>\n    <li>Keep Alive</li>\n</ul><br><br>The article <a href=\"http://www.semicomplete.com/blog/geekery/ssl-latency.html\">SSL handshake latency and HTTPS optimizations</a> (via Victor Danell) explains the ± 3.5* higher cost of SSL due to the 3 roundtrips need for the handshake (+ key generation time) and shows how to use curl to time connections and their SSL parts, as well as how to use OpenSSL and Tcpdump to learn even more about it.<br><br>See also <a href=\"https://istlsfastyet.com/\">IsTlsFastYet.com</a> for a lot of valuable information, benchmarks etc.<br><br><h4>Tools</h4><br><br>(See the articles linked to above for examples)<br><br><ul>\n    <li>curl</li>\n    <li>openssl s_client</li>\n    <li><a href=\"https://www.caida.org/tools/utilities/others/pathchar/\">pathchar</a> by the traceroute author, intended to help to \"find the bandwidth, delay, average queue and loss rate of every hop between any source &amp; destination\"; there is also <a href=\"http://www.kitchenlab.org/www/bmah/Software/pchar/\">pchar</a>, based on it</li>\n</ul><br><br>&nbsp;",
  "excerpt": ""
 },
 {
  "title": "A Costly Failure to Design for Performance and Robustness",
  "published": "2015-12-05 23:34:59",
  "postType": "post",
  "slug": "/2015/12/06/a-costly-failure-to-design-for-performance-and-robustness/",
  "status": "publish",
  "tags": [
   "design",
   "experience",
   "performance",
   "worklog"
  ],
  "categories": [
   "SW development"
  ],
  "content": "I have learned that it is costly to not prioritise expressing one's design concerns and ideas early. As a result, we have a shopping cart that is noticeably slow, goes down whenever the backend experiences problems, and is a potential performance bottleneck. Let's have a look at the problem, the actual and my ideal designs, and their pros and cons.<br><br>We have added shopping cart functionality to our web shop, using a backend service to provide most of the functionality and to hold the state. The design focus was on simplicity - the front-end is stateless, any change to the cart is sent to the backend and the current content of the cart is always fetched anew from it to avoid the complexity of maintaining and syncing state at two places. Even though the backend wasn't design for the actual front-end needs, we work around it. The front-end doesn't need to do much work and it is thus a success in this regard.<br><br><!--more--><br><br>However there are other concerns than simplicity and time-to-production that we could have been taken into account, I believe. But I failed to communicate those in time. The current solution would have been perfect if the network transfer times were negligible and if the backend service was 100% reliable. None of that is true. Every call takes at least 300ms and the backend can be overloaded or (as yesterday) unavailable due to network issues. I there is a high load, all customers will experience a very slow cart multiple times.<br><br>I prefer to design for robustness, with a healthy does of paranoia with respect to performance and the availability of any dependencies. I would have advocated to create the shopping cart in-browser and to hold the state primarily there, using localStorage (if available) for persistence and sharing across pages and tabs, sending the content to the backend asynchronously. When the user clicks \"buy\", the item would be added immediately to the cart, not after few 100s of ms or a few seconds. And if the backend eventually rejected the change, we would notify the user and remove it from the cart (an \"optimistic transaction\" - that is what <a href=\"https://www.youtube.com/watch?v=MDZpSIngwm4\">Om Next does by default</a>). If the backend is down, we can inform the user that fulfilling the order isn't possible at the moment but that the browser remembers it (even if quit) and that they should come back and try later again. I would primarily talk to the backend only at the last possible moment, when the user clicks \"go to checkout\" - or, perhaps, if the backend isn't overloaded, also after any change to the cart but asynchronously, to improve the perceived performance when the final button is clicked. The front-end and especially the browser code would be more complex and take longer to develop and test but it would be very well isolated from backend problems and would generate minimal load on the backend. I believe that in this case, it would be worth it. (Though I admittedly tend to overcomplicate things, with my performance and availability paranoia.)<br><br><h3>Conclusion</h3><br><br>We all have different experiences and preferences. It is therefore important to get varied people involved in the design of core functionality early. I should not expect other people - no matter how capable - to have the same experiences and insights as me and should thus prioritize voicing them. (Though I have to keep in mind that I am not infalliable and the different experiences and preferences of others are equally, if not more important than mine.)<br><br><h3>Update 12/2015</h3><br><br>After introducing TLS session re-use and optimizing our server-side code, the time needed for the back-end calls went drastically down and it is pretty usable now. I still dislike the tight coupling to the back-end but there is currently nothing forcing us to change it. We have a potential performance problem but only the future (and proper performance testing) will show whether it is a real problem. May be the future will show me that the simple solution we have adopted is good enough (and much \"cheaper\" in terms of development and maintenance time).",
  "excerpt": ""
 },
 {
  "title": "Why we practice fronted-first design (instead of API-first)",
  "published": "2015-12-05 23:13:47",
  "postType": "post",
  "slug": "/2015/12/06/why-we-practice-fronted-first-design-instead-of-api-first/",
  "status": "publish",
  "tags": [
   "design",
   "worklog"
  ],
  "categories": [
   "SW development"
  ],
  "content": "<p style=\"text-align:center;\"><em>Cross-posted <a href=\"http://teliasonera.github.io/tech-blog/blog/why-we-practice-fronted-first-design-instead-of-api-first/\">from the TeliaSonera tech blog</a></em></p><br><br>Alex has introduced us to the idea of front-end first design: You start by creating the front-end (browser) code. As you discover data or API calls that you need, you mock them. When the UI stabilizes, you use the mocked APIs and data to create the backend with exactly the functionality and exactly the data needed by the UI. The end result is a simpler application.<br><br>We are trying to adopt this as our approach because it is so sensible. Whenever we work with an API that wasn't designed with the actual client needs in mind, we experience unnecessary friction and have to do various workarounds and adaptations so front-end-first absolutely makes sense to us. (E.g. when working with a REST API designed in line with REST principles - but not with our needs, resulting in a too chatty communication and more complex code.)<br><br>Of course there are same limitations. It is more challenging when you need to support different clients. And you need to take into account not just what the UI wants but also what is reasonably possible in the constraints of the existing system. You want to avoid a big gap between the two - we still remember the pain of integrating OOP and relational databases and the complexity of pitfalls of Object-Relational Mappers such as Hibernate, that try to bridge the two.<br><br><h3>Conclusion</h3><br><br>Fronted-first design rocks (for us). Try it too and see whether you too get a simpler application code and shorter time to market.",
  "excerpt": ""
 },
 {
  "title": "2015 in review",
  "published": "2016-02-18 23:12:46",
  "postType": "post",
  "slug": "/2016/02/19/2015-in-review/",
  "status": "publish",
  "tags": [],
  "categories": [
   "Uncategorized"
  ],
  "content": "The WordPress.com stats helper monkeys prepared a 2015 annual report for this blog.<br><br><a href=\"/2015/annual-report/\"><img src=\"//s0.wp.com/wp-content/mu-plugins/annual-reports/img/2014-emailteaser.png\" alt=\"\" width=\"100%\" /></a><br><br>Here's an excerpt:<br><br><blockquote>The Louvre Museum has 8.5 million visitors per year. This blog was viewed about <strong>200,000</strong> times in 2015. If it were an exhibit at the Louvre Museum, it would take about 9 days for that many people to see it.</blockquote><br><br><a href=\"/2015/annual-report/\">Click here to see the complete report.</a>",
  "excerpt": ""
 },
 {
  "title": "Don''t add unnecessary checks to your code, pretty please!",
  "published": "2016-03-04 11:04:37",
  "postType": "post",
  "slug": "/2016/03/04/dont-add-unnecessary-checks-to-your-code-pretty-please/",
  "status": "publish",
  "tags": [
   "CleanCode",
   "opinion"
  ],
  "categories": [
   "SW development"
  ],
  "content": "Defensive programming suggests that we should add various checks to our code to ensure the presence and proper shape and type of data. But there is one important rule - only add a check if you <em>know</em> that thing can really happen. Don't add random checks just to be sure - because you are misleading the next developer.<br><br><!--more--><br><br>Imagine you need to call <code>.indexOf</code> on <code>product_code</code>. You might be tempted to add<br><br><pre><code>if (!_.isString(product_code)) return false;</code></pre><br><br>Now you are safe and your code can't fail. But when I read this code, I immediately think:<br><br><blockquote>Oh, I believed product_code to be always a string but obviously it is not always the case. It must have happened in the past or the author wouldn't have added this check. I wonder what are the possible non-string values. And what does it mean and how should I handle them?</blockquote><br><br>So by adding this check you have eroded significantly my trust in the data or rather trust in my mental model&nbsp;of the data (domains, possible values) and it has become much more fuzzy. Now I have to always assume that product_code can be something (what?!) else than a string, check for it everywhere and wonder what to do about it.<br><br>I have maintained a lot of legacy code, often encountering checks like this - and it always lead to an erosion of my understanding of the system and increased insecurity. So, pretty please, do not add such checks just for the sake defensiveness. (After all, you don't want to be practicing <a href=\"https://pragprog.com/the-pragmatic-programmer/extracts/coincidence\">Programming by Coincidence</a>, do you?)<br><br>Sometimes you need checks&nbsp;because the data comes from outside the system that you control. Then you should add the checks (only) to the boundary of the system so that every internal part of it can then rely on the data being as expected. (Here we would add the code to check/ensure that product_code is a string to the module that fetched product catalog information from an external service.)",
  "excerpt": ""
 },
 {
  "title": "It Is OK to Require Your Team-mates to Have Particular Domain/Technical Knowledge",
  "published": "2016-03-06 10:23:39",
  "postType": "post",
  "slug": "/2016/03/06/it-is-ok-to-requie-your-team-mates-to-have-particular-domaintechnical-knowledge/",
  "status": "publish",
  "tags": [
   "opinion"
  ],
  "categories": [
   "SW development"
  ],
  "content": "<p class=\"p1\"><span class=\"s1\">Should we write stupid code that is easy to understand for newcomers? It seems as a good thing to do. But it is the wrong thing to optimise for because it is a rare case. Most of the time you will be working with people experienced in the code base. And if there is a new member, you should not just throw her into the water and expect her to learn and understand everything on her own. It is better to optimise for the common case, i.e. people that are up to speed. It is thus OK to expect and require that the developers have certain domain and technical knowledge. And spend resources to ensure that is the case with new members. Simply put, you should not dumb down your code to match the common knowledge but elevate new team mates to the baseline that you defined for your product (based on your domain, the expected level of experience and dedication etc.).</span></p><br><br><p class=\"p1\"><!--more--></p><br><br>For example in my team, we use extensively lo-dash, a library for data transformation (map, filter, etc.). We expect all new members to become comfortable with it before being productive. That means learning not just&nbsp;<code>filter(cars, c =&gt; c.color === \"yellow\")</code> but also the short-hand forms such as <code>filter(cars, {color: \"yellow\"})</code>, <code>filter(cars, \"family\")</code> (having a truthy property family), and even <code>filter(cars, color? {color} : null)</code> (you need to know that null == (<code>()=&gt;true)</code>).<br><br><p class=\"p1\">Of course I don't want to suggest that you should bring in all possible libraries and concepts and require all to know everything. I speak about a few but crucial, carefully selected libraries (and concepts). You also don't need to use everything a library (or a language) has to offer - especially if it offers too much. Talk with your team-mates and select what is suitable for you - the less the better :-).</p><br><br><p class=\"p1\">The same thing applies to domain concepts - it is OK to expect and rely upon certain level of domain expertise, knowledge of business rules etc. (But you must make sure that&nbsp;all will have an opportunity to learn them.)</p><br><br><p class=\"p1\">To help with on-boarding, you should write down what this expected domain and technical knowledge is.</p><br><br><p class=\"p1\">PS: This idea was originally put forward in a much better way by Rich Hickey in has famous talk Simple Made Easy. (And I have certainly modified the message in quite few ways.)</p>",
  "excerpt": ""
 },
 {
  "title": "Demonstration: Applying the Parallel Change technique to change code in small, safe steps",
  "published": "2017-02-03 10:32:48",
  "postType": "post",
  "slug": "/2017/02/03/demonstration-applying-the-parallel-change-technique-to-change-code-in-small-safe-steps/",
  "status": "publish",
  "tags": [
   "best practices",
   "refactoring"
  ],
  "categories": [
   "General"
  ],
  "content": "The <a href=\"/wiki/development/parallel-design-parallel-change/\">Parallel Change</a> technique is intended to make it possible to change code in a small, save steps by first adding the new way of doing things (without breaking the old one; \"expand\"), then switching over to the new way (\"migrate\"), and finally removing the old way (\"contract\", i.e. make smaller). Here is an example of it applied in practice to refactor code producing a large JSON that contains a <a href=\"https://xlinux.nist.gov/dads/HTML/dictionary.html\">dictionary</a> of addresses at one place and refers to them by their keys at other places. The goal is to rename the key. (We can't use simple search &amp; replace for reasons.)<br><br><!--more--><br><br>The tests typically compare the produced and the expected JSON but the expected data isn't hardcoded but is generated through helper functions, such as:<br><br><pre><code>\nexpect(data).to.deep.equal({\n    ...expectAddresses({ billing: { /* .. */ }}) // this already uses the new key\n    ...expectNotificationRecipients(),\n    ...expectAccounts(),\n    ...\n});\n</code></pre><br><br>That makes our job much easier. So here is the full process (I use \"-&gt;\" to indicate the change performed):<br><br><ol>\n    <li>(Expand) In prod code where we create the data, keep the old &amp; add the new key:\n<code>addresses[\"accounts_street_address\"] = ...</code>\n-&gt; <code>addresses[\"billing\"] = addresses[\"accounts_street_address\"] = ...</code>\n=&gt; tests break</li>\n    <li>In tests, modify <code>expectAddresses()</code> to create and thus expect both as well:\n<code>addresses[\"accounts_street_address\"] = { \"street_address\": expectStreetAddress(billing || all) };</code>\n-&gt; <code>addresses[\"billing\"] = addresses[\"accounts_street_address\"] = { \"street_address\": expectStreetAddress(billing || all) };</code>\n=&gt; tests fixed</li>\n    <li>(Migrate) In prod code, use the new key when referring to the address:\n<code>\"address_reference_id\": \"accounts_street_address\"</code>\n-&gt; <code>\"address_reference_id\": \"billing\"</code>\n=&gt; tests break</li>\n    <li>In tests, fix <code>expectAccounts()</code> to expect the new key:\n<code>\"address_reference_id\": \"accounts_street_address\"</code>\n-&gt; <code>\"address_reference_id\": \"billing\"</code>\n=&gt; tests fixed</li>\n    <li>(Contract) In prod code, remove the old address:\n<code>addresses[\"billing\"] = addresses[\"accounts_street_address\"] = ...</code>\n-&gt; <code>addresses[\"billing\"] = ...</code>\n=&gt; tests break</li>\n    <li>In tests, fix <code>expectAddresses()</code> to not expect the old address anymore:\n<code>addresses[\"billing\"] = addresses[\"accounts_street_address\"] = ...</code>\n-&gt; <code>addresses[\"billing\"] = ...</code>\n=&gt; tests fixed</li>\n    <li>Fix two tests that access the address itself through its old name.</li>\n    <li>DONE!</li>\n</ol>",
  "excerpt": ""
 },
 {
  "title": "Simulating network timeouts with toxiproxy",
  "published": "2017-05-09 13:00:40",
  "postType": "post",
  "slug": "/2017/05/09/simulating-network-timeouts-with-toxiproxy/",
  "status": "publish",
  "tags": [
   "networking",
   "Testing",
   "tool"
  ],
  "categories": [
   "Tools",
   "Uncategorized"
  ],
  "content": "<p>Goal: Simulate how a Node.js application reacts to timeouts.</p>\n<p>Solution: Use <a href=\"http://toxiproxy.io\">toxiproxy</a> and its <code>timeout</code> \"toxic\" with the value of 0, i.e. <q>the connection won't close, and data will be delayed until the toxic is removed.</q></p>\n<p>The steps:</p>\n<p>1. Start toxiproxy, exposing the port <code>6666</code>&nbsp;that we intend to use as&nbsp;<code>localhost:6666</code>:</p>\n<pre>docker pull shopify/toxiproxy\ndocker run --name=toxiproxy --rm --expose 6666 -p 6666:6666 -it shopify/toxiproxy</pre>\n<p>(If I was on Linux and not OSX then I could use <code>--net=host</code> and wouldn't need to expose and/or map the port.)</p>\n<p>2. Tell toxiproxy to serve request att <code>6666</code>&nbsp; via an upstream service:</p>\n<pre>docker exec -it toxiproxy /bin/sh\n/ # cd /go/bin/\n/go/bin # ./toxiproxy-cli create upstream -l 0.0.0.0:6666 -u google.com:443</pre>\n<p>3. Modify your code to access the local port&nbsp;<code>6666</code>&nbsp;and test that everything works.</p>\n<p>Since we want to access Google via HTTPS, we would get a certificate error when accessing it via&nbsp;<code>localhost:6666</code>&nbsp;(e.g. \"<em>SSLHandshakeException: PKIX path building failed: [..] unable to find valid certification path to requested target</em>\" in Java or (much better) \"<em>(51) SSL: no alternative certificate subject name matches target host name 'localhost'</em>\" in curl) so we will add an alias to our local&nbsp;s&nbsp;<code>/etc/hosts</code>:</p>\n<pre>127.0.0.1 proxied.google.com</pre>\n<p>and use<br>https://proxied.google.com:6666 in our connecting code (instead of the <code>https://google.com:443</code>&nbsp;we had there before). Verify that it works and the code gets a response as expected.</p>\n<p>Note: google.com is likely a bad choice here since it will return 404 as you must specify the header&nbsp;\"Host: www.google.com\" to get 200 OK back; without it you will get 404.</p>\n<p>4. Tell toxiproxy to have an infinite timeout for this service</p>\n<p>Continuing our toxiproxy configuration from step 2:</p>\n<pre>./toxiproxy-cli toxic add -t timeout -a timeout=0 upstream</pre>\n<p>(Alternatively,&nbsp;e.g. timeout=100; then the connection will be closed after 100 ms.)</p>\n<p>5. Trigger your code again. You should get a timeout now.</p>\n<p>Tip: You can simulate the service being down via disabling the proxy:</p>\n<pre>./toxiproxy-cli toggle upstream</pre>\n<h3>Aside: Challenges when proxying through Toxiproxy</h3>\n<h5>The host header</h5>\n<p>Servers (e.g. google.com, example.com) don't like it when the Host header (derived normally from the URL) differs from what they expect. So you either need to make it possible to access localhost:&lt;toxiproxy port&gt; via the upstream server's hostname by adding it as an alias to /etc/hosts (but how do you then access the actual service?) or you need to override the host header. In curl that is easy with <code>-H \"Host: www.google.com\"</code> but not so in Java.</p>\n<p>In Java (openjdk 11.0.1 2018-10-16) you need to pass&nbsp;<code>-Dsun.net.http.allowRestrictedHeaders=true</code> to the JVM at startup to enable overriding the Host header (Oracle JVM might allow to do that at runtime) and then:</p>\n<pre>(doto ^HttpURLConnection (.openConnection (URL. \"https://proxied.google.com:6666/\"))<br>  (.setRequestProperty \"Host\" \"www.google.com\")<br>(.getInputStream)</pre>\n<h5>SSL certificate issues</h5>\n<p>As described above, when talking to HTTPS via Toxiproxy, you need to ensure that the hostname you use in your request is covered by the server's certificate, otherwise you will get SSL errors. To apply the solution described here, i.e. adding e.g. proxied.&lt;server name, e.g. google.com&gt; to your /etc/hosts works, provided the certificate is valid also for subdomains, i.e. is issued for &lt;server&gt; and *.&lt;server&gt;, which is not always the case.</p>\n<p>Alternatively, you can disable certificate validation - trivial in curl with <code>-k</code> but much more typing in Java.</p><br><br><!-- wp:paragraph -->\n<p></p>\n<!-- /wp:paragraph -->",
  "excerpt": ""
 },
 {
  "title": "Experience: Awesome productivity with ClojureScript''s REPL",
  "published": "2017-12-21 08:28:12",
  "postType": "post",
  "slug": "/2017/12/21/experience-awesome-productivity-with-clojurescripts-repl/",
  "status": "publish",
  "tags": [
   "ClojureScript",
   "productivity",
   "web"
  ],
  "categories": [
   "Languages"
  ],
  "content": "<p style=\"text-align:center;\"><em>Re-posted <a href=\"8000/blog/experience-awesome-productivity-with-clojurescript-s-repl/\">from Telia's tech blog</a>.</em></p><br><br>What's the deal with ClojureScript? How can you justify picking such a \"niche\" language? I have recently experienced a \"wow\" session, demonstrating the productivity gains of ClojureScript and the interactive development it enables thanks to its REPL. I would like to share the experience with you. (If you have never heard about it before - it is a modern, very well designed Lisp that compiles to JavaScript for frontend and backend development. It comes with a REPL that makes it possible to reload code changes and run code in the context of your live application, developing it while it is running.)<br><br><!--more--><br><br><em>Aside - about us: <a href=\"https://telia.no\">Telia Norge</a> is Norway's second largest mobile operator. Our team has spent the past three years with Node.js, React, and (eventually) Redux creating a great webshop (for hardware and subscriptions) to replace an off-the-shelf one, with a great success. Now we set out to make also the lives of our business customers much better - and we picked Clojure and ClojureScript for that.</em><br><br>The short story. I was adding an Ajax call, massaging data into the format it needed, triggering it from the UI, and handling its result or failure - a classical plumbing work. Being able to run any code from my IDE against the live, running application, accessing and changing its state at will, testing tiny code changes - all that resulted in a super quick feedback loop, enabling me to convert quickly on to working code.<br><br>One troublesome part of the code was the function formatting the application state into the form that the backend <code>submit-order</code> required. From a backend error about missing data, I was able to quickly go to running the formatting function against the actual application state, easily comparing the state and formatting output, never leaving my IDE and beloved keyboard shortcuts. As needed, replicating local variables and running parts of the function to zoom in on a particular part, fixing mistakes, and re-running, until all worked.<br><br><em>In JavaScript/Redux I would have used the Redux DevTools to explore the state, code hot reloading to update the formatting function, and the debugger to explore the output and find the bugs. I would have likely hardcoded the data so as not to loose them upon code reload and commented out the remote call itself. And I would click a button to trigger the functionality.</em><br><br>Another case in point was the display of an error message when the Ajax call failed. As usually, the code did not work at first. Using the REPL, bypassing the UI and browser, I was able to run the \"subscription\" that should have fetched the error message from the application state and supply it to the Reagent/React component, discovering the wrong data path, and go on to interactively develop the component (watching the magic of the browser updating at the command of my fingers).<br><br><em>In JavaScript/Redux I could have used the React and Redux DevTools to look at the actual data. But I don't know of a good way to debug the <code>connect</code> function extracting the relevant part of the state. (Well, I could - but never did - try to use the debugger. Typically I would add a few <code>console.log</code> to it.) Interactively developing the component would work just as well, as long as I would do something not to loose the state upon reload.</em><br><br>Having direct access to the application state, I was able to effortlessly simulate all the possible cases (resubmission, call in progress, success and error response) and ensure they were correctly handled by the UI.<br><br><h2>Comparison with vanilla JavaScript and Redux</h2><br><br>The React and Redux Dev Tools are very good. Hot code reloading works - when it works. The debugger is your good friend. I have been told that the application should have been able to preserve its state even as the code is hot reloaded, though that has not been my experience. (But that was perhaps because of local component state, not the global app state?) You can simulate the user by sending supported actions from the Redux Dev Tools.<br><br>I believe that some people might have managed to get close to the ClojureScript experience even with JavaScript and Redux. But I have never been able to match that. I have had pages that denied to be hot-reloaded despite my best efforts, state that was reset, and changes being ignored (because I mistakenly mutated data, oh the horror). The out of the box experience of ClojureScript is much better because it has been designed around immutability and explicit state management. And it has the magic of REPL that enables me to interact with the live, running application - the ultimate development tool.<br><br><h2>Conclusion</h2><br><br>My experience is that the cycle of problem discovery - troubleshooting - fix is much shorter in Clojure and ClojureScript thanks to the REPL. And when you really adopt REPL-driven development, you actually have to deal with troubleshooting problems much less since you produce small, working code changes.<br><br>To be frank, there are also some downsides. I will write about the reasons for picking Clojure(Script) and the benefits and drawbacks we have experienced in a future article.",
  "excerpt": ""
 },
 {
  "title": "How to patch Travis CI''s deployment tool for your needs",
  "published": "2018-01-09 13:10:17",
  "postType": "post",
  "slug": "/2018/01/09/how-to-patch-travis-cis-deployment-tool-for-your-needs/",
  "status": "publish",
  "tags": [],
  "categories": [
   "Tools"
  ],
  "content": "<a href=\"https://travis-ci.com/\">Travis CI</a> is a pretty good software-as-a-service Continuous Integration server. It can deploy to many targets, including AWS BeanStalk, S3, and CodeDeploy.<br><br>However it might happen that the deploy tool (<a href=\"https://github.com/travis-ci/dpl/\">dpl</a>) has a missing feature or doesn't do exactly what you need. Fortunately it is easy to fix and run a modified version of the tool, and I will show you how to do that.<br><br><!--more--><br><br>My particular problem is that dpl allows me to upload an archive to S3 and to create a CodeDeploy deployment, but it lacks the intermediary and required step of registering a new revision based on the uploaded archive. (See <a href=\"https://github.com/travis-ci/dpl/pull/732\">#732</a>)<br><br>To fix this:<br><br><ol>\n    <li>Subclass and fix the deployer</li>\n    <li>Send a pull request to Travis CI :-)</li>\n    <li>Run it as a Ruby script</li>\n</ol><br><br>Here is an example of fixing the <a href=\"https://github.com/travis-ci/dpl/blob/faa940805231f876e4aba9798a5a39e1faa20249/lib/dpl/provider/code_deploy.rb\">code_deploy.rb</a> to fetch S3 version and etag and register a revision before proceeding with creating the deployment:<br><br>https://gist.github.com/holyjak/3796133332cf317fe6acadbf77311445<br><br>As shown in the code, you can run it from the command line. To run it from your Travis CI build:<br><br><pre># excerpt from .travis.yml\ndeploy:\n  - provider: s3\n    local_dir: dpl_cd_upload\n    skip_cleanup: true\n    bucket: my-bucket \n    region: eu-west-1\n  - provider: script\n    script: ruby ./deploy_codedeploy.rb\n        --bucket=my-bucket \n        --key=myapp.zip\n        --application=my-cd-app\n        --deployment_group=my-cd-group-staging\n        --region=eu-west-1\n</pre><br><br>Enjoy!<br><br>PS: Or you can fork dpl and use your forked one, as described in <a href=\"https://github.com/travis-ci/dpl/blob/master/TESTING.md#testing-dpl-in-the-context-of-travis-ci-builds\">Testing dpl in the context of Travis CI builds</a>. This builds the whole dpl gem on the build VM.",
  "excerpt": ""
 },
 {
  "title": "Pains with Terraform (perhaps use Sceptre next time?)",
  "published": "2018-03-14 15:19:49",
  "postType": "post",
  "slug": "/2018/03/14/pains-with-terraform-perhaps-use-sceptre-next-time/",
  "status": "publish",
  "tags": [
   "aws",
   "Terraform"
  ],
  "categories": [
   "[Dev]Ops"
  ],
  "content": "<em>Cross-posted from <a href=\"http://techblog.telia.no/blog/pains-with-terraform-perhaps-use-sceptre-next-time/\">Telia's Tech Blog</a></em><br><br>We use Amazon Web Services (AWS) heavily and are in the process of migrating towards infrastructure-as-code, i.e. creating a textual description of the desired infrastructure in a Domain-Specific Language and letting the tool create and update the infrastructure.<br><br>We are lucky enough to have some of the leading Terraform experts in our organisation so they lay out the path and we follow it. We are at an initial stage and everything is thus \"work in progress\" and far from perfect, therefore it is important to judge leniently. Yet I think I have gain enough experience trying to apply Terraform both now and in the past to speak about some of the (current?) limitations and disadvantages and to consider alternatives.<br><br><!--more--><br><br>It is important to say that, despite its limitations, Terraform is an awesome tool, and likely the best solution if you use multiple IaaS/cloud services, not just AWS.<br><br><h2>Limitations and cons of Terraform</h2><br><br>The main problem I have experienced is limited support for logic in the configuration, which makes it hard to create flexible and reusable modules. I understand that sometimes there are good reasons to limit how much decision-making you can make (a well-known example are templating engines such as <a href=\"http://handlebarsjs.com/\">handlebars</a>) but here it seems to me that the pain overweights the gain. You can read more about this in the Gruntwork's post <a href=\"https://blog.gruntwork.io/terraform-tips-tricks-loops-if-statements-and-gotchas-f739bbae55f9\">Terraform tips &amp; tricks: loops, if-statements, and gotchas</a> (10/2016).<br><br>Here are the main obstacles I have encountered (worth mentioning that some of them may be intrinsic problems that cannot be solved by any tool):<br><br><ol>\n<li>No direct support for logic and loops makes reusable and configurable modules harder. There are ugly hacks that allow some configurability, such as using <code>count</code> of 0 or 1 on a resource instead of (a desired) <code>create = true|false</code> (and then <code>\"${element(..., 0)}\"</code> to get back the single element instead of an array).</li>\n<li>There is no way to skip a <code>module</code>, i.e. to simulate a <code>create</code> flag on it since the aforementioned <code>count</code> parameter is not available on modules. (Unless the module author was thoughtful enough to add a <code>create</code> flag of his own.)</li>\n<li>Limited reusability: the recently added local variables (<code>locals</code>) can only refer to attributes not whole resources so you have to to repeat the same expression for every attribute that you need. For example <code>codedeploy_bucket_arn = \"${element(compact(concat(aws_s3_bucket.codedeploy_bucket.*.arn, data.aws_s3_bucket.codedeploy_bucket.*.arn)), 0)}\"</code> and <code>codedeploy_bucket_name = \"${element(compact(concat(aws_s3_bucket.codedeploy_bucket.*.id, data.aws_s3_bucket.codedeploy_bucket.*.arn)), 0)}\"</code>. Ugly, right?</li>\n<li>In some cases it is not possible to have configuration depending on a yet-to-be-created infrastructure, e.g. creating a security group that should allow access from another security group in the same config (see the <a href=\"https://github.com/terraform-aws-modules/terraform-aws-security-group/issues/16\">sec. group issue #16</a>).</li>\n<li>Support for modules and reusability is limited. <a href=\"https://github.com/gruntwork-io/terragrunt\">Terragrunt</a> tries to mitigate some of these issues, allowing you to define e.g. remote state storage only once, yet it is still unnecessarily verbose. To me that means there is an underlying issue with the design.</li>\n<li>Interpolation (i.e. using variables) is not allowed at some places, e.g. in a <code>.tfvars</code> file used extensively with Terragrunt modules, which is quite inconvenient.</li>\n<li>Eventual consistency - Terraform does not always know to wait for a resource creation and full propagation and you might get weird errors and need to rerun it a few times. (Can perhaps be solved by specifying <code>depends_on</code> or adding some sleep time.)</li>\n<li>Terragrunt's <code>apply-all</code> did not really work for me, failing randomly and forcing me to manually unlock state and execute individual modules. Perhaps it is a problem with how we use it but this should be simple enough to work out of the box. (However <code>plan-all</code> worked nicely so I used that to find out which modules I need to apply manually. <code>validate-all</code> works well too.)</li>\n</ol><br><br>The <a href=\"https://amp.reddit.com/r/aws/comments/5rfmoq/introducing_sceptre_a_new_tool_to_drive/\">Introducing Sceptre a new tool to drive CloudFormation</a> thread at Reddit has also some insightful comments, such as ocsi01's (who is certainly biased, as the lead developer of Sceptre) (2/2017):<br><br><blockquote>\n  My issues with Terraform: https://github.com/hashicorp/terraform/issues/6045 Which is an example of it's reliability and maturity. (Along with the rest of the bugs and issues seen on github, some of them are really old.)\n  \n  Furthermore it's not supporting the description of a big, multi environment system following best practices like DRY. ( Mostly because of the lack of support for complex, structured properties like lists of maps, maps of maps, etc.) (They are developing it but the feature is not there yet, its not mature.)\n  \n  So my reasons to change:\n  \n  -Sceptre based on CloudFormation which is officially supported by AWS.\n  \n  -Sceptre using Troposphere, which gives you the potential to use python as a mature language. ( Compare to Terraform, where you cannot use custom code snippets, if it's not implemented/supported by TF.)\n  \n  -This makes easy to create and reuse highly generic templates.\n  \n  -Great support for using the exact same codebase for highly configured environments ( like dev, test, prod).\n  \n  -Supports change-sets, which was the only big selling point of Terraform a year ago.\n</blockquote><br><br><h2>Some pros of Terraform (as compared to CloudFormation)</h2><br><br>Terraform has quite a few advantages over raw CloudFormation (though Sceptre/Troposphere mitigate most if not all of these.) From Piotr Gospodarek's <a href=\"https://medium.com/@piotrgospodarek/cloudformation-vs-terraform-990318d6a7de\">CloudFormation vs Terraform</a> (10/2017):<br><br><ul>\n<li>Can see the changes to be performed before execution</li>\n<li>Far less verbose than CF's YAML</li>\n<li>Far better validity checks than CF</li>\n<li>Integrate other providers (Fastly, Firebase,,,.)</li>\n<li>Can use <code>data</code> to fetch info from AWS/state/...</li>\n</ul><br><br>(You might also want to check out the Reddit thread <a href=\"https://www.reddit.com/r/devops/comments/6avi5t/who_prefers_cloudformation_to_terraform/\">Who prefers CloudFormation to Terraform?</a>)<br><br><h2>Alternatives: Sceptre + Troposphere</h2><br><br>I agree with Piotr above that CloudFormation templates are good for machines but bad for people. Yet they are a good base to built upon. The best alternative, provided that you use exclusively AWS, seems to me (after a non-exhaustive search) to be Sceptre + Troposphere + Awacs. (<a href=\"https://github.com/remind101/stacker\">stacker</a> is a - reportedly more heavy-weight - alternative to Sceptre). These provide essentially native access to declaring AWS infrastructure pieces with the full power of a general purpose programming language (Python) when you need it.<br><br><ul>\n<li><a href=\"https://sceptre.cloudreach.com/latest/\">Sceptre</a> - a tool to drive Cloudformation. Sceptre manages the creating, updating and deletion of stacks, and provides meta commands to allow users to get information about their stacks.</li>\n<li><a href=\"https://github.com/cloudtools/troposphere/\">Troposphere</a> - Python DSL for creating CloudFormation descriptions (templates) - thus similar to a little more verbose Terraform but much more powerful</li>\n<li><a href=\"https://github.com/cloudtools/awacs\">Awacs</a> - Python library for AWS Access Policy Language creation (similar to Terraform's <a href=\"https://www.terraform.io/docs/providers/aws/d/iam_policy_document.html\">aws_iam_policy_document</a>)</li>\n</ul><br><br>What does Sceptre provide:<br><br><ul>\n<li>\"User Variables\" (a.k.a. Sceptre User Data) in addition to CF's native Parameters; contrary to those, User Variables may change the templates and thus enable conditional creation of a resource or creating a configurable number of resources</li>\n<li>Connect Stacks (i.e. modules) together, chaining Outputs from some as Parameters to others</li>\n<li>Show what is going to be changed before changing is, just as Tf's <code>plan</code>, using CF's Change Sets</li>\n<li>Source Parameters from external files etc. or anywhere else with a custom resolver (i.e. similar to Tf Data Sources)</li>\n<li>Configure hooks to run when Sceptre actions occur</li>\n<li>Allow CF template creation using CF JSON/YAML, Jinja2 (YAML/JSON) templates, or Python (Troposphere &amp; Co.)</li>\n<li>Easy support for working with role assumes or in multiple accounts</li>\n</ul><br><br><h3>Possible disadvantages of Spectre &amp; Co.</h3><br><br>A colleague of mine has kindly shared his experiences with tooling similar to Spectre, namely Ansible + Troposphere + Jinja2 + CF. Here are some of his comments regarding a steeper learning curve etc.:<br><br><blockquote>\n  I would say CloudFormation is harder to learn then terraform, also its really easy for files to become massive in CloudFormation since there is no easy way to split them except for using nested stacks which is tricky. We also made heavy use of Jinja2 for loops etc which made it harder to for beginners since they needed to learn both CF and Jinja2\n  \n  Troposphere is really nice and we used that for some stuff but since that generates a cloudformation you still need to understand what they generate so most of the times we skipped it and just went directly to CF/Jinja2\n</blockquote><br><br>Terraform modules are reportedly more flexible than CF Stacks. For example they support versioning so you can lock down what version your code use and not be affected by its development.<br><br><h2>Conclusion</h2><br><br>The next time when creating infrastructure-as-code, I would definitely love to try Sceptre &amp; friends instead of Terraform. On the other hand, if I needed to support something else beside AWS, I would stick with Terraform. But everything keeps evolving and the future is bright :-)",
  "excerpt": ""
 },
 {
  "title": "Why we love AWS Beanstalk but are leaving it anyway",
  "published": "2018-03-14 15:24:14",
  "postType": "post",
  "slug": "/2018/03/14/why-we-love-aws-beanstalk-but-are-leaving-it-anyway/",
  "status": "publish",
  "tags": [
   "aws",
   "DevOps"
  ],
  "categories": [
   "[Dev]Ops"
  ],
  "content": "<em>Cross-posted <a href=\"http://techblog.telia.no/blog/why-we-love-aws-beanstalk-but-are-leaving-it-anyway/\">from Telia's Tech Blog</a>.</em><br><br>We have had our mission-critical webapp running on <a href=\"https://aws.amazon.com/elasticbeanstalk/\">AWS Elastic Beanstalk</a> for three years and have been extremely happy with it. However we have now outgrown it and move to a manually managed infrastructure and CodeDeploy.<br><br>AWS Beanstalk provides you with lot of bang for the buck and enables you to get up and running in no time:<br><br><ul>\n<li>Simple, no-downtime deployment and automatic roll-back based on user-provided health-check (either one subset of nodes at a time or blue-green deployment)</li>\n<li>Autoscaling</li>\n<li>Managed updates - security fixes and other improvements installed automatically</li>\n<li>Built-in HTTP Proxy with caching in front of your application</li>\n<li>Monitoring dashboard with alerting and access to logs without the need for SSH</li>\n<li>A list of past versions &amp; ability to roll-back</li>\n<li>Support for many runtimes (Java, Node.js, Docker to name just a few)</li>\n</ul><br><br>So if you need a solid, state-of-the-art infrastructure for a <a href=\"https://www.youtube.com/watch?v=b2F-DItXtZs\">web-scale</a> application and you don't have lot of time and/or skill to build one on AWS on your own, I absolutely recommend Beanstalk.<br><br><!--more--><br><br>We have of course also experienced some downsides - it took quite a while for Amazon to upgrade from Node 4 to 6 (though now it is far ahead of us), there is a lot going on during a deployment and it can sometimes fail mysteriously, and you are rather limited to what it provides. But the main reason that we are moving away from it is that we are implementing infrastructure-as-code and want to be able to describe our infrastructure in a textual configuration with history, checked into a version control system. Lot of beanstalk configuration is done through the AWS Console and thus it is impossible to see its evolution over time. (It is possible to configure something in a <code>.ebextensions/</code> directory of your application, but it requires quite some knowledge and may be at odds with changes in the Console.)",
  "excerpt": ""
 },
 {
  "title": "Troubleshooting javax.net.ssl.SSLHandshakeException: Received fatal alert: handshake_failure",
  "published": "2018-10-05 12:49:34",
  "postType": "post",
  "slug": "/2018/10/05/troubleshooting-javax-net-ssl-sslhandshakeexception-received-fatal-alert-handshake_failure/",
  "status": "publish",
  "tags": [
   "java",
   "security",
   "troubleshooting"
  ],
  "categories": [
   "General",
   "Languages"
  ],
  "content": "<em>Re-published from the <a href=\"https://techblog.telia.no/blog/troubleshooting-javax-net-ssl-sslhandshakeexception-received-fatal-alert-handshake-failure/\">Telia Tech Blog</a>.</em><br><br>The infamous Java exception <code>javax.net.ssl.SSLHandshakeException: Received fatal alert: handshake_failure</code> is hardly understandable to a mere mortal. What it wants to say is, most likely, something like this:<br><br><blockquote>\n  Sorry, none of the cryptographic protocols/versions and cipher suites is accepted both by the JVM and the server.\n</blockquote><br><br>For instance the server requires a higher version of TLS than the (old) JVM supports or it requires stronger cipher suites than the JVM knows. You will now learn how to find out what is the case.<br><br>We will first find out what both the server and the JVM support and compare it to see where they disagree. Feel free to just skim through the outputs and return to them later after they were explained.<br><br><h3>What does the server support?</h3><br><br>We will use <code>nmap</code> for that (<code>brew install nmap</code> on OSX):<br><br><pre><code>\nmap --script ssl-enum-ciphers -p 443 my-server.example.com\nStarting Nmap 7.70 ( https://nmap.org ) at 2018-10-05 00:54 CEST\nNmap scan report for my-server.example.com (127.0.0.1)\nHost is up (0.031s latency).<br><br>PORT STATE SERVICE\n443/tcp open https\n| ssl-enum-ciphers:\n| TLSv1.2:\n| ciphers:\n| TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384 (secp256r1) - A\n| TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256 (secp256r1) - A\n| TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA384 (secp256r1) - A\n| TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA (secp256r1) - A\n| TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256 (secp256r1) - A\n| TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA (secp256r1) - A\n| compressors:\n| NULL\n| cipher preference: server\n|_ least strength: A\n</code></pre><br><br>Here we see that the server only supports TLS version 1.2 (<code>ssl-enum-ciphers: TLSv1.2:</code>) and the listed <code>ciphers</code>, such as <code>TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA</code>.<br><br><h3>What does the JVM have on offer?</h3><br><br>Now we will find out what the JVM supports (I did that through Clojure but you could have just as well used Java directly; notice the <code>javax.net.debug</code> property):<br><br><pre><code>\nsh $ env -i java -Djavax.net.debug=ssl:handshake:verbose java -jar clojure-1.8.0.jar\nClojure 1.8.0\nuser=&gt; (.connect (.openConnection (java.net.URL. &quot;https://my-server.example.com/ping&quot;)))\n;; ...\ndone seeding SecureRandom\nIgnoring unavailable cipher suite: TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA\nIgnoring unavailable cipher suite: TLS_DHE_RSA_WITH_AES_256_CBC_SHA\nIgnoring unavailable cipher suite: TLS_ECDH_RSA_WITH_AES_256_CBC_SHA\nIgnoring unsupported cipher suite: TLS_DHE_DSS_WITH_AES_128_CBC_SHA256\nIgnoring unsupported cipher suite: TLS_DHE_DSS_WITH_AES_256_CBC_SHA256\nIgnoring unsupported cipher suite: TLS_DHE_RSA_WITH_AES_128_CBC_SHA256\nIgnoring unsupported cipher suite: TLS_ECDH_RSA_WITH_AES_128_CBC_SHA256\nIgnoring unsupported cipher suite: TLS_DHE_RSA_WITH_AES_256_CBC_SHA256\nIgnoring unsupported cipher suite: TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA384\nIgnoring unsupported cipher suite: TLS_ECDH_ECDSA_WITH_AES_256_CBC_SHA384\nIgnoring unsupported cipher suite: TLS_RSA_WITH_AES_256_CBC_SHA256\nIgnoring unavailable cipher suite: TLS_ECDHE_ECDSA_WITH_AES_256_CBC_SHA\nIgnoring unsupported cipher suite: TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256\nIgnoring unsupported cipher suite: TLS_ECDHE_ECDSA_WITH_AES_256_CBC_SHA384\nIgnoring unavailable cipher suite: TLS_DHE_DSS_WITH_AES_256_CBC_SHA\nIgnoring unsupported cipher suite: TLS_ECDH_RSA_WITH_AES_256_CBC_SHA384\nIgnoring unsupported cipher suite: TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256\nIgnoring unsupported cipher suite: TLS_ECDH_ECDSA_WITH_AES_128_CBC_SHA256\nIgnoring unavailable cipher suite: TLS_ECDH_ECDSA_WITH_AES_256_CBC_SHA\nIgnoring unavailable cipher suite: TLS_RSA_WITH_AES_256_CBC_SHA\nIgnoring unsupported cipher suite: TLS_RSA_WITH_AES_128_CBC_SHA256\nAllow unsafe renegotiation: false\nAllow legacy hello messages: true\nIs initial handshake: true\nIs secure renegotiation: false\nmain, setSoTimeout(0) called\n%% No cached client session\n*** ClientHello, TLSv1\nRandomCookie: GMT: 1521850374 bytes = { 121, 217, 101, 186, 111, 183, 47, 46, 159, 230, 139, 103, 7, 181, 250, 172, 113, 121, 4, 55, 122, 148, 111, 82, 87, 170, 70, 10 }\nSession ID: {}\nCipher Suites: [TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA, TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA, TLS_RSA_WITH_AES_128_CBC_SHA, TLS_ECDH_ECDSA_WITH_AES_128_CBC_SHA, TLS_ECDH_RSA_WITH_AES_128_CBC_SHA, TLS_DHE_RSA_WITH_AES_128_CBC_SHA, TLS_DHE_DSS_WITH_AES_128_CBC_SHA, TLS_ECDHE_ECDSA_WITH_RC4_128_SHA, TLS_ECDHE_RSA_WITH_RC4_128_SHA, SSL_RSA_WITH_RC4_128_SHA, TLS_ECDH_ECDSA_WITH_RC4_128_SHA, TLS_ECDH_RSA_WITH_RC4_128_SHA, TLS_ECDHE_ECDSA_WITH_3DES_EDE_CBC_SHA, TLS_ECDHE_RSA_WITH_3DES_EDE_CBC_SHA, SSL_RSA_WITH_3DES_EDE_CBC_SHA, TLS_ECDH_ECDSA_WITH_3DES_EDE_CBC_SHA, TLS_ECDH_RSA_WITH_3DES_EDE_CBC_SHA, SSL_DHE_RSA_WITH_3DES_EDE_CBC_SHA, SSL_DHE_DSS_WITH_3DES_EDE_CBC_SHA, SSL_RSA_WITH_RC4_128_MD5, TLS_EMPTY_RENEGOTIATION_INFO_SCSV]\nCompression Methods: { 0 }\nExtension elliptic_curves, curve names: {secp256r1, sect163k1, sect163r2, secp192r1, secp224r1, sect233k1, sect233r1, sect283k1, sect283r1, secp384r1, sect409k1, sect409r1, secp521r1, sect571k1, sect571r1, secp160k1, secp160r1, secp160r2, sect163r1, secp192k1, sect193r1, sect193r2, secp224k1, sect239k1, secp256k1}\nExtension ec_point_formats, formats: [uncompressed]\nExtension server_name, server_name: [host_name: my-server.example.com]\n***\nmain, WRITE: TLSv1 Handshake, length = 175\nmain, READ: TLSv1 Alert, length = 2\nmain, RECV TLSv1 ALERT: fatal, handshake_failure\nmain, called closeSocket()\nmain, handling exception: javax.net.ssl.SSLHandshakeException: Received fatal alert: handshake_failure\nSSLHandshakeException Received fatal alert: handshake_failure sun.security.ssl.Alerts.getSSLException (Alerts.java:192)\n</code></pre><br><br>Here we see that the JVM uses TLS version 1 (see <code>*** ClientHello, TLSv1</code>) and supports the listed <code>Cipher Suites</code>, including <code>TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA</code>.<br><br><h3>What's wrong?</h3><br><br>Here we see that the server and JVM share exactly one cipher suite, <code>TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA</code>. But they fail to agree on the TLS version, since the server requires v1.2 while the JVM only offers v1.<br><br><h3>The solution</h3><br><br>You can either configure the server to support a cipher suite and protocol version that the JVM has or teach JVM to use what the server wants. In my cases that was resolved by running <code>java</code> with <code>-Dhttps.protocols=TLSv1.2</code> (alternatively, you could add all of <code>SSLv3,TLSv1,TLSv1.1,TLSv1.2</code>) as <a href=\"https://stackoverflow.com/questions/39157422/how-to-enable-tls-1-2-in-java-7\">recommended by π at StackOverflow</a>.<br><br><h2>Sources</h2><br><br>The troubleshooting technique comes from the article \"<a href=\"https://confluence.atlassian.com/jirakb/sslhandshakeexception-received-fatal-alert-handshake_failure-due-to-no-overlap-in-cipher-suite-943544397.html\">SSLHandshakeException: Received fatal alert: handshake_failure due to no overlap in cipher suite\n</a>\" by Atlassian. The observation that the server and JVM disagreed on the TLS version comes from my good colleague Neil.",
  "excerpt": ""
 },
 {
  "title": "Monitoring process memory/CPU usage with top and plotting it with gnuplot",
  "published": "2018-10-17 10:03:19",
  "postType": "post",
  "slug": "/2018/10/17/monitoring-process-memory-cpu-usage-with-top-and-plotting-it-with-gnuplot/",
  "status": "publish",
  "tags": [
   "monitoring",
   "performance"
  ],
  "categories": [
   "[Dev]Ops"
  ],
  "content": "<img class=\" size-medium wp-image-4759 alignleft\" src=\"/images/2018/10/siege-c3e2.png?w=300\" alt=\"siege-c3e2\" width=\"300\" height=\"225\" /><br><br>If you want to monitor the memory and CPU usage of a particular Linux process for a few minutes, perhaps during a performance test, you can capture the data with <code>top</code> and plot them with <code>gnuplot</code>. Here is how:<br><br><!--more--><br><br>Run this script (perhaps via <code>nohup</code>) to capture the data:<br><br>https://gist.github.com/holyjak/931a3441982c833f5f8fcdcf54d05c91<br><br>then plot them via <code>./usage-plot.gp top.dat top.png</code>:<br><br>https://gist.github.com/holyjak/1b58dedae3207b4a56c9abcde5f3fdb5",
  "excerpt": ""
 },
 {
  "title": "Beware the performance cost of async_hooks (Node 8)",
  "published": "2018-11-01 09:52:30",
  "postType": "post",
  "slug": "/2018/11/01/beware-the-performance-cost-of-async_hooks-node-8/",
  "status": "publish",
  "tags": [
   "nodejs",
   "performance"
  ],
  "categories": [
   "Languages"
  ],
  "content": "I was excited about <a href=\"https://nodejs.org/api/async_hooks.html\">async_hooks</a> having finally landed in Node.js 8, as it would enable me to share important troubleshooting information with all code involved in handling a particular request. However it turned out to have terrible impact of our CPU usage (YMMV):<br><br><img title=\"Production CPU usage spikes after async_hook deployment\" src=\"https://lh3.googleusercontent.com/3jnASSSx-wRJwWyFI6yxYklPZInqHJKuXcKJlIP-UoozB9sHi1bUW_pC5A2_XLWYWzg1AdKQqwGUXaZN9VvTZs8fij-JsefZ4jGWzvUzQA64brNTY0lB4Wp5C497hxP0Da55C6k4qcOmlPTwBr8B4mumQyXhmuYc2Op_Ng2zA1nPqf3ZdcjmhGerqYRTfHiLr5aS7_nB6D2upWAZ3phZm5KgWF4E7VsuRZs5PFuk_NaFjDNIKLx2mkRFee1VbqLxYYlPKaLuTk0_jX7yw0UGHZrCtnk5S5J66IaxT-eAuDG7HEtHe5qtY9N6odD5xaghzKcAGJBAHJHPBdxT8UiEFEEOmo6ES20_KjsJAocFlYir1rLkgbRRBXl96t8gphbo4u1CTxRsYkOcQateop9q1lMgRM3vzBtIkaTi306ey0-wmVMr6nwZKjrqvlOiNVExJCqvCtA8ny3O8gBr57LCEqbsVpd8uDiDarL8xv8jKwqYPlH6w_4Ib-5FsCejrpbxDYWuatW1z43OEHg5gAQbcH8G4e0cckYVS9568HLlwZY-3yzY3bN3bYuU2GqcACjgjWcMN_uoTivgK9_w55fKsW4DmJ6fS6XNsIGAH2JQthCi_pQQBS-_Gw3ZkvaDFeRgGpCqcFu-2_Qi3PzyhXLBVOFj=w524-h221-no\" /><br><br>This was quite extreme and is likely related to the way how our application works and uses Promises. Do your own testing to measure the actual impact in your app.<br><br>However I am not the only one who has seen some performance hit from async_hooks - see <a href=\"https://github.com/bmeurer/async-hooks-performance-impact\">https://github.com/bmeurer/async-hooks-performance-impact</a>, in particular:<br><br>Here the results of running the Promise micro benchmarks with and without <code>async_hooks</code> enabled:<br><br><table>\n<thead>\n<tr>\n<th align=\"right\">Benchmark</th>\n<th align=\"right\">Node 8.9.4</th>\n<th align=\"right\">Node 9.4.0</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td align=\"right\">Bluebird-doxbee (regular)</td>\n<td align=\"right\">226 ms</td>\n<td align=\"right\">189 ms</td>\n</tr>\n<tr>\n<td align=\"right\">Bluebird-doxbee (init hook)</td>\n<td align=\"right\">383 ms</td>\n<td align=\"right\">341 ms</td>\n</tr>\n<tr>\n<td align=\"right\">Bluebird-doxbee (all hooks)</td>\n<td align=\"right\">440 ms</td>\n<td align=\"right\">411 ms</td>\n</tr>\n<tr>\n<td align=\"right\">Bluebird-parallel (regular)</td>\n<td align=\"right\">924 ms</td>\n<td align=\"right\">696 ms</td>\n</tr>\n<tr>\n<td align=\"right\">Bluebird-parallel (init hook)</td>\n<td align=\"right\">1380 ms</td>\n<td align=\"right\">1050 ms</td>\n</tr>\n<tr>\n<td align=\"right\">Bluebird-parallel (all hooks)</td>\n<td align=\"right\">1488 ms</td>\n<td align=\"right\">1220 ms</td>\n</tr>\n<tr>\n<td align=\"right\">Wikipedia (regular)</td>\n<td align=\"right\">993 ms</td>\n<td align=\"right\">804 ms</td>\n</tr>\n<tr>\n<td align=\"right\">Wikipedia (init hook)</td>\n<td align=\"right\">2025 ms</td>\n<td align=\"right\">1893 ms</td>\n</tr>\n<tr>\n<td align=\"right\">Wikipedia (all hooks)</td>\n<td align=\"right\">2109 ms</td>\n<td align=\"right\">2124 ms</td>\n</tr>\n</tbody>\n</table><br><br>To confirm the impact of async_hook on our app, I have performed 3 performance tests:<br><br><h5>CPU usage without async_hooks (Node 8)</h5><br><br>It is difficult to see but the mean CPU usage is perhaps around 60% here.<br><br><img title=\"Usage without async hooks\" src=\"https://lh3.googleusercontent.com/tKVlaTA7MfGOz-vW6DzzkcIgnCg4ufGHX0ozpWo85446LatJ8boXGzQc0qY6hcqep63nS6T38u4oLrZtKi_tlnHgWKzzSHuSjDKYhJfDpOcmbPKNIUIadO7U1QysgrTIJhDtGAr-A3m6MNBxfQeJNe7Yj1mvfqZZg1Rb9i34115Ag_8Ww8A8NU_P5pmuA_5-9oeN5CcANW7A2oVZeSwdEIHJlsAU7360Aqb4pH1Ngk-3X5-lDNlcTe0lm_pMHyvsSlDwPt4uLqZfGeKGKdhQy7y4VKLrJgIZnHkkjk3iDqmAL5CvE6Qf9Au3KwDwqWDcO8r9nBREOaUFyIXcKBr1ujP1rqFmrYk2V-p6Ni2ma2hFZoPprTrsnqdRrmk-8nv9xNFEUBfJx0YmPLp38q2Kg6NldrdaIarrVaTO7wAg7c43XYu1ae79iMmo_rs0PCBgcxSaHB2s0VO-E55EWxF53Us1h4Dm1IC2ktIu14QKRAgYmOjwRLl80hswHLm4NfBWn1VGcNAY1exFvtHwMZMp0N-ELYgcZaF3XgkD-Xu6YLZVAi-kAdZh7ZTZXlXfikdK94mh4OBW8NjnCWrbcuIFockhuLQaDe-h95awlCExdW3TNL3bLDYgViiXAn24w7t0yOVtL8Odk6hQYzirIfLgkDIE=w500-h378-no\" /><br><br><h5>CPU usage with \"no-op\" async_hooks (Node 8)</h5><br><br>Here the CPU jumped to 100%.<br><br><img title=\"CPU usage with async hooks (that did nothing)\" src=\"https://lh3.googleusercontent.com/l_QPdAzalw-dGZpTVVFUgSRE9elcnrP1f3yloVU9tnN182H08p1Wg7WSEjQkOBnKm327XW3IIISUALa84W4pBihWKh6c8-u_az852lrudy6zH3FhAQJKIC6FuUNRPgYC_oNq7VqIHcAfxmkomvY6zH1Dlp2MxS6cMkJo5tE1_mntia-grVlcNezg0DabrefrvTkdzrMZzPDMRxZjF0JxmlfLTKlmiBBdu9mMaBYpmMq0mg8ZCwCV_BngqlHtuGp8N2ZwJjqqOnZe1HzeA_d2FzdKoYBcBaGpO3dX7uEQgZvtZTYucV4G44iwihfLfnDjV6YyiDPTHw2GXIDi-iOLaOasCjkZ0o3TXySnv3hv7z3mWiJDBdCZnKDFJwuWa_w234EChDuMsoG9wxH-1hOdgUkC4SKu06XsUCVPiIZ7_OsbQbPb1q4km8IlaoJ3Rnb6q6HcuKySMij6WAm2oApkHjY42cnZowyi0QthYiJ3FcJx9lgcClHRYIyDxxLtKbIbV85DtbNDR0zjei4acDklZb5x8z12BsjqqCy92JWo_lEgepqVatYGhZiYSwdFGEDQM52sSqgjqrNQr12NLyB1Hsdyj_KzMv4eolHhqvYWXABBS-jFEfJNbmZsW9poau1ZiaAogkQXZaE08rzkUql2DFyr=w500-h378-no\" /><br><br><h5>CPU usage with \"no-op\" async_hooks (Node 11)</h5><br><br>The same as above, but using Node 11 for comparison. I recorded it for just a few minutes but the CPU usage is still around 100%:<br><br><img title=\"Async hooks on Node 11\" src=\"https://lh3.googleusercontent.com/_5FI-y2oCB9eNmG9f6VhCMJNQW6JeF--H1Qe-gLppBll2E32agzyxBhpp8odQM1-WhSyatvL-StQ-iC4YGfWsPkikzBe19p6g7Hr6toJ5C2zU3dlc-XJJBb14Gpx6JMwQyvXYvjah_rtJT_c0pYnTnJmFypfuRneVi62xHk3W7S39TDqv4FMVY2JNg593alspr8ErCEEDLfAe1I0Kph-TX79i3yMTVzrJyp0Bj6bOutMmNsKnXsimR2PR1LRZD9l2v6sBkcZAebpaXHIz_VmJq6_14Hp8bgoYBPHkGsB74Nj0IPBQ2tHKC8yASOsrHfvZCRssy2FD6AYJHzD2dMlCNGUQODMfmhgp-FyRxQH9HZC1OJ29d7Z8h0o5ksl5wclxlVJacjZ8GD4l-yKVWm_5PMaObz1tYT1-4T3WctSzo6BBDql7Vd8EW4LF1hzuZI93fQQ6ydK20rM4l5RABwP7bQ2Dj72ONqhHMtS24TVTF8kOR1UiKYgMA9xvtZr4qCHr5a9vk4Zh9zQRoaaHCE5YYQXWllC1xDJqYwtDOLrJB6lIFTOtQ_KhEAbMCdTEuhJjZ27NUH2tlej-aRFMsbzYQ0DILHKdwYXCyyV1fRnfCJLHYAr-nykKlk5CLdvp-52TVD94KVdWYLlKC5-NYx6WkEH=w500-h378-no\" /><br><br><h3>The code</h3><br><br>This is the relevant code:<br><br>https://gist.github.com/holyjak/bd5060bfb16cd1431f306761656b55d7",
  "excerpt": ""
 },
 {
  "title": "How good monitoring saved our ass ... again",
  "published": "2018-11-01 11:55:48",
  "postType": "post",
  "slug": "/2018/11/01/how-good-monitoring-saved-our-ass-again/",
  "status": "publish",
  "tags": [
   "monitoring"
  ],
  "categories": [
   "[Dev]Ops"
  ],
  "content": "You know how it goes - suddenly people complain your app does not work, your are getting plenty of timeouts or other errors in your error tracking tool, you find the backend app that is misbehaving and finally \"fix\" the problem by restarting it. Phew!<br><br>But why? What caused the downtime? A glitch an an upstream system? Sudden overload due to a spike in concurrent users? Trolls?<br><br>You know that it helps sometimes to zoom out, to get the right perspective. Here the perspective was 7 days:<br><br><img title=\"System load over the past 7 days\" src=\"https://lh3.googleusercontent.com/iD8MlIDGGPM26RoMopxITnfTCG_OcF3-5tyD9tyImQnihoYe6e83BUMTX76lL2HD3BmJDYx-3rETnrAva0bAHh48efpoaDd3VOOOWiKGzqqvkQQFGSz5o9xnT843sqXjkXsJHxgEP1udYeQ14NgFsABJaC_3p7SvWT33qvSzmqP0TMo_XXrush-FtjrGNsqQ0CbC107ja0NpCCHpdHcNuYVl6VYrIjc6e8Ib1LVrzI_MJ9fIuZ0boJ0-IkRsyxazA_5g4LwhGfi4ulVbyaFK-GP61mrzUtuBGhbs9f0Wmr-ACKyS6Ue0xNnE55yujlF1oPEhDoCm76Oi2qskpwMrREEnURBAmTq1dy8yfn4MdjTUrbUMqVUZkoL78o7qhADK2_UOAFBwUHAbS_2zQuqEtlSBwFA_57xc0X6sDLcm4SHoK7OZYoPix0UecMC1dEKwelsKGK5IEzmmpcRe5grPBYms0QOaH7rTlpKqLC0L549HGik8jXJti6l1J8VHuUVz_oMQwIdsz8mQBMNmAXK7G6vmLZV3yTiIbYTU-w0MAQlKPsD-BKQ-MX_JYsx7t3lO5BH5uav2fPF_biyzveZcjkilkMnsIc8JyeO6X6r-jEzlC6e8vW1mxozj2CVwzN5jnn0VLC2nZgcZRoBbk8GeGnZx=w524-h221-no\" /><br><br>It was enough to look at this chart with the right zoom to see at once that something happened on October 23rd that caused a significant change in the behavior of the application. Quick search and indeed, the change in CPU usage corresponds with a deployment. A quick revert to the previous version shortly confirmed the culprit. (It would have been even easier if we showed deployments on these charts.)<br><br>This is not the first time good monitoring saved us. A while ago we struggled regularly with the application becoming sluggish and had to restart it regularly. A graph of the Node.js even loop lag showed it increasing over time. Once it was on the same dashboard as Node's heap usage, we could at once see that it correlated with increasing memory usage - indicating a memory leak. Few hours of experimenting and heap dump analysis later the problem was fixed.<br><br><strong>So good monitoring is paramount.</strong><br><br>Of course the trick is to know what to monitor and to display all relevant metrics in such a way that you can spot important relations. I am still working on improving that...",
  "excerpt": ""
 },
 {
  "title": "How I got fired and learned the importance of communication and play time",
  "published": "2018-11-04 06:49:15",
  "postType": "post",
  "slug": "/2018/11/04/how-i-got-fired-and-learned-the-importance-of-communication-and-play-time/",
  "status": "publish",
  "tags": [
   "experience",
   "work"
  ],
  "categories": [
   "General"
  ],
  "content": "<p class=\"p1\">When I came to the office one late autumn morning in 2005, I have been shocked to find out that - without any warning signs whatsoever - I hd been fired. That day I have learned the importance of communication. Their criticism was justified but the thing is, nobody bothered to tell me anything during my 11 months in the company. I received exactly 0 feedback about my behaviour or work. The company ended up at court with its client - which both explains why they were stressed and was also caused by bad communication. So communication - even, or especially under stress - is really important. It must be open, transparent, and broad.</p><br><br><p class=\"p1\">The funny thing is that I still do the things they fired me for.</p><br><br><!--more--><br><br><p class=\"p1\">One criticism was that I wasn't coming on time to the office. I never slacked, I always worked my hours (if not more), but indeed I made my hours more flexible then they were. Nobody ever complained about my late arrivals so I concluded it was OK (lack of communication on my part). Having flexible working hours so that I don't need to stress about every minute and can adjust to the current circumstances (while still respecting the shared core hours as much as possible) is still very important to me.</p><br><br><p class=\"p1\">The other main criticism was that I sometimes spent time producing utility libraries instead of working on the tasks assigned to me. I realise now I will never be the guy who can focus 100% on producing features (aside of short periods of crisis). It is crucial for me to have some 10 - 20% \"play time\" when I can work on things that are important for me such as tooling, utility libraries, code improvements. Thus, at my current company, I have created a Slack bot to ease the testing of our app, a metrics and monitoring solution for the app, spent a day performance testing our data server to find out its baseline behaviour and bottlenecks (discovering that we can downscale our production setup and save money), spent another day experimenting with different charting tools to find a good fit for my current and future needs, and contributed documentation improvements to Node.js and Clojure and fixes to TravisCI and various libraries. Admittedly, I should get better at communicating and aligning my interests with team's (and do a better job of getting them on board). And it is important to ensure that my contribution to the shared efforts does not suffer.</p>",
  "excerpt": ""
 },
 {
  "title": "Clojure - comparison of gnuplot, Incanter, oz/vega-lite for plotting usage data",
  "published": "2018-11-04 12:23:37",
  "postType": "post",
  "slug": "/2018/11/04/clojure-comparison-of-gnuplot-incanter-oz-vega-lite-for-plotting-usage-data/",
  "status": "publish",
  "tags": [
   "charting",
   "clojure",
   "data analysis"
  ],
  "categories": [
   "Languages",
   "[Dev]Ops"
  ],
  "content": "What is the best way to plot memory and CPU usage data (mainly) in Clojure? I will compare gnuplot, Incanter with JFreeChart, and vega-lite (via Oz). (Spoiler: I like Oz/vega-lite most but still use Incanter to prepare the data.)<br><br>The data looks like this:<br><br><pre>;; sec.ns | memory | CPU %\n1541052937.882172509 59m 0.0\n1541052981.122419892 78m 58.0\n1541052981.625876498 199m 85.9\n1541053011.489811184 1.2g 101.8\n</pre><br><br>The data has been produced by <a href=\"https://gist.github.com/holyjak/931a3441982c833f5f8fcdcf54d05c91\">monitor-usage.sh</a>.<br><br><h2>The tools</h2><br><br><h4>Gnuplot 5</h4><br><br>Gnuplot is the simplest, with a lot available out of the box. But it is also somewhat archaic and little flexible.<br><br><!--more--><br><br>Here is the code:<br><br>https://gist.github.com/holyjak/1b58dedae3207b4a56c9abcde5f3fdb5<br><br>And here is an example output:<br><br><img title=\"Usage data in gnuplot\" src=\"https://lh3.googleusercontent.com/kJgLplIChvJ37gBclTBrAI4hWO6Gf47ZGBA0MPJgPd9RgvLe77x_fHsT6VsJaCE52VQfVhRmlSj4JL-knc3nwzoQ_G_PUBUdChChcJqOZ1tBemc5dHuFZxXYeeCEHMFW5qwAUH0JZQB5Fx49ztkGOgM-tHhsvK2mPavjnuljLTbDG8Lr4FlucNVs47UhBBhrqYtV23zo5ttvuRP_2ULDxSYiM9SqpP8OFlQcVaUaKKXXpHeJG5ZGZnw5ZFuEdwnAPJ9L1ZGpHZBR3QJkt6cfLpNaIyIos84QLIVSPhyaUTkfj561uLF22YYiDdYvzvn_hJ4MMmsBqXLM_ErVzBocLlbUWMIEt8P9Fa4trqwS-3DjX_dxMzPNImggvDHMnfmIQASOZJOGWT1Qcg1agmNl6GU7dg4GUXFxLAltgpAavoUh63SDdE5TLQ_EttYOtl0TCOmzLhQseTkjLD15KBXiwXW29j-z-rrdq99bQttfI2zIov9CdmIG11CRTud0efwyj-cVe1VdJfLsyAWAdRA3IS7bisZHPxLGlNmclwb5a0TGoGm31YGjU0Of_YYKLSb_jZPDoF1gW1q3GJtn3Clzxku6ZkRnIrCt8HKtJ_-FHqVMd7aM2bVySkxdwOlmzmb0vHo3P3cjX2G1nupYPIHcUka3=w640-h480-no\" /><br><br>Pros: Feature-rich (support bytes axis, two Y axes, reading data).<br><br>Cons: Archaic language, less flexible; I couldn't stop it from drawing X labels over each other when I had data for a longer period.<br><br><h4>Incanter (JFreeChart)</h4><br><br>Incanter is (was?) the go to tool for data analysis in Clojure and it includes the Java library JFreeChart for charting. There has been some development lately (integrating clojure.core.matrix) but otherwise it is quite stagnating. That's why there have been newer community efforts.<br><br>Here is the first part of the code, that prepares the data for charting (also used for Oz):<br><br>https://gist.github.com/holyjak/c4a88135bc08703d6351754980537055<br><br>And here is the code to format the chart (the most difficult part was to display kB / MB / GB values on the axis in a nice way; I really missed Gnuplot's out-of-the-box support here):<br><br>https://gist.github.com/holyjak/4b22d6810ea16df940224a77f0db9dcc<br><br>That is quite insane amount of work, huh? And the result:<br><br><img title=\"Usage - Incanter\" src=\"https://lh3.googleusercontent.com/cArgyyZNtCUyT_c4qcenImGkQPQgeyOG-rQyy6Ykb48ETv1GGL6VpSdbJ3mRCw84NnSKdEXm4O7t4Ool-43RDMENdRrnZweiiFZCtqIOAajo2-zmtf9_riqcYJlO13sA5SZX7jMKSGsgaQQUaaX5uQsNPQiKh6zTj0w_pEWz-5KqW1Y3rqJK2NuXYHiMBJ9S-ItbR1MPMmBLC4EnusG8KfoEdDA-s6_c0y2xAiCB3H2fpYECMYxQbUoVoC0kjYLJ6sY3jwREKPHNvm1xzZ7cXsRYGO5VZSrURyilOwzpkYGjpoVMoRIMJYAVVr6GSoScO96npyPn3bNUmSG8pBUQmrz5sDX4Uajnw7ro4SabBQQzHf9LKz9_lxYKdGsk2PNFKtIaCbz-INE2lxkVTuJ9OIbl3Bkgpt2bbP3TdBXH8uIFoHGPLZAtn_BZdDV5CMoixYK4kh3tEGnaPUFmCAp-ZrEX-k6h5PInQMoCd6LK9TI-xtCXMj2xPO5G4Ma0Vn0sab7Z8-D4MrIn4JlmYRD_hMakyd2cZ9DXZRNt7ojQNMi5vzSD3SVFu40aEAZMrQ1V7gZOJf1wYmjIUjK790bWGEd_q5FHGiNvPmba9c1phYJXV-LkduoMAyBD6g8ILT6HMpEYqI0LImaiz7POnCVYDIOV=w500-h378-no\" /><br><br><h4>vega-lite via Oz</h4><br><br><blockquote>Vega and Vega-lite visualization grammars: Vega is a declarative format for creating, saving, and sharing visualization designs. With Vega, visualizations are described in JSON, and generate interactive views using either HTML5 Canvas or SVG.</blockquote><br><br><a href=\"https://vega.github.io/\">Vega-lite (and Vega</a>) is the new kid on the block. It has learned a lot from D3 and R's ggplot2 and is intended for data exploration, interactive charts, and making it possible to combine multiple charts on the same page - while making this as simple as possible. It is based on the Grammar of Graphics so it is presumabely well thought-through.<br><br><a href=\"https://github.com/metasoarous/oz/\">Oz</a> is a thin wrapper around vega/vega-lite that makes it possible to interact with the browser from Clojure REPL, with Clojure data.<br><br>(Note: Oz currently uses VL v2.6 while the latest VL is v3rc8, which fixes some limitations in v2.)<br><br>As mentioned above, we use the same <a href=\"https://gist.github.com/holyjak/c4a88135bc08703d6351754980537055\">usage-chart-preparation.clj</a> as the pure-Incanter example to prepare the data for charting. Then, to plot them:<br><br>https://gist.github.com/holyjak/c57c6e31d515259ed05f5a520571bb2c<br><br>It is more work than in Gnuplot but it provides more value and is much more powerful.<br><br>Here is the output (generated with VL v3 so the labels have the same color as the lines):<br><br><img title=\"Usage - vega-lite\" src=\"https://lh3.googleusercontent.com/pLrcmcx7gW2sR4m33MCpsACUGGW9wsf0tdXBZ6wG7cD-fgdZH36fAZBF6hyimXhWap5OZ_MqCLp4NTXs3n5FUQS9trXh1g0RzVo40gJ0SFpis6nHHL8mGLb2WN5Y_kVd2jCTMKJ8nWk2I051UA6p-HbPdYx3isZaN-6qOQLYkj2bS-WPtMNlsGkPqyqeVF-gHC54WPiXSisLQpqi8WHVm5rcx6PqsvY5YIKHGJSgWX9FXGh31bxP32a9NcNwHIWr-5IE12ZeTmIeV2aDH66ixfLhEJ2WiFn6IFj1VITHnbVXYiIkhCytt8_u4rvJboUWMPHYVyP412s2wF7zXBJNGH-HJuZ-phpmCAGJsf4a6iIc_xcRs7kanN2G7MG7z8Zb0PnIToSb3TZFsIZaG6rfkH_AX9tuW3xQdesnmZ0XYhWndPAqUDtLvdgsk_6R6PZ4DuXuZwPudaxzevCtAS9fOYtCgBmVC2WfNICeuJrvFq3BzBlDNOBICBVTEPhpDGTQ-GXmPOpU27ILloNDdA5W7r4SrC_EUACfv6B8ApMLl1bTC9Z-lGVQm_k4m-PRdBuf2fD-f30-SjbGkv7t3Pivfri1BjCIBeFxM7ElGFq4URaMi8PeJ148cFftDSRp6fcB3xULhWLqHmcDt3321OWkCW6y=w804-h251-no\" /><br><br>The awesome thing is that the chart and data can be encoded in an URL so that you can <a>open in in the online Vega Editor and play with it</a>.<br><br>Pros: Good and powerful design, modern, interactive, promising.<br><br>Cons: The community is very small so it is harder to get help, it isn't so mature yet (e.g. it was impossible to add a legend to my multi-layer chart). You have to transform your data into JSON so it likely isn't suitable for huge amounts of it.<br><br><h4>Other options</h4><br><br><a href=\"https://github.com/clojurewerkz/envision\">Clojurewerkz/envision</a> is \"a small, easy to use Clojure library for data processing, cleanup and visualisation. [..] Main idea of this library is to make exploratory analysis more interactive and visual, although in programmer's way.\" ClojureWerkz is known for its commitment to project quality and maintenance so that is good, on the other hand the last code change has been 2 years ago.<br><br>Outside of Clojure, I would expect Python to have some very good charting libraries.<br><br><h2>Conclusion</h2><br><br>Nothing is optimal :-) but vega-lite is very promising, I will continue to use it - and I will also still use Incanter to process and prepare the data.",
  "excerpt": ""
 },
 {
  "title": "Java: Simulating various connection problems with Toxiproxy",
  "published": "2018-11-26 21:55:13",
  "postType": "post",
  "slug": "/2018/11/26/java-understanding-the-different-network-https-exceptions/",
  "status": "publish",
  "tags": [
   "java"
  ],
  "categories": [
   "Languages"
  ],
  "content": "<!-- wp:embed {\"url\":\"https://gist.github.com/holyjak/f3f995173539be80ce518a579496c2ba\",\"type\":\"rich\",\"providerNameSlug\":\"\",\"className\":\"\"} -->\n<figure class=\"wp-block-embed is-type-rich\"><div class=\"wp-block-embed__wrapper\">\nhttps://gist.github.com/holyjak/f3f995173539be80ce518a579496c2ba\n</div></figure>\n<!-- /wp:embed -->",
  "excerpt": ""
 }
]