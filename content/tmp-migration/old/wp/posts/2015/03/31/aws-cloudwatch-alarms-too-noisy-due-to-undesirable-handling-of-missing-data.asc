{:title
 "AWS CloudWatch Alarms Too Noisy Due To Ignoring Missing Data in Averages",
 :date "2015-03-31",
 :layout :post,
 :tags ["monitoring" "DevOps"],
 :tags-orig ["aws" "monitoring" "ops"],
 :categories ["General" "Tools"],
 :extra-css #{}
}

++++
I want to know when our app starts getting slower so I sat up an alarm on the Latency metric of our ELB. According to the AWS Console, "<em>This alarm will trigger when the blue line [average latency over the period of 15 min] goes above the red line [2 sec] for a duration of 45 minutes.</em>" (I.e. it triggers if Latency &gt; 2 for 3 consecutive period(s).) This is exactly what I need - except that it is a lie.<br><br>This night I got 8 alarm/ok notifications even though the average latency has never been over 2 sec for 45 minutes. The problem is that <strong>CloudWatch ignores null/missing data</strong>. So if you have a slow request at 3am and no other request comes until 4am, it will look at [slow, null, null, null] and trigger the alarm.<br><br>So I want to configure it to treat null as 0 and preferably to ignore latency if it only affected a single user. But there is no way to do this in CloudWatch.<br><br><strong>Solution</strong>: I will likely need to run my own job that will read the metrics and produce a normalized, reasonable metric - replacing null / missing data with 0 and weight the average latency by the number of users in the period.
++++
